[
  {
    "episode": 1,
    "reward": -528.46306,
    "length": 621,
    "time": 82.059511,
    "actor_loss": -0.8974376916885376,
    "critic_loss": 0.5391558408737183,
    "ent_coef": 0.5935822129249573,
    "learning_rate": 0.001
  },
  {
    "episode": 2,
    "reward": -417.370726,
    "length": 586,
    "time": 162.083699,
    "actor_loss": 0.43845391273498535,
    "critic_loss": 0.4552057087421417,
    "ent_coef": 0.32990562915802,
    "learning_rate": 0.001
  },
  {
    "episode": 3,
    "reward": -221.613235,
    "length": 171,
    "time": 188.644403,
    "actor_loss": 0.9752346873283386,
    "critic_loss": 0.23426154255867004,
    "ent_coef": 0.2781526744365692,
    "learning_rate": 0.001
  },
  {
    "episode": 4,
    "reward": -326.100967,
    "length": 325,
    "time": 233.402527,
    "actor_loss": 2.073274612426758,
    "critic_loss": 0.6600600481033325,
    "ent_coef": 0.20167584717273712,
    "learning_rate": 0.001
  },
  {
    "episode": 5,
    "reward": -226.263319,
    "length": 187,
    "time": 260.142058,
    "actor_loss": 3.4890267848968506,
    "critic_loss": 199.44728088378906,
    "ent_coef": 0.1674853414297104,
    "learning_rate": 0.001
  },
  {
    "episode": 6,
    "reward": -336.215531,
    "length": 310,
    "time": 305.103797,
    "actor_loss": 3.8882312774658203,
    "critic_loss": 1.0285148620605469,
    "ent_coef": 0.12382987141609192,
    "learning_rate": 0.001
  },
  {
    "episode": 7,
    "reward": -224.007043,
    "length": 189,
    "time": 334.280687,
    "actor_loss": 5.343717575073242,
    "critic_loss": 0.5474390387535095,
    "ent_coef": 0.10374351590871811,
    "learning_rate": 0.001
  },
  {
    "episode": 8,
    "reward": -443.638919,
    "length": 553,
    "time": 408.173893,
    "actor_loss": 6.213184356689453,
    "critic_loss": 0.2600840926170349,
    "ent_coef": 0.0634862408041954,
    "learning_rate": 0.001
  },
  {
    "episode": 9,
    "reward": -171.647545,
    "length": 120,
    "time": 426.635517,
    "actor_loss": 6.514614582061768,
    "critic_loss": 4.4700517654418945,
    "ent_coef": 0.05757032334804535,
    "learning_rate": 0.001
  },
  {
    "episode": 10,
    "reward": -155.720637,
    "length": 111,
    "time": 444.465589,
    "actor_loss": 7.123595237731934,
    "critic_loss": 2.128746747970581,
    "ent_coef": 0.05259042978286743,
    "learning_rate": 0.001
  },
  {
    "episode": 11,
    "reward": -156.698052,
    "length": 108,
    "time": 462.168448,
    "actor_loss": 7.629887104034424,
    "critic_loss": 1.7735522985458374,
    "ent_coef": 0.04858545958995819,
    "learning_rate": 0.001
  },
  {
    "episode": 12,
    "reward": -154.90724,
    "length": 105,
    "time": 479.445173,
    "actor_loss": 7.750821113586426,
    "critic_loss": 1.8747442960739136,
    "ent_coef": 0.04505623131990433,
    "learning_rate": 0.001
  },
  {
    "episode": 13,
    "reward": -150.03511,
    "length": 97,
    "time": 494.457281,
    "actor_loss": 9.316904067993164,
    "critic_loss": 4.7526445388793945,
    "ent_coef": 0.042238183319568634,
    "learning_rate": 0.001
  },
  {
    "episode": 14,
    "reward": -172.693251,
    "length": 137,
    "time": 515.565854,
    "actor_loss": 7.9625325202941895,
    "critic_loss": 0.5911122560501099,
    "ent_coef": 0.03847614303231239,
    "learning_rate": 0.001
  },
  {
    "episode": 15,
    "reward": -148.267969,
    "length": 95,
    "time": 531.377839,
    "actor_loss": 8.641435623168945,
    "critic_loss": 0.5189803242683411,
    "ent_coef": 0.03633631020784378,
    "learning_rate": 0.001
  },
  {
    "episode": 16,
    "reward": -175.868925,
    "length": 132,
    "time": 552.291956,
    "actor_loss": 9.559480667114258,
    "critic_loss": 7.829811096191406,
    "ent_coef": 0.033583346754312515,
    "learning_rate": 0.001
  },
  {
    "episode": 17,
    "reward": -237.801128,
    "length": 237,
    "time": 586.946213,
    "actor_loss": 10.334555625915527,
    "critic_loss": 1.01175856590271,
    "ent_coef": 0.029616985470056534,
    "learning_rate": 0.001
  },
  {
    "episode": 18,
    "reward": -292.566182,
    "length": 291,
    "time": 628.239615,
    "actor_loss": 11.81851577758789,
    "critic_loss": 2.6219534873962402,
    "ent_coef": 0.02564571052789688,
    "learning_rate": 0.001
  },
  {
    "episode": 19,
    "reward": -183.744369,
    "length": 151,
    "time": 650.679233,
    "actor_loss": 11.998937606811523,
    "critic_loss": 1.1303988695144653,
    "ent_coef": 0.024309197440743446,
    "learning_rate": 0.001
  },
  {
    "episode": 20,
    "reward": -208.811457,
    "length": 153,
    "time": 675.21961,
    "actor_loss": 11.106325149536133,
    "critic_loss": 13.445219039916992,
    "ent_coef": 0.02273860014975071,
    "learning_rate": 0.001
  },
  {
    "episode": 21,
    "reward": -144.935807,
    "length": 94,
    "time": 690.080216,
    "actor_loss": 12.057342529296875,
    "critic_loss": 1.6341222524642944,
    "ent_coef": 0.022330498322844505,
    "learning_rate": 0.001
  },
  {
    "episode": 22,
    "reward": -199.418314,
    "length": 156,
    "time": 713.336034,
    "actor_loss": 11.909627914428711,
    "critic_loss": 1.2582043409347534,
    "ent_coef": 0.021015411242842674,
    "learning_rate": 0.001
  },
  {
    "episode": 23,
    "reward": -348.797178,
    "length": 315,
    "time": 756.487289,
    "actor_loss": 13.360879898071289,
    "critic_loss": 1.5675606727600098,
    "ent_coef": 0.019384022802114487,
    "learning_rate": 0.001
  },
  {
    "episode": 24,
    "reward": -198.948878,
    "length": 152,
    "time": 780.778044,
    "actor_loss": 13.249031066894531,
    "critic_loss": 2.890071153640747,
    "ent_coef": 0.019430596381425858,
    "learning_rate": 0.001
  },
  {
    "episode": 25,
    "reward": -146.64394,
    "length": 100,
    "time": 796.277366,
    "actor_loss": 14.435264587402344,
    "critic_loss": 2.8381032943725586,
    "ent_coef": 0.019641287624835968,
    "learning_rate": 0.001
  },
  {
    "episode": 26,
    "reward": -149.031645,
    "length": 105,
    "time": 812.895281,
    "actor_loss": 15.086577415466309,
    "critic_loss": 177.01058959960938,
    "ent_coef": 0.02016356587409973,
    "learning_rate": 0.001
  },
  {
    "episode": 27,
    "reward": -152.169162,
    "length": 114,
    "time": 830.436409,
    "actor_loss": 16.222028732299805,
    "critic_loss": 4.599294662475586,
    "ent_coef": 0.020039711147546768,
    "learning_rate": 0.001
  },
  {
    "episode": 28,
    "reward": -247.279303,
    "length": 218,
    "time": 863.093938,
    "actor_loss": 14.548442840576172,
    "critic_loss": 87.04995727539062,
    "ent_coef": 0.01889815554022789,
    "learning_rate": 0.001
  },
  {
    "episode": 29,
    "reward": -217.15433,
    "length": 169,
    "time": 888.652735,
    "actor_loss": 16.79178810119629,
    "critic_loss": 68.64179992675781,
    "ent_coef": 0.019687579944729805,
    "learning_rate": 0.001
  },
  {
    "episode": 30,
    "reward": -146.276042,
    "length": 89,
    "time": 905.793178,
    "actor_loss": 17.18545150756836,
    "critic_loss": 1.6335158348083496,
    "ent_coef": 0.02001086436212063,
    "learning_rate": 0.001
  },
  {
    "episode": 31,
    "reward": -143.805156,
    "length": 86,
    "time": 923.418899,
    "actor_loss": 17.54755401611328,
    "critic_loss": 2.317534923553467,
    "ent_coef": 0.019959280267357826,
    "learning_rate": 0.001
  },
  {
    "episode": 32,
    "reward": -154.18736,
    "length": 123,
    "time": 942.022005,
    "actor_loss": 18.515274047851562,
    "critic_loss": 2.6618504524230957,
    "ent_coef": 0.020573893561959267,
    "learning_rate": 0.001
  },
  {
    "episode": 33,
    "reward": -153.083529,
    "length": 130,
    "time": 961.764308,
    "actor_loss": 18.922000885009766,
    "critic_loss": 1.4770655632019043,
    "ent_coef": 0.022907352074980736,
    "learning_rate": 0.001
  },
  {
    "episode": 34,
    "reward": -156.855661,
    "length": 108,
    "time": 978.456662,
    "actor_loss": 17.426822662353516,
    "critic_loss": 94.05492401123047,
    "ent_coef": 0.024141738191246986,
    "learning_rate": 0.001
  },
  {
    "episode": 35,
    "reward": -166.209147,
    "length": 123,
    "time": 999.016892,
    "actor_loss": 17.731653213500977,
    "critic_loss": 47.4970703125,
    "ent_coef": 0.024369854480028152,
    "learning_rate": 0.001
  },
  {
    "episode": 36,
    "reward": -160.872676,
    "length": 126,
    "time": 1019.279935,
    "actor_loss": 19.152896881103516,
    "critic_loss": 20.70767593383789,
    "ent_coef": 0.02516215853393078,
    "learning_rate": 0.001
  },
  {
    "episode": 37,
    "reward": -155.208492,
    "length": 139,
    "time": 1040.781237,
    "actor_loss": 19.61662483215332,
    "critic_loss": 1.2374482154846191,
    "ent_coef": 0.026124784722924232,
    "learning_rate": 0.001
  },
  {
    "episode": 38,
    "reward": -160.714267,
    "length": 125,
    "time": 1063.276627,
    "actor_loss": 20.11644172668457,
    "critic_loss": 1.1537052392959595,
    "ent_coef": 0.027106069028377533,
    "learning_rate": 0.001
  },
  {
    "episode": 39,
    "reward": -163.304677,
    "length": 130,
    "time": 1084.933929,
    "actor_loss": 18.947914123535156,
    "critic_loss": 3.7359485626220703,
    "ent_coef": 0.027831487357616425,
    "learning_rate": 0.001
  },
  {
    "episode": 40,
    "reward": -155.76587,
    "length": 108,
    "time": 1105.176296,
    "actor_loss": 19.87822723388672,
    "critic_loss": 27.466556549072266,
    "ent_coef": 0.027987318113446236,
    "learning_rate": 0.001
  },
  {
    "episode": 41,
    "reward": 86.570348,
    "length": 76,
    "time": 1119.269749,
    "actor_loss": 19.81629180908203,
    "critic_loss": 36.26184844970703,
    "ent_coef": 0.027738796547055244,
    "learning_rate": 0.001
  },
  {
    "episode": 42,
    "reward": -154.948887,
    "length": 107,
    "time": 1137.155772,
    "actor_loss": 19.751544952392578,
    "critic_loss": 0.5991328954696655,
    "ent_coef": 0.02891376055777073,
    "learning_rate": 0.001
  },
  {
    "episode": 43,
    "reward": -158.633729,
    "length": 120,
    "time": 1156.860393,
    "actor_loss": 21.65546417236328,
    "critic_loss": 5.265241622924805,
    "ent_coef": 0.029494740068912506,
    "learning_rate": 0.001
  },
  {
    "episode": 44,
    "reward": -241.712493,
    "length": 195,
    "time": 1188.935844,
    "actor_loss": 24.347614288330078,
    "critic_loss": 1.2567553520202637,
    "ent_coef": 0.02784235216677189,
    "learning_rate": 0.001
  },
  {
    "episode": 45,
    "reward": -156.185308,
    "length": 106,
    "time": 1205.72245,
    "actor_loss": 20.282012939453125,
    "critic_loss": 0.7987961769104004,
    "ent_coef": 0.027821866795420647,
    "learning_rate": 0.001
  },
  {
    "episode": 46,
    "reward": -153.239065,
    "length": 110,
    "time": 1224.810098,
    "actor_loss": 21.19933319091797,
    "critic_loss": 0.5945807099342346,
    "ent_coef": 0.028216801583766937,
    "learning_rate": 0.001
  },
  {
    "episode": 47,
    "reward": -159.44874,
    "length": 137,
    "time": 1245.788788,
    "actor_loss": 21.16398048400879,
    "critic_loss": 7.60568904876709,
    "ent_coef": 0.026888541877269745,
    "learning_rate": 0.001
  },
  {
    "episode": 48,
    "reward": -162.816136,
    "length": 117,
    "time": 1264.449074,
    "actor_loss": 23.01354217529297,
    "critic_loss": 0.7984114289283752,
    "ent_coef": 0.02648807130753994,
    "learning_rate": 0.001
  },
  {
    "episode": 49,
    "reward": 82.923734,
    "length": 83,
    "time": 1278.037953,
    "actor_loss": 21.5604248046875,
    "critic_loss": 66.33747863769531,
    "ent_coef": 0.025982897728681564,
    "learning_rate": 0.001
  },
  {
    "episode": 50,
    "reward": 78.417903,
    "length": 83,
    "time": 1292.035972,
    "actor_loss": 23.28548812866211,
    "critic_loss": 1.653236746788025,
    "ent_coef": 0.02509668655693531,
    "learning_rate": 0.001
  },
  {
    "episode": 51,
    "reward": -188.86778,
    "length": 152,
    "time": 1316.254299,
    "actor_loss": 22.801671981811523,
    "critic_loss": 116.75454711914062,
    "ent_coef": 0.0244740042835474,
    "learning_rate": 0.001
  },
  {
    "episode": 52,
    "reward": -184.374676,
    "length": 141,
    "time": 1337.340138,
    "actor_loss": 21.60883140563965,
    "critic_loss": 131.147705078125,
    "ent_coef": 0.023180721327662468,
    "learning_rate": 0.001
  },
  {
    "episode": 53,
    "reward": -170.757028,
    "length": 129,
    "time": 1356.861457,
    "actor_loss": 23.40481185913086,
    "critic_loss": 1.150998830795288,
    "ent_coef": 0.024706337600946426,
    "learning_rate": 0.001
  },
  {
    "episode": 54,
    "reward": -168.336125,
    "length": 115,
    "time": 1377.163027,
    "actor_loss": 24.55368423461914,
    "critic_loss": 0.9624100923538208,
    "ent_coef": 0.02625999040901661,
    "learning_rate": 0.001
  },
  {
    "episode": 55,
    "reward": -145.47024,
    "length": 92,
    "time": 1393.282428,
    "actor_loss": 23.161556243896484,
    "critic_loss": 0.9298032522201538,
    "ent_coef": 0.02735835313796997,
    "learning_rate": 0.001
  },
  {
    "episode": 56,
    "reward": -160.172326,
    "length": 122,
    "time": 1419.043243,
    "actor_loss": 26.19900894165039,
    "critic_loss": 303.7442321777344,
    "ent_coef": 0.029525641351938248,
    "learning_rate": 0.001
  },
  {
    "episode": 57,
    "reward": -156.58784,
    "length": 130,
    "time": 1438.762445,
    "actor_loss": 22.61540985107422,
    "critic_loss": 97.0584945678711,
    "ent_coef": 0.029875880107283592,
    "learning_rate": 0.001
  },
  {
    "episode": 58,
    "reward": 88.005499,
    "length": 75,
    "time": 1453.801499,
    "actor_loss": 25.98407745361328,
    "critic_loss": 1.9026970863342285,
    "ent_coef": 0.031794313341379166,
    "learning_rate": 0.001
  },
  {
    "episode": 59,
    "reward": -150.871641,
    "length": 95,
    "time": 1472.649247,
    "actor_loss": 27.120569229125977,
    "critic_loss": 1.7232359647750854,
    "ent_coef": 0.033862121403217316,
    "learning_rate": 0.001
  },
  {
    "episode": 60,
    "reward": -157.537696,
    "length": 131,
    "time": 1491.90375,
    "actor_loss": 22.900991439819336,
    "critic_loss": 1.7522512674331665,
    "ent_coef": 0.037073079496622086,
    "learning_rate": 0.001
  },
  {
    "episode": 61,
    "reward": -153.730491,
    "length": 110,
    "time": 1509.580514,
    "actor_loss": 27.12734603881836,
    "critic_loss": 9.83875560760498,
    "ent_coef": 0.03728443384170532,
    "learning_rate": 0.001
  },
  {
    "episode": 62,
    "reward": -153.999341,
    "length": 108,
    "time": 1527.32717,
    "actor_loss": 25.833847045898438,
    "critic_loss": 1.4056432247161865,
    "ent_coef": 0.03459872677922249,
    "learning_rate": 0.001
  },
  {
    "episode": 63,
    "reward": -151.072435,
    "length": 89,
    "time": 1543.303385,
    "actor_loss": 25.053016662597656,
    "critic_loss": 12.250310897827148,
    "ent_coef": 0.030536241829395294,
    "learning_rate": 0.001
  },
  {
    "episode": 64,
    "reward": -175.159206,
    "length": 156,
    "time": 1567.729152,
    "actor_loss": 30.13020133972168,
    "critic_loss": 56.13447952270508,
    "ent_coef": 0.02711932733654976,
    "learning_rate": 0.001
  },
  {
    "episode": 65,
    "reward": -152.636091,
    "length": 130,
    "time": 1587.216603,
    "actor_loss": 29.95433807373047,
    "critic_loss": 2.6837759017944336,
    "ent_coef": 0.02866019494831562,
    "learning_rate": 0.001
  },
  {
    "episode": 66,
    "reward": 84.551604,
    "length": 78,
    "time": 1600.744162,
    "actor_loss": 28.098955154418945,
    "critic_loss": 1.7428239583969116,
    "ent_coef": 0.03028710186481476,
    "learning_rate": 0.001
  },
  {
    "episode": 67,
    "reward": -157.26664,
    "length": 130,
    "time": 1620.571764,
    "actor_loss": 28.691486358642578,
    "critic_loss": 2.3313214778900146,
    "ent_coef": 0.0338946171104908,
    "learning_rate": 0.001
  },
  {
    "episode": 68,
    "reward": -153.308332,
    "length": 121,
    "time": 1639.766251,
    "actor_loss": 29.486968994140625,
    "critic_loss": 2.412324905395508,
    "ent_coef": 0.03770560398697853,
    "learning_rate": 0.001
  },
  {
    "episode": 69,
    "reward": -149.504073,
    "length": 103,
    "time": 1658.895566,
    "actor_loss": 29.4184627532959,
    "critic_loss": 94.06240844726562,
    "ent_coef": 0.037866342812776566,
    "learning_rate": 0.001
  },
  {
    "episode": 70,
    "reward": -165.054961,
    "length": 134,
    "time": 1680.362957,
    "actor_loss": 29.255661010742188,
    "critic_loss": 29.87366485595703,
    "ent_coef": 0.0388607420027256,
    "learning_rate": 0.001
  },
  {
    "episode": 71,
    "reward": 88.590666,
    "length": 70,
    "time": 1693.253663,
    "actor_loss": 30.010215759277344,
    "critic_loss": 305.756103515625,
    "ent_coef": 0.03729167953133583,
    "learning_rate": 0.001
  },
  {
    "episode": 72,
    "reward": -162.32456,
    "length": 123,
    "time": 1712.065135,
    "actor_loss": 31.687965393066406,
    "critic_loss": 178.67767333984375,
    "ent_coef": 0.03779321536421776,
    "learning_rate": 0.001
  },
  {
    "episode": 73,
    "reward": -160.873924,
    "length": 122,
    "time": 1733.240311,
    "actor_loss": 29.449689865112305,
    "critic_loss": 300.81207275390625,
    "ent_coef": 0.03807021677494049,
    "learning_rate": 0.001
  },
  {
    "episode": 74,
    "reward": -153.23804,
    "length": 110,
    "time": 1750.159821,
    "actor_loss": 29.867942810058594,
    "critic_loss": 1.9272915124893188,
    "ent_coef": 0.04236624017357826,
    "learning_rate": 0.001
  },
  {
    "episode": 75,
    "reward": -150.996032,
    "length": 100,
    "time": 1765.927789,
    "actor_loss": 29.08804702758789,
    "critic_loss": 4.44866943359375,
    "ent_coef": 0.03970735892653465,
    "learning_rate": 0.001
  },
  {
    "episode": 76,
    "reward": -157.401842,
    "length": 110,
    "time": 1785.582419,
    "actor_loss": 30.653303146362305,
    "critic_loss": 1.5542168617248535,
    "ent_coef": 0.041481863707304,
    "learning_rate": 0.001
  },
  {
    "episode": 77,
    "reward": -147.553438,
    "length": 93,
    "time": 1803.187021,
    "actor_loss": 31.53658676147461,
    "critic_loss": 100.826171875,
    "ent_coef": 0.04374922066926956,
    "learning_rate": 0.001
  },
  {
    "episode": 78,
    "reward": -162.144447,
    "length": 122,
    "time": 1821.630819,
    "actor_loss": 31.75341796875,
    "critic_loss": 15.001015663146973,
    "ent_coef": 0.041381534188985825,
    "learning_rate": 0.001
  },
  {
    "episode": 79,
    "reward": -161.610716,
    "length": 110,
    "time": 1839.262206,
    "actor_loss": 30.342666625976562,
    "critic_loss": 614.7391967773438,
    "ent_coef": 0.038826823234558105,
    "learning_rate": 0.001
  },
  {
    "episode": 80,
    "reward": -146.166241,
    "length": 102,
    "time": 1855.244561,
    "actor_loss": 29.802608489990234,
    "critic_loss": 3.0907340049743652,
    "ent_coef": 0.03888709098100662,
    "learning_rate": 0.001
  },
  {
    "episode": 81,
    "reward": -149.052174,
    "length": 94,
    "time": 1871.319714,
    "actor_loss": 30.816431045532227,
    "critic_loss": 117.29910278320312,
    "ent_coef": 0.039965786039829254,
    "learning_rate": 0.001
  },
  {
    "episode": 82,
    "reward": -151.951152,
    "length": 109,
    "time": 1889.875983,
    "actor_loss": 30.225616455078125,
    "critic_loss": 2.079927921295166,
    "ent_coef": 0.041125621646642685,
    "learning_rate": 0.001
  },
  {
    "episode": 83,
    "reward": -174.614786,
    "length": 135,
    "time": 1911.719601,
    "actor_loss": 32.8364372253418,
    "critic_loss": 19.399574279785156,
    "ent_coef": 0.04564782977104187,
    "learning_rate": 0.001
  },
  {
    "episode": 84,
    "reward": -154.269404,
    "length": 98,
    "time": 1928.105256,
    "actor_loss": 32.27729797363281,
    "critic_loss": 2.5326476097106934,
    "ent_coef": 0.046183932572603226,
    "learning_rate": 0.001
  },
  {
    "episode": 85,
    "reward": -149.544952,
    "length": 99,
    "time": 1945.694899,
    "actor_loss": 30.598331451416016,
    "critic_loss": 3.9277968406677246,
    "ent_coef": 0.04625767841935158,
    "learning_rate": 0.001
  },
  {
    "episode": 86,
    "reward": -155.988982,
    "length": 114,
    "time": 1967.817173,
    "actor_loss": 31.170238494873047,
    "critic_loss": 276.495849609375,
    "ent_coef": 0.0466289184987545,
    "learning_rate": 0.001
  },
  {
    "episode": 87,
    "reward": -166.202564,
    "length": 118,
    "time": 1989.511831,
    "actor_loss": 28.714763641357422,
    "critic_loss": 44.7988166809082,
    "ent_coef": 0.04918491095304489,
    "learning_rate": 0.001
  },
  {
    "episode": 88,
    "reward": -143.331682,
    "length": 89,
    "time": 2004.594638,
    "actor_loss": 29.007104873657227,
    "critic_loss": 3.4975857734680176,
    "ent_coef": 0.050131503492593765,
    "learning_rate": 0.001
  },
  {
    "episode": 89,
    "reward": -149.646443,
    "length": 107,
    "time": 2020.767018,
    "actor_loss": 30.408119201660156,
    "critic_loss": 50.852783203125,
    "ent_coef": 0.05024001747369766,
    "learning_rate": 0.001
  },
  {
    "episode": 90,
    "reward": -154.097511,
    "length": 104,
    "time": 2036.877748,
    "actor_loss": 32.94258499145508,
    "critic_loss": 15.559392929077148,
    "ent_coef": 0.049876902252435684,
    "learning_rate": 0.001
  },
  {
    "episode": 91,
    "reward": -160.486176,
    "length": 121,
    "time": 2058.627663,
    "actor_loss": 30.142730712890625,
    "critic_loss": 1.1597418785095215,
    "ent_coef": 0.04824599623680115,
    "learning_rate": 0.001
  },
  {
    "episode": 92,
    "reward": -151.072257,
    "length": 116,
    "time": 2077.074053,
    "actor_loss": 30.8193359375,
    "critic_loss": 1.4051730632781982,
    "ent_coef": 0.049935050308704376,
    "learning_rate": 0.001
  },
  {
    "episode": 93,
    "reward": -153.060355,
    "length": 109,
    "time": 2093.559201,
    "actor_loss": 30.38927459716797,
    "critic_loss": 264.54986572265625,
    "ent_coef": 0.05237716808915138,
    "learning_rate": 0.001
  },
  {
    "episode": 94,
    "reward": -158.150515,
    "length": 111,
    "time": 2110.577364,
    "actor_loss": 31.14488410949707,
    "critic_loss": 1.2495548725128174,
    "ent_coef": 0.055654630064964294,
    "learning_rate": 0.001
  },
  {
    "episode": 95,
    "reward": -154.618283,
    "length": 117,
    "time": 2128.824563,
    "actor_loss": 31.0799617767334,
    "critic_loss": 4.804074287414551,
    "ent_coef": 0.05976036563515663,
    "learning_rate": 0.001
  },
  {
    "episode": 96,
    "reward": -150.196219,
    "length": 101,
    "time": 2147.324118,
    "actor_loss": 30.24077606201172,
    "critic_loss": 15.612228393554688,
    "ent_coef": 0.060480404645204544,
    "learning_rate": 0.001
  },
  {
    "episode": 97,
    "reward": -154.887499,
    "length": 109,
    "time": 2164.892206,
    "actor_loss": 32.357242584228516,
    "critic_loss": 1.8674310445785522,
    "ent_coef": 0.06099674105644226,
    "learning_rate": 0.001
  },
  {
    "episode": 98,
    "reward": -169.376774,
    "length": 122,
    "time": 2184.774923,
    "actor_loss": 32.811920166015625,
    "critic_loss": 51.701866149902344,
    "ent_coef": 0.0632995069026947,
    "learning_rate": 0.001
  },
  {
    "episode": 99,
    "reward": -149.729361,
    "length": 98,
    "time": 2200.967335,
    "actor_loss": 30.666221618652344,
    "critic_loss": 3.2296080589294434,
    "ent_coef": 0.06582727283239365,
    "learning_rate": 0.001
  },
  {
    "episode": 100,
    "reward": -151.854304,
    "length": 102,
    "time": 2219.086038,
    "actor_loss": 33.25495910644531,
    "critic_loss": 284.29132080078125,
    "ent_coef": 0.06798723340034485,
    "learning_rate": 0.001
  },
  {
    "episode": 101,
    "reward": -152.047864,
    "length": 105,
    "time": 2236.540718,
    "actor_loss": 32.87431335449219,
    "critic_loss": 3.364600896835327,
    "ent_coef": 0.06577543914318085,
    "learning_rate": 0.001
  },
  {
    "episode": 102,
    "reward": -151.829921,
    "length": 104,
    "time": 2252.676174,
    "actor_loss": 31.87186050415039,
    "critic_loss": 126.02076721191406,
    "ent_coef": 0.06706508994102478,
    "learning_rate": 0.001
  },
  {
    "episode": 103,
    "reward": -149.795602,
    "length": 102,
    "time": 2268.626398,
    "actor_loss": 30.78711700439453,
    "critic_loss": 3.2766284942626953,
    "ent_coef": 0.06986115127801895,
    "learning_rate": 0.001
  },
  {
    "episode": 104,
    "reward": -148.915911,
    "length": 99,
    "time": 2285.594559,
    "actor_loss": 33.22015380859375,
    "critic_loss": 283.41766357421875,
    "ent_coef": 0.07101666182279587,
    "learning_rate": 0.001
  },
  {
    "episode": 105,
    "reward": -148.845911,
    "length": 93,
    "time": 2300.426611,
    "actor_loss": 32.10977554321289,
    "critic_loss": 1.440551996231079,
    "ent_coef": 0.07179982960224152,
    "learning_rate": 0.001
  },
  {
    "episode": 106,
    "reward": -146.037321,
    "length": 94,
    "time": 2317.410909,
    "actor_loss": 31.975858688354492,
    "critic_loss": 2.540900945663452,
    "ent_coef": 0.07010401785373688,
    "learning_rate": 0.001
  },
  {
    "episode": 107,
    "reward": -155.047823,
    "length": 112,
    "time": 2334.525017,
    "actor_loss": 32.777793884277344,
    "critic_loss": 3.6928741931915283,
    "ent_coef": 0.07037118077278137,
    "learning_rate": 0.001
  },
  {
    "episode": 108,
    "reward": -150.969169,
    "length": 96,
    "time": 2349.940142,
    "actor_loss": 34.03485870361328,
    "critic_loss": 6.347500324249268,
    "ent_coef": 0.06768888980150223,
    "learning_rate": 0.001
  },
  {
    "episode": 109,
    "reward": -141.104236,
    "length": 95,
    "time": 2364.899252,
    "actor_loss": 34.461341857910156,
    "critic_loss": 81.21528625488281,
    "ent_coef": 0.06803085654973984,
    "learning_rate": 0.001
  },
  {
    "episode": 110,
    "reward": -149.448724,
    "length": 97,
    "time": 2382.997747,
    "actor_loss": 33.22330093383789,
    "critic_loss": 161.2052001953125,
    "ent_coef": 0.06561857461929321,
    "learning_rate": 0.001
  },
  {
    "episode": 111,
    "reward": -158.648219,
    "length": 122,
    "time": 2402.352396,
    "actor_loss": 32.878231048583984,
    "critic_loss": 19.57279396057129,
    "ent_coef": 0.06145285442471504,
    "learning_rate": 0.001
  },
  {
    "episode": 112,
    "reward": -160.450458,
    "length": 130,
    "time": 2422.866687,
    "actor_loss": 31.812660217285156,
    "critic_loss": 55.4124755859375,
    "ent_coef": 0.05888478085398674,
    "learning_rate": 0.001
  },
  {
    "episode": 113,
    "reward": -159.057366,
    "length": 101,
    "time": 2442.391384,
    "actor_loss": 35.49168014526367,
    "critic_loss": 189.77044677734375,
    "ent_coef": 0.06077297776937485,
    "learning_rate": 0.001
  },
  {
    "episode": 114,
    "reward": -149.700663,
    "length": 112,
    "time": 2462.662215,
    "actor_loss": 32.84208679199219,
    "critic_loss": 38.524200439453125,
    "ent_coef": 0.05822749435901642,
    "learning_rate": 0.001
  },
  {
    "episode": 115,
    "reward": -166.773082,
    "length": 135,
    "time": 2485.49642,
    "actor_loss": 34.7774658203125,
    "critic_loss": 5.621549606323242,
    "ent_coef": 0.058581531047821045,
    "learning_rate": 0.001
  },
  {
    "episode": 116,
    "reward": -162.42705,
    "length": 134,
    "time": 2507.374265,
    "actor_loss": 35.11147689819336,
    "critic_loss": 10.654499053955078,
    "ent_coef": 0.05884518846869469,
    "learning_rate": 0.001
  },
  {
    "episode": 117,
    "reward": -161.040364,
    "length": 117,
    "time": 2526.164844,
    "actor_loss": 34.39204406738281,
    "critic_loss": 263.30523681640625,
    "ent_coef": 0.05752713233232498,
    "learning_rate": 0.001
  },
  {
    "episode": 118,
    "reward": -160.6119,
    "length": 116,
    "time": 2543.895222,
    "actor_loss": 33.934452056884766,
    "critic_loss": 0.8460649251937866,
    "ent_coef": 0.0594414658844471,
    "learning_rate": 0.001
  },
  {
    "episode": 119,
    "reward": -147.558415,
    "length": 108,
    "time": 2561.360182,
    "actor_loss": 33.189613342285156,
    "critic_loss": 154.74224853515625,
    "ent_coef": 0.060591693967580795,
    "learning_rate": 0.001
  },
  {
    "episode": 120,
    "reward": -159.597052,
    "length": 132,
    "time": 2582.15811,
    "actor_loss": 36.01785659790039,
    "critic_loss": 3.7678840160369873,
    "ent_coef": 0.060838572680950165,
    "learning_rate": 0.001
  },
  {
    "episode": 121,
    "reward": -162.384206,
    "length": 119,
    "time": 2604.448292,
    "actor_loss": 34.974754333496094,
    "critic_loss": 3.3465912342071533,
    "ent_coef": 0.06042420491576195,
    "learning_rate": 0.001
  },
  {
    "episode": 122,
    "reward": -163.706088,
    "length": 127,
    "time": 2623.470166,
    "actor_loss": 36.041080474853516,
    "critic_loss": 52.0262565612793,
    "ent_coef": 0.0580749437212944,
    "learning_rate": 0.001
  },
  {
    "episode": 123,
    "reward": -153.224362,
    "length": 114,
    "time": 2640.851692,
    "actor_loss": 34.59651184082031,
    "critic_loss": 3.143430233001709,
    "ent_coef": 0.055126503109931946,
    "learning_rate": 0.001
  },
  {
    "episode": 124,
    "reward": -160.532041,
    "length": 115,
    "time": 2658.551237,
    "actor_loss": 33.910484313964844,
    "critic_loss": 201.72952270507812,
    "ent_coef": 0.05429694429039955,
    "learning_rate": 0.001
  },
  {
    "episode": 125,
    "reward": -155.322334,
    "length": 117,
    "time": 2679.10499,
    "actor_loss": 34.57795715332031,
    "critic_loss": 20.965621948242188,
    "ent_coef": 0.054724324494600296,
    "learning_rate": 0.001
  },
  {
    "episode": 126,
    "reward": -175.288432,
    "length": 141,
    "time": 2700.007281,
    "actor_loss": 35.039817810058594,
    "critic_loss": 99.0802001953125,
    "ent_coef": 0.0462447889149189,
    "learning_rate": 0.001
  },
  {
    "episode": 127,
    "reward": -165.193736,
    "length": 126,
    "time": 2719.679214,
    "actor_loss": 34.02949523925781,
    "critic_loss": 1.271143913269043,
    "ent_coef": 0.048311974853277206,
    "learning_rate": 0.001
  },
  {
    "episode": 128,
    "reward": -155.996563,
    "length": 117,
    "time": 2741.233918,
    "actor_loss": 32.40473175048828,
    "critic_loss": 2.7863516807556152,
    "ent_coef": 0.046076711267232895,
    "learning_rate": 0.001
  },
  {
    "episode": 129,
    "reward": -158.486899,
    "length": 130,
    "time": 2763.423553,
    "actor_loss": 34.48969268798828,
    "critic_loss": 1.442531704902649,
    "ent_coef": 0.04390649124979973,
    "learning_rate": 0.001
  },
  {
    "episode": 130,
    "reward": -162.755208,
    "length": 131,
    "time": 2783.144314,
    "actor_loss": 34.883155822753906,
    "critic_loss": 1.3066160678863525,
    "ent_coef": 0.0440136156976223,
    "learning_rate": 0.001
  },
  {
    "episode": 131,
    "reward": -183.358382,
    "length": 143,
    "time": 2805.340249,
    "actor_loss": 35.5084228515625,
    "critic_loss": 1.0713622570037842,
    "ent_coef": 0.0413019023835659,
    "learning_rate": 0.001
  },
  {
    "episode": 132,
    "reward": -155.938699,
    "length": 127,
    "time": 2827.44705,
    "actor_loss": 38.453758239746094,
    "critic_loss": 133.16690063476562,
    "ent_coef": 0.04448778182268143,
    "learning_rate": 0.001
  },
  {
    "episode": 133,
    "reward": -173.917811,
    "length": 150,
    "time": 2850.799858,
    "actor_loss": 36.06695556640625,
    "critic_loss": 1.1167784929275513,
    "ent_coef": 0.045078132301568985,
    "learning_rate": 0.001
  },
  {
    "episode": 134,
    "reward": -158.480131,
    "length": 134,
    "time": 2873.355587,
    "actor_loss": 36.42609405517578,
    "critic_loss": 2.5390257835388184,
    "ent_coef": 0.045734841376543045,
    "learning_rate": 0.001
  },
  {
    "episode": 135,
    "reward": 79.454856,
    "length": 96,
    "time": 2888.772,
    "actor_loss": 37.83028793334961,
    "critic_loss": 115.03849792480469,
    "ent_coef": 0.0443994514644146,
    "learning_rate": 0.001
  },
  {
    "episode": 136,
    "reward": -158.003001,
    "length": 115,
    "time": 2906.084781,
    "actor_loss": 34.553009033203125,
    "critic_loss": 6.9495649337768555,
    "ent_coef": 0.0430479533970356,
    "learning_rate": 0.001
  },
  {
    "episode": 137,
    "reward": -163.910049,
    "length": 130,
    "time": 2925.677581,
    "actor_loss": 38.521400451660156,
    "critic_loss": 3.5833024978637695,
    "ent_coef": 0.03853932395577431,
    "learning_rate": 0.001
  },
  {
    "episode": 138,
    "reward": -157.009275,
    "length": 98,
    "time": 2941.117752,
    "actor_loss": 38.401737213134766,
    "critic_loss": 37.548667907714844,
    "ent_coef": 0.03496868908405304,
    "learning_rate": 0.001
  },
  {
    "episode": 139,
    "reward": -151.130459,
    "length": 127,
    "time": 2960.8868,
    "actor_loss": 39.52851104736328,
    "critic_loss": 30.734004974365234,
    "ent_coef": 0.03655422106385231,
    "learning_rate": 0.001
  },
  {
    "episode": 140,
    "reward": -163.504439,
    "length": 123,
    "time": 2981.137196,
    "actor_loss": 36.10377502441406,
    "critic_loss": 56.82867431640625,
    "ent_coef": 0.0387510322034359,
    "learning_rate": 0.001
  },
  {
    "episode": 141,
    "reward": -163.103982,
    "length": 122,
    "time": 3004.139807,
    "actor_loss": 39.683837890625,
    "critic_loss": 45.74638748168945,
    "ent_coef": 0.03774085268378258,
    "learning_rate": 0.001
  },
  {
    "episode": 142,
    "reward": -176.084921,
    "length": 132,
    "time": 3023.959167,
    "actor_loss": 41.55160140991211,
    "critic_loss": 211.3273468017578,
    "ent_coef": 0.037457894533872604,
    "learning_rate": 0.001
  },
  {
    "episode": 143,
    "reward": 90.307445,
    "length": 88,
    "time": 3039.037171,
    "actor_loss": 37.04518508911133,
    "critic_loss": 65.01924133300781,
    "ent_coef": 0.03969865292310715,
    "learning_rate": 0.001
  },
  {
    "episode": 144,
    "reward": -151.526248,
    "length": 105,
    "time": 3055.318972,
    "actor_loss": 35.87031555175781,
    "critic_loss": 83.43994140625,
    "ent_coef": 0.04596823826432228,
    "learning_rate": 0.001
  },
  {
    "episode": 145,
    "reward": -150.725247,
    "length": 121,
    "time": 3074.595411,
    "actor_loss": 41.583770751953125,
    "critic_loss": 39.91639709472656,
    "ent_coef": 0.0503685288131237,
    "learning_rate": 0.001
  },
  {
    "episode": 146,
    "reward": 83.281254,
    "length": 123,
    "time": 3094.523204,
    "actor_loss": 38.58549118041992,
    "critic_loss": 1.100498080253601,
    "ent_coef": 0.048232320696115494,
    "learning_rate": 0.001
  },
  {
    "episode": 147,
    "reward": 81.991087,
    "length": 79,
    "time": 3107.821329,
    "actor_loss": 37.61503982543945,
    "critic_loss": 3.832592487335205,
    "ent_coef": 0.04725781828165054,
    "learning_rate": 0.001
  },
  {
    "episode": 148,
    "reward": 75.428563,
    "length": 92,
    "time": 3125.133186,
    "actor_loss": 37.30960464477539,
    "critic_loss": 2.585174083709717,
    "ent_coef": 0.047055963426828384,
    "learning_rate": 0.001
  },
  {
    "episode": 149,
    "reward": 78.813248,
    "length": 84,
    "time": 3140.078514,
    "actor_loss": 39.935813903808594,
    "critic_loss": 29.952878952026367,
    "ent_coef": 0.050571247935295105,
    "learning_rate": 0.001
  },
  {
    "episode": 150,
    "reward": -155.436966,
    "length": 107,
    "time": 3160.080472,
    "actor_loss": 41.47369384765625,
    "critic_loss": 2.8913822174072266,
    "ent_coef": 0.052647560834884644,
    "learning_rate": 0.001
  },
  {
    "episode": 151,
    "reward": -168.844508,
    "length": 124,
    "time": 3180.469853,
    "actor_loss": 40.59199905395508,
    "critic_loss": 1.705237865447998,
    "ent_coef": 0.05350513756275177,
    "learning_rate": 0.001
  },
  {
    "episode": 152,
    "reward": 82.536191,
    "length": 82,
    "time": 3193.540019,
    "actor_loss": 37.18880081176758,
    "critic_loss": 30.930644989013672,
    "ent_coef": 0.05384787917137146,
    "learning_rate": 0.001
  },
  {
    "episode": 153,
    "reward": -164.401912,
    "length": 135,
    "time": 3213.775387,
    "actor_loss": 39.335205078125,
    "critic_loss": 60.90297317504883,
    "ent_coef": 0.04918820783495903,
    "learning_rate": 0.001
  },
  {
    "episode": 154,
    "reward": -222.154649,
    "length": 172,
    "time": 3239.180463,
    "actor_loss": 41.561317443847656,
    "critic_loss": 154.92462158203125,
    "ent_coef": 0.04820915684103966,
    "learning_rate": 0.001
  },
  {
    "episode": 155,
    "reward": -180.72822,
    "length": 175,
    "time": 3268.37679,
    "actor_loss": 39.752532958984375,
    "critic_loss": 33.834815979003906,
    "ent_coef": 0.052316538989543915,
    "learning_rate": 0.001
  },
  {
    "episode": 156,
    "reward": -166.669168,
    "length": 130,
    "time": 3287.749906,
    "actor_loss": 40.099700927734375,
    "critic_loss": 2.4823248386383057,
    "ent_coef": 0.05655548721551895,
    "learning_rate": 0.001
  },
  {
    "episode": 157,
    "reward": -152.637362,
    "length": 107,
    "time": 3304.249179,
    "actor_loss": 39.79588317871094,
    "critic_loss": 45.04095458984375,
    "ent_coef": 0.06197131797671318,
    "learning_rate": 0.001
  },
  {
    "episode": 158,
    "reward": -151.787236,
    "length": 104,
    "time": 3320.208634,
    "actor_loss": 40.57963562011719,
    "critic_loss": 22.020315170288086,
    "ent_coef": 0.06684473156929016,
    "learning_rate": 0.001
  },
  {
    "episode": 159,
    "reward": -165.703043,
    "length": 119,
    "time": 3341.831744,
    "actor_loss": 39.13304138183594,
    "critic_loss": 98.53185272216797,
    "ent_coef": 0.06895781308412552,
    "learning_rate": 0.001
  },
  {
    "episode": 160,
    "reward": -155.701913,
    "length": 130,
    "time": 3361.659101,
    "actor_loss": 38.01924133300781,
    "critic_loss": 3.07167387008667,
    "ent_coef": 0.06952673196792603,
    "learning_rate": 0.001
  },
  {
    "episode": 161,
    "reward": -173.032547,
    "length": 132,
    "time": 3383.392079,
    "actor_loss": 40.73674392700195,
    "critic_loss": 8.65274715423584,
    "ent_coef": 0.06892717629671097,
    "learning_rate": 0.001
  },
  {
    "episode": 162,
    "reward": -151.280029,
    "length": 106,
    "time": 3399.871732,
    "actor_loss": 39.27430725097656,
    "critic_loss": 4.786111831665039,
    "ent_coef": 0.06815698742866516,
    "learning_rate": 0.001
  },
  {
    "episode": 163,
    "reward": -159.332191,
    "length": 103,
    "time": 3417.249252,
    "actor_loss": 41.8328857421875,
    "critic_loss": 26.734413146972656,
    "ent_coef": 0.06889398396015167,
    "learning_rate": 0.001
  },
  {
    "episode": 164,
    "reward": -162.354973,
    "length": 142,
    "time": 3439.64591,
    "actor_loss": 40.788352966308594,
    "critic_loss": 1.9542902708053589,
    "ent_coef": 0.06723955273628235,
    "learning_rate": 0.001
  },
  {
    "episode": 165,
    "reward": -178.696162,
    "length": 158,
    "time": 3463.735701,
    "actor_loss": 41.73506546020508,
    "critic_loss": 1.6293258666992188,
    "ent_coef": 0.06681206822395325,
    "learning_rate": 0.001
  },
  {
    "episode": 166,
    "reward": -174.3008,
    "length": 145,
    "time": 3488.370185,
    "actor_loss": 43.84210205078125,
    "critic_loss": 28.847204208374023,
    "ent_coef": 0.060102757066488266,
    "learning_rate": 0.001
  },
  {
    "episode": 167,
    "reward": -170.985214,
    "length": 117,
    "time": 3506.150757,
    "actor_loss": 41.53192138671875,
    "critic_loss": 1.5416938066482544,
    "ent_coef": 0.058330707252025604,
    "learning_rate": 0.001
  },
  {
    "episode": 168,
    "reward": -162.708023,
    "length": 133,
    "time": 3528.505704,
    "actor_loss": 40.53361511230469,
    "critic_loss": 12.742656707763672,
    "ent_coef": 0.058462779968976974,
    "learning_rate": 0.001
  },
  {
    "episode": 169,
    "reward": -169.712877,
    "length": 147,
    "time": 3549.821875,
    "actor_loss": 41.0394287109375,
    "critic_loss": 2.0123634338378906,
    "ent_coef": 0.059746988117694855,
    "learning_rate": 0.001
  },
  {
    "episode": 170,
    "reward": -173.819942,
    "length": 150,
    "time": 3574.441963,
    "actor_loss": 42.79206085205078,
    "critic_loss": 91.95690155029297,
    "ent_coef": 0.0592176578938961,
    "learning_rate": 0.001
  },
  {
    "episode": 171,
    "reward": -166.501613,
    "length": 137,
    "time": 3595.986645,
    "actor_loss": 42.494266510009766,
    "critic_loss": 1.1244747638702393,
    "ent_coef": 0.06468496471643448,
    "learning_rate": 0.001
  },
  {
    "episode": 172,
    "reward": -167.552459,
    "length": 117,
    "time": 3616.343111,
    "actor_loss": 40.933990478515625,
    "critic_loss": 4.743263244628906,
    "ent_coef": 0.06455503404140472,
    "learning_rate": 0.001
  },
  {
    "episode": 173,
    "reward": -154.610508,
    "length": 114,
    "time": 3635.829961,
    "actor_loss": 41.781585693359375,
    "critic_loss": 63.652931213378906,
    "ent_coef": 0.06605084240436554,
    "learning_rate": 0.001
  },
  {
    "episode": 174,
    "reward": -156.076685,
    "length": 121,
    "time": 3655.305405,
    "actor_loss": 43.136985778808594,
    "critic_loss": 87.92268371582031,
    "ent_coef": 0.06790508329868317,
    "learning_rate": 0.001
  },
  {
    "episode": 175,
    "reward": -160.080802,
    "length": 136,
    "time": 3676.356792,
    "actor_loss": 41.07159423828125,
    "critic_loss": 74.24440002441406,
    "ent_coef": 0.06948146224021912,
    "learning_rate": 0.001
  },
  {
    "episode": 176,
    "reward": -163.366069,
    "length": 116,
    "time": 3696.079918,
    "actor_loss": 39.76142501831055,
    "critic_loss": 1.4938232898712158,
    "ent_coef": 0.07333909720182419,
    "learning_rate": 0.001
  },
  {
    "episode": 177,
    "reward": -158.795932,
    "length": 134,
    "time": 3717.382199,
    "actor_loss": 42.869773864746094,
    "critic_loss": 187.9580841064453,
    "ent_coef": 0.07480846345424652,
    "learning_rate": 0.001
  },
  {
    "episode": 178,
    "reward": -167.911939,
    "length": 125,
    "time": 3735.938605,
    "actor_loss": 41.78678512573242,
    "critic_loss": 4.8246378898620605,
    "ent_coef": 0.07649749517440796,
    "learning_rate": 0.001
  },
  {
    "episode": 179,
    "reward": -161.482529,
    "length": 120,
    "time": 3753.816108,
    "actor_loss": 42.788482666015625,
    "critic_loss": 276.50439453125,
    "ent_coef": 0.07201755791902542,
    "learning_rate": 0.001
  },
  {
    "episode": 180,
    "reward": -174.977619,
    "length": 147,
    "time": 3776.427484,
    "actor_loss": 43.82951354980469,
    "critic_loss": 130.09523010253906,
    "ent_coef": 0.06454059481620789,
    "learning_rate": 0.001
  },
  {
    "episode": 181,
    "reward": -184.487765,
    "length": 141,
    "time": 3797.175195,
    "actor_loss": 44.497894287109375,
    "critic_loss": 1.324625015258789,
    "ent_coef": 0.057730577886104584,
    "learning_rate": 0.001
  },
  {
    "episode": 182,
    "reward": -149.823019,
    "length": 92,
    "time": 3811.693803,
    "actor_loss": 44.843040466308594,
    "critic_loss": 106.89288330078125,
    "ent_coef": 0.05499279871582985,
    "learning_rate": 0.001
  },
  {
    "episode": 183,
    "reward": -149.120704,
    "length": 100,
    "time": 3827.108723,
    "actor_loss": 43.027400970458984,
    "critic_loss": 4.815756797790527,
    "ent_coef": 0.04936916381120682,
    "learning_rate": 0.001
  },
  {
    "episode": 184,
    "reward": -145.221097,
    "length": 91,
    "time": 3846.002005,
    "actor_loss": 45.951026916503906,
    "critic_loss": 227.81338500976562,
    "ent_coef": 0.047164250165224075,
    "learning_rate": 0.001
  },
  {
    "episode": 185,
    "reward": -154.210244,
    "length": 142,
    "time": 3868.670972,
    "actor_loss": 42.50465393066406,
    "critic_loss": 6.298435211181641,
    "ent_coef": 0.05503866821527481,
    "learning_rate": 0.001
  },
  {
    "episode": 186,
    "reward": -157.948001,
    "length": 117,
    "time": 3886.182168,
    "actor_loss": 43.978515625,
    "critic_loss": 25.673805236816406,
    "ent_coef": 0.05757207050919533,
    "learning_rate": 0.001
  },
  {
    "episode": 187,
    "reward": -165.065422,
    "length": 119,
    "time": 3904.070617,
    "actor_loss": 40.96807098388672,
    "critic_loss": 2.431182861328125,
    "ent_coef": 0.05577666312456131,
    "learning_rate": 0.001
  },
  {
    "episode": 188,
    "reward": 87.594098,
    "length": 81,
    "time": 3917.205106,
    "actor_loss": 43.52458190917969,
    "critic_loss": 132.99514770507812,
    "ent_coef": 0.054820187389850616,
    "learning_rate": 0.001
  },
  {
    "episode": 189,
    "reward": -163.928504,
    "length": 113,
    "time": 3937.73542,
    "actor_loss": 43.18297576904297,
    "critic_loss": 138.35557556152344,
    "ent_coef": 0.05368857458233833,
    "learning_rate": 0.001
  },
  {
    "episode": 190,
    "reward": -175.345563,
    "length": 126,
    "time": 3957.725657,
    "actor_loss": 43.62310791015625,
    "critic_loss": 8.892467498779297,
    "ent_coef": 0.05515168979763985,
    "learning_rate": 0.001
  },
  {
    "episode": 191,
    "reward": -195.988722,
    "length": 161,
    "time": 3982.466207,
    "actor_loss": 42.94213104248047,
    "critic_loss": 23.46586036682129,
    "ent_coef": 0.053850140422582626,
    "learning_rate": 0.001
  },
  {
    "episode": 192,
    "reward": -170.30432,
    "length": 136,
    "time": 4004.447844,
    "actor_loss": 44.8946647644043,
    "critic_loss": 225.82235717773438,
    "ent_coef": 0.05466357246041298,
    "learning_rate": 0.001
  },
  {
    "episode": 193,
    "reward": -167.42485,
    "length": 129,
    "time": 4026.990784,
    "actor_loss": 45.46399688720703,
    "critic_loss": 91.83641052246094,
    "ent_coef": 0.052080802619457245,
    "learning_rate": 0.001
  },
  {
    "episode": 194,
    "reward": -170.654144,
    "length": 121,
    "time": 4048.602087,
    "actor_loss": 43.694374084472656,
    "critic_loss": 44.80529022216797,
    "ent_coef": 0.054668378084897995,
    "learning_rate": 0.001
  },
  {
    "episode": 195,
    "reward": -178.563744,
    "length": 170,
    "time": 4077.841892,
    "actor_loss": 45.43892288208008,
    "critic_loss": 30.046630859375,
    "ent_coef": 0.06371098756790161,
    "learning_rate": 0.001
  },
  {
    "episode": 196,
    "reward": -191.432899,
    "length": 166,
    "time": 4103.655391,
    "actor_loss": 43.64600372314453,
    "critic_loss": 366.09149169921875,
    "ent_coef": 0.06742067635059357,
    "learning_rate": 0.001
  },
  {
    "episode": 197,
    "reward": -187.170477,
    "length": 187,
    "time": 4134.7941,
    "actor_loss": 44.52705383300781,
    "critic_loss": 4.424421310424805,
    "ent_coef": 0.07525816559791565,
    "learning_rate": 0.001
  },
  {
    "episode": 198,
    "reward": -189.462552,
    "length": 178,
    "time": 4164.830966,
    "actor_loss": 45.75735855102539,
    "critic_loss": 120.76802062988281,
    "ent_coef": 0.07928307354450226,
    "learning_rate": 0.001
  },
  {
    "episode": 199,
    "reward": -189.134849,
    "length": 151,
    "time": 4188.465048,
    "actor_loss": 47.15984344482422,
    "critic_loss": 52.8129997253418,
    "ent_coef": 0.0801074355840683,
    "learning_rate": 0.001
  },
  {
    "episode": 200,
    "reward": -177.514711,
    "length": 116,
    "time": 4209.902683,
    "actor_loss": 46.2598762512207,
    "critic_loss": 3.613497257232666,
    "ent_coef": 0.09048458933830261,
    "learning_rate": 0.001
  },
  {
    "episode": 201,
    "reward": -148.794999,
    "length": 99,
    "time": 4228.699246,
    "actor_loss": 46.43852233886719,
    "critic_loss": 42.56528854370117,
    "ent_coef": 0.09763972461223602,
    "learning_rate": 0.001
  },
  {
    "episode": 202,
    "reward": -174.793989,
    "length": 120,
    "time": 4249.486027,
    "actor_loss": 44.321441650390625,
    "critic_loss": 6.032611846923828,
    "ent_coef": 0.10330858081579208,
    "learning_rate": 0.001
  },
  {
    "episode": 203,
    "reward": -187.084596,
    "length": 142,
    "time": 4272.262247,
    "actor_loss": 44.16707992553711,
    "critic_loss": 46.91621398925781,
    "ent_coef": 0.10426978021860123,
    "learning_rate": 0.001
  },
  {
    "episode": 204,
    "reward": -193.120692,
    "length": 144,
    "time": 4297.639826,
    "actor_loss": 43.81401062011719,
    "critic_loss": 37.72388458251953,
    "ent_coef": 0.1092284768819809,
    "learning_rate": 0.001
  },
  {
    "episode": 205,
    "reward": -234.33464,
    "length": 198,
    "time": 4327.540147,
    "actor_loss": 49.072879791259766,
    "critic_loss": 31.621150970458984,
    "ent_coef": 0.11377622187137604,
    "learning_rate": 0.001
  },
  {
    "episode": 206,
    "reward": -190.614831,
    "length": 157,
    "time": 4356.457142,
    "actor_loss": 47.679962158203125,
    "critic_loss": 82.83301544189453,
    "ent_coef": 0.09138324856758118,
    "learning_rate": 0.001
  },
  {
    "episode": 207,
    "reward": -177.790178,
    "length": 145,
    "time": 4380.382442,
    "actor_loss": 49.1474494934082,
    "critic_loss": 33.45100784301758,
    "ent_coef": 0.07605858892202377,
    "learning_rate": 0.001
  },
  {
    "episode": 208,
    "reward": -160.128591,
    "length": 113,
    "time": 4401.554043,
    "actor_loss": 45.27345275878906,
    "critic_loss": 2.8545467853546143,
    "ent_coef": 0.07064345479011536,
    "learning_rate": 0.001
  },
  {
    "episode": 209,
    "reward": -169.943138,
    "length": 118,
    "time": 4421.836907,
    "actor_loss": 45.90892791748047,
    "critic_loss": 41.06736373901367,
    "ent_coef": 0.07565921545028687,
    "learning_rate": 0.001
  },
  {
    "episode": 210,
    "reward": -174.495714,
    "length": 153,
    "time": 4448.417507,
    "actor_loss": 46.95382308959961,
    "critic_loss": 88.30775451660156,
    "ent_coef": 0.07842142879962921,
    "learning_rate": 0.001
  },
  {
    "episode": 211,
    "reward": -184.056416,
    "length": 143,
    "time": 4474.41201,
    "actor_loss": 45.29059600830078,
    "critic_loss": 226.05926513671875,
    "ent_coef": 0.08114560693502426,
    "learning_rate": 0.001
  },
  {
    "episode": 212,
    "reward": -186.982058,
    "length": 136,
    "time": 4497.318002,
    "actor_loss": 46.65129089355469,
    "critic_loss": 13.99013614654541,
    "ent_coef": 0.08564494550228119,
    "learning_rate": 0.001
  },
  {
    "episode": 213,
    "reward": -175.858731,
    "length": 118,
    "time": 4517.635879,
    "actor_loss": 45.78784942626953,
    "critic_loss": 304.09918212890625,
    "ent_coef": 0.09144794195890427,
    "learning_rate": 0.001
  },
  {
    "episode": 214,
    "reward": -180.27617,
    "length": 139,
    "time": 4542.460162,
    "actor_loss": 43.55378341674805,
    "critic_loss": 3.2762136459350586,
    "ent_coef": 0.08896443247795105,
    "learning_rate": 0.001
  },
  {
    "episode": 215,
    "reward": -181.468363,
    "length": 127,
    "time": 4562.885084,
    "actor_loss": 46.024837493896484,
    "critic_loss": 50.84636688232422,
    "ent_coef": 0.09473282843828201,
    "learning_rate": 0.001
  },
  {
    "episode": 216,
    "reward": -178.6342,
    "length": 139,
    "time": 4586.784165,
    "actor_loss": 48.969913482666016,
    "critic_loss": 2.412113666534424,
    "ent_coef": 0.08814273774623871,
    "learning_rate": 0.001
  },
  {
    "episode": 217,
    "reward": -180.584095,
    "length": 132,
    "time": 4608.835444,
    "actor_loss": 46.815311431884766,
    "critic_loss": 3.550013780593872,
    "ent_coef": 0.08894934505224228,
    "learning_rate": 0.001
  },
  {
    "episode": 218,
    "reward": -176.98658,
    "length": 137,
    "time": 4631.272149,
    "actor_loss": 44.357757568359375,
    "critic_loss": 2.5492351055145264,
    "ent_coef": 0.09036101400852203,
    "learning_rate": 0.001
  },
  {
    "episode": 219,
    "reward": -187.023702,
    "length": 150,
    "time": 4655.603304,
    "actor_loss": 46.22834396362305,
    "critic_loss": 5.772290229797363,
    "ent_coef": 0.07887022197246552,
    "learning_rate": 0.001
  },
  {
    "episode": 220,
    "reward": -189.043657,
    "length": 153,
    "time": 4680.39841,
    "actor_loss": 46.629859924316406,
    "critic_loss": 3.892946481704712,
    "ent_coef": 0.07659681886434555,
    "learning_rate": 0.001
  },
  {
    "episode": 221,
    "reward": -178.273846,
    "length": 136,
    "time": 4704.574789,
    "actor_loss": 48.36347961425781,
    "critic_loss": 28.18120574951172,
    "ent_coef": 0.07683788985013962,
    "learning_rate": 0.001
  },
  {
    "episode": 222,
    "reward": -182.001563,
    "length": 129,
    "time": 4727.352903,
    "actor_loss": 48.29375457763672,
    "critic_loss": 14.013086318969727,
    "ent_coef": 0.07786701619625092,
    "learning_rate": 0.001
  },
  {
    "episode": 223,
    "reward": -155.301632,
    "length": 91,
    "time": 4744.46466,
    "actor_loss": 46.661865234375,
    "critic_loss": 162.69931030273438,
    "ent_coef": 0.06780458986759186,
    "learning_rate": 0.001
  },
  {
    "episode": 224,
    "reward": -162.856091,
    "length": 129,
    "time": 4766.929434,
    "actor_loss": 48.85823059082031,
    "critic_loss": 4.5303850173950195,
    "ent_coef": 0.05886915698647499,
    "learning_rate": 0.001
  },
  {
    "episode": 225,
    "reward": -164.125278,
    "length": 117,
    "time": 4787.217567,
    "actor_loss": 44.259098052978516,
    "critic_loss": 4.057868003845215,
    "ent_coef": 0.05406138300895691,
    "learning_rate": 0.001
  },
  {
    "episode": 226,
    "reward": -162.134957,
    "length": 126,
    "time": 4809.572772,
    "actor_loss": 47.052005767822266,
    "critic_loss": 9.80253791809082,
    "ent_coef": 0.0501144677400589,
    "learning_rate": 0.001
  },
  {
    "episode": 227,
    "reward": -175.039699,
    "length": 133,
    "time": 4833.565008,
    "actor_loss": 47.06538391113281,
    "critic_loss": 1.8280582427978516,
    "ent_coef": 0.04888371378183365,
    "learning_rate": 0.001
  },
  {
    "episode": 228,
    "reward": -184.214449,
    "length": 149,
    "time": 4857.343636,
    "actor_loss": 48.568931579589844,
    "critic_loss": 118.13289642333984,
    "ent_coef": 0.05033072829246521,
    "learning_rate": 0.001
  },
  {
    "episode": 229,
    "reward": -184.475294,
    "length": 153,
    "time": 4881.816722,
    "actor_loss": 47.74418640136719,
    "critic_loss": 3.0189218521118164,
    "ent_coef": 0.047779474407434464,
    "learning_rate": 0.001
  },
  {
    "episode": 230,
    "reward": -180.592523,
    "length": 124,
    "time": 4900.417729,
    "actor_loss": 48.377662658691406,
    "critic_loss": 6.7930474281311035,
    "ent_coef": 0.05170959234237671,
    "learning_rate": 0.001
  },
  {
    "episode": 231,
    "reward": -171.121957,
    "length": 112,
    "time": 4919.224647,
    "actor_loss": 46.90149688720703,
    "critic_loss": 35.815860748291016,
    "ent_coef": 0.052494894713163376,
    "learning_rate": 0.001
  },
  {
    "episode": 232,
    "reward": -153.94254,
    "length": 124,
    "time": 4939.496652,
    "actor_loss": 48.48213577270508,
    "critic_loss": 2.635603427886963,
    "ent_coef": 0.052562445402145386,
    "learning_rate": 0.001
  },
  {
    "episode": 233,
    "reward": -186.175424,
    "length": 140,
    "time": 4963.290581,
    "actor_loss": 45.84364318847656,
    "critic_loss": 116.00166320800781,
    "ent_coef": 0.052917491644620895,
    "learning_rate": 0.001
  },
  {
    "episode": 234,
    "reward": -198.013097,
    "length": 155,
    "time": 4986.174421,
    "actor_loss": 51.87694549560547,
    "critic_loss": 18.2915096282959,
    "ent_coef": 0.05419783294200897,
    "learning_rate": 0.001
  },
  {
    "episode": 235,
    "reward": -184.170258,
    "length": 139,
    "time": 5009.350593,
    "actor_loss": 50.05393600463867,
    "critic_loss": 299.2148742675781,
    "ent_coef": 0.05510573834180832,
    "learning_rate": 0.001
  },
  {
    "episode": 236,
    "reward": -175.124593,
    "length": 131,
    "time": 5033.492587,
    "actor_loss": 46.90666961669922,
    "critic_loss": 166.84141540527344,
    "ent_coef": 0.05529981851577759,
    "learning_rate": 0.001
  },
  {
    "episode": 237,
    "reward": -186.374767,
    "length": 135,
    "time": 5056.346951,
    "actor_loss": 46.653778076171875,
    "critic_loss": 1.3669037818908691,
    "ent_coef": 0.05750542879104614,
    "learning_rate": 0.001
  },
  {
    "episode": 238,
    "reward": -170.168959,
    "length": 112,
    "time": 5076.664195,
    "actor_loss": 46.169349670410156,
    "critic_loss": 10.79600715637207,
    "ent_coef": 0.05767931416630745,
    "learning_rate": 0.001
  },
  {
    "episode": 239,
    "reward": -187.150344,
    "length": 136,
    "time": 5100.130808,
    "actor_loss": 49.8332405090332,
    "critic_loss": 61.639976501464844,
    "ent_coef": 0.05602852627635002,
    "learning_rate": 0.001
  },
  {
    "episode": 240,
    "reward": -233.610032,
    "length": 228,
    "time": 5137.621071,
    "actor_loss": 49.69025421142578,
    "critic_loss": 2.849980354309082,
    "ent_coef": 0.05605670437216759,
    "learning_rate": 0.001
  },
  {
    "episode": 241,
    "reward": -180.886735,
    "length": 142,
    "time": 5165.277257,
    "actor_loss": 47.35773849487305,
    "critic_loss": 10.116189956665039,
    "ent_coef": 0.055346012115478516,
    "learning_rate": 0.001
  },
  {
    "episode": 242,
    "reward": -175.419476,
    "length": 123,
    "time": 5189.658429,
    "actor_loss": 47.52840805053711,
    "critic_loss": 17.385387420654297,
    "ent_coef": 0.05836813896894455,
    "learning_rate": 0.001
  },
  {
    "episode": 243,
    "reward": -172.18062,
    "length": 122,
    "time": 5212.078877,
    "actor_loss": 45.969200134277344,
    "critic_loss": 38.752323150634766,
    "ent_coef": 0.060369085520505905,
    "learning_rate": 0.001
  },
  {
    "episode": 244,
    "reward": -173.216753,
    "length": 124,
    "time": 5233.35075,
    "actor_loss": 46.37899398803711,
    "critic_loss": 2.0529026985168457,
    "ent_coef": 0.059809427708387375,
    "learning_rate": 0.001
  },
  {
    "episode": 245,
    "reward": -156.960974,
    "length": 97,
    "time": 5249.699276,
    "actor_loss": 48.9937858581543,
    "critic_loss": 76.99862670898438,
    "ent_coef": 0.056542299687862396,
    "learning_rate": 0.001
  },
  {
    "episode": 246,
    "reward": -163.764045,
    "length": 126,
    "time": 5274.781367,
    "actor_loss": 47.23450469970703,
    "critic_loss": 2.5959343910217285,
    "ent_coef": 0.05577146261930466,
    "learning_rate": 0.001
  },
  {
    "episode": 247,
    "reward": -175.471257,
    "length": 137,
    "time": 5297.93265,
    "actor_loss": 45.43783950805664,
    "critic_loss": 129.3753662109375,
    "ent_coef": 0.05780641362071037,
    "learning_rate": 0.001
  },
  {
    "episode": 248,
    "reward": -173.338883,
    "length": 138,
    "time": 5320.212863,
    "actor_loss": 45.90151596069336,
    "critic_loss": 1.5487185716629028,
    "ent_coef": 0.05548820272088051,
    "learning_rate": 0.001
  },
  {
    "episode": 249,
    "reward": -178.463225,
    "length": 148,
    "time": 5343.319829,
    "actor_loss": 51.267982482910156,
    "critic_loss": 38.119388580322266,
    "ent_coef": 0.054262425750494,
    "learning_rate": 0.001
  },
  {
    "episode": 250,
    "reward": -183.454683,
    "length": 152,
    "time": 5366.430285,
    "actor_loss": 47.43085479736328,
    "critic_loss": 5.773236274719238,
    "ent_coef": 0.05363976210355759,
    "learning_rate": 0.001
  },
  {
    "episode": 251,
    "reward": -167.088231,
    "length": 128,
    "time": 5387.31589,
    "actor_loss": 47.63111114501953,
    "critic_loss": 5.605110168457031,
    "ent_coef": 0.05656663700938225,
    "learning_rate": 0.001
  },
  {
    "episode": 252,
    "reward": -169.494411,
    "length": 140,
    "time": 5412.480666,
    "actor_loss": 48.14984893798828,
    "critic_loss": 85.4749755859375,
    "ent_coef": 0.05438194423913956,
    "learning_rate": 0.001
  },
  {
    "episode": 253,
    "reward": -172.772893,
    "length": 136,
    "time": 5434.472857,
    "actor_loss": 48.85631561279297,
    "critic_loss": 4.447231292724609,
    "ent_coef": 0.055337972939014435,
    "learning_rate": 0.001
  },
  {
    "episode": 254,
    "reward": -174.263728,
    "length": 149,
    "time": 5458.054579,
    "actor_loss": 49.195404052734375,
    "critic_loss": 4.877978324890137,
    "ent_coef": 0.055230140686035156,
    "learning_rate": 0.001
  },
  {
    "episode": 255,
    "reward": -169.414827,
    "length": 136,
    "time": 5479.100443,
    "actor_loss": 48.667091369628906,
    "critic_loss": 23.732303619384766,
    "ent_coef": 0.05607181787490845,
    "learning_rate": 0.001
  },
  {
    "episode": 256,
    "reward": -174.162989,
    "length": 143,
    "time": 5501.358124,
    "actor_loss": 49.407005310058594,
    "critic_loss": 2.7822155952453613,
    "ent_coef": 0.056977465748786926,
    "learning_rate": 0.001
  },
  {
    "episode": 257,
    "reward": -165.088748,
    "length": 133,
    "time": 5521.94241,
    "actor_loss": 50.91983413696289,
    "critic_loss": 2.9998083114624023,
    "ent_coef": 0.0590030662715435,
    "learning_rate": 0.001
  },
  {
    "episode": 258,
    "reward": -189.317625,
    "length": 154,
    "time": 5548.267247,
    "actor_loss": 48.81072998046875,
    "critic_loss": 30.15027618408203,
    "ent_coef": 0.05557280406355858,
    "learning_rate": 0.001
  },
  {
    "episode": 259,
    "reward": -175.281995,
    "length": 136,
    "time": 5568.620291,
    "actor_loss": 47.95555877685547,
    "critic_loss": 4.5171709060668945,
    "ent_coef": 0.05378805845975876,
    "learning_rate": 0.001
  },
  {
    "episode": 260,
    "reward": -178.770779,
    "length": 147,
    "time": 5590.948188,
    "actor_loss": 51.086830139160156,
    "critic_loss": 32.588226318359375,
    "ent_coef": 0.051398854702711105,
    "learning_rate": 0.001
  },
  {
    "episode": 261,
    "reward": -177.064078,
    "length": 148,
    "time": 5614.65912,
    "actor_loss": 47.12104034423828,
    "critic_loss": 6.91737699508667,
    "ent_coef": 0.05045423284173012,
    "learning_rate": 0.001
  },
  {
    "episode": 262,
    "reward": -179.218735,
    "length": 139,
    "time": 5637.35181,
    "actor_loss": 47.06755828857422,
    "critic_loss": 61.482391357421875,
    "ent_coef": 0.05261095613241196,
    "learning_rate": 0.001
  },
  {
    "episode": 263,
    "reward": -157.084244,
    "length": 103,
    "time": 5655.305771,
    "actor_loss": 45.68598556518555,
    "critic_loss": 28.804298400878906,
    "ent_coef": 0.05132397264242172,
    "learning_rate": 0.001
  },
  {
    "episode": 264,
    "reward": -167.169409,
    "length": 141,
    "time": 5676.719964,
    "actor_loss": 52.10810089111328,
    "critic_loss": 32.82264709472656,
    "ent_coef": 0.05346022918820381,
    "learning_rate": 0.001
  },
  {
    "episode": 265,
    "reward": -168.371637,
    "length": 135,
    "time": 5696.793176,
    "actor_loss": 46.50811004638672,
    "critic_loss": 33.95485305786133,
    "ent_coef": 0.057671546936035156,
    "learning_rate": 0.001
  },
  {
    "episode": 266,
    "reward": -181.362026,
    "length": 141,
    "time": 5718.473388,
    "actor_loss": 50.35551452636719,
    "critic_loss": 29.53329849243164,
    "ent_coef": 0.06280495226383209,
    "learning_rate": 0.001
  },
  {
    "episode": 267,
    "reward": -168.532161,
    "length": 133,
    "time": 5739.526004,
    "actor_loss": 50.88899612426758,
    "critic_loss": 36.32732009887695,
    "ent_coef": 0.06585485488176346,
    "learning_rate": 0.001
  },
  {
    "episode": 268,
    "reward": -175.783682,
    "length": 153,
    "time": 5763.944349,
    "actor_loss": 52.51587677001953,
    "critic_loss": 10.974520683288574,
    "ent_coef": 0.06407865136861801,
    "learning_rate": 0.001
  },
  {
    "episode": 269,
    "reward": -170.625754,
    "length": 139,
    "time": 5784.666859,
    "actor_loss": 47.10974884033203,
    "critic_loss": 46.161293029785156,
    "ent_coef": 0.06031782180070877,
    "learning_rate": 0.001
  },
  {
    "episode": 270,
    "reward": -175.025318,
    "length": 146,
    "time": 5807.035636,
    "actor_loss": 47.69987869262695,
    "critic_loss": 73.53254699707031,
    "ent_coef": 0.0578332245349884,
    "learning_rate": 0.001
  },
  {
    "episode": 271,
    "reward": -169.60202,
    "length": 138,
    "time": 5829.935117,
    "actor_loss": 48.29656982421875,
    "critic_loss": 25.91551971435547,
    "ent_coef": 0.06358825415372849,
    "learning_rate": 0.001
  },
  {
    "episode": 272,
    "reward": -166.419795,
    "length": 142,
    "time": 5850.88537,
    "actor_loss": 48.942115783691406,
    "critic_loss": 2.5071887969970703,
    "ent_coef": 0.07192354649305344,
    "learning_rate": 0.001
  },
  {
    "episode": 273,
    "reward": -175.868164,
    "length": 151,
    "time": 5874.864061,
    "actor_loss": 51.03731155395508,
    "critic_loss": 43.54428482055664,
    "ent_coef": 0.06548480689525604,
    "learning_rate": 0.001
  },
  {
    "episode": 274,
    "reward": -168.221862,
    "length": 138,
    "time": 5896.46466,
    "actor_loss": 51.49090576171875,
    "critic_loss": 38.57511901855469,
    "ent_coef": 0.06388033926486969,
    "learning_rate": 0.001
  },
  {
    "episode": 275,
    "reward": -174.488169,
    "length": 151,
    "time": 5919.569303,
    "actor_loss": 49.78385543823242,
    "critic_loss": 27.66951560974121,
    "ent_coef": 0.06259354203939438,
    "learning_rate": 0.001
  },
  {
    "episode": 276,
    "reward": -166.715142,
    "length": 140,
    "time": 5941.192789,
    "actor_loss": 47.93865966796875,
    "critic_loss": 34.14402770996094,
    "ent_coef": 0.0675627589225769,
    "learning_rate": 0.001
  },
  {
    "episode": 277,
    "reward": -171.242101,
    "length": 142,
    "time": 5964.731804,
    "actor_loss": 50.16728973388672,
    "critic_loss": 41.95298767089844,
    "ent_coef": 0.0658549964427948,
    "learning_rate": 0.001
  },
  {
    "episode": 278,
    "reward": -171.198821,
    "length": 146,
    "time": 5988.374171,
    "actor_loss": 50.05680847167969,
    "critic_loss": 8.758064270019531,
    "ent_coef": 0.06221942976117134,
    "learning_rate": 0.001
  },
  {
    "episode": 279,
    "reward": -169.782161,
    "length": 137,
    "time": 6009.31733,
    "actor_loss": 51.0760383605957,
    "critic_loss": 71.4659423828125,
    "ent_coef": 0.05915479362010956,
    "learning_rate": 0.001
  },
  {
    "episode": 280,
    "reward": -183.796614,
    "length": 163,
    "time": 6033.99127,
    "actor_loss": 50.59800338745117,
    "critic_loss": 73.71766662597656,
    "ent_coef": 0.059085771441459656,
    "learning_rate": 0.001
  },
  {
    "episode": 281,
    "reward": -170.090964,
    "length": 152,
    "time": 6056.629766,
    "actor_loss": 50.08824920654297,
    "critic_loss": 637.3275146484375,
    "ent_coef": 0.06236899271607399,
    "learning_rate": 0.001
  },
  {
    "episode": 282,
    "reward": -167.481819,
    "length": 144,
    "time": 6077.610809,
    "actor_loss": 50.85704040527344,
    "critic_loss": 2.142354965209961,
    "ent_coef": 0.06331025063991547,
    "learning_rate": 0.001
  },
  {
    "episode": 283,
    "reward": -165.235345,
    "length": 142,
    "time": 6100.620637,
    "actor_loss": 47.55415344238281,
    "critic_loss": 3.3022608757019043,
    "ent_coef": 0.06644079089164734,
    "learning_rate": 0.001
  },
  {
    "episode": 284,
    "reward": -168.521546,
    "length": 144,
    "time": 6121.767224,
    "actor_loss": 49.48451232910156,
    "critic_loss": 7.616113662719727,
    "ent_coef": 0.07317700237035751,
    "learning_rate": 0.001
  },
  {
    "episode": 285,
    "reward": -171.395993,
    "length": 157,
    "time": 6145.591365,
    "actor_loss": 46.82745361328125,
    "critic_loss": 3.8025314807891846,
    "ent_coef": 0.06882640719413757,
    "learning_rate": 0.001
  },
  {
    "episode": 286,
    "reward": -165.540434,
    "length": 141,
    "time": 6167.118099,
    "actor_loss": 48.813720703125,
    "critic_loss": 41.807159423828125,
    "ent_coef": 0.06617075949907303,
    "learning_rate": 0.001
  },
  {
    "episode": 287,
    "reward": -171.282877,
    "length": 137,
    "time": 6189.081849,
    "actor_loss": 50.77275466918945,
    "critic_loss": 46.31497573852539,
    "ent_coef": 0.06661345809698105,
    "learning_rate": 0.001
  },
  {
    "episode": 288,
    "reward": -161.325154,
    "length": 130,
    "time": 6210.559166,
    "actor_loss": 49.83326721191406,
    "critic_loss": 27.516159057617188,
    "ent_coef": 0.06647332012653351,
    "learning_rate": 0.001
  },
  {
    "episode": 289,
    "reward": -163.255203,
    "length": 132,
    "time": 6233.15731,
    "actor_loss": 50.26007843017578,
    "critic_loss": 4.502541542053223,
    "ent_coef": 0.07275357842445374,
    "learning_rate": 0.001
  },
  {
    "episode": 290,
    "reward": -165.248577,
    "length": 141,
    "time": 6259.220372,
    "actor_loss": 50.74327087402344,
    "critic_loss": 51.11674118041992,
    "ent_coef": 0.07037465274333954,
    "learning_rate": 0.001
  },
  {
    "episode": 291,
    "reward": -168.945186,
    "length": 143,
    "time": 6280.544057,
    "actor_loss": 51.158504486083984,
    "critic_loss": 4.705121040344238,
    "ent_coef": 0.065458282828331,
    "learning_rate": 0.001
  },
  {
    "episode": 292,
    "reward": -163.228098,
    "length": 132,
    "time": 6300.614766,
    "actor_loss": 49.931278228759766,
    "critic_loss": 34.579795837402344,
    "ent_coef": 0.06829535961151123,
    "learning_rate": 0.001
  },
  {
    "episode": 293,
    "reward": -173.759231,
    "length": 154,
    "time": 6326.385952,
    "actor_loss": 49.342247009277344,
    "critic_loss": 1.7819780111312866,
    "ent_coef": 0.06691452115774155,
    "learning_rate": 0.001
  },
  {
    "episode": 294,
    "reward": -171.547998,
    "length": 146,
    "time": 6347.817484,
    "actor_loss": 48.56216049194336,
    "critic_loss": 28.409317016601562,
    "ent_coef": 0.06948258727788925,
    "learning_rate": 0.001
  },
  {
    "episode": 295,
    "reward": -180.28676,
    "length": 151,
    "time": 6370.910205,
    "actor_loss": 50.78752899169922,
    "critic_loss": 39.49273681640625,
    "ent_coef": 0.06696702539920807,
    "learning_rate": 0.001
  },
  {
    "episode": 296,
    "reward": -164.585958,
    "length": 137,
    "time": 6395.284502,
    "actor_loss": 49.7337532043457,
    "critic_loss": 314.57159423828125,
    "ent_coef": 0.068353071808815,
    "learning_rate": 0.001
  },
  {
    "episode": 297,
    "reward": -165.438121,
    "length": 142,
    "time": 6416.276,
    "actor_loss": 49.35009765625,
    "critic_loss": 1.2247371673583984,
    "ent_coef": 0.07188598811626434,
    "learning_rate": 0.001
  },
  {
    "episode": 298,
    "reward": -179.450997,
    "length": 159,
    "time": 6441.604814,
    "actor_loss": 49.09834289550781,
    "critic_loss": 59.45805358886719,
    "ent_coef": 0.06572076678276062,
    "learning_rate": 0.001
  },
  {
    "episode": 299,
    "reward": -171.265697,
    "length": 154,
    "time": 6466.95474,
    "actor_loss": 48.824745178222656,
    "critic_loss": 6.833822250366211,
    "ent_coef": 0.0598541796207428,
    "learning_rate": 0.001
  },
  {
    "episode": 300,
    "reward": -172.028248,
    "length": 150,
    "time": 6490.149272,
    "actor_loss": 50.183128356933594,
    "critic_loss": 47.20228958129883,
    "ent_coef": 0.0561252161860466,
    "learning_rate": 0.001
  },
  {
    "episode": 301,
    "reward": -167.848039,
    "length": 148,
    "time": 6513.525411,
    "actor_loss": 47.99776077270508,
    "critic_loss": 173.07809448242188,
    "ent_coef": 0.05827582627534866,
    "learning_rate": 0.001
  },
  {
    "episode": 302,
    "reward": -164.438183,
    "length": 131,
    "time": 6535.634571,
    "actor_loss": 50.96824645996094,
    "critic_loss": 3.7941412925720215,
    "ent_coef": 0.06468236446380615,
    "learning_rate": 0.001
  },
  {
    "episode": 303,
    "reward": -163.217157,
    "length": 132,
    "time": 6557.134359,
    "actor_loss": 50.175655364990234,
    "critic_loss": 3.814697265625,
    "ent_coef": 0.06578527390956879,
    "learning_rate": 0.001
  },
  {
    "episode": 304,
    "reward": -166.265357,
    "length": 134,
    "time": 6579.71525,
    "actor_loss": 49.624664306640625,
    "critic_loss": 3.705521583557129,
    "ent_coef": 0.06532509624958038,
    "learning_rate": 0.001
  },
  {
    "episode": 305,
    "reward": -165.433435,
    "length": 135,
    "time": 6599.72833,
    "actor_loss": 47.78089141845703,
    "critic_loss": 10.986865997314453,
    "ent_coef": 0.06492231786251068,
    "learning_rate": 0.001
  },
  {
    "episode": 306,
    "reward": -171.9819,
    "length": 149,
    "time": 6622.657593,
    "actor_loss": 52.80079650878906,
    "critic_loss": 58.02470397949219,
    "ent_coef": 0.06227094307541847,
    "learning_rate": 0.001
  },
  {
    "episode": 307,
    "reward": -171.77051,
    "length": 130,
    "time": 6642.093354,
    "actor_loss": 48.857261657714844,
    "critic_loss": 64.51080322265625,
    "ent_coef": 0.06578430533409119,
    "learning_rate": 0.001
  },
  {
    "episode": 308,
    "reward": -164.050033,
    "length": 132,
    "time": 6662.101493,
    "actor_loss": 48.77783966064453,
    "critic_loss": 311.9173583984375,
    "ent_coef": 0.06714837998151779,
    "learning_rate": 0.001
  },
  {
    "episode": 309,
    "reward": -173.505647,
    "length": 161,
    "time": 6687.106877,
    "actor_loss": 46.7911376953125,
    "critic_loss": 79.17827606201172,
    "ent_coef": 0.061626777052879333,
    "learning_rate": 0.001
  },
  {
    "episode": 310,
    "reward": -169.616133,
    "length": 155,
    "time": 6713.097982,
    "actor_loss": 50.15079879760742,
    "critic_loss": 5.068477153778076,
    "ent_coef": 0.061456430703401566,
    "learning_rate": 0.001
  },
  {
    "episode": 311,
    "reward": -167.842385,
    "length": 150,
    "time": 6734.909376,
    "actor_loss": 51.15571594238281,
    "critic_loss": 109.03472137451172,
    "ent_coef": 0.06114863604307175,
    "learning_rate": 0.001
  },
  {
    "episode": 312,
    "reward": -173.511752,
    "length": 158,
    "time": 6760.754929,
    "actor_loss": 53.41276168823242,
    "critic_loss": 3.300050973892212,
    "ent_coef": 0.058411866426467896,
    "learning_rate": 0.001
  },
  {
    "episode": 313,
    "reward": -164.269062,
    "length": 146,
    "time": 6784.121091,
    "actor_loss": 49.89228057861328,
    "critic_loss": 7.435205459594727,
    "ent_coef": 0.06311684846878052,
    "learning_rate": 0.001
  },
  {
    "episode": 314,
    "reward": -164.035543,
    "length": 133,
    "time": 6804.772967,
    "actor_loss": 50.38402557373047,
    "critic_loss": 32.888916015625,
    "ent_coef": 0.06435735523700714,
    "learning_rate": 0.001
  },
  {
    "episode": 315,
    "reward": -171.372801,
    "length": 137,
    "time": 6827.781789,
    "actor_loss": 50.47333526611328,
    "critic_loss": 36.96501922607422,
    "ent_coef": 0.0610765740275383,
    "learning_rate": 0.001
  },
  {
    "episode": 316,
    "reward": -168.80696,
    "length": 143,
    "time": 6848.875942,
    "actor_loss": 47.03091812133789,
    "critic_loss": 4.04606819152832,
    "ent_coef": 0.06304003298282623,
    "learning_rate": 0.001
  },
  {
    "episode": 317,
    "reward": -174.839272,
    "length": 145,
    "time": 6873.781596,
    "actor_loss": 52.187347412109375,
    "critic_loss": 2.179941177368164,
    "ent_coef": 0.06181703507900238,
    "learning_rate": 0.001
  },
  {
    "episode": 318,
    "reward": -174.341907,
    "length": 157,
    "time": 6897.927017,
    "actor_loss": 49.0715217590332,
    "critic_loss": 37.66740417480469,
    "ent_coef": 0.059814006090164185,
    "learning_rate": 0.001
  },
  {
    "episode": 319,
    "reward": -179.29514,
    "length": 164,
    "time": 6924.105667,
    "actor_loss": 48.547119140625,
    "critic_loss": 22.70726203918457,
    "ent_coef": 0.05810738354921341,
    "learning_rate": 0.001
  },
  {
    "episode": 320,
    "reward": -168.892605,
    "length": 145,
    "time": 6945.444183,
    "actor_loss": 46.61180877685547,
    "critic_loss": 28.08370590209961,
    "ent_coef": 0.06058359146118164,
    "learning_rate": 0.001
  },
  {
    "episode": 321,
    "reward": -212.863282,
    "length": 171,
    "time": 6972.277786,
    "actor_loss": 47.43133544921875,
    "critic_loss": 1.8016537427902222,
    "ent_coef": 0.06032200902700424,
    "learning_rate": 0.001
  },
  {
    "episode": 322,
    "reward": -172.544352,
    "length": 150,
    "time": 6997.758228,
    "actor_loss": 45.08475112915039,
    "critic_loss": 3.3162078857421875,
    "ent_coef": 0.06263285130262375,
    "learning_rate": 0.001
  },
  {
    "episode": 323,
    "reward": -173.618525,
    "length": 140,
    "time": 7019.104936,
    "actor_loss": 47.91407012939453,
    "critic_loss": 8.783851623535156,
    "ent_coef": 0.06540185958147049,
    "learning_rate": 0.001
  },
  {
    "episode": 324,
    "reward": -170.612955,
    "length": 148,
    "time": 7042.426851,
    "actor_loss": 49.38090133666992,
    "critic_loss": 2.561783790588379,
    "ent_coef": 0.06950300186872482,
    "learning_rate": 0.001
  },
  {
    "episode": 325,
    "reward": -170.816097,
    "length": 146,
    "time": 7064.618959,
    "actor_loss": 48.44068908691406,
    "critic_loss": 2.64709734916687,
    "ent_coef": 0.0691983625292778,
    "learning_rate": 0.001
  },
  {
    "episode": 326,
    "reward": -176.582403,
    "length": 151,
    "time": 7091.998829,
    "actor_loss": 46.3089714050293,
    "critic_loss": 122.33007049560547,
    "ent_coef": 0.06918857991695404,
    "learning_rate": 0.001
  },
  {
    "episode": 327,
    "reward": -172.37252,
    "length": 141,
    "time": 7116.56724,
    "actor_loss": 48.041587829589844,
    "critic_loss": 6.171796798706055,
    "ent_coef": 0.07825213670730591,
    "learning_rate": 0.001
  },
  {
    "episode": 328,
    "reward": 73.783942,
    "length": 92,
    "time": 7132.4666,
    "actor_loss": 49.93012237548828,
    "critic_loss": 17.909503936767578,
    "ent_coef": 0.07805135101079941,
    "learning_rate": 0.001
  },
  {
    "episode": 329,
    "reward": -182.843173,
    "length": 159,
    "time": 7156.444426,
    "actor_loss": 45.785274505615234,
    "critic_loss": 23.470504760742188,
    "ent_coef": 0.08036665618419647,
    "learning_rate": 0.001
  },
  {
    "episode": 330,
    "reward": -177.903049,
    "length": 174,
    "time": 7181.944236,
    "actor_loss": 49.37569808959961,
    "critic_loss": 15.968878746032715,
    "ent_coef": 0.08308166265487671,
    "learning_rate": 0.001
  },
  {
    "episode": 331,
    "reward": -164.930798,
    "length": 143,
    "time": 7204.147304,
    "actor_loss": 46.94379806518555,
    "critic_loss": 83.10274505615234,
    "ent_coef": 0.08598199486732483,
    "learning_rate": 0.001
  },
  {
    "episode": 332,
    "reward": -175.922656,
    "length": 156,
    "time": 7227.935604,
    "actor_loss": 49.074440002441406,
    "critic_loss": 13.288759231567383,
    "ent_coef": 0.08200540393590927,
    "learning_rate": 0.001
  },
  {
    "episode": 333,
    "reward": -170.789952,
    "length": 156,
    "time": 7251.52406,
    "actor_loss": 46.68171691894531,
    "critic_loss": 3.8867883682250977,
    "ent_coef": 0.07735373079776764,
    "learning_rate": 0.001
  },
  {
    "episode": 334,
    "reward": -173.613037,
    "length": 147,
    "time": 7273.601858,
    "actor_loss": 49.620880126953125,
    "critic_loss": 19.37100601196289,
    "ent_coef": 0.07520435750484467,
    "learning_rate": 0.001
  },
  {
    "episode": 335,
    "reward": -162.28788,
    "length": 591,
    "time": 7353.682515,
    "actor_loss": 44.257049560546875,
    "critic_loss": 41.40528869628906,
    "ent_coef": 0.07290488481521606,
    "learning_rate": 0.001
  },
  {
    "episode": 336,
    "reward": -163.746317,
    "length": 137,
    "time": 7377.021716,
    "actor_loss": 44.66279602050781,
    "critic_loss": 6.37429141998291,
    "ent_coef": 0.07517700642347336,
    "learning_rate": 0.001
  },
  {
    "episode": 337,
    "reward": 76.77975,
    "length": 88,
    "time": 7392.845371,
    "actor_loss": 50.367652893066406,
    "critic_loss": 109.78782653808594,
    "ent_coef": 0.07865481078624725,
    "learning_rate": 0.001
  },
  {
    "episode": 338,
    "reward": 33.302006,
    "length": 167,
    "time": 7417.396337,
    "actor_loss": 44.87061309814453,
    "critic_loss": 31.28882598876953,
    "ent_coef": 0.07903514802455902,
    "learning_rate": 0.001
  },
  {
    "episode": 339,
    "reward": 38.464954,
    "length": 153,
    "time": 7440.433975,
    "actor_loss": 47.0274658203125,
    "critic_loss": 3.0367519855499268,
    "ent_coef": 0.07939713448286057,
    "learning_rate": 0.001
  },
  {
    "episode": 340,
    "reward": -411.771541,
    "length": 510,
    "time": 7509.838933,
    "actor_loss": 46.394195556640625,
    "critic_loss": 3.468848705291748,
    "ent_coef": 0.07030918449163437,
    "learning_rate": 0.001
  },
  {
    "episode": 341,
    "reward": -170.710717,
    "length": 144,
    "time": 7533.542506,
    "actor_loss": 47.47325897216797,
    "critic_loss": 16.85032844543457,
    "ent_coef": 0.07355373352766037,
    "learning_rate": 0.001
  },
  {
    "episode": 342,
    "reward": -179.657476,
    "length": 148,
    "time": 7556.334948,
    "actor_loss": 46.15523147583008,
    "critic_loss": 23.842164993286133,
    "ent_coef": 0.08065582066774368,
    "learning_rate": 0.001
  },
  {
    "episode": 343,
    "reward": 72.435233,
    "length": 97,
    "time": 7574.061289,
    "actor_loss": 45.06267166137695,
    "critic_loss": 39.832489013671875,
    "ent_coef": 0.08092149347066879,
    "learning_rate": 0.001
  },
  {
    "episode": 344,
    "reward": -175.689966,
    "length": 164,
    "time": 7600.301208,
    "actor_loss": 46.006187438964844,
    "critic_loss": 62.988983154296875,
    "ent_coef": 0.08112836629152298,
    "learning_rate": 0.001
  },
  {
    "episode": 345,
    "reward": 38.780197,
    "length": 150,
    "time": 7623.371997,
    "actor_loss": 46.64439392089844,
    "critic_loss": 317.83819580078125,
    "ent_coef": 0.08125600963830948,
    "learning_rate": 0.001
  },
  {
    "episode": 346,
    "reward": -176.430075,
    "length": 159,
    "time": 7647.796816,
    "actor_loss": 44.169925689697266,
    "critic_loss": 3.3129544258117676,
    "ent_coef": 0.07635513693094254,
    "learning_rate": 0.001
  },
  {
    "episode": 347,
    "reward": 67.968035,
    "length": 92,
    "time": 7663.46856,
    "actor_loss": 43.636592864990234,
    "critic_loss": 5.166281223297119,
    "ent_coef": 0.07430032640695572,
    "learning_rate": 0.001
  },
  {
    "episode": 348,
    "reward": -159.732921,
    "length": 138,
    "time": 7684.609969,
    "actor_loss": 47.10212326049805,
    "critic_loss": 60.64404296875,
    "ent_coef": 0.07296666502952576,
    "learning_rate": 0.001
  },
  {
    "episode": 349,
    "reward": -196.972251,
    "length": 195,
    "time": 7713.674131,
    "actor_loss": 47.58567810058594,
    "critic_loss": 101.07947540283203,
    "ent_coef": 0.07007093727588654,
    "learning_rate": 0.001
  },
  {
    "episode": 350,
    "reward": 64.107824,
    "length": 86,
    "time": 7727.660595,
    "actor_loss": 44.56978988647461,
    "critic_loss": 13.990789413452148,
    "ent_coef": 0.07579648494720459,
    "learning_rate": 0.001
  },
  {
    "episode": 351,
    "reward": -166.109838,
    "length": 140,
    "time": 7750.684362,
    "actor_loss": 46.5221061706543,
    "critic_loss": 160.73069763183594,
    "ent_coef": 0.08017531782388687,
    "learning_rate": 0.001
  },
  {
    "episode": 352,
    "reward": -175.003036,
    "length": 185,
    "time": 7779.138983,
    "actor_loss": 46.349822998046875,
    "critic_loss": 286.64508056640625,
    "ent_coef": 0.08191046118736267,
    "learning_rate": 0.001
  },
  {
    "episode": 353,
    "reward": -173.829434,
    "length": 145,
    "time": 7800.565457,
    "actor_loss": 44.879241943359375,
    "critic_loss": 64.40226745605469,
    "ent_coef": 0.08273138105869293,
    "learning_rate": 0.001
  },
  {
    "episode": 354,
    "reward": -174.436696,
    "length": 150,
    "time": 7822.792723,
    "actor_loss": 45.62959671020508,
    "critic_loss": 17.768707275390625,
    "ent_coef": 0.08263611048460007,
    "learning_rate": 0.001
  },
  {
    "episode": 355,
    "reward": 78.791341,
    "length": 84,
    "time": 7837.331076,
    "actor_loss": 47.45352554321289,
    "critic_loss": 13.74911880493164,
    "ent_coef": 0.08137031644582748,
    "learning_rate": 0.001
  },
  {
    "episode": 356,
    "reward": 82.244855,
    "length": 80,
    "time": 7850.563688,
    "actor_loss": 43.01648712158203,
    "critic_loss": 9.18718147277832,
    "ent_coef": 0.0830809697508812,
    "learning_rate": 0.001
  },
  {
    "episode": 357,
    "reward": 62.810295,
    "length": 129,
    "time": 7870.564701,
    "actor_loss": 42.986480712890625,
    "critic_loss": 6.979350566864014,
    "ent_coef": 0.07787775248289108,
    "learning_rate": 0.001
  },
  {
    "episode": 358,
    "reward": -188.671503,
    "length": 179,
    "time": 7898.213104,
    "actor_loss": 42.98334503173828,
    "critic_loss": 36.022560119628906,
    "ent_coef": 0.07685495913028717,
    "learning_rate": 0.001
  },
  {
    "episode": 359,
    "reward": -390.246715,
    "length": 415,
    "time": 7954.457881,
    "actor_loss": 43.42005157470703,
    "critic_loss": 169.99905395507812,
    "ent_coef": 0.08071112632751465,
    "learning_rate": 0.001
  },
  {
    "episode": 360,
    "reward": 34.206271,
    "length": 173,
    "time": 7979.958966,
    "actor_loss": 47.605560302734375,
    "critic_loss": 25.68463897705078,
    "ent_coef": 0.08349290490150452,
    "learning_rate": 0.001
  },
  {
    "episode": 361,
    "reward": -167.193097,
    "length": 205,
    "time": 8011.967938,
    "actor_loss": 46.07152557373047,
    "critic_loss": 7.823431968688965,
    "ent_coef": 0.08214034885168076,
    "learning_rate": 0.001
  },
  {
    "episode": 362,
    "reward": 74.834294,
    "length": 89,
    "time": 8028.150948,
    "actor_loss": 43.863800048828125,
    "critic_loss": 5.9622273445129395,
    "ent_coef": 0.08148176968097687,
    "learning_rate": 0.001
  },
  {
    "episode": 363,
    "reward": -172.670256,
    "length": 143,
    "time": 8050.721209,
    "actor_loss": 45.71458435058594,
    "critic_loss": 3.653275966644287,
    "ent_coef": 0.07785755395889282,
    "learning_rate": 0.001
  },
  {
    "episode": 364,
    "reward": 77.624144,
    "length": 84,
    "time": 8065.549494,
    "actor_loss": 44.447174072265625,
    "critic_loss": 17.838138580322266,
    "ent_coef": 0.07484684139490128,
    "learning_rate": 0.001
  },
  {
    "episode": 365,
    "reward": -175.127983,
    "length": 130,
    "time": 8087.482254,
    "actor_loss": 44.651248931884766,
    "critic_loss": 79.17992401123047,
    "ent_coef": 0.0753297358751297,
    "learning_rate": 0.001
  },
  {
    "episode": 366,
    "reward": -165.591689,
    "length": 133,
    "time": 8107.32628,
    "actor_loss": 45.603004455566406,
    "critic_loss": 90.2186508178711,
    "ent_coef": 0.0776062160730362,
    "learning_rate": 0.001
  },
  {
    "episode": 367,
    "reward": -169.734112,
    "length": 148,
    "time": 8129.401497,
    "actor_loss": 42.761383056640625,
    "critic_loss": 226.99705505371094,
    "ent_coef": 0.07576194405555725,
    "learning_rate": 0.001
  },
  {
    "episode": 368,
    "reward": -184.647738,
    "length": 179,
    "time": 8155.655714,
    "actor_loss": 45.86585235595703,
    "critic_loss": 3.546152114868164,
    "ent_coef": 0.06934996694326401,
    "learning_rate": 0.001
  },
  {
    "episode": 369,
    "reward": -183.831253,
    "length": 175,
    "time": 8181.087643,
    "actor_loss": 43.21977615356445,
    "critic_loss": 5.572848320007324,
    "ent_coef": 0.06489147990942001,
    "learning_rate": 0.001
  },
  {
    "episode": 370,
    "reward": 61.952316,
    "length": 90,
    "time": 8197.467385,
    "actor_loss": 49.88654327392578,
    "critic_loss": 56.19022750854492,
    "ent_coef": 0.06682586669921875,
    "learning_rate": 0.001
  },
  {
    "episode": 371,
    "reward": 75.894546,
    "length": 77,
    "time": 8210.712057,
    "actor_loss": 43.05205154418945,
    "critic_loss": 3.191938877105713,
    "ent_coef": 0.07007531076669693,
    "learning_rate": 0.001
  },
  {
    "episode": 372,
    "reward": 81.959802,
    "length": 81,
    "time": 8225.148325,
    "actor_loss": 49.98781204223633,
    "critic_loss": 6.461244583129883,
    "ent_coef": 0.07133397459983826,
    "learning_rate": 0.001
  },
  {
    "episode": 373,
    "reward": 71.113212,
    "length": 96,
    "time": 8240.608047,
    "actor_loss": 43.84600830078125,
    "critic_loss": 32.19452667236328,
    "ent_coef": 0.07079346477985382,
    "learning_rate": 0.001
  },
  {
    "episode": 374,
    "reward": -177.238029,
    "length": 151,
    "time": 8263.777504,
    "actor_loss": 45.557037353515625,
    "critic_loss": 130.21273803710938,
    "ent_coef": 0.06895255297422409,
    "learning_rate": 0.001
  },
  {
    "episode": 375,
    "reward": 85.1324,
    "length": 73,
    "time": 8276.985904,
    "actor_loss": 44.36521911621094,
    "critic_loss": 5.516267776489258,
    "ent_coef": 0.06934146583080292,
    "learning_rate": 0.001
  },
  {
    "episode": 376,
    "reward": 46.105137,
    "length": 136,
    "time": 8297.576219,
    "actor_loss": 44.884490966796875,
    "critic_loss": 3.473886251449585,
    "ent_coef": 0.06846713274717331,
    "learning_rate": 0.001
  },
  {
    "episode": 377,
    "reward": 46.490533,
    "length": 135,
    "time": 8318.648697,
    "actor_loss": 42.94903564453125,
    "critic_loss": 68.66313171386719,
    "ent_coef": 0.06816606223583221,
    "learning_rate": 0.001
  },
  {
    "episode": 378,
    "reward": -320.735621,
    "length": 315,
    "time": 8365.676056,
    "actor_loss": 41.7642822265625,
    "critic_loss": 10.011144638061523,
    "ent_coef": 0.07479003071784973,
    "learning_rate": 0.001
  },
  {
    "episode": 379,
    "reward": 82.73335,
    "length": 103,
    "time": 8381.83557,
    "actor_loss": 44.8283576965332,
    "critic_loss": 43.043601989746094,
    "ent_coef": 0.07438533753156662,
    "learning_rate": 0.001
  },
  {
    "episode": 380,
    "reward": -367.307702,
    "length": 349,
    "time": 8433.101443,
    "actor_loss": 46.22996520996094,
    "critic_loss": 20.53302764892578,
    "ent_coef": 0.07910147309303284,
    "learning_rate": 0.001
  },
  {
    "episode": 381,
    "reward": -304.90831,
    "length": 294,
    "time": 8475.557996,
    "actor_loss": 44.134315490722656,
    "critic_loss": 5.32705020904541,
    "ent_coef": 0.07089896500110626,
    "learning_rate": 0.001
  },
  {
    "episode": 382,
    "reward": -262.24191,
    "length": 202,
    "time": 8504.609819,
    "actor_loss": 45.015769958496094,
    "critic_loss": 3.471813678741455,
    "ent_coef": 0.07147663831710815,
    "learning_rate": 0.001
  },
  {
    "episode": 383,
    "reward": 51.093603,
    "length": 149,
    "time": 8528.046796,
    "actor_loss": 41.94983673095703,
    "critic_loss": 123.81420135498047,
    "ent_coef": 0.06665632128715515,
    "learning_rate": 0.001
  },
  {
    "episode": 384,
    "reward": 68.903828,
    "length": 101,
    "time": 8547.790865,
    "actor_loss": 44.99842071533203,
    "critic_loss": 4.231393814086914,
    "ent_coef": 0.06457497924566269,
    "learning_rate": 0.001
  },
  {
    "episode": 385,
    "reward": 82.987135,
    "length": 77,
    "time": 8561.502668,
    "actor_loss": 43.111106872558594,
    "critic_loss": 19.66410255432129,
    "ent_coef": 0.06875713169574738,
    "learning_rate": 0.001
  },
  {
    "episode": 386,
    "reward": -164.298454,
    "length": 144,
    "time": 8582.835084,
    "actor_loss": 39.45876693725586,
    "critic_loss": 10.946586608886719,
    "ent_coef": 0.06914357841014862,
    "learning_rate": 0.001
  },
  {
    "episode": 387,
    "reward": 77.767423,
    "length": 86,
    "time": 8600.812662,
    "actor_loss": 40.911949157714844,
    "critic_loss": 32.87232971191406,
    "ent_coef": 0.06956363469362259,
    "learning_rate": 0.001
  },
  {
    "episode": 388,
    "reward": -163.840261,
    "length": 143,
    "time": 8623.258307,
    "actor_loss": 46.211402893066406,
    "critic_loss": 3.240044593811035,
    "ent_coef": 0.07212361693382263,
    "learning_rate": 0.001
  },
  {
    "episode": 389,
    "reward": 78.749829,
    "length": 83,
    "time": 8637.792246,
    "actor_loss": 46.18525695800781,
    "critic_loss": 21.51702308654785,
    "ent_coef": 0.07248935848474503,
    "learning_rate": 0.001
  },
  {
    "episode": 390,
    "reward": 78.518693,
    "length": 76,
    "time": 8650.51246,
    "actor_loss": 41.771453857421875,
    "critic_loss": 68.37200164794922,
    "ent_coef": 0.07699614763259888,
    "learning_rate": 0.001
  },
  {
    "episode": 391,
    "reward": 82.183683,
    "length": 73,
    "time": 8662.836789,
    "actor_loss": 42.49922561645508,
    "critic_loss": 2.7506189346313477,
    "ent_coef": 0.07989484071731567,
    "learning_rate": 0.001
  },
  {
    "episode": 392,
    "reward": 74.706717,
    "length": 116,
    "time": 8680.604069,
    "actor_loss": 45.6358642578125,
    "critic_loss": 48.1931266784668,
    "ent_coef": 0.07899423688650131,
    "learning_rate": 0.001
  },
  {
    "episode": 393,
    "reward": -165.189548,
    "length": 136,
    "time": 8702.907625,
    "actor_loss": 44.27412414550781,
    "critic_loss": 2.0330052375793457,
    "ent_coef": 0.08383623510599136,
    "learning_rate": 0.001
  },
  {
    "episode": 394,
    "reward": -167.241581,
    "length": 128,
    "time": 8723.341398,
    "actor_loss": 47.71382141113281,
    "critic_loss": 58.872135162353516,
    "ent_coef": 0.08281264454126358,
    "learning_rate": 0.001
  },
  {
    "episode": 395,
    "reward": -171.170874,
    "length": 153,
    "time": 8746.888923,
    "actor_loss": 37.704681396484375,
    "critic_loss": 5.903829097747803,
    "ent_coef": 0.08210448920726776,
    "learning_rate": 0.001
  },
  {
    "episode": 396,
    "reward": 77.308242,
    "length": 81,
    "time": 8761.30399,
    "actor_loss": 45.822044372558594,
    "critic_loss": 11.023018836975098,
    "ent_coef": 0.0823177844285965,
    "learning_rate": 0.001
  },
  {
    "episode": 397,
    "reward": 85.580549,
    "length": 72,
    "time": 8775.871499,
    "actor_loss": 45.46266174316406,
    "critic_loss": 16.349794387817383,
    "ent_coef": 0.07953161001205444,
    "learning_rate": 0.001
  },
  {
    "episode": 398,
    "reward": -165.923768,
    "length": 162,
    "time": 8799.729594,
    "actor_loss": 46.60392761230469,
    "critic_loss": 16.688026428222656,
    "ent_coef": 0.08087125420570374,
    "learning_rate": 0.001
  },
  {
    "episode": 399,
    "reward": -159.493145,
    "length": 139,
    "time": 8821.941157,
    "actor_loss": 42.335487365722656,
    "critic_loss": 122.22794342041016,
    "ent_coef": 0.08243802934885025,
    "learning_rate": 0.001
  },
  {
    "episode": 400,
    "reward": 79.48128,
    "length": 82,
    "time": 8835.821847,
    "actor_loss": 41.88265609741211,
    "critic_loss": 4.285306930541992,
    "ent_coef": 0.08535275608301163,
    "learning_rate": 0.001
  },
  {
    "episode": 401,
    "reward": -164.693669,
    "length": 143,
    "time": 8859.902935,
    "actor_loss": 46.90037536621094,
    "critic_loss": 12.812591552734375,
    "ent_coef": 0.08858254551887512,
    "learning_rate": 0.001
  },
  {
    "episode": 402,
    "reward": 73.373728,
    "length": 95,
    "time": 8876.046805,
    "actor_loss": 41.8243293762207,
    "critic_loss": 5.649755477905273,
    "ent_coef": 0.08706144243478775,
    "learning_rate": 0.001
  },
  {
    "episode": 403,
    "reward": 78.956047,
    "length": 78,
    "time": 8893.525619,
    "actor_loss": 44.67127990722656,
    "critic_loss": 11.251051902770996,
    "ent_coef": 0.08691874891519547,
    "learning_rate": 0.001
  },
  {
    "episode": 404,
    "reward": -169.075581,
    "length": 152,
    "time": 8916.473984,
    "actor_loss": 40.902015686035156,
    "critic_loss": 13.522960662841797,
    "ent_coef": 0.08850780129432678,
    "learning_rate": 0.001
  },
  {
    "episode": 405,
    "reward": 72.333298,
    "length": 89,
    "time": 8936.219873,
    "actor_loss": 43.177513122558594,
    "critic_loss": 14.034488677978516,
    "ent_coef": 0.09025673568248749,
    "learning_rate": 0.001
  },
  {
    "episode": 406,
    "reward": -161.842172,
    "length": 142,
    "time": 8958.849581,
    "actor_loss": 40.65986633300781,
    "critic_loss": 21.570236206054688,
    "ent_coef": 0.08723583072423935,
    "learning_rate": 0.001
  },
  {
    "episode": 407,
    "reward": 69.807032,
    "length": 90,
    "time": 8974.079659,
    "actor_loss": 42.60997772216797,
    "critic_loss": 9.426122665405273,
    "ent_coef": 0.0883297398686409,
    "learning_rate": 0.001
  },
  {
    "episode": 408,
    "reward": 75.578251,
    "length": 90,
    "time": 8988.772592,
    "actor_loss": 45.908241271972656,
    "critic_loss": 13.382026672363281,
    "ent_coef": 0.08786693960428238,
    "learning_rate": 0.001
  },
  {
    "episode": 409,
    "reward": 70.291876,
    "length": 82,
    "time": 9002.186495,
    "actor_loss": 44.436012268066406,
    "critic_loss": 38.53372573852539,
    "ent_coef": 0.08753050863742828,
    "learning_rate": 0.001
  },
  {
    "episode": 410,
    "reward": -173.527807,
    "length": 141,
    "time": 9026.677056,
    "actor_loss": 43.60462188720703,
    "critic_loss": 43.34064865112305,
    "ent_coef": 0.08715024590492249,
    "learning_rate": 0.001
  },
  {
    "episode": 411,
    "reward": -64.43856,
    "length": 288,
    "time": 9067.363647,
    "actor_loss": 40.257057189941406,
    "critic_loss": 15.040105819702148,
    "ent_coef": 0.08328071981668472,
    "learning_rate": 0.001
  },
  {
    "episode": 412,
    "reward": 71.49278,
    "length": 90,
    "time": 9081.777779,
    "actor_loss": 39.940467834472656,
    "critic_loss": 4.136402130126953,
    "ent_coef": 0.08167268335819244,
    "learning_rate": 0.001
  },
  {
    "episode": 413,
    "reward": -163.678483,
    "length": 136,
    "time": 9104.265358,
    "actor_loss": 43.97740173339844,
    "critic_loss": 53.978981018066406,
    "ent_coef": 0.08192790299654007,
    "learning_rate": 0.001
  },
  {
    "episode": 414,
    "reward": 71.741207,
    "length": 96,
    "time": 9122.347791,
    "actor_loss": 39.031288146972656,
    "critic_loss": 5.079930782318115,
    "ent_coef": 0.08301866054534912,
    "learning_rate": 0.001
  },
  {
    "episode": 415,
    "reward": -167.039225,
    "length": 129,
    "time": 9145.225327,
    "actor_loss": 38.84819030761719,
    "critic_loss": 5.6150031089782715,
    "ent_coef": 0.08592516928911209,
    "learning_rate": 0.001
  },
  {
    "episode": 416,
    "reward": -156.605859,
    "length": 139,
    "time": 9167.218065,
    "actor_loss": 40.83420181274414,
    "critic_loss": 10.58382797241211,
    "ent_coef": 0.08949687331914902,
    "learning_rate": 0.001
  },
  {
    "episode": 417,
    "reward": -161.86511,
    "length": 136,
    "time": 9187.695728,
    "actor_loss": 40.64519500732422,
    "critic_loss": 7.869624137878418,
    "ent_coef": 0.08579409867525101,
    "learning_rate": 0.001
  },
  {
    "episode": 418,
    "reward": -242.781153,
    "length": 247,
    "time": 9222.567982,
    "actor_loss": 42.70427322387695,
    "critic_loss": 252.67401123046875,
    "ent_coef": 0.07861901819705963,
    "learning_rate": 0.001
  },
  {
    "episode": 419,
    "reward": 70.453449,
    "length": 93,
    "time": 9240.255956,
    "actor_loss": 44.92448425292969,
    "critic_loss": 16.648086547851562,
    "ent_coef": 0.07698004692792892,
    "learning_rate": 0.001
  },
  {
    "episode": 420,
    "reward": 82.102379,
    "length": 77,
    "time": 9253.593747,
    "actor_loss": 41.918617248535156,
    "critic_loss": 16.200721740722656,
    "ent_coef": 0.07435817271471024,
    "learning_rate": 0.001
  },
  {
    "episode": 421,
    "reward": 55.060786,
    "length": 118,
    "time": 9272.054387,
    "actor_loss": 39.67403793334961,
    "critic_loss": 89.5327377319336,
    "ent_coef": 0.06849178671836853,
    "learning_rate": 0.001
  },
  {
    "episode": 422,
    "reward": -169.954311,
    "length": 146,
    "time": 9293.917794,
    "actor_loss": 38.686851501464844,
    "critic_loss": 1.9752027988433838,
    "ent_coef": 0.07027925550937653,
    "learning_rate": 0.001
  },
  {
    "episode": 423,
    "reward": -184.783041,
    "length": 158,
    "time": 9318.298715,
    "actor_loss": 41.72444152832031,
    "critic_loss": 5.909020900726318,
    "ent_coef": 0.07427289336919785,
    "learning_rate": 0.001
  },
  {
    "episode": 424,
    "reward": 76.445008,
    "length": 79,
    "time": 9334.87485,
    "actor_loss": 41.080406188964844,
    "critic_loss": 5.305098533630371,
    "ent_coef": 0.07377874106168747,
    "learning_rate": 0.001
  },
  {
    "episode": 425,
    "reward": 17.320444,
    "length": 172,
    "time": 9359.973458,
    "actor_loss": 38.98780822753906,
    "critic_loss": 189.16653442382812,
    "ent_coef": 0.07841424643993378,
    "learning_rate": 0.001
  },
  {
    "episode": 426,
    "reward": -166.652033,
    "length": 133,
    "time": 9381.285558,
    "actor_loss": 41.125274658203125,
    "critic_loss": 11.155662536621094,
    "ent_coef": 0.08152825385332108,
    "learning_rate": 0.001
  },
  {
    "episode": 427,
    "reward": 78.907599,
    "length": 76,
    "time": 9395.647759,
    "actor_loss": 36.437904357910156,
    "critic_loss": 9.644645690917969,
    "ent_coef": 0.08373737335205078,
    "learning_rate": 0.001
  },
  {
    "episode": 428,
    "reward": 79.542045,
    "length": 80,
    "time": 9413.005252,
    "actor_loss": 39.470970153808594,
    "critic_loss": 10.481070518493652,
    "ent_coef": 0.08491455018520355,
    "learning_rate": 0.001
  },
  {
    "episode": 429,
    "reward": -163.542675,
    "length": 138,
    "time": 9436.692432,
    "actor_loss": 39.406227111816406,
    "critic_loss": 30.72775650024414,
    "ent_coef": 0.0885639414191246,
    "learning_rate": 0.001
  },
  {
    "episode": 430,
    "reward": 71.802268,
    "length": 84,
    "time": 9452.348206,
    "actor_loss": 38.525840759277344,
    "critic_loss": 27.049381256103516,
    "ent_coef": 0.08448752760887146,
    "learning_rate": 0.001
  },
  {
    "episode": 431,
    "reward": 28.100861,
    "length": 175,
    "time": 9479.46162,
    "actor_loss": 38.074771881103516,
    "critic_loss": 13.079345703125,
    "ent_coef": 0.0807475596666336,
    "learning_rate": 0.001
  },
  {
    "episode": 432,
    "reward": -209.766442,
    "length": 210,
    "time": 9511.927981,
    "actor_loss": 39.09697723388672,
    "critic_loss": 5.685396194458008,
    "ent_coef": 0.08178576081991196,
    "learning_rate": 0.001
  },
  {
    "episode": 433,
    "reward": 83.187937,
    "length": 76,
    "time": 9524.705862,
    "actor_loss": 38.594207763671875,
    "critic_loss": 26.383514404296875,
    "ent_coef": 0.08395059406757355,
    "learning_rate": 0.001
  },
  {
    "episode": 434,
    "reward": 74.430327,
    "length": 88,
    "time": 9539.233711,
    "actor_loss": 40.82383728027344,
    "critic_loss": 43.7005500793457,
    "ent_coef": 0.08370060473680496,
    "learning_rate": 0.001
  },
  {
    "episode": 435,
    "reward": 67.423115,
    "length": 167,
    "time": 9565.568249,
    "actor_loss": 47.24120330810547,
    "critic_loss": 4.399036407470703,
    "ent_coef": 0.08412384241819382,
    "learning_rate": 0.001
  },
  {
    "episode": 436,
    "reward": 66.605683,
    "length": 161,
    "time": 9590.455891,
    "actor_loss": 39.56356430053711,
    "critic_loss": 29.09284019470215,
    "ent_coef": 0.09264866262674332,
    "learning_rate": 0.001
  },
  {
    "episode": 437,
    "reward": 66.546078,
    "length": 165,
    "time": 9614.618243,
    "actor_loss": 45.51188659667969,
    "critic_loss": 6.948857307434082,
    "ent_coef": 0.09106429666280746,
    "learning_rate": 0.001
  },
  {
    "episode": 438,
    "reward": 65.596209,
    "length": 125,
    "time": 9634.041559,
    "actor_loss": 37.40630340576172,
    "critic_loss": 13.416881561279297,
    "ent_coef": 0.09018298238515854,
    "learning_rate": 0.001
  },
  {
    "episode": 439,
    "reward": 67.067028,
    "length": 96,
    "time": 9649.768738,
    "actor_loss": 39.85622024536133,
    "critic_loss": 5.60453462600708,
    "ent_coef": 0.0905776396393776,
    "learning_rate": 0.001
  },
  {
    "episode": 440,
    "reward": 80.725539,
    "length": 101,
    "time": 9665.746425,
    "actor_loss": 42.488067626953125,
    "critic_loss": 63.11384582519531,
    "ent_coef": 0.0946231409907341,
    "learning_rate": 0.001
  },
  {
    "episode": 441,
    "reward": 58.841045,
    "length": 118,
    "time": 9687.679608,
    "actor_loss": 40.58143997192383,
    "critic_loss": 13.451445579528809,
    "ent_coef": 0.09142562001943588,
    "learning_rate": 0.001
  },
  {
    "episode": 442,
    "reward": 44.942276,
    "length": 155,
    "time": 9711.851245,
    "actor_loss": 41.18006896972656,
    "critic_loss": 30.669706344604492,
    "ent_coef": 0.09006239473819733,
    "learning_rate": 0.001
  },
  {
    "episode": 443,
    "reward": 7.861954,
    "length": 190,
    "time": 9741.823736,
    "actor_loss": 40.77653121948242,
    "critic_loss": 35.318180084228516,
    "ent_coef": 0.08788180351257324,
    "learning_rate": 0.001
  },
  {
    "episode": 444,
    "reward": -159.856947,
    "length": 133,
    "time": 9763.466417,
    "actor_loss": 35.08772659301758,
    "critic_loss": 230.6153564453125,
    "ent_coef": 0.09483883529901505,
    "learning_rate": 0.001
  },
  {
    "episode": 445,
    "reward": 74.128036,
    "length": 97,
    "time": 9780.883315,
    "actor_loss": 41.485137939453125,
    "critic_loss": 3.6891372203826904,
    "ent_coef": 0.09326250851154327,
    "learning_rate": 0.001
  },
  {
    "episode": 446,
    "reward": 59.124811,
    "length": 116,
    "time": 9801.505595,
    "actor_loss": 37.738277435302734,
    "critic_loss": 106.19056701660156,
    "ent_coef": 0.09103577584028244,
    "learning_rate": 0.001
  },
  {
    "episode": 447,
    "reward": -401.972249,
    "length": 588,
    "time": 9881.535595,
    "actor_loss": 35.21363830566406,
    "critic_loss": 15.07148265838623,
    "ent_coef": 0.07237030565738678,
    "learning_rate": 0.001
  },
  {
    "episode": 448,
    "reward": -456.661774,
    "length": 530,
    "time": 9953.868998,
    "actor_loss": 38.25682067871094,
    "critic_loss": 5.7003302574157715,
    "ent_coef": 0.0691973939538002,
    "learning_rate": 0.001
  },
  {
    "episode": 449,
    "reward": 58.511199,
    "length": 120,
    "time": 9976.05582,
    "actor_loss": 34.68300247192383,
    "critic_loss": 32.02307891845703,
    "ent_coef": 0.06838107854127884,
    "learning_rate": 0.001
  },
  {
    "episode": 450,
    "reward": 69.713311,
    "length": 96,
    "time": 9992.178972,
    "actor_loss": 39.62699890136719,
    "critic_loss": 2.576477527618408,
    "ent_coef": 0.06957487016916275,
    "learning_rate": 0.001
  },
  {
    "episode": 451,
    "reward": 35.536533,
    "length": 149,
    "time": 10015.720382,
    "actor_loss": 38.8834228515625,
    "critic_loss": 40.94652557373047,
    "ent_coef": 0.06767576932907104,
    "learning_rate": 0.001
  },
  {
    "episode": 452,
    "reward": 42.128327,
    "length": 149,
    "time": 10039.476599,
    "actor_loss": 40.259613037109375,
    "critic_loss": 3.670531988143921,
    "ent_coef": 0.0649624839425087,
    "learning_rate": 0.001
  },
  {
    "episode": 453,
    "reward": 71.514882,
    "length": 90,
    "time": 10054.036741,
    "actor_loss": 40.23689651489258,
    "critic_loss": 203.33526611328125,
    "ent_coef": 0.06635400652885437,
    "learning_rate": 0.001
  },
  {
    "episode": 454,
    "reward": 76.008888,
    "length": 84,
    "time": 10070.375852,
    "actor_loss": 35.837059020996094,
    "critic_loss": 9.79837703704834,
    "ent_coef": 0.07130418717861176,
    "learning_rate": 0.001
  },
  {
    "episode": 455,
    "reward": 78.538033,
    "length": 78,
    "time": 10083.157297,
    "actor_loss": 38.61663818359375,
    "critic_loss": 53.04584503173828,
    "ent_coef": 0.07245007157325745,
    "learning_rate": 0.001
  },
  {
    "episode": 456,
    "reward": 79.464628,
    "length": 90,
    "time": 10099.459902,
    "actor_loss": 28.038562774658203,
    "critic_loss": 39.95743942260742,
    "ent_coef": 0.07513374090194702,
    "learning_rate": 0.001
  },
  {
    "episode": 457,
    "reward": -161.20094,
    "length": 160,
    "time": 10123.518985,
    "actor_loss": 39.94589614868164,
    "critic_loss": 4.789036273956299,
    "ent_coef": 0.08254950493574142,
    "learning_rate": 0.001
  },
  {
    "episode": 458,
    "reward": 82.096392,
    "length": 90,
    "time": 10140.159263,
    "actor_loss": 35.94071578979492,
    "critic_loss": 61.68650817871094,
    "ent_coef": 0.08598419278860092,
    "learning_rate": 0.001
  },
  {
    "episode": 459,
    "reward": 79.171638,
    "length": 83,
    "time": 10154.679952,
    "actor_loss": 34.277626037597656,
    "critic_loss": 22.721975326538086,
    "ent_coef": 0.08725014328956604,
    "learning_rate": 0.001
  },
  {
    "episode": 460,
    "reward": -163.46936,
    "length": 123,
    "time": 10174.303854,
    "actor_loss": 37.68413543701172,
    "critic_loss": 8.558923721313477,
    "ent_coef": 0.09128273278474808,
    "learning_rate": 0.001
  },
  {
    "episode": 461,
    "reward": 77.502021,
    "length": 81,
    "time": 10187.475314,
    "actor_loss": 36.274139404296875,
    "critic_loss": 27.399206161499023,
    "ent_coef": 0.09178949147462845,
    "learning_rate": 0.001
  },
  {
    "episode": 462,
    "reward": 82.51557,
    "length": 76,
    "time": 10200.204755,
    "actor_loss": 43.41630935668945,
    "critic_loss": 6.244521617889404,
    "ent_coef": 0.0927208960056305,
    "learning_rate": 0.001
  },
  {
    "episode": 463,
    "reward": -164.276031,
    "length": 137,
    "time": 10221.851654,
    "actor_loss": 34.37650680541992,
    "critic_loss": 5.620416641235352,
    "ent_coef": 0.09116750955581665,
    "learning_rate": 0.001
  },
  {
    "episode": 464,
    "reward": 61.746097,
    "length": 108,
    "time": 10241.504756,
    "actor_loss": 37.27008819580078,
    "critic_loss": 71.7132568359375,
    "ent_coef": 0.09153283387422562,
    "learning_rate": 0.001
  },
  {
    "episode": 465,
    "reward": -164.229333,
    "length": 135,
    "time": 10263.919547,
    "actor_loss": 35.035789489746094,
    "critic_loss": 5.113667964935303,
    "ent_coef": 0.08937977254390717,
    "learning_rate": 0.001
  },
  {
    "episode": 466,
    "reward": 78.552898,
    "length": 83,
    "time": 10277.650071,
    "actor_loss": 38.9279670715332,
    "critic_loss": 10.397698402404785,
    "ent_coef": 0.08873797208070755,
    "learning_rate": 0.001
  },
  {
    "episode": 467,
    "reward": 80.86464,
    "length": 75,
    "time": 10291.531749,
    "actor_loss": 36.95519256591797,
    "critic_loss": 15.516890525817871,
    "ent_coef": 0.08947353810071945,
    "learning_rate": 0.001
  },
  {
    "episode": 468,
    "reward": 77.140172,
    "length": 82,
    "time": 10307.045605,
    "actor_loss": 37.79783248901367,
    "critic_loss": 70.79859161376953,
    "ent_coef": 0.08878914266824722,
    "learning_rate": 0.001
  },
  {
    "episode": 469,
    "reward": 78.504279,
    "length": 79,
    "time": 10321.263187,
    "actor_loss": 34.681922912597656,
    "critic_loss": 31.49811553955078,
    "ent_coef": 0.09275761991739273,
    "learning_rate": 0.001
  },
  {
    "episode": 470,
    "reward": -159.320323,
    "length": 141,
    "time": 10343.995521,
    "actor_loss": 31.369705200195312,
    "critic_loss": 151.48419189453125,
    "ent_coef": 0.09299036860466003,
    "learning_rate": 0.001
  },
  {
    "episode": 471,
    "reward": 72.526535,
    "length": 92,
    "time": 10359.403457,
    "actor_loss": 39.953086853027344,
    "critic_loss": 309.3319091796875,
    "ent_coef": 0.09290504455566406,
    "learning_rate": 0.001
  },
  {
    "episode": 472,
    "reward": -177.066628,
    "length": 216,
    "time": 10389.982233,
    "actor_loss": 33.050880432128906,
    "critic_loss": 189.5692596435547,
    "ent_coef": 0.09359505027532578,
    "learning_rate": 0.001
  },
  {
    "episode": 473,
    "reward": 78.349261,
    "length": 75,
    "time": 10403.697311,
    "actor_loss": 30.226654052734375,
    "critic_loss": 8.891212463378906,
    "ent_coef": 0.09667637199163437,
    "learning_rate": 0.001
  },
  {
    "episode": 474,
    "reward": 78.051212,
    "length": 138,
    "time": 10425.168581,
    "actor_loss": 37.2244987487793,
    "critic_loss": 44.88285827636719,
    "ent_coef": 0.10309756547212601,
    "learning_rate": 0.001
  },
  {
    "episode": 475,
    "reward": 76.477222,
    "length": 97,
    "time": 10442.650215,
    "actor_loss": 36.106441497802734,
    "critic_loss": 23.2017765045166,
    "ent_coef": 0.10497409105300903,
    "learning_rate": 0.001
  },
  {
    "episode": 476,
    "reward": 61.676058,
    "length": 148,
    "time": 10464.77896,
    "actor_loss": 32.5584716796875,
    "critic_loss": 208.2020263671875,
    "ent_coef": 0.10344772040843964,
    "learning_rate": 0.001
  },
  {
    "episode": 477,
    "reward": 60.972842,
    "length": 140,
    "time": 10487.076165,
    "actor_loss": 36.90411376953125,
    "critic_loss": 2.0650570392608643,
    "ent_coef": 0.09466913342475891,
    "learning_rate": 0.001
  },
  {
    "episode": 478,
    "reward": 56.075206,
    "length": 184,
    "time": 10513.911325,
    "actor_loss": 35.60520935058594,
    "critic_loss": 15.8465576171875,
    "ent_coef": 0.08876895159482956,
    "learning_rate": 0.001
  },
  {
    "episode": 479,
    "reward": 74.452856,
    "length": 81,
    "time": 10528.503656,
    "actor_loss": 37.098854064941406,
    "critic_loss": 13.851335525512695,
    "ent_coef": 0.08676489442586899,
    "learning_rate": 0.001
  },
  {
    "episode": 480,
    "reward": 72.25544,
    "length": 133,
    "time": 10548.929815,
    "actor_loss": 33.080665588378906,
    "critic_loss": 12.714659690856934,
    "ent_coef": 0.08461981266736984,
    "learning_rate": 0.001
  },
  {
    "episode": 481,
    "reward": 76.947731,
    "length": 85,
    "time": 10565.319104,
    "actor_loss": 34.814456939697266,
    "critic_loss": 10.058801651000977,
    "ent_coef": 0.08715778589248657,
    "learning_rate": 0.001
  },
  {
    "episode": 482,
    "reward": 85.970161,
    "length": 70,
    "time": 10578.595567,
    "actor_loss": 35.21501922607422,
    "critic_loss": 16.451019287109375,
    "ent_coef": 0.0892087072134018,
    "learning_rate": 0.001
  },
  {
    "episode": 483,
    "reward": 86.309558,
    "length": 71,
    "time": 10590.700912,
    "actor_loss": 26.178680419921875,
    "critic_loss": 205.23849487304688,
    "ent_coef": 0.09157826751470566,
    "learning_rate": 0.001
  },
  {
    "episode": 484,
    "reward": 80.966282,
    "length": 89,
    "time": 10608.180672,
    "actor_loss": 36.7447395324707,
    "critic_loss": 46.13486099243164,
    "ent_coef": 0.09738080948591232,
    "learning_rate": 0.001
  },
  {
    "episode": 485,
    "reward": 65.500561,
    "length": 102,
    "time": 10627.846526,
    "actor_loss": 35.5273323059082,
    "critic_loss": 76.58045196533203,
    "ent_coef": 0.09252744168043137,
    "learning_rate": 0.001
  },
  {
    "episode": 486,
    "reward": 82.072632,
    "length": 101,
    "time": 10646.982317,
    "actor_loss": 35.89830780029297,
    "critic_loss": 203.70565795898438,
    "ent_coef": 0.092088982462883,
    "learning_rate": 0.001
  },
  {
    "episode": 487,
    "reward": -164.170101,
    "length": 121,
    "time": 10666.764997,
    "actor_loss": 31.80916976928711,
    "critic_loss": 29.244840621948242,
    "ent_coef": 0.0892476812005043,
    "learning_rate": 0.001
  },
  {
    "episode": 488,
    "reward": 83.773001,
    "length": 88,
    "time": 10683.154307,
    "actor_loss": 38.30847930908203,
    "critic_loss": 16.043807983398438,
    "ent_coef": 0.0880851149559021,
    "learning_rate": 0.001
  },
  {
    "episode": 489,
    "reward": 60.494201,
    "length": 254,
    "time": 10720.264042,
    "actor_loss": 31.19134521484375,
    "critic_loss": 283.77545166015625,
    "ent_coef": 0.08502364158630371,
    "learning_rate": 0.001
  },
  {
    "episode": 490,
    "reward": 75.28744,
    "length": 84,
    "time": 10736.577698,
    "actor_loss": 35.30909729003906,
    "critic_loss": 59.11704635620117,
    "ent_coef": 0.08790406584739685,
    "learning_rate": 0.001
  },
  {
    "episode": 491,
    "reward": -170.586667,
    "length": 138,
    "time": 10758.345339,
    "actor_loss": 30.291088104248047,
    "critic_loss": 351.1005554199219,
    "ent_coef": 0.09510958939790726,
    "learning_rate": 0.001
  },
  {
    "episode": 492,
    "reward": 64.626871,
    "length": 105,
    "time": 10776.23795,
    "actor_loss": 36.338836669921875,
    "critic_loss": 53.415924072265625,
    "ent_coef": 0.09173595905303955,
    "learning_rate": 0.001
  },
  {
    "episode": 493,
    "reward": -166.871366,
    "length": 144,
    "time": 10797.642987,
    "actor_loss": 31.909465789794922,
    "critic_loss": 6.9499616622924805,
    "ent_coef": 0.0914963111281395,
    "learning_rate": 0.001
  },
  {
    "episode": 494,
    "reward": -164.098774,
    "length": 145,
    "time": 10820.136647,
    "actor_loss": 31.307512283325195,
    "critic_loss": 9.64546012878418,
    "ent_coef": 0.08680480718612671,
    "learning_rate": 0.001
  },
  {
    "episode": 495,
    "reward": -161.893047,
    "length": 137,
    "time": 10841.457164,
    "actor_loss": 33.19371795654297,
    "critic_loss": 13.470582962036133,
    "ent_coef": 0.08603162318468094,
    "learning_rate": 0.001
  },
  {
    "episode": 496,
    "reward": -168.982087,
    "length": 140,
    "time": 10863.541572,
    "actor_loss": 35.635704040527344,
    "critic_loss": 18.877071380615234,
    "ent_coef": 0.08907727152109146,
    "learning_rate": 0.001
  },
  {
    "episode": 497,
    "reward": -168.772961,
    "length": 129,
    "time": 10884.606422,
    "actor_loss": 31.057958602905273,
    "critic_loss": 21.96489715576172,
    "ent_coef": 0.09030614048242569,
    "learning_rate": 0.001
  },
  {
    "episode": 498,
    "reward": 72.66696,
    "length": 82,
    "time": 10900.379463,
    "actor_loss": 34.94562530517578,
    "critic_loss": 7.6186418533325195,
    "ent_coef": 0.0926971361041069,
    "learning_rate": 0.001
  },
  {
    "episode": 499,
    "reward": 72.987471,
    "length": 87,
    "time": 10914.930906,
    "actor_loss": 27.899179458618164,
    "critic_loss": 33.800567626953125,
    "ent_coef": 0.08930197358131409,
    "learning_rate": 0.001
  },
  {
    "episode": 500,
    "reward": 78.953155,
    "length": 80,
    "time": 10929.145026,
    "actor_loss": 34.50184631347656,
    "critic_loss": 50.67011260986328,
    "ent_coef": 0.09098948538303375,
    "learning_rate": 0.001
  },
  {
    "episode": 501,
    "reward": -160.811074,
    "length": 133,
    "time": 10950.842811,
    "actor_loss": 38.53920364379883,
    "critic_loss": 15.242635726928711,
    "ent_coef": 0.09524086117744446,
    "learning_rate": 0.001
  },
  {
    "episode": 502,
    "reward": -167.125245,
    "length": 145,
    "time": 10972.3407,
    "actor_loss": 36.798152923583984,
    "critic_loss": 15.432891845703125,
    "ent_coef": 0.09214215725660324,
    "learning_rate": 0.001
  },
  {
    "episode": 503,
    "reward": 75.992481,
    "length": 82,
    "time": 10986.784376,
    "actor_loss": 30.92152214050293,
    "critic_loss": 6.9804534912109375,
    "ent_coef": 0.09493516385555267,
    "learning_rate": 0.001
  },
  {
    "episode": 504,
    "reward": -161.029971,
    "length": 139,
    "time": 11007.59493,
    "actor_loss": 34.017452239990234,
    "critic_loss": 28.0614013671875,
    "ent_coef": 0.09680178016424179,
    "learning_rate": 0.001
  },
  {
    "episode": 505,
    "reward": -160.515308,
    "length": 137,
    "time": 11031.040125,
    "actor_loss": 34.050453186035156,
    "critic_loss": 9.060199737548828,
    "ent_coef": 0.09969934821128845,
    "learning_rate": 0.001
  },
  {
    "episode": 506,
    "reward": 82.66984,
    "length": 77,
    "time": 11043.771039,
    "actor_loss": 38.166908264160156,
    "critic_loss": 5.08930778503418,
    "ent_coef": 0.09873524308204651,
    "learning_rate": 0.001
  },
  {
    "episode": 507,
    "reward": -158.544197,
    "length": 128,
    "time": 11064.241039,
    "actor_loss": 34.865631103515625,
    "critic_loss": 62.050052642822266,
    "ent_coef": 0.09372490644454956,
    "learning_rate": 0.001
  },
  {
    "episode": 508,
    "reward": 81.101193,
    "length": 78,
    "time": 11077.310828,
    "actor_loss": 34.29756164550781,
    "critic_loss": 23.782611846923828,
    "ent_coef": 0.09460009634494781,
    "learning_rate": 0.001
  },
  {
    "episode": 509,
    "reward": 79.797047,
    "length": 92,
    "time": 11093.106184,
    "actor_loss": 31.110130310058594,
    "critic_loss": 10.013653755187988,
    "ent_coef": 0.09478665888309479,
    "learning_rate": 0.001
  },
  {
    "episode": 510,
    "reward": 73.666392,
    "length": 109,
    "time": 11114.57673,
    "actor_loss": 31.323850631713867,
    "critic_loss": 165.1991729736328,
    "ent_coef": 0.09635360538959503,
    "learning_rate": 0.001
  },
  {
    "episode": 511,
    "reward": -157.41069,
    "length": 592,
    "time": 11194.697726,
    "actor_loss": 26.168577194213867,
    "critic_loss": 7.4001359939575195,
    "ent_coef": 0.10615904629230499,
    "learning_rate": 0.001
  },
  {
    "episode": 512,
    "reward": 72.795786,
    "length": 85,
    "time": 11210.479191,
    "actor_loss": 27.406734466552734,
    "critic_loss": 14.792531967163086,
    "ent_coef": 0.1033530980348587,
    "learning_rate": 0.001
  },
  {
    "episode": 513,
    "reward": 81.60669,
    "length": 75,
    "time": 11223.251094,
    "actor_loss": 33.718971252441406,
    "critic_loss": 5.696983337402344,
    "ent_coef": 0.10362095385789871,
    "learning_rate": 0.001
  },
  {
    "episode": 514,
    "reward": 78.495831,
    "length": 107,
    "time": 11243.33717,
    "actor_loss": 36.145225524902344,
    "critic_loss": 34.89504623413086,
    "ent_coef": 0.10657882690429688,
    "learning_rate": 0.001
  },
  {
    "episode": 515,
    "reward": 74.747807,
    "length": 104,
    "time": 11259.832668,
    "actor_loss": 30.522930145263672,
    "critic_loss": 42.253807067871094,
    "ent_coef": 0.10725170373916626,
    "learning_rate": 0.001
  },
  {
    "episode": 516,
    "reward": -162.232679,
    "length": 126,
    "time": 11281.665013,
    "actor_loss": 35.628318786621094,
    "critic_loss": 4.101996898651123,
    "ent_coef": 0.1054096519947052,
    "learning_rate": 0.001
  },
  {
    "episode": 517,
    "reward": 77.907962,
    "length": 100,
    "time": 11297.65648,
    "actor_loss": 39.63507080078125,
    "critic_loss": 229.00726318359375,
    "ent_coef": 0.10670799016952515,
    "learning_rate": 0.001
  },
  {
    "episode": 518,
    "reward": 66.299487,
    "length": 124,
    "time": 11318.821669,
    "actor_loss": 31.76688003540039,
    "critic_loss": 229.9384765625,
    "ent_coef": 0.10636064410209656,
    "learning_rate": 0.001
  },
  {
    "episode": 519,
    "reward": 83.440232,
    "length": 77,
    "time": 11332.34409,
    "actor_loss": 30.636171340942383,
    "critic_loss": 179.81918334960938,
    "ent_coef": 0.1090446189045906,
    "learning_rate": 0.001
  },
  {
    "episode": 520,
    "reward": 81.948444,
    "length": 76,
    "time": 11346.187647,
    "actor_loss": 32.53516387939453,
    "critic_loss": 11.673219680786133,
    "ent_coef": 0.10700836777687073,
    "learning_rate": 0.001
  },
  {
    "episode": 521,
    "reward": 65.732638,
    "length": 178,
    "time": 11372.232214,
    "actor_loss": 33.40156173706055,
    "critic_loss": 26.219860076904297,
    "ent_coef": 0.11121515929698944,
    "learning_rate": 0.001
  },
  {
    "episode": 522,
    "reward": 82.193244,
    "length": 76,
    "time": 11387.993628,
    "actor_loss": 31.073410034179688,
    "critic_loss": 81.84068298339844,
    "ent_coef": 0.11424140632152557,
    "learning_rate": 0.001
  },
  {
    "episode": 523,
    "reward": 83.263008,
    "length": 73,
    "time": 11401.007895,
    "actor_loss": 33.279720306396484,
    "critic_loss": 152.42269897460938,
    "ent_coef": 0.11600025743246078,
    "learning_rate": 0.001
  },
  {
    "episode": 524,
    "reward": 80.099388,
    "length": 78,
    "time": 11415.295255,
    "actor_loss": 33.062294006347656,
    "critic_loss": 13.859747886657715,
    "ent_coef": 0.11985096335411072,
    "learning_rate": 0.001
  },
  {
    "episode": 525,
    "reward": 29.25922,
    "length": 575,
    "time": 11492.037276,
    "actor_loss": 32.28306579589844,
    "critic_loss": 83.42749786376953,
    "ent_coef": 0.11013173311948776,
    "learning_rate": 0.001
  },
  {
    "episode": 526,
    "reward": 64.660631,
    "length": 123,
    "time": 11515.307115,
    "actor_loss": 29.943115234375,
    "critic_loss": 332.02618408203125,
    "ent_coef": 0.10849232971668243,
    "learning_rate": 0.001
  },
  {
    "episode": 527,
    "reward": 75.152394,
    "length": 118,
    "time": 11535.945123,
    "actor_loss": 23.21969985961914,
    "critic_loss": 10.558221817016602,
    "ent_coef": 0.10302984714508057,
    "learning_rate": 0.001
  },
  {
    "episode": 528,
    "reward": -161.463874,
    "length": 581,
    "time": 11616.013874,
    "actor_loss": 30.48996353149414,
    "critic_loss": 149.65377807617188,
    "ent_coef": 0.10785131901502609,
    "learning_rate": 0.001
  },
  {
    "episode": 529,
    "reward": 76.524143,
    "length": 104,
    "time": 11633.126015,
    "actor_loss": 22.676849365234375,
    "critic_loss": 9.220491409301758,
    "ent_coef": 0.10871253162622452,
    "learning_rate": 0.001
  },
  {
    "episode": 530,
    "reward": 77.04312,
    "length": 84,
    "time": 11649.734349,
    "actor_loss": 31.471023559570312,
    "critic_loss": 20.843975067138672,
    "ent_coef": 0.10608503967523575,
    "learning_rate": 0.001
  },
  {
    "episode": 531,
    "reward": 70.655001,
    "length": 99,
    "time": 11667.716887,
    "actor_loss": 31.716121673583984,
    "critic_loss": 45.351043701171875,
    "ent_coef": 0.10666607320308685,
    "learning_rate": 0.001
  },
  {
    "episode": 532,
    "reward": 76.264518,
    "length": 87,
    "time": 11681.972234,
    "actor_loss": 34.689002990722656,
    "critic_loss": 12.781978607177734,
    "ent_coef": 0.10284460335969925,
    "learning_rate": 0.001
  },
  {
    "episode": 533,
    "reward": 81.646974,
    "length": 80,
    "time": 11697.238811,
    "actor_loss": 33.15702819824219,
    "critic_loss": 42.794822692871094,
    "ent_coef": 0.10177922248840332,
    "learning_rate": 0.001
  },
  {
    "episode": 534,
    "reward": -159.30065,
    "length": 123,
    "time": 11717.727532,
    "actor_loss": 26.05514907836914,
    "critic_loss": 391.08221435546875,
    "ent_coef": 0.1057228073477745,
    "learning_rate": 0.001
  },
  {
    "episode": 535,
    "reward": 77.089783,
    "length": 90,
    "time": 11734.43023,
    "actor_loss": 30.484233856201172,
    "critic_loss": 194.2136688232422,
    "ent_coef": 0.10579721629619598,
    "learning_rate": 0.001
  },
  {
    "episode": 536,
    "reward": 73.910246,
    "length": 85,
    "time": 11749.219311,
    "actor_loss": 27.543071746826172,
    "critic_loss": 43.583953857421875,
    "ent_coef": 0.10706103593111038,
    "learning_rate": 0.001
  },
  {
    "episode": 537,
    "reward": -102.861656,
    "length": 587,
    "time": 11829.254093,
    "actor_loss": 26.565242767333984,
    "critic_loss": 42.87420654296875,
    "ent_coef": 0.09977328032255173,
    "learning_rate": 0.001
  },
  {
    "episode": 538,
    "reward": 70.430816,
    "length": 95,
    "time": 11846.056787,
    "actor_loss": 29.972644805908203,
    "critic_loss": 32.65251922607422,
    "ent_coef": 0.10243546217679977,
    "learning_rate": 0.001
  },
  {
    "episode": 539,
    "reward": 77.085313,
    "length": 91,
    "time": 11860.718091,
    "actor_loss": 29.42547035217285,
    "critic_loss": 21.839828491210938,
    "ent_coef": 0.09991253167390823,
    "learning_rate": 0.001
  },
  {
    "episode": 540,
    "reward": 78.941437,
    "length": 86,
    "time": 11874.970927,
    "actor_loss": 29.7238826751709,
    "critic_loss": 5.38810920715332,
    "ent_coef": 0.1000223159790039,
    "learning_rate": 0.001
  },
  {
    "episode": 541,
    "reward": 75.053637,
    "length": 83,
    "time": 11889.451708,
    "actor_loss": 32.503562927246094,
    "critic_loss": 3.454563617706299,
    "ent_coef": 0.10081511735916138,
    "learning_rate": 0.001
  },
  {
    "episode": 542,
    "reward": 75.127703,
    "length": 90,
    "time": 11907.373198,
    "actor_loss": 28.663314819335938,
    "critic_loss": 39.94345474243164,
    "ent_coef": 0.09637190401554108,
    "learning_rate": 0.001
  },
  {
    "episode": 543,
    "reward": -103.61473,
    "length": 581,
    "time": 11987.378891,
    "actor_loss": 32.09811019897461,
    "critic_loss": 34.21778106689453,
    "ent_coef": 0.09365162998437881,
    "learning_rate": 0.001
  },
  {
    "episode": 544,
    "reward": 67.862058,
    "length": 140,
    "time": 12008.51448,
    "actor_loss": 26.647151947021484,
    "critic_loss": 29.941112518310547,
    "ent_coef": 0.09881894290447235,
    "learning_rate": 0.001
  },
  {
    "episode": 545,
    "reward": 79.11666,
    "length": 81,
    "time": 12023.105887,
    "actor_loss": 22.58165168762207,
    "critic_loss": 29.212596893310547,
    "ent_coef": 0.09928582608699799,
    "learning_rate": 0.001
  },
  {
    "episode": 546,
    "reward": -161.819021,
    "length": 131,
    "time": 12044.020139,
    "actor_loss": 31.094825744628906,
    "critic_loss": 58.580162048339844,
    "ent_coef": 0.104538194835186,
    "learning_rate": 0.001
  },
  {
    "episode": 547,
    "reward": 80.205584,
    "length": 83,
    "time": 12058.668465,
    "actor_loss": 26.24222755432129,
    "critic_loss": 36.53072738647461,
    "ent_coef": 0.10466593503952026,
    "learning_rate": 0.001
  },
  {
    "episode": 548,
    "reward": 72.358692,
    "length": 84,
    "time": 12074.295615,
    "actor_loss": 25.456546783447266,
    "critic_loss": 12.053760528564453,
    "ent_coef": 0.10597345232963562,
    "learning_rate": 0.001
  },
  {
    "episode": 549,
    "reward": 81.928591,
    "length": 81,
    "time": 12090.143841,
    "actor_loss": 24.374704360961914,
    "critic_loss": 67.53616333007812,
    "ent_coef": 0.10408240556716919,
    "learning_rate": 0.001
  },
  {
    "episode": 550,
    "reward": 76.629013,
    "length": 89,
    "time": 12105.929624,
    "actor_loss": 26.850921630859375,
    "critic_loss": 7.055486679077148,
    "ent_coef": 0.09919711947441101,
    "learning_rate": 0.001
  },
  {
    "episode": 551,
    "reward": 80.961338,
    "length": 78,
    "time": 12121.58835,
    "actor_loss": 22.37007713317871,
    "critic_loss": 4.691343307495117,
    "ent_coef": 0.09685303270816803,
    "learning_rate": 0.001
  },
  {
    "episode": 552,
    "reward": -158.578103,
    "length": 117,
    "time": 12140.52377,
    "actor_loss": 30.846145629882812,
    "critic_loss": 179.29580688476562,
    "ent_coef": 0.10007897019386292,
    "learning_rate": 0.001
  },
  {
    "episode": 553,
    "reward": 73.479458,
    "length": 81,
    "time": 12154.011971,
    "actor_loss": 26.049503326416016,
    "critic_loss": 49.558685302734375,
    "ent_coef": 0.10433796793222427,
    "learning_rate": 0.001
  },
  {
    "episode": 554,
    "reward": 63.026264,
    "length": 147,
    "time": 12176.099695,
    "actor_loss": 28.548933029174805,
    "critic_loss": 87.79106140136719,
    "ent_coef": 0.10353390872478485,
    "learning_rate": 0.001
  },
  {
    "episode": 555,
    "reward": 72.332906,
    "length": 91,
    "time": 12195.405827,
    "actor_loss": 26.950950622558594,
    "critic_loss": 9.419998168945312,
    "ent_coef": 0.1054384633898735,
    "learning_rate": 0.001
  },
  {
    "episode": 556,
    "reward": 81.753666,
    "length": 79,
    "time": 12209.458813,
    "actor_loss": 27.370494842529297,
    "critic_loss": 104.49664306640625,
    "ent_coef": 0.10663258284330368,
    "learning_rate": 0.001
  },
  {
    "episode": 557,
    "reward": 17.974029,
    "length": 173,
    "time": 12234.870207,
    "actor_loss": 28.86361312866211,
    "critic_loss": 8.284589767456055,
    "ent_coef": 0.10087504982948303,
    "learning_rate": 0.001
  },
  {
    "episode": 558,
    "reward": 74.561712,
    "length": 98,
    "time": 12251.655334,
    "actor_loss": 25.42605209350586,
    "critic_loss": 17.298141479492188,
    "ent_coef": 0.10334564000368118,
    "learning_rate": 0.001
  },
  {
    "episode": 559,
    "reward": 86.388311,
    "length": 73,
    "time": 12264.106845,
    "actor_loss": 29.633668899536133,
    "critic_loss": 8.095972061157227,
    "ent_coef": 0.10990201681852341,
    "learning_rate": 0.001
  },
  {
    "episode": 560,
    "reward": 76.972859,
    "length": 85,
    "time": 12278.517994,
    "actor_loss": 22.77214813232422,
    "critic_loss": 14.134431838989258,
    "ent_coef": 0.10568752139806747,
    "learning_rate": 0.001
  },
  {
    "episode": 561,
    "reward": 82.283008,
    "length": 83,
    "time": 12292.239766,
    "actor_loss": 24.95783233642578,
    "critic_loss": 7.968392372131348,
    "ent_coef": 0.10427010804414749,
    "learning_rate": 0.001
  },
  {
    "episode": 562,
    "reward": 79.502296,
    "length": 84,
    "time": 12307.848297,
    "actor_loss": 26.798179626464844,
    "critic_loss": 40.871612548828125,
    "ent_coef": 0.10064534097909927,
    "learning_rate": 0.001
  },
  {
    "episode": 563,
    "reward": 77.242319,
    "length": 132,
    "time": 12328.081375,
    "actor_loss": 28.928943634033203,
    "critic_loss": 39.308128356933594,
    "ent_coef": 0.1019340306520462,
    "learning_rate": 0.001
  },
  {
    "episode": 564,
    "reward": -158.387353,
    "length": 114,
    "time": 12346.75473,
    "actor_loss": 25.20284652709961,
    "critic_loss": 137.625244140625,
    "ent_coef": 0.10080894082784653,
    "learning_rate": 0.001
  },
  {
    "episode": 565,
    "reward": 65.991202,
    "length": 109,
    "time": 12363.856488,
    "actor_loss": 24.569900512695312,
    "critic_loss": 278.57763671875,
    "ent_coef": 0.09751921147108078,
    "learning_rate": 0.001
  },
  {
    "episode": 566,
    "reward": 82.97059,
    "length": 92,
    "time": 12379.089203,
    "actor_loss": 31.240570068359375,
    "critic_loss": 4.329969882965088,
    "ent_coef": 0.10010295361280441,
    "learning_rate": 0.001
  },
  {
    "episode": 567,
    "reward": 75.929537,
    "length": 86,
    "time": 12394.236989,
    "actor_loss": 23.589385986328125,
    "critic_loss": 7.932636737823486,
    "ent_coef": 0.09743355214595795,
    "learning_rate": 0.001
  },
  {
    "episode": 568,
    "reward": 60.017081,
    "length": 154,
    "time": 12419.469588,
    "actor_loss": 29.21649169921875,
    "critic_loss": 8.342785835266113,
    "ent_coef": 0.10220693051815033,
    "learning_rate": 0.001
  },
  {
    "episode": 569,
    "reward": 83.279845,
    "length": 77,
    "time": 12434.645019,
    "actor_loss": 25.509153366088867,
    "critic_loss": 244.77789306640625,
    "ent_coef": 0.10187385231256485,
    "learning_rate": 0.001
  },
  {
    "episode": 570,
    "reward": 80.619848,
    "length": 79,
    "time": 12448.867303,
    "actor_loss": 30.338485717773438,
    "critic_loss": 78.01661682128906,
    "ent_coef": 0.09986909478902817,
    "learning_rate": 0.001
  },
  {
    "episode": 571,
    "reward": -27.368928,
    "length": 225,
    "time": 12480.899491,
    "actor_loss": 26.696908950805664,
    "critic_loss": 22.107295989990234,
    "ent_coef": 0.09813161194324493,
    "learning_rate": 0.001
  },
  {
    "episode": 572,
    "reward": 75.147434,
    "length": 90,
    "time": 12498.243361,
    "actor_loss": 22.94747543334961,
    "critic_loss": 11.752135276794434,
    "ent_coef": 0.09392190724611282,
    "learning_rate": 0.001
  },
  {
    "episode": 573,
    "reward": 83.195163,
    "length": 80,
    "time": 12512.603696,
    "actor_loss": 22.44463348388672,
    "critic_loss": 54.349693298339844,
    "ent_coef": 0.09200063347816467,
    "learning_rate": 0.001
  },
  {
    "episode": 574,
    "reward": 72.241101,
    "length": 90,
    "time": 12528.374466,
    "actor_loss": 24.155698776245117,
    "critic_loss": 65.25653839111328,
    "ent_coef": 0.0925261452794075,
    "learning_rate": 0.001
  },
  {
    "episode": 575,
    "reward": 75.913707,
    "length": 89,
    "time": 12546.157844,
    "actor_loss": 24.759029388427734,
    "critic_loss": 8.187926292419434,
    "ent_coef": 0.09629535675048828,
    "learning_rate": 0.001
  },
  {
    "episode": 576,
    "reward": 80.336229,
    "length": 81,
    "time": 12561.27863,
    "actor_loss": 26.539640426635742,
    "critic_loss": 8.860736846923828,
    "ent_coef": 0.1007709726691246,
    "learning_rate": 0.001
  },
  {
    "episode": 577,
    "reward": 85.085249,
    "length": 86,
    "time": 12576.667701,
    "actor_loss": 22.492977142333984,
    "critic_loss": 21.523265838623047,
    "ent_coef": 0.10520848631858826,
    "learning_rate": 0.001
  },
  {
    "episode": 578,
    "reward": 70.409505,
    "length": 101,
    "time": 12592.806511,
    "actor_loss": 27.45446014404297,
    "critic_loss": 20.27962875366211,
    "ent_coef": 0.09886328876018524,
    "learning_rate": 0.001
  },
  {
    "episode": 579,
    "reward": 43.025683,
    "length": 144,
    "time": 12616.08197,
    "actor_loss": 28.336856842041016,
    "critic_loss": 5.145382881164551,
    "ent_coef": 0.09456799924373627,
    "learning_rate": 0.001
  },
  {
    "episode": 580,
    "reward": 78.939634,
    "length": 97,
    "time": 12632.800674,
    "actor_loss": 23.53280258178711,
    "critic_loss": 207.71969604492188,
    "ent_coef": 0.09628243744373322,
    "learning_rate": 0.001
  },
  {
    "episode": 581,
    "reward": 65.631352,
    "length": 101,
    "time": 12649.734661,
    "actor_loss": 20.65761947631836,
    "critic_loss": 15.199771881103516,
    "ent_coef": 0.09621570259332657,
    "learning_rate": 0.001
  },
  {
    "episode": 582,
    "reward": 75.386933,
    "length": 84,
    "time": 12663.709313,
    "actor_loss": 24.859851837158203,
    "critic_loss": 14.440793991088867,
    "ent_coef": 0.10324754565954208,
    "learning_rate": 0.001
  },
  {
    "episode": 583,
    "reward": 53.801527,
    "length": 142,
    "time": 12686.262443,
    "actor_loss": 18.983333587646484,
    "critic_loss": 50.284217834472656,
    "ent_coef": 0.1032228097319603,
    "learning_rate": 0.001
  },
  {
    "episode": 584,
    "reward": 81.842004,
    "length": 82,
    "time": 12700.067958,
    "actor_loss": 29.274555206298828,
    "critic_loss": 14.52195930480957,
    "ent_coef": 0.10161279886960983,
    "learning_rate": 0.001
  },
  {
    "episode": 585,
    "reward": 59.841709,
    "length": 156,
    "time": 12725.423749,
    "actor_loss": 26.991714477539062,
    "critic_loss": 15.092798233032227,
    "ent_coef": 0.10115870088338852,
    "learning_rate": 0.001
  },
  {
    "episode": 586,
    "reward": 68.25761,
    "length": 101,
    "time": 12745.695314,
    "actor_loss": 23.704214096069336,
    "critic_loss": 13.781779289245605,
    "ent_coef": 0.1036151796579361,
    "learning_rate": 0.001
  },
  {
    "episode": 587,
    "reward": 75.098436,
    "length": 88,
    "time": 12760.285766,
    "actor_loss": 28.123708724975586,
    "critic_loss": 9.39748764038086,
    "ent_coef": 0.10238678008317947,
    "learning_rate": 0.001
  },
  {
    "episode": 588,
    "reward": 62.485558,
    "length": 107,
    "time": 12778.021364,
    "actor_loss": 23.65113067626953,
    "critic_loss": 30.652734756469727,
    "ent_coef": 0.104046531021595,
    "learning_rate": 0.001
  },
  {
    "episode": 589,
    "reward": 79.74366,
    "length": 83,
    "time": 12794.629675,
    "actor_loss": 24.37985610961914,
    "critic_loss": 169.34292602539062,
    "ent_coef": 0.10218122601509094,
    "learning_rate": 0.001
  },
  {
    "episode": 590,
    "reward": 71.942913,
    "length": 103,
    "time": 12810.75513,
    "actor_loss": 27.316322326660156,
    "critic_loss": 409.0984191894531,
    "ent_coef": 0.10702744871377945,
    "learning_rate": 0.001
  },
  {
    "episode": 591,
    "reward": 76.548978,
    "length": 85,
    "time": 12825.035913,
    "actor_loss": 29.527347564697266,
    "critic_loss": 28.10321044921875,
    "ent_coef": 0.106645368039608,
    "learning_rate": 0.001
  },
  {
    "episode": 592,
    "reward": 74.756283,
    "length": 86,
    "time": 12842.589941,
    "actor_loss": 24.43434715270996,
    "critic_loss": 36.4161262512207,
    "ent_coef": 0.10848144441843033,
    "learning_rate": 0.001
  },
  {
    "episode": 593,
    "reward": 73.641434,
    "length": 88,
    "time": 12858.123398,
    "actor_loss": 26.92422103881836,
    "critic_loss": 10.582642555236816,
    "ent_coef": 0.1106669157743454,
    "learning_rate": 0.001
  },
  {
    "episode": 594,
    "reward": -166.117605,
    "length": 140,
    "time": 12880.195699,
    "actor_loss": 22.968076705932617,
    "critic_loss": 47.287109375,
    "ent_coef": 0.11035317182540894,
    "learning_rate": 0.001
  },
  {
    "episode": 595,
    "reward": 71.727013,
    "length": 93,
    "time": 12895.903777,
    "actor_loss": 21.344511032104492,
    "critic_loss": 194.66490173339844,
    "ent_coef": 0.10992913693189621,
    "learning_rate": 0.001
  },
  {
    "episode": 596,
    "reward": 62.119458,
    "length": 117,
    "time": 12914.067974,
    "actor_loss": 21.58160400390625,
    "critic_loss": 122.36141967773438,
    "ent_coef": 0.10962250083684921,
    "learning_rate": 0.001
  },
  {
    "episode": 597,
    "reward": 74.688839,
    "length": 97,
    "time": 12933.482131,
    "actor_loss": 27.473649978637695,
    "critic_loss": 17.292266845703125,
    "ent_coef": 0.11825180798768997,
    "learning_rate": 0.001
  },
  {
    "episode": 598,
    "reward": 64.87488,
    "length": 99,
    "time": 12950.243559,
    "actor_loss": 28.397048950195312,
    "critic_loss": 172.61410522460938,
    "ent_coef": 0.11736961454153061,
    "learning_rate": 0.001
  },
  {
    "episode": 599,
    "reward": 47.472953,
    "length": 137,
    "time": 12972.25841,
    "actor_loss": 28.693450927734375,
    "critic_loss": 66.63410186767578,
    "ent_coef": 0.10653406381607056,
    "learning_rate": 0.001
  },
  {
    "episode": 600,
    "reward": -163.617838,
    "length": 127,
    "time": 12992.048924,
    "actor_loss": 23.070194244384766,
    "critic_loss": 200.3415069580078,
    "ent_coef": 0.10758411884307861,
    "learning_rate": 0.001
  },
  {
    "episode": 601,
    "reward": 77.622791,
    "length": 81,
    "time": 13006.491206,
    "actor_loss": 23.377059936523438,
    "critic_loss": 124.27305603027344,
    "ent_coef": 0.10916562378406525,
    "learning_rate": 0.001
  },
  {
    "episode": 602,
    "reward": 77.146743,
    "length": 86,
    "time": 13021.159079,
    "actor_loss": 24.027416229248047,
    "critic_loss": 72.8426284790039,
    "ent_coef": 0.1068357303738594,
    "learning_rate": 0.001
  },
  {
    "episode": 603,
    "reward": 74.945811,
    "length": 88,
    "time": 13036.536793,
    "actor_loss": 25.00351333618164,
    "critic_loss": 66.19268798828125,
    "ent_coef": 0.10612113028764725,
    "learning_rate": 0.001
  },
  {
    "episode": 604,
    "reward": 67.554388,
    "length": 94,
    "time": 13053.22252,
    "actor_loss": 24.432313919067383,
    "critic_loss": 118.35928344726562,
    "ent_coef": 0.10589369386434555,
    "learning_rate": 0.001
  },
  {
    "episode": 605,
    "reward": 78.378483,
    "length": 80,
    "time": 13068.565579,
    "actor_loss": 21.06916046142578,
    "critic_loss": 25.415203094482422,
    "ent_coef": 0.10829905420541763,
    "learning_rate": 0.001
  },
  {
    "episode": 606,
    "reward": 82.962894,
    "length": 74,
    "time": 13081.363285,
    "actor_loss": 24.746063232421875,
    "critic_loss": 254.8203887939453,
    "ent_coef": 0.11156981438398361,
    "learning_rate": 0.001
  },
  {
    "episode": 607,
    "reward": 74.292246,
    "length": 90,
    "time": 13096.58034,
    "actor_loss": 20.501028060913086,
    "critic_loss": 160.67489624023438,
    "ent_coef": 0.11164578795433044,
    "learning_rate": 0.001
  },
  {
    "episode": 608,
    "reward": -166.333891,
    "length": 145,
    "time": 13118.550134,
    "actor_loss": 21.449249267578125,
    "critic_loss": 40.46220016479492,
    "ent_coef": 0.11066634207963943,
    "learning_rate": 0.001
  },
  {
    "episode": 609,
    "reward": 79.454175,
    "length": 84,
    "time": 13133.271859,
    "actor_loss": 19.342620849609375,
    "critic_loss": 10.080665588378906,
    "ent_coef": 0.10771940648555756,
    "learning_rate": 0.001
  },
  {
    "episode": 610,
    "reward": 77.31469,
    "length": 88,
    "time": 13147.771622,
    "actor_loss": 23.02732276916504,
    "critic_loss": 78.73805236816406,
    "ent_coef": 0.1059826985001564,
    "learning_rate": 0.001
  },
  {
    "episode": 611,
    "reward": 65.513805,
    "length": 138,
    "time": 13169.649678,
    "actor_loss": 20.525527954101562,
    "critic_loss": 6.721886157989502,
    "ent_coef": 0.10767164826393127,
    "learning_rate": 0.001
  },
  {
    "episode": 612,
    "reward": 79.659517,
    "length": 83,
    "time": 13186.008826,
    "actor_loss": 24.97271728515625,
    "critic_loss": 20.111406326293945,
    "ent_coef": 0.11021292954683304,
    "learning_rate": 0.001
  },
  {
    "episode": 613,
    "reward": 82.175081,
    "length": 82,
    "time": 13199.51951,
    "actor_loss": 23.847633361816406,
    "critic_loss": 14.374786376953125,
    "ent_coef": 0.1090216115117073,
    "learning_rate": 0.001
  },
  {
    "episode": 614,
    "reward": 78.120947,
    "length": 83,
    "time": 13213.676524,
    "actor_loss": 21.93771743774414,
    "critic_loss": 6.359011650085449,
    "ent_coef": 0.110113225877285,
    "learning_rate": 0.001
  },
  {
    "episode": 615,
    "reward": 64.407407,
    "length": 99,
    "time": 13230.28511,
    "actor_loss": 23.116621017456055,
    "critic_loss": 365.60791015625,
    "ent_coef": 0.10722682625055313,
    "learning_rate": 0.001
  },
  {
    "episode": 616,
    "reward": 79.536242,
    "length": 92,
    "time": 13246.832295,
    "actor_loss": 25.951316833496094,
    "critic_loss": 8.408666610717773,
    "ent_coef": 0.10788914561271667,
    "learning_rate": 0.001
  },
  {
    "episode": 617,
    "reward": 84.279206,
    "length": 75,
    "time": 13261.515282,
    "actor_loss": 18.63544273376465,
    "critic_loss": 18.42224884033203,
    "ent_coef": 0.10683608055114746,
    "learning_rate": 0.001
  },
  {
    "episode": 618,
    "reward": 70.210652,
    "length": 147,
    "time": 13285.966487,
    "actor_loss": 21.572589874267578,
    "critic_loss": 138.49124145507812,
    "ent_coef": 0.10162694752216339,
    "learning_rate": 0.001
  },
  {
    "episode": 619,
    "reward": -189.250476,
    "length": 201,
    "time": 13314.678001,
    "actor_loss": 24.83342170715332,
    "critic_loss": 30.14626693725586,
    "ent_coef": 0.10409856587648392,
    "learning_rate": 0.001
  },
  {
    "episode": 620,
    "reward": 65.050241,
    "length": 102,
    "time": 13332.055072,
    "actor_loss": 15.755993843078613,
    "critic_loss": 12.425485610961914,
    "ent_coef": 0.10468032956123352,
    "learning_rate": 0.001
  },
  {
    "episode": 621,
    "reward": 77.645068,
    "length": 79,
    "time": 13345.747396,
    "actor_loss": 23.570466995239258,
    "critic_loss": 7.457226276397705,
    "ent_coef": 0.10721393674612045,
    "learning_rate": 0.001
  },
  {
    "episode": 622,
    "reward": 80.628309,
    "length": 77,
    "time": 13358.677101,
    "actor_loss": 23.292957305908203,
    "critic_loss": 344.2173156738281,
    "ent_coef": 0.11119005084037781,
    "learning_rate": 0.001
  },
  {
    "episode": 623,
    "reward": -163.57054,
    "length": 138,
    "time": 13380.730501,
    "actor_loss": 20.97287940979004,
    "critic_loss": 8.876907348632812,
    "ent_coef": 0.1127881184220314,
    "learning_rate": 0.001
  },
  {
    "episode": 624,
    "reward": 75.775012,
    "length": 87,
    "time": 13397.991662,
    "actor_loss": 17.931760787963867,
    "critic_loss": 14.073020935058594,
    "ent_coef": 0.11074650287628174,
    "learning_rate": 0.001
  },
  {
    "episode": 625,
    "reward": 76.534034,
    "length": 104,
    "time": 13414.422557,
    "actor_loss": 24.24362564086914,
    "critic_loss": 178.37936401367188,
    "ent_coef": 0.11238276213407516,
    "learning_rate": 0.001
  },
  {
    "episode": 626,
    "reward": 71.447096,
    "length": 90,
    "time": 13431.19094,
    "actor_loss": 20.78217315673828,
    "critic_loss": 179.79055786132812,
    "ent_coef": 0.1180083230137825,
    "learning_rate": 0.001
  },
  {
    "episode": 627,
    "reward": 69.073633,
    "length": 104,
    "time": 13449.222405,
    "actor_loss": 15.935809135437012,
    "critic_loss": 62.35337829589844,
    "ent_coef": 0.12080961465835571,
    "learning_rate": 0.001
  },
  {
    "episode": 628,
    "reward": 71.721725,
    "length": 91,
    "time": 13464.238411,
    "actor_loss": 21.765748977661133,
    "critic_loss": 147.27529907226562,
    "ent_coef": 0.12430094182491302,
    "learning_rate": 0.001
  },
  {
    "episode": 629,
    "reward": 44.866207,
    "length": 513,
    "time": 13536.648977,
    "actor_loss": 21.085586547851562,
    "critic_loss": 57.77613067626953,
    "ent_coef": 0.12553420662879944,
    "learning_rate": 0.001
  },
  {
    "episode": 630,
    "reward": 66.956728,
    "length": 118,
    "time": 13556.160411,
    "actor_loss": 22.517322540283203,
    "critic_loss": 10.658487319946289,
    "ent_coef": 0.12166925519704819,
    "learning_rate": 0.001
  },
  {
    "episode": 631,
    "reward": 70.72501,
    "length": 90,
    "time": 13575.386487,
    "actor_loss": 24.807209014892578,
    "critic_loss": 9.370687484741211,
    "ent_coef": 0.11958674341440201,
    "learning_rate": 0.001
  },
  {
    "episode": 632,
    "reward": 70.621864,
    "length": 97,
    "time": 13591.721911,
    "actor_loss": 20.915193557739258,
    "critic_loss": 26.27029800415039,
    "ent_coef": 0.11679749935865402,
    "learning_rate": 0.001
  },
  {
    "episode": 633,
    "reward": 68.75649,
    "length": 112,
    "time": 13609.362212,
    "actor_loss": 19.699844360351562,
    "critic_loss": 20.220916748046875,
    "ent_coef": 0.11485977470874786,
    "learning_rate": 0.001
  },
  {
    "episode": 634,
    "reward": -58.297261,
    "length": 268,
    "time": 13647.229374,
    "actor_loss": 18.004697799682617,
    "critic_loss": 281.44146728515625,
    "ent_coef": 0.11088200658559799,
    "learning_rate": 0.001
  },
  {
    "episode": 635,
    "reward": 67.733715,
    "length": 96,
    "time": 13663.393412,
    "actor_loss": 22.01103973388672,
    "critic_loss": 23.070362091064453,
    "ent_coef": 0.10942772775888443,
    "learning_rate": 0.001
  },
  {
    "episode": 636,
    "reward": 74.973063,
    "length": 84,
    "time": 13678.255895,
    "actor_loss": 26.16766357421875,
    "critic_loss": 47.336910247802734,
    "ent_coef": 0.10407032817602158,
    "learning_rate": 0.001
  },
  {
    "episode": 637,
    "reward": 76.488132,
    "length": 84,
    "time": 13694.386629,
    "actor_loss": 20.53558349609375,
    "critic_loss": 5.532687187194824,
    "ent_coef": 0.10574600100517273,
    "learning_rate": 0.001
  },
  {
    "episode": 638,
    "reward": 76.439402,
    "length": 96,
    "time": 13712.235335,
    "actor_loss": 21.433698654174805,
    "critic_loss": 7.521964073181152,
    "ent_coef": 0.10682571679353714,
    "learning_rate": 0.001
  },
  {
    "episode": 639,
    "reward": -171.589363,
    "length": 223,
    "time": 13744.312135,
    "actor_loss": 25.15192985534668,
    "critic_loss": 8.835226058959961,
    "ent_coef": 0.11032894253730774,
    "learning_rate": 0.001
  },
  {
    "episode": 640,
    "reward": 78.95834,
    "length": 77,
    "time": 13757.846555,
    "actor_loss": 25.256938934326172,
    "critic_loss": 60.52484130859375,
    "ent_coef": 0.10985098034143448,
    "learning_rate": 0.001
  },
  {
    "episode": 641,
    "reward": 68.205914,
    "length": 100,
    "time": 13776.599098,
    "actor_loss": 19.81443214416504,
    "critic_loss": 10.799516677856445,
    "ent_coef": 0.1066829040646553,
    "learning_rate": 0.001
  },
  {
    "episode": 642,
    "reward": 70.435974,
    "length": 99,
    "time": 13792.323261,
    "actor_loss": 17.11996078491211,
    "critic_loss": 33.8066520690918,
    "ent_coef": 0.11002276837825775,
    "learning_rate": 0.001
  },
  {
    "episode": 643,
    "reward": 65.431585,
    "length": 100,
    "time": 13808.993144,
    "actor_loss": 16.67200469970703,
    "critic_loss": 159.875,
    "ent_coef": 0.1110236644744873,
    "learning_rate": 0.001
  },
  {
    "episode": 644,
    "reward": 67.155621,
    "length": 97,
    "time": 13825.164993,
    "actor_loss": 20.953933715820312,
    "critic_loss": 62.9789924621582,
    "ent_coef": 0.10930676013231277,
    "learning_rate": 0.001
  },
  {
    "episode": 645,
    "reward": 72.647728,
    "length": 94,
    "time": 13842.960245,
    "actor_loss": 23.329750061035156,
    "critic_loss": 47.30284881591797,
    "ent_coef": 0.11169096827507019,
    "learning_rate": 0.001
  },
  {
    "episode": 646,
    "reward": 66.544235,
    "length": 94,
    "time": 13861.157696,
    "actor_loss": 16.60995101928711,
    "critic_loss": 4.984540939331055,
    "ent_coef": 0.11269868165254593,
    "learning_rate": 0.001
  },
  {
    "episode": 647,
    "reward": 71.822206,
    "length": 89,
    "time": 13877.463908,
    "actor_loss": 22.074127197265625,
    "critic_loss": 71.22914123535156,
    "ent_coef": 0.11615626513957977,
    "learning_rate": 0.001
  },
  {
    "episode": 648,
    "reward": -173.55055,
    "length": 188,
    "time": 13907.11664,
    "actor_loss": 21.368972778320312,
    "critic_loss": 78.97527313232422,
    "ent_coef": 0.11042388528585434,
    "learning_rate": 0.001
  },
  {
    "episode": 649,
    "reward": 80.042575,
    "length": 85,
    "time": 13920.96832,
    "actor_loss": 16.005701065063477,
    "critic_loss": 181.33192443847656,
    "ent_coef": 0.11014887690544128,
    "learning_rate": 0.001
  },
  {
    "episode": 650,
    "reward": 61.613352,
    "length": 179,
    "time": 13949.92727,
    "actor_loss": 17.00263214111328,
    "critic_loss": 408.89813232421875,
    "ent_coef": 0.11429943889379501,
    "learning_rate": 0.001
  },
  {
    "episode": 651,
    "reward": 62.811724,
    "length": 98,
    "time": 13965.767955,
    "actor_loss": 17.665267944335938,
    "critic_loss": 16.14849853515625,
    "ent_coef": 0.11652480810880661,
    "learning_rate": 0.001
  },
  {
    "episode": 652,
    "reward": -179.317787,
    "length": 165,
    "time": 13990.135398,
    "actor_loss": 21.25296401977539,
    "critic_loss": 142.64553833007812,
    "ent_coef": 0.11865617334842682,
    "learning_rate": 0.001
  },
  {
    "episode": 653,
    "reward": -170.31326,
    "length": 157,
    "time": 14016.105099,
    "actor_loss": 14.008604049682617,
    "critic_loss": 178.05409240722656,
    "ent_coef": 0.12342666834592819,
    "learning_rate": 0.001
  },
  {
    "episode": 654,
    "reward": 79.70165,
    "length": 81,
    "time": 14031.374437,
    "actor_loss": 18.649673461914062,
    "critic_loss": 18.15252685546875,
    "ent_coef": 0.12234164029359818,
    "learning_rate": 0.001
  },
  {
    "episode": 655,
    "reward": 66.173518,
    "length": 108,
    "time": 14048.498436,
    "actor_loss": 18.016952514648438,
    "critic_loss": 35.86872100830078,
    "ent_coef": 0.117062509059906,
    "learning_rate": 0.001
  },
  {
    "episode": 656,
    "reward": 80.168373,
    "length": 79,
    "time": 14064.624406,
    "actor_loss": 21.89324188232422,
    "critic_loss": 23.001487731933594,
    "ent_coef": 0.12089308351278305,
    "learning_rate": 0.001
  },
  {
    "episode": 657,
    "reward": 76.257118,
    "length": 111,
    "time": 14085.11236,
    "actor_loss": 17.980358123779297,
    "critic_loss": 227.02252197265625,
    "ent_coef": 0.12181903421878815,
    "learning_rate": 0.001
  },
  {
    "episode": 658,
    "reward": 66.953634,
    "length": 96,
    "time": 14101.428231,
    "actor_loss": 18.979991912841797,
    "critic_loss": 45.475547790527344,
    "ent_coef": 0.11982174962759018,
    "learning_rate": 0.001
  },
  {
    "episode": 659,
    "reward": 65.364816,
    "length": 116,
    "time": 14119.930783,
    "actor_loss": 24.01785659790039,
    "critic_loss": 13.816802978515625,
    "ent_coef": 0.12335612624883652,
    "learning_rate": 0.001
  },
  {
    "episode": 660,
    "reward": 72.703983,
    "length": 87,
    "time": 14134.220849,
    "actor_loss": 14.94921875,
    "critic_loss": 117.50212097167969,
    "ent_coef": 0.12531740963459015,
    "learning_rate": 0.001
  },
  {
    "episode": 661,
    "reward": 79.786892,
    "length": 75,
    "time": 14147.838985,
    "actor_loss": 11.77070140838623,
    "critic_loss": 13.257549285888672,
    "ent_coef": 0.1300562173128128,
    "learning_rate": 0.001
  },
  {
    "episode": 662,
    "reward": -173.956181,
    "length": 152,
    "time": 14170.404428,
    "actor_loss": 17.283493041992188,
    "critic_loss": 14.394372940063477,
    "ent_coef": 0.12860459089279175,
    "learning_rate": 0.001
  },
  {
    "episode": 663,
    "reward": 65.763738,
    "length": 95,
    "time": 14188.118998,
    "actor_loss": 22.118587493896484,
    "critic_loss": 72.12928009033203,
    "ent_coef": 0.12487766146659851,
    "learning_rate": 0.001
  },
  {
    "episode": 664,
    "reward": 72.181205,
    "length": 96,
    "time": 14203.704486,
    "actor_loss": 22.20248794555664,
    "critic_loss": 50.44074249267578,
    "ent_coef": 0.12853176891803741,
    "learning_rate": 0.001
  },
  {
    "episode": 665,
    "reward": 74.608762,
    "length": 87,
    "time": 14219.917066,
    "actor_loss": 20.588857650756836,
    "critic_loss": 201.18992614746094,
    "ent_coef": 0.1272304803133011,
    "learning_rate": 0.001
  },
  {
    "episode": 666,
    "reward": 70.844365,
    "length": 93,
    "time": 14235.842963,
    "actor_loss": 18.295568466186523,
    "critic_loss": 121.80989074707031,
    "ent_coef": 0.12876486778259277,
    "learning_rate": 0.001
  },
  {
    "episode": 667,
    "reward": 67.189366,
    "length": 183,
    "time": 14263.517635,
    "actor_loss": 11.770090103149414,
    "critic_loss": 104.26476287841797,
    "ent_coef": 0.1392696499824524,
    "learning_rate": 0.001
  },
  {
    "episode": 668,
    "reward": 37.87798,
    "length": 447,
    "time": 14326.300515,
    "actor_loss": 17.514312744140625,
    "critic_loss": 58.56593704223633,
    "ent_coef": 0.1313851922750473,
    "learning_rate": 0.001
  },
  {
    "episode": 669,
    "reward": 73.084725,
    "length": 86,
    "time": 14340.303668,
    "actor_loss": 18.95693588256836,
    "critic_loss": 55.340789794921875,
    "ent_coef": 0.1315862387418747,
    "learning_rate": 0.001
  },
  {
    "episode": 670,
    "reward": 71.267837,
    "length": 89,
    "time": 14355.081247,
    "actor_loss": 14.872183799743652,
    "critic_loss": 300.03436279296875,
    "ent_coef": 0.12935686111450195,
    "learning_rate": 0.001
  },
  {
    "episode": 671,
    "reward": 68.027431,
    "length": 99,
    "time": 14374.646059,
    "actor_loss": 14.932398796081543,
    "critic_loss": 8.732955932617188,
    "ent_coef": 0.12397360801696777,
    "learning_rate": 0.001
  },
  {
    "episode": 672,
    "reward": -193.584777,
    "length": 184,
    "time": 14403.655929,
    "actor_loss": 13.122998237609863,
    "critic_loss": 35.736183166503906,
    "ent_coef": 0.11427998542785645,
    "learning_rate": 0.001
  },
  {
    "episode": 673,
    "reward": -170.093169,
    "length": 143,
    "time": 14425.026592,
    "actor_loss": 17.299678802490234,
    "critic_loss": 338.3930969238281,
    "ent_coef": 0.10934390127658844,
    "learning_rate": 0.001
  },
  {
    "episode": 674,
    "reward": -171.60066,
    "length": 147,
    "time": 14449.682642,
    "actor_loss": 22.134593963623047,
    "critic_loss": 15.12639045715332,
    "ent_coef": 0.10761760175228119,
    "learning_rate": 0.001
  },
  {
    "episode": 675,
    "reward": 70.056143,
    "length": 93,
    "time": 14465.548818,
    "actor_loss": 22.399105072021484,
    "critic_loss": 30.387592315673828,
    "ent_coef": 0.10603754222393036,
    "learning_rate": 0.001
  },
  {
    "episode": 676,
    "reward": 54.288692,
    "length": 121,
    "time": 14488.520633,
    "actor_loss": 17.03240203857422,
    "critic_loss": 34.1859130859375,
    "ent_coef": 0.09943020343780518,
    "learning_rate": 0.001
  },
  {
    "episode": 677,
    "reward": 56.965714,
    "length": 118,
    "time": 14508.159632,
    "actor_loss": 16.462448120117188,
    "critic_loss": 7.368070125579834,
    "ent_coef": 0.10071700066328049,
    "learning_rate": 0.001
  },
  {
    "episode": 678,
    "reward": 74.606305,
    "length": 86,
    "time": 14522.209226,
    "actor_loss": 24.870405197143555,
    "critic_loss": 14.902555465698242,
    "ent_coef": 0.10573720186948776,
    "learning_rate": 0.001
  },
  {
    "episode": 679,
    "reward": -166.007571,
    "length": 585,
    "time": 14602.274502,
    "actor_loss": 12.728500366210938,
    "critic_loss": 36.112396240234375,
    "ent_coef": 0.1123603954911232,
    "learning_rate": 0.001
  },
  {
    "episode": 680,
    "reward": -108.819016,
    "length": 601,
    "time": 14682.33739,
    "actor_loss": 16.60224151611328,
    "critic_loss": 9.217521667480469,
    "ent_coef": 0.116295725107193,
    "learning_rate": 0.001
  },
  {
    "episode": 681,
    "reward": -446.718102,
    "length": 548,
    "time": 14759.48281,
    "actor_loss": 15.316486358642578,
    "critic_loss": 143.83050537109375,
    "ent_coef": 0.10857480019330978,
    "learning_rate": 0.001
  },
  {
    "episode": 682,
    "reward": 82.889807,
    "length": 81,
    "time": 14772.88554,
    "actor_loss": 14.270071029663086,
    "critic_loss": 17.10228729248047,
    "ent_coef": 0.10885725170373917,
    "learning_rate": 0.001
  },
  {
    "episode": 683,
    "reward": 69.08773,
    "length": 101,
    "time": 14791.710909,
    "actor_loss": 14.322059631347656,
    "critic_loss": 149.79400634765625,
    "ent_coef": 0.10752927511930466,
    "learning_rate": 0.001
  },
  {
    "episode": 684,
    "reward": -184.084114,
    "length": 168,
    "time": 14818.301182,
    "actor_loss": 19.07614517211914,
    "critic_loss": 16.488908767700195,
    "ent_coef": 0.10722669959068298,
    "learning_rate": 0.001
  },
  {
    "episode": 685,
    "reward": 67.81664,
    "length": 100,
    "time": 14835.158873,
    "actor_loss": 18.732351303100586,
    "critic_loss": 846.6270751953125,
    "ent_coef": 0.11251068115234375,
    "learning_rate": 0.001
  },
  {
    "episode": 686,
    "reward": 63.422139,
    "length": 126,
    "time": 14857.808727,
    "actor_loss": 10.939848899841309,
    "critic_loss": 16.806814193725586,
    "ent_coef": 0.11887189745903015,
    "learning_rate": 0.001
  },
  {
    "episode": 687,
    "reward": -169.593573,
    "length": 162,
    "time": 14882.675234,
    "actor_loss": 11.048277854919434,
    "critic_loss": 64.33285522460938,
    "ent_coef": 0.1172717735171318,
    "learning_rate": 0.001
  },
  {
    "episode": 688,
    "reward": -108.714179,
    "length": 585,
    "time": 14962.719357,
    "actor_loss": 7.829339027404785,
    "critic_loss": 58.53608322143555,
    "ent_coef": 0.10469240695238113,
    "learning_rate": 0.001
  },
  {
    "episode": 689,
    "reward": 73.302521,
    "length": 93,
    "time": 14979.690091,
    "actor_loss": 16.98701286315918,
    "critic_loss": 17.760026931762695,
    "ent_coef": 0.10486358404159546,
    "learning_rate": 0.001
  },
  {
    "episode": 690,
    "reward": -188.584567,
    "length": 159,
    "time": 15003.585312,
    "actor_loss": 10.66833782196045,
    "critic_loss": 133.97335815429688,
    "ent_coef": 0.10420362651348114,
    "learning_rate": 0.001
  },
  {
    "episode": 691,
    "reward": -97.688331,
    "length": 599,
    "time": 15083.69475,
    "actor_loss": 19.753751754760742,
    "critic_loss": 56.086936950683594,
    "ent_coef": 0.11388689279556274,
    "learning_rate": 0.001
  },
  {
    "episode": 692,
    "reward": -421.982571,
    "length": 583,
    "time": 15163.82026,
    "actor_loss": 16.348541259765625,
    "critic_loss": 114.13328552246094,
    "ent_coef": 0.10654541850090027,
    "learning_rate": 0.001
  },
  {
    "episode": 693,
    "reward": -235.986709,
    "length": 242,
    "time": 15198.87276,
    "actor_loss": 17.798809051513672,
    "critic_loss": 53.06315612792969,
    "ent_coef": 0.10453367978334427,
    "learning_rate": 0.001
  },
  {
    "episode": 694,
    "reward": -23.531988,
    "length": 244,
    "time": 15235.156256,
    "actor_loss": 18.992050170898438,
    "critic_loss": 43.323638916015625,
    "ent_coef": 0.09914874285459518,
    "learning_rate": 0.001
  },
  {
    "episode": 695,
    "reward": 1.160569,
    "length": 205,
    "time": 15265.557207,
    "actor_loss": 11.55931282043457,
    "critic_loss": 74.38125610351562,
    "ent_coef": 0.10117878764867783,
    "learning_rate": 0.001
  },
  {
    "episode": 696,
    "reward": 75.930779,
    "length": 85,
    "time": 15279.955785,
    "actor_loss": 10.020174026489258,
    "critic_loss": 52.27178955078125,
    "ent_coef": 0.10673511028289795,
    "learning_rate": 0.001
  },
  {
    "episode": 697,
    "reward": 40.393466,
    "length": 148,
    "time": 15303.100863,
    "actor_loss": 16.110336303710938,
    "critic_loss": 24.55429458618164,
    "ent_coef": 0.10992758721113205,
    "learning_rate": 0.001
  },
  {
    "episode": 698,
    "reward": -151.344553,
    "length": 425,
    "time": 15361.901242,
    "actor_loss": 15.669927597045898,
    "critic_loss": 21.565059661865234,
    "ent_coef": 0.11113209277391434,
    "learning_rate": 0.001
  },
  {
    "episode": 699,
    "reward": -101.998491,
    "length": 340,
    "time": 15410.188061,
    "actor_loss": 15.012678146362305,
    "critic_loss": 173.2403106689453,
    "ent_coef": 0.10187523812055588,
    "learning_rate": 0.001
  },
  {
    "episode": 700,
    "reward": 80.546015,
    "length": 80,
    "time": 15425.593639,
    "actor_loss": 18.37542724609375,
    "critic_loss": 11.644481658935547,
    "ent_coef": 0.10381656140089035,
    "learning_rate": 0.001
  },
  {
    "episode": 701,
    "reward": 68.613872,
    "length": 104,
    "time": 15444.530027,
    "actor_loss": 11.006311416625977,
    "critic_loss": 19.91550064086914,
    "ent_coef": 0.10680363327264786,
    "learning_rate": 0.001
  },
  {
    "episode": 702,
    "reward": 75.084348,
    "length": 91,
    "time": 15459.238776,
    "actor_loss": 16.72588348388672,
    "critic_loss": 111.63050842285156,
    "ent_coef": 0.11176097393035889,
    "learning_rate": 0.001
  },
  {
    "episode": 703,
    "reward": 74.337242,
    "length": 94,
    "time": 15474.803973,
    "actor_loss": 4.7801642417907715,
    "critic_loss": 7.815829753875732,
    "ent_coef": 0.11169080436229706,
    "learning_rate": 0.001
  },
  {
    "episode": 704,
    "reward": 76.465088,
    "length": 87,
    "time": 15489.35283,
    "actor_loss": 15.049300193786621,
    "critic_loss": 10.263986587524414,
    "ent_coef": 0.1127595379948616,
    "learning_rate": 0.001
  },
  {
    "episode": 705,
    "reward": 80.266244,
    "length": 81,
    "time": 15504.917036,
    "actor_loss": 14.276902198791504,
    "critic_loss": 32.7480583190918,
    "ent_coef": 0.11522888392210007,
    "learning_rate": 0.001
  },
  {
    "episode": 706,
    "reward": 72.082248,
    "length": 91,
    "time": 15521.324966,
    "actor_loss": 19.589637756347656,
    "critic_loss": 36.42389678955078,
    "ent_coef": 0.11449813097715378,
    "learning_rate": 0.001
  },
  {
    "episode": 707,
    "reward": -170.804393,
    "length": 143,
    "time": 15544.333307,
    "actor_loss": 9.970603942871094,
    "critic_loss": 272.746337890625,
    "ent_coef": 0.11611901968717575,
    "learning_rate": 0.001
  },
  {
    "episode": 708,
    "reward": -167.469924,
    "length": 141,
    "time": 15568.374799,
    "actor_loss": 19.229171752929688,
    "critic_loss": 35.180049896240234,
    "ent_coef": 0.11511627584695816,
    "learning_rate": 0.001
  },
  {
    "episode": 709,
    "reward": 55.359567,
    "length": 118,
    "time": 15586.466466,
    "actor_loss": 9.24403190612793,
    "critic_loss": 36.84862518310547,
    "ent_coef": 0.11165888607501984,
    "learning_rate": 0.001
  },
  {
    "episode": 710,
    "reward": -168.399373,
    "length": 144,
    "time": 15608.132284,
    "actor_loss": 17.41946029663086,
    "critic_loss": 210.2173309326172,
    "ent_coef": 0.1140667051076889,
    "learning_rate": 0.001
  },
  {
    "episode": 711,
    "reward": 58.959687,
    "length": 119,
    "time": 15631.15168,
    "actor_loss": 14.750141143798828,
    "critic_loss": 8.298044204711914,
    "ent_coef": 0.11344335228204727,
    "learning_rate": 0.001
  },
  {
    "episode": 712,
    "reward": 72.777267,
    "length": 91,
    "time": 15646.087885,
    "actor_loss": 16.38005256652832,
    "critic_loss": 10.081034660339355,
    "ent_coef": 0.11389583349227905,
    "learning_rate": 0.001
  },
  {
    "episode": 713,
    "reward": 78.819493,
    "length": 86,
    "time": 15662.3378,
    "actor_loss": 10.68094253540039,
    "critic_loss": 138.25146484375,
    "ent_coef": 0.11290905624628067,
    "learning_rate": 0.001
  },
  {
    "episode": 714,
    "reward": 73.768614,
    "length": 91,
    "time": 15676.998663,
    "actor_loss": 13.91380500793457,
    "critic_loss": 4.488117218017578,
    "ent_coef": 0.1129123866558075,
    "learning_rate": 0.001
  },
  {
    "episode": 715,
    "reward": 71.783204,
    "length": 96,
    "time": 15697.072459,
    "actor_loss": 14.83645248413086,
    "critic_loss": 86.37028503417969,
    "ent_coef": 0.10830847918987274,
    "learning_rate": 0.001
  },
  {
    "episode": 716,
    "reward": 66.031366,
    "length": 116,
    "time": 15716.001492,
    "actor_loss": 9.3689546585083,
    "critic_loss": 129.04867553710938,
    "ent_coef": 0.10958829522132874,
    "learning_rate": 0.001
  },
  {
    "episode": 717,
    "reward": 71.212135,
    "length": 100,
    "time": 15731.836542,
    "actor_loss": 9.247489929199219,
    "critic_loss": 57.6171875,
    "ent_coef": 0.10661796480417252,
    "learning_rate": 0.001
  },
  {
    "episode": 718,
    "reward": 74.341877,
    "length": 85,
    "time": 15746.606426,
    "actor_loss": 10.95456314086914,
    "critic_loss": 113.74006652832031,
    "ent_coef": 0.10995068401098251,
    "learning_rate": 0.001
  },
  {
    "episode": 719,
    "reward": 76.179164,
    "length": 90,
    "time": 15763.959444,
    "actor_loss": 13.813186645507812,
    "critic_loss": 415.457763671875,
    "ent_coef": 0.1124521866440773,
    "learning_rate": 0.001
  },
  {
    "episode": 720,
    "reward": 77.344547,
    "length": 91,
    "time": 15780.008886,
    "actor_loss": 13.402748107910156,
    "critic_loss": 187.45785522460938,
    "ent_coef": 0.11065910756587982,
    "learning_rate": 0.001
  },
  {
    "episode": 721,
    "reward": 78.428582,
    "length": 86,
    "time": 15796.116202,
    "actor_loss": 17.785274505615234,
    "critic_loss": 12.571456909179688,
    "ent_coef": 0.11223653703927994,
    "learning_rate": 0.001
  },
  {
    "episode": 722,
    "reward": 81.926656,
    "length": 82,
    "time": 15809.836885,
    "actor_loss": 12.591044425964355,
    "critic_loss": 33.040008544921875,
    "ent_coef": 0.10993673652410507,
    "learning_rate": 0.001
  },
  {
    "episode": 723,
    "reward": 60.670273,
    "length": 118,
    "time": 15831.9901,
    "actor_loss": 12.05622673034668,
    "critic_loss": 119.36793518066406,
    "ent_coef": 0.10586610436439514,
    "learning_rate": 0.001
  },
  {
    "episode": 724,
    "reward": 68.355285,
    "length": 101,
    "time": 15851.006479,
    "actor_loss": 11.859151840209961,
    "critic_loss": 16.657222747802734,
    "ent_coef": 0.1134420856833458,
    "learning_rate": 0.001
  },
  {
    "episode": 725,
    "reward": 76.514404,
    "length": 88,
    "time": 15865.293652,
    "actor_loss": 13.243512153625488,
    "critic_loss": 9.845819473266602,
    "ent_coef": 0.11488275229930878,
    "learning_rate": 0.001
  },
  {
    "episode": 726,
    "reward": 49.893816,
    "length": 223,
    "time": 15899.728606,
    "actor_loss": 13.176584243774414,
    "critic_loss": 87.43948364257812,
    "ent_coef": 0.10706616193056107,
    "learning_rate": 0.001
  },
  {
    "episode": 727,
    "reward": 61.00469,
    "length": 120,
    "time": 15918.389882,
    "actor_loss": 16.082130432128906,
    "critic_loss": 59.029449462890625,
    "ent_coef": 0.10201715677976608,
    "learning_rate": 0.001
  },
  {
    "episode": 728,
    "reward": 75.088417,
    "length": 96,
    "time": 15933.81637,
    "actor_loss": 6.472860336303711,
    "critic_loss": 170.97109985351562,
    "ent_coef": 0.10211152583360672,
    "learning_rate": 0.001
  },
  {
    "episode": 729,
    "reward": 48.9343,
    "length": 133,
    "time": 15954.053157,
    "actor_loss": 13.42071533203125,
    "critic_loss": 16.004545211791992,
    "ent_coef": 0.10232025384902954,
    "learning_rate": 0.001
  },
  {
    "episode": 730,
    "reward": 76.241662,
    "length": 90,
    "time": 15969.477998,
    "actor_loss": 13.07699966430664,
    "critic_loss": 32.13420104980469,
    "ent_coef": 0.10420548915863037,
    "learning_rate": 0.001
  },
  {
    "episode": 731,
    "reward": 73.100148,
    "length": 95,
    "time": 15984.840055,
    "actor_loss": 13.977043151855469,
    "critic_loss": 108.62300109863281,
    "ent_coef": 0.10393746197223663,
    "learning_rate": 0.001
  },
  {
    "episode": 732,
    "reward": -171.018519,
    "length": 156,
    "time": 16009.073459,
    "actor_loss": 6.552743434906006,
    "critic_loss": 330.8238220214844,
    "ent_coef": 0.10451992601156235,
    "learning_rate": 0.001
  },
  {
    "episode": 733,
    "reward": 69.906657,
    "length": 97,
    "time": 16026.486853,
    "actor_loss": 4.122866153717041,
    "critic_loss": 107.01280212402344,
    "ent_coef": 0.10622008144855499,
    "learning_rate": 0.001
  },
  {
    "episode": 734,
    "reward": 38.226271,
    "length": 158,
    "time": 16050.868843,
    "actor_loss": 11.653613090515137,
    "critic_loss": 69.76988220214844,
    "ent_coef": 0.10165130347013474,
    "learning_rate": 0.001
  },
  {
    "episode": 735,
    "reward": 69.891808,
    "length": 100,
    "time": 16068.749538,
    "actor_loss": 13.280693054199219,
    "critic_loss": 28.19235610961914,
    "ent_coef": 0.09602673351764679,
    "learning_rate": 0.001
  },
  {
    "episode": 736,
    "reward": 68.827891,
    "length": 104,
    "time": 16086.470299,
    "actor_loss": 11.777284622192383,
    "critic_loss": 249.2145538330078,
    "ent_coef": 0.09886550158262253,
    "learning_rate": 0.001
  },
  {
    "episode": 737,
    "reward": 75.421091,
    "length": 89,
    "time": 16102.867302,
    "actor_loss": 15.629776954650879,
    "critic_loss": 62.443572998046875,
    "ent_coef": 0.10317426174879074,
    "learning_rate": 0.001
  },
  {
    "episode": 738,
    "reward": 67.609008,
    "length": 98,
    "time": 16118.57254,
    "actor_loss": 12.765678405761719,
    "critic_loss": 103.76176452636719,
    "ent_coef": 0.10690320283174515,
    "learning_rate": 0.001
  },
  {
    "episode": 739,
    "reward": 75.279611,
    "length": 95,
    "time": 16135.084603,
    "actor_loss": 12.50023078918457,
    "critic_loss": 157.49659729003906,
    "ent_coef": 0.1046203225851059,
    "learning_rate": 0.001
  },
  {
    "episode": 740,
    "reward": 77.749304,
    "length": 85,
    "time": 16155.016291,
    "actor_loss": 7.782257080078125,
    "critic_loss": 6.270805358886719,
    "ent_coef": 0.10307824611663818,
    "learning_rate": 0.001
  },
  {
    "episode": 741,
    "reward": -175.684596,
    "length": 150,
    "time": 16179.818437,
    "actor_loss": 12.106704711914062,
    "critic_loss": 12.830283164978027,
    "ent_coef": 0.11039261519908905,
    "learning_rate": 0.001
  },
  {
    "episode": 742,
    "reward": -0.113531,
    "length": 204,
    "time": 16209.351857,
    "actor_loss": 14.950043678283691,
    "critic_loss": 21.306421279907227,
    "ent_coef": 0.11638495326042175,
    "learning_rate": 0.001
  },
  {
    "episode": 743,
    "reward": 73.339616,
    "length": 88,
    "time": 16227.782871,
    "actor_loss": 9.632104873657227,
    "critic_loss": 38.15497970581055,
    "ent_coef": 0.1142791137099266,
    "learning_rate": 0.001
  },
  {
    "episode": 744,
    "reward": 77.91666,
    "length": 86,
    "time": 16241.845447,
    "actor_loss": 15.727614402770996,
    "critic_loss": 144.95880126953125,
    "ent_coef": 0.11149102449417114,
    "learning_rate": 0.001
  },
  {
    "episode": 745,
    "reward": 48.549385,
    "length": 134,
    "time": 16263.576278,
    "actor_loss": 10.516441345214844,
    "critic_loss": 23.519573211669922,
    "ent_coef": 0.10730866342782974,
    "learning_rate": 0.001
  },
  {
    "episode": 746,
    "reward": 20.340461,
    "length": 177,
    "time": 16290.423409,
    "actor_loss": 5.559577941894531,
    "critic_loss": 30.8616886138916,
    "ent_coef": 0.10472451895475388,
    "learning_rate": 0.001
  },
  {
    "episode": 747,
    "reward": 76.224585,
    "length": 91,
    "time": 16309.082006,
    "actor_loss": 10.418242454528809,
    "critic_loss": 328.9964599609375,
    "ent_coef": 0.10108981281518936,
    "learning_rate": 0.001
  },
  {
    "episode": 748,
    "reward": -3.699782,
    "length": 218,
    "time": 16341.212018,
    "actor_loss": 9.760270118713379,
    "critic_loss": 132.03683471679688,
    "ent_coef": 0.10311669111251831,
    "learning_rate": 0.001
  },
  {
    "episode": 749,
    "reward": 70.761117,
    "length": 93,
    "time": 16357.226081,
    "actor_loss": 4.1006011962890625,
    "critic_loss": 22.489532470703125,
    "ent_coef": 0.10346861183643341,
    "learning_rate": 0.001
  },
  {
    "episode": 750,
    "reward": 64.103357,
    "length": 114,
    "time": 16376.078698,
    "actor_loss": 9.557184219360352,
    "critic_loss": 40.19340515136719,
    "ent_coef": 0.10088221728801727,
    "learning_rate": 0.001
  },
  {
    "episode": 751,
    "reward": 55.793755,
    "length": 118,
    "time": 16396.436265,
    "actor_loss": 12.536676406860352,
    "critic_loss": 18.744659423828125,
    "ent_coef": 0.10385467857122421,
    "learning_rate": 0.001
  },
  {
    "episode": 752,
    "reward": 77.89758,
    "length": 87,
    "time": 16411.53469,
    "actor_loss": 12.505584716796875,
    "critic_loss": 66.06678771972656,
    "ent_coef": 0.10728070139884949,
    "learning_rate": 0.001
  },
  {
    "episode": 753,
    "reward": 75.137883,
    "length": 92,
    "time": 16427.57191,
    "actor_loss": 11.335967063903809,
    "critic_loss": 34.0447998046875,
    "ent_coef": 0.10619982331991196,
    "learning_rate": 0.001
  },
  {
    "episode": 754,
    "reward": 72.972937,
    "length": 95,
    "time": 16445.620306,
    "actor_loss": 10.4796142578125,
    "critic_loss": 24.883939743041992,
    "ent_coef": 0.10729801654815674,
    "learning_rate": 0.001
  },
  {
    "episode": 755,
    "reward": 74.193494,
    "length": 86,
    "time": 16461.382537,
    "actor_loss": 17.380739212036133,
    "critic_loss": 115.0148696899414,
    "ent_coef": 0.11029861867427826,
    "learning_rate": 0.001
  },
  {
    "episode": 756,
    "reward": 47.429976,
    "length": 138,
    "time": 16484.076938,
    "actor_loss": 8.497763633728027,
    "critic_loss": 8.520933151245117,
    "ent_coef": 0.10607884079217911,
    "learning_rate": 0.001
  },
  {
    "episode": 757,
    "reward": 70.871855,
    "length": 99,
    "time": 16502.079286,
    "actor_loss": 5.696894645690918,
    "critic_loss": 88.97607421875,
    "ent_coef": 0.10694760829210281,
    "learning_rate": 0.001
  },
  {
    "episode": 758,
    "reward": 71.380512,
    "length": 155,
    "time": 16526.159321,
    "actor_loss": 4.068094253540039,
    "critic_loss": 251.758056640625,
    "ent_coef": 0.1087799146771431,
    "learning_rate": 0.001
  },
  {
    "episode": 759,
    "reward": 72.95781,
    "length": 91,
    "time": 16541.150974,
    "actor_loss": 7.88315486907959,
    "critic_loss": 70.72248840332031,
    "ent_coef": 0.10953915119171143,
    "learning_rate": 0.001
  },
  {
    "episode": 760,
    "reward": 80.16115,
    "length": 82,
    "time": 16555.331786,
    "actor_loss": 0.11976218223571777,
    "critic_loss": 142.98577880859375,
    "ent_coef": 0.11266448348760605,
    "learning_rate": 0.001
  },
  {
    "episode": 761,
    "reward": 78.158354,
    "length": 77,
    "time": 16568.486854,
    "actor_loss": 9.907510757446289,
    "critic_loss": 12.002076148986816,
    "ent_coef": 0.11936860531568527,
    "learning_rate": 0.001
  },
  {
    "episode": 762,
    "reward": 80.248487,
    "length": 78,
    "time": 16581.352316,
    "actor_loss": 14.44525146484375,
    "critic_loss": 36.06951904296875,
    "ent_coef": 0.12358559668064117,
    "learning_rate": 0.001
  },
  {
    "episode": 763,
    "reward": 78.338351,
    "length": 85,
    "time": 16597.577766,
    "actor_loss": 7.840456962585449,
    "critic_loss": 24.56558609008789,
    "ent_coef": 0.11976191401481628,
    "learning_rate": 0.001
  },
  {
    "episode": 764,
    "reward": 65.895316,
    "length": 108,
    "time": 16617.15389,
    "actor_loss": 12.788186073303223,
    "critic_loss": 8.785024642944336,
    "ent_coef": 0.11418250948190689,
    "learning_rate": 0.001
  },
  {
    "episode": 765,
    "reward": 75.229906,
    "length": 92,
    "time": 16632.618336,
    "actor_loss": 13.261394500732422,
    "critic_loss": 7.5036139488220215,
    "ent_coef": 0.11691977828741074,
    "learning_rate": 0.001
  },
  {
    "episode": 766,
    "reward": -117.909987,
    "length": 602,
    "time": 16712.658648,
    "actor_loss": 8.983436584472656,
    "critic_loss": 195.17276000976562,
    "ent_coef": 0.11813084036111832,
    "learning_rate": 0.001
  },
  {
    "episode": 767,
    "reward": 77.956742,
    "length": 85,
    "time": 16729.849022,
    "actor_loss": 8.174739837646484,
    "critic_loss": 145.63436889648438,
    "ent_coef": 0.12017381191253662,
    "learning_rate": 0.001
  },
  {
    "episode": 768,
    "reward": 73.13153,
    "length": 86,
    "time": 16746.416128,
    "actor_loss": 6.0098466873168945,
    "critic_loss": 88.03398132324219,
    "ent_coef": 0.12229757010936737,
    "learning_rate": 0.001
  },
  {
    "episode": 769,
    "reward": 75.28447,
    "length": 95,
    "time": 16762.415643,
    "actor_loss": 6.96500301361084,
    "critic_loss": 375.80633544921875,
    "ent_coef": 0.12282263487577438,
    "learning_rate": 0.001
  },
  {
    "episode": 770,
    "reward": 79.307325,
    "length": 83,
    "time": 16777.275423,
    "actor_loss": 12.474936485290527,
    "critic_loss": 116.92750549316406,
    "ent_coef": 0.12416467070579529,
    "learning_rate": 0.001
  },
  {
    "episode": 771,
    "reward": 77.197101,
    "length": 76,
    "time": 16792.736242,
    "actor_loss": 6.948451042175293,
    "critic_loss": 97.92584228515625,
    "ent_coef": 0.1274726390838623,
    "learning_rate": 0.001
  },
  {
    "episode": 772,
    "reward": 76.55982,
    "length": 78,
    "time": 16805.938319,
    "actor_loss": 2.870910406112671,
    "critic_loss": 290.94110107421875,
    "ent_coef": 0.13006360828876495,
    "learning_rate": 0.001
  },
  {
    "episode": 773,
    "reward": 75.760633,
    "length": 82,
    "time": 16820.715673,
    "actor_loss": 8.044973373413086,
    "critic_loss": 4.705425262451172,
    "ent_coef": 0.12763004004955292,
    "learning_rate": 0.001
  },
  {
    "episode": 774,
    "reward": 76.770985,
    "length": 86,
    "time": 16837.830136,
    "actor_loss": 11.266939163208008,
    "critic_loss": 190.83099365234375,
    "ent_coef": 0.11957845091819763,
    "learning_rate": 0.001
  },
  {
    "episode": 775,
    "reward": 78.191172,
    "length": 87,
    "time": 16853.090067,
    "actor_loss": 6.26503324508667,
    "critic_loss": 14.219959259033203,
    "ent_coef": 0.11333470046520233,
    "learning_rate": 0.001
  },
  {
    "episode": 776,
    "reward": -188.109852,
    "length": 184,
    "time": 16880.109801,
    "actor_loss": 11.169567108154297,
    "critic_loss": 183.45294189453125,
    "ent_coef": 0.11371352523565292,
    "learning_rate": 0.001
  },
  {
    "episode": 777,
    "reward": 75.417163,
    "length": 79,
    "time": 16894.06562,
    "actor_loss": 3.882176399230957,
    "critic_loss": 259.86981201171875,
    "ent_coef": 0.12033528834581375,
    "learning_rate": 0.001
  },
  {
    "episode": 778,
    "reward": 75.205604,
    "length": 83,
    "time": 16910.876581,
    "actor_loss": 7.500524997711182,
    "critic_loss": 33.88330078125,
    "ent_coef": 0.12362723797559738,
    "learning_rate": 0.001
  },
  {
    "episode": 779,
    "reward": 71.683948,
    "length": 89,
    "time": 16927.775625,
    "actor_loss": 5.353946208953857,
    "critic_loss": 405.9547424316406,
    "ent_coef": 0.11646581441164017,
    "learning_rate": 0.001
  },
  {
    "episode": 780,
    "reward": 72.516223,
    "length": 92,
    "time": 16944.094145,
    "actor_loss": 16.09579849243164,
    "critic_loss": 301.8885498046875,
    "ent_coef": 0.11663047969341278,
    "learning_rate": 0.001
  },
  {
    "episode": 781,
    "reward": 70.25268,
    "length": 95,
    "time": 16959.329927,
    "actor_loss": 5.259556770324707,
    "critic_loss": 85.37609100341797,
    "ent_coef": 0.11429578810930252,
    "learning_rate": 0.001
  },
  {
    "episode": 782,
    "reward": 74.333856,
    "length": 87,
    "time": 16974.639627,
    "actor_loss": 4.585524559020996,
    "critic_loss": 165.01129150390625,
    "ent_coef": 0.11855841428041458,
    "learning_rate": 0.001
  },
  {
    "episode": 783,
    "reward": 73.88667,
    "length": 85,
    "time": 16989.672234,
    "actor_loss": 3.5466063022613525,
    "critic_loss": 24.680850982666016,
    "ent_coef": 0.12252850830554962,
    "learning_rate": 0.001
  },
  {
    "episode": 784,
    "reward": 44.586793,
    "length": 288,
    "time": 17030.567785,
    "actor_loss": -0.5133788585662842,
    "critic_loss": 39.20610046386719,
    "ent_coef": 0.12204010784626007,
    "learning_rate": 0.001
  },
  {
    "episode": 785,
    "reward": -193.331071,
    "length": 344,
    "time": 17079.46386,
    "actor_loss": 4.979511260986328,
    "critic_loss": 11.772336959838867,
    "ent_coef": 0.11923332512378693,
    "learning_rate": 0.001
  },
  {
    "episode": 786,
    "reward": 75.304314,
    "length": 87,
    "time": 17093.713187,
    "actor_loss": 6.3713274002075195,
    "critic_loss": 67.72740173339844,
    "ent_coef": 0.11552465707063675,
    "learning_rate": 0.001
  },
  {
    "episode": 787,
    "reward": 70.027226,
    "length": 97,
    "time": 17110.656655,
    "actor_loss": 7.792287826538086,
    "critic_loss": 214.10025024414062,
    "ent_coef": 0.11420363187789917,
    "learning_rate": 0.001
  },
  {
    "episode": 788,
    "reward": 66.189366,
    "length": 116,
    "time": 17128.529179,
    "actor_loss": 5.9092020988464355,
    "critic_loss": 26.82801628112793,
    "ent_coef": 0.11626201122999191,
    "learning_rate": 0.001
  },
  {
    "episode": 789,
    "reward": 76.467936,
    "length": 89,
    "time": 17142.934935,
    "actor_loss": 8.030550003051758,
    "critic_loss": 101.61116027832031,
    "ent_coef": 0.11294981837272644,
    "learning_rate": 0.001
  },
  {
    "episode": 790,
    "reward": -110.030588,
    "length": 594,
    "time": 17222.993145,
    "actor_loss": 7.9836249351501465,
    "critic_loss": 108.64190673828125,
    "ent_coef": 0.11342746764421463,
    "learning_rate": 0.001
  },
  {
    "episode": 791,
    "reward": -167.901994,
    "length": 144,
    "time": 17246.95664,
    "actor_loss": 0.09970617294311523,
    "critic_loss": 68.55014038085938,
    "ent_coef": 0.1193879246711731,
    "learning_rate": 0.001
  },
  {
    "episode": 792,
    "reward": 70.791203,
    "length": 102,
    "time": 17264.334866,
    "actor_loss": 6.494128227233887,
    "critic_loss": 28.216655731201172,
    "ent_coef": 0.1209477037191391,
    "learning_rate": 0.001
  },
  {
    "episode": 793,
    "reward": 72.80545,
    "length": 92,
    "time": 17280.168757,
    "actor_loss": 7.219748497009277,
    "critic_loss": 45.227874755859375,
    "ent_coef": 0.11911512911319733,
    "learning_rate": 0.001
  },
  {
    "episode": 794,
    "reward": 72.671245,
    "length": 94,
    "time": 17295.641322,
    "actor_loss": 4.224942684173584,
    "critic_loss": 130.04959106445312,
    "ent_coef": 0.11428720504045486,
    "learning_rate": 0.001
  },
  {
    "episode": 795,
    "reward": 74.204012,
    "length": 97,
    "time": 17311.349071,
    "actor_loss": 5.534252166748047,
    "critic_loss": 61.98405456542969,
    "ent_coef": 0.1090507060289383,
    "learning_rate": 0.001
  },
  {
    "episode": 796,
    "reward": 72.490978,
    "length": 90,
    "time": 17327.226244,
    "actor_loss": 7.829823970794678,
    "critic_loss": 17.411237716674805,
    "ent_coef": 0.11623161286115646,
    "learning_rate": 0.001
  },
  {
    "episode": 797,
    "reward": 75.938628,
    "length": 83,
    "time": 17340.933041,
    "actor_loss": 7.868996620178223,
    "critic_loss": 7.121167182922363,
    "ent_coef": 0.12275512516498566,
    "learning_rate": 0.001
  },
  {
    "episode": 798,
    "reward": 77.119215,
    "length": 82,
    "time": 17361.573362,
    "actor_loss": 6.935985565185547,
    "critic_loss": 53.58747100830078,
    "ent_coef": 0.12606482207775116,
    "learning_rate": 0.001
  },
  {
    "episode": 799,
    "reward": 83.230584,
    "length": 77,
    "time": 17374.839385,
    "actor_loss": 7.397489070892334,
    "critic_loss": 15.782431602478027,
    "ent_coef": 0.1282700151205063,
    "learning_rate": 0.001
  },
  {
    "episode": 800,
    "reward": 75.712653,
    "length": 86,
    "time": 17391.320931,
    "actor_loss": 11.689301490783691,
    "critic_loss": 59.4821662902832,
    "ent_coef": 0.12308790534734726,
    "learning_rate": 0.001
  },
  {
    "episode": 801,
    "reward": 74.70629,
    "length": 85,
    "time": 17406.176748,
    "actor_loss": 0.28094005584716797,
    "critic_loss": 65.20465087890625,
    "ent_coef": 0.12665721774101257,
    "learning_rate": 0.001
  },
  {
    "episode": 802,
    "reward": 72.361869,
    "length": 90,
    "time": 17421.141684,
    "actor_loss": 6.6567535400390625,
    "critic_loss": 18.590576171875,
    "ent_coef": 0.12842963635921478,
    "learning_rate": 0.001
  },
  {
    "episode": 803,
    "reward": -172.024845,
    "length": 149,
    "time": 17443.654845,
    "actor_loss": 9.43213939666748,
    "critic_loss": 17.35790252685547,
    "ent_coef": 0.12664638459682465,
    "learning_rate": 0.001
  },
  {
    "episode": 804,
    "reward": -165.732139,
    "length": 143,
    "time": 17467.504968,
    "actor_loss": 6.294066429138184,
    "critic_loss": 10.086793899536133,
    "ent_coef": 0.12375573068857193,
    "learning_rate": 0.001
  },
  {
    "episode": 805,
    "reward": 65.054421,
    "length": 105,
    "time": 17485.01614,
    "actor_loss": 2.4696450233459473,
    "critic_loss": 9.592964172363281,
    "ent_coef": 0.11787501722574234,
    "learning_rate": 0.001
  },
  {
    "episode": 806,
    "reward": 79.426695,
    "length": 82,
    "time": 17499.589097,
    "actor_loss": 2.7407851219177246,
    "critic_loss": 62.668426513671875,
    "ent_coef": 0.11953897029161453,
    "learning_rate": 0.001
  },
  {
    "episode": 807,
    "reward": 65.868244,
    "length": 104,
    "time": 17517.180963,
    "actor_loss": 8.438772201538086,
    "critic_loss": 64.57572937011719,
    "ent_coef": 0.11654625833034515,
    "learning_rate": 0.001
  },
  {
    "episode": 808,
    "reward": 66.293175,
    "length": 103,
    "time": 17534.693379,
    "actor_loss": 12.218487739562988,
    "critic_loss": 67.45147705078125,
    "ent_coef": 0.11443650722503662,
    "learning_rate": 0.001
  },
  {
    "episode": 809,
    "reward": 53.687166,
    "length": 140,
    "time": 17558.749023,
    "actor_loss": 7.158960342407227,
    "critic_loss": 22.25334930419922,
    "ent_coef": 0.10550267994403839,
    "learning_rate": 0.001
  },
  {
    "episode": 810,
    "reward": 67.074187,
    "length": 99,
    "time": 17574.47755,
    "actor_loss": 5.7589945793151855,
    "critic_loss": 82.38380432128906,
    "ent_coef": 0.10729297995567322,
    "learning_rate": 0.001
  },
  {
    "episode": 811,
    "reward": 80.723665,
    "length": 77,
    "time": 17588.261146,
    "actor_loss": 5.341770172119141,
    "critic_loss": 71.25016784667969,
    "ent_coef": 0.11271055787801743,
    "learning_rate": 0.001
  },
  {
    "episode": 812,
    "reward": 76.389058,
    "length": 95,
    "time": 17603.592331,
    "actor_loss": 9.739633560180664,
    "critic_loss": 25.030357360839844,
    "ent_coef": 0.11054772138595581,
    "learning_rate": 0.001
  },
  {
    "episode": 813,
    "reward": 65.628286,
    "length": 103,
    "time": 17619.879038,
    "actor_loss": 1.66655433177948,
    "critic_loss": 89.40829467773438,
    "ent_coef": 0.10679890960454941,
    "learning_rate": 0.001
  },
  {
    "episode": 814,
    "reward": 71.396948,
    "length": 92,
    "time": 17635.137035,
    "actor_loss": 5.29521369934082,
    "critic_loss": 781.00341796875,
    "ent_coef": 0.10805699229240417,
    "learning_rate": 0.001
  },
  {
    "episode": 815,
    "reward": 74.408597,
    "length": 83,
    "time": 17650.237484,
    "actor_loss": 9.83480167388916,
    "critic_loss": 65.27735137939453,
    "ent_coef": 0.10816306620836258,
    "learning_rate": 0.001
  },
  {
    "episode": 816,
    "reward": 75.810617,
    "length": 84,
    "time": 17665.272568,
    "actor_loss": 3.2760751247406006,
    "critic_loss": 314.5780334472656,
    "ent_coef": 0.107570119202137,
    "learning_rate": 0.001
  },
  {
    "episode": 817,
    "reward": 68.765236,
    "length": 97,
    "time": 17683.749354,
    "actor_loss": 6.199618339538574,
    "critic_loss": 58.6433219909668,
    "ent_coef": 0.10846457630395889,
    "learning_rate": 0.001
  },
  {
    "episode": 818,
    "reward": 79.005204,
    "length": 87,
    "time": 17697.921281,
    "actor_loss": -1.868280053138733,
    "critic_loss": 197.92196655273438,
    "ent_coef": 0.1112104132771492,
    "learning_rate": 0.001
  },
  {
    "episode": 819,
    "reward": 72.204802,
    "length": 93,
    "time": 17714.715144,
    "actor_loss": -4.461247444152832,
    "critic_loss": 13.61814022064209,
    "ent_coef": 0.1131988912820816,
    "learning_rate": 0.001
  },
  {
    "episode": 820,
    "reward": 75.264901,
    "length": 87,
    "time": 17730.53241,
    "actor_loss": 2.0007944107055664,
    "critic_loss": 95.33211517333984,
    "ent_coef": 0.11571328341960907,
    "learning_rate": 0.001
  },
  {
    "episode": 821,
    "reward": 70.701354,
    "length": 92,
    "time": 17747.344795,
    "actor_loss": 7.445561408996582,
    "critic_loss": 71.84732055664062,
    "ent_coef": 0.12433639913797379,
    "learning_rate": 0.001
  },
  {
    "episode": 822,
    "reward": 74.388563,
    "length": 104,
    "time": 17765.62669,
    "actor_loss": -1.5956722497940063,
    "critic_loss": 285.975830078125,
    "ent_coef": 0.12397772073745728,
    "learning_rate": 0.001
  },
  {
    "episode": 823,
    "reward": 70.666527,
    "length": 123,
    "time": 17785.307815,
    "actor_loss": 7.071666717529297,
    "critic_loss": 170.4907684326172,
    "ent_coef": 0.13037341833114624,
    "learning_rate": 0.001
  },
  {
    "episode": 824,
    "reward": 73.213638,
    "length": 87,
    "time": 17799.571294,
    "actor_loss": 8.93618392944336,
    "critic_loss": 13.115930557250977,
    "ent_coef": 0.12981444597244263,
    "learning_rate": 0.001
  },
  {
    "episode": 825,
    "reward": 72.708389,
    "length": 94,
    "time": 17814.656143,
    "actor_loss": 4.814381122589111,
    "critic_loss": 10.978412628173828,
    "ent_coef": 0.1271267533302307,
    "learning_rate": 0.001
  },
  {
    "episode": 826,
    "reward": 78.516182,
    "length": 88,
    "time": 17829.256176,
    "actor_loss": 4.3976922035217285,
    "critic_loss": 215.38502502441406,
    "ent_coef": 0.12223539501428604,
    "learning_rate": 0.001
  },
  {
    "episode": 827,
    "reward": 73.154723,
    "length": 89,
    "time": 17844.748416,
    "actor_loss": 6.512279510498047,
    "critic_loss": 36.57012939453125,
    "ent_coef": 0.1250433772802353,
    "learning_rate": 0.001
  },
  {
    "episode": 828,
    "reward": 72.138634,
    "length": 94,
    "time": 17863.237093,
    "actor_loss": -0.6038796901702881,
    "critic_loss": 305.47125244140625,
    "ent_coef": 0.125760018825531,
    "learning_rate": 0.001
  },
  {
    "episode": 829,
    "reward": -167.812839,
    "length": 142,
    "time": 17886.708425,
    "actor_loss": 4.453451156616211,
    "critic_loss": 14.923419952392578,
    "ent_coef": 0.12634727358818054,
    "learning_rate": 0.001
  },
  {
    "episode": 830,
    "reward": 62.853853,
    "length": 105,
    "time": 17903.171869,
    "actor_loss": 1.1432571411132812,
    "critic_loss": 7.912879467010498,
    "ent_coef": 0.1259925365447998,
    "learning_rate": 0.001
  },
  {
    "episode": 831,
    "reward": -188.764929,
    "length": 184,
    "time": 17930.368268,
    "actor_loss": 10.646930694580078,
    "critic_loss": 134.0536651611328,
    "ent_coef": 0.11999793350696564,
    "learning_rate": 0.001
  },
  {
    "episode": 832,
    "reward": 73.551697,
    "length": 94,
    "time": 17947.167739,
    "actor_loss": 4.759519100189209,
    "critic_loss": 15.92354965209961,
    "ent_coef": 0.1153530701994896,
    "learning_rate": 0.001
  },
  {
    "episode": 833,
    "reward": 66.748184,
    "length": 107,
    "time": 17964.034015,
    "actor_loss": 4.058042526245117,
    "critic_loss": 109.08479309082031,
    "ent_coef": 0.1154109537601471,
    "learning_rate": 0.001
  },
  {
    "episode": 834,
    "reward": 73.788519,
    "length": 86,
    "time": 17979.273695,
    "actor_loss": 1.187199592590332,
    "critic_loss": 63.07757568359375,
    "ent_coef": 0.11818802356719971,
    "learning_rate": 0.001
  },
  {
    "episode": 835,
    "reward": 64.306984,
    "length": 99,
    "time": 17995.926962,
    "actor_loss": 8.009628295898438,
    "critic_loss": 5.859471797943115,
    "ent_coef": 0.11932862550020218,
    "learning_rate": 0.001
  },
  {
    "episode": 836,
    "reward": 61.50054,
    "length": 110,
    "time": 18013.7369,
    "actor_loss": 2.9660024642944336,
    "critic_loss": 270.177734375,
    "ent_coef": 0.11789277195930481,
    "learning_rate": 0.001
  },
  {
    "episode": 837,
    "reward": 77.654334,
    "length": 88,
    "time": 18030.958194,
    "actor_loss": 7.642851829528809,
    "critic_loss": 37.51194763183594,
    "ent_coef": 0.12524431943893433,
    "learning_rate": 0.001
  },
  {
    "episode": 838,
    "reward": 75.165106,
    "length": 83,
    "time": 18044.532727,
    "actor_loss": 5.46063232421875,
    "critic_loss": 115.23066711425781,
    "ent_coef": 0.13042128086090088,
    "learning_rate": 0.001
  },
  {
    "episode": 839,
    "reward": 77.571725,
    "length": 86,
    "time": 18060.319692,
    "actor_loss": 0.17255795001983643,
    "critic_loss": 21.542037963867188,
    "ent_coef": 0.13502323627471924,
    "learning_rate": 0.001
  },
  {
    "episode": 840,
    "reward": 69.88657,
    "length": 103,
    "time": 18076.962399,
    "actor_loss": 2.366129159927368,
    "critic_loss": 9.048099517822266,
    "ent_coef": 0.1301620602607727,
    "learning_rate": 0.001
  },
  {
    "episode": 841,
    "reward": 28.951088,
    "length": 164,
    "time": 18103.59472,
    "actor_loss": 3.2544565200805664,
    "critic_loss": 101.1870346069336,
    "ent_coef": 0.12255299836397171,
    "learning_rate": 0.001
  },
  {
    "episode": 842,
    "reward": 48.60357,
    "length": 130,
    "time": 18125.958787,
    "actor_loss": -0.9513189792633057,
    "critic_loss": 101.57899475097656,
    "ent_coef": 0.12122534215450287,
    "learning_rate": 0.001
  },
  {
    "episode": 843,
    "reward": 83.220218,
    "length": 77,
    "time": 18139.994985,
    "actor_loss": 2.854865550994873,
    "critic_loss": 224.55331420898438,
    "ent_coef": 0.12643013894557953,
    "learning_rate": 0.001
  },
  {
    "episode": 844,
    "reward": -115.034335,
    "length": 597,
    "time": 18220.079799,
    "actor_loss": 2.3367910385131836,
    "critic_loss": 65.50309753417969,
    "ent_coef": 0.12059101462364197,
    "learning_rate": 0.001
  },
  {
    "episode": 845,
    "reward": 25.459102,
    "length": 164,
    "time": 18245.683247,
    "actor_loss": 5.645145893096924,
    "critic_loss": 84.11750793457031,
    "ent_coef": 0.11228664964437485,
    "learning_rate": 0.001
  },
  {
    "episode": 846,
    "reward": 74.307009,
    "length": 88,
    "time": 18263.816602,
    "actor_loss": 5.716060638427734,
    "critic_loss": 147.96185302734375,
    "ent_coef": 0.11348771303892136,
    "learning_rate": 0.001
  },
  {
    "episode": 847,
    "reward": 71.638988,
    "length": 91,
    "time": 18278.798748,
    "actor_loss": 9.90553092956543,
    "critic_loss": 11.152247428894043,
    "ent_coef": 0.11478561908006668,
    "learning_rate": 0.001
  },
  {
    "episode": 848,
    "reward": 76.640902,
    "length": 85,
    "time": 18294.170479,
    "actor_loss": 2.7167370319366455,
    "critic_loss": 8.747551918029785,
    "ent_coef": 0.11698073893785477,
    "learning_rate": 0.001
  },
  {
    "episode": 849,
    "reward": 83.864106,
    "length": 76,
    "time": 18310.942056,
    "actor_loss": -1.0808148384094238,
    "critic_loss": 14.795135498046875,
    "ent_coef": 0.11966366320848465,
    "learning_rate": 0.001
  },
  {
    "episode": 850,
    "reward": 54.141872,
    "length": 124,
    "time": 18330.282131,
    "actor_loss": -2.210108757019043,
    "critic_loss": 17.983673095703125,
    "ent_coef": 0.11541334539651871,
    "learning_rate": 0.001
  },
  {
    "episode": 851,
    "reward": 59.158101,
    "length": 106,
    "time": 18347.417875,
    "actor_loss": 3.9817397594451904,
    "critic_loss": 42.594024658203125,
    "ent_coef": 0.11794029176235199,
    "learning_rate": 0.001
  },
  {
    "episode": 852,
    "reward": -172.993631,
    "length": 154,
    "time": 18370.596834,
    "actor_loss": 1.6620441675186157,
    "critic_loss": 35.20165252685547,
    "ent_coef": 0.11944042891263962,
    "learning_rate": 0.001
  },
  {
    "episode": 853,
    "reward": 83.081644,
    "length": 76,
    "time": 18385.994071,
    "actor_loss": -2.8134684562683105,
    "critic_loss": 73.94072723388672,
    "ent_coef": 0.11890022456645966,
    "learning_rate": 0.001
  },
  {
    "episode": 854,
    "reward": 71.683371,
    "length": 98,
    "time": 18402.189367,
    "actor_loss": 0.5585904121398926,
    "critic_loss": 10.737222671508789,
    "ent_coef": 0.12186219543218613,
    "learning_rate": 0.001
  },
  {
    "episode": 855,
    "reward": 75.578418,
    "length": 83,
    "time": 18415.987919,
    "actor_loss": 7.437802314758301,
    "critic_loss": 15.780289649963379,
    "ent_coef": 0.12128642946481705,
    "learning_rate": 0.001
  },
  {
    "episode": 856,
    "reward": 86.477421,
    "length": 69,
    "time": 18430.394035,
    "actor_loss": 7.532185077667236,
    "critic_loss": 64.509033203125,
    "ent_coef": 0.12388544529676437,
    "learning_rate": 0.001
  },
  {
    "episode": 857,
    "reward": -166.363827,
    "length": 139,
    "time": 18454.199235,
    "actor_loss": 1.599731206893921,
    "critic_loss": 152.6612548828125,
    "ent_coef": 0.127414733171463,
    "learning_rate": 0.001
  },
  {
    "episode": 858,
    "reward": 76.899711,
    "length": 81,
    "time": 18467.769118,
    "actor_loss": 2.145418643951416,
    "critic_loss": 32.144893646240234,
    "ent_coef": 0.12619343400001526,
    "learning_rate": 0.001
  },
  {
    "episode": 859,
    "reward": 86.471839,
    "length": 72,
    "time": 18484.481259,
    "actor_loss": 2.317286968231201,
    "critic_loss": 332.7546691894531,
    "ent_coef": 0.12958717346191406,
    "learning_rate": 0.001
  },
  {
    "episode": 860,
    "reward": 76.471676,
    "length": 85,
    "time": 18499.699275,
    "actor_loss": 2.6930665969848633,
    "critic_loss": 61.40314483642578,
    "ent_coef": 0.13712827861309052,
    "learning_rate": 0.001
  },
  {
    "episode": 861,
    "reward": 77.505291,
    "length": 97,
    "time": 18514.974239,
    "actor_loss": -1.9268112182617188,
    "critic_loss": 57.369544982910156,
    "ent_coef": 0.13907067477703094,
    "learning_rate": 0.001
  },
  {
    "episode": 862,
    "reward": 74.10522,
    "length": 91,
    "time": 18532.027633,
    "actor_loss": -0.5844303369522095,
    "critic_loss": 32.62311935424805,
    "ent_coef": 0.1367819905281067,
    "learning_rate": 0.001
  },
  {
    "episode": 863,
    "reward": 80.967656,
    "length": 85,
    "time": 18546.467927,
    "actor_loss": 7.68534517288208,
    "critic_loss": 86.29145812988281,
    "ent_coef": 0.13370217382907867,
    "learning_rate": 0.001
  },
  {
    "episode": 864,
    "reward": -168.214833,
    "length": 146,
    "time": 18568.939387,
    "actor_loss": 1.1884077787399292,
    "critic_loss": 30.853614807128906,
    "ent_coef": 0.13257943093776703,
    "learning_rate": 0.001
  },
  {
    "episode": 865,
    "reward": 27.27435,
    "length": 166,
    "time": 18593.390839,
    "actor_loss": -2.107591152191162,
    "critic_loss": 64.80381774902344,
    "ent_coef": 0.12923522293567657,
    "learning_rate": 0.001
  },
  {
    "episode": 866,
    "reward": 3.257206,
    "length": 195,
    "time": 18623.63724,
    "actor_loss": 7.243614673614502,
    "critic_loss": 21.368560791015625,
    "ent_coef": 0.12540899217128754,
    "learning_rate": 0.001
  },
  {
    "episode": 867,
    "reward": 74.677618,
    "length": 90,
    "time": 18642.050579,
    "actor_loss": 7.571352005004883,
    "critic_loss": 4.7423415184021,
    "ent_coef": 0.12619109451770782,
    "learning_rate": 0.001
  },
  {
    "episode": 868,
    "reward": 73.58054,
    "length": 85,
    "time": 18658.732089,
    "actor_loss": -6.107205390930176,
    "critic_loss": 14.940505027770996,
    "ent_coef": 0.12225373089313507,
    "learning_rate": 0.001
  },
  {
    "episode": 869,
    "reward": 71.09757,
    "length": 91,
    "time": 18673.598208,
    "actor_loss": 1.2790069580078125,
    "critic_loss": 13.571769714355469,
    "ent_coef": 0.12183471769094467,
    "learning_rate": 0.001
  },
  {
    "episode": 870,
    "reward": 66.436716,
    "length": 102,
    "time": 18692.34627,
    "actor_loss": 4.782955169677734,
    "critic_loss": 12.205676078796387,
    "ent_coef": 0.12255395948886871,
    "learning_rate": 0.001
  },
  {
    "episode": 871,
    "reward": 70.839667,
    "length": 93,
    "time": 18707.711486,
    "actor_loss": 0.3025798797607422,
    "critic_loss": 227.55471801757812,
    "ent_coef": 0.12101191282272339,
    "learning_rate": 0.001
  },
  {
    "episode": 872,
    "reward": 69.450729,
    "length": 96,
    "time": 18724.001286,
    "actor_loss": -0.5131839513778687,
    "critic_loss": 434.98370361328125,
    "ent_coef": 0.12348966300487518,
    "learning_rate": 0.001
  },
  {
    "episode": 873,
    "reward": 73.391802,
    "length": 89,
    "time": 18738.712952,
    "actor_loss": 2.2132043838500977,
    "critic_loss": 25.33981704711914,
    "ent_coef": 0.12670685350894928,
    "learning_rate": 0.001
  },
  {
    "episode": 874,
    "reward": 58.65732,
    "length": 117,
    "time": 18756.939578,
    "actor_loss": -5.192469120025635,
    "critic_loss": 208.1424560546875,
    "ent_coef": 0.12521472573280334,
    "learning_rate": 0.001
  },
  {
    "episode": 875,
    "reward": 76.343574,
    "length": 85,
    "time": 18771.070485,
    "actor_loss": 1.8126485347747803,
    "critic_loss": 60.723052978515625,
    "ent_coef": 0.12525582313537598,
    "learning_rate": 0.001
  },
  {
    "episode": 876,
    "reward": 71.094101,
    "length": 91,
    "time": 18786.867499,
    "actor_loss": -3.0605499744415283,
    "critic_loss": 15.158851623535156,
    "ent_coef": 0.12311895191669464,
    "learning_rate": 0.001
  },
  {
    "episode": 877,
    "reward": 55.405357,
    "length": 123,
    "time": 18806.078895,
    "actor_loss": 1.4271416664123535,
    "critic_loss": 104.49057006835938,
    "ent_coef": 0.11914455145597458,
    "learning_rate": 0.001
  },
  {
    "episode": 878,
    "reward": 69.088067,
    "length": 94,
    "time": 18823.372566,
    "actor_loss": 1.541961669921875,
    "critic_loss": 30.915912628173828,
    "ent_coef": 0.12095958739519119,
    "learning_rate": 0.001
  },
  {
    "episode": 879,
    "reward": 76.613576,
    "length": 91,
    "time": 18838.199193,
    "actor_loss": -1.9774351119995117,
    "critic_loss": 155.33102416992188,
    "ent_coef": 0.12118084728717804,
    "learning_rate": 0.001
  },
  {
    "episode": 880,
    "reward": 74.605841,
    "length": 90,
    "time": 18855.948658,
    "actor_loss": -1.4373756647109985,
    "critic_loss": 23.158201217651367,
    "ent_coef": 0.12334585934877396,
    "learning_rate": 0.001
  },
  {
    "episode": 881,
    "reward": 73.415652,
    "length": 88,
    "time": 18870.557678,
    "actor_loss": 2.368476390838623,
    "critic_loss": 23.513248443603516,
    "ent_coef": 0.12377269566059113,
    "learning_rate": 0.001
  },
  {
    "episode": 882,
    "reward": 77.680246,
    "length": 83,
    "time": 18886.224129,
    "actor_loss": 3.453911781311035,
    "critic_loss": 13.651823043823242,
    "ent_coef": 0.12866273522377014,
    "learning_rate": 0.001
  },
  {
    "episode": 883,
    "reward": 68.535679,
    "length": 96,
    "time": 18902.74396,
    "actor_loss": 1.3347262144088745,
    "critic_loss": 46.949928283691406,
    "ent_coef": 0.13008087873458862,
    "learning_rate": 0.001
  },
  {
    "episode": 884,
    "reward": 75.06033,
    "length": 85,
    "time": 18917.717905,
    "actor_loss": -5.74990701675415,
    "critic_loss": 134.3162841796875,
    "ent_coef": 0.13722902536392212,
    "learning_rate": 0.001
  },
  {
    "episode": 885,
    "reward": 63.192856,
    "length": 101,
    "time": 18934.958966,
    "actor_loss": 5.405303001403809,
    "critic_loss": 52.34642028808594,
    "ent_coef": 0.13823391497135162,
    "learning_rate": 0.001
  },
  {
    "episode": 886,
    "reward": 72.819774,
    "length": 90,
    "time": 18950.470136,
    "actor_loss": 1.2546733617782593,
    "critic_loss": 9.534212112426758,
    "ent_coef": 0.13565106689929962,
    "learning_rate": 0.001
  },
  {
    "episode": 887,
    "reward": 76.607957,
    "length": 86,
    "time": 18964.603457,
    "actor_loss": 0.7820491790771484,
    "critic_loss": 110.51356506347656,
    "ent_coef": 0.13749133050441742,
    "learning_rate": 0.001
  },
  {
    "episode": 888,
    "reward": 74.80251,
    "length": 98,
    "time": 18980.247014,
    "actor_loss": 4.711400985717773,
    "critic_loss": 10.500374794006348,
    "ent_coef": 0.13845080137252808,
    "learning_rate": 0.001
  },
  {
    "episode": 889,
    "reward": 67.874535,
    "length": 97,
    "time": 18997.753947,
    "actor_loss": 2.4181151390075684,
    "critic_loss": 71.10404968261719,
    "ent_coef": 0.13967715203762054,
    "learning_rate": 0.001
  },
  {
    "episode": 890,
    "reward": 64.35669,
    "length": 100,
    "time": 19015.444725,
    "actor_loss": -3.256112575531006,
    "critic_loss": 357.94171142578125,
    "ent_coef": 0.1383732706308365,
    "learning_rate": 0.001
  },
  {
    "episode": 891,
    "reward": 60.820626,
    "length": 105,
    "time": 19035.218127,
    "actor_loss": 1.9688122272491455,
    "critic_loss": 16.280244827270508,
    "ent_coef": 0.1336124688386917,
    "learning_rate": 0.001
  },
  {
    "episode": 892,
    "reward": 76.927822,
    "length": 82,
    "time": 19049.881912,
    "actor_loss": -5.330270767211914,
    "critic_loss": 72.9290542602539,
    "ent_coef": 0.1347203552722931,
    "learning_rate": 0.001
  },
  {
    "episode": 893,
    "reward": 76.371053,
    "length": 88,
    "time": 19064.299075,
    "actor_loss": -3.1757161617279053,
    "critic_loss": 270.08746337890625,
    "ent_coef": 0.13590465486049652,
    "learning_rate": 0.001
  },
  {
    "episode": 894,
    "reward": 71.566063,
    "length": 108,
    "time": 19081.41725,
    "actor_loss": -5.228119850158691,
    "critic_loss": 38.728431701660156,
    "ent_coef": 0.13956038653850555,
    "learning_rate": 0.001
  },
  {
    "episode": 895,
    "reward": -162.331979,
    "length": 139,
    "time": 19103.187507,
    "actor_loss": -3.389486074447632,
    "critic_loss": 6.9539384841918945,
    "ent_coef": 0.14034026861190796,
    "learning_rate": 0.001
  },
  {
    "episode": 896,
    "reward": -175.936806,
    "length": 153,
    "time": 19126.152905,
    "actor_loss": -1.4749631881713867,
    "critic_loss": 293.45648193359375,
    "ent_coef": 0.14039473235607147,
    "learning_rate": 0.001
  },
  {
    "episode": 897,
    "reward": 73.478273,
    "length": 94,
    "time": 19142.569051,
    "actor_loss": -2.7587060928344727,
    "critic_loss": 16.979305267333984,
    "ent_coef": 0.13179540634155273,
    "learning_rate": 0.001
  },
  {
    "episode": 898,
    "reward": 72.461193,
    "length": 87,
    "time": 19160.625774,
    "actor_loss": -6.902750492095947,
    "critic_loss": 25.536231994628906,
    "ent_coef": 0.1301271915435791,
    "learning_rate": 0.001
  },
  {
    "episode": 899,
    "reward": 72.756435,
    "length": 92,
    "time": 19176.142691,
    "actor_loss": 2.3773627281188965,
    "critic_loss": 65.27302551269531,
    "ent_coef": 0.13027526438236237,
    "learning_rate": 0.001
  },
  {
    "episode": 900,
    "reward": 70.428076,
    "length": 97,
    "time": 19193.029715,
    "actor_loss": -6.286016941070557,
    "critic_loss": 59.85805892944336,
    "ent_coef": 0.12836109101772308,
    "learning_rate": 0.001
  },
  {
    "episode": 901,
    "reward": 70.795764,
    "length": 92,
    "time": 19208.953989,
    "actor_loss": -4.797124862670898,
    "critic_loss": 36.32537841796875,
    "ent_coef": 0.12865151464939117,
    "learning_rate": 0.001
  },
  {
    "episode": 902,
    "reward": 63.561423,
    "length": 106,
    "time": 19227.001572,
    "actor_loss": -0.42036503553390503,
    "critic_loss": 173.80789184570312,
    "ent_coef": 0.12016255408525467,
    "learning_rate": 0.001
  },
  {
    "episode": 903,
    "reward": 73.8162,
    "length": 85,
    "time": 19241.431125,
    "actor_loss": -5.693276405334473,
    "critic_loss": 99.39058685302734,
    "ent_coef": 0.12203336507081985,
    "learning_rate": 0.001
  },
  {
    "episode": 904,
    "reward": 74.810067,
    "length": 86,
    "time": 19255.507118,
    "actor_loss": 2.7663278579711914,
    "critic_loss": 5.990187168121338,
    "ent_coef": 0.12012550979852676,
    "learning_rate": 0.001
  },
  {
    "episode": 905,
    "reward": 67.871278,
    "length": 96,
    "time": 19271.343497,
    "actor_loss": -3.6407058238983154,
    "critic_loss": 3.140475034713745,
    "ent_coef": 0.11890378594398499,
    "learning_rate": 0.001
  },
  {
    "episode": 906,
    "reward": 72.722115,
    "length": 91,
    "time": 19286.370603,
    "actor_loss": -3.560131311416626,
    "critic_loss": 10.160697937011719,
    "ent_coef": 0.12107774615287781,
    "learning_rate": 0.001
  },
  {
    "episode": 907,
    "reward": 73.127479,
    "length": 88,
    "time": 19300.764401,
    "actor_loss": 2.1335830688476562,
    "critic_loss": 6.160378456115723,
    "ent_coef": 0.120310477912426,
    "learning_rate": 0.001
  },
  {
    "episode": 908,
    "reward": 66.577032,
    "length": 102,
    "time": 19317.126549,
    "actor_loss": -2.0427651405334473,
    "critic_loss": 18.54517936706543,
    "ent_coef": 0.12104766815900803,
    "learning_rate": 0.001
  },
  {
    "episode": 909,
    "reward": 65.603411,
    "length": 102,
    "time": 19337.225806,
    "actor_loss": -1.9763596057891846,
    "critic_loss": 14.981409072875977,
    "ent_coef": 0.12095004320144653,
    "learning_rate": 0.001
  },
  {
    "episode": 910,
    "reward": 66.177987,
    "length": 97,
    "time": 19354.72782,
    "actor_loss": -3.457764148712158,
    "critic_loss": 152.03819274902344,
    "ent_coef": 0.12118268758058548,
    "learning_rate": 0.001
  },
  {
    "episode": 911,
    "reward": 68.504371,
    "length": 96,
    "time": 19371.253358,
    "actor_loss": -2.36564564704895,
    "critic_loss": 74.30677032470703,
    "ent_coef": 0.11898892372846603,
    "learning_rate": 0.001
  },
  {
    "episode": 912,
    "reward": 64.586326,
    "length": 101,
    "time": 19387.423814,
    "actor_loss": 0.10170817375183105,
    "critic_loss": 128.42242431640625,
    "ent_coef": 0.12023783475160599,
    "learning_rate": 0.001
  },
  {
    "episode": 913,
    "reward": 78.470901,
    "length": 84,
    "time": 19402.572613,
    "actor_loss": 3.1057324409484863,
    "critic_loss": 129.45652770996094,
    "ent_coef": 0.12100986391305923,
    "learning_rate": 0.001
  },
  {
    "episode": 914,
    "reward": 75.00035,
    "length": 82,
    "time": 19417.273258,
    "actor_loss": 4.177632808685303,
    "critic_loss": 170.40093994140625,
    "ent_coef": 0.12403765320777893,
    "learning_rate": 0.001
  },
  {
    "episode": 915,
    "reward": 42.694189,
    "length": 310,
    "time": 19462.213104,
    "actor_loss": 1.4173660278320312,
    "critic_loss": 24.07965850830078,
    "ent_coef": 0.11683332175016403,
    "learning_rate": 0.001
  },
  {
    "episode": 916,
    "reward": 39.543942,
    "length": 133,
    "time": 19483.330205,
    "actor_loss": -0.5542166233062744,
    "critic_loss": 16.33359146118164,
    "ent_coef": 0.11543656885623932,
    "learning_rate": 0.001
  },
  {
    "episode": 917,
    "reward": 47.390534,
    "length": 118,
    "time": 19502.934755,
    "actor_loss": 1.1411749124526978,
    "critic_loss": 21.835166931152344,
    "ent_coef": 0.1151038184762001,
    "learning_rate": 0.001
  },
  {
    "episode": 918,
    "reward": 68.390426,
    "length": 96,
    "time": 19519.611271,
    "actor_loss": -4.1526780128479,
    "critic_loss": 29.03582000732422,
    "ent_coef": 0.1187233254313469,
    "learning_rate": 0.001
  },
  {
    "episode": 919,
    "reward": 53.83548,
    "length": 130,
    "time": 19539.491441,
    "actor_loss": -4.480275630950928,
    "critic_loss": 20.537979125976562,
    "ent_coef": 0.11165579408407211,
    "learning_rate": 0.001
  },
  {
    "episode": 920,
    "reward": 74.343818,
    "length": 91,
    "time": 19557.218992,
    "actor_loss": -1.6203680038452148,
    "critic_loss": 105.80931091308594,
    "ent_coef": 0.1132175400853157,
    "learning_rate": 0.001
  },
  {
    "episode": 921,
    "reward": -174.437226,
    "length": 151,
    "time": 19579.87647,
    "actor_loss": -5.268486499786377,
    "critic_loss": 62.58965301513672,
    "ent_coef": 0.11555720865726471,
    "learning_rate": 0.001
  },
  {
    "episode": 922,
    "reward": 69.27159,
    "length": 96,
    "time": 19597.616309,
    "actor_loss": -2.750382900238037,
    "critic_loss": 53.03746032714844,
    "ent_coef": 0.1155221164226532,
    "learning_rate": 0.001
  },
  {
    "episode": 923,
    "reward": 62.63221,
    "length": 118,
    "time": 19615.861244,
    "actor_loss": -2.2025060653686523,
    "critic_loss": 21.309274673461914,
    "ent_coef": 0.1234559565782547,
    "learning_rate": 0.001
  },
  {
    "episode": 924,
    "reward": 15.131163,
    "length": 166,
    "time": 19640.43909,
    "actor_loss": -2.0211925506591797,
    "critic_loss": 84.89443969726562,
    "ent_coef": 0.1247144341468811,
    "learning_rate": 0.001
  },
  {
    "episode": 925,
    "reward": 58.500919,
    "length": 111,
    "time": 19658.029358,
    "actor_loss": 2.661566972732544,
    "critic_loss": 88.12864685058594,
    "ent_coef": 0.12184932827949524,
    "learning_rate": 0.001
  },
  {
    "episode": 926,
    "reward": -196.618568,
    "length": 201,
    "time": 19687.79009,
    "actor_loss": 4.2345709800720215,
    "critic_loss": 33.23316955566406,
    "ent_coef": 0.12129929661750793,
    "learning_rate": 0.001
  },
  {
    "episode": 927,
    "reward": 72.010509,
    "length": 92,
    "time": 19702.956856,
    "actor_loss": -5.451839447021484,
    "critic_loss": 308.90496826171875,
    "ent_coef": 0.1274043321609497,
    "learning_rate": 0.001
  },
  {
    "episode": 928,
    "reward": 69.183268,
    "length": 93,
    "time": 19720.330289,
    "actor_loss": -9.853729248046875,
    "critic_loss": 15.837705612182617,
    "ent_coef": 0.1280592679977417,
    "learning_rate": 0.001
  },
  {
    "episode": 929,
    "reward": 68.78372,
    "length": 99,
    "time": 19737.440388,
    "actor_loss": -7.3384785652160645,
    "critic_loss": 33.32658767700195,
    "ent_coef": 0.12404080480337143,
    "learning_rate": 0.001
  },
  {
    "episode": 930,
    "reward": 66.189823,
    "length": 100,
    "time": 19754.182787,
    "actor_loss": 0.4396785497665405,
    "critic_loss": 89.30593872070312,
    "ent_coef": 0.11891499161720276,
    "learning_rate": 0.001
  },
  {
    "episode": 931,
    "reward": 78.849452,
    "length": 81,
    "time": 19768.672382,
    "actor_loss": -3.511754274368286,
    "critic_loss": 25.809524536132812,
    "ent_coef": 0.12044321745634079,
    "learning_rate": 0.001
  },
  {
    "episode": 932,
    "reward": 63.6208,
    "length": 103,
    "time": 19785.32717,
    "actor_loss": -6.231463432312012,
    "critic_loss": 48.86907958984375,
    "ent_coef": 0.1215578019618988,
    "learning_rate": 0.001
  },
  {
    "episode": 933,
    "reward": 73.003517,
    "length": 94,
    "time": 19801.754171,
    "actor_loss": 0.6435860395431519,
    "critic_loss": 309.93328857421875,
    "ent_coef": 0.12363404035568237,
    "learning_rate": 0.001
  },
  {
    "episode": 934,
    "reward": 67.651809,
    "length": 100,
    "time": 19818.511384,
    "actor_loss": -5.289828300476074,
    "critic_loss": 407.7847900390625,
    "ent_coef": 0.12034923583269119,
    "learning_rate": 0.001
  },
  {
    "episode": 935,
    "reward": 80.22009,
    "length": 81,
    "time": 19834.046097,
    "actor_loss": 3.611245632171631,
    "critic_loss": 12.671921730041504,
    "ent_coef": 0.12149081379175186,
    "learning_rate": 0.001
  },
  {
    "episode": 936,
    "reward": 74.651491,
    "length": 87,
    "time": 19848.395539,
    "actor_loss": -4.468437194824219,
    "critic_loss": 8.991630554199219,
    "ent_coef": 0.12137173861265182,
    "learning_rate": 0.001
  },
  {
    "episode": 937,
    "reward": 73.515692,
    "length": 97,
    "time": 19864.85224,
    "actor_loss": -2.7989587783813477,
    "critic_loss": 26.228052139282227,
    "ent_coef": 0.1205478385090828,
    "learning_rate": 0.001
  },
  {
    "episode": 938,
    "reward": 56.906858,
    "length": 116,
    "time": 19883.814513,
    "actor_loss": -6.319893836975098,
    "critic_loss": 33.35499572753906,
    "ent_coef": 0.11414782702922821,
    "learning_rate": 0.001
  },
  {
    "episode": 939,
    "reward": 73.284768,
    "length": 96,
    "time": 19900.192753,
    "actor_loss": -3.582418203353882,
    "critic_loss": 73.23358917236328,
    "ent_coef": 0.11189153045415878,
    "learning_rate": 0.001
  },
  {
    "episode": 940,
    "reward": 74.394507,
    "length": 85,
    "time": 19917.169058,
    "actor_loss": -12.30620002746582,
    "critic_loss": 176.93301391601562,
    "ent_coef": 0.11250869184732437,
    "learning_rate": 0.001
  },
  {
    "episode": 941,
    "reward": -173.963745,
    "length": 154,
    "time": 19944.01522,
    "actor_loss": -8.113858222961426,
    "critic_loss": 43.48070526123047,
    "ent_coef": 0.11473429203033447,
    "learning_rate": 0.001
  },
  {
    "episode": 942,
    "reward": -172.758953,
    "length": 150,
    "time": 19970.649406,
    "actor_loss": -3.9052507877349854,
    "critic_loss": 267.0820007324219,
    "ent_coef": 0.12238437682390213,
    "learning_rate": 0.001
  },
  {
    "episode": 943,
    "reward": 53.446098,
    "length": 123,
    "time": 19992.429161,
    "actor_loss": -5.413512229919434,
    "critic_loss": 44.07007598876953,
    "ent_coef": 0.1157870814204216,
    "learning_rate": 0.001
  },
  {
    "episode": 944,
    "reward": 78.337376,
    "length": 85,
    "time": 20010.39922,
    "actor_loss": -6.140523910522461,
    "critic_loss": 248.022705078125,
    "ent_coef": 0.1116330623626709,
    "learning_rate": 0.001
  },
  {
    "episode": 945,
    "reward": 75.210632,
    "length": 84,
    "time": 20025.567223,
    "actor_loss": -8.036237716674805,
    "critic_loss": 21.255409240722656,
    "ent_coef": 0.10945454984903336,
    "learning_rate": 0.001
  },
  {
    "episode": 946,
    "reward": 77.235775,
    "length": 81,
    "time": 20042.772369,
    "actor_loss": -2.6516101360321045,
    "critic_loss": 101.52545166015625,
    "ent_coef": 0.11164085566997528,
    "learning_rate": 0.001
  },
  {
    "episode": 947,
    "reward": 82.192739,
    "length": 81,
    "time": 20056.310991,
    "actor_loss": -6.14188289642334,
    "critic_loss": 32.04827880859375,
    "ent_coef": 0.1088232547044754,
    "learning_rate": 0.001
  },
  {
    "episode": 948,
    "reward": 82.176338,
    "length": 77,
    "time": 20070.439363,
    "actor_loss": -6.126285552978516,
    "critic_loss": 97.5247802734375,
    "ent_coef": 0.10787029564380646,
    "learning_rate": 0.001
  },
  {
    "episode": 949,
    "reward": 74.761178,
    "length": 90,
    "time": 20085.581758,
    "actor_loss": -10.416916847229004,
    "critic_loss": 159.57699584960938,
    "ent_coef": 0.1108325645327568,
    "learning_rate": 0.001
  },
  {
    "episode": 950,
    "reward": 74.281745,
    "length": 91,
    "time": 20101.07202,
    "actor_loss": -0.7245485782623291,
    "critic_loss": 85.93071746826172,
    "ent_coef": 0.1123381182551384,
    "learning_rate": 0.001
  },
  {
    "episode": 951,
    "reward": -178.632103,
    "length": 160,
    "time": 20124.817046,
    "actor_loss": -3.430154323577881,
    "critic_loss": 170.66993713378906,
    "ent_coef": 0.11490283161401749,
    "learning_rate": 0.001
  },
  {
    "episode": 952,
    "reward": 76.109457,
    "length": 82,
    "time": 20139.28212,
    "actor_loss": -1.603106141090393,
    "critic_loss": 23.221899032592773,
    "ent_coef": 0.1203187108039856,
    "learning_rate": 0.001
  },
  {
    "episode": 953,
    "reward": 78.453348,
    "length": 78,
    "time": 20153.25722,
    "actor_loss": -4.221405982971191,
    "critic_loss": 162.79989624023438,
    "ent_coef": 0.12465913593769073,
    "learning_rate": 0.001
  },
  {
    "episode": 954,
    "reward": -164.311756,
    "length": 136,
    "time": 20174.689065,
    "actor_loss": -4.486931324005127,
    "critic_loss": 292.76031494140625,
    "ent_coef": 0.1315695196390152,
    "learning_rate": 0.001
  },
  {
    "episode": 955,
    "reward": 76.111573,
    "length": 84,
    "time": 20188.803402,
    "actor_loss": -6.397350311279297,
    "critic_loss": 276.04632568359375,
    "ent_coef": 0.13598819077014923,
    "learning_rate": 0.001
  },
  {
    "episode": 956,
    "reward": 77.706718,
    "length": 79,
    "time": 20202.422392,
    "actor_loss": -5.7181010246276855,
    "critic_loss": 130.46240234375,
    "ent_coef": 0.13382770121097565,
    "learning_rate": 0.001
  },
  {
    "episode": 957,
    "reward": 71.161467,
    "length": 91,
    "time": 20220.207663,
    "actor_loss": -3.1024255752563477,
    "critic_loss": 66.63700866699219,
    "ent_coef": 0.12709182500839233,
    "learning_rate": 0.001
  },
  {
    "episode": 958,
    "reward": 65.138136,
    "length": 136,
    "time": 20240.728732,
    "actor_loss": 0.6655874252319336,
    "critic_loss": 453.8895263671875,
    "ent_coef": 0.1267884373664856,
    "learning_rate": 0.001
  },
  {
    "episode": 959,
    "reward": 80.667468,
    "length": 81,
    "time": 20255.094426,
    "actor_loss": -8.037476539611816,
    "critic_loss": 114.67198181152344,
    "ent_coef": 0.12499430030584335,
    "learning_rate": 0.001
  },
  {
    "episode": 960,
    "reward": 83.822693,
    "length": 74,
    "time": 20268.752177,
    "actor_loss": -7.489691734313965,
    "critic_loss": 75.34535217285156,
    "ent_coef": 0.12603172659873962,
    "learning_rate": 0.001
  },
  {
    "episode": 961,
    "reward": 74.090413,
    "length": 91,
    "time": 20285.385338,
    "actor_loss": -7.271554470062256,
    "critic_loss": 38.54890441894531,
    "ent_coef": 0.12328694760799408,
    "learning_rate": 0.001
  },
  {
    "episode": 962,
    "reward": 78.624424,
    "length": 79,
    "time": 20300.534054,
    "actor_loss": -11.58883285522461,
    "critic_loss": 164.37295532226562,
    "ent_coef": 0.1256585568189621,
    "learning_rate": 0.001
  },
  {
    "episode": 963,
    "reward": 77.114702,
    "length": 88,
    "time": 20318.296103,
    "actor_loss": -6.246258735656738,
    "critic_loss": 499.3193054199219,
    "ent_coef": 0.11981303244829178,
    "learning_rate": 0.001
  },
  {
    "episode": 964,
    "reward": 62.520069,
    "length": 108,
    "time": 20337.267312,
    "actor_loss": -9.165842056274414,
    "critic_loss": 113.15868377685547,
    "ent_coef": 0.1206316202878952,
    "learning_rate": 0.001
  },
  {
    "episode": 965,
    "reward": -174.652123,
    "length": 107,
    "time": 20355.172462,
    "actor_loss": -7.469296455383301,
    "critic_loss": 11.810821533203125,
    "ent_coef": 0.12169986218214035,
    "learning_rate": 0.001
  },
  {
    "episode": 966,
    "reward": 80.392525,
    "length": 94,
    "time": 20371.460271,
    "actor_loss": -8.518359184265137,
    "critic_loss": 13.867006301879883,
    "ent_coef": 0.1230500265955925,
    "learning_rate": 0.001
  },
  {
    "episode": 967,
    "reward": 78.981646,
    "length": 85,
    "time": 20388.273764,
    "actor_loss": -6.698385238647461,
    "critic_loss": 96.15316772460938,
    "ent_coef": 0.12138261646032333,
    "learning_rate": 0.001
  },
  {
    "episode": 968,
    "reward": 69.719899,
    "length": 98,
    "time": 20405.085496,
    "actor_loss": -9.36279582977295,
    "critic_loss": 76.87347412109375,
    "ent_coef": 0.11582355946302414,
    "learning_rate": 0.001
  },
  {
    "episode": 969,
    "reward": -171.48266,
    "length": 150,
    "time": 20427.398631,
    "actor_loss": -6.538607597351074,
    "critic_loss": 46.56005096435547,
    "ent_coef": 0.11707758158445358,
    "learning_rate": 0.001
  },
  {
    "episode": 970,
    "reward": 31.556407,
    "length": 144,
    "time": 20449.902116,
    "actor_loss": -6.6024169921875,
    "critic_loss": 77.22065734863281,
    "ent_coef": 0.1126871258020401,
    "learning_rate": 0.001
  },
  {
    "episode": 971,
    "reward": 65.700394,
    "length": 103,
    "time": 20468.693153,
    "actor_loss": -9.243343353271484,
    "critic_loss": 158.3002166748047,
    "ent_coef": 0.11454793065786362,
    "learning_rate": 0.001
  },
  {
    "episode": 972,
    "reward": 75.263379,
    "length": 86,
    "time": 20482.83217,
    "actor_loss": -5.2161054611206055,
    "critic_loss": 51.349334716796875,
    "ent_coef": 0.11650381237268448,
    "learning_rate": 0.001
  },
  {
    "episode": 973,
    "reward": 64.087557,
    "length": 104,
    "time": 20499.327171,
    "actor_loss": -6.602461338043213,
    "critic_loss": 124.28984069824219,
    "ent_coef": 0.11268559843301773,
    "learning_rate": 0.001
  },
  {
    "episode": 974,
    "reward": -170.605811,
    "length": 150,
    "time": 20522.027176,
    "actor_loss": -8.085238456726074,
    "critic_loss": 63.746944427490234,
    "ent_coef": 0.11060456186532974,
    "learning_rate": 0.001
  },
  {
    "episode": 975,
    "reward": 72.068147,
    "length": 96,
    "time": 20537.778555,
    "actor_loss": -7.715898036956787,
    "critic_loss": 313.6257019042969,
    "ent_coef": 0.11214644461870193,
    "learning_rate": 0.001
  },
  {
    "episode": 976,
    "reward": 60.523292,
    "length": 116,
    "time": 20560.061477,
    "actor_loss": -9.92579174041748,
    "critic_loss": 7.715278148651123,
    "ent_coef": 0.11767110228538513,
    "learning_rate": 0.001
  },
  {
    "episode": 977,
    "reward": 68.732959,
    "length": 99,
    "time": 20575.999311,
    "actor_loss": -7.460411071777344,
    "critic_loss": 95.47206115722656,
    "ent_coef": 0.12342441082000732,
    "learning_rate": 0.001
  },
  {
    "episode": 978,
    "reward": 36.565188,
    "length": 153,
    "time": 20600.984102,
    "actor_loss": -2.988182544708252,
    "critic_loss": 20.388755798339844,
    "ent_coef": 0.13052870333194733,
    "learning_rate": 0.001
  },
  {
    "episode": 979,
    "reward": 71.938549,
    "length": 97,
    "time": 20617.907465,
    "actor_loss": -8.8978271484375,
    "critic_loss": 12.13178825378418,
    "ent_coef": 0.12848985195159912,
    "learning_rate": 0.001
  },
  {
    "episode": 980,
    "reward": 52.709577,
    "length": 127,
    "time": 20639.821561,
    "actor_loss": -10.37542724609375,
    "critic_loss": 157.45339965820312,
    "ent_coef": 0.1222381591796875,
    "learning_rate": 0.001
  },
  {
    "episode": 981,
    "reward": -235.688758,
    "length": 448,
    "time": 20701.68323,
    "actor_loss": -6.870261192321777,
    "critic_loss": 15.090187072753906,
    "ent_coef": 0.11777916550636292,
    "learning_rate": 0.001
  },
  {
    "episode": 982,
    "reward": 79.850352,
    "length": 81,
    "time": 20716.057591,
    "actor_loss": -11.367172241210938,
    "critic_loss": 28.668930053710938,
    "ent_coef": 0.11971887946128845,
    "learning_rate": 0.001
  },
  {
    "episode": 983,
    "reward": 66.163461,
    "length": 95,
    "time": 20731.623699,
    "actor_loss": -7.364126205444336,
    "critic_loss": 16.796527862548828,
    "ent_coef": 0.12967346608638763,
    "learning_rate": 0.001
  },
  {
    "episode": 984,
    "reward": 76.619959,
    "length": 87,
    "time": 20745.984877,
    "actor_loss": -5.213380813598633,
    "critic_loss": 274.4078369140625,
    "ent_coef": 0.13422396779060364,
    "learning_rate": 0.001
  },
  {
    "episode": 985,
    "reward": 69.641481,
    "length": 97,
    "time": 20763.211969,
    "actor_loss": -14.384974479675293,
    "critic_loss": 131.6644744873047,
    "ent_coef": 0.13076384365558624,
    "learning_rate": 0.001
  },
  {
    "episode": 986,
    "reward": -232.73193,
    "length": 159,
    "time": 20787.896021,
    "actor_loss": -10.62000560760498,
    "critic_loss": 141.46246337890625,
    "ent_coef": 0.1320798397064209,
    "learning_rate": 0.001
  },
  {
    "episode": 987,
    "reward": 92.852991,
    "length": 95,
    "time": 20803.124817,
    "actor_loss": -7.608966827392578,
    "critic_loss": 147.66317749023438,
    "ent_coef": 0.13412585854530334,
    "learning_rate": 0.001
  },
  {
    "episode": 988,
    "reward": 72.609288,
    "length": 92,
    "time": 20818.144936,
    "actor_loss": -14.615157127380371,
    "critic_loss": 85.64808654785156,
    "ent_coef": 0.13540206849575043,
    "learning_rate": 0.001
  },
  {
    "episode": 989,
    "reward": 61.782533,
    "length": 113,
    "time": 20836.82726,
    "actor_loss": -9.894989967346191,
    "critic_loss": 63.80633544921875,
    "ent_coef": 0.1274547129869461,
    "learning_rate": 0.001
  },
  {
    "episode": 990,
    "reward": -162.890844,
    "length": 145,
    "time": 20858.913359,
    "actor_loss": -11.304637908935547,
    "critic_loss": 352.4656677246094,
    "ent_coef": 0.12012407928705215,
    "learning_rate": 0.001
  },
  {
    "episode": 991,
    "reward": 72.438011,
    "length": 90,
    "time": 20874.517868,
    "actor_loss": -8.69434928894043,
    "critic_loss": 52.18988800048828,
    "ent_coef": 0.12039996683597565,
    "learning_rate": 0.001
  },
  {
    "episode": 992,
    "reward": 85.386416,
    "length": 77,
    "time": 20888.805604,
    "actor_loss": -3.7472407817840576,
    "critic_loss": 247.12835693359375,
    "ent_coef": 0.12414966523647308,
    "learning_rate": 0.001
  },
  {
    "episode": 993,
    "reward": 78.035812,
    "length": 88,
    "time": 20905.935435,
    "actor_loss": -9.375913619995117,
    "critic_loss": 38.90033721923828,
    "ent_coef": 0.12546856701374054,
    "learning_rate": 0.001
  },
  {
    "episode": 994,
    "reward": 77.674421,
    "length": 88,
    "time": 20920.479037,
    "actor_loss": -10.065502166748047,
    "critic_loss": 43.254112243652344,
    "ent_coef": 0.12715288996696472,
    "learning_rate": 0.001
  },
  {
    "episode": 995,
    "reward": -169.117854,
    "length": 148,
    "time": 20943.978051,
    "actor_loss": -5.950957298278809,
    "critic_loss": 410.96728515625,
    "ent_coef": 0.13545501232147217,
    "learning_rate": 0.001
  },
  {
    "episode": 996,
    "reward": 75.355373,
    "length": 88,
    "time": 20959.875638,
    "actor_loss": -12.80833625793457,
    "critic_loss": 100.70889282226562,
    "ent_coef": 0.13472618162631989,
    "learning_rate": 0.001
  },
  {
    "episode": 997,
    "reward": 77.233029,
    "length": 84,
    "time": 20976.179866,
    "actor_loss": -11.199667930603027,
    "critic_loss": 36.86952209472656,
    "ent_coef": 0.13239546120166779,
    "learning_rate": 0.001
  },
  {
    "episode": 998,
    "reward": 73.594109,
    "length": 88,
    "time": 20990.755005,
    "actor_loss": -9.643793106079102,
    "critic_loss": 97.871826171875,
    "ent_coef": 0.12690384685993195,
    "learning_rate": 0.001
  },
  {
    "episode": 999,
    "reward": 72.523329,
    "length": 95,
    "time": 21007.686314,
    "actor_loss": -6.26129150390625,
    "critic_loss": 10.718387603759766,
    "ent_coef": 0.12437088042497635,
    "learning_rate": 0.001
  },
  {
    "episode": 1000,
    "reward": 79.750193,
    "length": 83,
    "time": 21021.718781,
    "actor_loss": -8.728860855102539,
    "critic_loss": 103.3625717163086,
    "ent_coef": 0.11866845190525055,
    "learning_rate": 0.001
  },
  {
    "episode": 1001,
    "reward": 84.523928,
    "length": 74,
    "time": 21034.491394,
    "actor_loss": -2.8663761615753174,
    "critic_loss": 38.87392807006836,
    "ent_coef": 0.11676133424043655,
    "learning_rate": 0.001
  },
  {
    "episode": 1002,
    "reward": 73.550507,
    "length": 88,
    "time": 21050.067014,
    "actor_loss": -9.337499618530273,
    "critic_loss": 16.787187576293945,
    "ent_coef": 0.11839115619659424,
    "learning_rate": 0.001
  },
  {
    "episode": 1003,
    "reward": 67.034412,
    "length": 103,
    "time": 21067.432148,
    "actor_loss": -6.525413990020752,
    "critic_loss": 164.95819091796875,
    "ent_coef": 0.11692990362644196,
    "learning_rate": 0.001
  },
  {
    "episode": 1004,
    "reward": 74.12437,
    "length": 83,
    "time": 21084.019227,
    "actor_loss": -4.802326202392578,
    "critic_loss": 156.59385681152344,
    "ent_coef": 0.11712568253278732,
    "learning_rate": 0.001
  },
  {
    "episode": 1005,
    "reward": 76.783439,
    "length": 89,
    "time": 21102.77291,
    "actor_loss": -6.240192890167236,
    "critic_loss": 318.9266662597656,
    "ent_coef": 0.11879079788923264,
    "learning_rate": 0.001
  },
  {
    "episode": 1006,
    "reward": 69.102831,
    "length": 104,
    "time": 21119.216142,
    "actor_loss": -7.305947780609131,
    "critic_loss": 310.14947509765625,
    "ent_coef": 0.11503251641988754,
    "learning_rate": 0.001
  },
  {
    "episode": 1007,
    "reward": 74.859213,
    "length": 84,
    "time": 21133.988378,
    "actor_loss": -8.876923561096191,
    "critic_loss": 13.555618286132812,
    "ent_coef": 0.11418314278125763,
    "learning_rate": 0.001
  },
  {
    "episode": 1008,
    "reward": 70.469721,
    "length": 92,
    "time": 21149.72006,
    "actor_loss": -7.415464401245117,
    "critic_loss": 31.24911117553711,
    "ent_coef": 0.11228158324956894,
    "learning_rate": 0.001
  },
  {
    "episode": 1009,
    "reward": 78.473967,
    "length": 80,
    "time": 21165.095571,
    "actor_loss": -6.453085422515869,
    "critic_loss": 62.54769515991211,
    "ent_coef": 0.11667077988386154,
    "learning_rate": 0.001
  },
  {
    "episode": 1010,
    "reward": 75.792183,
    "length": 85,
    "time": 21178.968289,
    "actor_loss": -8.700828552246094,
    "critic_loss": 61.85917663574219,
    "ent_coef": 0.1222631111741066,
    "learning_rate": 0.001
  },
  {
    "episode": 1011,
    "reward": 73.666067,
    "length": 93,
    "time": 21195.257784,
    "actor_loss": -10.844743728637695,
    "critic_loss": 132.88101196289062,
    "ent_coef": 0.12368753552436829,
    "learning_rate": 0.001
  },
  {
    "episode": 1012,
    "reward": 75.898364,
    "length": 79,
    "time": 21209.643046,
    "actor_loss": -10.613813400268555,
    "critic_loss": 71.66095733642578,
    "ent_coef": 0.1247391477227211,
    "learning_rate": 0.001
  },
  {
    "episode": 1013,
    "reward": 79.67367,
    "length": 75,
    "time": 21224.019228,
    "actor_loss": -12.955389022827148,
    "critic_loss": 51.329139709472656,
    "ent_coef": 0.13006918132305145,
    "learning_rate": 0.001
  },
  {
    "episode": 1014,
    "reward": 84.504715,
    "length": 76,
    "time": 21237.272618,
    "actor_loss": -7.49761962890625,
    "critic_loss": 241.54867553710938,
    "ent_coef": 0.1319732517004013,
    "learning_rate": 0.001
  },
  {
    "episode": 1015,
    "reward": 17.333668,
    "length": 171,
    "time": 21262.680089,
    "actor_loss": -11.066007614135742,
    "critic_loss": 157.50228881835938,
    "ent_coef": 0.12314749509096146,
    "learning_rate": 0.001
  },
  {
    "episode": 1016,
    "reward": 44.430684,
    "length": 134,
    "time": 21284.805005,
    "actor_loss": -14.515918731689453,
    "critic_loss": 25.697982788085938,
    "ent_coef": 0.12146332114934921,
    "learning_rate": 0.001
  },
  {
    "episode": 1017,
    "reward": 37.899701,
    "length": 148,
    "time": 21307.416823,
    "actor_loss": -9.145650863647461,
    "critic_loss": 27.747516632080078,
    "ent_coef": 0.1187843382358551,
    "learning_rate": 0.001
  },
  {
    "episode": 1018,
    "reward": 73.860977,
    "length": 90,
    "time": 21324.98115,
    "actor_loss": -11.226334571838379,
    "critic_loss": 75.36305236816406,
    "ent_coef": 0.11932409554719925,
    "learning_rate": 0.001
  },
  {
    "episode": 1019,
    "reward": -281.3397,
    "length": 214,
    "time": 21357.401477,
    "actor_loss": -11.201953887939453,
    "critic_loss": 13.512598037719727,
    "ent_coef": 0.1178107038140297,
    "learning_rate": 0.001
  },
  {
    "episode": 1020,
    "reward": 87.545325,
    "length": 83,
    "time": 21371.251894,
    "actor_loss": -5.8355512619018555,
    "critic_loss": 3.078453540802002,
    "ent_coef": 0.11762398481369019,
    "learning_rate": 0.001
  },
  {
    "episode": 1021,
    "reward": 78.406533,
    "length": 82,
    "time": 21386.907394,
    "actor_loss": -8.043747901916504,
    "critic_loss": 34.00048065185547,
    "ent_coef": 0.11830701678991318,
    "learning_rate": 0.001
  },
  {
    "episode": 1022,
    "reward": 75.274081,
    "length": 86,
    "time": 21402.335699,
    "actor_loss": -8.359559059143066,
    "critic_loss": 60.36412048339844,
    "ent_coef": 0.11657169461250305,
    "learning_rate": 0.001
  },
  {
    "episode": 1023,
    "reward": 74.362281,
    "length": 94,
    "time": 21417.690007,
    "actor_loss": -13.411635398864746,
    "critic_loss": 98.166015625,
    "ent_coef": 0.11832874268293381,
    "learning_rate": 0.001
  },
  {
    "episode": 1024,
    "reward": 74.964995,
    "length": 99,
    "time": 21433.611777,
    "actor_loss": -5.706818580627441,
    "critic_loss": 42.773555755615234,
    "ent_coef": 0.11196617037057877,
    "learning_rate": 0.001
  },
  {
    "episode": 1025,
    "reward": 81.881844,
    "length": 80,
    "time": 21448.337738,
    "actor_loss": -13.076122283935547,
    "critic_loss": 316.19012451171875,
    "ent_coef": 0.1084909588098526,
    "learning_rate": 0.001
  },
  {
    "episode": 1026,
    "reward": 73.730647,
    "length": 92,
    "time": 21464.353025,
    "actor_loss": -13.5936279296875,
    "critic_loss": 81.72220611572266,
    "ent_coef": 0.10557635128498077,
    "learning_rate": 0.001
  },
  {
    "episode": 1027,
    "reward": 78.743654,
    "length": 83,
    "time": 21479.993418,
    "actor_loss": -8.927070617675781,
    "critic_loss": 73.38737487792969,
    "ent_coef": 0.10125794261693954,
    "learning_rate": 0.001
  },
  {
    "episode": 1028,
    "reward": 74.010336,
    "length": 87,
    "time": 21494.360419,
    "actor_loss": -15.527847290039062,
    "critic_loss": 181.93299865722656,
    "ent_coef": 0.1030997782945633,
    "learning_rate": 0.001
  },
  {
    "episode": 1029,
    "reward": 69.009638,
    "length": 101,
    "time": 21510.50711,
    "actor_loss": -13.631916046142578,
    "critic_loss": 55.577674865722656,
    "ent_coef": 0.1020055040717125,
    "learning_rate": 0.001
  },
  {
    "episode": 1030,
    "reward": 75.454328,
    "length": 88,
    "time": 21527.049871,
    "actor_loss": -8.50243854522705,
    "critic_loss": 453.802734375,
    "ent_coef": 0.10541002452373505,
    "learning_rate": 0.001
  },
  {
    "episode": 1031,
    "reward": 82.786198,
    "length": 77,
    "time": 21542.280994,
    "actor_loss": -11.714160919189453,
    "critic_loss": 165.061767578125,
    "ent_coef": 0.10451917350292206,
    "learning_rate": 0.001
  },
  {
    "episode": 1032,
    "reward": 77.107511,
    "length": 87,
    "time": 21558.648815,
    "actor_loss": -8.63433837890625,
    "critic_loss": 169.70059204101562,
    "ent_coef": 0.10332708060741425,
    "learning_rate": 0.001
  },
  {
    "episode": 1033,
    "reward": 80.469533,
    "length": 81,
    "time": 21572.263944,
    "actor_loss": -11.095582962036133,
    "critic_loss": 64.4937744140625,
    "ent_coef": 0.10493084788322449,
    "learning_rate": 0.001
  },
  {
    "episode": 1034,
    "reward": 75.782971,
    "length": 90,
    "time": 21587.826616,
    "actor_loss": -15.357501029968262,
    "critic_loss": 58.46669006347656,
    "ent_coef": 0.10560022294521332,
    "learning_rate": 0.001
  },
  {
    "episode": 1035,
    "reward": 84.186127,
    "length": 77,
    "time": 21600.795952,
    "actor_loss": -16.163410186767578,
    "critic_loss": 78.04427337646484,
    "ent_coef": 0.10804692655801773,
    "learning_rate": 0.001
  },
  {
    "episode": 1036,
    "reward": 79.66923,
    "length": 76,
    "time": 21614.820684,
    "actor_loss": -8.14799690246582,
    "critic_loss": 138.75424194335938,
    "ent_coef": 0.11030277609825134,
    "learning_rate": 0.001
  },
  {
    "episode": 1037,
    "reward": 71.348369,
    "length": 94,
    "time": 21630.848886,
    "actor_loss": -11.600147247314453,
    "critic_loss": 153.92556762695312,
    "ent_coef": 0.11417319625616074,
    "learning_rate": 0.001
  },
  {
    "episode": 1038,
    "reward": -171.463065,
    "length": 147,
    "time": 21653.227139,
    "actor_loss": -5.511696815490723,
    "critic_loss": 12.658391952514648,
    "ent_coef": 0.11061927676200867,
    "learning_rate": 0.001
  },
  {
    "episode": 1039,
    "reward": 74.486135,
    "length": 89,
    "time": 21669.25202,
    "actor_loss": -7.088155746459961,
    "critic_loss": 271.8959045410156,
    "ent_coef": 0.11085570603609085,
    "learning_rate": 0.001
  },
  {
    "episode": 1040,
    "reward": 85.761487,
    "length": 72,
    "time": 21681.658423,
    "actor_loss": -8.902729034423828,
    "critic_loss": 17.364124298095703,
    "ent_coef": 0.11023428291082382,
    "learning_rate": 0.001
  },
  {
    "episode": 1041,
    "reward": 86.405123,
    "length": 69,
    "time": 21696.594313,
    "actor_loss": -14.898616790771484,
    "critic_loss": 320.6636962890625,
    "ent_coef": 0.115256667137146,
    "learning_rate": 0.001
  },
  {
    "episode": 1042,
    "reward": 84.702357,
    "length": 73,
    "time": 21710.024858,
    "actor_loss": -11.66590690612793,
    "critic_loss": 42.998069763183594,
    "ent_coef": 0.11866378039121628,
    "learning_rate": 0.001
  },
  {
    "episode": 1043,
    "reward": 82.117373,
    "length": 81,
    "time": 21724.715286,
    "actor_loss": -8.779216766357422,
    "critic_loss": 108.12007141113281,
    "ent_coef": 0.12293566018342972,
    "learning_rate": 0.001
  },
  {
    "episode": 1044,
    "reward": 81.950476,
    "length": 80,
    "time": 21740.775848,
    "actor_loss": -12.451286315917969,
    "critic_loss": 51.58042907714844,
    "ent_coef": 0.12910526990890503,
    "learning_rate": 0.001
  },
  {
    "episode": 1045,
    "reward": 81.965921,
    "length": 78,
    "time": 21753.886372,
    "actor_loss": -8.493173599243164,
    "critic_loss": 9.532493591308594,
    "ent_coef": 0.13432268798351288,
    "learning_rate": 0.001
  },
  {
    "episode": 1046,
    "reward": -171.84965,
    "length": 149,
    "time": 21779.717046,
    "actor_loss": -10.094043731689453,
    "critic_loss": 339.3973388671875,
    "ent_coef": 0.131056547164917,
    "learning_rate": 0.001
  },
  {
    "episode": 1047,
    "reward": 73.121143,
    "length": 90,
    "time": 21796.407873,
    "actor_loss": -9.448205947875977,
    "critic_loss": 571.6356201171875,
    "ent_coef": 0.12574277818202972,
    "learning_rate": 0.001
  },
  {
    "episode": 1048,
    "reward": 69.175965,
    "length": 92,
    "time": 21812.674229,
    "actor_loss": -14.866470336914062,
    "critic_loss": 23.067819595336914,
    "ent_coef": 0.12209078669548035,
    "learning_rate": 0.001
  },
  {
    "episode": 1049,
    "reward": 81.139745,
    "length": 84,
    "time": 21826.73912,
    "actor_loss": -9.425774574279785,
    "critic_loss": 15.067094802856445,
    "ent_coef": 0.11890214681625366,
    "learning_rate": 0.001
  },
  {
    "episode": 1050,
    "reward": 78.54355,
    "length": 78,
    "time": 21840.798043,
    "actor_loss": -12.80685806274414,
    "critic_loss": 78.75662231445312,
    "ent_coef": 0.11757925152778625,
    "learning_rate": 0.001
  },
  {
    "episode": 1051,
    "reward": 85.96972,
    "length": 72,
    "time": 21855.448257,
    "actor_loss": -12.458230972290039,
    "critic_loss": 105.20794677734375,
    "ent_coef": 0.11995520442724228,
    "learning_rate": 0.001
  },
  {
    "episode": 1052,
    "reward": -169.1234,
    "length": 152,
    "time": 21881.314718,
    "actor_loss": -6.563282012939453,
    "critic_loss": 62.71249008178711,
    "ent_coef": 0.12233294546604156,
    "learning_rate": 0.001
  },
  {
    "episode": 1053,
    "reward": 64.189137,
    "length": 144,
    "time": 21903.701761,
    "actor_loss": -10.71213150024414,
    "critic_loss": 25.480005264282227,
    "ent_coef": 0.12484074383974075,
    "learning_rate": 0.001
  },
  {
    "episode": 1054,
    "reward": 57.725611,
    "length": 108,
    "time": 21921.446253,
    "actor_loss": -14.797011375427246,
    "critic_loss": 48.479034423828125,
    "ent_coef": 0.12349840998649597,
    "learning_rate": 0.001
  },
  {
    "episode": 1055,
    "reward": 84.692012,
    "length": 74,
    "time": 21937.898818,
    "actor_loss": -15.442097663879395,
    "critic_loss": 25.203113555908203,
    "ent_coef": 0.12309172004461288,
    "learning_rate": 0.001
  },
  {
    "episode": 1056,
    "reward": 80.434348,
    "length": 83,
    "time": 21951.825695,
    "actor_loss": -17.398096084594727,
    "critic_loss": 79.8477554321289,
    "ent_coef": 0.11911265552043915,
    "learning_rate": 0.001
  },
  {
    "episode": 1057,
    "reward": 73.116753,
    "length": 93,
    "time": 21970.847515,
    "actor_loss": -17.875638961791992,
    "critic_loss": 72.13658142089844,
    "ent_coef": 0.11490228772163391,
    "learning_rate": 0.001
  },
  {
    "episode": 1058,
    "reward": -163.583836,
    "length": 155,
    "time": 21995.827061,
    "actor_loss": -8.54955768585205,
    "critic_loss": 18.97170066833496,
    "ent_coef": 0.125785693526268,
    "learning_rate": 0.001
  },
  {
    "episode": 1059,
    "reward": -164.878613,
    "length": 146,
    "time": 22018.972137,
    "actor_loss": -10.531414031982422,
    "critic_loss": 8.483606338500977,
    "ent_coef": 0.1292603313922882,
    "learning_rate": 0.001
  },
  {
    "episode": 1060,
    "reward": -161.573281,
    "length": 122,
    "time": 22037.749209,
    "actor_loss": -12.381288528442383,
    "critic_loss": 107.41165161132812,
    "ent_coef": 0.13293401896953583,
    "learning_rate": 0.001
  },
  {
    "episode": 1061,
    "reward": 85.215737,
    "length": 78,
    "time": 22055.401196,
    "actor_loss": -8.570241928100586,
    "critic_loss": 38.464744567871094,
    "ent_coef": 0.13049979507923126,
    "learning_rate": 0.001
  },
  {
    "episode": 1062,
    "reward": 83.600005,
    "length": 75,
    "time": 22068.879351,
    "actor_loss": -6.412503242492676,
    "critic_loss": 83.61082458496094,
    "ent_coef": 0.13110783696174622,
    "learning_rate": 0.001
  },
  {
    "episode": 1063,
    "reward": 88.594322,
    "length": 67,
    "time": 22081.197204,
    "actor_loss": -17.999507904052734,
    "critic_loss": 70.13603210449219,
    "ent_coef": 0.1331317275762558,
    "learning_rate": 0.001
  },
  {
    "episode": 1064,
    "reward": 81.052251,
    "length": 76,
    "time": 22094.318647,
    "actor_loss": -14.927111625671387,
    "critic_loss": 40.750267028808594,
    "ent_coef": 0.13311290740966797,
    "learning_rate": 0.001
  },
  {
    "episode": 1065,
    "reward": 86.440952,
    "length": 71,
    "time": 22106.395406,
    "actor_loss": -14.850628852844238,
    "critic_loss": 17.99224090576172,
    "ent_coef": 0.13426119089126587,
    "learning_rate": 0.001
  },
  {
    "episode": 1066,
    "reward": 86.791604,
    "length": 69,
    "time": 22120.270693,
    "actor_loss": -13.29284954071045,
    "critic_loss": 28.040651321411133,
    "ent_coef": 0.13698935508728027,
    "learning_rate": 0.001
  },
  {
    "episode": 1067,
    "reward": 82.498725,
    "length": 80,
    "time": 22134.894787,
    "actor_loss": -9.782403945922852,
    "critic_loss": 44.27237319946289,
    "ent_coef": 0.1313309222459793,
    "learning_rate": 0.001
  },
  {
    "episode": 1068,
    "reward": 81.514,
    "length": 89,
    "time": 22150.582912,
    "actor_loss": -13.41186809539795,
    "critic_loss": 17.045551300048828,
    "ent_coef": 0.12660466134548187,
    "learning_rate": 0.001
  },
  {
    "episode": 1069,
    "reward": 77.369112,
    "length": 81,
    "time": 22166.706329,
    "actor_loss": -15.465117454528809,
    "critic_loss": 103.3830795288086,
    "ent_coef": 0.12758085131645203,
    "learning_rate": 0.001
  },
  {
    "episode": 1070,
    "reward": 77.252916,
    "length": 91,
    "time": 22185.416194,
    "actor_loss": -11.305261611938477,
    "critic_loss": 60.707275390625,
    "ent_coef": 0.1192755177617073,
    "learning_rate": 0.001
  },
  {
    "episode": 1071,
    "reward": 69.672637,
    "length": 95,
    "time": 22203.155228,
    "actor_loss": -10.018575668334961,
    "critic_loss": 8.992548942565918,
    "ent_coef": 0.10726944357156754,
    "learning_rate": 0.001
  },
  {
    "episode": 1072,
    "reward": 79.514115,
    "length": 83,
    "time": 22217.130938,
    "actor_loss": -14.517642974853516,
    "critic_loss": 10.776115417480469,
    "ent_coef": 0.1032097190618515,
    "learning_rate": 0.001
  },
  {
    "episode": 1073,
    "reward": 85.960997,
    "length": 71,
    "time": 22230.491511,
    "actor_loss": -13.7282075881958,
    "critic_loss": 145.486328125,
    "ent_coef": 0.10261929780244827,
    "learning_rate": 0.001
  },
  {
    "episode": 1074,
    "reward": -160.516737,
    "length": 142,
    "time": 22253.966819,
    "actor_loss": -14.808135986328125,
    "critic_loss": 12.52579402923584,
    "ent_coef": 0.1071753203868866,
    "learning_rate": 0.001
  },
  {
    "episode": 1075,
    "reward": 89.535951,
    "length": 65,
    "time": 22268.089021,
    "actor_loss": -14.143599510192871,
    "critic_loss": 42.389076232910156,
    "ent_coef": 0.11107302457094193,
    "learning_rate": 0.001
  },
  {
    "episode": 1076,
    "reward": 80.27815,
    "length": 81,
    "time": 22282.067526,
    "actor_loss": -14.945425987243652,
    "critic_loss": 79.84657287597656,
    "ent_coef": 0.10529574751853943,
    "learning_rate": 0.001
  },
  {
    "episode": 1077,
    "reward": 81.924673,
    "length": 78,
    "time": 22295.508336,
    "actor_loss": -14.426095962524414,
    "critic_loss": 340.72369384765625,
    "ent_coef": 0.09760257601737976,
    "learning_rate": 0.001
  },
  {
    "episode": 1078,
    "reward": -169.580117,
    "length": 164,
    "time": 22319.858377,
    "actor_loss": -15.622568130493164,
    "critic_loss": 75.83750915527344,
    "ent_coef": 0.09984628856182098,
    "learning_rate": 0.001
  },
  {
    "episode": 1079,
    "reward": 79.759559,
    "length": 79,
    "time": 22334.565987,
    "actor_loss": -15.558573722839355,
    "critic_loss": 66.27337646484375,
    "ent_coef": 0.1009829118847847,
    "learning_rate": 0.001
  },
  {
    "episode": 1080,
    "reward": 75.218508,
    "length": 87,
    "time": 22350.612841,
    "actor_loss": -11.984134674072266,
    "critic_loss": 18.53607940673828,
    "ent_coef": 0.10228220373392105,
    "learning_rate": 0.001
  },
  {
    "episode": 1081,
    "reward": 83.599831,
    "length": 74,
    "time": 22364.628279,
    "actor_loss": -11.052146911621094,
    "critic_loss": 171.84512329101562,
    "ent_coef": 0.10599109530448914,
    "learning_rate": 0.001
  },
  {
    "episode": 1082,
    "reward": 82.581024,
    "length": 81,
    "time": 22378.191414,
    "actor_loss": -13.788132667541504,
    "critic_loss": 33.14225387573242,
    "ent_coef": 0.10543790459632874,
    "learning_rate": 0.001
  },
  {
    "episode": 1083,
    "reward": 76.831732,
    "length": 83,
    "time": 22391.978074,
    "actor_loss": -8.80242919921875,
    "critic_loss": 19.959033966064453,
    "ent_coef": 0.10705095529556274,
    "learning_rate": 0.001
  },
  {
    "episode": 1084,
    "reward": 80.202326,
    "length": 80,
    "time": 22408.243387,
    "actor_loss": -15.74003791809082,
    "critic_loss": 235.33779907226562,
    "ent_coef": 0.1046658530831337,
    "learning_rate": 0.001
  },
  {
    "episode": 1085,
    "reward": 73.649762,
    "length": 93,
    "time": 22426.597333,
    "actor_loss": -18.222366333007812,
    "critic_loss": 8.83453369140625,
    "ent_coef": 0.10513364523649216,
    "learning_rate": 0.001
  },
  {
    "episode": 1086,
    "reward": 87.52191,
    "length": 69,
    "time": 22441.103276,
    "actor_loss": -16.745065689086914,
    "critic_loss": 282.6954345703125,
    "ent_coef": 0.11121039092540741,
    "learning_rate": 0.001
  },
  {
    "episode": 1087,
    "reward": 84.242061,
    "length": 77,
    "time": 22454.278904,
    "actor_loss": -14.289379119873047,
    "critic_loss": 339.45697021484375,
    "ent_coef": 0.11337223649024963,
    "learning_rate": 0.001
  },
  {
    "episode": 1088,
    "reward": 83.307865,
    "length": 83,
    "time": 22469.448595,
    "actor_loss": -18.513286590576172,
    "critic_loss": 27.316173553466797,
    "ent_coef": 0.11859261989593506,
    "learning_rate": 0.001
  },
  {
    "episode": 1089,
    "reward": 83.433786,
    "length": 81,
    "time": 22484.943888,
    "actor_loss": -14.847273826599121,
    "critic_loss": 363.51361083984375,
    "ent_coef": 0.11769388616085052,
    "learning_rate": 0.001
  },
  {
    "episode": 1090,
    "reward": 78.03716,
    "length": 82,
    "time": 22499.430362,
    "actor_loss": -12.913116455078125,
    "critic_loss": 34.53105163574219,
    "ent_coef": 0.11432547122240067,
    "learning_rate": 0.001
  },
  {
    "episode": 1091,
    "reward": 78.689869,
    "length": 79,
    "time": 22514.727701,
    "actor_loss": -14.922500610351562,
    "critic_loss": 40.88442611694336,
    "ent_coef": 0.11542854458093643,
    "learning_rate": 0.001
  },
  {
    "episode": 1092,
    "reward": 81.654658,
    "length": 83,
    "time": 22530.037141,
    "actor_loss": -10.876980781555176,
    "critic_loss": 42.322265625,
    "ent_coef": 0.11352662742137909,
    "learning_rate": 0.001
  },
  {
    "episode": 1093,
    "reward": 66.498001,
    "length": 106,
    "time": 22546.781116,
    "actor_loss": -13.040666580200195,
    "critic_loss": 461.56134033203125,
    "ent_coef": 0.10604611784219742,
    "learning_rate": 0.001
  },
  {
    "episode": 1094,
    "reward": 87.275976,
    "length": 69,
    "time": 22558.82741,
    "actor_loss": -17.865009307861328,
    "critic_loss": 87.57113647460938,
    "ent_coef": 0.10547403246164322,
    "learning_rate": 0.001
  },
  {
    "episode": 1095,
    "reward": 85.102445,
    "length": 77,
    "time": 22571.78441,
    "actor_loss": -17.793033599853516,
    "critic_loss": 31.36550521850586,
    "ent_coef": 0.10190664231777191,
    "learning_rate": 0.001
  },
  {
    "episode": 1096,
    "reward": 85.414216,
    "length": 78,
    "time": 22584.79952,
    "actor_loss": -9.41249942779541,
    "critic_loss": 11.751916885375977,
    "ent_coef": 0.10232603549957275,
    "learning_rate": 0.001
  },
  {
    "episode": 1097,
    "reward": 81.379668,
    "length": 82,
    "time": 22598.548003,
    "actor_loss": -10.098285675048828,
    "critic_loss": 17.786155700683594,
    "ent_coef": 0.1060982421040535,
    "learning_rate": 0.001
  },
  {
    "episode": 1098,
    "reward": 83.776425,
    "length": 79,
    "time": 22613.60393,
    "actor_loss": -12.819129943847656,
    "critic_loss": 19.625402450561523,
    "ent_coef": 0.11067784577608109,
    "learning_rate": 0.001
  },
  {
    "episode": 1099,
    "reward": 89.447911,
    "length": 64,
    "time": 22624.931148,
    "actor_loss": -12.261775970458984,
    "critic_loss": 164.34213256835938,
    "ent_coef": 0.1164267286658287,
    "learning_rate": 0.001
  },
  {
    "episode": 1100,
    "reward": 88.472739,
    "length": 67,
    "time": 22636.927785,
    "actor_loss": -17.677330017089844,
    "critic_loss": 147.127685546875,
    "ent_coef": 0.1210380345582962,
    "learning_rate": 0.001
  },
  {
    "episode": 1101,
    "reward": 88.83709,
    "length": 66,
    "time": 22649.534204,
    "actor_loss": -20.03253936767578,
    "critic_loss": 53.948028564453125,
    "ent_coef": 0.12427128851413727,
    "learning_rate": 0.001
  },
  {
    "episode": 1102,
    "reward": 82.823159,
    "length": 75,
    "time": 22664.114844,
    "actor_loss": -13.181591987609863,
    "critic_loss": 316.720458984375,
    "ent_coef": 0.12476995587348938,
    "learning_rate": 0.001
  },
  {
    "episode": 1103,
    "reward": 85.856334,
    "length": 76,
    "time": 22677.022969,
    "actor_loss": -18.263591766357422,
    "critic_loss": 75.5106201171875,
    "ent_coef": 0.12395652383565903,
    "learning_rate": 0.001
  },
  {
    "episode": 1104,
    "reward": 85.322813,
    "length": 72,
    "time": 22689.289301,
    "actor_loss": -11.757909774780273,
    "critic_loss": 5.972640514373779,
    "ent_coef": 0.12329717725515366,
    "learning_rate": 0.001
  },
  {
    "episode": 1105,
    "reward": 88.954913,
    "length": 66,
    "time": 22705.039069,
    "actor_loss": -17.996829986572266,
    "critic_loss": 359.80242919921875,
    "ent_coef": 0.12390673905611038,
    "learning_rate": 0.001
  },
  {
    "episode": 1106,
    "reward": 84.336837,
    "length": 78,
    "time": 22719.370299,
    "actor_loss": -15.904953002929688,
    "critic_loss": 114.98471069335938,
    "ent_coef": 0.11947309225797653,
    "learning_rate": 0.001
  },
  {
    "episode": 1107,
    "reward": 86.682295,
    "length": 70,
    "time": 22731.77187,
    "actor_loss": -15.685844421386719,
    "critic_loss": 278.5035400390625,
    "ent_coef": 0.12009822577238083,
    "learning_rate": 0.001
  },
  {
    "episode": 1108,
    "reward": 86.278998,
    "length": 71,
    "time": 22745.71286,
    "actor_loss": -19.90799331665039,
    "critic_loss": 92.07040405273438,
    "ent_coef": 0.12368237227201462,
    "learning_rate": 0.001
  },
  {
    "episode": 1109,
    "reward": 87.354982,
    "length": 68,
    "time": 22759.308252,
    "actor_loss": -14.481760025024414,
    "critic_loss": 125.91000366210938,
    "ent_coef": 0.12687301635742188,
    "learning_rate": 0.001
  },
  {
    "episode": 1110,
    "reward": 88.277821,
    "length": 67,
    "time": 22770.992696,
    "actor_loss": -17.908172607421875,
    "critic_loss": 102.38530731201172,
    "ent_coef": 0.12974430620670319,
    "learning_rate": 0.001
  },
  {
    "episode": 1111,
    "reward": 82.21504,
    "length": 78,
    "time": 22785.621221,
    "actor_loss": -14.248295783996582,
    "critic_loss": 109.0345458984375,
    "ent_coef": 0.12549050152301788,
    "learning_rate": 0.001
  },
  {
    "episode": 1112,
    "reward": 78.560734,
    "length": 82,
    "time": 22801.242682,
    "actor_loss": -14.55179500579834,
    "critic_loss": 23.729049682617188,
    "ent_coef": 0.12285871803760529,
    "learning_rate": 0.001
  },
  {
    "episode": 1113,
    "reward": 84.559061,
    "length": 74,
    "time": 22816.984226,
    "actor_loss": -11.405839920043945,
    "critic_loss": 76.24436950683594,
    "ent_coef": 0.12066306173801422,
    "learning_rate": 0.001
  },
  {
    "episode": 1114,
    "reward": 73.331498,
    "length": 83,
    "time": 22833.20342,
    "actor_loss": -15.435323715209961,
    "critic_loss": 135.2247314453125,
    "ent_coef": 0.11914185434579849,
    "learning_rate": 0.001
  },
  {
    "episode": 1115,
    "reward": 84.457075,
    "length": 73,
    "time": 22846.580697,
    "actor_loss": -16.320167541503906,
    "critic_loss": 84.92095184326172,
    "ent_coef": 0.11959288269281387,
    "learning_rate": 0.001
  },
  {
    "episode": 1116,
    "reward": 67.282894,
    "length": 96,
    "time": 22862.224101,
    "actor_loss": -14.070576667785645,
    "critic_loss": 14.977123260498047,
    "ent_coef": 0.11398140341043472,
    "learning_rate": 0.001
  },
  {
    "episode": 1117,
    "reward": 82.251878,
    "length": 77,
    "time": 22875.307806,
    "actor_loss": -20.389747619628906,
    "critic_loss": 337.9002380371094,
    "ent_coef": 0.1101747453212738,
    "learning_rate": 0.001
  },
  {
    "episode": 1118,
    "reward": 78.564907,
    "length": 81,
    "time": 22891.55592,
    "actor_loss": -24.783084869384766,
    "critic_loss": 87.47975158691406,
    "ent_coef": 0.106631338596344,
    "learning_rate": 0.001
  },
  {
    "episode": 1119,
    "reward": 81.169691,
    "length": 83,
    "time": 22908.186831,
    "actor_loss": -16.633102416992188,
    "critic_loss": 143.99522399902344,
    "ent_coef": 0.10454893112182617,
    "learning_rate": 0.001
  },
  {
    "episode": 1120,
    "reward": 75.699821,
    "length": 81,
    "time": 22923.560556,
    "actor_loss": -14.878072738647461,
    "critic_loss": 28.175090789794922,
    "ent_coef": 0.10001201927661896,
    "learning_rate": 0.001
  },
  {
    "episode": 1121,
    "reward": 76.407901,
    "length": 83,
    "time": 22939.446959,
    "actor_loss": -18.254104614257812,
    "critic_loss": 26.92938995361328,
    "ent_coef": 0.10083499550819397,
    "learning_rate": 0.001
  },
  {
    "episode": 1122,
    "reward": 81.548311,
    "length": 82,
    "time": 22953.23948,
    "actor_loss": -14.59168815612793,
    "critic_loss": 125.38044738769531,
    "ent_coef": 0.10142207890748978,
    "learning_rate": 0.001
  },
  {
    "episode": 1123,
    "reward": 71.468694,
    "length": 99,
    "time": 22970.842257,
    "actor_loss": -17.048503875732422,
    "critic_loss": 86.01876068115234,
    "ent_coef": 0.10228235274553299,
    "learning_rate": 0.001
  },
  {
    "episode": 1124,
    "reward": 84.365022,
    "length": 75,
    "time": 22986.248074,
    "actor_loss": -18.578554153442383,
    "critic_loss": 55.998191833496094,
    "ent_coef": 0.10207729786634445,
    "learning_rate": 0.001
  },
  {
    "episode": 1125,
    "reward": 85.47407,
    "length": 72,
    "time": 23000.562905,
    "actor_loss": -15.682707786560059,
    "critic_loss": 85.51945495605469,
    "ent_coef": 0.10785355418920517,
    "learning_rate": 0.001
  },
  {
    "episode": 1126,
    "reward": 83.615845,
    "length": 78,
    "time": 23015.606712,
    "actor_loss": -14.813166618347168,
    "critic_loss": 24.86426544189453,
    "ent_coef": 0.11401480436325073,
    "learning_rate": 0.001
  },
  {
    "episode": 1127,
    "reward": 73.895339,
    "length": 90,
    "time": 23031.084812,
    "actor_loss": -16.403785705566406,
    "critic_loss": 62.55894470214844,
    "ent_coef": 0.11401306092739105,
    "learning_rate": 0.001
  },
  {
    "episode": 1128,
    "reward": 75.112045,
    "length": 84,
    "time": 23046.172539,
    "actor_loss": -14.797957420349121,
    "critic_loss": 82.54840850830078,
    "ent_coef": 0.11854193359613419,
    "learning_rate": 0.001
  },
  {
    "episode": 1129,
    "reward": 71.377383,
    "length": 94,
    "time": 23062.437158,
    "actor_loss": -12.109916687011719,
    "critic_loss": 72.137451171875,
    "ent_coef": 0.11595048010349274,
    "learning_rate": 0.001
  },
  {
    "episode": 1130,
    "reward": 84.487734,
    "length": 73,
    "time": 23077.727563,
    "actor_loss": -24.07158660888672,
    "critic_loss": 83.1573486328125,
    "ent_coef": 0.11621130257844925,
    "learning_rate": 0.001
  },
  {
    "episode": 1131,
    "reward": 80.317778,
    "length": 85,
    "time": 23091.597692,
    "actor_loss": -15.624863624572754,
    "critic_loss": 27.97274398803711,
    "ent_coef": 0.1156662330031395,
    "learning_rate": 0.001
  },
  {
    "episode": 1132,
    "reward": 86.454881,
    "length": 74,
    "time": 23106.313254,
    "actor_loss": -19.531103134155273,
    "critic_loss": 101.99143981933594,
    "ent_coef": 0.1169758290052414,
    "learning_rate": 0.001
  },
  {
    "episode": 1133,
    "reward": 88.789943,
    "length": 65,
    "time": 23125.67451,
    "actor_loss": -20.149181365966797,
    "critic_loss": 9.240936279296875,
    "ent_coef": 0.11869612336158752,
    "learning_rate": 0.001
  },
  {
    "episode": 1134,
    "reward": 80.898561,
    "length": 76,
    "time": 23139.494182,
    "actor_loss": -16.05613136291504,
    "critic_loss": 52.601463317871094,
    "ent_coef": 0.11855649203062057,
    "learning_rate": 0.001
  },
  {
    "episode": 1135,
    "reward": 87.108802,
    "length": 68,
    "time": 23152.125862,
    "actor_loss": -17.965137481689453,
    "critic_loss": 122.8990478515625,
    "ent_coef": 0.12374138832092285,
    "learning_rate": 0.001
  },
  {
    "episode": 1136,
    "reward": 88.718587,
    "length": 66,
    "time": 23166.849203,
    "actor_loss": -13.925491333007812,
    "critic_loss": 28.791521072387695,
    "ent_coef": 0.12895075976848602,
    "learning_rate": 0.001
  },
  {
    "episode": 1137,
    "reward": 72.258652,
    "length": 91,
    "time": 23182.2141,
    "actor_loss": -19.13524627685547,
    "critic_loss": 78.53732299804688,
    "ent_coef": 0.12858733534812927,
    "learning_rate": 0.001
  },
  {
    "episode": 1138,
    "reward": 88.583425,
    "length": 65,
    "time": 23195.319584,
    "actor_loss": -19.73040008544922,
    "critic_loss": 19.965866088867188,
    "ent_coef": 0.12904410064220428,
    "learning_rate": 0.001
  },
  {
    "episode": 1139,
    "reward": 86.466187,
    "length": 70,
    "time": 23208.243187,
    "actor_loss": -18.401256561279297,
    "critic_loss": 113.64556884765625,
    "ent_coef": 0.12732644379138947,
    "learning_rate": 0.001
  },
  {
    "episode": 1140,
    "reward": 89.798455,
    "length": 63,
    "time": 23223.550851,
    "actor_loss": -14.697114944458008,
    "critic_loss": 6.739020824432373,
    "ent_coef": 0.1293737292289734,
    "learning_rate": 0.001
  },
  {
    "episode": 1141,
    "reward": 89.712775,
    "length": 64,
    "time": 23236.045825,
    "actor_loss": -24.431568145751953,
    "critic_loss": 18.438671112060547,
    "ent_coef": 0.13477902114391327,
    "learning_rate": 0.001
  },
  {
    "episode": 1142,
    "reward": 89.345989,
    "length": 66,
    "time": 23248.053997,
    "actor_loss": -15.779943466186523,
    "critic_loss": 232.6866912841797,
    "ent_coef": 0.133744478225708,
    "learning_rate": 0.001
  },
  {
    "episode": 1143,
    "reward": 88.439027,
    "length": 67,
    "time": 23261.368141,
    "actor_loss": -15.628137588500977,
    "critic_loss": 280.93048095703125,
    "ent_coef": 0.1332205981016159,
    "learning_rate": 0.001
  },
  {
    "episode": 1144,
    "reward": 80.338562,
    "length": 83,
    "time": 23276.006324,
    "actor_loss": -17.84013557434082,
    "critic_loss": 17.000961303710938,
    "ent_coef": 0.1286703497171402,
    "learning_rate": 0.001
  },
  {
    "episode": 1145,
    "reward": 85.824914,
    "length": 71,
    "time": 23288.944467,
    "actor_loss": -25.168638229370117,
    "critic_loss": 305.7530517578125,
    "ent_coef": 0.12467477470636368,
    "learning_rate": 0.001
  },
  {
    "episode": 1146,
    "reward": 74.012148,
    "length": 87,
    "time": 23305.80987,
    "actor_loss": -21.54561996459961,
    "critic_loss": 343.6798400878906,
    "ent_coef": 0.11975079774856567,
    "learning_rate": 0.001
  },
  {
    "episode": 1147,
    "reward": 88.279577,
    "length": 72,
    "time": 23320.633031,
    "actor_loss": -18.292804718017578,
    "critic_loss": 17.288541793823242,
    "ent_coef": 0.11791723966598511,
    "learning_rate": 0.001
  },
  {
    "episode": 1148,
    "reward": 86.814825,
    "length": 74,
    "time": 23333.210407,
    "actor_loss": -16.471744537353516,
    "critic_loss": 22.534255981445312,
    "ent_coef": 0.11614210903644562,
    "learning_rate": 0.001
  },
  {
    "episode": 1149,
    "reward": 88.242232,
    "length": 65,
    "time": 23345.784717,
    "actor_loss": -18.854473114013672,
    "critic_loss": 11.908707618713379,
    "ent_coef": 0.115840844810009,
    "learning_rate": 0.001
  },
  {
    "episode": 1150,
    "reward": 85.947746,
    "length": 75,
    "time": 23359.69648,
    "actor_loss": -19.330242156982422,
    "critic_loss": 75.92601013183594,
    "ent_coef": 0.11574849486351013,
    "learning_rate": 0.001
  },
  {
    "episode": 1151,
    "reward": 87.875543,
    "length": 73,
    "time": 23372.245052,
    "actor_loss": -19.691837310791016,
    "critic_loss": 66.60948944091797,
    "ent_coef": 0.11391739547252655,
    "learning_rate": 0.001
  },
  {
    "episode": 1152,
    "reward": 86.67168,
    "length": 72,
    "time": 23386.826575,
    "actor_loss": -21.405303955078125,
    "critic_loss": 436.70257568359375,
    "ent_coef": 0.11281536519527435,
    "learning_rate": 0.001
  },
  {
    "episode": 1153,
    "reward": 86.415579,
    "length": 73,
    "time": 23401.447782,
    "actor_loss": -16.010271072387695,
    "critic_loss": 50.8767204284668,
    "ent_coef": 0.11003094911575317,
    "learning_rate": 0.001
  },
  {
    "episode": 1154,
    "reward": 86.672662,
    "length": 70,
    "time": 23416.464122,
    "actor_loss": -24.51643943786621,
    "critic_loss": 162.32830810546875,
    "ent_coef": 0.10853825509548187,
    "learning_rate": 0.001
  },
  {
    "episode": 1155,
    "reward": 76.375462,
    "length": 93,
    "time": 23434.526084,
    "actor_loss": -14.847637176513672,
    "critic_loss": 11.571449279785156,
    "ent_coef": 0.10398455709218979,
    "learning_rate": 0.001
  },
  {
    "episode": 1156,
    "reward": 85.3503,
    "length": 73,
    "time": 23449.876089,
    "actor_loss": -21.40301513671875,
    "critic_loss": 66.75404357910156,
    "ent_coef": 0.10200322419404984,
    "learning_rate": 0.001
  },
  {
    "episode": 1157,
    "reward": 88.163061,
    "length": 66,
    "time": 23462.170475,
    "actor_loss": -15.122884750366211,
    "critic_loss": 13.176824569702148,
    "ent_coef": 0.10210710018873215,
    "learning_rate": 0.001
  },
  {
    "episode": 1158,
    "reward": 85.143826,
    "length": 77,
    "time": 23475.194954,
    "actor_loss": -24.433223724365234,
    "critic_loss": 177.77877807617188,
    "ent_coef": 0.10073793679475784,
    "learning_rate": 0.001
  },
  {
    "episode": 1159,
    "reward": 84.499134,
    "length": 78,
    "time": 23488.305641,
    "actor_loss": -19.510517120361328,
    "critic_loss": 59.748565673828125,
    "ent_coef": 0.09773050248622894,
    "learning_rate": 0.001
  },
  {
    "episode": 1160,
    "reward": 83.591381,
    "length": 80,
    "time": 23504.848963,
    "actor_loss": -19.17527961730957,
    "critic_loss": 106.47529602050781,
    "ent_coef": 0.09347216039896011,
    "learning_rate": 0.001
  },
  {
    "episode": 1161,
    "reward": 84.977794,
    "length": 75,
    "time": 23521.306575,
    "actor_loss": -18.12073516845703,
    "critic_loss": 5.5799880027771,
    "ent_coef": 0.09257861226797104,
    "learning_rate": 0.001
  },
  {
    "episode": 1162,
    "reward": 86.657226,
    "length": 72,
    "time": 23533.730154,
    "actor_loss": -19.18901824951172,
    "critic_loss": 220.26858520507812,
    "ent_coef": 0.09391666948795319,
    "learning_rate": 0.001
  },
  {
    "episode": 1163,
    "reward": 76.490299,
    "length": 86,
    "time": 23548.942745,
    "actor_loss": -15.011648178100586,
    "critic_loss": 16.02275848388672,
    "ent_coef": 0.09179572016000748,
    "learning_rate": 0.001
  },
  {
    "episode": 1164,
    "reward": 86.689253,
    "length": 72,
    "time": 23562.039627,
    "actor_loss": -20.45256805419922,
    "critic_loss": 14.824883460998535,
    "ent_coef": 0.09226349741220474,
    "learning_rate": 0.001
  },
  {
    "episode": 1165,
    "reward": 86.685459,
    "length": 71,
    "time": 23575.754747,
    "actor_loss": -28.03420639038086,
    "critic_loss": 32.37538528442383,
    "ent_coef": 0.09727432578802109,
    "learning_rate": 0.001
  },
  {
    "episode": 1166,
    "reward": 91.153156,
    "length": 62,
    "time": 23588.527534,
    "actor_loss": -12.966712951660156,
    "critic_loss": 360.7942810058594,
    "ent_coef": 0.10296142846345901,
    "learning_rate": 0.001
  },
  {
    "episode": 1167,
    "reward": 86.169821,
    "length": 75,
    "time": 23601.390285,
    "actor_loss": -14.02424430847168,
    "critic_loss": 75.91375732421875,
    "ent_coef": 0.10442828387022018,
    "learning_rate": 0.001
  },
  {
    "episode": 1168,
    "reward": 89.027445,
    "length": 64,
    "time": 23613.718669,
    "actor_loss": -12.948087692260742,
    "critic_loss": 159.97683715820312,
    "ent_coef": 0.10794933140277863,
    "learning_rate": 0.001
  },
  {
    "episode": 1169,
    "reward": -162.651713,
    "length": 147,
    "time": 23636.094116,
    "actor_loss": -16.71482276916504,
    "critic_loss": 88.9697265625,
    "ent_coef": 0.11492258310317993,
    "learning_rate": 0.001
  },
  {
    "episode": 1170,
    "reward": 89.732181,
    "length": 64,
    "time": 23649.135445,
    "actor_loss": -21.262142181396484,
    "critic_loss": 44.20972442626953,
    "ent_coef": 0.11715585738420486,
    "learning_rate": 0.001
  },
  {
    "episode": 1171,
    "reward": 87.534423,
    "length": 68,
    "time": 23661.12564,
    "actor_loss": -17.73989486694336,
    "critic_loss": 17.461347579956055,
    "ent_coef": 0.12024658173322678,
    "learning_rate": 0.001
  },
  {
    "episode": 1172,
    "reward": 86.278688,
    "length": 70,
    "time": 23676.697335,
    "actor_loss": -20.94755744934082,
    "critic_loss": 61.14870834350586,
    "ent_coef": 0.11853009462356567,
    "learning_rate": 0.001
  },
  {
    "episode": 1173,
    "reward": 84.195831,
    "length": 75,
    "time": 23691.376876,
    "actor_loss": -24.470638275146484,
    "critic_loss": 108.98522186279297,
    "ent_coef": 0.11454509198665619,
    "learning_rate": 0.001
  },
  {
    "episode": 1174,
    "reward": 84.208547,
    "length": 75,
    "time": 23704.808443,
    "actor_loss": -25.29364585876465,
    "critic_loss": 57.728431701660156,
    "ent_coef": 0.11511042714118958,
    "learning_rate": 0.001
  },
  {
    "episode": 1175,
    "reward": 80.00948,
    "length": 80,
    "time": 23720.759411,
    "actor_loss": -20.055986404418945,
    "critic_loss": 114.67477416992188,
    "ent_coef": 0.11203847825527191,
    "learning_rate": 0.001
  },
  {
    "episode": 1176,
    "reward": 71.117197,
    "length": 93,
    "time": 23735.739509,
    "actor_loss": -22.610363006591797,
    "critic_loss": 42.29510498046875,
    "ent_coef": 0.1098203957080841,
    "learning_rate": 0.001
  },
  {
    "episode": 1177,
    "reward": 89.409003,
    "length": 65,
    "time": 23748.135131,
    "actor_loss": -17.3492488861084,
    "critic_loss": 109.62366485595703,
    "ent_coef": 0.11198269575834274,
    "learning_rate": 0.001
  },
  {
    "episode": 1178,
    "reward": 90.480803,
    "length": 63,
    "time": 23761.9082,
    "actor_loss": -12.071266174316406,
    "critic_loss": 62.16954803466797,
    "ent_coef": 0.11020593345165253,
    "learning_rate": 0.001
  },
  {
    "episode": 1179,
    "reward": 90.493245,
    "length": 62,
    "time": 23774.09656,
    "actor_loss": -21.572914123535156,
    "critic_loss": 50.20585250854492,
    "ent_coef": 0.1093122586607933,
    "learning_rate": 0.001
  },
  {
    "episode": 1180,
    "reward": 88.116643,
    "length": 66,
    "time": 23787.419097,
    "actor_loss": -21.25503921508789,
    "critic_loss": 53.04525375366211,
    "ent_coef": 0.11068528890609741,
    "learning_rate": 0.001
  },
  {
    "episode": 1181,
    "reward": 89.71149,
    "length": 64,
    "time": 23801.253634,
    "actor_loss": -24.155685424804688,
    "critic_loss": 26.356670379638672,
    "ent_coef": 0.11632711440324783,
    "learning_rate": 0.001
  },
  {
    "episode": 1182,
    "reward": 81.520591,
    "length": 80,
    "time": 23816.913167,
    "actor_loss": -17.813758850097656,
    "critic_loss": 235.768310546875,
    "ent_coef": 0.11479221284389496,
    "learning_rate": 0.001
  },
  {
    "episode": 1183,
    "reward": 77.697391,
    "length": 79,
    "time": 23832.853469,
    "actor_loss": -25.251815795898438,
    "critic_loss": 20.24878692626953,
    "ent_coef": 0.11454315483570099,
    "learning_rate": 0.001
  },
  {
    "episode": 1184,
    "reward": 88.447922,
    "length": 68,
    "time": 23845.268656,
    "actor_loss": -21.322355270385742,
    "critic_loss": 54.155113220214844,
    "ent_coef": 0.11711937189102173,
    "learning_rate": 0.001
  },
  {
    "episode": 1185,
    "reward": 91.121191,
    "length": 62,
    "time": 23856.33208,
    "actor_loss": -11.967588424682617,
    "critic_loss": 86.85325622558594,
    "ent_coef": 0.12013112753629684,
    "learning_rate": 0.001
  },
  {
    "episode": 1186,
    "reward": 87.568243,
    "length": 70,
    "time": 23870.415364,
    "actor_loss": -25.473304748535156,
    "critic_loss": 153.43832397460938,
    "ent_coef": 0.12205242365598679,
    "learning_rate": 0.001
  },
  {
    "episode": 1187,
    "reward": 89.413592,
    "length": 65,
    "time": 23882.054999,
    "actor_loss": -22.38901138305664,
    "critic_loss": 201.56832885742188,
    "ent_coef": 0.12087514996528625,
    "learning_rate": 0.001
  },
  {
    "episode": 1188,
    "reward": 87.451319,
    "length": 74,
    "time": 23895.67428,
    "actor_loss": -23.251449584960938,
    "critic_loss": 70.19309997558594,
    "ent_coef": 0.11794253438711166,
    "learning_rate": 0.001
  },
  {
    "episode": 1189,
    "reward": 79.753554,
    "length": 85,
    "time": 23912.562305,
    "actor_loss": -24.812742233276367,
    "critic_loss": 101.1776123046875,
    "ent_coef": 0.11813660711050034,
    "learning_rate": 0.001
  },
  {
    "episode": 1190,
    "reward": -161.374587,
    "length": 146,
    "time": 23936.236441,
    "actor_loss": -19.96579360961914,
    "critic_loss": 23.796283721923828,
    "ent_coef": 0.11918273568153381,
    "learning_rate": 0.001
  },
  {
    "episode": 1191,
    "reward": 86.25398,
    "length": 74,
    "time": 23950.845798,
    "actor_loss": -15.958738327026367,
    "critic_loss": 47.745460510253906,
    "ent_coef": 0.11747412383556366,
    "learning_rate": 0.001
  },
  {
    "episode": 1192,
    "reward": 90.183551,
    "length": 64,
    "time": 23970.724043,
    "actor_loss": -19.18407440185547,
    "critic_loss": 83.58626556396484,
    "ent_coef": 0.11583007872104645,
    "learning_rate": 0.001
  },
  {
    "episode": 1193,
    "reward": 86.625754,
    "length": 72,
    "time": 23986.809551,
    "actor_loss": -17.932334899902344,
    "critic_loss": 52.073631286621094,
    "ent_coef": 0.11373478174209595,
    "learning_rate": 0.001
  },
  {
    "episode": 1194,
    "reward": 91.107399,
    "length": 61,
    "time": 24000.345524,
    "actor_loss": -19.144105911254883,
    "critic_loss": 8.926839828491211,
    "ent_coef": 0.11347288638353348,
    "learning_rate": 0.001
  },
  {
    "episode": 1195,
    "reward": 89.724219,
    "length": 64,
    "time": 24013.587774,
    "actor_loss": -20.898347854614258,
    "critic_loss": 34.46715545654297,
    "ent_coef": 0.11143684387207031,
    "learning_rate": 0.001
  },
  {
    "episode": 1196,
    "reward": 85.926637,
    "length": 73,
    "time": 24028.947377,
    "actor_loss": -27.28595542907715,
    "critic_loss": 137.85806274414062,
    "ent_coef": 0.1119491457939148,
    "learning_rate": 0.001
  },
  {
    "episode": 1197,
    "reward": 89.582817,
    "length": 67,
    "time": 24041.473132,
    "actor_loss": -17.01949691772461,
    "critic_loss": 42.690670013427734,
    "ent_coef": 0.12038470059633255,
    "learning_rate": 0.001
  },
  {
    "episode": 1198,
    "reward": 88.292701,
    "length": 70,
    "time": 24055.29496,
    "actor_loss": -21.079090118408203,
    "critic_loss": 12.353588104248047,
    "ent_coef": 0.12762121856212616,
    "learning_rate": 0.001
  },
  {
    "episode": 1199,
    "reward": 91.500235,
    "length": 60,
    "time": 24066.498294,
    "actor_loss": -26.627092361450195,
    "critic_loss": 95.42001342773438,
    "ent_coef": 0.13219492137432098,
    "learning_rate": 0.001
  },
  {
    "episode": 1200,
    "reward": 90.592638,
    "length": 62,
    "time": 24081.382288,
    "actor_loss": -24.588092803955078,
    "critic_loss": 158.56109619140625,
    "ent_coef": 0.1354563981294632,
    "learning_rate": 0.001
  },
  {
    "episode": 1201,
    "reward": 89.938962,
    "length": 64,
    "time": 24092.796864,
    "actor_loss": -21.331825256347656,
    "critic_loss": 109.2907943725586,
    "ent_coef": 0.13574859499931335,
    "learning_rate": 0.001
  },
  {
    "episode": 1202,
    "reward": -162.437105,
    "length": 157,
    "time": 24116.836375,
    "actor_loss": -22.449209213256836,
    "critic_loss": 6.128918647766113,
    "ent_coef": 0.14298607409000397,
    "learning_rate": 0.001
  },
  {
    "episode": 1203,
    "reward": 90.867975,
    "length": 60,
    "time": 24128.53839,
    "actor_loss": -18.302217483520508,
    "critic_loss": 179.48915100097656,
    "ent_coef": 0.14961564540863037,
    "learning_rate": 0.001
  },
  {
    "episode": 1204,
    "reward": 90.447864,
    "length": 63,
    "time": 24141.585093,
    "actor_loss": -17.91533088684082,
    "critic_loss": 58.423500061035156,
    "ent_coef": 0.14932169020175934,
    "learning_rate": 0.001
  },
  {
    "episode": 1205,
    "reward": 88.316591,
    "length": 66,
    "time": 24153.986933,
    "actor_loss": -20.2252197265625,
    "critic_loss": 102.05082702636719,
    "ent_coef": 0.1487111747264862,
    "learning_rate": 0.001
  },
  {
    "episode": 1206,
    "reward": 89.203924,
    "length": 65,
    "time": 24166.424418,
    "actor_loss": -19.094411849975586,
    "critic_loss": 313.0855712890625,
    "ent_coef": 0.1472783237695694,
    "learning_rate": 0.001
  },
  {
    "episode": 1207,
    "reward": 74.434087,
    "length": 108,
    "time": 24184.4928,
    "actor_loss": -20.361351013183594,
    "critic_loss": 35.34080505371094,
    "ent_coef": 0.14193451404571533,
    "learning_rate": 0.001
  },
  {
    "episode": 1208,
    "reward": 84.30104,
    "length": 75,
    "time": 24200.173128,
    "actor_loss": -19.302085876464844,
    "critic_loss": 100.84954833984375,
    "ent_coef": 0.13722224533557892,
    "learning_rate": 0.001
  },
  {
    "episode": 1209,
    "reward": 88.465902,
    "length": 65,
    "time": 24213.061056,
    "actor_loss": -19.422527313232422,
    "critic_loss": 113.04739379882812,
    "ent_coef": 0.13675332069396973,
    "learning_rate": 0.001
  },
  {
    "episode": 1210,
    "reward": 89.848811,
    "length": 65,
    "time": 24225.775531,
    "actor_loss": -20.709049224853516,
    "critic_loss": 4.513221740722656,
    "ent_coef": 0.13452325761318207,
    "learning_rate": 0.001
  },
  {
    "episode": 1211,
    "reward": 90.596313,
    "length": 63,
    "time": 24237.061372,
    "actor_loss": -22.508602142333984,
    "critic_loss": 7.035189628601074,
    "ent_coef": 0.13358113169670105,
    "learning_rate": 0.001
  },
  {
    "episode": 1212,
    "reward": 92.113499,
    "length": 59,
    "time": 24247.800853,
    "actor_loss": -23.532062530517578,
    "critic_loss": 204.85272216796875,
    "ent_coef": 0.13684172928333282,
    "learning_rate": 0.001
  },
  {
    "episode": 1213,
    "reward": 89.01504,
    "length": 69,
    "time": 24259.846221,
    "actor_loss": -16.889530181884766,
    "critic_loss": 284.6457824707031,
    "ent_coef": 0.13791781663894653,
    "learning_rate": 0.001
  },
  {
    "episode": 1214,
    "reward": 86.944181,
    "length": 71,
    "time": 24273.005638,
    "actor_loss": -20.271394729614258,
    "critic_loss": 15.488801956176758,
    "ent_coef": 0.13457100093364716,
    "learning_rate": 0.001
  },
  {
    "episode": 1215,
    "reward": 86.510954,
    "length": 71,
    "time": 24286.310227,
    "actor_loss": -22.485952377319336,
    "critic_loss": 157.33258056640625,
    "ent_coef": 0.1302468478679657,
    "learning_rate": 0.001
  },
  {
    "episode": 1216,
    "reward": 88.301023,
    "length": 65,
    "time": 24300.704859,
    "actor_loss": -23.552467346191406,
    "critic_loss": 135.48556518554688,
    "ent_coef": 0.1286890059709549,
    "learning_rate": 0.001
  },
  {
    "episode": 1217,
    "reward": 90.697376,
    "length": 63,
    "time": 24313.946189,
    "actor_loss": -22.426403045654297,
    "critic_loss": 6.001157760620117,
    "ent_coef": 0.12474970519542694,
    "learning_rate": 0.001
  },
  {
    "episode": 1218,
    "reward": 87.142517,
    "length": 67,
    "time": 24326.517452,
    "actor_loss": -18.782691955566406,
    "critic_loss": 13.088935852050781,
    "ent_coef": 0.11903608590364456,
    "learning_rate": 0.001
  },
  {
    "episode": 1219,
    "reward": 89.458085,
    "length": 63,
    "time": 24339.834882,
    "actor_loss": -19.484294891357422,
    "critic_loss": 51.57837677001953,
    "ent_coef": 0.12054186314344406,
    "learning_rate": 0.001
  },
  {
    "episode": 1220,
    "reward": 90.393723,
    "length": 63,
    "time": 24351.702616,
    "actor_loss": -24.068283081054688,
    "critic_loss": 348.5041198730469,
    "ent_coef": 0.12375964969396591,
    "learning_rate": 0.001
  },
  {
    "episode": 1221,
    "reward": 88.321421,
    "length": 70,
    "time": 24363.928392,
    "actor_loss": -31.452144622802734,
    "critic_loss": 67.80968475341797,
    "ent_coef": 0.11970441788434982,
    "learning_rate": 0.001
  },
  {
    "episode": 1222,
    "reward": 88.654896,
    "length": 65,
    "time": 24375.872453,
    "actor_loss": -18.64519500732422,
    "critic_loss": 52.71741485595703,
    "ent_coef": 0.12260212749242783,
    "learning_rate": 0.001
  },
  {
    "episode": 1223,
    "reward": 89.518874,
    "length": 68,
    "time": 24387.807543,
    "actor_loss": -24.457130432128906,
    "critic_loss": 109.01361083984375,
    "ent_coef": 0.12241373211145401,
    "learning_rate": 0.001
  },
  {
    "episode": 1224,
    "reward": 89.382515,
    "length": 69,
    "time": 24401.700256,
    "actor_loss": -23.905364990234375,
    "critic_loss": 430.83709716796875,
    "ent_coef": 0.12106066197156906,
    "learning_rate": 0.001
  },
  {
    "episode": 1225,
    "reward": -155.950558,
    "length": 126,
    "time": 24420.874151,
    "actor_loss": -26.5172176361084,
    "critic_loss": 121.45695495605469,
    "ent_coef": 0.1167360320687294,
    "learning_rate": 0.001
  },
  {
    "episode": 1226,
    "reward": 89.683463,
    "length": 64,
    "time": 24435.778836,
    "actor_loss": -17.90070343017578,
    "critic_loss": 9.761978149414062,
    "ent_coef": 0.11461152881383896,
    "learning_rate": 0.001
  },
  {
    "episode": 1227,
    "reward": 90.909983,
    "length": 61,
    "time": 24447.077794,
    "actor_loss": -20.91341209411621,
    "critic_loss": 79.43236541748047,
    "ent_coef": 0.12026703357696533,
    "learning_rate": 0.001
  },
  {
    "episode": 1228,
    "reward": 88.992265,
    "length": 65,
    "time": 24458.477842,
    "actor_loss": -24.430789947509766,
    "critic_loss": 50.053955078125,
    "ent_coef": 0.12198682129383087,
    "learning_rate": 0.001
  },
  {
    "episode": 1229,
    "reward": 84.423218,
    "length": 76,
    "time": 24471.525995,
    "actor_loss": -20.917591094970703,
    "critic_loss": 77.92269134521484,
    "ent_coef": 0.11623169481754303,
    "learning_rate": 0.001
  },
  {
    "episode": 1230,
    "reward": 89.166353,
    "length": 66,
    "time": 24485.480376,
    "actor_loss": -24.065887451171875,
    "critic_loss": 59.154117584228516,
    "ent_coef": 0.1121860072016716,
    "learning_rate": 0.001
  },
  {
    "episode": 1231,
    "reward": 88.700489,
    "length": 65,
    "time": 24497.15634,
    "actor_loss": -22.85080337524414,
    "critic_loss": 109.25192260742188,
    "ent_coef": 0.11677388101816177,
    "learning_rate": 0.001
  },
  {
    "episode": 1232,
    "reward": 91.548046,
    "length": 60,
    "time": 24508.429992,
    "actor_loss": -24.787517547607422,
    "critic_loss": 10.345706939697266,
    "ent_coef": 0.12246008962392807,
    "learning_rate": 0.001
  },
  {
    "episode": 1233,
    "reward": 90.354763,
    "length": 62,
    "time": 24522.663529,
    "actor_loss": -24.840822219848633,
    "critic_loss": 94.14408874511719,
    "ent_coef": 0.12846609950065613,
    "learning_rate": 0.001
  },
  {
    "episode": 1234,
    "reward": 90.222855,
    "length": 63,
    "time": 24534.588204,
    "actor_loss": -21.186805725097656,
    "critic_loss": 82.6162109375,
    "ent_coef": 0.1261734962463379,
    "learning_rate": 0.001
  },
  {
    "episode": 1235,
    "reward": 77.346827,
    "length": 79,
    "time": 24548.809005,
    "actor_loss": -20.79216194152832,
    "critic_loss": 132.08551025390625,
    "ent_coef": 0.12442966550588608,
    "learning_rate": 0.001
  },
  {
    "episode": 1236,
    "reward": 82.768341,
    "length": 78,
    "time": 24561.947504,
    "actor_loss": -21.11057472229004,
    "critic_loss": 34.908138275146484,
    "ent_coef": 0.12216001749038696,
    "learning_rate": 0.001
  },
  {
    "episode": 1237,
    "reward": 83.000665,
    "length": 79,
    "time": 24578.663728,
    "actor_loss": -23.680347442626953,
    "critic_loss": 105.62395477294922,
    "ent_coef": 0.12127500772476196,
    "learning_rate": 0.001
  },
  {
    "episode": 1238,
    "reward": 77.595971,
    "length": 83,
    "time": 24594.675951,
    "actor_loss": -24.909257888793945,
    "critic_loss": 7.506601810455322,
    "ent_coef": 0.1249779760837555,
    "learning_rate": 0.001
  },
  {
    "episode": 1239,
    "reward": 88.556749,
    "length": 66,
    "time": 24606.452071,
    "actor_loss": -22.836925506591797,
    "critic_loss": 16.129777908325195,
    "ent_coef": 0.1266964226961136,
    "learning_rate": 0.001
  },
  {
    "episode": 1240,
    "reward": 82.547698,
    "length": 75,
    "time": 24621.403418,
    "actor_loss": -20.285011291503906,
    "critic_loss": 25.94660758972168,
    "ent_coef": 0.12917040288448334,
    "learning_rate": 0.001
  },
  {
    "episode": 1241,
    "reward": 82.898202,
    "length": 76,
    "time": 24634.470235,
    "actor_loss": -26.69655418395996,
    "critic_loss": 56.012203216552734,
    "ent_coef": 0.12681441009044647,
    "learning_rate": 0.001
  },
  {
    "episode": 1242,
    "reward": 73.752622,
    "length": 88,
    "time": 24649.356061,
    "actor_loss": -24.103734970092773,
    "critic_loss": 79.67432403564453,
    "ent_coef": 0.12005891650915146,
    "learning_rate": 0.001
  },
  {
    "episode": 1243,
    "reward": 84.841582,
    "length": 71,
    "time": 24663.839061,
    "actor_loss": -27.39773941040039,
    "critic_loss": 51.47846603393555,
    "ent_coef": 0.1179262325167656,
    "learning_rate": 0.001
  },
  {
    "episode": 1244,
    "reward": 83.19962,
    "length": 81,
    "time": 24677.476704,
    "actor_loss": -23.81678009033203,
    "critic_loss": 8.163182258605957,
    "ent_coef": 0.11732245236635208,
    "learning_rate": 0.001
  },
  {
    "episode": 1245,
    "reward": 85.40489,
    "length": 69,
    "time": 24689.813313,
    "actor_loss": -21.72368621826172,
    "critic_loss": 418.75469970703125,
    "ent_coef": 0.11786661297082901,
    "learning_rate": 0.001
  },
  {
    "episode": 1246,
    "reward": 85.005862,
    "length": 79,
    "time": 24703.028428,
    "actor_loss": -24.144014358520508,
    "critic_loss": 130.86871337890625,
    "ent_coef": 0.1169835552573204,
    "learning_rate": 0.001
  },
  {
    "episode": 1247,
    "reward": 79.556269,
    "length": 85,
    "time": 24717.440937,
    "actor_loss": -24.33511734008789,
    "critic_loss": 66.43038940429688,
    "ent_coef": 0.11770710349082947,
    "learning_rate": 0.001
  },
  {
    "episode": 1248,
    "reward": 79.679131,
    "length": 79,
    "time": 24731.872637,
    "actor_loss": -20.5427303314209,
    "critic_loss": 229.3897705078125,
    "ent_coef": 0.1184183806180954,
    "learning_rate": 0.001
  },
  {
    "episode": 1249,
    "reward": 83.148132,
    "length": 74,
    "time": 24745.91868,
    "actor_loss": -16.89883804321289,
    "critic_loss": 13.872856140136719,
    "ent_coef": 0.12120861560106277,
    "learning_rate": 0.001
  },
  {
    "episode": 1250,
    "reward": 83.860165,
    "length": 73,
    "time": 24758.336652,
    "actor_loss": -23.9575252532959,
    "critic_loss": 97.65020751953125,
    "ent_coef": 0.1243072897195816,
    "learning_rate": 0.001
  },
  {
    "episode": 1251,
    "reward": 83.721255,
    "length": 75,
    "time": 24772.190165,
    "actor_loss": -22.9180908203125,
    "critic_loss": 10.011237144470215,
    "ent_coef": 0.12338695675134659,
    "learning_rate": 0.001
  },
  {
    "episode": 1252,
    "reward": 90.278204,
    "length": 63,
    "time": 24783.367131,
    "actor_loss": -19.07349395751953,
    "critic_loss": 22.508073806762695,
    "ent_coef": 0.1287376433610916,
    "learning_rate": 0.001
  },
  {
    "episode": 1253,
    "reward": 88.666534,
    "length": 65,
    "time": 24797.330307,
    "actor_loss": -25.230241775512695,
    "critic_loss": 46.135868072509766,
    "ent_coef": 0.12987710535526276,
    "learning_rate": 0.001
  },
  {
    "episode": 1254,
    "reward": 87.593177,
    "length": 67,
    "time": 24809.829559,
    "actor_loss": -18.842967987060547,
    "critic_loss": 12.881542205810547,
    "ent_coef": 0.13170337677001953,
    "learning_rate": 0.001
  },
  {
    "episode": 1255,
    "reward": 84.479212,
    "length": 72,
    "time": 24822.217905,
    "actor_loss": -21.49683952331543,
    "critic_loss": 84.65415954589844,
    "ent_coef": 0.13032841682434082,
    "learning_rate": 0.001
  },
  {
    "episode": 1256,
    "reward": 85.535293,
    "length": 72,
    "time": 24835.832158,
    "actor_loss": -25.440624237060547,
    "critic_loss": 107.4971923828125,
    "ent_coef": 0.13148997724056244,
    "learning_rate": 0.001
  },
  {
    "episode": 1257,
    "reward": 76.859495,
    "length": 89,
    "time": 24851.434105,
    "actor_loss": -25.238075256347656,
    "critic_loss": 68.25697326660156,
    "ent_coef": 0.13084080815315247,
    "learning_rate": 0.001
  },
  {
    "episode": 1258,
    "reward": 87.622989,
    "length": 67,
    "time": 24865.16202,
    "actor_loss": -24.397781372070312,
    "critic_loss": 82.98157501220703,
    "ent_coef": 0.1348702609539032,
    "learning_rate": 0.001
  },
  {
    "episode": 1259,
    "reward": 84.796905,
    "length": 77,
    "time": 24878.932401,
    "actor_loss": -24.602481842041016,
    "critic_loss": 9.790730476379395,
    "ent_coef": 0.14073963463306427,
    "learning_rate": 0.001
  },
  {
    "episode": 1260,
    "reward": 90.295871,
    "length": 62,
    "time": 24890.997559,
    "actor_loss": -24.50910186767578,
    "critic_loss": 129.04379272460938,
    "ent_coef": 0.14147864282131195,
    "learning_rate": 0.001
  },
  {
    "episode": 1261,
    "reward": 88.610032,
    "length": 65,
    "time": 24905.168739,
    "actor_loss": -22.978740692138672,
    "critic_loss": 16.20416259765625,
    "ent_coef": 0.14038191735744476,
    "learning_rate": 0.001
  },
  {
    "episode": 1262,
    "reward": 78.57888,
    "length": 84,
    "time": 24919.610953,
    "actor_loss": -19.46079444885254,
    "critic_loss": 22.287857055664062,
    "ent_coef": 0.1358422040939331,
    "learning_rate": 0.001
  },
  {
    "episode": 1263,
    "reward": 80.51124,
    "length": 78,
    "time": 24934.088271,
    "actor_loss": -24.465167999267578,
    "critic_loss": 72.69335174560547,
    "ent_coef": 0.1326969414949417,
    "learning_rate": 0.001
  },
  {
    "episode": 1264,
    "reward": 80.202921,
    "length": 79,
    "time": 24949.122241,
    "actor_loss": -21.971073150634766,
    "critic_loss": 60.74594497680664,
    "ent_coef": 0.13341005146503448,
    "learning_rate": 0.001
  },
  {
    "episode": 1265,
    "reward": 86.176015,
    "length": 70,
    "time": 24961.430654,
    "actor_loss": -21.94894027709961,
    "critic_loss": 113.17652893066406,
    "ent_coef": 0.13226112723350525,
    "learning_rate": 0.001
  },
  {
    "episode": 1266,
    "reward": 84.138749,
    "length": 72,
    "time": 24974.692074,
    "actor_loss": -26.792770385742188,
    "critic_loss": 59.924530029296875,
    "ent_coef": 0.13294711709022522,
    "learning_rate": 0.001
  },
  {
    "episode": 1267,
    "reward": 82.422556,
    "length": 75,
    "time": 24987.65109,
    "actor_loss": -21.14715003967285,
    "critic_loss": 8.515481948852539,
    "ent_coef": 0.13556495308876038,
    "learning_rate": 0.001
  },
  {
    "episode": 1268,
    "reward": 86.561667,
    "length": 69,
    "time": 24999.813675,
    "actor_loss": -28.902610778808594,
    "critic_loss": 51.013282775878906,
    "ent_coef": 0.13413730263710022,
    "learning_rate": 0.001
  },
  {
    "episode": 1269,
    "reward": 81.921124,
    "length": 77,
    "time": 25012.852233,
    "actor_loss": -22.593564987182617,
    "critic_loss": 16.66448974609375,
    "ent_coef": 0.13102154433727264,
    "learning_rate": 0.001
  },
  {
    "episode": 1270,
    "reward": -160.927758,
    "length": 135,
    "time": 25034.259839,
    "actor_loss": -28.978099822998047,
    "critic_loss": 21.83554458618164,
    "ent_coef": 0.1283572018146515,
    "learning_rate": 0.001
  },
  {
    "episode": 1271,
    "reward": 88.582075,
    "length": 67,
    "time": 25047.230741,
    "actor_loss": -27.5189208984375,
    "critic_loss": 63.61921691894531,
    "ent_coef": 0.1260165274143219,
    "learning_rate": 0.001
  },
  {
    "episode": 1272,
    "reward": 85.677319,
    "length": 70,
    "time": 25060.575011,
    "actor_loss": -22.943984985351562,
    "critic_loss": 68.38397216796875,
    "ent_coef": 0.12429063022136688,
    "learning_rate": 0.001
  },
  {
    "episode": 1273,
    "reward": 83.996079,
    "length": 77,
    "time": 25074.750307,
    "actor_loss": -25.68020248413086,
    "critic_loss": 85.22128295898438,
    "ent_coef": 0.11959156394004822,
    "learning_rate": 0.001
  },
  {
    "episode": 1274,
    "reward": 78.227984,
    "length": 89,
    "time": 25091.262566,
    "actor_loss": -25.755687713623047,
    "critic_loss": 35.7978401184082,
    "ent_coef": 0.11948888003826141,
    "learning_rate": 0.001
  },
  {
    "episode": 1275,
    "reward": 80.369095,
    "length": 78,
    "time": 25107.039134,
    "actor_loss": -25.56671142578125,
    "critic_loss": 69.260986328125,
    "ent_coef": 0.12028233706951141,
    "learning_rate": 0.001
  },
  {
    "episode": 1276,
    "reward": 83.975286,
    "length": 78,
    "time": 25121.008195,
    "actor_loss": -22.339282989501953,
    "critic_loss": 182.0436248779297,
    "ent_coef": 0.118723064661026,
    "learning_rate": 0.001
  },
  {
    "episode": 1277,
    "reward": 74.458971,
    "length": 86,
    "time": 25135.962168,
    "actor_loss": -17.234922409057617,
    "critic_loss": 10.735343933105469,
    "ent_coef": 0.11542647331953049,
    "learning_rate": 0.001
  },
  {
    "episode": 1278,
    "reward": 83.317146,
    "length": 74,
    "time": 25149.190951,
    "actor_loss": -29.733352661132812,
    "critic_loss": 13.322410583496094,
    "ent_coef": 0.11752157658338547,
    "learning_rate": 0.001
  },
  {
    "episode": 1279,
    "reward": 76.69426,
    "length": 84,
    "time": 25164.677529,
    "actor_loss": -25.195205688476562,
    "critic_loss": 16.84893035888672,
    "ent_coef": 0.11789766699075699,
    "learning_rate": 0.001
  },
  {
    "episode": 1280,
    "reward": 87.283224,
    "length": 67,
    "time": 25178.539006,
    "actor_loss": -22.662439346313477,
    "critic_loss": 67.74830627441406,
    "ent_coef": 0.12313783168792725,
    "learning_rate": 0.001
  },
  {
    "episode": 1281,
    "reward": 75.795678,
    "length": 90,
    "time": 25195.196066,
    "actor_loss": -28.242807388305664,
    "critic_loss": 11.824944496154785,
    "ent_coef": 0.12342140823602676,
    "learning_rate": 0.001
  },
  {
    "episode": 1282,
    "reward": 88.343743,
    "length": 67,
    "time": 25210.1129,
    "actor_loss": -28.438600540161133,
    "critic_loss": 106.60049438476562,
    "ent_coef": 0.11953552067279816,
    "learning_rate": 0.001
  },
  {
    "episode": 1283,
    "reward": 75.829359,
    "length": 91,
    "time": 25228.319764,
    "actor_loss": -26.548616409301758,
    "critic_loss": 41.47216796875,
    "ent_coef": 0.11548392474651337,
    "learning_rate": 0.001
  },
  {
    "episode": 1284,
    "reward": 89.244091,
    "length": 66,
    "time": 25243.100812,
    "actor_loss": -24.148042678833008,
    "critic_loss": 5.23270320892334,
    "ent_coef": 0.11326057463884354,
    "learning_rate": 0.001
  },
  {
    "episode": 1285,
    "reward": 86.340524,
    "length": 70,
    "time": 25255.067124,
    "actor_loss": -25.422786712646484,
    "critic_loss": 6.254098892211914,
    "ent_coef": 0.11271615326404572,
    "learning_rate": 0.001
  },
  {
    "episode": 1286,
    "reward": 89.000382,
    "length": 67,
    "time": 25267.1926,
    "actor_loss": -28.271371841430664,
    "critic_loss": 64.48455047607422,
    "ent_coef": 0.11160264909267426,
    "learning_rate": 0.001
  },
  {
    "episode": 1287,
    "reward": 86.098741,
    "length": 75,
    "time": 25282.052256,
    "actor_loss": -33.31315612792969,
    "critic_loss": 164.47076416015625,
    "ent_coef": 0.10896934568881989,
    "learning_rate": 0.001
  },
  {
    "episode": 1288,
    "reward": 87.601468,
    "length": 71,
    "time": 25295.126683,
    "actor_loss": -22.706893920898438,
    "critic_loss": 375.5960388183594,
    "ent_coef": 0.10672502964735031,
    "learning_rate": 0.001
  },
  {
    "episode": 1289,
    "reward": 88.942341,
    "length": 70,
    "time": 25309.49542,
    "actor_loss": -24.018783569335938,
    "critic_loss": 77.8978271484375,
    "ent_coef": 0.10715615749359131,
    "learning_rate": 0.001
  },
  {
    "episode": 1290,
    "reward": 82.796631,
    "length": 78,
    "time": 25325.445256,
    "actor_loss": -23.27198028564453,
    "critic_loss": 5.128432273864746,
    "ent_coef": 0.1121940091252327,
    "learning_rate": 0.001
  },
  {
    "episode": 1291,
    "reward": 86.091146,
    "length": 74,
    "time": 25340.197879,
    "actor_loss": -24.65834617614746,
    "critic_loss": 125.85472106933594,
    "ent_coef": 0.11148201674222946,
    "learning_rate": 0.001
  },
  {
    "episode": 1292,
    "reward": 88.062948,
    "length": 66,
    "time": 25353.954971,
    "actor_loss": -24.749588012695312,
    "critic_loss": 40.82127380371094,
    "ent_coef": 0.11373413354158401,
    "learning_rate": 0.001
  },
  {
    "episode": 1293,
    "reward": 86.515337,
    "length": 74,
    "time": 25367.511146,
    "actor_loss": -26.472789764404297,
    "critic_loss": 97.10664367675781,
    "ent_coef": 0.11933505535125732,
    "learning_rate": 0.001
  },
  {
    "episode": 1294,
    "reward": 80.080787,
    "length": 78,
    "time": 25380.690941,
    "actor_loss": -23.58578109741211,
    "critic_loss": 152.1904296875,
    "ent_coef": 0.1239260882139206,
    "learning_rate": 0.001
  },
  {
    "episode": 1295,
    "reward": 85.617667,
    "length": 71,
    "time": 25393.64392,
    "actor_loss": -28.879486083984375,
    "critic_loss": 127.23170471191406,
    "ent_coef": 0.12283733487129211,
    "learning_rate": 0.001
  },
  {
    "episode": 1296,
    "reward": 82.225429,
    "length": 75,
    "time": 25407.348689,
    "actor_loss": -20.712665557861328,
    "critic_loss": 44.19877243041992,
    "ent_coef": 0.12104521691799164,
    "learning_rate": 0.001
  },
  {
    "episode": 1297,
    "reward": 78.057747,
    "length": 83,
    "time": 25425.105865,
    "actor_loss": -22.815216064453125,
    "critic_loss": 51.52787780761719,
    "ent_coef": 0.12004827708005905,
    "learning_rate": 0.001
  },
  {
    "episode": 1298,
    "reward": 81.556059,
    "length": 77,
    "time": 25437.973745,
    "actor_loss": -23.57103157043457,
    "critic_loss": 37.89892578125,
    "ent_coef": 0.11824245005846024,
    "learning_rate": 0.001
  },
  {
    "episode": 1299,
    "reward": 84.354227,
    "length": 78,
    "time": 25451.665015,
    "actor_loss": -27.189701080322266,
    "critic_loss": 50.51203918457031,
    "ent_coef": 0.1172470673918724,
    "learning_rate": 0.001
  },
  {
    "episode": 1300,
    "reward": 84.28529,
    "length": 72,
    "time": 25465.115059,
    "actor_loss": -30.205745697021484,
    "critic_loss": 21.33926010131836,
    "ent_coef": 0.1237485334277153,
    "learning_rate": 0.001
  },
  {
    "episode": 1301,
    "reward": 86.910497,
    "length": 68,
    "time": 25478.688771,
    "actor_loss": -23.849592208862305,
    "critic_loss": 61.988346099853516,
    "ent_coef": 0.1296926587820053,
    "learning_rate": 0.001
  },
  {
    "episode": 1302,
    "reward": 83.468031,
    "length": 79,
    "time": 25493.729441,
    "actor_loss": -22.3223876953125,
    "critic_loss": 17.78555679321289,
    "ent_coef": 0.1350373476743698,
    "learning_rate": 0.001
  },
  {
    "episode": 1303,
    "reward": 85.6515,
    "length": 70,
    "time": 25506.78583,
    "actor_loss": -24.256519317626953,
    "critic_loss": 43.859657287597656,
    "ent_coef": 0.13697317242622375,
    "learning_rate": 0.001
  },
  {
    "episode": 1304,
    "reward": 86.386913,
    "length": 69,
    "time": 25518.710812,
    "actor_loss": -32.28620529174805,
    "critic_loss": 117.0487060546875,
    "ent_coef": 0.13658136129379272,
    "learning_rate": 0.001
  },
  {
    "episode": 1305,
    "reward": 85.313735,
    "length": 72,
    "time": 25531.152591,
    "actor_loss": -26.41284942626953,
    "critic_loss": 121.7584457397461,
    "ent_coef": 0.13326017558574677,
    "learning_rate": 0.001
  },
  {
    "episode": 1306,
    "reward": 75.932005,
    "length": 90,
    "time": 25548.293298,
    "actor_loss": -31.775379180908203,
    "critic_loss": 297.93310546875,
    "ent_coef": 0.1303080916404724,
    "learning_rate": 0.001
  },
  {
    "episode": 1307,
    "reward": 85.846975,
    "length": 69,
    "time": 25562.792714,
    "actor_loss": -23.310626983642578,
    "critic_loss": 67.79530334472656,
    "ent_coef": 0.13396309316158295,
    "learning_rate": 0.001
  },
  {
    "episode": 1308,
    "reward": 86.671485,
    "length": 69,
    "time": 25576.165762,
    "actor_loss": -23.981922149658203,
    "critic_loss": 31.285903930664062,
    "ent_coef": 0.14018839597702026,
    "learning_rate": 0.001
  },
  {
    "episode": 1309,
    "reward": 86.85966,
    "length": 68,
    "time": 25589.744582,
    "actor_loss": -28.647062301635742,
    "critic_loss": 111.08037567138672,
    "ent_coef": 0.14379392564296722,
    "learning_rate": 0.001
  },
  {
    "episode": 1310,
    "reward": 86.068372,
    "length": 70,
    "time": 25603.775696,
    "actor_loss": -28.915285110473633,
    "critic_loss": 59.769447326660156,
    "ent_coef": 0.14654850959777832,
    "learning_rate": 0.001
  },
  {
    "episode": 1311,
    "reward": 84.163288,
    "length": 73,
    "time": 25616.239938,
    "actor_loss": -29.109619140625,
    "critic_loss": 195.66372680664062,
    "ent_coef": 0.14101962745189667,
    "learning_rate": 0.001
  },
  {
    "episode": 1312,
    "reward": 72.888871,
    "length": 89,
    "time": 25630.719167,
    "actor_loss": -24.812335968017578,
    "critic_loss": 179.10476684570312,
    "ent_coef": 0.13021616637706757,
    "learning_rate": 0.001
  },
  {
    "episode": 1313,
    "reward": 85.931352,
    "length": 71,
    "time": 25645.955006,
    "actor_loss": -29.097476959228516,
    "critic_loss": 147.64178466796875,
    "ent_coef": 0.13084320724010468,
    "learning_rate": 0.001
  },
  {
    "episode": 1314,
    "reward": 86.241724,
    "length": 68,
    "time": 25658.713858,
    "actor_loss": -24.037260055541992,
    "critic_loss": 135.35379028320312,
    "ent_coef": 0.13453702628612518,
    "learning_rate": 0.001
  },
  {
    "episode": 1315,
    "reward": 82.726533,
    "length": 80,
    "time": 25672.168354,
    "actor_loss": -24.102909088134766,
    "critic_loss": 40.113502502441406,
    "ent_coef": 0.13671503961086273,
    "learning_rate": 0.001
  },
  {
    "episode": 1316,
    "reward": 73.399953,
    "length": 89,
    "time": 25686.874498,
    "actor_loss": -23.111326217651367,
    "critic_loss": 4.5414276123046875,
    "ent_coef": 0.13475467264652252,
    "learning_rate": 0.001
  },
  {
    "episode": 1317,
    "reward": 83.742498,
    "length": 73,
    "time": 25699.474923,
    "actor_loss": -29.623455047607422,
    "critic_loss": 45.59259796142578,
    "ent_coef": 0.13469788432121277,
    "learning_rate": 0.001
  },
  {
    "episode": 1318,
    "reward": 84.886826,
    "length": 73,
    "time": 25712.896695,
    "actor_loss": -25.108858108520508,
    "critic_loss": 97.58576965332031,
    "ent_coef": 0.13311734795570374,
    "learning_rate": 0.001
  },
  {
    "episode": 1319,
    "reward": 82.106582,
    "length": 78,
    "time": 25726.022875,
    "actor_loss": -19.4578914642334,
    "critic_loss": 12.74509048461914,
    "ent_coef": 0.12921398878097534,
    "learning_rate": 0.001
  },
  {
    "episode": 1320,
    "reward": 81.767527,
    "length": 78,
    "time": 25739.338017,
    "actor_loss": -25.08531951904297,
    "critic_loss": 150.8587646484375,
    "ent_coef": 0.12236874550580978,
    "learning_rate": 0.001
  },
  {
    "episode": 1321,
    "reward": 83.983172,
    "length": 72,
    "time": 25751.564033,
    "actor_loss": -33.803131103515625,
    "critic_loss": 14.896058082580566,
    "ent_coef": 0.12189440429210663,
    "learning_rate": 0.001
  },
  {
    "episode": 1322,
    "reward": 84.302588,
    "length": 74,
    "time": 25766.168023,
    "actor_loss": -27.454641342163086,
    "critic_loss": 30.36568832397461,
    "ent_coef": 0.12044105678796768,
    "learning_rate": 0.001
  },
  {
    "episode": 1323,
    "reward": 85.367782,
    "length": 73,
    "time": 25778.534138,
    "actor_loss": -29.028928756713867,
    "critic_loss": 12.576448440551758,
    "ent_coef": 0.11787459999322891,
    "learning_rate": 0.001
  },
  {
    "episode": 1324,
    "reward": 83.255753,
    "length": 73,
    "time": 25790.966044,
    "actor_loss": -29.710859298706055,
    "critic_loss": 32.399192810058594,
    "ent_coef": 0.11670761555433273,
    "learning_rate": 0.001
  },
  {
    "episode": 1325,
    "reward": 88.597352,
    "length": 66,
    "time": 25802.557378,
    "actor_loss": -22.996667861938477,
    "critic_loss": 176.39883422851562,
    "ent_coef": 0.1153613030910492,
    "learning_rate": 0.001
  },
  {
    "episode": 1326,
    "reward": 87.477941,
    "length": 67,
    "time": 25815.260333,
    "actor_loss": -24.529857635498047,
    "critic_loss": 55.867462158203125,
    "ent_coef": 0.11264552175998688,
    "learning_rate": 0.001
  },
  {
    "episode": 1327,
    "reward": 85.931706,
    "length": 70,
    "time": 25827.883579,
    "actor_loss": -33.63995361328125,
    "critic_loss": 78.82307434082031,
    "ent_coef": 0.11146683990955353,
    "learning_rate": 0.001
  },
  {
    "episode": 1328,
    "reward": 85.915387,
    "length": 75,
    "time": 25841.487618,
    "actor_loss": -22.328662872314453,
    "critic_loss": 216.63055419921875,
    "ent_coef": 0.1154031902551651,
    "learning_rate": 0.001
  },
  {
    "episode": 1329,
    "reward": 88.578424,
    "length": 66,
    "time": 25853.048972,
    "actor_loss": -24.631031036376953,
    "critic_loss": 21.888525009155273,
    "ent_coef": 0.11944139748811722,
    "learning_rate": 0.001
  },
  {
    "episode": 1330,
    "reward": 85.473679,
    "length": 71,
    "time": 25866.724688,
    "actor_loss": -26.64527130126953,
    "critic_loss": 295.3907470703125,
    "ent_coef": 0.12150955945253372,
    "learning_rate": 0.001
  },
  {
    "episode": 1331,
    "reward": 86.825195,
    "length": 69,
    "time": 25878.974693,
    "actor_loss": -28.93862533569336,
    "critic_loss": 56.50285339355469,
    "ent_coef": 0.12137066572904587,
    "learning_rate": 0.001
  },
  {
    "episode": 1332,
    "reward": 87.554859,
    "length": 68,
    "time": 25891.755219,
    "actor_loss": -27.76799774169922,
    "critic_loss": 13.687580108642578,
    "ent_coef": 0.12280761450529099,
    "learning_rate": 0.001
  },
  {
    "episode": 1333,
    "reward": 82.776213,
    "length": 79,
    "time": 25905.060421,
    "actor_loss": -36.03809356689453,
    "critic_loss": 149.48118591308594,
    "ent_coef": 0.12348242104053497,
    "learning_rate": 0.001
  },
  {
    "episode": 1334,
    "reward": 87.298428,
    "length": 69,
    "time": 25921.412136,
    "actor_loss": -30.13579559326172,
    "critic_loss": 3.6823787689208984,
    "ent_coef": 0.1241907849907875,
    "learning_rate": 0.001
  },
  {
    "episode": 1335,
    "reward": 83.392317,
    "length": 78,
    "time": 25936.270828,
    "actor_loss": -26.960983276367188,
    "critic_loss": 26.69322967529297,
    "ent_coef": 0.1211412101984024,
    "learning_rate": 0.001
  },
  {
    "episode": 1336,
    "reward": 78.931265,
    "length": 81,
    "time": 25949.98835,
    "actor_loss": -29.87288475036621,
    "critic_loss": 56.5950813293457,
    "ent_coef": 0.12413391470909119,
    "learning_rate": 0.001
  },
  {
    "episode": 1337,
    "reward": 77.569265,
    "length": 81,
    "time": 25963.5829,
    "actor_loss": -22.345165252685547,
    "critic_loss": 170.4512939453125,
    "ent_coef": 0.12561830878257751,
    "learning_rate": 0.001
  },
  {
    "episode": 1338,
    "reward": 86.951263,
    "length": 69,
    "time": 25977.016961,
    "actor_loss": -31.938690185546875,
    "critic_loss": 122.86273193359375,
    "ent_coef": 0.12437828630208969,
    "learning_rate": 0.001
  },
  {
    "episode": 1339,
    "reward": 87.408601,
    "length": 71,
    "time": 25990.365715,
    "actor_loss": -26.606279373168945,
    "critic_loss": 169.11508178710938,
    "ent_coef": 0.12216729670763016,
    "learning_rate": 0.001
  },
  {
    "episode": 1340,
    "reward": 76.508931,
    "length": 89,
    "time": 26005.33924,
    "actor_loss": -27.782161712646484,
    "critic_loss": 54.226112365722656,
    "ent_coef": 0.12438096106052399,
    "learning_rate": 0.001
  },
  {
    "episode": 1341,
    "reward": 85.352501,
    "length": 72,
    "time": 26019.161795,
    "actor_loss": -23.658498764038086,
    "critic_loss": 398.6400146484375,
    "ent_coef": 0.12822966277599335,
    "learning_rate": 0.001
  },
  {
    "episode": 1342,
    "reward": 78.196726,
    "length": 85,
    "time": 26035.100539,
    "actor_loss": -27.43223762512207,
    "critic_loss": 98.4695816040039,
    "ent_coef": 0.13073962926864624,
    "learning_rate": 0.001
  },
  {
    "episode": 1343,
    "reward": 87.238013,
    "length": 68,
    "time": 26049.214146,
    "actor_loss": -24.992115020751953,
    "critic_loss": 19.046649932861328,
    "ent_coef": 0.13240894675254822,
    "learning_rate": 0.001
  },
  {
    "episode": 1344,
    "reward": 85.715351,
    "length": 71,
    "time": 26062.87978,
    "actor_loss": -28.577850341796875,
    "critic_loss": 79.98114013671875,
    "ent_coef": 0.13760657608509064,
    "learning_rate": 0.001
  },
  {
    "episode": 1345,
    "reward": 87.653161,
    "length": 68,
    "time": 26074.994599,
    "actor_loss": -26.173463821411133,
    "critic_loss": 150.48065185546875,
    "ent_coef": 0.14026561379432678,
    "learning_rate": 0.001
  },
  {
    "episode": 1346,
    "reward": 83.491517,
    "length": 75,
    "time": 26087.654711,
    "actor_loss": -24.753461837768555,
    "critic_loss": 28.186721801757812,
    "ent_coef": 0.14032123982906342,
    "learning_rate": 0.001
  },
  {
    "episode": 1347,
    "reward": 85.214455,
    "length": 71,
    "time": 26102.878854,
    "actor_loss": -25.342971801757812,
    "critic_loss": 50.59294509887695,
    "ent_coef": 0.1414162516593933,
    "learning_rate": 0.001
  },
  {
    "episode": 1348,
    "reward": 75.151677,
    "length": 87,
    "time": 26118.739327,
    "actor_loss": -23.60931396484375,
    "critic_loss": 308.5477294921875,
    "ent_coef": 0.13644370436668396,
    "learning_rate": 0.001
  },
  {
    "episode": 1349,
    "reward": 85.898616,
    "length": 71,
    "time": 26132.097848,
    "actor_loss": -28.55401611328125,
    "critic_loss": 49.59247589111328,
    "ent_coef": 0.13528896868228912,
    "learning_rate": 0.001
  },
  {
    "episode": 1350,
    "reward": 87.559211,
    "length": 68,
    "time": 26144.863734,
    "actor_loss": -29.006629943847656,
    "critic_loss": 145.4862060546875,
    "ent_coef": 0.13471654057502747,
    "learning_rate": 0.001
  },
  {
    "episode": 1351,
    "reward": 85.781579,
    "length": 70,
    "time": 26158.58057,
    "actor_loss": -25.72502899169922,
    "critic_loss": 52.24880599975586,
    "ent_coef": 0.1294458657503128,
    "learning_rate": 0.001
  },
  {
    "episode": 1352,
    "reward": 81.808669,
    "length": 81,
    "time": 26175.308491,
    "actor_loss": -34.8613395690918,
    "critic_loss": 14.037593841552734,
    "ent_coef": 0.11958247423171997,
    "learning_rate": 0.001
  },
  {
    "episode": 1353,
    "reward": 86.651959,
    "length": 68,
    "time": 26187.085354,
    "actor_loss": -28.36780548095703,
    "critic_loss": 81.58037567138672,
    "ent_coef": 0.11838289350271225,
    "learning_rate": 0.001
  },
  {
    "episode": 1354,
    "reward": 89.778331,
    "length": 64,
    "time": 26198.482476,
    "actor_loss": -26.680723190307617,
    "critic_loss": 59.56778335571289,
    "ent_coef": 0.11793001741170883,
    "learning_rate": 0.001
  },
  {
    "episode": 1355,
    "reward": 89.007763,
    "length": 65,
    "time": 26212.082031,
    "actor_loss": -24.962371826171875,
    "critic_loss": 88.27560424804688,
    "ent_coef": 0.11700513958930969,
    "learning_rate": 0.001
  },
  {
    "episode": 1356,
    "reward": 87.835879,
    "length": 71,
    "time": 26225.312318,
    "actor_loss": -24.13626480102539,
    "critic_loss": 140.69403076171875,
    "ent_coef": 0.11938155442476273,
    "learning_rate": 0.001
  },
  {
    "episode": 1357,
    "reward": -158.574223,
    "length": 128,
    "time": 26247.242081,
    "actor_loss": -27.75103759765625,
    "critic_loss": 10.60210132598877,
    "ent_coef": 0.12132059037685394,
    "learning_rate": 0.001
  },
  {
    "episode": 1358,
    "reward": 83.53578,
    "length": 72,
    "time": 26264.025396,
    "actor_loss": -27.19854164123535,
    "critic_loss": 40.018917083740234,
    "ent_coef": 0.12511873245239258,
    "learning_rate": 0.001
  },
  {
    "episode": 1359,
    "reward": 86.948359,
    "length": 73,
    "time": 26276.401016,
    "actor_loss": -34.95851135253906,
    "critic_loss": 319.37127685546875,
    "ent_coef": 0.12995591759681702,
    "learning_rate": 0.001
  },
  {
    "episode": 1360,
    "reward": 85.928162,
    "length": 70,
    "time": 26289.653017,
    "actor_loss": -24.34408187866211,
    "critic_loss": 51.934539794921875,
    "ent_coef": 0.1296689361333847,
    "learning_rate": 0.001
  },
  {
    "episode": 1361,
    "reward": 87.736864,
    "length": 68,
    "time": 26304.835371,
    "actor_loss": -33.89450454711914,
    "critic_loss": 128.9532470703125,
    "ent_coef": 0.12683632969856262,
    "learning_rate": 0.001
  },
  {
    "episode": 1362,
    "reward": 83.146815,
    "length": 78,
    "time": 26319.966445,
    "actor_loss": -31.536893844604492,
    "critic_loss": 13.286766052246094,
    "ent_coef": 0.12406408786773682,
    "learning_rate": 0.001
  },
  {
    "episode": 1363,
    "reward": 85.681014,
    "length": 69,
    "time": 26332.937895,
    "actor_loss": -31.77973747253418,
    "critic_loss": 8.163880348205566,
    "ent_coef": 0.12058434635400772,
    "learning_rate": 0.001
  },
  {
    "episode": 1364,
    "reward": 80.688663,
    "length": 83,
    "time": 26346.945468,
    "actor_loss": -21.446063995361328,
    "critic_loss": 52.35920715332031,
    "ent_coef": 0.12032143026590347,
    "learning_rate": 0.001
  },
  {
    "episode": 1365,
    "reward": 75.016073,
    "length": 91,
    "time": 26363.501807,
    "actor_loss": -26.367700576782227,
    "critic_loss": 7.945235252380371,
    "ent_coef": 0.11706066876649857,
    "learning_rate": 0.001
  },
  {
    "episode": 1366,
    "reward": 73.705268,
    "length": 87,
    "time": 26378.187697,
    "actor_loss": -33.23381042480469,
    "critic_loss": 278.8332214355469,
    "ent_coef": 0.11583324521780014,
    "learning_rate": 0.001
  },
  {
    "episode": 1367,
    "reward": 85.612943,
    "length": 75,
    "time": 26391.530172,
    "actor_loss": -26.400259017944336,
    "critic_loss": 63.05399703979492,
    "ent_coef": 0.11538068950176239,
    "learning_rate": 0.001
  },
  {
    "episode": 1368,
    "reward": 78.107656,
    "length": 79,
    "time": 26408.004609,
    "actor_loss": -24.36489486694336,
    "critic_loss": 20.425674438476562,
    "ent_coef": 0.11556390672922134,
    "learning_rate": 0.001
  },
  {
    "episode": 1369,
    "reward": 78.2641,
    "length": 84,
    "time": 26421.760053,
    "actor_loss": -28.92236328125,
    "critic_loss": 434.85516357421875,
    "ent_coef": 0.11430998891592026,
    "learning_rate": 0.001
  },
  {
    "episode": 1370,
    "reward": 76.447149,
    "length": 84,
    "time": 26436.454308,
    "actor_loss": -32.418174743652344,
    "critic_loss": 64.44129943847656,
    "ent_coef": 0.115276999771595,
    "learning_rate": 0.001
  },
  {
    "episode": 1371,
    "reward": 81.337589,
    "length": 74,
    "time": 26449.257641,
    "actor_loss": -23.26844024658203,
    "critic_loss": 37.361000061035156,
    "ent_coef": 0.11657989025115967,
    "learning_rate": 0.001
  },
  {
    "episode": 1372,
    "reward": 71.152802,
    "length": 83,
    "time": 26463.098167,
    "actor_loss": -26.99749755859375,
    "critic_loss": 123.22613525390625,
    "ent_coef": 0.11996904015541077,
    "learning_rate": 0.001
  },
  {
    "episode": 1373,
    "reward": 77.233582,
    "length": 82,
    "time": 26477.570366,
    "actor_loss": -29.867568969726562,
    "critic_loss": 401.00482177734375,
    "ent_coef": 0.12911848723888397,
    "learning_rate": 0.001
  },
  {
    "episode": 1374,
    "reward": 76.398738,
    "length": 82,
    "time": 26492.418016,
    "actor_loss": -27.629344940185547,
    "critic_loss": 28.99041748046875,
    "ent_coef": 0.12916812300682068,
    "learning_rate": 0.001
  },
  {
    "episode": 1375,
    "reward": 80.456006,
    "length": 77,
    "time": 26505.470485,
    "actor_loss": -35.45391082763672,
    "critic_loss": 26.49835968017578,
    "ent_coef": 0.1262296736240387,
    "learning_rate": 0.001
  },
  {
    "episode": 1376,
    "reward": 89.351777,
    "length": 64,
    "time": 26516.77022,
    "actor_loss": -30.048564910888672,
    "critic_loss": 34.46067810058594,
    "ent_coef": 0.12423881888389587,
    "learning_rate": 0.001
  },
  {
    "episode": 1377,
    "reward": 84.981195,
    "length": 70,
    "time": 26530.722819,
    "actor_loss": -29.144359588623047,
    "critic_loss": 45.81361389160156,
    "ent_coef": 0.12365308403968811,
    "learning_rate": 0.001
  },
  {
    "episode": 1378,
    "reward": 89.355052,
    "length": 64,
    "time": 26544.974166,
    "actor_loss": -30.96405792236328,
    "critic_loss": 21.345489501953125,
    "ent_coef": 0.12376195192337036,
    "learning_rate": 0.001
  },
  {
    "episode": 1379,
    "reward": 90.461304,
    "length": 63,
    "time": 26559.865822,
    "actor_loss": -31.94009017944336,
    "critic_loss": 63.78030776977539,
    "ent_coef": 0.12362140417098999,
    "learning_rate": 0.001
  },
  {
    "episode": 1380,
    "reward": 83.98067,
    "length": 89,
    "time": 26577.392636,
    "actor_loss": -28.66233253479004,
    "critic_loss": 51.361854553222656,
    "ent_coef": 0.11890251934528351,
    "learning_rate": 0.001
  },
  {
    "episode": 1381,
    "reward": 81.18439,
    "length": 75,
    "time": 26591.2477,
    "actor_loss": -28.817657470703125,
    "critic_loss": 7.380602836608887,
    "ent_coef": 0.11883150041103363,
    "learning_rate": 0.001
  },
  {
    "episode": 1382,
    "reward": 80.760692,
    "length": 76,
    "time": 26606.382021,
    "actor_loss": -27.076416015625,
    "critic_loss": 49.905242919921875,
    "ent_coef": 0.12585894763469696,
    "learning_rate": 0.001
  },
  {
    "episode": 1383,
    "reward": 75.980162,
    "length": 85,
    "time": 26622.608845,
    "actor_loss": -27.217802047729492,
    "critic_loss": 150.45101928710938,
    "ent_coef": 0.12973357737064362,
    "learning_rate": 0.001
  },
  {
    "episode": 1384,
    "reward": 82.639746,
    "length": 74,
    "time": 26636.033619,
    "actor_loss": -27.229732513427734,
    "critic_loss": 67.30125427246094,
    "ent_coef": 0.1340549737215042,
    "learning_rate": 0.001
  },
  {
    "episode": 1385,
    "reward": 82.577975,
    "length": 74,
    "time": 26650.968862,
    "actor_loss": -26.042118072509766,
    "critic_loss": 115.97682189941406,
    "ent_coef": 0.13417468965053558,
    "learning_rate": 0.001
  },
  {
    "episode": 1386,
    "reward": 82.626788,
    "length": 79,
    "time": 26665.273046,
    "actor_loss": -27.94921875,
    "critic_loss": 137.326171875,
    "ent_coef": 0.13081027567386627,
    "learning_rate": 0.001
  },
  {
    "episode": 1387,
    "reward": 82.482236,
    "length": 74,
    "time": 26678.07577,
    "actor_loss": -26.364295959472656,
    "critic_loss": 464.5363464355469,
    "ent_coef": 0.1307942122220993,
    "learning_rate": 0.001
  },
  {
    "episode": 1388,
    "reward": 87.685546,
    "length": 67,
    "time": 26690.522687,
    "actor_loss": -23.542633056640625,
    "critic_loss": 32.55278778076172,
    "ent_coef": 0.1305254101753235,
    "learning_rate": 0.001
  },
  {
    "episode": 1389,
    "reward": 84.902583,
    "length": 71,
    "time": 26703.497329,
    "actor_loss": -24.626235961914062,
    "critic_loss": 36.92375183105469,
    "ent_coef": 0.13343165814876556,
    "learning_rate": 0.001
  },
  {
    "episode": 1390,
    "reward": 77.30568,
    "length": 80,
    "time": 26717.099575,
    "actor_loss": -25.251583099365234,
    "critic_loss": 50.58537292480469,
    "ent_coef": 0.13515010476112366,
    "learning_rate": 0.001
  },
  {
    "episode": 1391,
    "reward": 85.262818,
    "length": 76,
    "time": 26729.990373,
    "actor_loss": -31.74162483215332,
    "critic_loss": 107.54086303710938,
    "ent_coef": 0.13509409129619598,
    "learning_rate": 0.001
  },
  {
    "episode": 1392,
    "reward": 76.799036,
    "length": 87,
    "time": 26745.787137,
    "actor_loss": -25.804048538208008,
    "critic_loss": 74.85734558105469,
    "ent_coef": 0.13046707212924957,
    "learning_rate": 0.001
  },
  {
    "episode": 1393,
    "reward": 86.308594,
    "length": 70,
    "time": 26759.939961,
    "actor_loss": -29.505218505859375,
    "critic_loss": 90.47406005859375,
    "ent_coef": 0.1300063282251358,
    "learning_rate": 0.001
  },
  {
    "episode": 1394,
    "reward": 87.512721,
    "length": 69,
    "time": 26771.950311,
    "actor_loss": -27.953670501708984,
    "critic_loss": 40.718414306640625,
    "ent_coef": 0.12899166345596313,
    "learning_rate": 0.001
  },
  {
    "episode": 1395,
    "reward": 87.048678,
    "length": 68,
    "time": 26784.932168,
    "actor_loss": -30.769371032714844,
    "critic_loss": 27.53632164001465,
    "ent_coef": 0.12631730735301971,
    "learning_rate": 0.001
  },
  {
    "episode": 1396,
    "reward": 80.132072,
    "length": 80,
    "time": 26800.027956,
    "actor_loss": -36.57910919189453,
    "critic_loss": 22.865081787109375,
    "ent_coef": 0.12243252992630005,
    "learning_rate": 0.001
  },
  {
    "episode": 1397,
    "reward": 82.211741,
    "length": 77,
    "time": 26812.825641,
    "actor_loss": -27.46433448791504,
    "critic_loss": 48.44950866699219,
    "ent_coef": 0.12053853273391724,
    "learning_rate": 0.001
  },
  {
    "episode": 1398,
    "reward": 82.564425,
    "length": 74,
    "time": 26826.657898,
    "actor_loss": -33.855125427246094,
    "critic_loss": 56.42985534667969,
    "ent_coef": 0.11708525568246841,
    "learning_rate": 0.001
  },
  {
    "episode": 1399,
    "reward": 85.824423,
    "length": 69,
    "time": 26842.468201,
    "actor_loss": -31.828170776367188,
    "critic_loss": 24.36117172241211,
    "ent_coef": 0.11750998347997665,
    "learning_rate": 0.001
  },
  {
    "episode": 1400,
    "reward": 88.009577,
    "length": 67,
    "time": 26854.913406,
    "actor_loss": -34.62260437011719,
    "critic_loss": 135.86940002441406,
    "ent_coef": 0.11746768653392792,
    "learning_rate": 0.001
  },
  {
    "episode": 1401,
    "reward": 83.915048,
    "length": 72,
    "time": 26870.00677,
    "actor_loss": -23.876882553100586,
    "critic_loss": 39.99078369140625,
    "ent_coef": 0.11633424460887909,
    "learning_rate": 0.001
  },
  {
    "episode": 1402,
    "reward": 87.49264,
    "length": 72,
    "time": 26883.322608,
    "actor_loss": -28.241418838500977,
    "critic_loss": 176.7312469482422,
    "ent_coef": 0.11835221946239471,
    "learning_rate": 0.001
  },
  {
    "episode": 1403,
    "reward": 87.546753,
    "length": 68,
    "time": 26897.461554,
    "actor_loss": -30.810096740722656,
    "critic_loss": 76.91028594970703,
    "ent_coef": 0.11886031180620193,
    "learning_rate": 0.001
  },
  {
    "episode": 1404,
    "reward": 83.485131,
    "length": 72,
    "time": 26909.831443,
    "actor_loss": -29.144866943359375,
    "critic_loss": 47.29927444458008,
    "ent_coef": 0.12486924231052399,
    "learning_rate": 0.001
  },
  {
    "episode": 1405,
    "reward": 79.47291,
    "length": 78,
    "time": 26925.917233,
    "actor_loss": -25.625614166259766,
    "critic_loss": 30.351119995117188,
    "ent_coef": 0.12588277459144592,
    "learning_rate": 0.001
  },
  {
    "episode": 1406,
    "reward": 84.103898,
    "length": 72,
    "time": 26939.281081,
    "actor_loss": -29.47287368774414,
    "critic_loss": 474.04241943359375,
    "ent_coef": 0.12817183136940002,
    "learning_rate": 0.001
  },
  {
    "episode": 1407,
    "reward": 83.333665,
    "length": 72,
    "time": 26952.730352,
    "actor_loss": -33.40965270996094,
    "critic_loss": 51.67137908935547,
    "ent_coef": 0.12779150903224945,
    "learning_rate": 0.001
  },
  {
    "episode": 1408,
    "reward": 89.016801,
    "length": 66,
    "time": 26967.166546,
    "actor_loss": -33.94474411010742,
    "critic_loss": 85.05789184570312,
    "ent_coef": 0.12570367753505707,
    "learning_rate": 0.001
  },
  {
    "episode": 1409,
    "reward": 82.123898,
    "length": 75,
    "time": 26980.991517,
    "actor_loss": -33.463890075683594,
    "critic_loss": 135.69473266601562,
    "ent_coef": 0.12726923823356628,
    "learning_rate": 0.001
  },
  {
    "episode": 1410,
    "reward": 88.86079,
    "length": 65,
    "time": 26995.248524,
    "actor_loss": -29.063697814941406,
    "critic_loss": 37.304969787597656,
    "ent_coef": 0.13341476023197174,
    "learning_rate": 0.001
  },
  {
    "episode": 1411,
    "reward": 84.443119,
    "length": 73,
    "time": 27009.603269,
    "actor_loss": -30.344432830810547,
    "critic_loss": 47.03468322753906,
    "ent_coef": 0.1344112753868103,
    "learning_rate": 0.001
  },
  {
    "episode": 1412,
    "reward": 85.701976,
    "length": 69,
    "time": 27022.486733,
    "actor_loss": -29.163780212402344,
    "critic_loss": 30.242250442504883,
    "ent_coef": 0.135800302028656,
    "learning_rate": 0.001
  },
  {
    "episode": 1413,
    "reward": 85.662056,
    "length": 73,
    "time": 27035.037619,
    "actor_loss": -29.21780014038086,
    "critic_loss": 9.674947738647461,
    "ent_coef": 0.13678529858589172,
    "learning_rate": 0.001
  },
  {
    "episode": 1414,
    "reward": 87.516387,
    "length": 66,
    "time": 27049.558696,
    "actor_loss": -36.35560607910156,
    "critic_loss": 120.73042297363281,
    "ent_coef": 0.13814274966716766,
    "learning_rate": 0.001
  },
  {
    "episode": 1415,
    "reward": 89.002384,
    "length": 66,
    "time": 27060.983221,
    "actor_loss": -26.37258529663086,
    "critic_loss": 101.27027130126953,
    "ent_coef": 0.137765035033226,
    "learning_rate": 0.001
  },
  {
    "episode": 1416,
    "reward": 86.682277,
    "length": 67,
    "time": 27073.866948,
    "actor_loss": -33.668338775634766,
    "critic_loss": 6.394955635070801,
    "ent_coef": 0.13975533843040466,
    "learning_rate": 0.001
  },
  {
    "episode": 1417,
    "reward": 85.418291,
    "length": 70,
    "time": 27088.638733,
    "actor_loss": -27.84734344482422,
    "critic_loss": 39.802574157714844,
    "ent_coef": 0.14083872735500336,
    "learning_rate": 0.001
  },
  {
    "episode": 1418,
    "reward": 82.166092,
    "length": 81,
    "time": 27102.193214,
    "actor_loss": -29.79322052001953,
    "critic_loss": 138.8057403564453,
    "ent_coef": 0.14596639573574066,
    "learning_rate": 0.001
  },
  {
    "episode": 1419,
    "reward": 82.122784,
    "length": 73,
    "time": 27117.618712,
    "actor_loss": -31.00593376159668,
    "critic_loss": 13.123771667480469,
    "ent_coef": 0.14463560283184052,
    "learning_rate": 0.001
  },
  {
    "episode": 1420,
    "reward": 84.546649,
    "length": 77,
    "time": 27133.917444,
    "actor_loss": -29.939739227294922,
    "critic_loss": 9.465169906616211,
    "ent_coef": 0.14331944286823273,
    "learning_rate": 0.001
  },
  {
    "episode": 1421,
    "reward": 91.106374,
    "length": 62,
    "time": 27147.775023,
    "actor_loss": -32.889259338378906,
    "critic_loss": 16.17037582397461,
    "ent_coef": 0.1420254409313202,
    "learning_rate": 0.001
  },
  {
    "episode": 1422,
    "reward": -159.314981,
    "length": 121,
    "time": 27167.240216,
    "actor_loss": -36.854366302490234,
    "critic_loss": 229.52261352539062,
    "ent_coef": 0.13864772021770477,
    "learning_rate": 0.001
  },
  {
    "episode": 1423,
    "reward": 88.352535,
    "length": 65,
    "time": 27179.591079,
    "actor_loss": -38.31187438964844,
    "critic_loss": 64.04100036621094,
    "ent_coef": 0.13901874423027039,
    "learning_rate": 0.001
  },
  {
    "episode": 1424,
    "reward": 90.869074,
    "length": 63,
    "time": 27190.816141,
    "actor_loss": -32.53710174560547,
    "critic_loss": 127.39505004882812,
    "ent_coef": 0.13985209167003632,
    "learning_rate": 0.001
  },
  {
    "episode": 1425,
    "reward": -156.957378,
    "length": 133,
    "time": 27213.149545,
    "actor_loss": -33.12898254394531,
    "critic_loss": 122.073486328125,
    "ent_coef": 0.13275927305221558,
    "learning_rate": 0.001
  },
  {
    "episode": 1426,
    "reward": 75.25623,
    "length": 84,
    "time": 27228.041698,
    "actor_loss": -31.02140998840332,
    "critic_loss": 105.1148910522461,
    "ent_coef": 0.13233250379562378,
    "learning_rate": 0.001
  },
  {
    "episode": 1427,
    "reward": 77.324725,
    "length": 81,
    "time": 27242.071608,
    "actor_loss": -26.22979736328125,
    "critic_loss": 35.147621154785156,
    "ent_coef": 0.13025550544261932,
    "learning_rate": 0.001
  },
  {
    "episode": 1428,
    "reward": 85.384308,
    "length": 69,
    "time": 27254.262233,
    "actor_loss": -33.02996826171875,
    "critic_loss": 72.98197937011719,
    "ent_coef": 0.13073590397834778,
    "learning_rate": 0.001
  },
  {
    "episode": 1429,
    "reward": 85.177806,
    "length": 70,
    "time": 27267.240376,
    "actor_loss": -24.878555297851562,
    "critic_loss": 18.554353713989258,
    "ent_coef": 0.1290626972913742,
    "learning_rate": 0.001
  },
  {
    "episode": 1430,
    "reward": 89.64259,
    "length": 63,
    "time": 27281.431192,
    "actor_loss": -32.1417236328125,
    "critic_loss": 85.67506408691406,
    "ent_coef": 0.12922169268131256,
    "learning_rate": 0.001
  },
  {
    "episode": 1431,
    "reward": 86.87984,
    "length": 68,
    "time": 27294.327067,
    "actor_loss": -34.875877380371094,
    "critic_loss": 25.941574096679688,
    "ent_coef": 0.12969698011875153,
    "learning_rate": 0.001
  },
  {
    "episode": 1432,
    "reward": 79.774942,
    "length": 84,
    "time": 27312.367957,
    "actor_loss": -38.7857666015625,
    "critic_loss": 8.384184837341309,
    "ent_coef": 0.12859730422496796,
    "learning_rate": 0.001
  },
  {
    "episode": 1433,
    "reward": 86.248761,
    "length": 69,
    "time": 27326.845682,
    "actor_loss": -33.84391784667969,
    "critic_loss": 40.06647491455078,
    "ent_coef": 0.12765534222126007,
    "learning_rate": 0.001
  },
  {
    "episode": 1434,
    "reward": 78.054289,
    "length": 81,
    "time": 27341.98713,
    "actor_loss": -30.364364624023438,
    "critic_loss": 197.44708251953125,
    "ent_coef": 0.1267651617527008,
    "learning_rate": 0.001
  },
  {
    "episode": 1435,
    "reward": 84.134937,
    "length": 72,
    "time": 27355.220891,
    "actor_loss": -33.458900451660156,
    "critic_loss": 51.873931884765625,
    "ent_coef": 0.12341831624507904,
    "learning_rate": 0.001
  },
  {
    "episode": 1436,
    "reward": 85.854153,
    "length": 69,
    "time": 27367.025567,
    "actor_loss": -35.841495513916016,
    "critic_loss": 90.25088500976562,
    "ent_coef": 0.12476629763841629,
    "learning_rate": 0.001
  },
  {
    "episode": 1437,
    "reward": 89.551343,
    "length": 65,
    "time": 27379.507443,
    "actor_loss": -28.00057601928711,
    "critic_loss": 76.54933166503906,
    "ent_coef": 0.12958282232284546,
    "learning_rate": 0.001
  },
  {
    "episode": 1438,
    "reward": 81.866412,
    "length": 76,
    "time": 27392.345769,
    "actor_loss": -35.1804084777832,
    "critic_loss": 26.02557373046875,
    "ent_coef": 0.13294939696788788,
    "learning_rate": 0.001
  },
  {
    "episode": 1439,
    "reward": 82.336895,
    "length": 76,
    "time": 27405.273016,
    "actor_loss": -32.83116149902344,
    "critic_loss": 15.750704765319824,
    "ent_coef": 0.1319301277399063,
    "learning_rate": 0.001
  },
  {
    "episode": 1440,
    "reward": 78.792401,
    "length": 79,
    "time": 27421.065389,
    "actor_loss": -30.559532165527344,
    "critic_loss": 113.27119445800781,
    "ent_coef": 0.13448935747146606,
    "learning_rate": 0.001
  },
  {
    "episode": 1441,
    "reward": 81.372599,
    "length": 77,
    "time": 27434.058529,
    "actor_loss": -33.54532241821289,
    "critic_loss": 12.604564666748047,
    "ent_coef": 0.13884195685386658,
    "learning_rate": 0.001
  },
  {
    "episode": 1442,
    "reward": 83.705595,
    "length": 73,
    "time": 27446.60411,
    "actor_loss": -30.261804580688477,
    "critic_loss": 12.808874130249023,
    "ent_coef": 0.13952043652534485,
    "learning_rate": 0.001
  },
  {
    "episode": 1443,
    "reward": 86.607411,
    "length": 69,
    "time": 27458.75041,
    "actor_loss": -28.752552032470703,
    "critic_loss": 22.320587158203125,
    "ent_coef": 0.13857752084732056,
    "learning_rate": 0.001
  },
  {
    "episode": 1444,
    "reward": 88.899592,
    "length": 66,
    "time": 27471.357528,
    "actor_loss": -35.75408935546875,
    "critic_loss": 105.27276611328125,
    "ent_coef": 0.13567864894866943,
    "learning_rate": 0.001
  },
  {
    "episode": 1445,
    "reward": 84.326409,
    "length": 72,
    "time": 27484.404933,
    "actor_loss": -29.65176010131836,
    "critic_loss": 10.496583938598633,
    "ent_coef": 0.13246625661849976,
    "learning_rate": 0.001
  },
  {
    "episode": 1446,
    "reward": 83.828646,
    "length": 79,
    "time": 27498.698262,
    "actor_loss": -32.54091262817383,
    "critic_loss": 63.00402069091797,
    "ent_coef": 0.12928348779678345,
    "learning_rate": 0.001
  },
  {
    "episode": 1447,
    "reward": 86.596172,
    "length": 70,
    "time": 27511.60199,
    "actor_loss": -28.78223419189453,
    "critic_loss": 112.59705352783203,
    "ent_coef": 0.129189595580101,
    "learning_rate": 0.001
  },
  {
    "episode": 1448,
    "reward": 84.140113,
    "length": 73,
    "time": 27525.246542,
    "actor_loss": -31.958011627197266,
    "critic_loss": 56.572364807128906,
    "ent_coef": 0.13108454644680023,
    "learning_rate": 0.001
  },
  {
    "episode": 1449,
    "reward": 84.019207,
    "length": 76,
    "time": 27540.690505,
    "actor_loss": -35.13133239746094,
    "critic_loss": 138.9635467529297,
    "ent_coef": 0.13505907356739044,
    "learning_rate": 0.001
  },
  {
    "episode": 1450,
    "reward": 89.114393,
    "length": 65,
    "time": 27553.007408,
    "actor_loss": -35.79224395751953,
    "critic_loss": 66.88790893554688,
    "ent_coef": 0.13980503380298615,
    "learning_rate": 0.001
  },
  {
    "episode": 1451,
    "reward": 82.624502,
    "length": 73,
    "time": 27567.419409,
    "actor_loss": -32.55812072753906,
    "critic_loss": 33.052223205566406,
    "ent_coef": 0.14350904524326324,
    "learning_rate": 0.001
  },
  {
    "episode": 1452,
    "reward": 88.591133,
    "length": 65,
    "time": 27580.021123,
    "actor_loss": -34.528533935546875,
    "critic_loss": 70.26290893554688,
    "ent_coef": 0.14681416749954224,
    "learning_rate": 0.001
  },
  {
    "episode": 1453,
    "reward": -159.017654,
    "length": 146,
    "time": 27605.368078,
    "actor_loss": -37.42102813720703,
    "critic_loss": 31.06271743774414,
    "ent_coef": 0.1378147155046463,
    "learning_rate": 0.001
  },
  {
    "episode": 1454,
    "reward": 84.502081,
    "length": 71,
    "time": 27619.372618,
    "actor_loss": -28.048057556152344,
    "critic_loss": 139.01251220703125,
    "ent_coef": 0.13847297430038452,
    "learning_rate": 0.001
  },
  {
    "episode": 1455,
    "reward": 88.6337,
    "length": 66,
    "time": 27631.8096,
    "actor_loss": -33.44815444946289,
    "critic_loss": 77.42430114746094,
    "ent_coef": 0.14067934453487396,
    "learning_rate": 0.001
  },
  {
    "episode": 1456,
    "reward": 87.872804,
    "length": 67,
    "time": 27644.850308,
    "actor_loss": -32.499080657958984,
    "critic_loss": 10.032821655273438,
    "ent_coef": 0.14400433003902435,
    "learning_rate": 0.001
  },
  {
    "episode": 1457,
    "reward": 86.187533,
    "length": 68,
    "time": 27656.648526,
    "actor_loss": -32.10914993286133,
    "critic_loss": 99.19529724121094,
    "ent_coef": 0.14609919488430023,
    "learning_rate": 0.001
  },
  {
    "episode": 1458,
    "reward": 85.068457,
    "length": 71,
    "time": 27669.078919,
    "actor_loss": -40.89585494995117,
    "critic_loss": 44.35136795043945,
    "ent_coef": 0.14341787993907928,
    "learning_rate": 0.001
  },
  {
    "episode": 1459,
    "reward": 84.296162,
    "length": 73,
    "time": 27686.526308,
    "actor_loss": -35.422061920166016,
    "critic_loss": 190.74081420898438,
    "ent_coef": 0.13943985104560852,
    "learning_rate": 0.001
  },
  {
    "episode": 1460,
    "reward": 87.286549,
    "length": 67,
    "time": 27698.66665,
    "actor_loss": -29.053009033203125,
    "critic_loss": 34.039520263671875,
    "ent_coef": 0.13911272585391998,
    "learning_rate": 0.001
  },
  {
    "episode": 1461,
    "reward": -159.339241,
    "length": 136,
    "time": 27719.622476,
    "actor_loss": -36.77198028564453,
    "critic_loss": 7.29693603515625,
    "ent_coef": 0.14539162814617157,
    "learning_rate": 0.001
  },
  {
    "episode": 1462,
    "reward": 79.579849,
    "length": 80,
    "time": 27735.359024,
    "actor_loss": -36.18400573730469,
    "critic_loss": 49.76927185058594,
    "ent_coef": 0.14446838200092316,
    "learning_rate": 0.001
  },
  {
    "episode": 1463,
    "reward": 84.806966,
    "length": 74,
    "time": 27747.880164,
    "actor_loss": -33.403358459472656,
    "critic_loss": 89.12671661376953,
    "ent_coef": 0.14168182015419006,
    "learning_rate": 0.001
  },
  {
    "episode": 1464,
    "reward": 85.781307,
    "length": 70,
    "time": 27763.520672,
    "actor_loss": -33.28870391845703,
    "critic_loss": 87.61888122558594,
    "ent_coef": 0.14052416384220123,
    "learning_rate": 0.001
  },
  {
    "episode": 1465,
    "reward": 83.427836,
    "length": 74,
    "time": 27776.527193,
    "actor_loss": -36.34990692138672,
    "critic_loss": 79.76995086669922,
    "ent_coef": 0.1419236809015274,
    "learning_rate": 0.001
  },
  {
    "episode": 1466,
    "reward": 85.507246,
    "length": 71,
    "time": 27790.700461,
    "actor_loss": -34.77998352050781,
    "critic_loss": 48.181251525878906,
    "ent_coef": 0.1410297453403473,
    "learning_rate": 0.001
  },
  {
    "episode": 1467,
    "reward": 83.390477,
    "length": 73,
    "time": 27803.57481,
    "actor_loss": -34.60231018066406,
    "critic_loss": 127.59428405761719,
    "ent_coef": 0.1422552615404129,
    "learning_rate": 0.001
  },
  {
    "episode": 1468,
    "reward": 84.909093,
    "length": 71,
    "time": 27817.033566,
    "actor_loss": -32.21184539794922,
    "critic_loss": 35.48573303222656,
    "ent_coef": 0.14062726497650146,
    "learning_rate": 0.001
  },
  {
    "episode": 1469,
    "reward": 85.342121,
    "length": 71,
    "time": 27830.490609,
    "actor_loss": -34.47504425048828,
    "critic_loss": 19.899202346801758,
    "ent_coef": 0.1383620798587799,
    "learning_rate": 0.001
  },
  {
    "episode": 1470,
    "reward": 82.781396,
    "length": 76,
    "time": 27845.441186,
    "actor_loss": -34.873374938964844,
    "critic_loss": 18.443614959716797,
    "ent_coef": 0.1362985521554947,
    "learning_rate": 0.001
  },
  {
    "episode": 1471,
    "reward": 83.957188,
    "length": 74,
    "time": 27858.025713,
    "actor_loss": -35.506187438964844,
    "critic_loss": 89.79948425292969,
    "ent_coef": 0.1338537186384201,
    "learning_rate": 0.001
  },
  {
    "episode": 1472,
    "reward": 83.5418,
    "length": 72,
    "time": 27872.305583,
    "actor_loss": -31.083465576171875,
    "critic_loss": 7.969268798828125,
    "ent_coef": 0.13387684524059296,
    "learning_rate": 0.001
  },
  {
    "episode": 1473,
    "reward": 81.967123,
    "length": 76,
    "time": 27885.360719,
    "actor_loss": -36.91265106201172,
    "critic_loss": 48.447608947753906,
    "ent_coef": 0.13457076251506805,
    "learning_rate": 0.001
  },
  {
    "episode": 1474,
    "reward": 72.288136,
    "length": 85,
    "time": 27900.429478,
    "actor_loss": -41.36730194091797,
    "critic_loss": 12.451196670532227,
    "ent_coef": 0.13489222526550293,
    "learning_rate": 0.001
  },
  {
    "episode": 1475,
    "reward": 79.262977,
    "length": 80,
    "time": 27915.007756,
    "actor_loss": -36.77824401855469,
    "critic_loss": 79.77598571777344,
    "ent_coef": 0.13458989560604095,
    "learning_rate": 0.001
  },
  {
    "episode": 1476,
    "reward": 83.572392,
    "length": 74,
    "time": 27932.201378,
    "actor_loss": -33.148399353027344,
    "critic_loss": 140.8666534423828,
    "ent_coef": 0.13384366035461426,
    "learning_rate": 0.001
  },
  {
    "episode": 1477,
    "reward": 78.793878,
    "length": 80,
    "time": 27947.961016,
    "actor_loss": -35.05954360961914,
    "critic_loss": 22.275482177734375,
    "ent_coef": 0.1313084065914154,
    "learning_rate": 0.001
  },
  {
    "episode": 1478,
    "reward": 83.736057,
    "length": 73,
    "time": 27965.164202,
    "actor_loss": -29.134281158447266,
    "critic_loss": 46.882667541503906,
    "ent_coef": 0.13033898174762726,
    "learning_rate": 0.001
  },
  {
    "episode": 1479,
    "reward": 87.903973,
    "length": 66,
    "time": 27979.0585,
    "actor_loss": -31.272464752197266,
    "critic_loss": 105.62335968017578,
    "ent_coef": 0.12660756707191467,
    "learning_rate": 0.001
  },
  {
    "episode": 1480,
    "reward": 85.932,
    "length": 75,
    "time": 27994.583184,
    "actor_loss": -31.6417236328125,
    "critic_loss": 118.83645629882812,
    "ent_coef": 0.1249849796295166,
    "learning_rate": 0.001
  },
  {
    "episode": 1481,
    "reward": 78.959496,
    "length": 79,
    "time": 28008.27196,
    "actor_loss": -35.66883087158203,
    "critic_loss": 93.56549072265625,
    "ent_coef": 0.1259477436542511,
    "learning_rate": 0.001
  },
  {
    "episode": 1482,
    "reward": 84.152981,
    "length": 76,
    "time": 28021.901469,
    "actor_loss": -30.681747436523438,
    "critic_loss": 104.79939270019531,
    "ent_coef": 0.12829941511154175,
    "learning_rate": 0.001
  },
  {
    "episode": 1483,
    "reward": 83.714996,
    "length": 75,
    "time": 28037.464542,
    "actor_loss": -34.10638427734375,
    "critic_loss": 78.93861389160156,
    "ent_coef": 0.12598249316215515,
    "learning_rate": 0.001
  },
  {
    "episode": 1484,
    "reward": 81.141534,
    "length": 77,
    "time": 28051.558035,
    "actor_loss": -34.44435119628906,
    "critic_loss": 77.83274841308594,
    "ent_coef": 0.12725023925304413,
    "learning_rate": 0.001
  },
  {
    "episode": 1485,
    "reward": 86.094048,
    "length": 69,
    "time": 28063.677241,
    "actor_loss": -36.61419677734375,
    "critic_loss": 20.911436080932617,
    "ent_coef": 0.1258222907781601,
    "learning_rate": 0.001
  },
  {
    "episode": 1486,
    "reward": 79.531816,
    "length": 78,
    "time": 28079.913513,
    "actor_loss": -39.92189407348633,
    "critic_loss": 122.72084045410156,
    "ent_coef": 0.12259349972009659,
    "learning_rate": 0.001
  },
  {
    "episode": 1487,
    "reward": 80.09595,
    "length": 84,
    "time": 28095.553171,
    "actor_loss": -37.28834915161133,
    "critic_loss": 7.435379981994629,
    "ent_coef": 0.12643392384052277,
    "learning_rate": 0.001
  },
  {
    "episode": 1488,
    "reward": 88.609776,
    "length": 65,
    "time": 28107.962734,
    "actor_loss": -32.60190200805664,
    "critic_loss": 97.22171783447266,
    "ent_coef": 0.1287134289741516,
    "learning_rate": 0.001
  },
  {
    "episode": 1489,
    "reward": 86.444235,
    "length": 68,
    "time": 28119.810104,
    "actor_loss": -26.224998474121094,
    "critic_loss": 21.110149383544922,
    "ent_coef": 0.13167184591293335,
    "learning_rate": 0.001
  },
  {
    "episode": 1490,
    "reward": 87.65259,
    "length": 68,
    "time": 28133.423153,
    "actor_loss": -35.47801971435547,
    "critic_loss": 90.44400024414062,
    "ent_coef": 0.13334114849567413,
    "learning_rate": 0.001
  },
  {
    "episode": 1491,
    "reward": 84.479759,
    "length": 71,
    "time": 28145.850591,
    "actor_loss": -33.052616119384766,
    "critic_loss": 67.54324340820312,
    "ent_coef": 0.13398995995521545,
    "learning_rate": 0.001
  },
  {
    "episode": 1492,
    "reward": -165.190987,
    "length": 141,
    "time": 28168.804679,
    "actor_loss": -35.709388732910156,
    "critic_loss": 80.6772232055664,
    "ent_coef": 0.13505849242210388,
    "learning_rate": 0.001
  },
  {
    "episode": 1493,
    "reward": 88.246517,
    "length": 67,
    "time": 28180.505759,
    "actor_loss": -39.0282096862793,
    "critic_loss": 12.67553424835205,
    "ent_coef": 0.13454490900039673,
    "learning_rate": 0.001
  },
  {
    "episode": 1494,
    "reward": 86.061386,
    "length": 69,
    "time": 28193.740258,
    "actor_loss": -34.508995056152344,
    "critic_loss": 17.44379425048828,
    "ent_coef": 0.13554267585277557,
    "learning_rate": 0.001
  },
  {
    "episode": 1495,
    "reward": 84.826627,
    "length": 74,
    "time": 28208.063582,
    "actor_loss": -35.51235580444336,
    "critic_loss": 29.491146087646484,
    "ent_coef": 0.1389293223619461,
    "learning_rate": 0.001
  },
  {
    "episode": 1496,
    "reward": 85.982633,
    "length": 70,
    "time": 28221.293362,
    "actor_loss": -34.725059509277344,
    "critic_loss": 96.54280090332031,
    "ent_coef": 0.13785013556480408,
    "learning_rate": 0.001
  },
  {
    "episode": 1497,
    "reward": 79.178464,
    "length": 80,
    "time": 28236.69982,
    "actor_loss": -36.52720642089844,
    "critic_loss": 65.20829772949219,
    "ent_coef": 0.13621269166469574,
    "learning_rate": 0.001
  },
  {
    "episode": 1498,
    "reward": 72.820332,
    "length": 88,
    "time": 28254.193768,
    "actor_loss": -37.81024932861328,
    "critic_loss": 9.520009994506836,
    "ent_coef": 0.13898642361164093,
    "learning_rate": 0.001
  },
  {
    "episode": 1499,
    "reward": 77.741245,
    "length": 87,
    "time": 28271.173667,
    "actor_loss": -39.477394104003906,
    "critic_loss": 76.06394958496094,
    "ent_coef": 0.1405162215232849,
    "learning_rate": 0.001
  },
  {
    "episode": 1500,
    "reward": 86.744776,
    "length": 69,
    "time": 28285.644268,
    "actor_loss": -35.23218536376953,
    "critic_loss": 13.267993927001953,
    "ent_coef": 0.14171184599399567,
    "learning_rate": 0.001
  },
  {
    "episode": 1501,
    "reward": 78.190555,
    "length": 79,
    "time": 28300.005507,
    "actor_loss": -30.78217124938965,
    "critic_loss": 172.46868896484375,
    "ent_coef": 0.1420070230960846,
    "learning_rate": 0.001
  },
  {
    "episode": 1502,
    "reward": 83.081836,
    "length": 75,
    "time": 28312.814269,
    "actor_loss": -33.66095733642578,
    "critic_loss": 134.4307861328125,
    "ent_coef": 0.14021854102611542,
    "learning_rate": 0.001
  },
  {
    "episode": 1503,
    "reward": 78.985253,
    "length": 77,
    "time": 28326.283036,
    "actor_loss": -40.45889663696289,
    "critic_loss": 107.65862274169922,
    "ent_coef": 0.14107584953308105,
    "learning_rate": 0.001
  },
  {
    "episode": 1504,
    "reward": 84.550644,
    "length": 71,
    "time": 28340.088605,
    "actor_loss": -31.651647567749023,
    "critic_loss": 211.08926391601562,
    "ent_coef": 0.14295929670333862,
    "learning_rate": 0.001
  },
  {
    "episode": 1505,
    "reward": 83.56785,
    "length": 72,
    "time": 28352.782166,
    "actor_loss": -33.994659423828125,
    "critic_loss": 39.83747100830078,
    "ent_coef": 0.14526402950286865,
    "learning_rate": 0.001
  },
  {
    "episode": 1506,
    "reward": 79.521212,
    "length": 85,
    "time": 28367.138114,
    "actor_loss": -35.18243408203125,
    "critic_loss": 29.303300857543945,
    "ent_coef": 0.1423300802707672,
    "learning_rate": 0.001
  },
  {
    "episode": 1507,
    "reward": 82.460017,
    "length": 79,
    "time": 28383.406873,
    "actor_loss": -34.585670471191406,
    "critic_loss": 6.521015167236328,
    "ent_coef": 0.13884058594703674,
    "learning_rate": 0.001
  },
  {
    "episode": 1508,
    "reward": 73.650507,
    "length": 91,
    "time": 28401.955852,
    "actor_loss": -33.860389709472656,
    "critic_loss": 37.88722610473633,
    "ent_coef": 0.1407887190580368,
    "learning_rate": 0.001
  },
  {
    "episode": 1509,
    "reward": 74.01018,
    "length": 87,
    "time": 28417.52021,
    "actor_loss": -36.091209411621094,
    "critic_loss": 179.56597900390625,
    "ent_coef": 0.13501757383346558,
    "learning_rate": 0.001
  },
  {
    "episode": 1510,
    "reward": 75.604397,
    "length": 86,
    "time": 28434.979621,
    "actor_loss": -39.444915771484375,
    "critic_loss": 8.979772567749023,
    "ent_coef": 0.1327933520078659,
    "learning_rate": 0.001
  },
  {
    "episode": 1511,
    "reward": 79.592698,
    "length": 80,
    "time": 28449.65554,
    "actor_loss": -39.39640808105469,
    "critic_loss": 41.03155517578125,
    "ent_coef": 0.1311645805835724,
    "learning_rate": 0.001
  },
  {
    "episode": 1512,
    "reward": 83.728933,
    "length": 74,
    "time": 28466.463574,
    "actor_loss": -38.402732849121094,
    "critic_loss": 48.2545166015625,
    "ent_coef": 0.13045792281627655,
    "learning_rate": 0.001
  },
  {
    "episode": 1513,
    "reward": 86.220826,
    "length": 69,
    "time": 28480.198001,
    "actor_loss": -37.15624237060547,
    "critic_loss": 42.73101043701172,
    "ent_coef": 0.1298324167728424,
    "learning_rate": 0.001
  },
  {
    "episode": 1514,
    "reward": 87.629103,
    "length": 68,
    "time": 28495.71952,
    "actor_loss": -34.22638702392578,
    "critic_loss": 34.2285041809082,
    "ent_coef": 0.12774579226970673,
    "learning_rate": 0.001
  },
  {
    "episode": 1515,
    "reward": 79.668836,
    "length": 82,
    "time": 28512.568851,
    "actor_loss": -35.657806396484375,
    "critic_loss": 12.190834045410156,
    "ent_coef": 0.13080622255802155,
    "learning_rate": 0.001
  },
  {
    "episode": 1516,
    "reward": 74.90988,
    "length": 89,
    "time": 28528.993032,
    "actor_loss": -37.11322021484375,
    "critic_loss": 33.714744567871094,
    "ent_coef": 0.1312987357378006,
    "learning_rate": 0.001
  },
  {
    "episode": 1517,
    "reward": 84.99046,
    "length": 74,
    "time": 28543.191289,
    "actor_loss": -37.02825927734375,
    "critic_loss": 125.09700012207031,
    "ent_coef": 0.1300683170557022,
    "learning_rate": 0.001
  },
  {
    "episode": 1518,
    "reward": 79.734708,
    "length": 77,
    "time": 28557.984008,
    "actor_loss": -30.695911407470703,
    "critic_loss": 7.2887773513793945,
    "ent_coef": 0.12923003733158112,
    "learning_rate": 0.001
  },
  {
    "episode": 1519,
    "reward": 84.063802,
    "length": 80,
    "time": 28572.135227,
    "actor_loss": -27.71190643310547,
    "critic_loss": 58.24138259887695,
    "ent_coef": 0.1291583627462387,
    "learning_rate": 0.001
  },
  {
    "episode": 1520,
    "reward": 79.628363,
    "length": 84,
    "time": 28586.475782,
    "actor_loss": -37.3788948059082,
    "critic_loss": 86.12701416015625,
    "ent_coef": 0.1292983591556549,
    "learning_rate": 0.001
  },
  {
    "episode": 1521,
    "reward": 78.709948,
    "length": 86,
    "time": 28602.503793,
    "actor_loss": -34.10383605957031,
    "critic_loss": 374.7758483886719,
    "ent_coef": 0.12842334806919098,
    "learning_rate": 0.001
  },
  {
    "episode": 1522,
    "reward": 78.431023,
    "length": 89,
    "time": 28619.92606,
    "actor_loss": -34.610694885253906,
    "critic_loss": 10.827917098999023,
    "ent_coef": 0.12139382213354111,
    "learning_rate": 0.001
  },
  {
    "episode": 1523,
    "reward": 72.293897,
    "length": 89,
    "time": 28636.057914,
    "actor_loss": -31.893226623535156,
    "critic_loss": 155.07083129882812,
    "ent_coef": 0.12799562513828278,
    "learning_rate": 0.001
  },
  {
    "episode": 1524,
    "reward": 88.90043,
    "length": 67,
    "time": 28648.794632,
    "actor_loss": -43.84539031982422,
    "critic_loss": 70.59390258789062,
    "ent_coef": 0.12923777103424072,
    "learning_rate": 0.001
  },
  {
    "episode": 1525,
    "reward": 85.103599,
    "length": 73,
    "time": 28661.32658,
    "actor_loss": -39.120243072509766,
    "critic_loss": 8.644257545471191,
    "ent_coef": 0.132680743932724,
    "learning_rate": 0.001
  },
  {
    "episode": 1526,
    "reward": 69.940402,
    "length": 98,
    "time": 28677.206736,
    "actor_loss": -35.049903869628906,
    "critic_loss": 53.25885009765625,
    "ent_coef": 0.13713647425174713,
    "learning_rate": 0.001
  },
  {
    "episode": 1527,
    "reward": 86.066924,
    "length": 70,
    "time": 28691.978792,
    "actor_loss": -34.564659118652344,
    "critic_loss": 107.44636535644531,
    "ent_coef": 0.1373494565486908,
    "learning_rate": 0.001
  },
  {
    "episode": 1528,
    "reward": 86.717155,
    "length": 74,
    "time": 28705.612778,
    "actor_loss": -39.173282623291016,
    "critic_loss": 129.73190307617188,
    "ent_coef": 0.13349542021751404,
    "learning_rate": 0.001
  },
  {
    "episode": 1529,
    "reward": 86.473426,
    "length": 72,
    "time": 28717.958595,
    "actor_loss": -34.261478424072266,
    "critic_loss": 24.629222869873047,
    "ent_coef": 0.13046766817569733,
    "learning_rate": 0.001
  },
  {
    "episode": 1530,
    "reward": 85.244993,
    "length": 76,
    "time": 28731.745449,
    "actor_loss": -35.47773742675781,
    "critic_loss": 17.15866470336914,
    "ent_coef": 0.13378632068634033,
    "learning_rate": 0.001
  },
  {
    "episode": 1531,
    "reward": 85.403438,
    "length": 73,
    "time": 28746.260354,
    "actor_loss": -33.34054183959961,
    "critic_loss": 100.01593017578125,
    "ent_coef": 0.13324971497058868,
    "learning_rate": 0.001
  },
  {
    "episode": 1532,
    "reward": 86.12009,
    "length": 76,
    "time": 28760.607449,
    "actor_loss": -37.135005950927734,
    "critic_loss": 93.45196533203125,
    "ent_coef": 0.1309521347284317,
    "learning_rate": 0.001
  },
  {
    "episode": 1533,
    "reward": 70.93986,
    "length": 94,
    "time": 28776.331036,
    "actor_loss": -43.04930877685547,
    "critic_loss": 57.706336975097656,
    "ent_coef": 0.12637601792812347,
    "learning_rate": 0.001
  },
  {
    "episode": 1534,
    "reward": -160.086375,
    "length": 130,
    "time": 28799.225567,
    "actor_loss": -39.40876007080078,
    "critic_loss": 15.557842254638672,
    "ent_coef": 0.123851478099823,
    "learning_rate": 0.001
  },
  {
    "episode": 1535,
    "reward": 85.37058,
    "length": 80,
    "time": 28813.455833,
    "actor_loss": -37.517547607421875,
    "critic_loss": 13.20004653930664,
    "ent_coef": 0.12174702435731888,
    "learning_rate": 0.001
  },
  {
    "episode": 1536,
    "reward": 87.080616,
    "length": 68,
    "time": 28825.296256,
    "actor_loss": -34.02354049682617,
    "critic_loss": 27.775468826293945,
    "ent_coef": 0.12091521918773651,
    "learning_rate": 0.001
  },
  {
    "episode": 1537,
    "reward": 84.52,
    "length": 78,
    "time": 28838.25512,
    "actor_loss": -40.66828155517578,
    "critic_loss": 74.68159484863281,
    "ent_coef": 0.12402880936861038,
    "learning_rate": 0.001
  },
  {
    "episode": 1538,
    "reward": 82.529608,
    "length": 75,
    "time": 28851.987098,
    "actor_loss": -37.765933990478516,
    "critic_loss": 148.89923095703125,
    "ent_coef": 0.1262098252773285,
    "learning_rate": 0.001
  },
  {
    "episode": 1539,
    "reward": 76.733753,
    "length": 92,
    "time": 28868.262749,
    "actor_loss": -44.82492446899414,
    "critic_loss": 173.91461181640625,
    "ent_coef": 0.12756788730621338,
    "learning_rate": 0.001
  },
  {
    "episode": 1540,
    "reward": 86.99,
    "length": 74,
    "time": 28881.869232,
    "actor_loss": -41.82865524291992,
    "critic_loss": 61.826560974121094,
    "ent_coef": 0.12802064418792725,
    "learning_rate": 0.001
  },
  {
    "episode": 1541,
    "reward": 86.372841,
    "length": 73,
    "time": 28895.104069,
    "actor_loss": -37.385711669921875,
    "critic_loss": 75.28285217285156,
    "ent_coef": 0.1260976493358612,
    "learning_rate": 0.001
  },
  {
    "episode": 1542,
    "reward": 88.014451,
    "length": 68,
    "time": 28907.849741,
    "actor_loss": -43.98261260986328,
    "critic_loss": 123.09359741210938,
    "ent_coef": 0.12823626399040222,
    "learning_rate": 0.001
  },
  {
    "episode": 1543,
    "reward": 83.167195,
    "length": 75,
    "time": 28921.57697,
    "actor_loss": -36.228572845458984,
    "critic_loss": 5.572064399719238,
    "ent_coef": 0.1269497126340866,
    "learning_rate": 0.001
  },
  {
    "episode": 1544,
    "reward": 81.849183,
    "length": 76,
    "time": 28935.27552,
    "actor_loss": -27.616806030273438,
    "critic_loss": 50.90415954589844,
    "ent_coef": 0.12288566678762436,
    "learning_rate": 0.001
  },
  {
    "episode": 1545,
    "reward": 85.86583,
    "length": 72,
    "time": 28948.030699,
    "actor_loss": -40.181827545166016,
    "critic_loss": 96.74819946289062,
    "ent_coef": 0.12116561830043793,
    "learning_rate": 0.001
  },
  {
    "episode": 1546,
    "reward": 77.130374,
    "length": 91,
    "time": 28964.955158,
    "actor_loss": -39.30372619628906,
    "critic_loss": 96.34304809570312,
    "ent_coef": 0.11825716495513916,
    "learning_rate": 0.001
  },
  {
    "episode": 1547,
    "reward": 80.409239,
    "length": 77,
    "time": 28979.574952,
    "actor_loss": -36.487335205078125,
    "critic_loss": 38.419464111328125,
    "ent_coef": 0.11761847883462906,
    "learning_rate": 0.001
  },
  {
    "episode": 1548,
    "reward": 85.003925,
    "length": 76,
    "time": 28994.547679,
    "actor_loss": -37.5015754699707,
    "critic_loss": 22.7080020904541,
    "ent_coef": 0.12046627700328827,
    "learning_rate": 0.001
  },
  {
    "episode": 1549,
    "reward": 81.430126,
    "length": 79,
    "time": 29009.930585,
    "actor_loss": -36.676902770996094,
    "critic_loss": 18.21041488647461,
    "ent_coef": 0.12255512923002243,
    "learning_rate": 0.001
  },
  {
    "episode": 1550,
    "reward": 81.485648,
    "length": 79,
    "time": 29024.759136,
    "actor_loss": -39.4358024597168,
    "critic_loss": 81.59629821777344,
    "ent_coef": 0.1214977353811264,
    "learning_rate": 0.001
  },
  {
    "episode": 1551,
    "reward": 78.84468,
    "length": 113,
    "time": 29042.709064,
    "actor_loss": -37.04582595825195,
    "critic_loss": 53.795860290527344,
    "ent_coef": 0.12275499850511551,
    "learning_rate": 0.001
  },
  {
    "episode": 1552,
    "reward": 76.012815,
    "length": 85,
    "time": 29058.699213,
    "actor_loss": -35.567466735839844,
    "critic_loss": 75.55506896972656,
    "ent_coef": 0.12479718029499054,
    "learning_rate": 0.001
  },
  {
    "episode": 1553,
    "reward": 86.483096,
    "length": 75,
    "time": 29075.346668,
    "actor_loss": -34.93368911743164,
    "critic_loss": 55.542808532714844,
    "ent_coef": 0.12543527781963348,
    "learning_rate": 0.001
  },
  {
    "episode": 1554,
    "reward": 82.866903,
    "length": 77,
    "time": 29088.225788,
    "actor_loss": -34.96286392211914,
    "critic_loss": 158.963623046875,
    "ent_coef": 0.12710559368133545,
    "learning_rate": 0.001
  },
  {
    "episode": 1555,
    "reward": 88.673025,
    "length": 65,
    "time": 29102.190709,
    "actor_loss": -44.51292037963867,
    "critic_loss": 37.622955322265625,
    "ent_coef": 0.1307859718799591,
    "learning_rate": 0.001
  },
  {
    "episode": 1556,
    "reward": 81.602684,
    "length": 79,
    "time": 29115.73301,
    "actor_loss": -34.405723571777344,
    "critic_loss": 9.653475761413574,
    "ent_coef": 0.1292942464351654,
    "learning_rate": 0.001
  },
  {
    "episode": 1557,
    "reward": 80.674691,
    "length": 89,
    "time": 29131.148316,
    "actor_loss": -44.709896087646484,
    "critic_loss": 12.343955993652344,
    "ent_coef": 0.1258796900510788,
    "learning_rate": 0.001
  },
  {
    "episode": 1558,
    "reward": 84.588116,
    "length": 81,
    "time": 29147.604171,
    "actor_loss": -37.92072296142578,
    "critic_loss": 55.20415115356445,
    "ent_coef": 0.126474991440773,
    "learning_rate": 0.001
  },
  {
    "episode": 1559,
    "reward": 76.423908,
    "length": 84,
    "time": 29162.353119,
    "actor_loss": -33.513671875,
    "critic_loss": 24.5759220123291,
    "ent_coef": 0.12821342051029205,
    "learning_rate": 0.001
  },
  {
    "episode": 1560,
    "reward": 84.040747,
    "length": 77,
    "time": 29175.312451,
    "actor_loss": -37.25565719604492,
    "critic_loss": 6.58256721496582,
    "ent_coef": 0.1304524540901184,
    "learning_rate": 0.001
  },
  {
    "episode": 1561,
    "reward": 80.712338,
    "length": 95,
    "time": 29191.60448,
    "actor_loss": -42.59990692138672,
    "critic_loss": 63.993568420410156,
    "ent_coef": 0.13173678517341614,
    "learning_rate": 0.001
  },
  {
    "episode": 1562,
    "reward": 82.904714,
    "length": 79,
    "time": 29206.917665,
    "actor_loss": -35.933380126953125,
    "critic_loss": 45.49861145019531,
    "ent_coef": 0.13069124519824982,
    "learning_rate": 0.001
  },
  {
    "episode": 1563,
    "reward": -169.046564,
    "length": 155,
    "time": 29230.78616,
    "actor_loss": -33.817161560058594,
    "critic_loss": 104.4188003540039,
    "ent_coef": 0.1291770339012146,
    "learning_rate": 0.001
  },
  {
    "episode": 1564,
    "reward": 84.742081,
    "length": 77,
    "time": 29251.227169,
    "actor_loss": -36.9905891418457,
    "critic_loss": 18.859943389892578,
    "ent_coef": 0.13570183515548706,
    "learning_rate": 0.001
  },
  {
    "episode": 1565,
    "reward": -162.833147,
    "length": 145,
    "time": 29272.833329,
    "actor_loss": -40.096466064453125,
    "critic_loss": 33.20771789550781,
    "ent_coef": 0.13828054070472717,
    "learning_rate": 0.001
  },
  {
    "episode": 1566,
    "reward": -156.876492,
    "length": 179,
    "time": 29302.096378,
    "actor_loss": -37.940391540527344,
    "critic_loss": 166.8970947265625,
    "ent_coef": 0.13074442744255066,
    "learning_rate": 0.001
  },
  {
    "episode": 1567,
    "reward": 82.949195,
    "length": 76,
    "time": 29318.54469,
    "actor_loss": -33.08572006225586,
    "critic_loss": 15.251896858215332,
    "ent_coef": 0.14249014854431152,
    "learning_rate": 0.001
  },
  {
    "episode": 1568,
    "reward": -153.339533,
    "length": 116,
    "time": 29338.685983,
    "actor_loss": -35.19300079345703,
    "critic_loss": 140.30770874023438,
    "ent_coef": 0.14316803216934204,
    "learning_rate": 0.001
  },
  {
    "episode": 1569,
    "reward": 85.122563,
    "length": 72,
    "time": 29351.893071,
    "actor_loss": -41.78374481201172,
    "critic_loss": 53.911251068115234,
    "ent_coef": 0.138791024684906,
    "learning_rate": 0.001
  },
  {
    "episode": 1570,
    "reward": 79.10884,
    "length": 85,
    "time": 29365.910526,
    "actor_loss": -34.34954071044922,
    "critic_loss": 132.4845428466797,
    "ent_coef": 0.1394934356212616,
    "learning_rate": 0.001
  },
  {
    "episode": 1571,
    "reward": 83.521346,
    "length": 78,
    "time": 29381.834205,
    "actor_loss": -39.310813903808594,
    "critic_loss": 24.791099548339844,
    "ent_coef": 0.13671469688415527,
    "learning_rate": 0.001
  },
  {
    "episode": 1572,
    "reward": 86.332267,
    "length": 71,
    "time": 29394.065538,
    "actor_loss": -29.39687728881836,
    "critic_loss": 25.874439239501953,
    "ent_coef": 0.13069689273834229,
    "learning_rate": 0.001
  },
  {
    "episode": 1573,
    "reward": 79.435066,
    "length": 80,
    "time": 29407.599315,
    "actor_loss": -34.72331237792969,
    "critic_loss": 63.78172302246094,
    "ent_coef": 0.12505115568637848,
    "learning_rate": 0.001
  },
  {
    "episode": 1574,
    "reward": -155.634915,
    "length": 114,
    "time": 29425.50075,
    "actor_loss": -36.226966857910156,
    "critic_loss": 143.81362915039062,
    "ent_coef": 0.12677988409996033,
    "learning_rate": 0.001
  },
  {
    "episode": 1575,
    "reward": 91.02391,
    "length": 62,
    "time": 29439.713706,
    "actor_loss": -46.790863037109375,
    "critic_loss": 21.33409309387207,
    "ent_coef": 0.12891551852226257,
    "learning_rate": 0.001
  },
  {
    "episode": 1576,
    "reward": 86.270848,
    "length": 70,
    "time": 29452.568004,
    "actor_loss": -39.97639465332031,
    "critic_loss": 117.13519287109375,
    "ent_coef": 0.13130414485931396,
    "learning_rate": 0.001
  },
  {
    "episode": 1577,
    "reward": 87.073501,
    "length": 68,
    "time": 29465.268541,
    "actor_loss": -37.126220703125,
    "critic_loss": 129.367919921875,
    "ent_coef": 0.136422798037529,
    "learning_rate": 0.001
  },
  {
    "episode": 1578,
    "reward": 82.947226,
    "length": 79,
    "time": 29479.291324,
    "actor_loss": -38.43014144897461,
    "critic_loss": 29.336589813232422,
    "ent_coef": 0.14177420735359192,
    "learning_rate": 0.001
  },
  {
    "episode": 1579,
    "reward": -155.480746,
    "length": 139,
    "time": 29499.978334,
    "actor_loss": -35.29222106933594,
    "critic_loss": 33.92859649658203,
    "ent_coef": 0.14006716012954712,
    "learning_rate": 0.001
  },
  {
    "episode": 1580,
    "reward": 86.080399,
    "length": 70,
    "time": 29515.581589,
    "actor_loss": -40.20233917236328,
    "critic_loss": 84.73836517333984,
    "ent_coef": 0.14345774054527283,
    "learning_rate": 0.001
  },
  {
    "episode": 1581,
    "reward": 87.648257,
    "length": 71,
    "time": 29529.535489,
    "actor_loss": -40.519798278808594,
    "critic_loss": 31.24489974975586,
    "ent_coef": 0.14573195576667786,
    "learning_rate": 0.001
  },
  {
    "episode": 1582,
    "reward": 79.551565,
    "length": 79,
    "time": 29543.240025,
    "actor_loss": -48.26797866821289,
    "critic_loss": 127.22445678710938,
    "ent_coef": 0.14326953887939453,
    "learning_rate": 0.001
  },
  {
    "episode": 1583,
    "reward": 74.792695,
    "length": 101,
    "time": 29561.831394,
    "actor_loss": -39.90271759033203,
    "critic_loss": 132.9686279296875,
    "ent_coef": 0.13503161072731018,
    "learning_rate": 0.001
  },
  {
    "episode": 1584,
    "reward": -158.079074,
    "length": 130,
    "time": 29582.007927,
    "actor_loss": -35.33670425415039,
    "critic_loss": 95.07028198242188,
    "ent_coef": 0.1378123164176941,
    "learning_rate": 0.001
  },
  {
    "episode": 1585,
    "reward": 88.575721,
    "length": 70,
    "time": 29594.811006,
    "actor_loss": -34.74195098876953,
    "critic_loss": 23.480300903320312,
    "ent_coef": 0.14912767708301544,
    "learning_rate": 0.001
  },
  {
    "episode": 1586,
    "reward": 85.819858,
    "length": 68,
    "time": 29608.491158,
    "actor_loss": -40.589942932128906,
    "critic_loss": 162.58248901367188,
    "ent_coef": 0.15337157249450684,
    "learning_rate": 0.001
  },
  {
    "episode": 1587,
    "reward": 92.217698,
    "length": 58,
    "time": 29620.048495,
    "actor_loss": -38.47956466674805,
    "critic_loss": 135.26531982421875,
    "ent_coef": 0.15788902342319489,
    "learning_rate": 0.001
  },
  {
    "episode": 1588,
    "reward": -160.278165,
    "length": 183,
    "time": 29646.841681,
    "actor_loss": -29.931568145751953,
    "critic_loss": 22.44363021850586,
    "ent_coef": 0.14953242242336273,
    "learning_rate": 0.001
  },
  {
    "episode": 1589,
    "reward": 80.52972,
    "length": 78,
    "time": 29660.907651,
    "actor_loss": -39.02154541015625,
    "critic_loss": 21.98369026184082,
    "ent_coef": 0.14781978726387024,
    "learning_rate": 0.001
  },
  {
    "episode": 1590,
    "reward": 86.030988,
    "length": 70,
    "time": 29672.863254,
    "actor_loss": -38.344844818115234,
    "critic_loss": 59.6385383605957,
    "ent_coef": 0.14548571407794952,
    "learning_rate": 0.001
  },
  {
    "episode": 1591,
    "reward": 87.559473,
    "length": 67,
    "time": 29684.751906,
    "actor_loss": -35.10127258300781,
    "critic_loss": 20.18114471435547,
    "ent_coef": 0.1410139799118042,
    "learning_rate": 0.001
  },
  {
    "episode": 1592,
    "reward": 86.701813,
    "length": 68,
    "time": 29698.723337,
    "actor_loss": -36.72461700439453,
    "critic_loss": 103.49700927734375,
    "ent_coef": 0.14391525089740753,
    "learning_rate": 0.001
  },
  {
    "episode": 1593,
    "reward": 83.141938,
    "length": 108,
    "time": 29715.995767,
    "actor_loss": -32.77276611328125,
    "critic_loss": 36.456356048583984,
    "ent_coef": 0.15264210104942322,
    "learning_rate": 0.001
  },
  {
    "episode": 1594,
    "reward": 87.629466,
    "length": 67,
    "time": 29727.549943,
    "actor_loss": -38.383270263671875,
    "critic_loss": 17.466524124145508,
    "ent_coef": 0.15278451144695282,
    "learning_rate": 0.001
  },
  {
    "episode": 1595,
    "reward": 80.029044,
    "length": 85,
    "time": 29741.640525,
    "actor_loss": -39.93075180053711,
    "critic_loss": 291.54833984375,
    "ent_coef": 0.1447281390428543,
    "learning_rate": 0.001
  },
  {
    "episode": 1596,
    "reward": 86.945536,
    "length": 67,
    "time": 29753.834093,
    "actor_loss": -30.378982543945312,
    "critic_loss": 16.024330139160156,
    "ent_coef": 0.14636337757110596,
    "learning_rate": 0.001
  },
  {
    "episode": 1597,
    "reward": -153.753515,
    "length": 121,
    "time": 29772.325186,
    "actor_loss": -40.93997573852539,
    "critic_loss": 128.4770050048828,
    "ent_coef": 0.1463836431503296,
    "learning_rate": 0.001
  },
  {
    "episode": 1598,
    "reward": 79.911661,
    "length": 80,
    "time": 29786.978475,
    "actor_loss": -36.80499267578125,
    "critic_loss": 49.384952545166016,
    "ent_coef": 0.1450597643852234,
    "learning_rate": 0.001
  },
  {
    "episode": 1599,
    "reward": 84.067873,
    "length": 113,
    "time": 29806.471044,
    "actor_loss": -38.824127197265625,
    "critic_loss": 57.86005401611328,
    "ent_coef": 0.1474635750055313,
    "learning_rate": 0.001
  },
  {
    "episode": 1600,
    "reward": 86.331259,
    "length": 69,
    "time": 29818.508524,
    "actor_loss": -26.41242027282715,
    "critic_loss": 133.3607940673828,
    "ent_coef": 0.1489133983850479,
    "learning_rate": 0.001
  },
  {
    "episode": 1601,
    "reward": -162.911796,
    "length": 142,
    "time": 29843.095677,
    "actor_loss": -43.102294921875,
    "critic_loss": 56.725547790527344,
    "ent_coef": 0.1416843831539154,
    "learning_rate": 0.001
  },
  {
    "episode": 1602,
    "reward": 87.235366,
    "length": 73,
    "time": 29856.431149,
    "actor_loss": -39.80849838256836,
    "critic_loss": 6.3843913078308105,
    "ent_coef": 0.13962669670581818,
    "learning_rate": 0.001
  },
  {
    "episode": 1603,
    "reward": 88.493729,
    "length": 67,
    "time": 29869.338679,
    "actor_loss": -38.944969177246094,
    "critic_loss": 21.647756576538086,
    "ent_coef": 0.14289240539073944,
    "learning_rate": 0.001
  },
  {
    "episode": 1604,
    "reward": 87.43566,
    "length": 66,
    "time": 29881.336734,
    "actor_loss": -39.422481536865234,
    "critic_loss": 376.72625732421875,
    "ent_coef": 0.14779604971408844,
    "learning_rate": 0.001
  },
  {
    "episode": 1605,
    "reward": 89.351329,
    "length": 66,
    "time": 29896.219993,
    "actor_loss": -39.09477996826172,
    "critic_loss": 20.178768157958984,
    "ent_coef": 0.14986494183540344,
    "learning_rate": 0.001
  },
  {
    "episode": 1606,
    "reward": 86.526935,
    "length": 70,
    "time": 29908.721463,
    "actor_loss": -41.327308654785156,
    "critic_loss": 121.86900329589844,
    "ent_coef": 0.1516106277704239,
    "learning_rate": 0.001
  },
  {
    "episode": 1607,
    "reward": 80.534282,
    "length": 77,
    "time": 29921.879572,
    "actor_loss": -36.8577995300293,
    "critic_loss": 115.09062194824219,
    "ent_coef": 0.15070326626300812,
    "learning_rate": 0.001
  },
  {
    "episode": 1608,
    "reward": 88.019139,
    "length": 67,
    "time": 29935.395245,
    "actor_loss": -36.88188934326172,
    "critic_loss": 24.587398529052734,
    "ent_coef": 0.15223509073257446,
    "learning_rate": 0.001
  },
  {
    "episode": 1609,
    "reward": 85.912175,
    "length": 74,
    "time": 29948.955503,
    "actor_loss": -41.91508483886719,
    "critic_loss": 14.741402626037598,
    "ent_coef": 0.15374203026294708,
    "learning_rate": 0.001
  },
  {
    "episode": 1610,
    "reward": 85.671667,
    "length": 70,
    "time": 29960.919833,
    "actor_loss": -36.022239685058594,
    "critic_loss": 49.63572311401367,
    "ent_coef": 0.15466032922267914,
    "learning_rate": 0.001
  },
  {
    "episode": 1611,
    "reward": 88.919404,
    "length": 65,
    "time": 29972.558467,
    "actor_loss": -46.03253173828125,
    "critic_loss": 117.93475341796875,
    "ent_coef": 0.1525282859802246,
    "learning_rate": 0.001
  },
  {
    "episode": 1612,
    "reward": 83.00862,
    "length": 79,
    "time": 29986.550242,
    "actor_loss": -36.90230941772461,
    "critic_loss": 137.90390014648438,
    "ent_coef": 0.1517861932516098,
    "learning_rate": 0.001
  },
  {
    "episode": 1613,
    "reward": 87.929975,
    "length": 69,
    "time": 29998.927181,
    "actor_loss": -42.38927459716797,
    "critic_loss": 272.40740966796875,
    "ent_coef": 0.151712104678154,
    "learning_rate": 0.001
  },
  {
    "episode": 1614,
    "reward": 88.338859,
    "length": 67,
    "time": 30011.643448,
    "actor_loss": -36.04701232910156,
    "critic_loss": 6.433836936950684,
    "ent_coef": 0.15523944795131683,
    "learning_rate": 0.001
  },
  {
    "episode": 1615,
    "reward": 87.752347,
    "length": 66,
    "time": 30023.255538,
    "actor_loss": -38.02935791015625,
    "critic_loss": 14.194851875305176,
    "ent_coef": 0.16159112751483917,
    "learning_rate": 0.001
  },
  {
    "episode": 1616,
    "reward": 82.154233,
    "length": 75,
    "time": 30036.102898,
    "actor_loss": -32.32539367675781,
    "critic_loss": 23.720373153686523,
    "ent_coef": 0.16271400451660156,
    "learning_rate": 0.001
  },
  {
    "episode": 1617,
    "reward": 84.92715,
    "length": 72,
    "time": 30049.976036,
    "actor_loss": -36.79238510131836,
    "critic_loss": 50.33658218383789,
    "ent_coef": 0.15706239640712738,
    "learning_rate": 0.001
  },
  {
    "episode": 1618,
    "reward": 88.118736,
    "length": 66,
    "time": 30063.734086,
    "actor_loss": -39.86497497558594,
    "critic_loss": 26.820602416992188,
    "ent_coef": 0.15551573038101196,
    "learning_rate": 0.001
  },
  {
    "episode": 1619,
    "reward": 88.294402,
    "length": 67,
    "time": 30075.324574,
    "actor_loss": -41.63224792480469,
    "critic_loss": 29.675819396972656,
    "ent_coef": 0.15454623103141785,
    "learning_rate": 0.001
  },
  {
    "episode": 1620,
    "reward": 85.506981,
    "length": 69,
    "time": 30087.599947,
    "actor_loss": -42.4371337890625,
    "critic_loss": 420.1128234863281,
    "ent_coef": 0.1509622484445572,
    "learning_rate": 0.001
  },
  {
    "episode": 1621,
    "reward": 84.291554,
    "length": 73,
    "time": 30099.93312,
    "actor_loss": -36.98362731933594,
    "critic_loss": 79.18065643310547,
    "ent_coef": 0.15012551844120026,
    "learning_rate": 0.001
  },
  {
    "episode": 1622,
    "reward": 84.09498,
    "length": 72,
    "time": 30113.053193,
    "actor_loss": -42.83788299560547,
    "critic_loss": 31.554439544677734,
    "ent_coef": 0.15081757307052612,
    "learning_rate": 0.001
  },
  {
    "episode": 1623,
    "reward": 86.589311,
    "length": 70,
    "time": 30125.094021,
    "actor_loss": -31.83233642578125,
    "critic_loss": 81.40699005126953,
    "ent_coef": 0.15089896321296692,
    "learning_rate": 0.001
  },
  {
    "episode": 1624,
    "reward": 88.166043,
    "length": 66,
    "time": 30137.634845,
    "actor_loss": -40.94892120361328,
    "critic_loss": 67.02716064453125,
    "ent_coef": 0.15032993257045746,
    "learning_rate": 0.001
  },
  {
    "episode": 1625,
    "reward": 89.152247,
    "length": 65,
    "time": 30151.302871,
    "actor_loss": -34.817657470703125,
    "critic_loss": 86.77374267578125,
    "ent_coef": 0.14918407797813416,
    "learning_rate": 0.001
  },
  {
    "episode": 1626,
    "reward": 82.051634,
    "length": 76,
    "time": 30164.192745,
    "actor_loss": -38.05813980102539,
    "critic_loss": 125.84954071044922,
    "ent_coef": 0.14377900958061218,
    "learning_rate": 0.001
  },
  {
    "episode": 1627,
    "reward": 76.950981,
    "length": 88,
    "time": 30179.316517,
    "actor_loss": -35.52764129638672,
    "critic_loss": 128.7062530517578,
    "ent_coef": 0.13924576342105865,
    "learning_rate": 0.001
  },
  {
    "episode": 1628,
    "reward": 83.722876,
    "length": 76,
    "time": 30193.017962,
    "actor_loss": -41.32861328125,
    "critic_loss": 59.59370803833008,
    "ent_coef": 0.13788533210754395,
    "learning_rate": 0.001
  },
  {
    "episode": 1629,
    "reward": 90.944636,
    "length": 61,
    "time": 30204.752517,
    "actor_loss": -40.169097900390625,
    "critic_loss": 105.95758056640625,
    "ent_coef": 0.13918527960777283,
    "learning_rate": 0.001
  },
  {
    "episode": 1630,
    "reward": 88.258406,
    "length": 65,
    "time": 30218.397902,
    "actor_loss": -43.88074493408203,
    "critic_loss": 70.02664184570312,
    "ent_coef": 0.1458318531513214,
    "learning_rate": 0.001
  },
  {
    "episode": 1631,
    "reward": 88.040736,
    "length": 65,
    "time": 30230.880401,
    "actor_loss": -37.79740524291992,
    "critic_loss": 13.4642915725708,
    "ent_coef": 0.1504463106393814,
    "learning_rate": 0.001
  },
  {
    "episode": 1632,
    "reward": 89.356213,
    "length": 65,
    "time": 30242.531281,
    "actor_loss": -43.69108200073242,
    "critic_loss": 68.20486450195312,
    "ent_coef": 0.1544998586177826,
    "learning_rate": 0.001
  },
  {
    "episode": 1633,
    "reward": 89.338047,
    "length": 64,
    "time": 30254.322071,
    "actor_loss": -34.08283233642578,
    "critic_loss": 108.99092102050781,
    "ent_coef": 0.15538373589515686,
    "learning_rate": 0.001
  },
  {
    "episode": 1634,
    "reward": 85.606268,
    "length": 71,
    "time": 30266.675102,
    "actor_loss": -35.92691421508789,
    "critic_loss": 10.008312225341797,
    "ent_coef": 0.1567024290561676,
    "learning_rate": 0.001
  },
  {
    "episode": 1635,
    "reward": 87.294349,
    "length": 69,
    "time": 30279.497926,
    "actor_loss": -36.53533935546875,
    "critic_loss": 49.160858154296875,
    "ent_coef": 0.15435725450515747,
    "learning_rate": 0.001
  },
  {
    "episode": 1636,
    "reward": 85.944804,
    "length": 71,
    "time": 30291.937906,
    "actor_loss": -46.642295837402344,
    "critic_loss": 37.844757080078125,
    "ent_coef": 0.1545809507369995,
    "learning_rate": 0.001
  },
  {
    "episode": 1637,
    "reward": 85.078318,
    "length": 71,
    "time": 30304.201196,
    "actor_loss": -41.8408203125,
    "critic_loss": 21.305294036865234,
    "ent_coef": 0.15624935925006866,
    "learning_rate": 0.001
  },
  {
    "episode": 1638,
    "reward": 87.966261,
    "length": 67,
    "time": 30317.211477,
    "actor_loss": -42.32685089111328,
    "critic_loss": 19.633956909179688,
    "ent_coef": 0.15964724123477936,
    "learning_rate": 0.001
  },
  {
    "episode": 1639,
    "reward": 78.632781,
    "length": 81,
    "time": 30331.743904,
    "actor_loss": -43.3260612487793,
    "critic_loss": 80.78263854980469,
    "ent_coef": 0.15899154543876648,
    "learning_rate": 0.001
  },
  {
    "episode": 1640,
    "reward": -167.771981,
    "length": 156,
    "time": 30354.881042,
    "actor_loss": -32.57050323486328,
    "critic_loss": 90.92257690429688,
    "ent_coef": 0.15122713148593903,
    "learning_rate": 0.001
  },
  {
    "episode": 1641,
    "reward": -158.18325,
    "length": 130,
    "time": 30376.739898,
    "actor_loss": -41.975547790527344,
    "critic_loss": 119.23893737792969,
    "ent_coef": 0.14526858925819397,
    "learning_rate": 0.001
  },
  {
    "episode": 1642,
    "reward": 83.418419,
    "length": 74,
    "time": 30390.686444,
    "actor_loss": -43.34569549560547,
    "critic_loss": 12.951560020446777,
    "ent_coef": 0.1437968611717224,
    "learning_rate": 0.001
  },
  {
    "episode": 1643,
    "reward": 78.962255,
    "length": 80,
    "time": 30404.115263,
    "actor_loss": -35.226890563964844,
    "critic_loss": 14.900161743164062,
    "ent_coef": 0.1422916203737259,
    "learning_rate": 0.001
  },
  {
    "episode": 1644,
    "reward": 78.70396,
    "length": 85,
    "time": 30418.049399,
    "actor_loss": -43.70901107788086,
    "critic_loss": 43.58544921875,
    "ent_coef": 0.1427675485610962,
    "learning_rate": 0.001
  },
  {
    "episode": 1645,
    "reward": 85.914366,
    "length": 70,
    "time": 30430.165736,
    "actor_loss": -34.438873291015625,
    "critic_loss": 11.309534072875977,
    "ent_coef": 0.1468164175748825,
    "learning_rate": 0.001
  },
  {
    "episode": 1646,
    "reward": 80.825122,
    "length": 156,
    "time": 30455.634477,
    "actor_loss": -41.83686828613281,
    "critic_loss": 24.74195671081543,
    "ent_coef": 0.14815837144851685,
    "learning_rate": 0.001
  },
  {
    "episode": 1647,
    "reward": 82.881303,
    "length": 76,
    "time": 30469.223175,
    "actor_loss": -40.15174865722656,
    "critic_loss": 26.182697296142578,
    "ent_coef": 0.14657779037952423,
    "learning_rate": 0.001
  },
  {
    "episode": 1648,
    "reward": 82.18063,
    "length": 78,
    "time": 30483.792857,
    "actor_loss": -29.562047958374023,
    "critic_loss": 13.554323196411133,
    "ent_coef": 0.14781346917152405,
    "learning_rate": 0.001
  },
  {
    "episode": 1649,
    "reward": 85.947255,
    "length": 71,
    "time": 30499.673406,
    "actor_loss": -42.71181869506836,
    "critic_loss": 53.28645706176758,
    "ent_coef": 0.1478346884250641,
    "learning_rate": 0.001
  },
  {
    "episode": 1650,
    "reward": 89.037747,
    "length": 66,
    "time": 30514.451902,
    "actor_loss": -41.225135803222656,
    "critic_loss": 18.28723907470703,
    "ent_coef": 0.1539182811975479,
    "learning_rate": 0.001
  },
  {
    "episode": 1651,
    "reward": 88.283731,
    "length": 66,
    "time": 30527.089313,
    "actor_loss": -43.731353759765625,
    "critic_loss": 32.67938995361328,
    "ent_coef": 0.15328191220760345,
    "learning_rate": 0.001
  },
  {
    "episode": 1652,
    "reward": 88.540319,
    "length": 68,
    "time": 30538.92235,
    "actor_loss": -44.79606246948242,
    "critic_loss": 49.33811950683594,
    "ent_coef": 0.15496395528316498,
    "learning_rate": 0.001
  },
  {
    "episode": 1653,
    "reward": 88.067496,
    "length": 66,
    "time": 30550.673697,
    "actor_loss": -35.424537658691406,
    "critic_loss": 64.73734283447266,
    "ent_coef": 0.1582213193178177,
    "learning_rate": 0.001
  },
  {
    "episode": 1654,
    "reward": 83.762967,
    "length": 80,
    "time": 30566.318844,
    "actor_loss": -45.833641052246094,
    "critic_loss": 82.38101196289062,
    "ent_coef": 0.16068582236766815,
    "learning_rate": 0.001
  },
  {
    "episode": 1655,
    "reward": 85.440609,
    "length": 72,
    "time": 30579.838737,
    "actor_loss": -46.80581283569336,
    "critic_loss": 14.640464782714844,
    "ent_coef": 0.160669207572937,
    "learning_rate": 0.001
  },
  {
    "episode": 1656,
    "reward": 89.788168,
    "length": 65,
    "time": 30592.378011,
    "actor_loss": -40.18122100830078,
    "critic_loss": 46.96453857421875,
    "ent_coef": 0.15900824964046478,
    "learning_rate": 0.001
  },
  {
    "episode": 1657,
    "reward": 83.586679,
    "length": 76,
    "time": 30606.727321,
    "actor_loss": -39.241615295410156,
    "critic_loss": 150.41571044921875,
    "ent_coef": 0.160127192735672,
    "learning_rate": 0.001
  },
  {
    "episode": 1658,
    "reward": 87.877316,
    "length": 70,
    "time": 30618.994561,
    "actor_loss": -33.50083541870117,
    "critic_loss": 67.94526672363281,
    "ent_coef": 0.15504373610019684,
    "learning_rate": 0.001
  },
  {
    "episode": 1659,
    "reward": 72.896651,
    "length": 95,
    "time": 30634.148018,
    "actor_loss": -33.83307647705078,
    "critic_loss": 53.95341491699219,
    "ent_coef": 0.15328024327754974,
    "learning_rate": 0.001
  },
  {
    "episode": 1660,
    "reward": 85.587274,
    "length": 71,
    "time": 30647.186328,
    "actor_loss": -41.02764129638672,
    "critic_loss": 103.39169311523438,
    "ent_coef": 0.15473856031894684,
    "learning_rate": 0.001
  },
  {
    "episode": 1661,
    "reward": 86.427066,
    "length": 72,
    "time": 30659.605536,
    "actor_loss": -43.666507720947266,
    "critic_loss": 42.622798919677734,
    "ent_coef": 0.15555636584758759,
    "learning_rate": 0.001
  },
  {
    "episode": 1662,
    "reward": 80.849001,
    "length": 80,
    "time": 30675.206742,
    "actor_loss": -36.766578674316406,
    "critic_loss": 47.578636169433594,
    "ent_coef": 0.15929970145225525,
    "learning_rate": 0.001
  },
  {
    "episode": 1663,
    "reward": 84.787063,
    "length": 72,
    "time": 30689.121634,
    "actor_loss": -41.66553497314453,
    "critic_loss": 36.022499084472656,
    "ent_coef": 0.15578854084014893,
    "learning_rate": 0.001
  },
  {
    "episode": 1664,
    "reward": 84.972721,
    "length": 76,
    "time": 30704.03002,
    "actor_loss": -36.56201171875,
    "critic_loss": 5.875161170959473,
    "ent_coef": 0.15656834840774536,
    "learning_rate": 0.001
  },
  {
    "episode": 1665,
    "reward": 85.994486,
    "length": 71,
    "time": 30718.943258,
    "actor_loss": -40.80549621582031,
    "critic_loss": 491.72528076171875,
    "ent_coef": 0.15961511433124542,
    "learning_rate": 0.001
  },
  {
    "episode": 1666,
    "reward": 84.883659,
    "length": 73,
    "time": 30732.443596,
    "actor_loss": -41.52260208129883,
    "critic_loss": 99.06055450439453,
    "ent_coef": 0.160316601395607,
    "learning_rate": 0.001
  },
  {
    "episode": 1667,
    "reward": 83.905193,
    "length": 74,
    "time": 30747.670616,
    "actor_loss": -40.43811798095703,
    "critic_loss": 110.0836181640625,
    "ent_coef": 0.16093643009662628,
    "learning_rate": 0.001
  },
  {
    "episode": 1668,
    "reward": 90.204486,
    "length": 63,
    "time": 30758.766554,
    "actor_loss": -44.33063507080078,
    "critic_loss": 5.34499454498291,
    "ent_coef": 0.15981635451316833,
    "learning_rate": 0.001
  },
  {
    "episode": 1669,
    "reward": 85.73662,
    "length": 75,
    "time": 30771.840698,
    "actor_loss": -44.386390686035156,
    "critic_loss": 179.24729919433594,
    "ent_coef": 0.15401721000671387,
    "learning_rate": 0.001
  },
  {
    "episode": 1670,
    "reward": 90.172243,
    "length": 63,
    "time": 30783.501619,
    "actor_loss": -35.22674560546875,
    "critic_loss": 164.57742309570312,
    "ent_coef": 0.15884451568126678,
    "learning_rate": 0.001
  },
  {
    "episode": 1671,
    "reward": 85.702236,
    "length": 72,
    "time": 30799.991079,
    "actor_loss": -41.57012939453125,
    "critic_loss": 48.397193908691406,
    "ent_coef": 0.16028060019016266,
    "learning_rate": 0.001
  },
  {
    "episode": 1672,
    "reward": 87.089668,
    "length": 70,
    "time": 30812.034245,
    "actor_loss": -38.087249755859375,
    "critic_loss": 20.715858459472656,
    "ent_coef": 0.16078931093215942,
    "learning_rate": 0.001
  },
  {
    "episode": 1673,
    "reward": 88.942553,
    "length": 64,
    "time": 30825.977301,
    "actor_loss": -37.28717803955078,
    "critic_loss": 16.330402374267578,
    "ent_coef": 0.16520944237709045,
    "learning_rate": 0.001
  },
  {
    "episode": 1674,
    "reward": 82.027306,
    "length": 79,
    "time": 30839.080225,
    "actor_loss": -46.490013122558594,
    "critic_loss": 32.050140380859375,
    "ent_coef": 0.17139045894145966,
    "learning_rate": 0.001
  },
  {
    "episode": 1675,
    "reward": 88.251478,
    "length": 66,
    "time": 30851.403062,
    "actor_loss": -42.99930191040039,
    "critic_loss": 48.07592010498047,
    "ent_coef": 0.17886513471603394,
    "learning_rate": 0.001
  },
  {
    "episode": 1676,
    "reward": 84.745834,
    "length": 73,
    "time": 30866.024027,
    "actor_loss": -43.649635314941406,
    "critic_loss": 22.219505310058594,
    "ent_coef": 0.17842015624046326,
    "learning_rate": 0.001
  },
  {
    "episode": 1677,
    "reward": 86.655497,
    "length": 71,
    "time": 30878.227377,
    "actor_loss": -44.26805877685547,
    "critic_loss": 204.0091552734375,
    "ent_coef": 0.17370453476905823,
    "learning_rate": 0.001
  },
  {
    "episode": 1678,
    "reward": 84.425279,
    "length": 78,
    "time": 30892.755608,
    "actor_loss": -38.48928451538086,
    "critic_loss": 226.67933654785156,
    "ent_coef": 0.16685934364795685,
    "learning_rate": 0.001
  },
  {
    "episode": 1679,
    "reward": 86.179891,
    "length": 71,
    "time": 30906.117754,
    "actor_loss": -44.74190902709961,
    "critic_loss": 9.474569320678711,
    "ent_coef": 0.1650724709033966,
    "learning_rate": 0.001
  },
  {
    "episode": 1680,
    "reward": 85.572989,
    "length": 70,
    "time": 30921.109365,
    "actor_loss": -32.28705596923828,
    "critic_loss": 5.62852668762207,
    "ent_coef": 0.16557526588439941,
    "learning_rate": 0.001
  },
  {
    "episode": 1681,
    "reward": 88.548879,
    "length": 68,
    "time": 30933.98415,
    "actor_loss": -43.364803314208984,
    "critic_loss": 76.12026977539062,
    "ent_coef": 0.16490544378757477,
    "learning_rate": 0.001
  },
  {
    "episode": 1682,
    "reward": 86.121015,
    "length": 70,
    "time": 30949.645728,
    "actor_loss": -41.87932586669922,
    "critic_loss": 54.073123931884766,
    "ent_coef": 0.16227848827838898,
    "learning_rate": 0.001
  },
  {
    "episode": 1683,
    "reward": 86.089407,
    "length": 71,
    "time": 30964.884278,
    "actor_loss": -39.85055160522461,
    "critic_loss": 43.10507583618164,
    "ent_coef": 0.16322650015354156,
    "learning_rate": 0.001
  },
  {
    "episode": 1684,
    "reward": 85.520774,
    "length": 71,
    "time": 30979.160717,
    "actor_loss": -45.298561096191406,
    "critic_loss": 33.41621780395508,
    "ent_coef": 0.16138862073421478,
    "learning_rate": 0.001
  },
  {
    "episode": 1685,
    "reward": 86.575137,
    "length": 71,
    "time": 30991.38996,
    "actor_loss": -45.65672302246094,
    "critic_loss": 29.02288055419922,
    "ent_coef": 0.15906131267547607,
    "learning_rate": 0.001
  },
  {
    "episode": 1686,
    "reward": 88.363874,
    "length": 68,
    "time": 31004.158086,
    "actor_loss": -40.84538269042969,
    "critic_loss": 31.3326416015625,
    "ent_coef": 0.16090163588523865,
    "learning_rate": 0.001
  },
  {
    "episode": 1687,
    "reward": 85.926381,
    "length": 69,
    "time": 31016.153274,
    "actor_loss": -41.961612701416016,
    "critic_loss": 9.509201049804688,
    "ent_coef": 0.15586085617542267,
    "learning_rate": 0.001
  },
  {
    "episode": 1688,
    "reward": 85.075776,
    "length": 76,
    "time": 31029.299089,
    "actor_loss": -38.88836669921875,
    "critic_loss": 24.983814239501953,
    "ent_coef": 0.147935152053833,
    "learning_rate": 0.001
  },
  {
    "episode": 1689,
    "reward": 83.338825,
    "length": 77,
    "time": 31045.027544,
    "actor_loss": -38.646949768066406,
    "critic_loss": 39.45510482788086,
    "ent_coef": 0.14501772820949554,
    "learning_rate": 0.001
  },
  {
    "episode": 1690,
    "reward": 84.727397,
    "length": 76,
    "time": 31059.055706,
    "actor_loss": -43.37152862548828,
    "critic_loss": 204.35205078125,
    "ent_coef": 0.14689135551452637,
    "learning_rate": 0.001
  },
  {
    "episode": 1691,
    "reward": 78.295016,
    "length": 87,
    "time": 31075.098846,
    "actor_loss": -44.95708084106445,
    "critic_loss": 616.7357177734375,
    "ent_coef": 0.14506594836711884,
    "learning_rate": 0.001
  },
  {
    "episode": 1692,
    "reward": -156.945128,
    "length": 118,
    "time": 31093.264828,
    "actor_loss": -39.366973876953125,
    "critic_loss": 41.659481048583984,
    "ent_coef": 0.14654400944709778,
    "learning_rate": 0.001
  },
  {
    "episode": 1693,
    "reward": 87.94755,
    "length": 65,
    "time": 31105.585655,
    "actor_loss": -36.10951232910156,
    "critic_loss": 179.22015380859375,
    "ent_coef": 0.14700022339820862,
    "learning_rate": 0.001
  },
  {
    "episode": 1694,
    "reward": 85.964256,
    "length": 70,
    "time": 31120.769127,
    "actor_loss": -33.70685577392578,
    "critic_loss": 38.88389205932617,
    "ent_coef": 0.1475188136100769,
    "learning_rate": 0.001
  },
  {
    "episode": 1695,
    "reward": 87.849368,
    "length": 68,
    "time": 31133.80334,
    "actor_loss": -42.65284729003906,
    "critic_loss": 21.23412322998047,
    "ent_coef": 0.15125210583209991,
    "learning_rate": 0.001
  },
  {
    "episode": 1696,
    "reward": 78.097404,
    "length": 81,
    "time": 31149.116731,
    "actor_loss": -43.57659149169922,
    "critic_loss": 19.23883056640625,
    "ent_coef": 0.14703063666820526,
    "learning_rate": 0.001
  },
  {
    "episode": 1697,
    "reward": 84.884955,
    "length": 73,
    "time": 31162.492961,
    "actor_loss": -48.53352737426758,
    "critic_loss": 17.53323745727539,
    "ent_coef": 0.14538423717021942,
    "learning_rate": 0.001
  },
  {
    "episode": 1698,
    "reward": 89.407324,
    "length": 65,
    "time": 31173.928883,
    "actor_loss": -47.53007507324219,
    "critic_loss": 32.10908126831055,
    "ent_coef": 0.14262430369853973,
    "learning_rate": 0.001
  },
  {
    "episode": 1699,
    "reward": 88.326688,
    "length": 67,
    "time": 31187.767848,
    "actor_loss": -35.182334899902344,
    "critic_loss": 19.48212432861328,
    "ent_coef": 0.13972866535186768,
    "learning_rate": 0.001
  },
  {
    "episode": 1700,
    "reward": 85.959412,
    "length": 71,
    "time": 31199.918694,
    "actor_loss": -42.23240280151367,
    "critic_loss": 28.404369354248047,
    "ent_coef": 0.14275239408016205,
    "learning_rate": 0.001
  },
  {
    "episode": 1701,
    "reward": 87.827311,
    "length": 68,
    "time": 31211.788478,
    "actor_loss": -40.236454010009766,
    "critic_loss": 13.67470932006836,
    "ent_coef": 0.1439812332391739,
    "learning_rate": 0.001
  },
  {
    "episode": 1702,
    "reward": 88.57825,
    "length": 66,
    "time": 31223.417549,
    "actor_loss": -40.68080139160156,
    "critic_loss": 34.301483154296875,
    "ent_coef": 0.1424679458141327,
    "learning_rate": 0.001
  },
  {
    "episode": 1703,
    "reward": 89.365933,
    "length": 65,
    "time": 31237.175107,
    "actor_loss": -40.55584716796875,
    "critic_loss": 8.632002830505371,
    "ent_coef": 0.1430048942565918,
    "learning_rate": 0.001
  },
  {
    "episode": 1704,
    "reward": 88.501942,
    "length": 67,
    "time": 31248.844884,
    "actor_loss": -38.978092193603516,
    "critic_loss": 60.672401428222656,
    "ent_coef": 0.143670454621315,
    "learning_rate": 0.001
  },
  {
    "episode": 1705,
    "reward": 88.632117,
    "length": 70,
    "time": 31261.713458,
    "actor_loss": -42.46323013305664,
    "critic_loss": 57.434959411621094,
    "ent_coef": 0.14333179593086243,
    "learning_rate": 0.001
  },
  {
    "episode": 1706,
    "reward": 87.9988,
    "length": 67,
    "time": 31275.438814,
    "actor_loss": -39.04839324951172,
    "critic_loss": 76.19935607910156,
    "ent_coef": 0.14661861956119537,
    "learning_rate": 0.001
  },
  {
    "episode": 1707,
    "reward": -157.587266,
    "length": 118,
    "time": 31294.838191,
    "actor_loss": -40.73332977294922,
    "critic_loss": 112.87141418457031,
    "ent_coef": 0.1418008953332901,
    "learning_rate": 0.001
  },
  {
    "episode": 1708,
    "reward": 87.941636,
    "length": 71,
    "time": 31307.352222,
    "actor_loss": -40.90570068359375,
    "critic_loss": 64.30679321289062,
    "ent_coef": 0.1413150578737259,
    "learning_rate": 0.001
  },
  {
    "episode": 1709,
    "reward": 84.827296,
    "length": 74,
    "time": 31321.592723,
    "actor_loss": -41.93829345703125,
    "critic_loss": 42.315696716308594,
    "ent_coef": 0.13784869015216827,
    "learning_rate": 0.001
  },
  {
    "episode": 1710,
    "reward": 90.403099,
    "length": 64,
    "time": 31334.279021,
    "actor_loss": -42.395408630371094,
    "critic_loss": 48.78706359863281,
    "ent_coef": 0.13663306832313538,
    "learning_rate": 0.001
  },
  {
    "episode": 1711,
    "reward": 87.706571,
    "length": 68,
    "time": 31347.53473,
    "actor_loss": -39.923580169677734,
    "critic_loss": 153.062744140625,
    "ent_coef": 0.1392403095960617,
    "learning_rate": 0.001
  },
  {
    "episode": 1712,
    "reward": 85.409293,
    "length": 72,
    "time": 31361.214045,
    "actor_loss": -36.948265075683594,
    "critic_loss": 14.019468307495117,
    "ent_coef": 0.14338740706443787,
    "learning_rate": 0.001
  },
  {
    "episode": 1713,
    "reward": 87.992345,
    "length": 68,
    "time": 31375.632638,
    "actor_loss": -41.5460205078125,
    "critic_loss": 36.647056579589844,
    "ent_coef": 0.14322195947170258,
    "learning_rate": 0.001
  },
  {
    "episode": 1714,
    "reward": -166.738266,
    "length": 258,
    "time": 31413.844618,
    "actor_loss": -35.03034210205078,
    "critic_loss": 26.6459903717041,
    "ent_coef": 0.15721312165260315,
    "learning_rate": 0.001
  },
  {
    "episode": 1715,
    "reward": 80.725355,
    "length": 83,
    "time": 31429.769545,
    "actor_loss": -38.8492431640625,
    "critic_loss": 20.04499053955078,
    "ent_coef": 0.16034631431102753,
    "learning_rate": 0.001
  },
  {
    "episode": 1716,
    "reward": 82.674964,
    "length": 83,
    "time": 31444.890072,
    "actor_loss": -40.302642822265625,
    "critic_loss": 55.4725341796875,
    "ent_coef": 0.15961039066314697,
    "learning_rate": 0.001
  },
  {
    "episode": 1717,
    "reward": 79.73777,
    "length": 85,
    "time": 31460.962806,
    "actor_loss": -47.828025817871094,
    "critic_loss": 23.005760192871094,
    "ent_coef": 0.15255863964557648,
    "learning_rate": 0.001
  },
  {
    "episode": 1718,
    "reward": 87.140418,
    "length": 70,
    "time": 31473.532875,
    "actor_loss": -40.63863754272461,
    "critic_loss": 14.50761604309082,
    "ent_coef": 0.14879226684570312,
    "learning_rate": 0.001
  },
  {
    "episode": 1719,
    "reward": 82.828547,
    "length": 81,
    "time": 31487.626068,
    "actor_loss": -36.631351470947266,
    "critic_loss": 24.695789337158203,
    "ent_coef": 0.14599581062793732,
    "learning_rate": 0.001
  },
  {
    "episode": 1720,
    "reward": 88.366987,
    "length": 68,
    "time": 31500.571724,
    "actor_loss": -48.656410217285156,
    "critic_loss": 32.6757698059082,
    "ent_coef": 0.14623163640499115,
    "learning_rate": 0.001
  },
  {
    "episode": 1721,
    "reward": 89.18594,
    "length": 64,
    "time": 31514.476633,
    "actor_loss": -37.98857498168945,
    "critic_loss": 19.772672653198242,
    "ent_coef": 0.15464726090431213,
    "learning_rate": 0.001
  },
  {
    "episode": 1722,
    "reward": 89.904475,
    "length": 64,
    "time": 31527.950269,
    "actor_loss": -40.45380401611328,
    "critic_loss": 35.81829833984375,
    "ent_coef": 0.15473394095897675,
    "learning_rate": 0.001
  },
  {
    "episode": 1723,
    "reward": 86.328719,
    "length": 70,
    "time": 31541.95249,
    "actor_loss": -43.00995635986328,
    "critic_loss": 38.73017120361328,
    "ent_coef": 0.15594923496246338,
    "learning_rate": 0.001
  },
  {
    "episode": 1724,
    "reward": 88.037512,
    "length": 66,
    "time": 31553.978723,
    "actor_loss": -43.355926513671875,
    "critic_loss": 34.917930603027344,
    "ent_coef": 0.16048112511634827,
    "learning_rate": 0.001
  },
  {
    "episode": 1725,
    "reward": 86.0033,
    "length": 70,
    "time": 31567.457371,
    "actor_loss": -41.78724670410156,
    "critic_loss": 23.00133514404297,
    "ent_coef": 0.16246123611927032,
    "learning_rate": 0.001
  },
  {
    "episode": 1726,
    "reward": 88.012339,
    "length": 67,
    "time": 31582.582354,
    "actor_loss": -46.21653366088867,
    "critic_loss": 92.64894104003906,
    "ent_coef": 0.16276201605796814,
    "learning_rate": 0.001
  },
  {
    "episode": 1727,
    "reward": 91.418634,
    "length": 61,
    "time": 31594.872962,
    "actor_loss": -34.5430908203125,
    "critic_loss": 405.44854736328125,
    "ent_coef": 0.1592005491256714,
    "learning_rate": 0.001
  },
  {
    "episode": 1728,
    "reward": -152.033759,
    "length": 101,
    "time": 31613.789032,
    "actor_loss": -44.53520202636719,
    "critic_loss": 74.20657348632812,
    "ent_coef": 0.15750886499881744,
    "learning_rate": 0.001
  },
  {
    "episode": 1729,
    "reward": 88.163956,
    "length": 71,
    "time": 31628.134928,
    "actor_loss": -36.40643310546875,
    "critic_loss": 10.14085578918457,
    "ent_coef": 0.15664295852184296,
    "learning_rate": 0.001
  },
  {
    "episode": 1730,
    "reward": 85.821443,
    "length": 76,
    "time": 31641.90932,
    "actor_loss": -44.03681945800781,
    "critic_loss": 59.37132263183594,
    "ent_coef": 0.15364135801792145,
    "learning_rate": 0.001
  },
  {
    "episode": 1731,
    "reward": 87.916717,
    "length": 68,
    "time": 31657.629734,
    "actor_loss": -41.40700912475586,
    "critic_loss": 12.902544975280762,
    "ent_coef": 0.15416425466537476,
    "learning_rate": 0.001
  },
  {
    "episode": 1732,
    "reward": 85.82787,
    "length": 75,
    "time": 31670.43692,
    "actor_loss": -39.248661041259766,
    "critic_loss": 49.96582794189453,
    "ent_coef": 0.151010200381279,
    "learning_rate": 0.001
  },
  {
    "episode": 1733,
    "reward": 88.289048,
    "length": 65,
    "time": 31682.558061,
    "actor_loss": -44.81817626953125,
    "critic_loss": 53.40180206298828,
    "ent_coef": 0.151472806930542,
    "learning_rate": 0.001
  },
  {
    "episode": 1734,
    "reward": 88.513658,
    "length": 66,
    "time": 31694.867451,
    "actor_loss": -47.514644622802734,
    "critic_loss": 149.00265502929688,
    "ent_coef": 0.15158692002296448,
    "learning_rate": 0.001
  },
  {
    "episode": 1735,
    "reward": 83.475926,
    "length": 75,
    "time": 31709.74284,
    "actor_loss": -49.14027786254883,
    "critic_loss": 69.20565795898438,
    "ent_coef": 0.14750128984451294,
    "learning_rate": 0.001
  },
  {
    "episode": 1736,
    "reward": 87.245752,
    "length": 68,
    "time": 31722.063098,
    "actor_loss": -42.69386291503906,
    "critic_loss": 35.308929443359375,
    "ent_coef": 0.14950798451900482,
    "learning_rate": 0.001
  },
  {
    "episode": 1737,
    "reward": 86.096972,
    "length": 72,
    "time": 31739.437618,
    "actor_loss": -40.50054931640625,
    "critic_loss": 16.473018646240234,
    "ent_coef": 0.1486397683620453,
    "learning_rate": 0.001
  },
  {
    "episode": 1738,
    "reward": 86.039086,
    "length": 75,
    "time": 31752.818348,
    "actor_loss": -44.817657470703125,
    "critic_loss": 68.5328369140625,
    "ent_coef": 0.1480589658021927,
    "learning_rate": 0.001
  },
  {
    "episode": 1739,
    "reward": 89.881487,
    "length": 63,
    "time": 31767.255225,
    "actor_loss": -41.650062561035156,
    "critic_loss": 56.44053268432617,
    "ent_coef": 0.14431753754615784,
    "learning_rate": 0.001
  },
  {
    "episode": 1740,
    "reward": 91.38607,
    "length": 60,
    "time": 31779.164488,
    "actor_loss": -43.1660041809082,
    "critic_loss": 19.001577377319336,
    "ent_coef": 0.14774832129478455,
    "learning_rate": 0.001
  },
  {
    "episode": 1741,
    "reward": 83.88116,
    "length": 76,
    "time": 31796.72117,
    "actor_loss": -41.27894592285156,
    "critic_loss": 44.36969757080078,
    "ent_coef": 0.14815804362297058,
    "learning_rate": 0.001
  },
  {
    "episode": 1742,
    "reward": 88.950349,
    "length": 68,
    "time": 31809.301682,
    "actor_loss": -39.691375732421875,
    "critic_loss": 9.359766006469727,
    "ent_coef": 0.14169421792030334,
    "learning_rate": 0.001
  },
  {
    "episode": 1743,
    "reward": 88.846703,
    "length": 70,
    "time": 31821.41452,
    "actor_loss": -44.95549774169922,
    "critic_loss": 72.98587036132812,
    "ent_coef": 0.14372539520263672,
    "learning_rate": 0.001
  },
  {
    "episode": 1744,
    "reward": 80.164702,
    "length": 78,
    "time": 31834.637369,
    "actor_loss": -42.762672424316406,
    "critic_loss": 5.241052627563477,
    "ent_coef": 0.1434144526720047,
    "learning_rate": 0.001
  },
  {
    "episode": 1745,
    "reward": 86.724978,
    "length": 69,
    "time": 31847.979908,
    "actor_loss": -42.26946258544922,
    "critic_loss": 70.53184509277344,
    "ent_coef": 0.14170335233211517,
    "learning_rate": 0.001
  },
  {
    "episode": 1746,
    "reward": 89.438442,
    "length": 65,
    "time": 31860.328573,
    "actor_loss": -48.4867057800293,
    "critic_loss": 34.20103454589844,
    "ent_coef": 0.14003105461597443,
    "learning_rate": 0.001
  },
  {
    "episode": 1747,
    "reward": 81.924546,
    "length": 78,
    "time": 31876.433569,
    "actor_loss": -43.48722839355469,
    "critic_loss": 16.73954200744629,
    "ent_coef": 0.1393194943666458,
    "learning_rate": 0.001
  },
  {
    "episode": 1748,
    "reward": 80.398346,
    "length": 78,
    "time": 31889.775615,
    "actor_loss": -35.501014709472656,
    "critic_loss": 48.014583587646484,
    "ent_coef": 0.13719168305397034,
    "learning_rate": 0.001
  },
  {
    "episode": 1749,
    "reward": 80.604936,
    "length": 77,
    "time": 31904.798257,
    "actor_loss": -41.698936462402344,
    "critic_loss": 36.688507080078125,
    "ent_coef": 0.13400739431381226,
    "learning_rate": 0.001
  },
  {
    "episode": 1750,
    "reward": 88.435854,
    "length": 70,
    "time": 31917.096383,
    "actor_loss": -43.851600646972656,
    "critic_loss": 81.06005859375,
    "ent_coef": 0.13396769762039185,
    "learning_rate": 0.001
  },
  {
    "episode": 1751,
    "reward": 83.945263,
    "length": 72,
    "time": 31929.691997,
    "actor_loss": -44.640167236328125,
    "critic_loss": 58.96589279174805,
    "ent_coef": 0.13857948780059814,
    "learning_rate": 0.001
  },
  {
    "episode": 1752,
    "reward": 89.077855,
    "length": 66,
    "time": 31941.381925,
    "actor_loss": -38.225284576416016,
    "critic_loss": 136.4483642578125,
    "ent_coef": 0.14117906987667084,
    "learning_rate": 0.001
  },
  {
    "episode": 1753,
    "reward": 86.132553,
    "length": 71,
    "time": 31956.578847,
    "actor_loss": -37.58121871948242,
    "critic_loss": 52.23699188232422,
    "ent_coef": 0.13684312999248505,
    "learning_rate": 0.001
  },
  {
    "episode": 1754,
    "reward": 88.996635,
    "length": 64,
    "time": 31970.019106,
    "actor_loss": -38.42418670654297,
    "critic_loss": 9.735416412353516,
    "ent_coef": 0.13542543351650238,
    "learning_rate": 0.001
  },
  {
    "episode": 1755,
    "reward": 87.513056,
    "length": 72,
    "time": 31985.116912,
    "actor_loss": -43.96002197265625,
    "critic_loss": 8.469165802001953,
    "ent_coef": 0.1352795660495758,
    "learning_rate": 0.001
  },
  {
    "episode": 1756,
    "reward": 87.303558,
    "length": 72,
    "time": 31998.264682,
    "actor_loss": -46.321044921875,
    "critic_loss": 6.935566425323486,
    "ent_coef": 0.13517463207244873,
    "learning_rate": 0.001
  },
  {
    "episode": 1757,
    "reward": 88.334168,
    "length": 66,
    "time": 32013.371794,
    "actor_loss": -40.442848205566406,
    "critic_loss": 46.35437774658203,
    "ent_coef": 0.13582003116607666,
    "learning_rate": 0.001
  },
  {
    "episode": 1758,
    "reward": 83.670598,
    "length": 117,
    "time": 32032.493474,
    "actor_loss": -36.408260345458984,
    "critic_loss": 33.426612854003906,
    "ent_coef": 0.1308099627494812,
    "learning_rate": 0.001
  },
  {
    "episode": 1759,
    "reward": 87.164107,
    "length": 73,
    "time": 32046.514937,
    "actor_loss": -39.13081741333008,
    "critic_loss": 11.578624725341797,
    "ent_coef": 0.1351613849401474,
    "learning_rate": 0.001
  },
  {
    "episode": 1760,
    "reward": -150.879514,
    "length": 98,
    "time": 32063.560418,
    "actor_loss": -37.05101776123047,
    "critic_loss": 15.031033515930176,
    "ent_coef": 0.13970975577831268,
    "learning_rate": 0.001
  },
  {
    "episode": 1761,
    "reward": 88.687301,
    "length": 81,
    "time": 32077.920563,
    "actor_loss": -38.90259552001953,
    "critic_loss": 24.684831619262695,
    "ent_coef": 0.1375928521156311,
    "learning_rate": 0.001
  },
  {
    "episode": 1762,
    "reward": 87.032271,
    "length": 71,
    "time": 32090.448295,
    "actor_loss": -39.29145812988281,
    "critic_loss": 20.815101623535156,
    "ent_coef": 0.1377210021018982,
    "learning_rate": 0.001
  },
  {
    "episode": 1763,
    "reward": 87.833986,
    "length": 67,
    "time": 32104.442848,
    "actor_loss": -44.261802673339844,
    "critic_loss": 415.24163818359375,
    "ent_coef": 0.14362137019634247,
    "learning_rate": 0.001
  },
  {
    "episode": 1764,
    "reward": 86.239734,
    "length": 72,
    "time": 32118.658587,
    "actor_loss": -43.81563949584961,
    "critic_loss": 12.743234634399414,
    "ent_coef": 0.14380210638046265,
    "learning_rate": 0.001
  },
  {
    "episode": 1765,
    "reward": 82.131804,
    "length": 82,
    "time": 32132.858618,
    "actor_loss": -38.341270446777344,
    "critic_loss": 131.02462768554688,
    "ent_coef": 0.143497496843338,
    "learning_rate": 0.001
  },
  {
    "episode": 1766,
    "reward": 90.03789,
    "length": 63,
    "time": 32145.128166,
    "actor_loss": -40.44190216064453,
    "critic_loss": 61.01119613647461,
    "ent_coef": 0.14623798429965973,
    "learning_rate": 0.001
  },
  {
    "episode": 1767,
    "reward": 87.451995,
    "length": 67,
    "time": 32159.849985,
    "actor_loss": -40.659645080566406,
    "critic_loss": 57.255126953125,
    "ent_coef": 0.1479724645614624,
    "learning_rate": 0.001
  },
  {
    "episode": 1768,
    "reward": 86.580612,
    "length": 69,
    "time": 32171.937044,
    "actor_loss": -42.32852554321289,
    "critic_loss": 9.180999755859375,
    "ent_coef": 0.14585649967193604,
    "learning_rate": 0.001
  },
  {
    "episode": 1769,
    "reward": 87.761242,
    "length": 66,
    "time": 32184.685618,
    "actor_loss": -39.13208770751953,
    "critic_loss": 28.41482925415039,
    "ent_coef": 0.14906160533428192,
    "learning_rate": 0.001
  },
  {
    "episode": 1770,
    "reward": 87.125974,
    "length": 72,
    "time": 32198.023241,
    "actor_loss": -44.706398010253906,
    "critic_loss": 30.803119659423828,
    "ent_coef": 0.14686313271522522,
    "learning_rate": 0.001
  },
  {
    "episode": 1771,
    "reward": 88.141958,
    "length": 71,
    "time": 32211.621051,
    "actor_loss": -39.59226608276367,
    "critic_loss": 53.63861083984375,
    "ent_coef": 0.1487189680337906,
    "learning_rate": 0.001
  },
  {
    "episode": 1772,
    "reward": 87.309307,
    "length": 67,
    "time": 32226.864755,
    "actor_loss": -40.40601348876953,
    "critic_loss": 59.132293701171875,
    "ent_coef": 0.14932173490524292,
    "learning_rate": 0.001
  },
  {
    "episode": 1773,
    "reward": 86.21841,
    "length": 75,
    "time": 32243.703763,
    "actor_loss": -40.66872024536133,
    "critic_loss": 9.752443313598633,
    "ent_coef": 0.14679820835590363,
    "learning_rate": 0.001
  },
  {
    "episode": 1774,
    "reward": 85.583537,
    "length": 72,
    "time": 32257.128549,
    "actor_loss": -40.601558685302734,
    "critic_loss": 48.28422164916992,
    "ent_coef": 0.1461942493915558,
    "learning_rate": 0.001
  },
  {
    "episode": 1775,
    "reward": 88.129658,
    "length": 66,
    "time": 32270.151531,
    "actor_loss": -42.15898132324219,
    "critic_loss": 29.123722076416016,
    "ent_coef": 0.148720845580101,
    "learning_rate": 0.001
  },
  {
    "episode": 1776,
    "reward": 85.473566,
    "length": 72,
    "time": 32283.524251,
    "actor_loss": -37.85411834716797,
    "critic_loss": 82.21397399902344,
    "ent_coef": 0.15194424986839294,
    "learning_rate": 0.001
  },
  {
    "episode": 1777,
    "reward": 90.171426,
    "length": 62,
    "time": 32294.502062,
    "actor_loss": -44.37815856933594,
    "critic_loss": 65.04693603515625,
    "ent_coef": 0.15812505781650543,
    "learning_rate": 0.001
  },
  {
    "episode": 1778,
    "reward": 83.45823,
    "length": 75,
    "time": 32307.253561,
    "actor_loss": -41.66633987426758,
    "critic_loss": 25.500530242919922,
    "ent_coef": 0.15649999678134918,
    "learning_rate": 0.001
  },
  {
    "episode": 1779,
    "reward": 88.781561,
    "length": 65,
    "time": 32318.84987,
    "actor_loss": -37.60686492919922,
    "critic_loss": 19.364906311035156,
    "ent_coef": 0.1548270434141159,
    "learning_rate": 0.001
  },
  {
    "episode": 1780,
    "reward": 85.385091,
    "length": 72,
    "time": 32332.477696,
    "actor_loss": -41.68732452392578,
    "critic_loss": 86.48667907714844,
    "ent_coef": 0.16005313396453857,
    "learning_rate": 0.001
  },
  {
    "episode": 1781,
    "reward": 86.487767,
    "length": 69,
    "time": 32344.971841,
    "actor_loss": -37.163814544677734,
    "critic_loss": 21.58890151977539,
    "ent_coef": 0.1571275293827057,
    "learning_rate": 0.001
  },
  {
    "episode": 1782,
    "reward": 88.106535,
    "length": 68,
    "time": 32359.840609,
    "actor_loss": -45.73450469970703,
    "critic_loss": 165.17733764648438,
    "ent_coef": 0.15256652235984802,
    "learning_rate": 0.001
  },
  {
    "episode": 1783,
    "reward": 88.378998,
    "length": 66,
    "time": 32374.64173,
    "actor_loss": -45.999324798583984,
    "critic_loss": 143.07803344726562,
    "ent_coef": 0.14649386703968048,
    "learning_rate": 0.001
  },
  {
    "episode": 1784,
    "reward": 88.608353,
    "length": 67,
    "time": 32386.430584,
    "actor_loss": -51.16358947753906,
    "critic_loss": 45.084007263183594,
    "ent_coef": 0.1444394886493683,
    "learning_rate": 0.001
  },
  {
    "episode": 1785,
    "reward": 87.899582,
    "length": 68,
    "time": 32398.355631,
    "actor_loss": -41.24089050292969,
    "critic_loss": 20.46451187133789,
    "ent_coef": 0.14600855112075806,
    "learning_rate": 0.001
  },
  {
    "episode": 1786,
    "reward": 84.681055,
    "length": 73,
    "time": 32412.637088,
    "actor_loss": -42.70695114135742,
    "critic_loss": 52.127906799316406,
    "ent_coef": 0.14552688598632812,
    "learning_rate": 0.001
  },
  {
    "episode": 1787,
    "reward": 87.549795,
    "length": 68,
    "time": 32426.333965,
    "actor_loss": -43.374061584472656,
    "critic_loss": 39.1269645690918,
    "ent_coef": 0.14019595086574554,
    "learning_rate": 0.001
  },
  {
    "episode": 1788,
    "reward": 84.797445,
    "length": 83,
    "time": 32440.876233,
    "actor_loss": -43.59625244140625,
    "critic_loss": 89.92445373535156,
    "ent_coef": 0.1408902257680893,
    "learning_rate": 0.001
  },
  {
    "episode": 1789,
    "reward": -154.199365,
    "length": 119,
    "time": 32462.129279,
    "actor_loss": -37.91889572143555,
    "critic_loss": 91.20425415039062,
    "ent_coef": 0.1428101807832718,
    "learning_rate": 0.001
  },
  {
    "episode": 1790,
    "reward": 91.13046,
    "length": 70,
    "time": 32475.170979,
    "actor_loss": -37.636314392089844,
    "critic_loss": 87.01983642578125,
    "ent_coef": 0.14036154747009277,
    "learning_rate": 0.001
  },
  {
    "episode": 1791,
    "reward": 86.221188,
    "length": 74,
    "time": 32489.046039,
    "actor_loss": -45.44285202026367,
    "critic_loss": 28.431758880615234,
    "ent_coef": 0.13646964728832245,
    "learning_rate": 0.001
  },
  {
    "episode": 1792,
    "reward": 88.142015,
    "length": 66,
    "time": 32502.736681,
    "actor_loss": -36.64008712768555,
    "critic_loss": 12.480789184570312,
    "ent_coef": 0.13583271205425262,
    "learning_rate": 0.001
  },
  {
    "episode": 1793,
    "reward": 88.655609,
    "length": 65,
    "time": 32516.509003,
    "actor_loss": -47.068336486816406,
    "critic_loss": 31.458473205566406,
    "ent_coef": 0.13623782992362976,
    "learning_rate": 0.001
  },
  {
    "episode": 1794,
    "reward": 89.422938,
    "length": 64,
    "time": 32530.538243,
    "actor_loss": -38.51536178588867,
    "critic_loss": 30.221614837646484,
    "ent_coef": 0.13223183155059814,
    "learning_rate": 0.001
  },
  {
    "episode": 1795,
    "reward": 85.832935,
    "length": 74,
    "time": 32546.436296,
    "actor_loss": -46.55738067626953,
    "critic_loss": 121.2489242553711,
    "ent_coef": 0.12607432901859283,
    "learning_rate": 0.001
  },
  {
    "episode": 1796,
    "reward": -157.450531,
    "length": 135,
    "time": 32567.357883,
    "actor_loss": -43.791908264160156,
    "critic_loss": 38.2446403503418,
    "ent_coef": 0.1275506466627121,
    "learning_rate": 0.001
  },
  {
    "episode": 1797,
    "reward": 86.24706,
    "length": 73,
    "time": 32582.45694,
    "actor_loss": -44.83296203613281,
    "critic_loss": 91.92176818847656,
    "ent_coef": 0.1319173276424408,
    "learning_rate": 0.001
  },
  {
    "episode": 1798,
    "reward": 89.772841,
    "length": 64,
    "time": 32594.604764,
    "actor_loss": -43.954612731933594,
    "critic_loss": 31.163196563720703,
    "ent_coef": 0.13405482470989227,
    "learning_rate": 0.001
  },
  {
    "episode": 1799,
    "reward": 86.315319,
    "length": 69,
    "time": 32606.874854,
    "actor_loss": -40.584800720214844,
    "critic_loss": 22.650753021240234,
    "ent_coef": 0.13684362173080444,
    "learning_rate": 0.001
  },
  {
    "episode": 1800,
    "reward": 87.707784,
    "length": 66,
    "time": 32620.534947,
    "actor_loss": -38.53016662597656,
    "critic_loss": 21.238182067871094,
    "ent_coef": 0.13874001801013947,
    "learning_rate": 0.001
  },
  {
    "episode": 1801,
    "reward": 88.602006,
    "length": 66,
    "time": 32632.335367,
    "actor_loss": -39.63783264160156,
    "critic_loss": 44.5008544921875,
    "ent_coef": 0.1398565024137497,
    "learning_rate": 0.001
  },
  {
    "episode": 1802,
    "reward": 87.529725,
    "length": 74,
    "time": 32645.128011,
    "actor_loss": -35.17816162109375,
    "critic_loss": 12.63673210144043,
    "ent_coef": 0.13726279139518738,
    "learning_rate": 0.001
  },
  {
    "episode": 1803,
    "reward": 87.551585,
    "length": 67,
    "time": 32656.92998,
    "actor_loss": -37.607215881347656,
    "critic_loss": 131.87042236328125,
    "ent_coef": 0.14045147597789764,
    "learning_rate": 0.001
  },
  {
    "episode": 1804,
    "reward": 89.423565,
    "length": 64,
    "time": 32670.336562,
    "actor_loss": -41.66615676879883,
    "critic_loss": 24.359134674072266,
    "ent_coef": 0.1442781686782837,
    "learning_rate": 0.001
  },
  {
    "episode": 1805,
    "reward": 83.488712,
    "length": 75,
    "time": 32684.487508,
    "actor_loss": -45.83264923095703,
    "critic_loss": 85.52151489257812,
    "ent_coef": 0.14895784854888916,
    "learning_rate": 0.001
  },
  {
    "episode": 1806,
    "reward": 85.00356,
    "length": 72,
    "time": 32699.200435,
    "actor_loss": -34.10317611694336,
    "critic_loss": 6.843507766723633,
    "ent_coef": 0.15366682410240173,
    "learning_rate": 0.001
  },
  {
    "episode": 1807,
    "reward": 87.989632,
    "length": 67,
    "time": 32713.444434,
    "actor_loss": -39.5525016784668,
    "critic_loss": 13.874283790588379,
    "ent_coef": 0.15255020558834076,
    "learning_rate": 0.001
  },
  {
    "episode": 1808,
    "reward": 87.493314,
    "length": 67,
    "time": 32728.845135,
    "actor_loss": -45.71299743652344,
    "critic_loss": 35.084999084472656,
    "ent_coef": 0.15604522824287415,
    "learning_rate": 0.001
  },
  {
    "episode": 1809,
    "reward": 88.532636,
    "length": 66,
    "time": 32743.492733,
    "actor_loss": -41.8656005859375,
    "critic_loss": 14.21230697631836,
    "ent_coef": 0.16172662377357483,
    "learning_rate": 0.001
  },
  {
    "episode": 1810,
    "reward": 89.103926,
    "length": 64,
    "time": 32754.84626,
    "actor_loss": -36.90156173706055,
    "critic_loss": 35.2282600402832,
    "ent_coef": 0.16646045446395874,
    "learning_rate": 0.001
  },
  {
    "episode": 1811,
    "reward": 88.858163,
    "length": 66,
    "time": 32767.625981,
    "actor_loss": -39.8585205078125,
    "critic_loss": 344.586669921875,
    "ent_coef": 0.15901824831962585,
    "learning_rate": 0.001
  },
  {
    "episode": 1812,
    "reward": 86.57103,
    "length": 70,
    "time": 32781.433884,
    "actor_loss": -44.655128479003906,
    "critic_loss": 93.63636016845703,
    "ent_coef": 0.15553788840770721,
    "learning_rate": 0.001
  },
  {
    "episode": 1813,
    "reward": 83.527657,
    "length": 75,
    "time": 32795.903904,
    "actor_loss": -39.66227722167969,
    "critic_loss": 30.47988510131836,
    "ent_coef": 0.15229400992393494,
    "learning_rate": 0.001
  },
  {
    "episode": 1814,
    "reward": 88.781683,
    "length": 66,
    "time": 32807.723936,
    "actor_loss": -40.46240997314453,
    "critic_loss": 19.60477066040039,
    "ent_coef": 0.156128391623497,
    "learning_rate": 0.001
  },
  {
    "episode": 1815,
    "reward": 88.876958,
    "length": 64,
    "time": 32821.130193,
    "actor_loss": -42.09809875488281,
    "critic_loss": 87.23255920410156,
    "ent_coef": 0.15977120399475098,
    "learning_rate": 0.001
  },
  {
    "episode": 1816,
    "reward": 86.856213,
    "length": 70,
    "time": 32834.249878,
    "actor_loss": -38.047569274902344,
    "critic_loss": 8.982763290405273,
    "ent_coef": 0.15801472961902618,
    "learning_rate": 0.001
  },
  {
    "episode": 1817,
    "reward": 85.687583,
    "length": 71,
    "time": 32846.788224,
    "actor_loss": -52.84943771362305,
    "critic_loss": 52.79142379760742,
    "ent_coef": 0.1569020301103592,
    "learning_rate": 0.001
  },
  {
    "episode": 1818,
    "reward": 87.967522,
    "length": 69,
    "time": 32860.234618,
    "actor_loss": -47.39588165283203,
    "critic_loss": 179.5926513671875,
    "ent_coef": 0.1509084403514862,
    "learning_rate": 0.001
  },
  {
    "episode": 1819,
    "reward": 80.576647,
    "length": 79,
    "time": 32874.550524,
    "actor_loss": -43.396728515625,
    "critic_loss": 57.95970153808594,
    "ent_coef": 0.14502814412117004,
    "learning_rate": 0.001
  },
  {
    "episode": 1820,
    "reward": 88.809066,
    "length": 67,
    "time": 32887.359394,
    "actor_loss": -38.85252380371094,
    "critic_loss": 9.371766090393066,
    "ent_coef": 0.1453264206647873,
    "learning_rate": 0.001
  },
  {
    "episode": 1821,
    "reward": 85.930782,
    "length": 71,
    "time": 32901.429916,
    "actor_loss": -43.487159729003906,
    "critic_loss": 10.955284118652344,
    "ent_coef": 0.14255186915397644,
    "learning_rate": 0.001
  },
  {
    "episode": 1822,
    "reward": 86.790245,
    "length": 74,
    "time": 32915.45744,
    "actor_loss": -34.0038948059082,
    "critic_loss": 105.74225616455078,
    "ent_coef": 0.13993658125400543,
    "learning_rate": 0.001
  },
  {
    "episode": 1823,
    "reward": 88.261033,
    "length": 71,
    "time": 32927.842477,
    "actor_loss": -45.021080017089844,
    "critic_loss": 273.17706298828125,
    "ent_coef": 0.13790027797222137,
    "learning_rate": 0.001
  },
  {
    "episode": 1824,
    "reward": 89.294475,
    "length": 64,
    "time": 32939.117552,
    "actor_loss": -44.52165985107422,
    "critic_loss": 57.71463394165039,
    "ent_coef": 0.1398334503173828,
    "learning_rate": 0.001
  },
  {
    "episode": 1825,
    "reward": 87.601934,
    "length": 68,
    "time": 32951.775754,
    "actor_loss": -45.73468780517578,
    "critic_loss": 27.549781799316406,
    "ent_coef": 0.139896422624588,
    "learning_rate": 0.001
  },
  {
    "episode": 1826,
    "reward": 87.734806,
    "length": 69,
    "time": 32966.030688,
    "actor_loss": -44.603904724121094,
    "critic_loss": 104.19700622558594,
    "ent_coef": 0.134073868393898,
    "learning_rate": 0.001
  },
  {
    "episode": 1827,
    "reward": 87.652826,
    "length": 68,
    "time": 32979.07033,
    "actor_loss": -45.31153869628906,
    "critic_loss": 16.39485740661621,
    "ent_coef": 0.13246874511241913,
    "learning_rate": 0.001
  },
  {
    "episode": 1828,
    "reward": 88.051506,
    "length": 69,
    "time": 32992.752239,
    "actor_loss": -43.72337341308594,
    "critic_loss": 93.50735473632812,
    "ent_coef": 0.13108175992965698,
    "learning_rate": 0.001
  },
  {
    "episode": 1829,
    "reward": 87.612607,
    "length": 68,
    "time": 33007.950206,
    "actor_loss": -47.65422058105469,
    "critic_loss": 87.64665222167969,
    "ent_coef": 0.1331409215927124,
    "learning_rate": 0.001
  },
  {
    "episode": 1830,
    "reward": 90.309295,
    "length": 63,
    "time": 33019.580064,
    "actor_loss": -41.85963439941406,
    "critic_loss": 12.319475173950195,
    "ent_coef": 0.1353497952222824,
    "learning_rate": 0.001
  },
  {
    "episode": 1831,
    "reward": 82.716332,
    "length": 94,
    "time": 33036.011838,
    "actor_loss": -45.47290802001953,
    "critic_loss": 17.91195297241211,
    "ent_coef": 0.12750236690044403,
    "learning_rate": 0.001
  },
  {
    "episode": 1832,
    "reward": 88.961482,
    "length": 64,
    "time": 33047.326516,
    "actor_loss": -38.61267852783203,
    "critic_loss": 14.83458137512207,
    "ent_coef": 0.12580929696559906,
    "learning_rate": 0.001
  },
  {
    "episode": 1833,
    "reward": 87.307031,
    "length": 69,
    "time": 33060.926908,
    "actor_loss": -44.51707458496094,
    "critic_loss": 22.94927978515625,
    "ent_coef": 0.12231456488370895,
    "learning_rate": 0.001
  },
  {
    "episode": 1834,
    "reward": 85.431003,
    "length": 71,
    "time": 33073.50937,
    "actor_loss": -45.18901824951172,
    "critic_loss": 23.083980560302734,
    "ent_coef": 0.12306360900402069,
    "learning_rate": 0.001
  },
  {
    "episode": 1835,
    "reward": 90.261299,
    "length": 63,
    "time": 33087.847092,
    "actor_loss": -44.825965881347656,
    "critic_loss": 72.97232818603516,
    "ent_coef": 0.12908051908016205,
    "learning_rate": 0.001
  },
  {
    "episode": 1836,
    "reward": 89.098779,
    "length": 65,
    "time": 33099.335718,
    "actor_loss": -39.466697692871094,
    "critic_loss": 30.947765350341797,
    "ent_coef": 0.13661211729049683,
    "learning_rate": 0.001
  },
  {
    "episode": 1837,
    "reward": 81.213642,
    "length": 77,
    "time": 33115.354588,
    "actor_loss": -35.6000862121582,
    "critic_loss": 33.29938888549805,
    "ent_coef": 0.139428049325943,
    "learning_rate": 0.001
  },
  {
    "episode": 1838,
    "reward": 86.654573,
    "length": 69,
    "time": 33127.177383,
    "actor_loss": -46.46194076538086,
    "critic_loss": 117.33106994628906,
    "ent_coef": 0.13943436741828918,
    "learning_rate": 0.001
  },
  {
    "episode": 1839,
    "reward": 87.662986,
    "length": 69,
    "time": 33140.097544,
    "actor_loss": -50.50733184814453,
    "critic_loss": 40.73651123046875,
    "ent_coef": 0.1431024819612503,
    "learning_rate": 0.001
  },
  {
    "episode": 1840,
    "reward": 86.965438,
    "length": 72,
    "time": 33152.590168,
    "actor_loss": -50.26786804199219,
    "critic_loss": 34.35765838623047,
    "ent_coef": 0.14143699407577515,
    "learning_rate": 0.001
  },
  {
    "episode": 1841,
    "reward": 85.968142,
    "length": 72,
    "time": 33165.03847,
    "actor_loss": -39.93496322631836,
    "critic_loss": 127.64208984375,
    "ent_coef": 0.1397111862897873,
    "learning_rate": 0.001
  },
  {
    "episode": 1842,
    "reward": 85.639608,
    "length": 71,
    "time": 33178.421381,
    "actor_loss": -39.44496154785156,
    "critic_loss": 29.08746337890625,
    "ent_coef": 0.14387568831443787,
    "learning_rate": 0.001
  },
  {
    "episode": 1843,
    "reward": -160.349774,
    "length": 108,
    "time": 33198.800321,
    "actor_loss": -46.154701232910156,
    "critic_loss": 8.507807731628418,
    "ent_coef": 0.14578865468502045,
    "learning_rate": 0.001
  },
  {
    "episode": 1844,
    "reward": 93.94783,
    "length": 68,
    "time": 33210.602461,
    "actor_loss": -52.058868408203125,
    "critic_loss": 11.087729454040527,
    "ent_coef": 0.1453586220741272,
    "learning_rate": 0.001
  },
  {
    "episode": 1845,
    "reward": 88.708044,
    "length": 66,
    "time": 33222.2844,
    "actor_loss": -37.958736419677734,
    "critic_loss": 57.74329376220703,
    "ent_coef": 0.14582520723342896,
    "learning_rate": 0.001
  },
  {
    "episode": 1846,
    "reward": 90.88237,
    "length": 63,
    "time": 33235.227339,
    "actor_loss": -45.67424011230469,
    "critic_loss": 36.86893844604492,
    "ent_coef": 0.1478201448917389,
    "learning_rate": 0.001
  },
  {
    "episode": 1847,
    "reward": 81.150023,
    "length": 80,
    "time": 33249.74499,
    "actor_loss": -40.63503646850586,
    "critic_loss": 168.0480499267578,
    "ent_coef": 0.1462554633617401,
    "learning_rate": 0.001
  },
  {
    "episode": 1848,
    "reward": -162.08806,
    "length": 138,
    "time": 33270.753798,
    "actor_loss": -41.1512336730957,
    "critic_loss": 6.969430923461914,
    "ent_coef": 0.1491183638572693,
    "learning_rate": 0.001
  },
  {
    "episode": 1849,
    "reward": 88.632416,
    "length": 66,
    "time": 33285.679974,
    "actor_loss": -47.659637451171875,
    "critic_loss": 30.865249633789062,
    "ent_coef": 0.15447048842906952,
    "learning_rate": 0.001
  },
  {
    "episode": 1850,
    "reward": 85.38086,
    "length": 72,
    "time": 33298.083145,
    "actor_loss": -46.968631744384766,
    "critic_loss": 51.67411804199219,
    "ent_coef": 0.15702757239341736,
    "learning_rate": 0.001
  },
  {
    "episode": 1851,
    "reward": 88.30768,
    "length": 66,
    "time": 33312.438666,
    "actor_loss": -41.15561294555664,
    "critic_loss": 120.62338256835938,
    "ent_coef": 0.15459933876991272,
    "learning_rate": 0.001
  },
  {
    "episode": 1852,
    "reward": 89.494393,
    "length": 64,
    "time": 33327.956268,
    "actor_loss": -46.229454040527344,
    "critic_loss": 23.89874839782715,
    "ent_coef": 0.15607476234436035,
    "learning_rate": 0.001
  },
  {
    "episode": 1853,
    "reward": 86.576683,
    "length": 70,
    "time": 33343.960431,
    "actor_loss": -41.37691116333008,
    "critic_loss": 58.016021728515625,
    "ent_coef": 0.15011046826839447,
    "learning_rate": 0.001
  },
  {
    "episode": 1854,
    "reward": 88.971736,
    "length": 65,
    "time": 33356.701093,
    "actor_loss": -45.91632080078125,
    "critic_loss": 32.865875244140625,
    "ent_coef": 0.15538246929645538,
    "learning_rate": 0.001
  },
  {
    "episode": 1855,
    "reward": 86.663639,
    "length": 69,
    "time": 33368.595849,
    "actor_loss": -42.36894226074219,
    "critic_loss": 32.98467254638672,
    "ent_coef": 0.15752781927585602,
    "learning_rate": 0.001
  },
  {
    "episode": 1856,
    "reward": 84.57548,
    "length": 74,
    "time": 33381.38279,
    "actor_loss": -48.25459289550781,
    "critic_loss": 6.4301252365112305,
    "ent_coef": 0.15600471198558807,
    "learning_rate": 0.001
  },
  {
    "episode": 1857,
    "reward": 86.090551,
    "length": 70,
    "time": 33393.65662,
    "actor_loss": -53.91348648071289,
    "critic_loss": 29.103084564208984,
    "ent_coef": 0.1531912386417389,
    "learning_rate": 0.001
  },
  {
    "episode": 1858,
    "reward": 84.473743,
    "length": 73,
    "time": 33410.283219,
    "actor_loss": -42.221466064453125,
    "critic_loss": 10.639450073242188,
    "ent_coef": 0.15491950511932373,
    "learning_rate": 0.001
  },
  {
    "episode": 1859,
    "reward": 82.296579,
    "length": 77,
    "time": 33425.127444,
    "actor_loss": -47.69453430175781,
    "critic_loss": 17.05002784729004,
    "ent_coef": 0.15160870552062988,
    "learning_rate": 0.001
  },
  {
    "episode": 1860,
    "reward": 87.681885,
    "length": 68,
    "time": 33439.705508,
    "actor_loss": -48.837928771972656,
    "critic_loss": 42.205421447753906,
    "ent_coef": 0.1527780443429947,
    "learning_rate": 0.001
  },
  {
    "episode": 1861,
    "reward": 87.790231,
    "length": 68,
    "time": 33454.727339,
    "actor_loss": -41.28236770629883,
    "critic_loss": 51.76299285888672,
    "ent_coef": 0.16193348169326782,
    "learning_rate": 0.001
  },
  {
    "episode": 1862,
    "reward": 87.916425,
    "length": 68,
    "time": 33473.007203,
    "actor_loss": -41.44449996948242,
    "critic_loss": 4.051533222198486,
    "ent_coef": 0.17061740159988403,
    "learning_rate": 0.001
  },
  {
    "episode": 1863,
    "reward": 87.246307,
    "length": 68,
    "time": 33485.93419,
    "actor_loss": -50.20623779296875,
    "critic_loss": 25.05978775024414,
    "ent_coef": 0.16955310106277466,
    "learning_rate": 0.001
  },
  {
    "episode": 1864,
    "reward": 83.250825,
    "length": 74,
    "time": 33498.514855,
    "actor_loss": -50.290733337402344,
    "critic_loss": 52.26579284667969,
    "ent_coef": 0.1671629101037979,
    "learning_rate": 0.001
  },
  {
    "episode": 1865,
    "reward": 87.290862,
    "length": 69,
    "time": 33511.762545,
    "actor_loss": -51.96467971801758,
    "critic_loss": 25.51181411743164,
    "ent_coef": 0.1676698625087738,
    "learning_rate": 0.001
  },
  {
    "episode": 1866,
    "reward": 85.991172,
    "length": 71,
    "time": 33525.275705,
    "actor_loss": -42.72130584716797,
    "critic_loss": 42.69567108154297,
    "ent_coef": 0.16870613396167755,
    "learning_rate": 0.001
  },
  {
    "episode": 1867,
    "reward": 87.82813,
    "length": 68,
    "time": 33538.017124,
    "actor_loss": -46.09999084472656,
    "critic_loss": 95.96578216552734,
    "ent_coef": 0.173760324716568,
    "learning_rate": 0.001
  },
  {
    "episode": 1868,
    "reward": 86.809,
    "length": 69,
    "time": 33553.875815,
    "actor_loss": -48.77592086791992,
    "critic_loss": 121.6955795288086,
    "ent_coef": 0.18170510232448578,
    "learning_rate": 0.001
  },
  {
    "episode": 1869,
    "reward": 88.702255,
    "length": 66,
    "time": 33567.833066,
    "actor_loss": -44.818199157714844,
    "critic_loss": 119.38333129882812,
    "ent_coef": 0.17695550620555878,
    "learning_rate": 0.001
  },
  {
    "episode": 1870,
    "reward": 86.277168,
    "length": 69,
    "time": 33582.25426,
    "actor_loss": -48.3994026184082,
    "critic_loss": 39.456600189208984,
    "ent_coef": 0.17393812537193298,
    "learning_rate": 0.001
  },
  {
    "episode": 1871,
    "reward": 85.825726,
    "length": 72,
    "time": 33596.435997,
    "actor_loss": -44.35260009765625,
    "critic_loss": 24.69116973876953,
    "ent_coef": 0.16958025097846985,
    "learning_rate": 0.001
  },
  {
    "episode": 1872,
    "reward": 83.169889,
    "length": 75,
    "time": 33614.570922,
    "actor_loss": -45.48486328125,
    "critic_loss": 141.5322723388672,
    "ent_coef": 0.16368603706359863,
    "learning_rate": 0.001
  },
  {
    "episode": 1873,
    "reward": 82.188403,
    "length": 78,
    "time": 33627.970921,
    "actor_loss": -46.767372131347656,
    "critic_loss": 43.51465606689453,
    "ent_coef": 0.15824931859970093,
    "learning_rate": 0.001
  },
  {
    "episode": 1874,
    "reward": 85.633798,
    "length": 72,
    "time": 33643.706596,
    "actor_loss": -50.12530517578125,
    "critic_loss": 79.4281005859375,
    "ent_coef": 0.15851350128650665,
    "learning_rate": 0.001
  },
  {
    "episode": 1875,
    "reward": 85.454078,
    "length": 71,
    "time": 33656.759467,
    "actor_loss": -43.2144775390625,
    "critic_loss": 45.33012771606445,
    "ent_coef": 0.1557270586490631,
    "learning_rate": 0.001
  },
  {
    "episode": 1876,
    "reward": 84.210255,
    "length": 74,
    "time": 33669.677074,
    "actor_loss": -46.05094528198242,
    "critic_loss": 23.572376251220703,
    "ent_coef": 0.1529679149389267,
    "learning_rate": 0.001
  },
  {
    "episode": 1877,
    "reward": 84.659476,
    "length": 72,
    "time": 33682.954281,
    "actor_loss": -49.53779220581055,
    "critic_loss": 26.37261199951172,
    "ent_coef": 0.15380629897117615,
    "learning_rate": 0.001
  },
  {
    "episode": 1878,
    "reward": 84.739266,
    "length": 77,
    "time": 33696.904651,
    "actor_loss": -48.51313781738281,
    "critic_loss": 121.21222686767578,
    "ent_coef": 0.1466083526611328,
    "learning_rate": 0.001
  },
  {
    "episode": 1879,
    "reward": 87.62587,
    "length": 68,
    "time": 33709.180443,
    "actor_loss": -43.12319564819336,
    "critic_loss": 394.5852355957031,
    "ent_coef": 0.1472586691379547,
    "learning_rate": 0.001
  },
  {
    "episode": 1880,
    "reward": 84.702706,
    "length": 72,
    "time": 33723.440907,
    "actor_loss": -46.050514221191406,
    "critic_loss": 50.704490661621094,
    "ent_coef": 0.14035950601100922,
    "learning_rate": 0.001
  },
  {
    "episode": 1881,
    "reward": 68.858302,
    "length": 101,
    "time": 33741.477489,
    "actor_loss": -45.88787841796875,
    "critic_loss": 58.865028381347656,
    "ent_coef": 0.1274976283311844,
    "learning_rate": 0.001
  },
  {
    "episode": 1882,
    "reward": 80.394535,
    "length": 81,
    "time": 33754.661341,
    "actor_loss": -46.18354034423828,
    "critic_loss": 68.44804382324219,
    "ent_coef": 0.12771469354629517,
    "learning_rate": 0.001
  },
  {
    "episode": 1883,
    "reward": 81.610906,
    "length": 78,
    "time": 33767.988703,
    "actor_loss": -50.066078186035156,
    "critic_loss": 302.6865234375,
    "ent_coef": 0.1279190480709076,
    "learning_rate": 0.001
  },
  {
    "episode": 1884,
    "reward": 83.337604,
    "length": 75,
    "time": 33780.495369,
    "actor_loss": -42.77847671508789,
    "critic_loss": 20.95934295654297,
    "ent_coef": 0.1291808784008026,
    "learning_rate": 0.001
  },
  {
    "episode": 1885,
    "reward": 86.068251,
    "length": 75,
    "time": 33795.953368,
    "actor_loss": -48.04865646362305,
    "critic_loss": 30.32295799255371,
    "ent_coef": 0.12604528665542603,
    "learning_rate": 0.001
  },
  {
    "episode": 1886,
    "reward": 85.047899,
    "length": 72,
    "time": 33812.264938,
    "actor_loss": -45.07732009887695,
    "critic_loss": 65.557373046875,
    "ent_coef": 0.12170529365539551,
    "learning_rate": 0.001
  },
  {
    "episode": 1887,
    "reward": 75.376489,
    "length": 86,
    "time": 33827.340914,
    "actor_loss": -42.624656677246094,
    "critic_loss": 41.17975997924805,
    "ent_coef": 0.11710797995328903,
    "learning_rate": 0.001
  },
  {
    "episode": 1888,
    "reward": 88.321767,
    "length": 67,
    "time": 33841.762747,
    "actor_loss": -45.428768157958984,
    "critic_loss": 25.039382934570312,
    "ent_coef": 0.11793598532676697,
    "learning_rate": 0.001
  },
  {
    "episode": 1889,
    "reward": 87.054903,
    "length": 69,
    "time": 33853.91901,
    "actor_loss": -44.244361877441406,
    "critic_loss": 78.46342468261719,
    "ent_coef": 0.11987560987472534,
    "learning_rate": 0.001
  },
  {
    "episode": 1890,
    "reward": 88.05927,
    "length": 68,
    "time": 33866.012525,
    "actor_loss": -43.75398254394531,
    "critic_loss": 116.65744018554688,
    "ent_coef": 0.12358742207288742,
    "learning_rate": 0.001
  },
  {
    "episode": 1891,
    "reward": 82.293332,
    "length": 75,
    "time": 33881.035896,
    "actor_loss": -45.43696212768555,
    "critic_loss": 14.151588439941406,
    "ent_coef": 0.12220779806375504,
    "learning_rate": 0.001
  },
  {
    "episode": 1892,
    "reward": 88.932726,
    "length": 66,
    "time": 33895.361708,
    "actor_loss": -42.19489288330078,
    "critic_loss": 13.263867378234863,
    "ent_coef": 0.12318772077560425,
    "learning_rate": 0.001
  },
  {
    "episode": 1893,
    "reward": 83.499366,
    "length": 75,
    "time": 33908.588203,
    "actor_loss": -48.93443298339844,
    "critic_loss": 69.76782989501953,
    "ent_coef": 0.12192931026220322,
    "learning_rate": 0.001
  },
  {
    "episode": 1894,
    "reward": 88.369873,
    "length": 71,
    "time": 33922.116578,
    "actor_loss": -51.64576721191406,
    "critic_loss": 74.81880187988281,
    "ent_coef": 0.12334942072629929,
    "learning_rate": 0.001
  },
  {
    "episode": 1895,
    "reward": 89.028361,
    "length": 64,
    "time": 33933.517817,
    "actor_loss": -49.23326873779297,
    "critic_loss": 20.820587158203125,
    "ent_coef": 0.13054196536540985,
    "learning_rate": 0.001
  },
  {
    "episode": 1896,
    "reward": 87.865586,
    "length": 68,
    "time": 33948.062913,
    "actor_loss": -50.796634674072266,
    "critic_loss": 13.074899673461914,
    "ent_coef": 0.13428398966789246,
    "learning_rate": 0.001
  },
  {
    "episode": 1897,
    "reward": 81.647277,
    "length": 76,
    "time": 33961.166119,
    "actor_loss": -46.86891555786133,
    "critic_loss": 12.836100578308105,
    "ent_coef": 0.13563521206378937,
    "learning_rate": 0.001
  },
  {
    "episode": 1898,
    "reward": 82.251101,
    "length": 75,
    "time": 33974.284811,
    "actor_loss": -50.9423828125,
    "critic_loss": 10.29606819152832,
    "ent_coef": 0.13751845061779022,
    "learning_rate": 0.001
  },
  {
    "episode": 1899,
    "reward": 85.56191,
    "length": 73,
    "time": 33988.813912,
    "actor_loss": -48.50323486328125,
    "critic_loss": 9.097148895263672,
    "ent_coef": 0.13982602953910828,
    "learning_rate": 0.001
  },
  {
    "episode": 1900,
    "reward": 86.741924,
    "length": 69,
    "time": 34000.915049,
    "actor_loss": -41.092350006103516,
    "critic_loss": 5.180983543395996,
    "ent_coef": 0.13344036042690277,
    "learning_rate": 0.001
  },
  {
    "episode": 1901,
    "reward": 87.000679,
    "length": 70,
    "time": 34015.143114,
    "actor_loss": -46.418426513671875,
    "critic_loss": 68.66011810302734,
    "ent_coef": 0.12977327406406403,
    "learning_rate": 0.001
  },
  {
    "episode": 1902,
    "reward": 88.019526,
    "length": 69,
    "time": 34027.313025,
    "actor_loss": -45.50386428833008,
    "critic_loss": 19.761882781982422,
    "ent_coef": 0.12908153235912323,
    "learning_rate": 0.001
  },
  {
    "episode": 1903,
    "reward": 84.828954,
    "length": 73,
    "time": 34040.578917,
    "actor_loss": -45.53370666503906,
    "critic_loss": 6.090298652648926,
    "ent_coef": 0.1261950582265854,
    "learning_rate": 0.001
  },
  {
    "episode": 1904,
    "reward": 84.830426,
    "length": 73,
    "time": 34055.367926,
    "actor_loss": -42.461952209472656,
    "critic_loss": 55.40242004394531,
    "ent_coef": 0.12623056769371033,
    "learning_rate": 0.001
  },
  {
    "episode": 1905,
    "reward": 82.523531,
    "length": 77,
    "time": 34069.481405,
    "actor_loss": -49.50330352783203,
    "critic_loss": 16.63318634033203,
    "ent_coef": 0.12199266254901886,
    "learning_rate": 0.001
  },
  {
    "episode": 1906,
    "reward": 85.386267,
    "length": 71,
    "time": 34083.172003,
    "actor_loss": -47.87928771972656,
    "critic_loss": 35.4306755065918,
    "ent_coef": 0.12623314559459686,
    "learning_rate": 0.001
  },
  {
    "episode": 1907,
    "reward": 87.472388,
    "length": 69,
    "time": 34098.422596,
    "actor_loss": -50.38843536376953,
    "critic_loss": 54.96377944946289,
    "ent_coef": 0.12834548950195312,
    "learning_rate": 0.001
  },
  {
    "episode": 1908,
    "reward": 86.436607,
    "length": 69,
    "time": 34111.329237,
    "actor_loss": -42.663997650146484,
    "critic_loss": 156.60711669921875,
    "ent_coef": 0.12738440930843353,
    "learning_rate": 0.001
  },
  {
    "episode": 1909,
    "reward": 87.227736,
    "length": 70,
    "time": 34124.441616,
    "actor_loss": -38.183013916015625,
    "critic_loss": 4.597784519195557,
    "ent_coef": 0.12111403793096542,
    "learning_rate": 0.001
  },
  {
    "episode": 1910,
    "reward": 83.715662,
    "length": 76,
    "time": 34138.856065,
    "actor_loss": -45.44334411621094,
    "critic_loss": 28.27288818359375,
    "ent_coef": 0.11834976822137833,
    "learning_rate": 0.001
  },
  {
    "episode": 1911,
    "reward": 86.155038,
    "length": 71,
    "time": 34151.1434,
    "actor_loss": -51.7623176574707,
    "critic_loss": 129.6184539794922,
    "ent_coef": 0.12218303978443146,
    "learning_rate": 0.001
  },
  {
    "episode": 1912,
    "reward": 86.340258,
    "length": 70,
    "time": 34164.325706,
    "actor_loss": -46.40876007080078,
    "critic_loss": 29.337142944335938,
    "ent_coef": 0.12826792895793915,
    "learning_rate": 0.001
  },
  {
    "episode": 1913,
    "reward": 84.049324,
    "length": 74,
    "time": 34177.971407,
    "actor_loss": -43.61123275756836,
    "critic_loss": 23.3006649017334,
    "ent_coef": 0.13274332880973816,
    "learning_rate": 0.001
  },
  {
    "episode": 1914,
    "reward": 86.707954,
    "length": 70,
    "time": 34191.396696,
    "actor_loss": -44.25559997558594,
    "critic_loss": 46.62073516845703,
    "ent_coef": 0.13730113208293915,
    "learning_rate": 0.001
  },
  {
    "episode": 1915,
    "reward": 68.256556,
    "length": 97,
    "time": 34209.900579,
    "actor_loss": -51.09381103515625,
    "critic_loss": 16.171649932861328,
    "ent_coef": 0.1365976482629776,
    "learning_rate": 0.001
  },
  {
    "episode": 1916,
    "reward": 82.827929,
    "length": 75,
    "time": 34227.989854,
    "actor_loss": -41.408775329589844,
    "critic_loss": 19.61244010925293,
    "ent_coef": 0.13725000619888306,
    "learning_rate": 0.001
  },
  {
    "episode": 1917,
    "reward": 86.65779,
    "length": 69,
    "time": 34240.104315,
    "actor_loss": -45.753517150878906,
    "critic_loss": 18.377796173095703,
    "ent_coef": 0.1404394954442978,
    "learning_rate": 0.001
  },
  {
    "episode": 1918,
    "reward": 79.230788,
    "length": 84,
    "time": 34254.591804,
    "actor_loss": -44.01652526855469,
    "critic_loss": 16.072839736938477,
    "ent_coef": 0.13474908471107483,
    "learning_rate": 0.001
  },
  {
    "episode": 1919,
    "reward": 84.007082,
    "length": 74,
    "time": 34271.395779,
    "actor_loss": -51.99797058105469,
    "critic_loss": 84.4668197631836,
    "ent_coef": 0.132007896900177,
    "learning_rate": 0.001
  },
  {
    "episode": 1920,
    "reward": 88.125456,
    "length": 68,
    "time": 34284.885856,
    "actor_loss": -43.41179656982422,
    "critic_loss": 115.05960083007812,
    "ent_coef": 0.13003066182136536,
    "learning_rate": 0.001
  },
  {
    "episode": 1921,
    "reward": 83.151145,
    "length": 79,
    "time": 34302.012083,
    "actor_loss": -47.64078140258789,
    "critic_loss": 139.28890991210938,
    "ent_coef": 0.1272634118795395,
    "learning_rate": 0.001
  },
  {
    "episode": 1922,
    "reward": 80.021047,
    "length": 82,
    "time": 34316.598619,
    "actor_loss": -44.47922897338867,
    "critic_loss": 74.98904418945312,
    "ent_coef": 0.12414726614952087,
    "learning_rate": 0.001
  },
  {
    "episode": 1923,
    "reward": 74.175446,
    "length": 91,
    "time": 34331.555125,
    "actor_loss": -48.46233367919922,
    "critic_loss": 66.26200866699219,
    "ent_coef": 0.11934290826320648,
    "learning_rate": 0.001
  },
  {
    "episode": 1924,
    "reward": 87.609108,
    "length": 68,
    "time": 34343.848672,
    "actor_loss": -42.57658386230469,
    "critic_loss": 14.393983840942383,
    "ent_coef": 0.11553291231393814,
    "learning_rate": 0.001
  },
  {
    "episode": 1925,
    "reward": 89.021228,
    "length": 64,
    "time": 34357.007156,
    "actor_loss": -49.98414611816406,
    "critic_loss": 34.962158203125,
    "ent_coef": 0.11858439445495605,
    "learning_rate": 0.001
  },
  {
    "episode": 1926,
    "reward": 88.643682,
    "length": 65,
    "time": 34369.355383,
    "actor_loss": -52.93238830566406,
    "critic_loss": 90.09784698486328,
    "ent_coef": 0.11872880905866623,
    "learning_rate": 0.001
  },
  {
    "episode": 1927,
    "reward": 82.678891,
    "length": 77,
    "time": 34385.941809,
    "actor_loss": -43.91014862060547,
    "critic_loss": 18.027877807617188,
    "ent_coef": 0.11948466300964355,
    "learning_rate": 0.001
  },
  {
    "episode": 1928,
    "reward": 83.3999,
    "length": 76,
    "time": 34400.752586,
    "actor_loss": -51.2628288269043,
    "critic_loss": 10.534817695617676,
    "ent_coef": 0.12058492749929428,
    "learning_rate": 0.001
  },
  {
    "episode": 1929,
    "reward": 85.438295,
    "length": 69,
    "time": 34414.901477,
    "actor_loss": -45.882450103759766,
    "critic_loss": 10.766305923461914,
    "ent_coef": 0.1281779706478119,
    "learning_rate": 0.001
  },
  {
    "episode": 1930,
    "reward": 85.610533,
    "length": 70,
    "time": 34428.161006,
    "actor_loss": -47.300724029541016,
    "critic_loss": 41.269779205322266,
    "ent_coef": 0.13436545431613922,
    "learning_rate": 0.001
  },
  {
    "episode": 1931,
    "reward": 89.211917,
    "length": 64,
    "time": 34440.032877,
    "actor_loss": -48.83258056640625,
    "critic_loss": 15.385330200195312,
    "ent_coef": 0.14126147329807281,
    "learning_rate": 0.001
  },
  {
    "episode": 1932,
    "reward": 87.371476,
    "length": 67,
    "time": 34451.642724,
    "actor_loss": -54.703372955322266,
    "critic_loss": 49.366912841796875,
    "ent_coef": 0.14599037170410156,
    "learning_rate": 0.001
  },
  {
    "episode": 1933,
    "reward": 89.610691,
    "length": 63,
    "time": 34463.410756,
    "actor_loss": -49.45642852783203,
    "critic_loss": 94.49392700195312,
    "ent_coef": 0.15167959034442902,
    "learning_rate": 0.001
  },
  {
    "episode": 1934,
    "reward": 86.142507,
    "length": 69,
    "time": 34475.284039,
    "actor_loss": -47.64179229736328,
    "critic_loss": 25.054664611816406,
    "ent_coef": 0.151176318526268,
    "learning_rate": 0.001
  },
  {
    "episode": 1935,
    "reward": 86.659013,
    "length": 68,
    "time": 34489.728451,
    "actor_loss": -44.78286361694336,
    "critic_loss": 17.51318359375,
    "ent_coef": 0.15127532184123993,
    "learning_rate": 0.001
  },
  {
    "episode": 1936,
    "reward": 84.027197,
    "length": 78,
    "time": 34502.929371,
    "actor_loss": -52.137290954589844,
    "critic_loss": 33.661643981933594,
    "ent_coef": 0.1386796087026596,
    "learning_rate": 0.001
  },
  {
    "episode": 1937,
    "reward": 81.875336,
    "length": 75,
    "time": 34516.893851,
    "actor_loss": -47.869903564453125,
    "critic_loss": 7.139278411865234,
    "ent_coef": 0.13191625475883484,
    "learning_rate": 0.001
  },
  {
    "episode": 1938,
    "reward": 85.96309,
    "length": 83,
    "time": 34531.870166,
    "actor_loss": -49.77433776855469,
    "critic_loss": 30.706634521484375,
    "ent_coef": 0.13203682005405426,
    "learning_rate": 0.001
  },
  {
    "episode": 1939,
    "reward": 87.343004,
    "length": 71,
    "time": 34546.597437,
    "actor_loss": -43.904266357421875,
    "critic_loss": 66.68531799316406,
    "ent_coef": 0.13272228837013245,
    "learning_rate": 0.001
  },
  {
    "episode": 1940,
    "reward": 77.580532,
    "length": 81,
    "time": 34561.11898,
    "actor_loss": -44.97410583496094,
    "critic_loss": 57.648719787597656,
    "ent_coef": 0.13636866211891174,
    "learning_rate": 0.001
  },
  {
    "episode": 1941,
    "reward": 87.222701,
    "length": 68,
    "time": 34572.86031,
    "actor_loss": -46.66759490966797,
    "critic_loss": 34.26693344116211,
    "ent_coef": 0.13592632114887238,
    "learning_rate": 0.001
  },
  {
    "episode": 1942,
    "reward": 82.642165,
    "length": 74,
    "time": 34589.386697,
    "actor_loss": -52.17852783203125,
    "critic_loss": 59.09387969970703,
    "ent_coef": 0.13233502209186554,
    "learning_rate": 0.001
  },
  {
    "episode": 1943,
    "reward": 87.921033,
    "length": 67,
    "time": 34601.851529,
    "actor_loss": -54.51583480834961,
    "critic_loss": 27.394319534301758,
    "ent_coef": 0.1309434175491333,
    "learning_rate": 0.001
  },
  {
    "episode": 1944,
    "reward": -156.947793,
    "length": 121,
    "time": 34621.427984,
    "actor_loss": -45.50908279418945,
    "critic_loss": 31.843521118164062,
    "ent_coef": 0.12419925630092621,
    "learning_rate": 0.001
  },
  {
    "episode": 1945,
    "reward": 83.905525,
    "length": 72,
    "time": 34634.832153,
    "actor_loss": -48.00849914550781,
    "critic_loss": 69.6631088256836,
    "ent_coef": 0.12200139462947845,
    "learning_rate": 0.001
  },
  {
    "episode": 1946,
    "reward": 88.164213,
    "length": 67,
    "time": 34648.578741,
    "actor_loss": -47.608646392822266,
    "critic_loss": 8.755975723266602,
    "ent_coef": 0.12235374003648758,
    "learning_rate": 0.001
  },
  {
    "episode": 1947,
    "reward": 84.899317,
    "length": 72,
    "time": 34664.03814,
    "actor_loss": -43.092498779296875,
    "critic_loss": 17.179811477661133,
    "ent_coef": 0.1258988380432129,
    "learning_rate": 0.001
  },
  {
    "episode": 1948,
    "reward": 89.933842,
    "length": 65,
    "time": 34676.358257,
    "actor_loss": -49.05797576904297,
    "critic_loss": 141.5753173828125,
    "ent_coef": 0.12467688322067261,
    "learning_rate": 0.001
  },
  {
    "episode": 1949,
    "reward": 79.088004,
    "length": 82,
    "time": 34690.983335,
    "actor_loss": -50.91331481933594,
    "critic_loss": 73.74452209472656,
    "ent_coef": 0.12535840272903442,
    "learning_rate": 0.001
  },
  {
    "episode": 1950,
    "reward": 88.004767,
    "length": 66,
    "time": 34703.544403,
    "actor_loss": -52.486236572265625,
    "critic_loss": 5.94219446182251,
    "ent_coef": 0.12634241580963135,
    "learning_rate": 0.001
  },
  {
    "episode": 1951,
    "reward": 87.909372,
    "length": 67,
    "time": 34715.462744,
    "actor_loss": -51.273895263671875,
    "critic_loss": 14.61912727355957,
    "ent_coef": 0.12652850151062012,
    "learning_rate": 0.001
  },
  {
    "episode": 1952,
    "reward": 86.44426,
    "length": 71,
    "time": 34729.998519,
    "actor_loss": -46.0051155090332,
    "critic_loss": 18.098257064819336,
    "ent_coef": 0.12626807391643524,
    "learning_rate": 0.001
  },
  {
    "episode": 1953,
    "reward": 82.355991,
    "length": 76,
    "time": 34746.028359,
    "actor_loss": -49.35054016113281,
    "critic_loss": 37.786598205566406,
    "ent_coef": 0.1282469928264618,
    "learning_rate": 0.001
  },
  {
    "episode": 1954,
    "reward": 86.694413,
    "length": 69,
    "time": 34759.901885,
    "actor_loss": -48.748016357421875,
    "critic_loss": 83.66697692871094,
    "ent_coef": 0.12890994548797607,
    "learning_rate": 0.001
  },
  {
    "episode": 1955,
    "reward": 89.053206,
    "length": 65,
    "time": 34772.07647,
    "actor_loss": -40.573326110839844,
    "critic_loss": 51.38828659057617,
    "ent_coef": 0.1321144551038742,
    "learning_rate": 0.001
  },
  {
    "episode": 1956,
    "reward": 86.615718,
    "length": 74,
    "time": 34786.532135,
    "actor_loss": -45.78959655761719,
    "critic_loss": 44.283119201660156,
    "ent_coef": 0.1354755163192749,
    "learning_rate": 0.001
  },
  {
    "episode": 1957,
    "reward": 84.597836,
    "length": 72,
    "time": 34802.142576,
    "actor_loss": -52.02375030517578,
    "critic_loss": 40.28305435180664,
    "ent_coef": 0.13512977957725525,
    "learning_rate": 0.001
  },
  {
    "episode": 1958,
    "reward": 76.775125,
    "length": 83,
    "time": 34818.995616,
    "actor_loss": -49.91916275024414,
    "critic_loss": 13.48336410522461,
    "ent_coef": 0.13352486491203308,
    "learning_rate": 0.001
  },
  {
    "episode": 1959,
    "reward": 86.840546,
    "length": 70,
    "time": 34833.03408,
    "actor_loss": -50.50518798828125,
    "critic_loss": 9.683046340942383,
    "ent_coef": 0.12813256680965424,
    "learning_rate": 0.001
  },
  {
    "episode": 1960,
    "reward": 83.137466,
    "length": 77,
    "time": 34846.068582,
    "actor_loss": -52.34724044799805,
    "critic_loss": 68.39433288574219,
    "ent_coef": 0.12829482555389404,
    "learning_rate": 0.001
  },
  {
    "episode": 1961,
    "reward": 84.562058,
    "length": 77,
    "time": 34859.563954,
    "actor_loss": -51.77112579345703,
    "critic_loss": 30.26728057861328,
    "ent_coef": 0.1253238022327423,
    "learning_rate": 0.001
  },
  {
    "episode": 1962,
    "reward": 84.216882,
    "length": 72,
    "time": 34871.86897,
    "actor_loss": -47.10407257080078,
    "critic_loss": 10.924570083618164,
    "ent_coef": 0.12633907794952393,
    "learning_rate": 0.001
  },
  {
    "episode": 1963,
    "reward": 83.906999,
    "length": 78,
    "time": 34885.842202,
    "actor_loss": -48.10595703125,
    "critic_loss": 54.75075912475586,
    "ent_coef": 0.12808354198932648,
    "learning_rate": 0.001
  },
  {
    "episode": 1964,
    "reward": 84.05153,
    "length": 78,
    "time": 34899.147395,
    "actor_loss": -48.66735076904297,
    "critic_loss": 10.501749038696289,
    "ent_coef": 0.12764790654182434,
    "learning_rate": 0.001
  },
  {
    "episode": 1965,
    "reward": 80.907453,
    "length": 84,
    "time": 34913.395087,
    "actor_loss": -43.74199295043945,
    "critic_loss": 10.471784591674805,
    "ent_coef": 0.12414117157459259,
    "learning_rate": 0.001
  },
  {
    "episode": 1966,
    "reward": 83.292823,
    "length": 74,
    "time": 34926.677167,
    "actor_loss": -46.68918228149414,
    "critic_loss": 30.762313842773438,
    "ent_coef": 0.1218578964471817,
    "learning_rate": 0.001
  },
  {
    "episode": 1967,
    "reward": 86.01754,
    "length": 70,
    "time": 34939.308355,
    "actor_loss": -50.68358612060547,
    "critic_loss": 24.262453079223633,
    "ent_coef": 0.1218995675444603,
    "learning_rate": 0.001
  },
  {
    "episode": 1968,
    "reward": 86.605649,
    "length": 69,
    "time": 34952.436844,
    "actor_loss": -40.197452545166016,
    "critic_loss": 28.232078552246094,
    "ent_coef": 0.12204314023256302,
    "learning_rate": 0.001
  },
  {
    "episode": 1969,
    "reward": 85.681496,
    "length": 72,
    "time": 34965.644562,
    "actor_loss": -51.66693115234375,
    "critic_loss": 22.655540466308594,
    "ent_coef": 0.12226010113954544,
    "learning_rate": 0.001
  },
  {
    "episode": 1970,
    "reward": 76.044395,
    "length": 85,
    "time": 34979.652881,
    "actor_loss": -49.06721878051758,
    "critic_loss": 39.17729949951172,
    "ent_coef": 0.11818286776542664,
    "learning_rate": 0.001
  },
  {
    "episode": 1971,
    "reward": 88.211203,
    "length": 69,
    "time": 34993.820441,
    "actor_loss": -50.37828063964844,
    "critic_loss": 10.776403427124023,
    "ent_coef": 0.11879396438598633,
    "learning_rate": 0.001
  },
  {
    "episode": 1972,
    "reward": 83.718215,
    "length": 75,
    "time": 35007.646152,
    "actor_loss": -43.6546745300293,
    "critic_loss": 28.57636260986328,
    "ent_coef": 0.12004898488521576,
    "learning_rate": 0.001
  },
  {
    "episode": 1973,
    "reward": 88.272779,
    "length": 70,
    "time": 35019.617627,
    "actor_loss": -47.171730041503906,
    "critic_loss": 16.599687576293945,
    "ent_coef": 0.1277201771736145,
    "learning_rate": 0.001
  },
  {
    "episode": 1974,
    "reward": 76.451053,
    "length": 84,
    "time": 35034.590709,
    "actor_loss": -43.59107208251953,
    "critic_loss": 22.362045288085938,
    "ent_coef": 0.12798048555850983,
    "learning_rate": 0.001
  },
  {
    "episode": 1975,
    "reward": 79.696846,
    "length": 79,
    "time": 35050.728075,
    "actor_loss": -56.38134765625,
    "critic_loss": 50.378517150878906,
    "ent_coef": 0.12880343198776245,
    "learning_rate": 0.001
  },
  {
    "episode": 1976,
    "reward": 84.483462,
    "length": 73,
    "time": 35064.264449,
    "actor_loss": -53.88599395751953,
    "critic_loss": 62.80317687988281,
    "ent_coef": 0.12446079403162003,
    "learning_rate": 0.001
  },
  {
    "episode": 1977,
    "reward": 86.735414,
    "length": 70,
    "time": 35077.263171,
    "actor_loss": -42.70903778076172,
    "critic_loss": 11.879449844360352,
    "ent_coef": 0.12395011633634567,
    "learning_rate": 0.001
  },
  {
    "episode": 1978,
    "reward": 84.753926,
    "length": 78,
    "time": 35090.82496,
    "actor_loss": -45.87538146972656,
    "critic_loss": 28.074142456054688,
    "ent_coef": 0.12497588992118835,
    "learning_rate": 0.001
  },
  {
    "episode": 1979,
    "reward": 85.912795,
    "length": 69,
    "time": 35103.469163,
    "actor_loss": -50.67436981201172,
    "critic_loss": 81.40020751953125,
    "ent_coef": 0.12903952598571777,
    "learning_rate": 0.001
  },
  {
    "episode": 1980,
    "reward": 89.659683,
    "length": 65,
    "time": 35116.329755,
    "actor_loss": -46.589691162109375,
    "critic_loss": 58.37785339355469,
    "ent_coef": 0.13334143161773682,
    "learning_rate": 0.001
  },
  {
    "episode": 1981,
    "reward": 80.205789,
    "length": 79,
    "time": 35130.727673,
    "actor_loss": -51.485389709472656,
    "critic_loss": 7.316614151000977,
    "ent_coef": 0.1329367756843567,
    "learning_rate": 0.001
  },
  {
    "episode": 1982,
    "reward": 89.850436,
    "length": 64,
    "time": 35145.474665,
    "actor_loss": -50.76789855957031,
    "critic_loss": 62.08358383178711,
    "ent_coef": 0.1364014893770218,
    "learning_rate": 0.001
  },
  {
    "episode": 1983,
    "reward": 66.766689,
    "length": 101,
    "time": 35167.516153,
    "actor_loss": -50.231353759765625,
    "critic_loss": 17.463708877563477,
    "ent_coef": 0.1311836838722229,
    "learning_rate": 0.001
  },
  {
    "episode": 1984,
    "reward": 86.865233,
    "length": 68,
    "time": 35182.631987,
    "actor_loss": -41.42308807373047,
    "critic_loss": 153.70957946777344,
    "ent_coef": 0.13099081814289093,
    "learning_rate": 0.001
  },
  {
    "episode": 1985,
    "reward": 87.765707,
    "length": 67,
    "time": 35196.141014,
    "actor_loss": -42.132789611816406,
    "critic_loss": 12.206892967224121,
    "ent_coef": 0.13124136626720428,
    "learning_rate": 0.001
  },
  {
    "episode": 1986,
    "reward": 89.071924,
    "length": 66,
    "time": 35209.490777,
    "actor_loss": -43.5182991027832,
    "critic_loss": 46.59136962890625,
    "ent_coef": 0.12716244161128998,
    "learning_rate": 0.001
  },
  {
    "episode": 1987,
    "reward": 84.637902,
    "length": 73,
    "time": 35224.751016,
    "actor_loss": -46.288780212402344,
    "critic_loss": 75.02153015136719,
    "ent_coef": 0.1290796548128128,
    "learning_rate": 0.001
  },
  {
    "episode": 1988,
    "reward": 86.214538,
    "length": 68,
    "time": 35236.509077,
    "actor_loss": -57.42504119873047,
    "critic_loss": 132.5315704345703,
    "ent_coef": 0.13215388357639313,
    "learning_rate": 0.001
  },
  {
    "episode": 1989,
    "reward": 83.684221,
    "length": 90,
    "time": 35251.239624,
    "actor_loss": -47.43872833251953,
    "critic_loss": 43.214393615722656,
    "ent_coef": 0.12449438869953156,
    "learning_rate": 0.001
  },
  {
    "episode": 1990,
    "reward": -160.610317,
    "length": 117,
    "time": 35269.301607,
    "actor_loss": -51.111846923828125,
    "critic_loss": 73.08319091796875,
    "ent_coef": 0.12353528290987015,
    "learning_rate": 0.001
  },
  {
    "episode": 1991,
    "reward": 79.611114,
    "length": 78,
    "time": 35285.186327,
    "actor_loss": -51.28025817871094,
    "critic_loss": 39.908958435058594,
    "ent_coef": 0.12058889120817184,
    "learning_rate": 0.001
  },
  {
    "episode": 1992,
    "reward": 81.871552,
    "length": 98,
    "time": 35303.385907,
    "actor_loss": -47.489501953125,
    "critic_loss": 50.4664306640625,
    "ent_coef": 0.1277795284986496,
    "learning_rate": 0.001
  },
  {
    "episode": 1993,
    "reward": 84.321751,
    "length": 70,
    "time": 35316.41655,
    "actor_loss": -51.459388732910156,
    "critic_loss": 4.135298252105713,
    "ent_coef": 0.13075928390026093,
    "learning_rate": 0.001
  },
  {
    "episode": 1994,
    "reward": 84.744013,
    "length": 71,
    "time": 35332.995279,
    "actor_loss": -48.291526794433594,
    "critic_loss": 84.55007934570312,
    "ent_coef": 0.12831354141235352,
    "learning_rate": 0.001
  },
  {
    "episode": 1995,
    "reward": 85.425215,
    "length": 73,
    "time": 35346.49342,
    "actor_loss": -44.297157287597656,
    "critic_loss": 84.32147216796875,
    "ent_coef": 0.12322115153074265,
    "learning_rate": 0.001
  },
  {
    "episode": 1996,
    "reward": 85.687119,
    "length": 72,
    "time": 35360.112216,
    "actor_loss": -49.26734924316406,
    "critic_loss": 21.43012237548828,
    "ent_coef": 0.12400515377521515,
    "learning_rate": 0.001
  },
  {
    "episode": 1997,
    "reward": 91.259105,
    "length": 63,
    "time": 35372.273504,
    "actor_loss": -47.665348052978516,
    "critic_loss": 60.25947570800781,
    "ent_coef": 0.12876330316066742,
    "learning_rate": 0.001
  },
  {
    "episode": 1998,
    "reward": 86.434192,
    "length": 69,
    "time": 35385.330912,
    "actor_loss": -44.95473098754883,
    "critic_loss": 40.04735565185547,
    "ent_coef": 0.1281837373971939,
    "learning_rate": 0.001
  },
  {
    "episode": 1999,
    "reward": -154.814992,
    "length": 115,
    "time": 35404.507938,
    "actor_loss": -46.408634185791016,
    "critic_loss": 35.53142166137695,
    "ent_coef": 0.13149096071720123,
    "learning_rate": 0.001
  },
  {
    "episode": 2000,
    "reward": 88.83198,
    "length": 66,
    "time": 35417.522358,
    "actor_loss": -44.432334899902344,
    "critic_loss": 29.373638153076172,
    "ent_coef": 0.12997187674045563,
    "learning_rate": 0.001
  },
  {
    "episode": 2001,
    "reward": 87.881459,
    "length": 72,
    "time": 35430.141589,
    "actor_loss": -49.28099060058594,
    "critic_loss": 73.11001586914062,
    "ent_coef": 0.1323324739933014,
    "learning_rate": 0.001
  },
  {
    "episode": 2002,
    "reward": 87.803189,
    "length": 71,
    "time": 35442.697866,
    "actor_loss": -48.22663116455078,
    "critic_loss": 9.049967765808105,
    "ent_coef": 0.13262641429901123,
    "learning_rate": 0.001
  },
  {
    "episode": 2003,
    "reward": 86.518291,
    "length": 68,
    "time": 35455.693701,
    "actor_loss": -49.408287048339844,
    "critic_loss": 36.566715240478516,
    "ent_coef": 0.12934646010398865,
    "learning_rate": 0.001
  },
  {
    "episode": 2004,
    "reward": 89.281419,
    "length": 63,
    "time": 35470.28926,
    "actor_loss": -45.342041015625,
    "critic_loss": 15.156109809875488,
    "ent_coef": 0.12676231563091278,
    "learning_rate": 0.001
  },
  {
    "episode": 2005,
    "reward": 88.110903,
    "length": 67,
    "time": 35485.63032,
    "actor_loss": -47.57981491088867,
    "critic_loss": 6.898628234863281,
    "ent_coef": 0.1219652071595192,
    "learning_rate": 0.001
  },
  {
    "episode": 2006,
    "reward": 82.170506,
    "length": 76,
    "time": 35499.884968,
    "actor_loss": -44.69055938720703,
    "critic_loss": 14.353534698486328,
    "ent_coef": 0.12006192654371262,
    "learning_rate": 0.001
  },
  {
    "episode": 2007,
    "reward": 87.325197,
    "length": 66,
    "time": 35511.532447,
    "actor_loss": -47.693138122558594,
    "critic_loss": 6.177031993865967,
    "ent_coef": 0.11685613542795181,
    "learning_rate": 0.001
  },
  {
    "episode": 2008,
    "reward": 88.348543,
    "length": 66,
    "time": 35524.105383,
    "actor_loss": -45.25282669067383,
    "critic_loss": 9.451375961303711,
    "ent_coef": 0.11554606258869171,
    "learning_rate": 0.001
  },
  {
    "episode": 2009,
    "reward": 85.345161,
    "length": 71,
    "time": 35540.098143,
    "actor_loss": -52.64178466796875,
    "critic_loss": 58.45225524902344,
    "ent_coef": 0.11189185082912445,
    "learning_rate": 0.001
  },
  {
    "episode": 2010,
    "reward": 87.57728,
    "length": 67,
    "time": 35552.696492,
    "actor_loss": -48.824462890625,
    "critic_loss": 43.981468200683594,
    "ent_coef": 0.11767525225877762,
    "learning_rate": 0.001
  },
  {
    "episode": 2011,
    "reward": -157.08311,
    "length": 125,
    "time": 35574.081568,
    "actor_loss": -47.230255126953125,
    "critic_loss": 7.896100044250488,
    "ent_coef": 0.13121643662452698,
    "learning_rate": 0.001
  },
  {
    "episode": 2012,
    "reward": 88.176035,
    "length": 70,
    "time": 35586.114441,
    "actor_loss": -51.72180938720703,
    "critic_loss": 17.935148239135742,
    "ent_coef": 0.13751055300235748,
    "learning_rate": 0.001
  },
  {
    "episode": 2013,
    "reward": -272.199846,
    "length": 268,
    "time": 35625.680632,
    "actor_loss": -46.40422058105469,
    "critic_loss": 82.65621948242188,
    "ent_coef": 0.13546563684940338,
    "learning_rate": 0.001
  },
  {
    "episode": 2014,
    "reward": 96.106509,
    "length": 69,
    "time": 35641.82727,
    "actor_loss": -50.4493293762207,
    "critic_loss": 2.8797569274902344,
    "ent_coef": 0.13170550763607025,
    "learning_rate": 0.001
  },
  {
    "episode": 2015,
    "reward": 84.315684,
    "length": 77,
    "time": 35654.796127,
    "actor_loss": -45.74100875854492,
    "critic_loss": 15.62835693359375,
    "ent_coef": 0.12768708169460297,
    "learning_rate": 0.001
  },
  {
    "episode": 2016,
    "reward": 83.396696,
    "length": 75,
    "time": 35668.476131,
    "actor_loss": -43.91493225097656,
    "critic_loss": 8.70854377746582,
    "ent_coef": 0.12535396218299866,
    "learning_rate": 0.001
  },
  {
    "episode": 2017,
    "reward": 88.723267,
    "length": 65,
    "time": 35679.918573,
    "actor_loss": -47.211822509765625,
    "critic_loss": 20.61663055419922,
    "ent_coef": 0.12599588930606842,
    "learning_rate": 0.001
  },
  {
    "episode": 2018,
    "reward": 80.345504,
    "length": 79,
    "time": 35693.270677,
    "actor_loss": -48.06827163696289,
    "critic_loss": 40.75749588012695,
    "ent_coef": 0.12455561012029648,
    "learning_rate": 0.001
  },
  {
    "episode": 2019,
    "reward": 86.006017,
    "length": 70,
    "time": 35706.307878,
    "actor_loss": -45.565086364746094,
    "critic_loss": 14.629631996154785,
    "ent_coef": 0.12532484531402588,
    "learning_rate": 0.001
  },
  {
    "episode": 2020,
    "reward": 87.028922,
    "length": 69,
    "time": 35719.400477,
    "actor_loss": -50.27718734741211,
    "critic_loss": 290.67071533203125,
    "ent_coef": 0.12713918089866638,
    "learning_rate": 0.001
  },
  {
    "episode": 2021,
    "reward": 82.594943,
    "length": 80,
    "time": 35733.599608,
    "actor_loss": -46.63252639770508,
    "critic_loss": 26.13080596923828,
    "ent_coef": 0.12463010102510452,
    "learning_rate": 0.001
  },
  {
    "episode": 2022,
    "reward": 87.87595,
    "length": 66,
    "time": 35745.269816,
    "actor_loss": -50.80397415161133,
    "critic_loss": 33.31035614013672,
    "ent_coef": 0.12572309374809265,
    "learning_rate": 0.001
  },
  {
    "episode": 2023,
    "reward": 88.606571,
    "length": 68,
    "time": 35757.133,
    "actor_loss": -47.08942794799805,
    "critic_loss": 20.702075958251953,
    "ent_coef": 0.1317066103219986,
    "learning_rate": 0.001
  },
  {
    "episode": 2024,
    "reward": 81.25334,
    "length": 77,
    "time": 35775.000217,
    "actor_loss": -50.18836975097656,
    "critic_loss": 24.630237579345703,
    "ent_coef": 0.12885648012161255,
    "learning_rate": 0.001
  },
  {
    "episode": 2025,
    "reward": 85.905781,
    "length": 70,
    "time": 35788.206791,
    "actor_loss": -49.39974594116211,
    "critic_loss": 10.659204483032227,
    "ent_coef": 0.1257648915052414,
    "learning_rate": 0.001
  },
  {
    "episode": 2026,
    "reward": 88.101592,
    "length": 67,
    "time": 35800.09382,
    "actor_loss": -58.15074920654297,
    "critic_loss": 75.626708984375,
    "ent_coef": 0.12331884354352951,
    "learning_rate": 0.001
  },
  {
    "episode": 2027,
    "reward": 83.480851,
    "length": 93,
    "time": 35819.125566,
    "actor_loss": -50.46893310546875,
    "critic_loss": 27.124649047851562,
    "ent_coef": 0.12210125476121902,
    "learning_rate": 0.001
  },
  {
    "episode": 2028,
    "reward": 89.15135,
    "length": 64,
    "time": 35833.180923,
    "actor_loss": -45.46331024169922,
    "critic_loss": 82.7389907836914,
    "ent_coef": 0.12438312917947769,
    "learning_rate": 0.001
  },
  {
    "episode": 2029,
    "reward": 86.79076,
    "length": 71,
    "time": 35847.240725,
    "actor_loss": -50.97801208496094,
    "critic_loss": 88.01657104492188,
    "ent_coef": 0.12326187640428543,
    "learning_rate": 0.001
  },
  {
    "episode": 2030,
    "reward": 83.634512,
    "length": 72,
    "time": 35860.787067,
    "actor_loss": -52.7537841796875,
    "critic_loss": 88.53237915039062,
    "ent_coef": 0.12419548630714417,
    "learning_rate": 0.001
  },
  {
    "episode": 2031,
    "reward": 88.063253,
    "length": 68,
    "time": 35872.864913,
    "actor_loss": -48.98775100708008,
    "critic_loss": 18.39341926574707,
    "ent_coef": 0.12453170120716095,
    "learning_rate": 0.001
  },
  {
    "episode": 2032,
    "reward": 87.299398,
    "length": 68,
    "time": 35884.786988,
    "actor_loss": -46.258724212646484,
    "critic_loss": 17.314151763916016,
    "ent_coef": 0.12500682473182678,
    "learning_rate": 0.001
  },
  {
    "episode": 2033,
    "reward": 88.693222,
    "length": 67,
    "time": 35897.55477,
    "actor_loss": -50.274330139160156,
    "critic_loss": 578.3892822265625,
    "ent_coef": 0.12530308961868286,
    "learning_rate": 0.001
  },
  {
    "episode": 2034,
    "reward": 88.637221,
    "length": 65,
    "time": 35909.805191,
    "actor_loss": -47.75041961669922,
    "critic_loss": 5.435690879821777,
    "ent_coef": 0.12362688034772873,
    "learning_rate": 0.001
  },
  {
    "episode": 2035,
    "reward": 86.085252,
    "length": 70,
    "time": 35922.260772,
    "actor_loss": -50.936073303222656,
    "critic_loss": 58.75809860229492,
    "ent_coef": 0.1179765984416008,
    "learning_rate": 0.001
  },
  {
    "episode": 2036,
    "reward": 88.103274,
    "length": 71,
    "time": 35935.276619,
    "actor_loss": -50.992523193359375,
    "critic_loss": 15.917299270629883,
    "ent_coef": 0.11932575702667236,
    "learning_rate": 0.001
  },
  {
    "episode": 2037,
    "reward": 74.531735,
    "length": 90,
    "time": 35953.786994,
    "actor_loss": -42.55951690673828,
    "critic_loss": 20.118289947509766,
    "ent_coef": 0.11923711001873016,
    "learning_rate": 0.001
  },
  {
    "episode": 2038,
    "reward": 89.25568,
    "length": 64,
    "time": 35967.46156,
    "actor_loss": -52.148353576660156,
    "critic_loss": 16.38107681274414,
    "ent_coef": 0.1258290708065033,
    "learning_rate": 0.001
  },
  {
    "episode": 2039,
    "reward": 89.593809,
    "length": 65,
    "time": 35979.770242,
    "actor_loss": -44.683349609375,
    "critic_loss": 25.032991409301758,
    "ent_coef": 0.12963716685771942,
    "learning_rate": 0.001
  },
  {
    "episode": 2040,
    "reward": 89.940142,
    "length": 64,
    "time": 35991.022094,
    "actor_loss": -46.52064514160156,
    "critic_loss": 152.41104125976562,
    "ent_coef": 0.13206976652145386,
    "learning_rate": 0.001
  },
  {
    "episode": 2041,
    "reward": 87.275073,
    "length": 69,
    "time": 36003.240433,
    "actor_loss": -48.79232406616211,
    "critic_loss": 23.28974723815918,
    "ent_coef": 0.13762956857681274,
    "learning_rate": 0.001
  },
  {
    "episode": 2042,
    "reward": 88.705392,
    "length": 71,
    "time": 36015.930609,
    "actor_loss": -49.575706481933594,
    "critic_loss": 15.826377868652344,
    "ent_coef": 0.14052210748195648,
    "learning_rate": 0.001
  },
  {
    "episode": 2043,
    "reward": 79.979915,
    "length": 79,
    "time": 36031.499489,
    "actor_loss": -54.140419006347656,
    "critic_loss": 26.157058715820312,
    "ent_coef": 0.14455878734588623,
    "learning_rate": 0.001
  },
  {
    "episode": 2044,
    "reward": 82.208297,
    "length": 76,
    "time": 36044.526081,
    "actor_loss": -48.922386169433594,
    "critic_loss": 144.68809509277344,
    "ent_coef": 0.1462022364139557,
    "learning_rate": 0.001
  },
  {
    "episode": 2045,
    "reward": 86.409478,
    "length": 70,
    "time": 36057.968838,
    "actor_loss": -48.540748596191406,
    "critic_loss": 22.046916961669922,
    "ent_coef": 0.14086541533470154,
    "learning_rate": 0.001
  },
  {
    "episode": 2046,
    "reward": 86.253495,
    "length": 69,
    "time": 36069.941016,
    "actor_loss": -44.76979064941406,
    "critic_loss": 8.537810325622559,
    "ent_coef": 0.14426109194755554,
    "learning_rate": 0.001
  },
  {
    "episode": 2047,
    "reward": 85.915672,
    "length": 70,
    "time": 36083.547407,
    "actor_loss": -46.04043960571289,
    "critic_loss": 195.40463256835938,
    "ent_coef": 0.14026039838790894,
    "learning_rate": 0.001
  },
  {
    "episode": 2048,
    "reward": 88.629514,
    "length": 68,
    "time": 36095.230529,
    "actor_loss": -49.154747009277344,
    "critic_loss": 7.387603759765625,
    "ent_coef": 0.13533316552639008,
    "learning_rate": 0.001
  },
  {
    "episode": 2049,
    "reward": 86.359934,
    "length": 69,
    "time": 36107.320013,
    "actor_loss": -48.51811218261719,
    "critic_loss": 51.37932586669922,
    "ent_coef": 0.1372741162776947,
    "learning_rate": 0.001
  },
  {
    "episode": 2050,
    "reward": 87.820502,
    "length": 68,
    "time": 36119.666308,
    "actor_loss": -49.1739616394043,
    "critic_loss": 23.825969696044922,
    "ent_coef": 0.1374686360359192,
    "learning_rate": 0.001
  },
  {
    "episode": 2051,
    "reward": 76.369999,
    "length": 85,
    "time": 36135.984244,
    "actor_loss": -49.98200607299805,
    "critic_loss": 77.95684814453125,
    "ent_coef": 0.13166551291942596,
    "learning_rate": 0.001
  },
  {
    "episode": 2052,
    "reward": 81.027396,
    "length": 77,
    "time": 36149.1964,
    "actor_loss": -50.03045654296875,
    "critic_loss": 60.135528564453125,
    "ent_coef": 0.13060811161994934,
    "learning_rate": 0.001
  },
  {
    "episode": 2053,
    "reward": 86.902041,
    "length": 69,
    "time": 36161.582885,
    "actor_loss": -49.67556381225586,
    "critic_loss": 83.97783660888672,
    "ent_coef": 0.13315778970718384,
    "learning_rate": 0.001
  },
  {
    "episode": 2054,
    "reward": 87.889231,
    "length": 66,
    "time": 36173.580934,
    "actor_loss": -50.96376419067383,
    "critic_loss": 601.7567138671875,
    "ent_coef": 0.1335059255361557,
    "learning_rate": 0.001
  },
  {
    "episode": 2055,
    "reward": 83.198543,
    "length": 75,
    "time": 36187.383859,
    "actor_loss": -45.87445068359375,
    "critic_loss": 45.78202438354492,
    "ent_coef": 0.1351664811372757,
    "learning_rate": 0.001
  },
  {
    "episode": 2056,
    "reward": 80.311267,
    "length": 78,
    "time": 36202.330265,
    "actor_loss": -59.22631072998047,
    "critic_loss": 19.166213989257812,
    "ent_coef": 0.1358771026134491,
    "learning_rate": 0.001
  },
  {
    "episode": 2057,
    "reward": 86.925429,
    "length": 70,
    "time": 36216.017183,
    "actor_loss": -48.27861785888672,
    "critic_loss": 18.963552474975586,
    "ent_coef": 0.13248777389526367,
    "learning_rate": 0.001
  },
  {
    "episode": 2058,
    "reward": 86.389275,
    "length": 69,
    "time": 36228.060109,
    "actor_loss": -46.01708221435547,
    "critic_loss": 44.311553955078125,
    "ent_coef": 0.12684446573257446,
    "learning_rate": 0.001
  },
  {
    "episode": 2059,
    "reward": 88.292608,
    "length": 65,
    "time": 36241.501913,
    "actor_loss": -54.72969055175781,
    "critic_loss": 369.05438232421875,
    "ent_coef": 0.12749862670898438,
    "learning_rate": 0.001
  },
  {
    "episode": 2060,
    "reward": 89.20789,
    "length": 66,
    "time": 36253.165865,
    "actor_loss": -43.33954620361328,
    "critic_loss": 103.67057037353516,
    "ent_coef": 0.12829448282718658,
    "learning_rate": 0.001
  },
  {
    "episode": 2061,
    "reward": 82.56292,
    "length": 77,
    "time": 36269.797917,
    "actor_loss": -46.423580169677734,
    "critic_loss": 29.160572052001953,
    "ent_coef": 0.1267690658569336,
    "learning_rate": 0.001
  },
  {
    "episode": 2062,
    "reward": 87.066303,
    "length": 73,
    "time": 36283.592971,
    "actor_loss": -47.478599548339844,
    "critic_loss": 8.911971092224121,
    "ent_coef": 0.1258317083120346,
    "learning_rate": 0.001
  },
  {
    "episode": 2063,
    "reward": 88.916793,
    "length": 65,
    "time": 36295.363568,
    "actor_loss": -53.74652862548828,
    "critic_loss": 11.73523998260498,
    "ent_coef": 0.12747658789157867,
    "learning_rate": 0.001
  },
  {
    "episode": 2064,
    "reward": 86.573192,
    "length": 70,
    "time": 36307.398391,
    "actor_loss": -51.43841552734375,
    "critic_loss": 17.749553680419922,
    "ent_coef": 0.12867271900177002,
    "learning_rate": 0.001
  },
  {
    "episode": 2065,
    "reward": 87.209605,
    "length": 71,
    "time": 36329.240023,
    "actor_loss": -43.81196594238281,
    "critic_loss": 55.207069396972656,
    "ent_coef": 0.13175523281097412,
    "learning_rate": 0.001
  },
  {
    "episode": 2066,
    "reward": 85.310255,
    "length": 70,
    "time": 36342.445988,
    "actor_loss": -46.33766174316406,
    "critic_loss": 3.7486355304718018,
    "ent_coef": 0.13229341804981232,
    "learning_rate": 0.001
  },
  {
    "episode": 2067,
    "reward": 80.872405,
    "length": 83,
    "time": 36358.095176,
    "actor_loss": -43.91925048828125,
    "critic_loss": 59.72352600097656,
    "ent_coef": 0.13078288733959198,
    "learning_rate": 0.001
  },
  {
    "episode": 2068,
    "reward": 87.683827,
    "length": 68,
    "time": 36370.079742,
    "actor_loss": -52.19879150390625,
    "critic_loss": 478.39447021484375,
    "ent_coef": 0.13262410461902618,
    "learning_rate": 0.001
  },
  {
    "episode": 2069,
    "reward": 87.669888,
    "length": 71,
    "time": 36383.065743,
    "actor_loss": -46.26777267456055,
    "critic_loss": 26.560596466064453,
    "ent_coef": 0.13409966230392456,
    "learning_rate": 0.001
  },
  {
    "episode": 2070,
    "reward": 85.812296,
    "length": 71,
    "time": 36398.117901,
    "actor_loss": -55.79084396362305,
    "critic_loss": 11.566778182983398,
    "ent_coef": 0.13353231549263,
    "learning_rate": 0.001
  },
  {
    "episode": 2071,
    "reward": 83.92148,
    "length": 74,
    "time": 36411.179388,
    "actor_loss": -50.91788101196289,
    "critic_loss": 26.495960235595703,
    "ent_coef": 0.1364482343196869,
    "learning_rate": 0.001
  },
  {
    "episode": 2072,
    "reward": 86.611382,
    "length": 68,
    "time": 36427.543993,
    "actor_loss": -56.64249038696289,
    "critic_loss": 54.131839752197266,
    "ent_coef": 0.13737699389457703,
    "learning_rate": 0.001
  },
  {
    "episode": 2073,
    "reward": 88.66424,
    "length": 66,
    "time": 36439.041166,
    "actor_loss": -52.07023620605469,
    "critic_loss": 42.20154571533203,
    "ent_coef": 0.1399191915988922,
    "learning_rate": 0.001
  },
  {
    "episode": 2074,
    "reward": 89.157178,
    "length": 66,
    "time": 36450.906387,
    "actor_loss": -45.22617721557617,
    "critic_loss": 5.7755045890808105,
    "ent_coef": 0.1409982591867447,
    "learning_rate": 0.001
  },
  {
    "episode": 2075,
    "reward": 86.62085,
    "length": 69,
    "time": 36462.66596,
    "actor_loss": -51.393699645996094,
    "critic_loss": 16.066396713256836,
    "ent_coef": 0.13997261226177216,
    "learning_rate": 0.001
  },
  {
    "episode": 2076,
    "reward": 85.933963,
    "length": 69,
    "time": 36475.971657,
    "actor_loss": -45.44152069091797,
    "critic_loss": 8.180606842041016,
    "ent_coef": 0.1353512555360794,
    "learning_rate": 0.001
  },
  {
    "episode": 2077,
    "reward": 86.639725,
    "length": 68,
    "time": 36487.876946,
    "actor_loss": -53.454227447509766,
    "critic_loss": 6.575527667999268,
    "ent_coef": 0.1336785852909088,
    "learning_rate": 0.001
  },
  {
    "episode": 2078,
    "reward": 90.466985,
    "length": 62,
    "time": 36500.96292,
    "actor_loss": -55.26187515258789,
    "critic_loss": 55.54279327392578,
    "ent_coef": 0.1339271366596222,
    "learning_rate": 0.001
  },
  {
    "episode": 2079,
    "reward": 87.757839,
    "length": 68,
    "time": 36512.826317,
    "actor_loss": -50.832149505615234,
    "critic_loss": 7.60404634475708,
    "ent_coef": 0.13436074554920197,
    "learning_rate": 0.001
  },
  {
    "episode": 2080,
    "reward": 80.733504,
    "length": 78,
    "time": 36528.126694,
    "actor_loss": -49.442718505859375,
    "critic_loss": 7.222978115081787,
    "ent_coef": 0.13216334581375122,
    "learning_rate": 0.001
  },
  {
    "episode": 2081,
    "reward": 86.460994,
    "length": 70,
    "time": 36541.093833,
    "actor_loss": -44.760772705078125,
    "critic_loss": 45.580101013183594,
    "ent_coef": 0.13035444915294647,
    "learning_rate": 0.001
  },
  {
    "episode": 2082,
    "reward": 77.004292,
    "length": 99,
    "time": 36558.031555,
    "actor_loss": -50.806739807128906,
    "critic_loss": 11.241159439086914,
    "ent_coef": 0.13165850937366486,
    "learning_rate": 0.001
  },
  {
    "episode": 2083,
    "reward": 90.363157,
    "length": 62,
    "time": 36570.945205,
    "actor_loss": -49.45329666137695,
    "critic_loss": 15.957820892333984,
    "ent_coef": 0.1365976482629776,
    "learning_rate": 0.001
  },
  {
    "episode": 2084,
    "reward": 89.41399,
    "length": 64,
    "time": 36582.283913,
    "actor_loss": -51.60253143310547,
    "critic_loss": 115.48062133789062,
    "ent_coef": 0.1407044380903244,
    "learning_rate": 0.001
  },
  {
    "episode": 2085,
    "reward": 87.835881,
    "length": 68,
    "time": 36594.118087,
    "actor_loss": -47.3030891418457,
    "critic_loss": 55.077369689941406,
    "ent_coef": 0.14031744003295898,
    "learning_rate": 0.001
  },
  {
    "episode": 2086,
    "reward": 83.186167,
    "length": 75,
    "time": 36608.71356,
    "actor_loss": -47.25300598144531,
    "critic_loss": 57.92547607421875,
    "ent_coef": 0.13508541882038116,
    "learning_rate": 0.001
  },
  {
    "episode": 2087,
    "reward": 84.596565,
    "length": 73,
    "time": 36622.263463,
    "actor_loss": -49.314697265625,
    "critic_loss": 46.503578186035156,
    "ent_coef": 0.12467709183692932,
    "learning_rate": 0.001
  },
  {
    "episode": 2088,
    "reward": 88.983834,
    "length": 66,
    "time": 36635.416208,
    "actor_loss": -58.48493957519531,
    "critic_loss": 132.930419921875,
    "ent_coef": 0.12409056723117828,
    "learning_rate": 0.001
  },
  {
    "episode": 2089,
    "reward": 83.522681,
    "length": 74,
    "time": 36650.635885,
    "actor_loss": -50.08084487915039,
    "critic_loss": 42.10485076904297,
    "ent_coef": 0.12426633387804031,
    "learning_rate": 0.001
  },
  {
    "episode": 2090,
    "reward": 89.08291,
    "length": 65,
    "time": 36664.34852,
    "actor_loss": -56.72775650024414,
    "critic_loss": 12.714157104492188,
    "ent_coef": 0.12607453763484955,
    "learning_rate": 0.001
  },
  {
    "episode": 2091,
    "reward": 88.251251,
    "length": 67,
    "time": 36676.695311,
    "actor_loss": -51.064598083496094,
    "critic_loss": 3.938634157180786,
    "ent_coef": 0.12685826420783997,
    "learning_rate": 0.001
  },
  {
    "episode": 2092,
    "reward": 86.626715,
    "length": 69,
    "time": 36688.877002,
    "actor_loss": -57.35132598876953,
    "critic_loss": 39.62908172607422,
    "ent_coef": 0.12658944725990295,
    "learning_rate": 0.001
  },
  {
    "episode": 2093,
    "reward": 89.368935,
    "length": 64,
    "time": 36703.303848,
    "actor_loss": -52.19978332519531,
    "critic_loss": 7.227290630340576,
    "ent_coef": 0.1258806586265564,
    "learning_rate": 0.001
  },
  {
    "episode": 2094,
    "reward": 87.688364,
    "length": 67,
    "time": 36715.337326,
    "actor_loss": -55.71040344238281,
    "critic_loss": 10.662863731384277,
    "ent_coef": 0.12720279395580292,
    "learning_rate": 0.001
  },
  {
    "episode": 2095,
    "reward": 75.68204,
    "length": 86,
    "time": 36729.299572,
    "actor_loss": -52.99187469482422,
    "critic_loss": 50.27149200439453,
    "ent_coef": 0.12618395686149597,
    "learning_rate": 0.001
  },
  {
    "episode": 2096,
    "reward": 73.406293,
    "length": 88,
    "time": 36746.723382,
    "actor_loss": -52.9495849609375,
    "critic_loss": 129.99330139160156,
    "ent_coef": 0.128677099943161,
    "learning_rate": 0.001
  },
  {
    "episode": 2097,
    "reward": 85.883045,
    "length": 71,
    "time": 36761.104153,
    "actor_loss": -48.39825439453125,
    "critic_loss": 13.507827758789062,
    "ent_coef": 0.13289010524749756,
    "learning_rate": 0.001
  },
  {
    "episode": 2098,
    "reward": 86.440075,
    "length": 70,
    "time": 36774.297622,
    "actor_loss": -46.27192687988281,
    "critic_loss": 10.191875457763672,
    "ent_coef": 0.13536687195301056,
    "learning_rate": 0.001
  },
  {
    "episode": 2099,
    "reward": 89.231837,
    "length": 65,
    "time": 36786.790383,
    "actor_loss": -52.18675231933594,
    "critic_loss": 9.903440475463867,
    "ent_coef": 0.1330869197845459,
    "learning_rate": 0.001
  },
  {
    "episode": 2100,
    "reward": 89.854401,
    "length": 64,
    "time": 36799.097449,
    "actor_loss": -50.13911056518555,
    "critic_loss": 163.10513305664062,
    "ent_coef": 0.1334071308374405,
    "learning_rate": 0.001
  },
  {
    "episode": 2101,
    "reward": 87.450617,
    "length": 68,
    "time": 36812.979607,
    "actor_loss": -54.618370056152344,
    "critic_loss": 19.293197631835938,
    "ent_coef": 0.13315732777118683,
    "learning_rate": 0.001
  },
  {
    "episode": 2102,
    "reward": 77.679644,
    "length": 82,
    "time": 36828.80869,
    "actor_loss": -52.51601028442383,
    "critic_loss": 81.09036254882812,
    "ent_coef": 0.13616517186164856,
    "learning_rate": 0.001
  },
  {
    "episode": 2103,
    "reward": 87.171055,
    "length": 70,
    "time": 36844.492747,
    "actor_loss": -54.4124755859375,
    "critic_loss": 15.863259315490723,
    "ent_coef": 0.1369241625070572,
    "learning_rate": 0.001
  },
  {
    "episode": 2104,
    "reward": 83.476351,
    "length": 75,
    "time": 36858.317297,
    "actor_loss": -48.313758850097656,
    "critic_loss": 24.360218048095703,
    "ent_coef": 0.13575655221939087,
    "learning_rate": 0.001
  },
  {
    "episode": 2105,
    "reward": 76.658663,
    "length": 101,
    "time": 36874.282056,
    "actor_loss": -47.6817512512207,
    "critic_loss": 58.83307647705078,
    "ent_coef": 0.13545756042003632,
    "learning_rate": 0.001
  },
  {
    "episode": 2106,
    "reward": 74.555658,
    "length": 88,
    "time": 36889.240768,
    "actor_loss": -56.43779754638672,
    "critic_loss": 18.60366439819336,
    "ent_coef": 0.1334124058485031,
    "learning_rate": 0.001
  },
  {
    "episode": 2107,
    "reward": 82.250433,
    "length": 76,
    "time": 36904.000899,
    "actor_loss": -43.965293884277344,
    "critic_loss": 25.90227699279785,
    "ent_coef": 0.13565784692764282,
    "learning_rate": 0.001
  },
  {
    "episode": 2108,
    "reward": 72.820562,
    "length": 89,
    "time": 36918.929622,
    "actor_loss": -45.02070999145508,
    "critic_loss": 13.347599029541016,
    "ent_coef": 0.13419225811958313,
    "learning_rate": 0.001
  },
  {
    "episode": 2109,
    "reward": 81.356552,
    "length": 78,
    "time": 36933.01081,
    "actor_loss": -49.09659194946289,
    "critic_loss": 18.222824096679688,
    "ent_coef": 0.12998439371585846,
    "learning_rate": 0.001
  },
  {
    "episode": 2110,
    "reward": 85.829876,
    "length": 70,
    "time": 36945.570475,
    "actor_loss": -50.3157844543457,
    "critic_loss": 55.97156524658203,
    "ent_coef": 0.13243262469768524,
    "learning_rate": 0.001
  },
  {
    "episode": 2111,
    "reward": 82.61042,
    "length": 74,
    "time": 36959.588671,
    "actor_loss": -52.80704116821289,
    "critic_loss": 22.45049285888672,
    "ent_coef": 0.1322188377380371,
    "learning_rate": 0.001
  },
  {
    "episode": 2112,
    "reward": 86.49119,
    "length": 70,
    "time": 36972.00343,
    "actor_loss": -55.25092315673828,
    "critic_loss": 5.8594970703125,
    "ent_coef": 0.13220664858818054,
    "learning_rate": 0.001
  },
  {
    "episode": 2113,
    "reward": 88.479714,
    "length": 66,
    "time": 36985.631649,
    "actor_loss": -51.023460388183594,
    "critic_loss": 47.33769989013672,
    "ent_coef": 0.132200688123703,
    "learning_rate": 0.001
  },
  {
    "episode": 2114,
    "reward": 87.570071,
    "length": 66,
    "time": 36997.54947,
    "actor_loss": -45.9013557434082,
    "critic_loss": 90.45993041992188,
    "ent_coef": 0.12870974838733673,
    "learning_rate": 0.001
  },
  {
    "episode": 2115,
    "reward": 87.693092,
    "length": 67,
    "time": 37009.296793,
    "actor_loss": -48.34056854248047,
    "critic_loss": 16.544343948364258,
    "ent_coef": 0.12150292098522186,
    "learning_rate": 0.001
  },
  {
    "episode": 2116,
    "reward": 85.986389,
    "length": 71,
    "time": 37025.140864,
    "actor_loss": -48.95519256591797,
    "critic_loss": 34.085384368896484,
    "ent_coef": 0.1214548721909523,
    "learning_rate": 0.001
  },
  {
    "episode": 2117,
    "reward": 81.88235,
    "length": 77,
    "time": 37039.335312,
    "actor_loss": -54.79138946533203,
    "critic_loss": 10.847421646118164,
    "ent_coef": 0.12361647933721542,
    "learning_rate": 0.001
  },
  {
    "episode": 2118,
    "reward": 89.003855,
    "length": 64,
    "time": 37052.680869,
    "actor_loss": -51.272216796875,
    "critic_loss": 5.290294647216797,
    "ent_coef": 0.12169145792722702,
    "learning_rate": 0.001
  },
  {
    "episode": 2119,
    "reward": 82.134177,
    "length": 77,
    "time": 37065.684179,
    "actor_loss": -52.44865036010742,
    "critic_loss": 164.92723083496094,
    "ent_coef": 0.11904201656579971,
    "learning_rate": 0.001
  },
  {
    "episode": 2120,
    "reward": 87.87628,
    "length": 68,
    "time": 37078.891263,
    "actor_loss": -50.8135986328125,
    "critic_loss": 12.223822593688965,
    "ent_coef": 0.11978238821029663,
    "learning_rate": 0.001
  },
  {
    "episode": 2121,
    "reward": 89.270739,
    "length": 63,
    "time": 37090.274368,
    "actor_loss": -50.75116729736328,
    "critic_loss": 15.051965713500977,
    "ent_coef": 0.12150358408689499,
    "learning_rate": 0.001
  },
  {
    "episode": 2122,
    "reward": 80.739953,
    "length": 79,
    "time": 37104.241699,
    "actor_loss": -47.13007354736328,
    "critic_loss": 43.833251953125,
    "ent_coef": 0.11760780215263367,
    "learning_rate": 0.001
  },
  {
    "episode": 2123,
    "reward": 83.207447,
    "length": 73,
    "time": 37117.561981,
    "actor_loss": -49.91339111328125,
    "critic_loss": 6.150909423828125,
    "ent_coef": 0.11252116411924362,
    "learning_rate": 0.001
  },
  {
    "episode": 2124,
    "reward": 87.730995,
    "length": 69,
    "time": 37129.524927,
    "actor_loss": -48.739131927490234,
    "critic_loss": 18.05957794189453,
    "ent_coef": 0.11255411058664322,
    "learning_rate": 0.001
  },
  {
    "episode": 2125,
    "reward": 91.109022,
    "length": 62,
    "time": 37141.019819,
    "actor_loss": -55.27756881713867,
    "critic_loss": 9.471162796020508,
    "ent_coef": 0.11455779522657394,
    "learning_rate": 0.001
  },
  {
    "episode": 2126,
    "reward": 84.561037,
    "length": 73,
    "time": 37154.718467,
    "actor_loss": -51.01506423950195,
    "critic_loss": 18.496658325195312,
    "ent_coef": 0.11179724335670471,
    "learning_rate": 0.001
  },
  {
    "episode": 2127,
    "reward": 76.61202,
    "length": 84,
    "time": 37169.349949,
    "actor_loss": -49.076988220214844,
    "critic_loss": 15.814251899719238,
    "ent_coef": 0.10668514668941498,
    "learning_rate": 0.001
  },
  {
    "episode": 2128,
    "reward": 87.751372,
    "length": 70,
    "time": 37181.519647,
    "actor_loss": -52.04344940185547,
    "critic_loss": 72.34700012207031,
    "ent_coef": 0.10440226644277573,
    "learning_rate": 0.001
  },
  {
    "episode": 2129,
    "reward": 60.372061,
    "length": 107,
    "time": 37199.541776,
    "actor_loss": -52.41407012939453,
    "critic_loss": 227.74951171875,
    "ent_coef": 0.10473914444446564,
    "learning_rate": 0.001
  },
  {
    "episode": 2130,
    "reward": 86.01802,
    "length": 68,
    "time": 37211.998448,
    "actor_loss": -45.476905822753906,
    "critic_loss": 81.55734252929688,
    "ent_coef": 0.11115959286689758,
    "learning_rate": 0.001
  },
  {
    "episode": 2131,
    "reward": 89.54509,
    "length": 63,
    "time": 37224.426349,
    "actor_loss": -50.99267578125,
    "critic_loss": 6.678461074829102,
    "ent_coef": 0.11093555390834808,
    "learning_rate": 0.001
  },
  {
    "episode": 2132,
    "reward": 78.021213,
    "length": 81,
    "time": 37239.228375,
    "actor_loss": -48.01959228515625,
    "critic_loss": 27.72089385986328,
    "ent_coef": 0.10861223936080933,
    "learning_rate": 0.001
  },
  {
    "episode": 2133,
    "reward": 71.628832,
    "length": 96,
    "time": 37255.817127,
    "actor_loss": -49.668739318847656,
    "critic_loss": 14.036959648132324,
    "ent_coef": 0.10920844972133636,
    "learning_rate": 0.001
  },
  {
    "episode": 2134,
    "reward": 82.324947,
    "length": 77,
    "time": 37269.002084,
    "actor_loss": -51.696495056152344,
    "critic_loss": 21.727602005004883,
    "ent_coef": 0.10898078233003616,
    "learning_rate": 0.001
  },
  {
    "episode": 2135,
    "reward": 85.691975,
    "length": 71,
    "time": 37281.599857,
    "actor_loss": -45.43648147583008,
    "critic_loss": 684.833984375,
    "ent_coef": 0.1072673574090004,
    "learning_rate": 0.001
  },
  {
    "episode": 2136,
    "reward": 76.912053,
    "length": 85,
    "time": 37299.920085,
    "actor_loss": -52.635215759277344,
    "critic_loss": 29.630752563476562,
    "ent_coef": 0.10377057641744614,
    "learning_rate": 0.001
  },
  {
    "episode": 2137,
    "reward": 83.386652,
    "length": 74,
    "time": 37314.415938,
    "actor_loss": -49.420654296875,
    "critic_loss": 20.74634552001953,
    "ent_coef": 0.10316789895296097,
    "learning_rate": 0.001
  },
  {
    "episode": 2138,
    "reward": 88.276603,
    "length": 71,
    "time": 37327.878889,
    "actor_loss": -52.16829299926758,
    "critic_loss": 34.470237731933594,
    "ent_coef": 0.10336703062057495,
    "learning_rate": 0.001
  },
  {
    "episode": 2139,
    "reward": 65.271243,
    "length": 99,
    "time": 37343.92803,
    "actor_loss": -54.83238983154297,
    "critic_loss": 15.856988906860352,
    "ent_coef": 0.10090300440788269,
    "learning_rate": 0.001
  },
  {
    "episode": 2140,
    "reward": 84.27339,
    "length": 73,
    "time": 37356.636888,
    "actor_loss": -48.94182586669922,
    "critic_loss": 42.05860137939453,
    "ent_coef": 0.10333829373121262,
    "learning_rate": 0.001
  },
  {
    "episode": 2141,
    "reward": 81.9942,
    "length": 76,
    "time": 37370.67671,
    "actor_loss": -54.1517448425293,
    "critic_loss": 32.460079193115234,
    "ent_coef": 0.10494273900985718,
    "learning_rate": 0.001
  },
  {
    "episode": 2142,
    "reward": 83.915471,
    "length": 74,
    "time": 37385.251744,
    "actor_loss": -49.55305862426758,
    "critic_loss": 30.33348846435547,
    "ent_coef": 0.10638793557882309,
    "learning_rate": 0.001
  },
  {
    "episode": 2143,
    "reward": 86.985324,
    "length": 68,
    "time": 37397.957208,
    "actor_loss": -47.464141845703125,
    "critic_loss": 116.94901275634766,
    "ent_coef": 0.10904008895158768,
    "learning_rate": 0.001
  },
  {
    "episode": 2144,
    "reward": 75.884598,
    "length": 87,
    "time": 37412.426056,
    "actor_loss": -54.165733337402344,
    "critic_loss": 131.58714294433594,
    "ent_coef": 0.10934236645698547,
    "learning_rate": 0.001
  },
  {
    "episode": 2145,
    "reward": 86.940296,
    "length": 69,
    "time": 37425.322872,
    "actor_loss": -52.98773956298828,
    "critic_loss": 160.61264038085938,
    "ent_coef": 0.10916770994663239,
    "learning_rate": 0.001
  },
  {
    "episode": 2146,
    "reward": 90.367834,
    "length": 63,
    "time": 37436.608154,
    "actor_loss": -48.900108337402344,
    "critic_loss": 11.8275146484375,
    "ent_coef": 0.10891322046518326,
    "learning_rate": 0.001
  },
  {
    "episode": 2147,
    "reward": 86.817265,
    "length": 68,
    "time": 37450.210812,
    "actor_loss": -51.871551513671875,
    "critic_loss": 30.36283302307129,
    "ent_coef": 0.111975759267807,
    "learning_rate": 0.001
  },
  {
    "episode": 2148,
    "reward": 59.338631,
    "length": 107,
    "time": 37467.944453,
    "actor_loss": -49.8095703125,
    "critic_loss": 83.90575408935547,
    "ent_coef": 0.1073780432343483,
    "learning_rate": 0.001
  },
  {
    "episode": 2149,
    "reward": 82.759033,
    "length": 75,
    "time": 37480.619375,
    "actor_loss": -52.77696228027344,
    "critic_loss": 14.838650703430176,
    "ent_coef": 0.10663934797048569,
    "learning_rate": 0.001
  },
  {
    "episode": 2150,
    "reward": 71.010511,
    "length": 88,
    "time": 37498.456477,
    "actor_loss": -45.157928466796875,
    "critic_loss": 14.465150833129883,
    "ent_coef": 0.10713013261556625,
    "learning_rate": 0.001
  },
  {
    "episode": 2151,
    "reward": 86.871392,
    "length": 68,
    "time": 37512.021144,
    "actor_loss": -46.16998291015625,
    "critic_loss": 13.378880500793457,
    "ent_coef": 0.11111309379339218,
    "learning_rate": 0.001
  },
  {
    "episode": 2152,
    "reward": 87.171057,
    "length": 67,
    "time": 37525.826907,
    "actor_loss": -51.172157287597656,
    "critic_loss": 3.9472591876983643,
    "ent_coef": 0.11684264242649078,
    "learning_rate": 0.001
  },
  {
    "episode": 2153,
    "reward": 90.625567,
    "length": 63,
    "time": 37537.033298,
    "actor_loss": -55.55634307861328,
    "critic_loss": 73.55204772949219,
    "ent_coef": 0.11891663819551468,
    "learning_rate": 0.001
  },
  {
    "episode": 2154,
    "reward": -306.313138,
    "length": 245,
    "time": 37575.695325,
    "actor_loss": -48.12812042236328,
    "critic_loss": 10.314041137695312,
    "ent_coef": 0.1169520914554596,
    "learning_rate": 0.001
  },
  {
    "episode": 2155,
    "reward": 98.652683,
    "length": 71,
    "time": 37590.295773,
    "actor_loss": -48.445133209228516,
    "critic_loss": 53.07618713378906,
    "ent_coef": 0.11500528454780579,
    "learning_rate": 0.001
  },
  {
    "episode": 2156,
    "reward": 77.433503,
    "length": 83,
    "time": 37604.175684,
    "actor_loss": -51.66517639160156,
    "critic_loss": 4.180336952209473,
    "ent_coef": 0.1107318252325058,
    "learning_rate": 0.001
  },
  {
    "episode": 2157,
    "reward": 89.274699,
    "length": 64,
    "time": 37618.337689,
    "actor_loss": -48.674800872802734,
    "critic_loss": 10.964823722839355,
    "ent_coef": 0.10733054578304291,
    "learning_rate": 0.001
  },
  {
    "episode": 2158,
    "reward": 87.497377,
    "length": 68,
    "time": 37630.113592,
    "actor_loss": -48.71654510498047,
    "critic_loss": 3.946720600128174,
    "ent_coef": 0.11400599777698517,
    "learning_rate": 0.001
  },
  {
    "episode": 2159,
    "reward": 81.578434,
    "length": 77,
    "time": 37645.318386,
    "actor_loss": -49.0009651184082,
    "critic_loss": 18.926959991455078,
    "ent_coef": 0.11371634155511856,
    "learning_rate": 0.001
  },
  {
    "episode": 2160,
    "reward": 81.038586,
    "length": 78,
    "time": 37661.286353,
    "actor_loss": -43.528629302978516,
    "critic_loss": 27.984954833984375,
    "ent_coef": 0.1075882539153099,
    "learning_rate": 0.001
  },
  {
    "episode": 2161,
    "reward": 70.912799,
    "length": 92,
    "time": 37676.175098,
    "actor_loss": -53.96125793457031,
    "critic_loss": 6.988729000091553,
    "ent_coef": 0.10034074634313583,
    "learning_rate": 0.001
  },
  {
    "episode": 2162,
    "reward": 89.519537,
    "length": 64,
    "time": 37690.259251,
    "actor_loss": -51.598854064941406,
    "critic_loss": 36.23094940185547,
    "ent_coef": 0.10040713101625443,
    "learning_rate": 0.001
  },
  {
    "episode": 2163,
    "reward": 82.139985,
    "length": 74,
    "time": 37703.670622,
    "actor_loss": -46.181949615478516,
    "critic_loss": 66.22807312011719,
    "ent_coef": 0.10114249587059021,
    "learning_rate": 0.001
  },
  {
    "episode": 2164,
    "reward": 84.774349,
    "length": 71,
    "time": 37718.314236,
    "actor_loss": -54.11621856689453,
    "critic_loss": 10.749195098876953,
    "ent_coef": 0.10154104232788086,
    "learning_rate": 0.001
  },
  {
    "episode": 2165,
    "reward": 87.444867,
    "length": 67,
    "time": 37730.75075,
    "actor_loss": -46.28965759277344,
    "critic_loss": 17.139394760131836,
    "ent_coef": 0.10462871193885803,
    "learning_rate": 0.001
  },
  {
    "episode": 2166,
    "reward": 91.098494,
    "length": 62,
    "time": 37741.880733,
    "actor_loss": -48.196624755859375,
    "critic_loss": 60.84922790527344,
    "ent_coef": 0.10685096681118011,
    "learning_rate": 0.001
  },
  {
    "episode": 2167,
    "reward": 82.578507,
    "length": 75,
    "time": 37755.61957,
    "actor_loss": -45.70348358154297,
    "critic_loss": 175.47036743164062,
    "ent_coef": 0.10811059921979904,
    "learning_rate": 0.001
  },
  {
    "episode": 2168,
    "reward": 89.917185,
    "length": 63,
    "time": 37766.899538,
    "actor_loss": -48.713783264160156,
    "critic_loss": 5.1726508140563965,
    "ent_coef": 0.1092883050441742,
    "learning_rate": 0.001
  },
  {
    "episode": 2169,
    "reward": 83.783573,
    "length": 73,
    "time": 37779.875495,
    "actor_loss": -55.67340087890625,
    "critic_loss": 46.94029998779297,
    "ent_coef": 0.10774186253547668,
    "learning_rate": 0.001
  },
  {
    "episode": 2170,
    "reward": 88.016086,
    "length": 66,
    "time": 37791.448453,
    "actor_loss": -56.00929260253906,
    "critic_loss": 10.239339828491211,
    "ent_coef": 0.10783311724662781,
    "learning_rate": 0.001
  },
  {
    "episode": 2171,
    "reward": 85.730783,
    "length": 69,
    "time": 37804.496667,
    "actor_loss": -47.11392593383789,
    "critic_loss": 6.65904426574707,
    "ent_coef": 0.10720067471265793,
    "learning_rate": 0.001
  },
  {
    "episode": 2172,
    "reward": 90.121994,
    "length": 62,
    "time": 37815.966168,
    "actor_loss": -49.128257751464844,
    "critic_loss": 6.321491718292236,
    "ent_coef": 0.11267802119255066,
    "learning_rate": 0.001
  },
  {
    "episode": 2173,
    "reward": 85.251171,
    "length": 70,
    "time": 37828.924586,
    "actor_loss": -58.02954864501953,
    "critic_loss": 8.534324645996094,
    "ent_coef": 0.11818086355924606,
    "learning_rate": 0.001
  },
  {
    "episode": 2174,
    "reward": 85.707173,
    "length": 69,
    "time": 37841.905432,
    "actor_loss": -49.08544921875,
    "critic_loss": 9.39021110534668,
    "ent_coef": 0.12038203328847885,
    "learning_rate": 0.001
  },
  {
    "episode": 2175,
    "reward": 88.45828,
    "length": 66,
    "time": 37853.795465,
    "actor_loss": -52.74420928955078,
    "critic_loss": 5.673569679260254,
    "ent_coef": 0.12048238515853882,
    "learning_rate": 0.001
  },
  {
    "episode": 2176,
    "reward": 89.216591,
    "length": 64,
    "time": 37867.267649,
    "actor_loss": -54.647281646728516,
    "critic_loss": 5.257261753082275,
    "ent_coef": 0.1240493580698967,
    "learning_rate": 0.001
  },
  {
    "episode": 2177,
    "reward": 83.216609,
    "length": 78,
    "time": 37884.16517,
    "actor_loss": -53.72236633300781,
    "critic_loss": 12.339616775512695,
    "ent_coef": 0.12061787396669388,
    "learning_rate": 0.001
  },
  {
    "episode": 2178,
    "reward": 82.96589,
    "length": 75,
    "time": 37898.793142,
    "actor_loss": -52.00559997558594,
    "critic_loss": 10.096837997436523,
    "ent_coef": 0.1201075091958046,
    "learning_rate": 0.001
  },
  {
    "episode": 2179,
    "reward": 89.101807,
    "length": 64,
    "time": 37910.506175,
    "actor_loss": -45.267601013183594,
    "critic_loss": 7.280577659606934,
    "ent_coef": 0.12259098887443542,
    "learning_rate": 0.001
  },
  {
    "episode": 2180,
    "reward": 90.082193,
    "length": 64,
    "time": 37921.873982,
    "actor_loss": -51.34205627441406,
    "critic_loss": 7.998141765594482,
    "ent_coef": 0.1231459379196167,
    "learning_rate": 0.001
  },
  {
    "episode": 2181,
    "reward": 90.403584,
    "length": 63,
    "time": 37936.214407,
    "actor_loss": -58.65093231201172,
    "critic_loss": 65.92318725585938,
    "ent_coef": 0.12391887605190277,
    "learning_rate": 0.001
  },
  {
    "episode": 2182,
    "reward": 89.531272,
    "length": 65,
    "time": 37949.559142,
    "actor_loss": -50.69811248779297,
    "critic_loss": 6.948643684387207,
    "ent_coef": 0.12439422309398651,
    "learning_rate": 0.001
  },
  {
    "episode": 2183,
    "reward": 74.016754,
    "length": 92,
    "time": 37966.382569,
    "actor_loss": -53.196495056152344,
    "critic_loss": 16.670459747314453,
    "ent_coef": 0.11826758831739426,
    "learning_rate": 0.001
  },
  {
    "episode": 2184,
    "reward": 89.894214,
    "length": 64,
    "time": 37977.680781,
    "actor_loss": -55.520450592041016,
    "critic_loss": 27.033985137939453,
    "ent_coef": 0.11695028841495514,
    "learning_rate": 0.001
  },
  {
    "episode": 2185,
    "reward": 83.425037,
    "length": 74,
    "time": 37990.614443,
    "actor_loss": -47.97077941894531,
    "critic_loss": 87.54090881347656,
    "ent_coef": 0.11431518942117691,
    "learning_rate": 0.001
  },
  {
    "episode": 2186,
    "reward": 85.545975,
    "length": 72,
    "time": 38004.597499,
    "actor_loss": -55.20930862426758,
    "critic_loss": 12.82979965209961,
    "ent_coef": 0.10935626178979874,
    "learning_rate": 0.001
  },
  {
    "episode": 2187,
    "reward": 81.337841,
    "length": 77,
    "time": 38017.726014,
    "actor_loss": -51.6041145324707,
    "critic_loss": 19.923837661743164,
    "ent_coef": 0.1108718290925026,
    "learning_rate": 0.001
  },
  {
    "episode": 2188,
    "reward": 75.243048,
    "length": 84,
    "time": 38033.148088,
    "actor_loss": -55.35206604003906,
    "critic_loss": 12.596333503723145,
    "ent_coef": 0.11002165824174881,
    "learning_rate": 0.001
  },
  {
    "episode": 2189,
    "reward": 90.920739,
    "length": 61,
    "time": 38047.133912,
    "actor_loss": -54.521297454833984,
    "critic_loss": 30.73545265197754,
    "ent_coef": 0.11305982619524002,
    "learning_rate": 0.001
  },
  {
    "episode": 2190,
    "reward": 89.252726,
    "length": 65,
    "time": 38060.633781,
    "actor_loss": -47.829002380371094,
    "critic_loss": 15.168183326721191,
    "ent_coef": 0.11408010870218277,
    "learning_rate": 0.001
  },
  {
    "episode": 2191,
    "reward": 87.036396,
    "length": 69,
    "time": 38073.562022,
    "actor_loss": -48.420631408691406,
    "critic_loss": 8.434330940246582,
    "ent_coef": 0.1117277443408966,
    "learning_rate": 0.001
  },
  {
    "episode": 2192,
    "reward": 88.604851,
    "length": 65,
    "time": 38086.123535,
    "actor_loss": -47.22418975830078,
    "critic_loss": 377.82257080078125,
    "ent_coef": 0.10815664380788803,
    "learning_rate": 0.001
  },
  {
    "episode": 2193,
    "reward": 78.644316,
    "length": 81,
    "time": 38100.853961,
    "actor_loss": -52.7462158203125,
    "critic_loss": 11.331663131713867,
    "ent_coef": 0.10357768088579178,
    "learning_rate": 0.001
  },
  {
    "episode": 2194,
    "reward": 81.827196,
    "length": 77,
    "time": 38116.794623,
    "actor_loss": -54.62708282470703,
    "critic_loss": 8.810867309570312,
    "ent_coef": 0.09950965642929077,
    "learning_rate": 0.001
  },
  {
    "episode": 2195,
    "reward": 88.230248,
    "length": 65,
    "time": 38128.631118,
    "actor_loss": -51.25225067138672,
    "critic_loss": 4.74397087097168,
    "ent_coef": 0.10200611501932144,
    "learning_rate": 0.001
  },
  {
    "episode": 2196,
    "reward": 86.018185,
    "length": 69,
    "time": 38140.584107,
    "actor_loss": -52.15778350830078,
    "critic_loss": 5.727231979370117,
    "ent_coef": 0.10737617313861847,
    "learning_rate": 0.001
  },
  {
    "episode": 2197,
    "reward": 87.712979,
    "length": 67,
    "time": 38153.178805,
    "actor_loss": -51.01304626464844,
    "critic_loss": 49.351783752441406,
    "ent_coef": 0.10946068167686462,
    "learning_rate": 0.001
  },
  {
    "episode": 2198,
    "reward": 84.920738,
    "length": 71,
    "time": 38165.83418,
    "actor_loss": -49.030662536621094,
    "critic_loss": 5.493504524230957,
    "ent_coef": 0.10797852277755737,
    "learning_rate": 0.001
  },
  {
    "episode": 2199,
    "reward": 88.576927,
    "length": 69,
    "time": 38179.893427,
    "actor_loss": -51.36796951293945,
    "critic_loss": 9.611443519592285,
    "ent_coef": 0.10645091533660889,
    "learning_rate": 0.001
  },
  {
    "episode": 2200,
    "reward": 86.594006,
    "length": 73,
    "time": 38195.365002,
    "actor_loss": -59.323421478271484,
    "critic_loss": 12.918811798095703,
    "ent_coef": 0.10216687619686127,
    "learning_rate": 0.001
  },
  {
    "episode": 2201,
    "reward": 86.893322,
    "length": 69,
    "time": 38208.223552,
    "actor_loss": -49.80128479003906,
    "critic_loss": 11.78459644317627,
    "ent_coef": 0.09997444599866867,
    "learning_rate": 0.001
  },
  {
    "episode": 2202,
    "reward": 88.306684,
    "length": 65,
    "time": 38221.453916,
    "actor_loss": -52.96825408935547,
    "critic_loss": 13.12706470489502,
    "ent_coef": 0.105280302464962,
    "learning_rate": 0.001
  },
  {
    "episode": 2203,
    "reward": 83.803736,
    "length": 72,
    "time": 38233.97067,
    "actor_loss": -51.28395080566406,
    "critic_loss": 52.001129150390625,
    "ent_coef": 0.10535508394241333,
    "learning_rate": 0.001
  },
  {
    "episode": 2204,
    "reward": 89.090152,
    "length": 65,
    "time": 38246.598369,
    "actor_loss": -53.78065490722656,
    "critic_loss": 7.340287208557129,
    "ent_coef": 0.10704539716243744,
    "learning_rate": 0.001
  },
  {
    "episode": 2205,
    "reward": 85.318979,
    "length": 74,
    "time": 38261.701288,
    "actor_loss": -51.2813606262207,
    "critic_loss": 116.7464599609375,
    "ent_coef": 0.10342042148113251,
    "learning_rate": 0.001
  },
  {
    "episode": 2206,
    "reward": 88.469687,
    "length": 65,
    "time": 38273.036859,
    "actor_loss": -57.41746520996094,
    "critic_loss": 7.971904277801514,
    "ent_coef": 0.10154765099287033,
    "learning_rate": 0.001
  },
  {
    "episode": 2207,
    "reward": 91.222943,
    "length": 62,
    "time": 38285.898402,
    "actor_loss": -46.81838607788086,
    "critic_loss": 26.65179443359375,
    "ent_coef": 0.10299339890480042,
    "learning_rate": 0.001
  },
  {
    "episode": 2208,
    "reward": 85.346729,
    "length": 71,
    "time": 38298.080328,
    "actor_loss": -53.79407501220703,
    "critic_loss": 110.3370361328125,
    "ent_coef": 0.10276437550783157,
    "learning_rate": 0.001
  },
  {
    "episode": 2209,
    "reward": 84.922906,
    "length": 73,
    "time": 38310.741891,
    "actor_loss": -55.06329345703125,
    "critic_loss": 17.47951889038086,
    "ent_coef": 0.09900832921266556,
    "learning_rate": 0.001
  },
  {
    "episode": 2210,
    "reward": 86.58902,
    "length": 70,
    "time": 38324.086683,
    "actor_loss": -56.62178421020508,
    "critic_loss": 7.0269775390625,
    "ent_coef": 0.10124645382165909,
    "learning_rate": 0.001
  },
  {
    "episode": 2211,
    "reward": 89.162557,
    "length": 65,
    "time": 38335.584269,
    "actor_loss": -49.499637603759766,
    "critic_loss": 5.867505073547363,
    "ent_coef": 0.10446912050247192,
    "learning_rate": 0.001
  },
  {
    "episode": 2212,
    "reward": 75.359153,
    "length": 86,
    "time": 38349.8135,
    "actor_loss": -52.35124969482422,
    "critic_loss": 141.56723022460938,
    "ent_coef": 0.09901130944490433,
    "learning_rate": 0.001
  },
  {
    "episode": 2213,
    "reward": 81.597109,
    "length": 75,
    "time": 38363.875471,
    "actor_loss": -50.60055160522461,
    "critic_loss": 109.7645263671875,
    "ent_coef": 0.10259363055229187,
    "learning_rate": 0.001
  },
  {
    "episode": 2214,
    "reward": 88.135235,
    "length": 66,
    "time": 38376.819257,
    "actor_loss": -51.1972770690918,
    "critic_loss": 7.408852577209473,
    "ent_coef": 0.10758515447378159,
    "learning_rate": 0.001
  },
  {
    "episode": 2215,
    "reward": 86.4343,
    "length": 69,
    "time": 38391.102088,
    "actor_loss": -54.71710205078125,
    "critic_loss": 8.350804328918457,
    "ent_coef": 0.10923875868320465,
    "learning_rate": 0.001
  },
  {
    "episode": 2216,
    "reward": 88.464142,
    "length": 69,
    "time": 38403.104811,
    "actor_loss": -51.51554870605469,
    "critic_loss": 7.212374687194824,
    "ent_coef": 0.11420737206935883,
    "learning_rate": 0.001
  },
  {
    "episode": 2217,
    "reward": 87.404494,
    "length": 67,
    "time": 38416.501229,
    "actor_loss": -53.875816345214844,
    "critic_loss": 11.703178405761719,
    "ent_coef": 0.11501672118902206,
    "learning_rate": 0.001
  },
  {
    "episode": 2218,
    "reward": 88.56749,
    "length": 70,
    "time": 38431.250788,
    "actor_loss": -53.23059844970703,
    "critic_loss": 9.789603233337402,
    "ent_coef": 0.11671360582113266,
    "learning_rate": 0.001
  },
  {
    "episode": 2219,
    "reward": 81.738339,
    "length": 78,
    "time": 38446.482078,
    "actor_loss": -54.49688720703125,
    "critic_loss": 10.900449752807617,
    "ent_coef": 0.11543644219636917,
    "learning_rate": 0.001
  },
  {
    "episode": 2220,
    "reward": 85.709105,
    "length": 69,
    "time": 38458.633326,
    "actor_loss": -50.402366638183594,
    "critic_loss": 12.77781867980957,
    "ent_coef": 0.11594871431589127,
    "learning_rate": 0.001
  },
  {
    "episode": 2221,
    "reward": 90.21209,
    "length": 63,
    "time": 38472.267618,
    "actor_loss": -54.17701721191406,
    "critic_loss": 9.344202041625977,
    "ent_coef": 0.11575443297624588,
    "learning_rate": 0.001
  },
  {
    "episode": 2222,
    "reward": 85.032793,
    "length": 72,
    "time": 38486.169457,
    "actor_loss": -51.90723419189453,
    "critic_loss": 455.82275390625,
    "ent_coef": 0.11247400939464569,
    "learning_rate": 0.001
  },
  {
    "episode": 2223,
    "reward": 86.441291,
    "length": 69,
    "time": 38499.46832,
    "actor_loss": -48.928627014160156,
    "critic_loss": 135.17892456054688,
    "ent_coef": 0.1072733923792839,
    "learning_rate": 0.001
  },
  {
    "episode": 2224,
    "reward": 89.567718,
    "length": 66,
    "time": 38513.93206,
    "actor_loss": -50.643531799316406,
    "critic_loss": 24.183944702148438,
    "ent_coef": 0.10591965168714523,
    "learning_rate": 0.001
  },
  {
    "episode": 2225,
    "reward": 90.854296,
    "length": 61,
    "time": 38526.825711,
    "actor_loss": -48.7518424987793,
    "critic_loss": 3.4025940895080566,
    "ent_coef": 0.11087848991155624,
    "learning_rate": 0.001
  },
  {
    "episode": 2226,
    "reward": 80.668583,
    "length": 77,
    "time": 38541.124547,
    "actor_loss": -48.663543701171875,
    "critic_loss": 33.66272735595703,
    "ent_coef": 0.11051589250564575,
    "learning_rate": 0.001
  },
  {
    "episode": 2227,
    "reward": 90.314186,
    "length": 64,
    "time": 38552.900496,
    "actor_loss": -51.70331573486328,
    "critic_loss": 10.083194732666016,
    "ent_coef": 0.11013125628232956,
    "learning_rate": 0.001
  },
  {
    "episode": 2228,
    "reward": 90.497499,
    "length": 63,
    "time": 38564.113595,
    "actor_loss": -53.38276290893555,
    "critic_loss": 89.53170013427734,
    "ent_coef": 0.11260758340358734,
    "learning_rate": 0.001
  },
  {
    "episode": 2229,
    "reward": 84.237318,
    "length": 75,
    "time": 38576.586176,
    "actor_loss": -45.90800476074219,
    "critic_loss": 65.96347045898438,
    "ent_coef": 0.11198649555444717,
    "learning_rate": 0.001
  },
  {
    "episode": 2230,
    "reward": 80.422234,
    "length": 78,
    "time": 38591.168871,
    "actor_loss": -52.482967376708984,
    "critic_loss": 6.5612287521362305,
    "ent_coef": 0.11320032179355621,
    "learning_rate": 0.001
  },
  {
    "episode": 2231,
    "reward": 84.222048,
    "length": 70,
    "time": 38603.63084,
    "actor_loss": -51.16221618652344,
    "critic_loss": 213.71986389160156,
    "ent_coef": 0.11439387500286102,
    "learning_rate": 0.001
  },
  {
    "episode": 2232,
    "reward": 88.927885,
    "length": 65,
    "time": 38617.187208,
    "actor_loss": -54.88768768310547,
    "critic_loss": 31.346784591674805,
    "ent_coef": 0.11579977720975876,
    "learning_rate": 0.001
  },
  {
    "episode": 2233,
    "reward": 84.117158,
    "length": 78,
    "time": 38630.971657,
    "actor_loss": -64.39633178710938,
    "critic_loss": 20.68206787109375,
    "ent_coef": 0.11367262154817581,
    "learning_rate": 0.001
  },
  {
    "episode": 2234,
    "reward": 88.638436,
    "length": 67,
    "time": 38643.532999,
    "actor_loss": -55.3237419128418,
    "critic_loss": 36.14639663696289,
    "ent_coef": 0.11303117126226425,
    "learning_rate": 0.001
  },
  {
    "episode": 2235,
    "reward": 89.279554,
    "length": 65,
    "time": 38656.342113,
    "actor_loss": -56.51451873779297,
    "critic_loss": 6.244516372680664,
    "ent_coef": 0.11188745498657227,
    "learning_rate": 0.001
  },
  {
    "episode": 2236,
    "reward": 89.900616,
    "length": 65,
    "time": 38671.506026,
    "actor_loss": -51.1708869934082,
    "critic_loss": 4.485365390777588,
    "ent_coef": 0.10912526398897171,
    "learning_rate": 0.001
  },
  {
    "episode": 2237,
    "reward": 88.26424,
    "length": 67,
    "time": 38683.144453,
    "actor_loss": -57.0040397644043,
    "critic_loss": 9.73498821258545,
    "ent_coef": 0.10547491163015366,
    "learning_rate": 0.001
  },
  {
    "episode": 2238,
    "reward": 91.26358,
    "length": 62,
    "time": 38696.423568,
    "actor_loss": -52.54021072387695,
    "critic_loss": 15.316156387329102,
    "ent_coef": 0.1121312603354454,
    "learning_rate": 0.001
  },
  {
    "episode": 2239,
    "reward": 87.949714,
    "length": 66,
    "time": 38710.568991,
    "actor_loss": -50.35530090332031,
    "critic_loss": 15.928455352783203,
    "ent_coef": 0.11424416303634644,
    "learning_rate": 0.001
  },
  {
    "episode": 2240,
    "reward": 79.312931,
    "length": 80,
    "time": 38724.333968,
    "actor_loss": -54.28944396972656,
    "critic_loss": 4.733852386474609,
    "ent_coef": 0.11576593667268753,
    "learning_rate": 0.001
  },
  {
    "episode": 2241,
    "reward": 91.028762,
    "length": 61,
    "time": 38737.05868,
    "actor_loss": -51.5173454284668,
    "critic_loss": 8.610748291015625,
    "ent_coef": 0.119876429438591,
    "learning_rate": 0.001
  },
  {
    "episode": 2242,
    "reward": 89.518379,
    "length": 64,
    "time": 38748.538506,
    "actor_loss": -52.550994873046875,
    "critic_loss": 281.56890869140625,
    "ent_coef": 0.12005002051591873,
    "learning_rate": 0.001
  },
  {
    "episode": 2243,
    "reward": 87.316492,
    "length": 68,
    "time": 38763.338503,
    "actor_loss": -51.37848663330078,
    "critic_loss": 59.70452117919922,
    "ent_coef": 0.12160760164260864,
    "learning_rate": 0.001
  },
  {
    "episode": 2244,
    "reward": 80.019603,
    "length": 79,
    "time": 38778.194801,
    "actor_loss": -55.80621337890625,
    "critic_loss": 17.360382080078125,
    "ent_coef": 0.11526928097009659,
    "learning_rate": 0.001
  },
  {
    "episode": 2245,
    "reward": 87.539833,
    "length": 68,
    "time": 38791.204222,
    "actor_loss": -51.345211029052734,
    "critic_loss": 4.305291175842285,
    "ent_coef": 0.11219817399978638,
    "learning_rate": 0.001
  },
  {
    "episode": 2246,
    "reward": 74.332652,
    "length": 87,
    "time": 38807.306126,
    "actor_loss": -55.13867950439453,
    "critic_loss": 12.119741439819336,
    "ent_coef": 0.11114300787448883,
    "learning_rate": 0.001
  },
  {
    "episode": 2247,
    "reward": 82.354033,
    "length": 70,
    "time": 38819.368698,
    "actor_loss": -53.190025329589844,
    "critic_loss": 18.12631607055664,
    "ent_coef": 0.1082179844379425,
    "learning_rate": 0.001
  },
  {
    "episode": 2248,
    "reward": 87.126933,
    "length": 67,
    "time": 38831.054404,
    "actor_loss": -49.104408264160156,
    "critic_loss": 7.266875743865967,
    "ent_coef": 0.10983773320913315,
    "learning_rate": 0.001
  },
  {
    "episode": 2249,
    "reward": 88.725038,
    "length": 67,
    "time": 38844.821653,
    "actor_loss": -55.308650970458984,
    "critic_loss": 118.07677459716797,
    "ent_coef": 0.10782378911972046,
    "learning_rate": 0.001
  },
  {
    "episode": 2250,
    "reward": 84.981169,
    "length": 72,
    "time": 38859.520823,
    "actor_loss": -49.003196716308594,
    "critic_loss": 59.872276306152344,
    "ent_coef": 0.10480431467294693,
    "learning_rate": 0.001
  },
  {
    "episode": 2251,
    "reward": 82.559403,
    "length": 76,
    "time": 38873.925742,
    "actor_loss": -55.589603424072266,
    "critic_loss": 45.293235778808594,
    "ent_coef": 0.10328428447246552,
    "learning_rate": 0.001
  },
  {
    "episode": 2252,
    "reward": 88.894116,
    "length": 66,
    "time": 38885.420537,
    "actor_loss": -51.79563522338867,
    "critic_loss": 9.776473999023438,
    "ent_coef": 0.10087311267852783,
    "learning_rate": 0.001
  },
  {
    "episode": 2253,
    "reward": 89.442912,
    "length": 64,
    "time": 38898.654256,
    "actor_loss": -51.54376983642578,
    "critic_loss": 139.95806884765625,
    "ent_coef": 0.10133044421672821,
    "learning_rate": 0.001
  },
  {
    "episode": 2254,
    "reward": 90.6701,
    "length": 61,
    "time": 38909.579273,
    "actor_loss": -58.29861068725586,
    "critic_loss": 72.14662170410156,
    "ent_coef": 0.1048659086227417,
    "learning_rate": 0.001
  },
  {
    "episode": 2255,
    "reward": 88.158806,
    "length": 67,
    "time": 38921.127991,
    "actor_loss": -58.75933074951172,
    "critic_loss": 76.32492065429688,
    "ent_coef": 0.10812598466873169,
    "learning_rate": 0.001
  },
  {
    "episode": 2256,
    "reward": 89.76798,
    "length": 64,
    "time": 38932.606546,
    "actor_loss": -58.03947067260742,
    "critic_loss": 24.824485778808594,
    "ent_coef": 0.11082198470830917,
    "learning_rate": 0.001
  },
  {
    "episode": 2257,
    "reward": 87.307873,
    "length": 68,
    "time": 38946.091543,
    "actor_loss": -51.71402359008789,
    "critic_loss": 7.160933971405029,
    "ent_coef": 0.1117018312215805,
    "learning_rate": 0.001
  },
  {
    "episode": 2258,
    "reward": 88.632941,
    "length": 65,
    "time": 38959.352262,
    "actor_loss": -52.26996994018555,
    "critic_loss": 53.13291931152344,
    "ent_coef": 0.1144571602344513,
    "learning_rate": 0.001
  },
  {
    "episode": 2259,
    "reward": 84.934354,
    "length": 72,
    "time": 38973.562451,
    "actor_loss": -55.30024719238281,
    "critic_loss": 111.06158447265625,
    "ent_coef": 0.11113304644823074,
    "learning_rate": 0.001
  },
  {
    "episode": 2260,
    "reward": 80.847088,
    "length": 78,
    "time": 38987.147114,
    "actor_loss": -50.880714416503906,
    "critic_loss": 7.911974906921387,
    "ent_coef": 0.10460369288921356,
    "learning_rate": 0.001
  },
  {
    "episode": 2261,
    "reward": 85.816509,
    "length": 76,
    "time": 39002.926525,
    "actor_loss": -55.81604766845703,
    "critic_loss": 15.632475852966309,
    "ent_coef": 0.09803547710180283,
    "learning_rate": 0.001
  },
  {
    "episode": 2262,
    "reward": 86.69186,
    "length": 68,
    "time": 39014.749887,
    "actor_loss": -49.949073791503906,
    "critic_loss": 60.53205871582031,
    "ent_coef": 0.09611120820045471,
    "learning_rate": 0.001
  },
  {
    "episode": 2263,
    "reward": 88.320363,
    "length": 66,
    "time": 39026.427286,
    "actor_loss": -47.0797233581543,
    "critic_loss": 6.895502090454102,
    "ent_coef": 0.10203085094690323,
    "learning_rate": 0.001
  },
  {
    "episode": 2264,
    "reward": 90.611685,
    "length": 62,
    "time": 39038.572011,
    "actor_loss": -51.88043975830078,
    "critic_loss": 26.736331939697266,
    "ent_coef": 0.10747918486595154,
    "learning_rate": 0.001
  },
  {
    "episode": 2265,
    "reward": 89.889766,
    "length": 63,
    "time": 39050.500127,
    "actor_loss": -50.67681884765625,
    "critic_loss": 16.644283294677734,
    "ent_coef": 0.1051429957151413,
    "learning_rate": 0.001
  },
  {
    "episode": 2266,
    "reward": 89.26445,
    "length": 65,
    "time": 39064.77315,
    "actor_loss": -49.015804290771484,
    "critic_loss": 17.599578857421875,
    "ent_coef": 0.10416383296251297,
    "learning_rate": 0.001
  },
  {
    "episode": 2267,
    "reward": 88.949661,
    "length": 66,
    "time": 39077.734966,
    "actor_loss": -59.7762451171875,
    "critic_loss": 40.36769485473633,
    "ent_coef": 0.1045636236667633,
    "learning_rate": 0.001
  },
  {
    "episode": 2268,
    "reward": 89.60933,
    "length": 65,
    "time": 39091.602364,
    "actor_loss": -56.064979553222656,
    "critic_loss": 2.6609268188476562,
    "ent_coef": 0.10553800314664841,
    "learning_rate": 0.001
  },
  {
    "episode": 2269,
    "reward": 86.026125,
    "length": 70,
    "time": 39103.741904,
    "actor_loss": -53.20384979248047,
    "critic_loss": 46.809391021728516,
    "ent_coef": 0.1062992736697197,
    "learning_rate": 0.001
  },
  {
    "episode": 2270,
    "reward": 86.899174,
    "length": 69,
    "time": 39116.017208,
    "actor_loss": -57.27520751953125,
    "critic_loss": 12.29034423828125,
    "ent_coef": 0.10724110901355743,
    "learning_rate": 0.001
  },
  {
    "episode": 2271,
    "reward": 89.892953,
    "length": 64,
    "time": 39130.615777,
    "actor_loss": -58.72126770019531,
    "critic_loss": 21.08739471435547,
    "ent_coef": 0.1102251410484314,
    "learning_rate": 0.001
  },
  {
    "episode": 2272,
    "reward": 88.417481,
    "length": 66,
    "time": 39145.739015,
    "actor_loss": -57.60167694091797,
    "critic_loss": 13.438329696655273,
    "ent_coef": 0.11515118926763535,
    "learning_rate": 0.001
  },
  {
    "episode": 2273,
    "reward": 83.18412,
    "length": 76,
    "time": 39161.940233,
    "actor_loss": -57.59723663330078,
    "critic_loss": 16.630741119384766,
    "ent_coef": 0.11685490608215332,
    "learning_rate": 0.001
  },
  {
    "episode": 2274,
    "reward": 88.23958,
    "length": 68,
    "time": 39173.69951,
    "actor_loss": -51.63444519042969,
    "critic_loss": 3.429121255874634,
    "ent_coef": 0.11556076258420944,
    "learning_rate": 0.001
  },
  {
    "episode": 2275,
    "reward": 78.248343,
    "length": 80,
    "time": 39187.636392,
    "actor_loss": -48.1668815612793,
    "critic_loss": 9.120311737060547,
    "ent_coef": 0.11109902709722519,
    "learning_rate": 0.001
  },
  {
    "episode": 2276,
    "reward": 70.986388,
    "length": 96,
    "time": 39203.473338,
    "actor_loss": -58.41045379638672,
    "critic_loss": 16.01626968383789,
    "ent_coef": 0.10749917477369308,
    "learning_rate": 0.001
  },
  {
    "episode": 2277,
    "reward": 87.307631,
    "length": 68,
    "time": 39218.241625,
    "actor_loss": -52.59394073486328,
    "critic_loss": 5.460554122924805,
    "ent_coef": 0.10553893446922302,
    "learning_rate": 0.001
  },
  {
    "episode": 2278,
    "reward": 85.662987,
    "length": 71,
    "time": 39232.990402,
    "actor_loss": -54.571739196777344,
    "critic_loss": 25.911680221557617,
    "ent_coef": 0.10190339386463165,
    "learning_rate": 0.001
  },
  {
    "episode": 2279,
    "reward": 78.320519,
    "length": 81,
    "time": 39247.849461,
    "actor_loss": -55.25374221801758,
    "critic_loss": 12.402812957763672,
    "ent_coef": 0.10032907873392105,
    "learning_rate": 0.001
  },
  {
    "episode": 2280,
    "reward": 89.572622,
    "length": 64,
    "time": 39260.622697,
    "actor_loss": -55.942420959472656,
    "critic_loss": 20.860563278198242,
    "ent_coef": 0.10396814346313477,
    "learning_rate": 0.001
  },
  {
    "episode": 2281,
    "reward": 87.929515,
    "length": 66,
    "time": 39273.906494,
    "actor_loss": -49.25708770751953,
    "critic_loss": 4.758307933807373,
    "ent_coef": 0.10722360759973526,
    "learning_rate": 0.001
  },
  {
    "episode": 2282,
    "reward": 87.063826,
    "length": 69,
    "time": 39288.196711,
    "actor_loss": -55.804412841796875,
    "critic_loss": 6.550276279449463,
    "ent_coef": 0.10619911551475525,
    "learning_rate": 0.001
  },
  {
    "episode": 2283,
    "reward": 83.218576,
    "length": 75,
    "time": 39300.870729,
    "actor_loss": -53.72744369506836,
    "critic_loss": 14.569859504699707,
    "ent_coef": 0.10753852874040604,
    "learning_rate": 0.001
  },
  {
    "episode": 2284,
    "reward": 90.642088,
    "length": 63,
    "time": 39314.806153,
    "actor_loss": -54.74364471435547,
    "critic_loss": 54.64886474609375,
    "ent_coef": 0.10909634083509445,
    "learning_rate": 0.001
  },
  {
    "episode": 2285,
    "reward": 89.010281,
    "length": 65,
    "time": 39326.224854,
    "actor_loss": -51.231109619140625,
    "critic_loss": 35.16096496582031,
    "ent_coef": 0.10928638279438019,
    "learning_rate": 0.001
  },
  {
    "episode": 2286,
    "reward": 88.917205,
    "length": 65,
    "time": 39338.783514,
    "actor_loss": -63.34602355957031,
    "critic_loss": 26.261547088623047,
    "ent_coef": 0.11015084385871887,
    "learning_rate": 0.001
  },
  {
    "episode": 2287,
    "reward": 86.574781,
    "length": 70,
    "time": 39353.397784,
    "actor_loss": -57.03996658325195,
    "critic_loss": 17.345670700073242,
    "ent_coef": 0.10438370704650879,
    "learning_rate": 0.001
  },
  {
    "episode": 2288,
    "reward": 88.563371,
    "length": 66,
    "time": 39365.826677,
    "actor_loss": -62.50700759887695,
    "critic_loss": 10.188154220581055,
    "ent_coef": 0.1056617945432663,
    "learning_rate": 0.001
  },
  {
    "episode": 2289,
    "reward": 86.372409,
    "length": 68,
    "time": 39377.532946,
    "actor_loss": -55.3248176574707,
    "critic_loss": 9.665264129638672,
    "ent_coef": 0.10394242405891418,
    "learning_rate": 0.001
  },
  {
    "episode": 2290,
    "reward": 88.571729,
    "length": 66,
    "time": 39391.488276,
    "actor_loss": -53.81879425048828,
    "critic_loss": 21.038291931152344,
    "ent_coef": 0.10426148027181625,
    "learning_rate": 0.001
  },
  {
    "episode": 2291,
    "reward": 88.627095,
    "length": 66,
    "time": 39405.334381,
    "actor_loss": -48.56474685668945,
    "critic_loss": 11.160985946655273,
    "ent_coef": 0.1023101881146431,
    "learning_rate": 0.001
  },
  {
    "episode": 2292,
    "reward": 90.680935,
    "length": 62,
    "time": 39417.501747,
    "actor_loss": -56.71414566040039,
    "critic_loss": 8.609379768371582,
    "ent_coef": 0.10296499729156494,
    "learning_rate": 0.001
  },
  {
    "episode": 2293,
    "reward": 90.200799,
    "length": 63,
    "time": 39430.597392,
    "actor_loss": -55.61674880981445,
    "critic_loss": 10.437950134277344,
    "ent_coef": 0.10055485367774963,
    "learning_rate": 0.001
  },
  {
    "episode": 2294,
    "reward": 90.623343,
    "length": 63,
    "time": 39445.192497,
    "actor_loss": -60.169395446777344,
    "critic_loss": 5.817309856414795,
    "ent_coef": 0.10076388716697693,
    "learning_rate": 0.001
  },
  {
    "episode": 2295,
    "reward": 87.778502,
    "length": 67,
    "time": 39458.053765,
    "actor_loss": -51.785804748535156,
    "critic_loss": 36.19945526123047,
    "ent_coef": 0.09977751225233078,
    "learning_rate": 0.001
  },
  {
    "episode": 2296,
    "reward": 90.313206,
    "length": 62,
    "time": 39469.222449,
    "actor_loss": -54.408851623535156,
    "critic_loss": 4.379301071166992,
    "ent_coef": 0.10216522216796875,
    "learning_rate": 0.001
  },
  {
    "episode": 2297,
    "reward": 86.567755,
    "length": 69,
    "time": 39483.283197,
    "actor_loss": -60.00894546508789,
    "critic_loss": 29.455936431884766,
    "ent_coef": 0.10701888054609299,
    "learning_rate": 0.001
  },
  {
    "episode": 2298,
    "reward": 89.786488,
    "length": 65,
    "time": 39495.62041,
    "actor_loss": -58.06856918334961,
    "critic_loss": 73.65968322753906,
    "ent_coef": 0.10591469705104828,
    "learning_rate": 0.001
  },
  {
    "episode": 2299,
    "reward": 86.697919,
    "length": 69,
    "time": 39508.524447,
    "actor_loss": -58.187904357910156,
    "critic_loss": 9.214445114135742,
    "ent_coef": 0.0986398309469223,
    "learning_rate": 0.001
  },
  {
    "episode": 2300,
    "reward": 79.687861,
    "length": 80,
    "time": 39522.117963,
    "actor_loss": -56.44437789916992,
    "critic_loss": 25.97620391845703,
    "ent_coef": 0.09130859375,
    "learning_rate": 0.001
  },
  {
    "episode": 2301,
    "reward": 72.647527,
    "length": 90,
    "time": 39536.891645,
    "actor_loss": -61.46111297607422,
    "critic_loss": 4.007872581481934,
    "ent_coef": 0.08613510429859161,
    "learning_rate": 0.001
  },
  {
    "episode": 2302,
    "reward": 86.142939,
    "length": 70,
    "time": 39549.398298,
    "actor_loss": -61.62104034423828,
    "critic_loss": 92.95033264160156,
    "ent_coef": 0.08591863512992859,
    "learning_rate": 0.001
  },
  {
    "episode": 2303,
    "reward": 89.516206,
    "length": 64,
    "time": 39560.716024,
    "actor_loss": -63.451595306396484,
    "critic_loss": 7.636630058288574,
    "ent_coef": 0.0889190062880516,
    "learning_rate": 0.001
  },
  {
    "episode": 2304,
    "reward": 91.374961,
    "length": 61,
    "time": 39571.602674,
    "actor_loss": -54.87943649291992,
    "critic_loss": 8.662456512451172,
    "ent_coef": 0.09341160207986832,
    "learning_rate": 0.001
  },
  {
    "episode": 2305,
    "reward": 87.773188,
    "length": 67,
    "time": 39583.975692,
    "actor_loss": -50.65192413330078,
    "critic_loss": 15.628705978393555,
    "ent_coef": 0.09443743526935577,
    "learning_rate": 0.001
  },
  {
    "episode": 2306,
    "reward": 90.061254,
    "length": 62,
    "time": 39595.061522,
    "actor_loss": -58.523128509521484,
    "critic_loss": 4.3159074783325195,
    "ent_coef": 0.09714522957801819,
    "learning_rate": 0.001
  },
  {
    "episode": 2307,
    "reward": 85.822588,
    "length": 74,
    "time": 39611.541484,
    "actor_loss": -61.30128860473633,
    "critic_loss": 10.700510025024414,
    "ent_coef": 0.09422346204519272,
    "learning_rate": 0.001
  },
  {
    "episode": 2308,
    "reward": 89.951656,
    "length": 64,
    "time": 39625.365268,
    "actor_loss": -60.963924407958984,
    "critic_loss": 8.044529914855957,
    "ent_coef": 0.09168955683708191,
    "learning_rate": 0.001
  },
  {
    "episode": 2309,
    "reward": 81.467832,
    "length": 77,
    "time": 39638.263781,
    "actor_loss": -63.043052673339844,
    "critic_loss": 9.197325706481934,
    "ent_coef": 0.09087157994508743,
    "learning_rate": 0.001
  },
  {
    "episode": 2310,
    "reward": 83.627307,
    "length": 72,
    "time": 39650.588306,
    "actor_loss": -57.4129638671875,
    "critic_loss": 7.02077054977417,
    "ent_coef": 0.09450612962245941,
    "learning_rate": 0.001
  },
  {
    "episode": 2311,
    "reward": 90.17215,
    "length": 63,
    "time": 39664.682912,
    "actor_loss": -57.475189208984375,
    "critic_loss": 67.5604476928711,
    "ent_coef": 0.09636632353067398,
    "learning_rate": 0.001
  },
  {
    "episode": 2312,
    "reward": 64.136168,
    "length": 100,
    "time": 39680.563985,
    "actor_loss": -57.42705535888672,
    "critic_loss": 2.7699179649353027,
    "ent_coef": 0.10264699161052704,
    "learning_rate": 0.001
  },
  {
    "episode": 2313,
    "reward": 89.447994,
    "length": 64,
    "time": 39694.49083,
    "actor_loss": -54.41584396362305,
    "critic_loss": 55.84114074707031,
    "ent_coef": 0.10438402742147446,
    "learning_rate": 0.001
  },
  {
    "episode": 2314,
    "reward": 87.716016,
    "length": 67,
    "time": 39707.974782,
    "actor_loss": -50.15684509277344,
    "critic_loss": 3.1720519065856934,
    "ent_coef": 0.10370936244726181,
    "learning_rate": 0.001
  },
  {
    "episode": 2315,
    "reward": 90.120968,
    "length": 63,
    "time": 39720.471874,
    "actor_loss": -55.331451416015625,
    "critic_loss": 10.849230766296387,
    "ent_coef": 0.11110679060220718,
    "learning_rate": 0.001
  },
  {
    "episode": 2316,
    "reward": 88.198744,
    "length": 67,
    "time": 39736.929235,
    "actor_loss": -54.841941833496094,
    "critic_loss": 10.517707824707031,
    "ent_coef": 0.11099328845739365,
    "learning_rate": 0.001
  },
  {
    "episode": 2317,
    "reward": 81.274633,
    "length": 77,
    "time": 39752.911682,
    "actor_loss": -49.47197723388672,
    "critic_loss": 42.77699279785156,
    "ent_coef": 0.10657396912574768,
    "learning_rate": 0.001
  },
  {
    "episode": 2318,
    "reward": 71.614083,
    "length": 93,
    "time": 39768.904875,
    "actor_loss": -63.879520416259766,
    "critic_loss": 21.890640258789062,
    "ent_coef": 0.10294793546199799,
    "learning_rate": 0.001
  },
  {
    "episode": 2319,
    "reward": 88.01693,
    "length": 67,
    "time": 39781.567782,
    "actor_loss": -54.61228942871094,
    "critic_loss": 72.5373306274414,
    "ent_coef": 0.1099405363202095,
    "learning_rate": 0.001
  },
  {
    "episode": 2320,
    "reward": 89.444136,
    "length": 63,
    "time": 39792.835997,
    "actor_loss": -56.45790100097656,
    "critic_loss": 21.592180252075195,
    "ent_coef": 0.11648211628198624,
    "learning_rate": 0.001
  },
  {
    "episode": 2321,
    "reward": 90.958792,
    "length": 62,
    "time": 39808.089987,
    "actor_loss": -56.298805236816406,
    "critic_loss": 34.27015686035156,
    "ent_coef": 0.11463861912488937,
    "learning_rate": 0.001
  },
  {
    "episode": 2322,
    "reward": 88.547867,
    "length": 65,
    "time": 39819.460434,
    "actor_loss": -59.68183898925781,
    "critic_loss": 17.925209045410156,
    "ent_coef": 0.11395955085754395,
    "learning_rate": 0.001
  },
  {
    "episode": 2323,
    "reward": 87.532034,
    "length": 70,
    "time": 39836.409901,
    "actor_loss": -54.14228820800781,
    "critic_loss": 7.420191764831543,
    "ent_coef": 0.11339262127876282,
    "learning_rate": 0.001
  },
  {
    "episode": 2324,
    "reward": 81.845641,
    "length": 76,
    "time": 39850.759847,
    "actor_loss": -54.168392181396484,
    "critic_loss": 52.511695861816406,
    "ent_coef": 0.10793060064315796,
    "learning_rate": 0.001
  },
  {
    "episode": 2325,
    "reward": 75.582155,
    "length": 84,
    "time": 39868.131325,
    "actor_loss": -53.60563659667969,
    "critic_loss": 31.9478702545166,
    "ent_coef": 0.10910866409540176,
    "learning_rate": 0.001
  },
  {
    "episode": 2326,
    "reward": 89.210097,
    "length": 65,
    "time": 39883.408476,
    "actor_loss": -58.34356689453125,
    "critic_loss": 7.106340408325195,
    "ent_coef": 0.11124050617218018,
    "learning_rate": 0.001
  },
  {
    "episode": 2327,
    "reward": 82.380515,
    "length": 77,
    "time": 39896.710181,
    "actor_loss": -59.538963317871094,
    "critic_loss": 36.9422721862793,
    "ent_coef": 0.10831379145383835,
    "learning_rate": 0.001
  },
  {
    "episode": 2328,
    "reward": 77.583203,
    "length": 83,
    "time": 39910.297169,
    "actor_loss": -56.93650817871094,
    "critic_loss": 9.041543006896973,
    "ent_coef": 0.1040005013346672,
    "learning_rate": 0.001
  },
  {
    "episode": 2329,
    "reward": 87.235432,
    "length": 67,
    "time": 39922.697664,
    "actor_loss": -52.354923248291016,
    "critic_loss": 36.19001770019531,
    "ent_coef": 0.10062026977539062,
    "learning_rate": 0.001
  },
  {
    "episode": 2330,
    "reward": 75.487379,
    "length": 83,
    "time": 39936.540935,
    "actor_loss": -53.72713088989258,
    "critic_loss": 17.635204315185547,
    "ent_coef": 0.09663749486207962,
    "learning_rate": 0.001
  },
  {
    "episode": 2331,
    "reward": 87.983272,
    "length": 65,
    "time": 39949.502017,
    "actor_loss": -60.57073211669922,
    "critic_loss": 75.19415283203125,
    "ent_coef": 0.09265154600143433,
    "learning_rate": 0.001
  },
  {
    "episode": 2332,
    "reward": 88.915654,
    "length": 66,
    "time": 39961.914958,
    "actor_loss": -54.950469970703125,
    "critic_loss": 24.08847427368164,
    "ent_coef": 0.0907839983701706,
    "learning_rate": 0.001
  },
  {
    "episode": 2333,
    "reward": 87.97199,
    "length": 67,
    "time": 39973.953097,
    "actor_loss": -62.093345642089844,
    "critic_loss": 3.4468166828155518,
    "ent_coef": 0.09022296220064163,
    "learning_rate": 0.001
  },
  {
    "episode": 2334,
    "reward": 88.442203,
    "length": 66,
    "time": 39988.674764,
    "actor_loss": -53.8619270324707,
    "critic_loss": 7.764890193939209,
    "ent_coef": 0.09182790666818619,
    "learning_rate": 0.001
  },
  {
    "episode": 2335,
    "reward": 90.874608,
    "length": 63,
    "time": 40003.23988,
    "actor_loss": -59.03041076660156,
    "critic_loss": 3.3291733264923096,
    "ent_coef": 0.09425672143697739,
    "learning_rate": 0.001
  },
  {
    "episode": 2336,
    "reward": 88.283138,
    "length": 66,
    "time": 40016.912404,
    "actor_loss": -55.416507720947266,
    "critic_loss": 6.307967185974121,
    "ent_coef": 0.09225991368293762,
    "learning_rate": 0.001
  },
  {
    "episode": 2337,
    "reward": 85.541803,
    "length": 70,
    "time": 40029.33497,
    "actor_loss": -56.10248565673828,
    "critic_loss": 12.837333679199219,
    "ent_coef": 0.08997749537229538,
    "learning_rate": 0.001
  },
  {
    "episode": 2338,
    "reward": 89.333301,
    "length": 65,
    "time": 40043.730118,
    "actor_loss": -58.146080017089844,
    "critic_loss": 11.59777545928955,
    "ent_coef": 0.09016657620668411,
    "learning_rate": 0.001
  },
  {
    "episode": 2339,
    "reward": 81.642988,
    "length": 78,
    "time": 40056.990508,
    "actor_loss": -54.152305603027344,
    "critic_loss": 21.466907501220703,
    "ent_coef": 0.09086962789297104,
    "learning_rate": 0.001
  },
  {
    "episode": 2340,
    "reward": 80.263908,
    "length": 82,
    "time": 40070.975727,
    "actor_loss": -53.01740264892578,
    "critic_loss": 19.00594711303711,
    "ent_coef": 0.08960969746112823,
    "learning_rate": 0.001
  },
  {
    "episode": 2341,
    "reward": 85.923005,
    "length": 70,
    "time": 40083.597567,
    "actor_loss": -54.003143310546875,
    "critic_loss": 12.70573902130127,
    "ent_coef": 0.08910901099443436,
    "learning_rate": 0.001
  },
  {
    "episode": 2342,
    "reward": 89.208417,
    "length": 65,
    "time": 40097.002578,
    "actor_loss": -60.204017639160156,
    "critic_loss": 4.878387451171875,
    "ent_coef": 0.09069301187992096,
    "learning_rate": 0.001
  },
  {
    "episode": 2343,
    "reward": 65.309223,
    "length": 101,
    "time": 40116.213977,
    "actor_loss": -56.960479736328125,
    "critic_loss": 14.820198059082031,
    "ent_coef": 0.09077294170856476,
    "learning_rate": 0.001
  },
  {
    "episode": 2344,
    "reward": 87.307113,
    "length": 68,
    "time": 40130.032192,
    "actor_loss": -59.204010009765625,
    "critic_loss": 67.24539184570312,
    "ent_coef": 0.09287124872207642,
    "learning_rate": 0.001
  },
  {
    "episode": 2345,
    "reward": 86.244874,
    "length": 72,
    "time": 40145.418078,
    "actor_loss": -50.60139083862305,
    "critic_loss": 23.11559295654297,
    "ent_coef": 0.09205736964941025,
    "learning_rate": 0.001
  },
  {
    "episode": 2346,
    "reward": 88.341052,
    "length": 66,
    "time": 40157.138799,
    "actor_loss": -55.00038146972656,
    "critic_loss": 202.53488159179688,
    "ent_coef": 0.09065982699394226,
    "learning_rate": 0.001
  },
  {
    "episode": 2347,
    "reward": 87.096523,
    "length": 69,
    "time": 40169.176352,
    "actor_loss": -63.377376556396484,
    "critic_loss": 23.12851905822754,
    "ent_coef": 0.09216818958520889,
    "learning_rate": 0.001
  },
  {
    "episode": 2348,
    "reward": 89.23778,
    "length": 66,
    "time": 40181.809317,
    "actor_loss": -55.04250717163086,
    "critic_loss": 11.632384300231934,
    "ent_coef": 0.09614338725805283,
    "learning_rate": 0.001
  },
  {
    "episode": 2349,
    "reward": 88.908768,
    "length": 64,
    "time": 40193.803192,
    "actor_loss": -56.082252502441406,
    "critic_loss": 3.394416332244873,
    "ent_coef": 0.10297267884016037,
    "learning_rate": 0.001
  },
  {
    "episode": 2350,
    "reward": 77.522714,
    "length": 88,
    "time": 40208.247908,
    "actor_loss": -56.20408248901367,
    "critic_loss": 17.132362365722656,
    "ent_coef": 0.0999259501695633,
    "learning_rate": 0.001
  },
  {
    "episode": 2351,
    "reward": 78.239701,
    "length": 82,
    "time": 40224.950693,
    "actor_loss": -63.01001739501953,
    "critic_loss": 16.05241584777832,
    "ent_coef": 0.09249696135520935,
    "learning_rate": 0.001
  },
  {
    "episode": 2352,
    "reward": 77.414062,
    "length": 80,
    "time": 40239.119562,
    "actor_loss": -61.57634735107422,
    "critic_loss": 10.719367980957031,
    "ent_coef": 0.09063155949115753,
    "learning_rate": 0.001
  },
  {
    "episode": 2353,
    "reward": 83.171472,
    "length": 74,
    "time": 40253.982309,
    "actor_loss": -56.56071853637695,
    "critic_loss": 137.21815490722656,
    "ent_coef": 0.08786965906620026,
    "learning_rate": 0.001
  },
  {
    "episode": 2354,
    "reward": 85.827126,
    "length": 70,
    "time": 40267.172078,
    "actor_loss": -62.295928955078125,
    "critic_loss": 3.2526607513427734,
    "ent_coef": 0.08280660212039948,
    "learning_rate": 0.001
  },
  {
    "episode": 2355,
    "reward": 88.67449,
    "length": 65,
    "time": 40279.510844,
    "actor_loss": -58.64783477783203,
    "critic_loss": 112.2334976196289,
    "ent_coef": 0.08399609476327896,
    "learning_rate": 0.001
  },
  {
    "episode": 2356,
    "reward": 56.592576,
    "length": 112,
    "time": 40298.106126,
    "actor_loss": -60.53718948364258,
    "critic_loss": 58.00104522705078,
    "ent_coef": 0.08172837644815445,
    "learning_rate": 0.001
  },
  {
    "episode": 2357,
    "reward": 87.032751,
    "length": 68,
    "time": 40311.832937,
    "actor_loss": -61.501670837402344,
    "critic_loss": 38.28236389160156,
    "ent_coef": 0.08143947273492813,
    "learning_rate": 0.001
  },
  {
    "episode": 2358,
    "reward": 87.708146,
    "length": 67,
    "time": 40325.071742,
    "actor_loss": -53.2016487121582,
    "critic_loss": 6.905829429626465,
    "ent_coef": 0.08591049909591675,
    "learning_rate": 0.001
  },
  {
    "episode": 2359,
    "reward": 54.283655,
    "length": 111,
    "time": 40342.909762,
    "actor_loss": -64.49436950683594,
    "critic_loss": 7.52412748336792,
    "ent_coef": 0.08756215125322342,
    "learning_rate": 0.001
  },
  {
    "episode": 2360,
    "reward": 85.145332,
    "length": 73,
    "time": 40357.340394,
    "actor_loss": -56.635169982910156,
    "critic_loss": 104.97477722167969,
    "ent_coef": 0.08728773891925812,
    "learning_rate": 0.001
  },
  {
    "episode": 2361,
    "reward": 85.752821,
    "length": 70,
    "time": 40370.32095,
    "actor_loss": -54.203826904296875,
    "critic_loss": 3.033763885498047,
    "ent_coef": 0.08932200819253922,
    "learning_rate": 0.001
  },
  {
    "episode": 2362,
    "reward": 83.155588,
    "length": 74,
    "time": 40383.791755,
    "actor_loss": -56.53620147705078,
    "critic_loss": 7.109885215759277,
    "ent_coef": 0.08833453804254532,
    "learning_rate": 0.001
  },
  {
    "episode": 2363,
    "reward": 88.065544,
    "length": 66,
    "time": 40396.654409,
    "actor_loss": -56.69579315185547,
    "critic_loss": 29.11935806274414,
    "ent_coef": 0.0902663841843605,
    "learning_rate": 0.001
  },
  {
    "episode": 2364,
    "reward": 79.285111,
    "length": 79,
    "time": 40410.00424,
    "actor_loss": -51.89830017089844,
    "critic_loss": 431.9366455078125,
    "ent_coef": 0.08894241601228714,
    "learning_rate": 0.001
  },
  {
    "episode": 2365,
    "reward": 88.889376,
    "length": 66,
    "time": 40422.715393,
    "actor_loss": -59.60655975341797,
    "critic_loss": 11.416040420532227,
    "ent_coef": 0.09212952107191086,
    "learning_rate": 0.001
  },
  {
    "episode": 2366,
    "reward": 87.907736,
    "length": 67,
    "time": 40435.808437,
    "actor_loss": -62.777671813964844,
    "critic_loss": 2.904165506362915,
    "ent_coef": 0.0899999588727951,
    "learning_rate": 0.001
  },
  {
    "episode": 2367,
    "reward": 88.460891,
    "length": 66,
    "time": 40448.529158,
    "actor_loss": -58.79573059082031,
    "critic_loss": 49.18771743774414,
    "ent_coef": 0.08995010703802109,
    "learning_rate": 0.001
  },
  {
    "episode": 2368,
    "reward": 79.182421,
    "length": 81,
    "time": 40462.173423,
    "actor_loss": -62.31336975097656,
    "critic_loss": 121.91033935546875,
    "ent_coef": 0.08549461513757706,
    "learning_rate": 0.001
  },
  {
    "episode": 2369,
    "reward": 87.691198,
    "length": 67,
    "time": 40476.964942,
    "actor_loss": -59.70433807373047,
    "critic_loss": 5.796589374542236,
    "ent_coef": 0.08687330037355423,
    "learning_rate": 0.001
  },
  {
    "episode": 2370,
    "reward": 77.548183,
    "length": 82,
    "time": 40491.805215,
    "actor_loss": -60.46430969238281,
    "critic_loss": 4.806801795959473,
    "ent_coef": 0.08421581238508224,
    "learning_rate": 0.001
  },
  {
    "episode": 2371,
    "reward": 87.765237,
    "length": 66,
    "time": 40503.437977,
    "actor_loss": -60.552764892578125,
    "critic_loss": 1.681581735610962,
    "ent_coef": 0.0829768255352974,
    "learning_rate": 0.001
  },
  {
    "episode": 2372,
    "reward": 71.903673,
    "length": 96,
    "time": 40519.267004,
    "actor_loss": -61.532047271728516,
    "critic_loss": 63.051673889160156,
    "ent_coef": 0.08470442146062851,
    "learning_rate": 0.001
  },
  {
    "episode": 2373,
    "reward": 90.619102,
    "length": 62,
    "time": 40530.235842,
    "actor_loss": -55.64427185058594,
    "critic_loss": 25.78997802734375,
    "ent_coef": 0.08941350132226944,
    "learning_rate": 0.001
  },
  {
    "episode": 2374,
    "reward": 89.499917,
    "length": 63,
    "time": 40542.077554,
    "actor_loss": -61.62479782104492,
    "critic_loss": 17.85912322998047,
    "ent_coef": 0.09383074939250946,
    "learning_rate": 0.001
  },
  {
    "episode": 2375,
    "reward": 84.704012,
    "length": 72,
    "time": 40554.711051,
    "actor_loss": -49.61786651611328,
    "critic_loss": 19.251644134521484,
    "ent_coef": 0.08972246944904327,
    "learning_rate": 0.001
  },
  {
    "episode": 2376,
    "reward": 81.633855,
    "length": 80,
    "time": 40569.685468,
    "actor_loss": -57.71727752685547,
    "critic_loss": 8.171480178833008,
    "ent_coef": 0.0937260165810585,
    "learning_rate": 0.001
  },
  {
    "episode": 2377,
    "reward": 85.668415,
    "length": 71,
    "time": 40586.113354,
    "actor_loss": -63.329078674316406,
    "critic_loss": 39.25645446777344,
    "ent_coef": 0.09575320780277252,
    "learning_rate": 0.001
  },
  {
    "episode": 2378,
    "reward": 71.349253,
    "length": 88,
    "time": 40603.352872,
    "actor_loss": -51.50083541870117,
    "critic_loss": 5.038699150085449,
    "ent_coef": 0.09457508474588394,
    "learning_rate": 0.001
  },
  {
    "episode": 2379,
    "reward": 72.596201,
    "length": 90,
    "time": 40619.082796,
    "actor_loss": -52.204795837402344,
    "critic_loss": 17.618572235107422,
    "ent_coef": 0.0952221006155014,
    "learning_rate": 0.001
  },
  {
    "episode": 2380,
    "reward": 85.365559,
    "length": 71,
    "time": 40631.363964,
    "actor_loss": -57.10783386230469,
    "critic_loss": 9.341421127319336,
    "ent_coef": 0.09568288177251816,
    "learning_rate": 0.001
  },
  {
    "episode": 2381,
    "reward": 81.119716,
    "length": 78,
    "time": 40645.629619,
    "actor_loss": -57.49129104614258,
    "critic_loss": 13.544614791870117,
    "ent_coef": 0.09512319415807724,
    "learning_rate": 0.001
  },
  {
    "episode": 2382,
    "reward": 86.278283,
    "length": 70,
    "time": 40657.629655,
    "actor_loss": -63.66874694824219,
    "critic_loss": 23.407390594482422,
    "ent_coef": 0.0928286537528038,
    "learning_rate": 0.001
  },
  {
    "episode": 2383,
    "reward": 85.294199,
    "length": 71,
    "time": 40669.774227,
    "actor_loss": -54.903221130371094,
    "critic_loss": 18.18634796142578,
    "ent_coef": 0.08845144510269165,
    "learning_rate": 0.001
  },
  {
    "episode": 2384,
    "reward": 84.439771,
    "length": 72,
    "time": 40685.333062,
    "actor_loss": -66.18433380126953,
    "critic_loss": 2.7856764793395996,
    "ent_coef": 0.08479094505310059,
    "learning_rate": 0.001
  },
  {
    "episode": 2385,
    "reward": 89.093639,
    "length": 64,
    "time": 40696.717507,
    "actor_loss": -59.857749938964844,
    "critic_loss": 3.3818085193634033,
    "ent_coef": 0.08425790816545486,
    "learning_rate": 0.001
  },
  {
    "episode": 2386,
    "reward": 75.9796,
    "length": 88,
    "time": 40712.166023,
    "actor_loss": -54.95379638671875,
    "critic_loss": 90.58094787597656,
    "ent_coef": 0.08149321377277374,
    "learning_rate": 0.001
  },
  {
    "episode": 2387,
    "reward": 81.083063,
    "length": 76,
    "time": 40725.899405,
    "actor_loss": -57.66523742675781,
    "critic_loss": 3.4924135208129883,
    "ent_coef": 0.07924473285675049,
    "learning_rate": 0.001
  },
  {
    "episode": 2388,
    "reward": 90.572781,
    "length": 62,
    "time": 40741.307743,
    "actor_loss": -63.2947998046875,
    "critic_loss": 123.74112701416016,
    "ent_coef": 0.08147627115249634,
    "learning_rate": 0.001
  },
  {
    "episode": 2389,
    "reward": 90.413723,
    "length": 63,
    "time": 40756.275754,
    "actor_loss": -57.555763244628906,
    "critic_loss": 4.8077850341796875,
    "ent_coef": 0.08553563058376312,
    "learning_rate": 0.001
  },
  {
    "episode": 2390,
    "reward": 85.201173,
    "length": 73,
    "time": 40768.82769,
    "actor_loss": -58.944942474365234,
    "critic_loss": 55.731056213378906,
    "ent_coef": 0.08488480001688004,
    "learning_rate": 0.001
  },
  {
    "episode": 2391,
    "reward": 80.003455,
    "length": 79,
    "time": 40783.415006,
    "actor_loss": -55.00745391845703,
    "critic_loss": 82.90081787109375,
    "ent_coef": 0.08593954890966415,
    "learning_rate": 0.001
  },
  {
    "episode": 2392,
    "reward": 82.155576,
    "length": 76,
    "time": 40802.730148,
    "actor_loss": -57.61943435668945,
    "critic_loss": 13.612914085388184,
    "ent_coef": 0.08532705903053284,
    "learning_rate": 0.001
  },
  {
    "episode": 2393,
    "reward": 78.942326,
    "length": 80,
    "time": 40818.472615,
    "actor_loss": -56.82260513305664,
    "critic_loss": 3.2428600788116455,
    "ent_coef": 0.08079735934734344,
    "learning_rate": 0.001
  },
  {
    "episode": 2394,
    "reward": 87.574569,
    "length": 69,
    "time": 40830.490584,
    "actor_loss": -59.9417724609375,
    "critic_loss": 5.159102439880371,
    "ent_coef": 0.07975324243307114,
    "learning_rate": 0.001
  },
  {
    "episode": 2395,
    "reward": 82.9209,
    "length": 74,
    "time": 40844.469887,
    "actor_loss": -54.23716735839844,
    "critic_loss": 84.53840637207031,
    "ent_coef": 0.08136627823114395,
    "learning_rate": 0.001
  },
  {
    "episode": 2396,
    "reward": 88.779746,
    "length": 66,
    "time": 40857.061585,
    "actor_loss": -60.76991271972656,
    "critic_loss": 17.419063568115234,
    "ent_coef": 0.08527953177690506,
    "learning_rate": 0.001
  },
  {
    "episode": 2397,
    "reward": 87.405824,
    "length": 66,
    "time": 40868.944593,
    "actor_loss": -62.030784606933594,
    "critic_loss": 5.415754318237305,
    "ent_coef": 0.09051536023616791,
    "learning_rate": 0.001
  },
  {
    "episode": 2398,
    "reward": 89.924826,
    "length": 63,
    "time": 40882.485367,
    "actor_loss": -59.348785400390625,
    "critic_loss": 16.203372955322266,
    "ent_coef": 0.09033109992742538,
    "learning_rate": 0.001
  },
  {
    "episode": 2399,
    "reward": 86.023116,
    "length": 70,
    "time": 40896.338603,
    "actor_loss": -58.13534164428711,
    "critic_loss": 2.7058005332946777,
    "ent_coef": 0.08617628365755081,
    "learning_rate": 0.001
  },
  {
    "episode": 2400,
    "reward": 90.088379,
    "length": 63,
    "time": 40907.639414,
    "actor_loss": -56.5426025390625,
    "critic_loss": 3.043151378631592,
    "ent_coef": 0.08520736545324326,
    "learning_rate": 0.001
  },
  {
    "episode": 2401,
    "reward": 86.390231,
    "length": 69,
    "time": 40922.516644,
    "actor_loss": -61.756744384765625,
    "critic_loss": 29.70039176940918,
    "ent_coef": 0.08633679896593094,
    "learning_rate": 0.001
  },
  {
    "episode": 2402,
    "reward": 77.159091,
    "length": 83,
    "time": 40937.196132,
    "actor_loss": -54.18292999267578,
    "critic_loss": 5.118129730224609,
    "ent_coef": 0.08725317567586899,
    "learning_rate": 0.001
  },
  {
    "episode": 2403,
    "reward": 85.934746,
    "length": 70,
    "time": 40949.208777,
    "actor_loss": -59.751258850097656,
    "critic_loss": 28.916940689086914,
    "ent_coef": 0.08949865400791168,
    "learning_rate": 0.001
  },
  {
    "episode": 2404,
    "reward": 82.612629,
    "length": 75,
    "time": 40963.960775,
    "actor_loss": -62.765872955322266,
    "critic_loss": 13.185415267944336,
    "ent_coef": 0.08517195284366608,
    "learning_rate": 0.001
  },
  {
    "episode": 2405,
    "reward": 87.542049,
    "length": 69,
    "time": 40976.24439,
    "actor_loss": -54.347679138183594,
    "critic_loss": 3.5754876136779785,
    "ent_coef": 0.08181221038103104,
    "learning_rate": 0.001
  },
  {
    "episode": 2406,
    "reward": 86.819537,
    "length": 68,
    "time": 40989.270198,
    "actor_loss": -54.62176513671875,
    "critic_loss": 12.419506072998047,
    "ent_coef": 0.07790644466876984,
    "learning_rate": 0.001
  },
  {
    "episode": 2407,
    "reward": 87.465046,
    "length": 65,
    "time": 41001.572306,
    "actor_loss": -57.47431182861328,
    "critic_loss": 3.6520156860351562,
    "ent_coef": 0.08025328814983368,
    "learning_rate": 0.001
  },
  {
    "episode": 2408,
    "reward": 82.472857,
    "length": 77,
    "time": 41016.068905,
    "actor_loss": -61.22480010986328,
    "critic_loss": 53.49052429199219,
    "ent_coef": 0.08146007359027863,
    "learning_rate": 0.001
  },
  {
    "episode": 2409,
    "reward": 77.928327,
    "length": 83,
    "time": 41031.900936,
    "actor_loss": -59.859169006347656,
    "critic_loss": 8.348136901855469,
    "ent_coef": 0.0784972608089447,
    "learning_rate": 0.001
  },
  {
    "episode": 2410,
    "reward": 88.764446,
    "length": 66,
    "time": 41044.385197,
    "actor_loss": -58.51793670654297,
    "critic_loss": 3.453458309173584,
    "ent_coef": 0.07690975069999695,
    "learning_rate": 0.001
  },
  {
    "episode": 2411,
    "reward": 85.621617,
    "length": 70,
    "time": 41060.330154,
    "actor_loss": -61.01738739013672,
    "critic_loss": 6.405266761779785,
    "ent_coef": 0.07621361315250397,
    "learning_rate": 0.001
  },
  {
    "episode": 2412,
    "reward": 89.246911,
    "length": 65,
    "time": 41073.670689,
    "actor_loss": -65.62313842773438,
    "critic_loss": 13.583572387695312,
    "ent_coef": 0.07949989289045334,
    "learning_rate": 0.001
  },
  {
    "episode": 2413,
    "reward": 78.491547,
    "length": 78,
    "time": 41086.939503,
    "actor_loss": -56.67637634277344,
    "critic_loss": 4.115029335021973,
    "ent_coef": 0.08815501630306244,
    "learning_rate": 0.001
  },
  {
    "episode": 2414,
    "reward": 90.005109,
    "length": 63,
    "time": 41098.868737,
    "actor_loss": -60.497596740722656,
    "critic_loss": 19.951866149902344,
    "ent_coef": 0.09020321816205978,
    "learning_rate": 0.001
  },
  {
    "episode": 2415,
    "reward": 78.693381,
    "length": 80,
    "time": 41114.050519,
    "actor_loss": -59.24437713623047,
    "critic_loss": 19.290958404541016,
    "ent_coef": 0.08577370643615723,
    "learning_rate": 0.001
  },
  {
    "episode": 2416,
    "reward": -270.19182,
    "length": 220,
    "time": 41145.233116,
    "actor_loss": -53.9968147277832,
    "critic_loss": 89.35804748535156,
    "ent_coef": 0.07505954802036285,
    "learning_rate": 0.001
  },
  {
    "episode": 2417,
    "reward": 108.399953,
    "length": 72,
    "time": 41159.537011,
    "actor_loss": -60.637516021728516,
    "critic_loss": 8.410916328430176,
    "ent_coef": 0.0771557092666626,
    "learning_rate": 0.001
  },
  {
    "episode": 2418,
    "reward": 79.524072,
    "length": 78,
    "time": 41172.76207,
    "actor_loss": -61.20097732543945,
    "critic_loss": 46.177310943603516,
    "ent_coef": 0.08188372850418091,
    "learning_rate": 0.001
  },
  {
    "episode": 2419,
    "reward": 88.521913,
    "length": 66,
    "time": 41185.920479,
    "actor_loss": -53.1190185546875,
    "critic_loss": 13.588913917541504,
    "ent_coef": 0.08379162102937698,
    "learning_rate": 0.001
  },
  {
    "episode": 2420,
    "reward": 88.229986,
    "length": 66,
    "time": 41197.553978,
    "actor_loss": -59.00811004638672,
    "critic_loss": 31.1033935546875,
    "ent_coef": 0.08768162131309509,
    "learning_rate": 0.001
  },
  {
    "episode": 2421,
    "reward": 89.820584,
    "length": 65,
    "time": 41210.397567,
    "actor_loss": -55.1389045715332,
    "critic_loss": 9.77896785736084,
    "ent_coef": 0.09135164320468903,
    "learning_rate": 0.001
  },
  {
    "episode": 2422,
    "reward": 90.037276,
    "length": 63,
    "time": 41224.198537,
    "actor_loss": -61.71216583251953,
    "critic_loss": 8.233470916748047,
    "ent_coef": 0.09693353623151779,
    "learning_rate": 0.001
  },
  {
    "episode": 2423,
    "reward": 89.257505,
    "length": 65,
    "time": 41235.743847,
    "actor_loss": -55.10406494140625,
    "critic_loss": 4.689225673675537,
    "ent_coef": 0.09409402310848236,
    "learning_rate": 0.001
  },
  {
    "episode": 2424,
    "reward": 85.490782,
    "length": 74,
    "time": 41252.196492,
    "actor_loss": -61.35749053955078,
    "critic_loss": 96.75047302246094,
    "ent_coef": 0.09013231843709946,
    "learning_rate": 0.001
  },
  {
    "episode": 2425,
    "reward": 86.788759,
    "length": 68,
    "time": 41267.089436,
    "actor_loss": -64.82133483886719,
    "critic_loss": 6.322929859161377,
    "ent_coef": 0.0926087498664856,
    "learning_rate": 0.001
  },
  {
    "episode": 2426,
    "reward": 88.805184,
    "length": 66,
    "time": 41278.767208,
    "actor_loss": -64.57158660888672,
    "critic_loss": 19.295366287231445,
    "ent_coef": 0.09176307171583176,
    "learning_rate": 0.001
  },
  {
    "episode": 2427,
    "reward": 86.261085,
    "length": 71,
    "time": 41293.843647,
    "actor_loss": -61.569156646728516,
    "critic_loss": 7.309609889984131,
    "ent_coef": 0.09138739854097366,
    "learning_rate": 0.001
  },
  {
    "episode": 2428,
    "reward": -176.003555,
    "length": 111,
    "time": 41314.496845,
    "actor_loss": -61.12554931640625,
    "critic_loss": 27.187618255615234,
    "ent_coef": 0.09240570664405823,
    "learning_rate": 0.001
  },
  {
    "episode": 2429,
    "reward": 99.643862,
    "length": 66,
    "time": 41326.231572,
    "actor_loss": -57.3404655456543,
    "critic_loss": 14.298351287841797,
    "ent_coef": 0.09183208644390106,
    "learning_rate": 0.001
  },
  {
    "episode": 2430,
    "reward": 88.242999,
    "length": 66,
    "time": 41341.781593,
    "actor_loss": -56.110801696777344,
    "critic_loss": 5.4957194328308105,
    "ent_coef": 0.09289306402206421,
    "learning_rate": 0.001
  },
  {
    "episode": 2431,
    "reward": 89.329773,
    "length": 65,
    "time": 41353.522098,
    "actor_loss": -58.54775619506836,
    "critic_loss": 13.370250701904297,
    "ent_coef": 0.09212256222963333,
    "learning_rate": 0.001
  },
  {
    "episode": 2432,
    "reward": 87.670922,
    "length": 69,
    "time": 41368.996658,
    "actor_loss": -65.18787384033203,
    "critic_loss": 25.46664047241211,
    "ent_coef": 0.09134116768836975,
    "learning_rate": 0.001
  },
  {
    "episode": 2433,
    "reward": 87.627396,
    "length": 67,
    "time": 41381.324224,
    "actor_loss": -64.07830810546875,
    "critic_loss": 14.456575393676758,
    "ent_coef": 0.09449783712625504,
    "learning_rate": 0.001
  },
  {
    "episode": 2434,
    "reward": 86.563017,
    "length": 69,
    "time": 41394.536637,
    "actor_loss": -57.119140625,
    "critic_loss": 6.791849613189697,
    "ent_coef": 0.10045816004276276,
    "learning_rate": 0.001
  },
  {
    "episode": 2435,
    "reward": 86.166161,
    "length": 70,
    "time": 41406.868593,
    "actor_loss": -58.80765914916992,
    "critic_loss": 48.368648529052734,
    "ent_coef": 0.09835727512836456,
    "learning_rate": 0.001
  },
  {
    "episode": 2436,
    "reward": 83.759273,
    "length": 76,
    "time": 41420.898876,
    "actor_loss": -64.03666687011719,
    "critic_loss": 13.647242546081543,
    "ent_coef": 0.0897514596581459,
    "learning_rate": 0.001
  },
  {
    "episode": 2437,
    "reward": 79.028584,
    "length": 82,
    "time": 41435.266365,
    "actor_loss": -65.5813980102539,
    "critic_loss": 9.699339866638184,
    "ent_coef": 0.08497849106788635,
    "learning_rate": 0.001
  },
  {
    "episode": 2438,
    "reward": 81.91155,
    "length": 78,
    "time": 41449.177969,
    "actor_loss": -60.56951904296875,
    "critic_loss": 6.163478851318359,
    "ent_coef": 0.07975687831640244,
    "learning_rate": 0.001
  },
  {
    "episode": 2439,
    "reward": 88.894212,
    "length": 67,
    "time": 41460.72619,
    "actor_loss": -63.16039276123047,
    "critic_loss": 3.6296372413635254,
    "ent_coef": 0.07667462527751923,
    "learning_rate": 0.001
  },
  {
    "episode": 2440,
    "reward": 87.455032,
    "length": 69,
    "time": 41474.23246,
    "actor_loss": -56.7545166015625,
    "critic_loss": 7.6507720947265625,
    "ent_coef": 0.07294546067714691,
    "learning_rate": 0.001
  },
  {
    "episode": 2441,
    "reward": 86.465447,
    "length": 69,
    "time": 41486.337695,
    "actor_loss": -57.912071228027344,
    "critic_loss": 9.117932319641113,
    "ent_coef": 0.07037566602230072,
    "learning_rate": 0.001
  },
  {
    "episode": 2442,
    "reward": 89.511498,
    "length": 65,
    "time": 41498.199497,
    "actor_loss": -56.20674514770508,
    "critic_loss": 141.0867156982422,
    "ent_coef": 0.06924497336149216,
    "learning_rate": 0.001
  },
  {
    "episode": 2443,
    "reward": 88.693605,
    "length": 65,
    "time": 41511.106714,
    "actor_loss": -55.202308654785156,
    "critic_loss": 8.35595989227295,
    "ent_coef": 0.07136166840791702,
    "learning_rate": 0.001
  },
  {
    "episode": 2444,
    "reward": 79.421647,
    "length": 80,
    "time": 41526.617621,
    "actor_loss": -60.878273010253906,
    "critic_loss": 4.2851243019104,
    "ent_coef": 0.0739842876791954,
    "learning_rate": 0.001
  },
  {
    "episode": 2445,
    "reward": 77.577579,
    "length": 89,
    "time": 41541.91357,
    "actor_loss": -61.443336486816406,
    "critic_loss": 4.700524806976318,
    "ent_coef": 0.0724979043006897,
    "learning_rate": 0.001
  },
  {
    "episode": 2446,
    "reward": 90.916652,
    "length": 62,
    "time": 41554.626567,
    "actor_loss": -62.503665924072266,
    "critic_loss": 15.091373443603516,
    "ent_coef": 0.07553722709417343,
    "learning_rate": 0.001
  },
  {
    "episode": 2447,
    "reward": 86.554032,
    "length": 71,
    "time": 41567.46983,
    "actor_loss": -61.07483673095703,
    "critic_loss": 41.601722717285156,
    "ent_coef": 0.0759831890463829,
    "learning_rate": 0.001
  },
  {
    "episode": 2448,
    "reward": 87.059358,
    "length": 67,
    "time": 41580.63008,
    "actor_loss": -62.92144775390625,
    "critic_loss": 61.464874267578125,
    "ent_coef": 0.0755251944065094,
    "learning_rate": 0.001
  },
  {
    "episode": 2449,
    "reward": 85.040749,
    "length": 73,
    "time": 41593.940801,
    "actor_loss": -54.76887512207031,
    "critic_loss": 14.059731483459473,
    "ent_coef": 0.07372988760471344,
    "learning_rate": 0.001
  },
  {
    "episode": 2450,
    "reward": 84.113156,
    "length": 74,
    "time": 41606.670413,
    "actor_loss": -63.29499816894531,
    "critic_loss": 4.994807243347168,
    "ent_coef": 0.07391374558210373,
    "learning_rate": 0.001
  },
  {
    "episode": 2451,
    "reward": 87.895712,
    "length": 68,
    "time": 41618.871687,
    "actor_loss": -65.6458511352539,
    "critic_loss": 6.273464202880859,
    "ent_coef": 0.07277952879667282,
    "learning_rate": 0.001
  },
  {
    "episode": 2452,
    "reward": 72.475155,
    "length": 87,
    "time": 41635.329761,
    "actor_loss": -56.4434928894043,
    "critic_loss": 12.619184494018555,
    "ent_coef": 0.07252974808216095,
    "learning_rate": 0.001
  },
  {
    "episode": 2453,
    "reward": 84.434712,
    "length": 73,
    "time": 41649.868858,
    "actor_loss": -59.60553741455078,
    "critic_loss": 6.1193928718566895,
    "ent_coef": 0.07297805696725845,
    "learning_rate": 0.001
  },
  {
    "episode": 2454,
    "reward": 90.79789,
    "length": 62,
    "time": 41660.794936,
    "actor_loss": -62.020240783691406,
    "critic_loss": 22.928966522216797,
    "ent_coef": 0.07773571461439133,
    "learning_rate": 0.001
  },
  {
    "episode": 2455,
    "reward": 85.863348,
    "length": 71,
    "time": 41675.56693,
    "actor_loss": -66.07486724853516,
    "critic_loss": 4.741427421569824,
    "ent_coef": 0.08046431094408035,
    "learning_rate": 0.001
  },
  {
    "episode": 2456,
    "reward": 89.412428,
    "length": 65,
    "time": 41692.911937,
    "actor_loss": -63.196842193603516,
    "critic_loss": 6.628589153289795,
    "ent_coef": 0.08059234917163849,
    "learning_rate": 0.001
  },
  {
    "episode": 2457,
    "reward": 85.259917,
    "length": 70,
    "time": 41705.204131,
    "actor_loss": -57.79954528808594,
    "critic_loss": 19.48401641845703,
    "ent_coef": 0.08141417056322098,
    "learning_rate": 0.001
  },
  {
    "episode": 2458,
    "reward": 85.587509,
    "length": 70,
    "time": 41717.272368,
    "actor_loss": -58.75734329223633,
    "critic_loss": 27.30575942993164,
    "ent_coef": 0.08159220963716507,
    "learning_rate": 0.001
  },
  {
    "episode": 2459,
    "reward": 89.814202,
    "length": 63,
    "time": 41729.311236,
    "actor_loss": -55.6518669128418,
    "critic_loss": 58.49665451049805,
    "ent_coef": 0.08309867978096008,
    "learning_rate": 0.001
  },
  {
    "episode": 2460,
    "reward": 87.553707,
    "length": 67,
    "time": 41741.006726,
    "actor_loss": -58.485679626464844,
    "critic_loss": 12.079377174377441,
    "ent_coef": 0.08152059465646744,
    "learning_rate": 0.001
  },
  {
    "episode": 2461,
    "reward": 85.260832,
    "length": 70,
    "time": 41753.204911,
    "actor_loss": -60.13923645019531,
    "critic_loss": 10.036952018737793,
    "ent_coef": 0.08181778341531754,
    "learning_rate": 0.001
  },
  {
    "episode": 2462,
    "reward": 77.410957,
    "length": 80,
    "time": 41769.508729,
    "actor_loss": -62.20356750488281,
    "critic_loss": 27.98040771484375,
    "ent_coef": 0.0858856812119484,
    "learning_rate": 0.001
  },
  {
    "episode": 2463,
    "reward": 87.874567,
    "length": 68,
    "time": 41782.054318,
    "actor_loss": -58.80072021484375,
    "critic_loss": 26.694599151611328,
    "ent_coef": 0.08459915220737457,
    "learning_rate": 0.001
  },
  {
    "episode": 2464,
    "reward": 79.87359,
    "length": 81,
    "time": 41795.720949,
    "actor_loss": -60.232723236083984,
    "critic_loss": 123.54708099365234,
    "ent_coef": 0.08215583860874176,
    "learning_rate": 0.001
  },
  {
    "episode": 2465,
    "reward": 88.764465,
    "length": 66,
    "time": 41807.893322,
    "actor_loss": -60.67778778076172,
    "critic_loss": 6.917734622955322,
    "ent_coef": 0.08157355338335037,
    "learning_rate": 0.001
  },
  {
    "episode": 2466,
    "reward": 83.050516,
    "length": 73,
    "time": 41820.244759,
    "actor_loss": -66.37955474853516,
    "critic_loss": 5.0484771728515625,
    "ent_coef": 0.07905331999063492,
    "learning_rate": 0.001
  },
  {
    "episode": 2467,
    "reward": 88.957514,
    "length": 65,
    "time": 41833.47527,
    "actor_loss": -61.084686279296875,
    "critic_loss": 12.22792911529541,
    "ent_coef": 0.08459936082363129,
    "learning_rate": 0.001
  },
  {
    "episode": 2468,
    "reward": 88.360815,
    "length": 67,
    "time": 41845.463953,
    "actor_loss": -57.883758544921875,
    "critic_loss": 48.31865692138672,
    "ent_coef": 0.08620636910200119,
    "learning_rate": 0.001
  },
  {
    "episode": 2469,
    "reward": 86.817837,
    "length": 67,
    "time": 41857.307548,
    "actor_loss": -59.887123107910156,
    "critic_loss": 21.33856201171875,
    "ent_coef": 0.08663966506719589,
    "learning_rate": 0.001
  },
  {
    "episode": 2470,
    "reward": 81.188719,
    "length": 77,
    "time": 41870.772036,
    "actor_loss": -58.798301696777344,
    "critic_loss": 10.729413986206055,
    "ent_coef": 0.08892495930194855,
    "learning_rate": 0.001
  },
  {
    "episode": 2471,
    "reward": 83.494482,
    "length": 74,
    "time": 41883.506045,
    "actor_loss": -62.527923583984375,
    "critic_loss": 2.7768964767456055,
    "ent_coef": 0.08335163444280624,
    "learning_rate": 0.001
  },
  {
    "episode": 2472,
    "reward": 87.534939,
    "length": 68,
    "time": 41897.169306,
    "actor_loss": -60.62725067138672,
    "critic_loss": 6.4984846115112305,
    "ent_coef": 0.081624835729599,
    "learning_rate": 0.001
  },
  {
    "episode": 2473,
    "reward": 86.24645,
    "length": 70,
    "time": 41909.282496,
    "actor_loss": -60.13007736206055,
    "critic_loss": 8.271780014038086,
    "ent_coef": 0.07784827053546906,
    "learning_rate": 0.001
  },
  {
    "episode": 2474,
    "reward": 88.453746,
    "length": 67,
    "time": 41922.635645,
    "actor_loss": -59.98138427734375,
    "critic_loss": 16.250526428222656,
    "ent_coef": 0.08022679388523102,
    "learning_rate": 0.001
  },
  {
    "episode": 2475,
    "reward": 89.152427,
    "length": 64,
    "time": 41936.872268,
    "actor_loss": -70.48936462402344,
    "critic_loss": 9.912607192993164,
    "ent_coef": 0.08467591553926468,
    "learning_rate": 0.001
  },
  {
    "episode": 2476,
    "reward": 86.690924,
    "length": 69,
    "time": 41950.316524,
    "actor_loss": -66.72181701660156,
    "critic_loss": 3.985569477081299,
    "ent_coef": 0.08460139483213425,
    "learning_rate": 0.001
  },
  {
    "episode": 2477,
    "reward": 87.486826,
    "length": 68,
    "time": 41961.892474,
    "actor_loss": -56.17982864379883,
    "critic_loss": 17.0151424407959,
    "ent_coef": 0.08469242602586746,
    "learning_rate": 0.001
  },
  {
    "episode": 2478,
    "reward": 76.857972,
    "length": 84,
    "time": 41975.579782,
    "actor_loss": -65.85661315917969,
    "critic_loss": 6.653013229370117,
    "ent_coef": 0.08336184918880463,
    "learning_rate": 0.001
  },
  {
    "episode": 2479,
    "reward": 82.543019,
    "length": 77,
    "time": 41989.791954,
    "actor_loss": -63.96694564819336,
    "critic_loss": 77.28366088867188,
    "ent_coef": 0.07913323491811752,
    "learning_rate": 0.001
  },
  {
    "episode": 2480,
    "reward": 72.692886,
    "length": 90,
    "time": 42004.525474,
    "actor_loss": -57.196258544921875,
    "critic_loss": 33.52507781982422,
    "ent_coef": 0.07788408547639847,
    "learning_rate": 0.001
  },
  {
    "episode": 2481,
    "reward": 89.778465,
    "length": 63,
    "time": 42017.817254,
    "actor_loss": -64.74037170410156,
    "critic_loss": 44.31653594970703,
    "ent_coef": 0.0832899883389473,
    "learning_rate": 0.001
  },
  {
    "episode": 2482,
    "reward": 90.960463,
    "length": 62,
    "time": 42029.690746,
    "actor_loss": -63.78266143798828,
    "critic_loss": 16.410736083984375,
    "ent_coef": 0.0889056921005249,
    "learning_rate": 0.001
  },
  {
    "episode": 2483,
    "reward": 87.561353,
    "length": 67,
    "time": 42043.955193,
    "actor_loss": -63.25828552246094,
    "critic_loss": 5.478447914123535,
    "ent_coef": 0.08848177641630173,
    "learning_rate": 0.001
  },
  {
    "episode": 2484,
    "reward": 87.541334,
    "length": 70,
    "time": 42057.86039,
    "actor_loss": -57.042686462402344,
    "critic_loss": 30.079158782958984,
    "ent_coef": 0.08746720850467682,
    "learning_rate": 0.001
  },
  {
    "episode": 2485,
    "reward": 88.375011,
    "length": 66,
    "time": 42069.44289,
    "actor_loss": -62.58972930908203,
    "critic_loss": 14.372705459594727,
    "ent_coef": 0.08938330411911011,
    "learning_rate": 0.001
  },
  {
    "episode": 2486,
    "reward": 85.971677,
    "length": 72,
    "time": 42084.879733,
    "actor_loss": -58.567100524902344,
    "critic_loss": 78.41523742675781,
    "ent_coef": 0.09189093858003616,
    "learning_rate": 0.001
  },
  {
    "episode": 2487,
    "reward": 84.834578,
    "length": 72,
    "time": 42097.37049,
    "actor_loss": -57.088260650634766,
    "critic_loss": 17.502620697021484,
    "ent_coef": 0.09505534172058105,
    "learning_rate": 0.001
  },
  {
    "episode": 2488,
    "reward": 90.600555,
    "length": 64,
    "time": 42110.81697,
    "actor_loss": -60.000640869140625,
    "critic_loss": 15.57443618774414,
    "ent_coef": 0.09903104603290558,
    "learning_rate": 0.001
  },
  {
    "episode": 2489,
    "reward": 88.512384,
    "length": 65,
    "time": 42122.908603,
    "actor_loss": -62.72052001953125,
    "critic_loss": 46.781883239746094,
    "ent_coef": 0.09889428317546844,
    "learning_rate": 0.001
  },
  {
    "episode": 2490,
    "reward": 88.299221,
    "length": 66,
    "time": 42135.483404,
    "actor_loss": -63.417903900146484,
    "critic_loss": 10.276050567626953,
    "ent_coef": 0.09479095786809921,
    "learning_rate": 0.001
  },
  {
    "episode": 2491,
    "reward": 86.68392,
    "length": 70,
    "time": 42150.688738,
    "actor_loss": -57.36457824707031,
    "critic_loss": 69.01023864746094,
    "ent_coef": 0.08784875273704529,
    "learning_rate": 0.001
  },
  {
    "episode": 2492,
    "reward": 88.860735,
    "length": 66,
    "time": 42163.622821,
    "actor_loss": -61.4267463684082,
    "critic_loss": 18.022254943847656,
    "ent_coef": 0.08801103383302689,
    "learning_rate": 0.001
  },
  {
    "episode": 2493,
    "reward": 82.743604,
    "length": 77,
    "time": 42184.187496,
    "actor_loss": -64.1765365600586,
    "critic_loss": 16.25521469116211,
    "ent_coef": 0.08699081838130951,
    "learning_rate": 0.001
  },
  {
    "episode": 2494,
    "reward": 89.773146,
    "length": 65,
    "time": 42196.582826,
    "actor_loss": -54.80537414550781,
    "critic_loss": 5.357394218444824,
    "ent_coef": 0.09107165783643723,
    "learning_rate": 0.001
  },
  {
    "episode": 2495,
    "reward": 87.927927,
    "length": 68,
    "time": 42208.47734,
    "actor_loss": -62.18658447265625,
    "critic_loss": 16.737136840820312,
    "ent_coef": 0.08952824771404266,
    "learning_rate": 0.001
  },
  {
    "episode": 2496,
    "reward": 83.034599,
    "length": 75,
    "time": 42224.048588,
    "actor_loss": -57.39916229248047,
    "critic_loss": 7.111330032348633,
    "ent_coef": 0.08712124824523926,
    "learning_rate": 0.001
  },
  {
    "episode": 2497,
    "reward": 89.685797,
    "length": 64,
    "time": 42235.292395,
    "actor_loss": -61.389793395996094,
    "critic_loss": 2.8568856716156006,
    "ent_coef": 0.08880213648080826,
    "learning_rate": 0.001
  },
  {
    "episode": 2498,
    "reward": 83.111194,
    "length": 75,
    "time": 42248.042159,
    "actor_loss": -64.41941833496094,
    "critic_loss": 34.11621856689453,
    "ent_coef": 0.08741215616464615,
    "learning_rate": 0.001
  },
  {
    "episode": 2499,
    "reward": 81.911009,
    "length": 77,
    "time": 42262.749763,
    "actor_loss": -65.8201904296875,
    "critic_loss": 2.0363941192626953,
    "ent_coef": 0.08599799126386642,
    "learning_rate": 0.001
  },
  {
    "episode": 2500,
    "reward": 86.309149,
    "length": 72,
    "time": 42275.278656,
    "actor_loss": -60.92725372314453,
    "critic_loss": 16.06532096862793,
    "ent_coef": 0.08404946327209473,
    "learning_rate": 0.001
  },
  {
    "episode": 2501,
    "reward": 89.138623,
    "length": 64,
    "time": 42287.869735,
    "actor_loss": -55.95085906982422,
    "critic_loss": 6.268288612365723,
    "ent_coef": 0.08645845949649811,
    "learning_rate": 0.001
  },
  {
    "episode": 2502,
    "reward": 90.454832,
    "length": 62,
    "time": 42300.879937,
    "actor_loss": -60.377174377441406,
    "critic_loss": 2.7230312824249268,
    "ent_coef": 0.08818068355321884,
    "learning_rate": 0.001
  },
  {
    "episode": 2503,
    "reward": 87.769371,
    "length": 69,
    "time": 42313.882007,
    "actor_loss": -66.32575988769531,
    "critic_loss": 11.314605712890625,
    "ent_coef": 0.08699703216552734,
    "learning_rate": 0.001
  },
  {
    "episode": 2504,
    "reward": 86.886801,
    "length": 69,
    "time": 42326.590505,
    "actor_loss": -58.78868865966797,
    "critic_loss": 31.392993927001953,
    "ent_coef": 0.09027324616909027,
    "learning_rate": 0.001
  },
  {
    "episode": 2505,
    "reward": 88.30678,
    "length": 66,
    "time": 42339.029616,
    "actor_loss": -62.022865295410156,
    "critic_loss": 26.465763092041016,
    "ent_coef": 0.09416642040014267,
    "learning_rate": 0.001
  },
  {
    "episode": 2506,
    "reward": 83.089455,
    "length": 75,
    "time": 42353.056147,
    "actor_loss": -54.75312423706055,
    "critic_loss": 5.434696197509766,
    "ent_coef": 0.08984998613595963,
    "learning_rate": 0.001
  },
  {
    "episode": 2507,
    "reward": 82.959306,
    "length": 75,
    "time": 42367.188083,
    "actor_loss": -59.86189270019531,
    "critic_loss": 131.06326293945312,
    "ent_coef": 0.0872889906167984,
    "learning_rate": 0.001
  },
  {
    "episode": 2508,
    "reward": 86.765686,
    "length": 69,
    "time": 42379.29285,
    "actor_loss": -56.66746520996094,
    "critic_loss": 99.149658203125,
    "ent_coef": 0.08444429188966751,
    "learning_rate": 0.001
  },
  {
    "episode": 2509,
    "reward": 91.645627,
    "length": 60,
    "time": 42393.84138,
    "actor_loss": -58.34742736816406,
    "critic_loss": 6.547308444976807,
    "ent_coef": 0.09192444384098053,
    "learning_rate": 0.001
  },
  {
    "episode": 2510,
    "reward": 84.044537,
    "length": 75,
    "time": 42410.90494,
    "actor_loss": -68.50634002685547,
    "critic_loss": 39.44303894042969,
    "ent_coef": 0.09289882332086563,
    "learning_rate": 0.001
  },
  {
    "episode": 2511,
    "reward": 78.182179,
    "length": 86,
    "time": 42425.089281,
    "actor_loss": -64.28709411621094,
    "critic_loss": 11.962895393371582,
    "ent_coef": 0.08979225158691406,
    "learning_rate": 0.001
  },
  {
    "episode": 2512,
    "reward": 84.824208,
    "length": 72,
    "time": 42437.63699,
    "actor_loss": -60.324459075927734,
    "critic_loss": 14.058886528015137,
    "ent_coef": 0.0891936719417572,
    "learning_rate": 0.001
  },
  {
    "episode": 2513,
    "reward": -220.176195,
    "length": 189,
    "time": 42465.594325,
    "actor_loss": -60.21097946166992,
    "critic_loss": 6.013620376586914,
    "ent_coef": 0.08199519664049149,
    "learning_rate": 0.001
  },
  {
    "episode": 2514,
    "reward": 96.850633,
    "length": 70,
    "time": 42478.176016,
    "actor_loss": -62.40005874633789,
    "critic_loss": 15.336502075195312,
    "ent_coef": 0.08584199100732803,
    "learning_rate": 0.001
  },
  {
    "episode": 2515,
    "reward": 89.563312,
    "length": 64,
    "time": 42490.539173,
    "actor_loss": -60.23997116088867,
    "critic_loss": 39.23408889770508,
    "ent_coef": 0.08913561701774597,
    "learning_rate": 0.001
  },
  {
    "episode": 2516,
    "reward": 77.715267,
    "length": 88,
    "time": 42509.046035,
    "actor_loss": -62.815086364746094,
    "critic_loss": 11.591926574707031,
    "ent_coef": 0.08466879278421402,
    "learning_rate": 0.001
  },
  {
    "episode": 2517,
    "reward": 79.273803,
    "length": 86,
    "time": 42523.413429,
    "actor_loss": -63.04350280761719,
    "critic_loss": 11.420181274414062,
    "ent_coef": 0.08452989906072617,
    "learning_rate": 0.001
  },
  {
    "episode": 2518,
    "reward": 75.649892,
    "length": 93,
    "time": 42541.442786,
    "actor_loss": -56.506591796875,
    "critic_loss": 4.627225875854492,
    "ent_coef": 0.08452323079109192,
    "learning_rate": 0.001
  },
  {
    "episode": 2519,
    "reward": 65.101244,
    "length": 115,
    "time": 42563.016794,
    "actor_loss": -58.8079719543457,
    "critic_loss": 11.216585159301758,
    "ent_coef": 0.08747434616088867,
    "learning_rate": 0.001
  },
  {
    "episode": 2520,
    "reward": 66.537396,
    "length": 115,
    "time": 42582.508362,
    "actor_loss": -60.655757904052734,
    "critic_loss": 2.533202886581421,
    "ent_coef": 0.08751963078975677,
    "learning_rate": 0.001
  },
  {
    "episode": 2521,
    "reward": 73.489983,
    "length": 101,
    "time": 42603.670979,
    "actor_loss": -58.38393783569336,
    "critic_loss": 9.034318923950195,
    "ent_coef": 0.0846545547246933,
    "learning_rate": 0.001
  },
  {
    "episode": 2522,
    "reward": 81.876274,
    "length": 77,
    "time": 42618.295014,
    "actor_loss": -59.28150177001953,
    "critic_loss": 10.029006004333496,
    "ent_coef": 0.086171455681324,
    "learning_rate": 0.001
  },
  {
    "episode": 2523,
    "reward": 88.86477,
    "length": 66,
    "time": 42631.218636,
    "actor_loss": -63.84147644042969,
    "critic_loss": 11.715030670166016,
    "ent_coef": 0.08949828892946243,
    "learning_rate": 0.001
  },
  {
    "episode": 2524,
    "reward": 76.153657,
    "length": 90,
    "time": 42645.915939,
    "actor_loss": -58.258182525634766,
    "critic_loss": 5.400195121765137,
    "ent_coef": 0.08570346981287003,
    "learning_rate": 0.001
  },
  {
    "episode": 2525,
    "reward": 83.499372,
    "length": 73,
    "time": 42659.684204,
    "actor_loss": -61.950843811035156,
    "critic_loss": 3.950366258621216,
    "ent_coef": 0.08731646835803986,
    "learning_rate": 0.001
  },
  {
    "episode": 2526,
    "reward": 86.139659,
    "length": 70,
    "time": 42671.766199,
    "actor_loss": -62.70323181152344,
    "critic_loss": 61.64350128173828,
    "ent_coef": 0.08903132379055023,
    "learning_rate": 0.001
  },
  {
    "episode": 2527,
    "reward": 48.811485,
    "length": 119,
    "time": 42692.579376,
    "actor_loss": -62.825557708740234,
    "critic_loss": 3.9111642837524414,
    "ent_coef": 0.08531151711940765,
    "learning_rate": 0.001
  },
  {
    "episode": 2528,
    "reward": 83.981195,
    "length": 74,
    "time": 42706.08912,
    "actor_loss": -60.46269989013672,
    "critic_loss": 8.748363494873047,
    "ent_coef": 0.08667223155498505,
    "learning_rate": 0.001
  },
  {
    "episode": 2529,
    "reward": 83.214166,
    "length": 74,
    "time": 42722.575832,
    "actor_loss": -63.43727493286133,
    "critic_loss": 7.28810977935791,
    "ent_coef": 0.0926673486828804,
    "learning_rate": 0.001
  },
  {
    "episode": 2530,
    "reward": 83.160672,
    "length": 79,
    "time": 42736.737716,
    "actor_loss": -62.81890106201172,
    "critic_loss": 92.8675308227539,
    "ent_coef": 0.095168836414814,
    "learning_rate": 0.001
  },
  {
    "episode": 2531,
    "reward": 45.873654,
    "length": 158,
    "time": 42762.111871,
    "actor_loss": -66.61554718017578,
    "critic_loss": 11.868297576904297,
    "ent_coef": 0.09453414380550385,
    "learning_rate": 0.001
  },
  {
    "episode": 2532,
    "reward": 87.353368,
    "length": 71,
    "time": 42775.43378,
    "actor_loss": -59.7200927734375,
    "critic_loss": 5.592502593994141,
    "ent_coef": 0.099611796438694,
    "learning_rate": 0.001
  },
  {
    "episode": 2533,
    "reward": 78.243022,
    "length": 87,
    "time": 42790.721752,
    "actor_loss": -56.34577178955078,
    "critic_loss": 7.710939407348633,
    "ent_coef": 0.09557086229324341,
    "learning_rate": 0.001
  },
  {
    "episode": 2534,
    "reward": -159.535532,
    "length": 157,
    "time": 42815.052103,
    "actor_loss": -61.82209014892578,
    "critic_loss": 26.323444366455078,
    "ent_coef": 0.1018826887011528,
    "learning_rate": 0.001
  },
  {
    "episode": 2535,
    "reward": 83.660975,
    "length": 75,
    "time": 42828.867603,
    "actor_loss": -63.044681549072266,
    "critic_loss": 83.79145812988281,
    "ent_coef": 0.10132735222578049,
    "learning_rate": 0.001
  },
  {
    "episode": 2536,
    "reward": 60.072651,
    "length": 129,
    "time": 42849.566812,
    "actor_loss": -60.55480194091797,
    "critic_loss": 7.32712459564209,
    "ent_coef": 0.09987447410821915,
    "learning_rate": 0.001
  },
  {
    "episode": 2537,
    "reward": 76.657793,
    "length": 79,
    "time": 42863.707399,
    "actor_loss": -59.881927490234375,
    "critic_loss": 712.36083984375,
    "ent_coef": 0.10595733672380447,
    "learning_rate": 0.001
  },
  {
    "episode": 2538,
    "reward": 80.478792,
    "length": 83,
    "time": 42879.944322,
    "actor_loss": -64.4449691772461,
    "critic_loss": 57.872406005859375,
    "ent_coef": 0.10309939086437225,
    "learning_rate": 0.001
  },
  {
    "episode": 2539,
    "reward": 84.506491,
    "length": 74,
    "time": 42894.326533,
    "actor_loss": -62.8980712890625,
    "critic_loss": 2.7645397186279297,
    "ent_coef": 0.10139542818069458,
    "learning_rate": 0.001
  },
  {
    "episode": 2540,
    "reward": 88.433503,
    "length": 67,
    "time": 42908.160534,
    "actor_loss": -59.899635314941406,
    "critic_loss": 4.094226360321045,
    "ent_coef": 0.10597951710224152,
    "learning_rate": 0.001
  },
  {
    "episode": 2541,
    "reward": 82.09878,
    "length": 80,
    "time": 42923.673694,
    "actor_loss": -67.18901062011719,
    "critic_loss": 24.784809112548828,
    "ent_coef": 0.10118715465068817,
    "learning_rate": 0.001
  },
  {
    "episode": 2542,
    "reward": 82.887649,
    "length": 74,
    "time": 42936.387569,
    "actor_loss": -63.45808410644531,
    "critic_loss": 7.6500349044799805,
    "ent_coef": 0.10292211174964905,
    "learning_rate": 0.001
  },
  {
    "episode": 2543,
    "reward": 81.344692,
    "length": 80,
    "time": 42949.946739,
    "actor_loss": -57.604618072509766,
    "critic_loss": 2.5744924545288086,
    "ent_coef": 0.10955613106489182,
    "learning_rate": 0.001
  },
  {
    "episode": 2544,
    "reward": 87.127849,
    "length": 67,
    "time": 42961.530132,
    "actor_loss": -62.63753128051758,
    "critic_loss": 24.086902618408203,
    "ent_coef": 0.11352487653493881,
    "learning_rate": 0.001
  },
  {
    "episode": 2545,
    "reward": 86.230607,
    "length": 71,
    "time": 42976.583892,
    "actor_loss": -61.94662857055664,
    "critic_loss": 7.949432373046875,
    "ent_coef": 0.1124233677983284,
    "learning_rate": 0.001
  },
  {
    "episode": 2546,
    "reward": 82.456838,
    "length": 78,
    "time": 42989.763838,
    "actor_loss": -61.223636627197266,
    "critic_loss": 12.262815475463867,
    "ent_coef": 0.10548563301563263,
    "learning_rate": 0.001
  },
  {
    "episode": 2547,
    "reward": 68.217292,
    "length": 110,
    "time": 43009.432695,
    "actor_loss": -56.06513977050781,
    "critic_loss": 12.522879600524902,
    "ent_coef": 0.1024133637547493,
    "learning_rate": 0.001
  },
  {
    "episode": 2548,
    "reward": 86.380458,
    "length": 71,
    "time": 43021.830402,
    "actor_loss": -62.319271087646484,
    "critic_loss": 32.51133728027344,
    "ent_coef": 0.09842099249362946,
    "learning_rate": 0.001
  },
  {
    "episode": 2549,
    "reward": 84.39739,
    "length": 76,
    "time": 43037.946322,
    "actor_loss": -63.118309020996094,
    "critic_loss": 5.9999518394470215,
    "ent_coef": 0.09598903357982635,
    "learning_rate": 0.001
  },
  {
    "episode": 2550,
    "reward": 84.460159,
    "length": 74,
    "time": 43050.985898,
    "actor_loss": -55.66961669921875,
    "critic_loss": 62.32242202758789,
    "ent_coef": 0.09603367000818253,
    "learning_rate": 0.001
  },
  {
    "episode": 2551,
    "reward": 82.971094,
    "length": 79,
    "time": 43068.308462,
    "actor_loss": -66.02391052246094,
    "critic_loss": 60.35151672363281,
    "ent_coef": 0.09651291370391846,
    "learning_rate": 0.001
  },
  {
    "episode": 2552,
    "reward": 91.950542,
    "length": 60,
    "time": 43079.643926,
    "actor_loss": -58.62040328979492,
    "critic_loss": 4.569617748260498,
    "ent_coef": 0.10191240161657333,
    "learning_rate": 0.001
  },
  {
    "episode": 2553,
    "reward": 88.471126,
    "length": 67,
    "time": 43093.868428,
    "actor_loss": -60.56104278564453,
    "critic_loss": 6.7860026359558105,
    "ent_coef": 0.10323304682970047,
    "learning_rate": 0.001
  },
  {
    "episode": 2554,
    "reward": 85.446389,
    "length": 72,
    "time": 43109.307177,
    "actor_loss": -64.62210083007812,
    "critic_loss": 23.88080596923828,
    "ent_coef": 0.1020316556096077,
    "learning_rate": 0.001
  },
  {
    "episode": 2555,
    "reward": 86.81514,
    "length": 69,
    "time": 43122.400059,
    "actor_loss": -59.86016845703125,
    "critic_loss": 12.023927688598633,
    "ent_coef": 0.10069935023784637,
    "learning_rate": 0.001
  },
  {
    "episode": 2556,
    "reward": 83.114033,
    "length": 77,
    "time": 43137.210892,
    "actor_loss": -60.12879180908203,
    "critic_loss": 8.99770736694336,
    "ent_coef": 0.09543642401695251,
    "learning_rate": 0.001
  },
  {
    "episode": 2557,
    "reward": 88.367365,
    "length": 66,
    "time": 43148.979966,
    "actor_loss": -58.46223068237305,
    "critic_loss": 6.623736381530762,
    "ent_coef": 0.0954977497458458,
    "learning_rate": 0.001
  },
  {
    "episode": 2558,
    "reward": 88.908339,
    "length": 65,
    "time": 43162.570923,
    "actor_loss": -59.315731048583984,
    "critic_loss": 4.959357261657715,
    "ent_coef": 0.09771201014518738,
    "learning_rate": 0.001
  },
  {
    "episode": 2559,
    "reward": 89.344713,
    "length": 64,
    "time": 43175.60679,
    "actor_loss": -61.79621887207031,
    "critic_loss": 6.692117214202881,
    "ent_coef": 0.10187173634767532,
    "learning_rate": 0.001
  },
  {
    "episode": 2560,
    "reward": 88.603117,
    "length": 65,
    "time": 43188.006698,
    "actor_loss": -66.64955139160156,
    "critic_loss": 8.11501693725586,
    "ent_coef": 0.10087966918945312,
    "learning_rate": 0.001
  },
  {
    "episode": 2561,
    "reward": 82.915107,
    "length": 78,
    "time": 43202.538152,
    "actor_loss": -63.4182014465332,
    "critic_loss": 25.60073471069336,
    "ent_coef": 0.09699614346027374,
    "learning_rate": 0.001
  },
  {
    "episode": 2562,
    "reward": 78.748004,
    "length": 82,
    "time": 43216.309769,
    "actor_loss": -69.84271240234375,
    "critic_loss": 3.49580454826355,
    "ent_coef": 0.09746494144201279,
    "learning_rate": 0.001
  },
  {
    "episode": 2563,
    "reward": 89.492831,
    "length": 64,
    "time": 43229.634806,
    "actor_loss": -59.511131286621094,
    "critic_loss": 28.15017318725586,
    "ent_coef": 0.10139717161655426,
    "learning_rate": 0.001
  },
  {
    "episode": 2564,
    "reward": 86.789727,
    "length": 71,
    "time": 43243.858245,
    "actor_loss": -62.98276901245117,
    "critic_loss": 10.488463401794434,
    "ent_coef": 0.10025732219219208,
    "learning_rate": 0.001
  },
  {
    "episode": 2565,
    "reward": 84.171328,
    "length": 74,
    "time": 43259.700575,
    "actor_loss": -63.00383377075195,
    "critic_loss": 6.879497528076172,
    "ent_coef": 0.09648545831441879,
    "learning_rate": 0.001
  },
  {
    "episode": 2566,
    "reward": 82.707595,
    "length": 81,
    "time": 43273.06552,
    "actor_loss": -57.50696563720703,
    "critic_loss": 4.439023971557617,
    "ent_coef": 0.10121703892946243,
    "learning_rate": 0.001
  },
  {
    "episode": 2567,
    "reward": 86.489905,
    "length": 73,
    "time": 43286.690044,
    "actor_loss": -57.980804443359375,
    "critic_loss": 37.23565673828125,
    "ent_coef": 0.10579948127269745,
    "learning_rate": 0.001
  },
  {
    "episode": 2568,
    "reward": 89.363906,
    "length": 64,
    "time": 43298.882487,
    "actor_loss": -61.012535095214844,
    "critic_loss": 12.338844299316406,
    "ent_coef": 0.10787168890237808,
    "learning_rate": 0.001
  },
  {
    "episode": 2569,
    "reward": 86.265162,
    "length": 70,
    "time": 43312.073188,
    "actor_loss": -58.961891174316406,
    "critic_loss": 7.62338924407959,
    "ent_coef": 0.10860302299261093,
    "learning_rate": 0.001
  },
  {
    "episode": 2570,
    "reward": 90.250529,
    "length": 62,
    "time": 43324.093395,
    "actor_loss": -60.939414978027344,
    "critic_loss": 179.79258728027344,
    "ent_coef": 0.11208449304103851,
    "learning_rate": 0.001
  },
  {
    "episode": 2571,
    "reward": 86.987393,
    "length": 70,
    "time": 43338.649224,
    "actor_loss": -64.58053588867188,
    "critic_loss": 3.381685495376587,
    "ent_coef": 0.10649117082357407,
    "learning_rate": 0.001
  },
  {
    "episode": 2572,
    "reward": 88.243729,
    "length": 66,
    "time": 43350.994532,
    "actor_loss": -59.32417297363281,
    "critic_loss": 48.35706329345703,
    "ent_coef": 0.10214298963546753,
    "learning_rate": 0.001
  },
  {
    "episode": 2573,
    "reward": 79.47721,
    "length": 82,
    "time": 43365.442595,
    "actor_loss": -59.88157272338867,
    "critic_loss": 69.9583740234375,
    "ent_coef": 0.09725403040647507,
    "learning_rate": 0.001
  },
  {
    "episode": 2574,
    "reward": 87.117971,
    "length": 70,
    "time": 43380.673336,
    "actor_loss": -56.32744598388672,
    "critic_loss": 67.31262969970703,
    "ent_coef": 0.09638675302267075,
    "learning_rate": 0.001
  },
  {
    "episode": 2575,
    "reward": 88.932023,
    "length": 64,
    "time": 43393.456872,
    "actor_loss": -65.5144271850586,
    "critic_loss": 3.7329154014587402,
    "ent_coef": 0.09883402287960052,
    "learning_rate": 0.001
  },
  {
    "episode": 2576,
    "reward": 87.299091,
    "length": 69,
    "time": 43405.238415,
    "actor_loss": -60.729148864746094,
    "critic_loss": 6.012767791748047,
    "ent_coef": 0.0974106714129448,
    "learning_rate": 0.001
  },
  {
    "episode": 2577,
    "reward": 85.915487,
    "length": 70,
    "time": 43417.239474,
    "actor_loss": -63.30318069458008,
    "critic_loss": 3.0057687759399414,
    "ent_coef": 0.0964018777012825,
    "learning_rate": 0.001
  },
  {
    "episode": 2578,
    "reward": 87.995038,
    "length": 68,
    "time": 43429.041656,
    "actor_loss": -57.9122314453125,
    "critic_loss": 5.9344563484191895,
    "ent_coef": 0.09603078663349152,
    "learning_rate": 0.001
  },
  {
    "episode": 2579,
    "reward": 89.801762,
    "length": 65,
    "time": 43440.725088,
    "actor_loss": -61.62592315673828,
    "critic_loss": 34.34297561645508,
    "ent_coef": 0.10033512860536575,
    "learning_rate": 0.001
  },
  {
    "episode": 2580,
    "reward": 84.888892,
    "length": 73,
    "time": 43454.734124,
    "actor_loss": -58.92352294921875,
    "critic_loss": 3.4232444763183594,
    "ent_coef": 0.10100330412387848,
    "learning_rate": 0.001
  },
  {
    "episode": 2581,
    "reward": 87.955387,
    "length": 68,
    "time": 43467.839998,
    "actor_loss": -66.46131896972656,
    "critic_loss": 6.599349021911621,
    "ent_coef": 0.1001993715763092,
    "learning_rate": 0.001
  },
  {
    "episode": 2582,
    "reward": 90.697223,
    "length": 62,
    "time": 43486.294973,
    "actor_loss": -67.15098571777344,
    "critic_loss": 10.746623992919922,
    "ent_coef": 0.10104936361312866,
    "learning_rate": 0.001
  },
  {
    "episode": 2583,
    "reward": 83.525122,
    "length": 74,
    "time": 43499.855565,
    "actor_loss": -60.20518493652344,
    "critic_loss": 37.93534851074219,
    "ent_coef": 0.09575997292995453,
    "learning_rate": 0.001
  },
  {
    "episode": 2584,
    "reward": 85.603121,
    "length": 70,
    "time": 43512.387625,
    "actor_loss": -59.91925811767578,
    "critic_loss": 34.040985107421875,
    "ent_coef": 0.09541640430688858,
    "learning_rate": 0.001
  },
  {
    "episode": 2585,
    "reward": 90.261606,
    "length": 62,
    "time": 43523.537556,
    "actor_loss": -59.7359619140625,
    "critic_loss": 3.7262701988220215,
    "ent_coef": 0.09887955337762833,
    "learning_rate": 0.001
  },
  {
    "episode": 2586,
    "reward": 87.563872,
    "length": 67,
    "time": 43535.17715,
    "actor_loss": -62.59874725341797,
    "critic_loss": 6.1401753425598145,
    "ent_coef": 0.10082131624221802,
    "learning_rate": 0.001
  },
  {
    "episode": 2587,
    "reward": 86.191945,
    "length": 69,
    "time": 43548.777556,
    "actor_loss": -61.437355041503906,
    "critic_loss": 59.94001388549805,
    "ent_coef": 0.10213850438594818,
    "learning_rate": 0.001
  },
  {
    "episode": 2588,
    "reward": 90.841281,
    "length": 61,
    "time": 43559.733436,
    "actor_loss": -60.642417907714844,
    "critic_loss": 17.30264663696289,
    "ent_coef": 0.10616982728242874,
    "learning_rate": 0.001
  },
  {
    "episode": 2589,
    "reward": 90.353494,
    "length": 62,
    "time": 43571.000207,
    "actor_loss": -63.34651184082031,
    "critic_loss": 5.762054443359375,
    "ent_coef": 0.10935430228710175,
    "learning_rate": 0.001
  },
  {
    "episode": 2590,
    "reward": 88.053875,
    "length": 66,
    "time": 43583.676971,
    "actor_loss": -63.61759948730469,
    "critic_loss": 3.5959272384643555,
    "ent_coef": 0.11101866513490677,
    "learning_rate": 0.001
  },
  {
    "episode": 2591,
    "reward": 88.288316,
    "length": 66,
    "time": 43596.315053,
    "actor_loss": -65.6921615600586,
    "critic_loss": 3.501227855682373,
    "ent_coef": 0.11560676246881485,
    "learning_rate": 0.001
  },
  {
    "episode": 2592,
    "reward": 88.245219,
    "length": 67,
    "time": 43608.382576,
    "actor_loss": -60.482627868652344,
    "critic_loss": 7.146040916442871,
    "ent_coef": 0.10927478969097137,
    "learning_rate": 0.001
  },
  {
    "episode": 2593,
    "reward": 82.560461,
    "length": 76,
    "time": 43622.349569,
    "actor_loss": -63.27582550048828,
    "critic_loss": 10.037565231323242,
    "ent_coef": 0.1048785075545311,
    "learning_rate": 0.001
  },
  {
    "episode": 2594,
    "reward": 87.783373,
    "length": 68,
    "time": 43635.339497,
    "actor_loss": -64.13280487060547,
    "critic_loss": 5.847630500793457,
    "ent_coef": 0.1013723686337471,
    "learning_rate": 0.001
  },
  {
    "episode": 2595,
    "reward": 84.021272,
    "length": 75,
    "time": 43648.127248,
    "actor_loss": -64.58822631835938,
    "critic_loss": 8.97203540802002,
    "ent_coef": 0.09552954137325287,
    "learning_rate": 0.001
  },
  {
    "episode": 2596,
    "reward": 88.871904,
    "length": 65,
    "time": 43660.596893,
    "actor_loss": -61.36155700683594,
    "critic_loss": 2.6945629119873047,
    "ent_coef": 0.09279405325651169,
    "learning_rate": 0.001
  },
  {
    "episode": 2597,
    "reward": 82.766445,
    "length": 76,
    "time": 43674.070757,
    "actor_loss": -58.19245529174805,
    "critic_loss": 49.83186340332031,
    "ent_coef": 0.09318166971206665,
    "learning_rate": 0.001
  },
  {
    "episode": 2598,
    "reward": 84.521416,
    "length": 74,
    "time": 43688.828519,
    "actor_loss": -62.965965270996094,
    "critic_loss": 9.23765754699707,
    "ent_coef": 0.09489363431930542,
    "learning_rate": 0.001
  },
  {
    "episode": 2599,
    "reward": 87.26778,
    "length": 69,
    "time": 43703.308773,
    "actor_loss": -63.743980407714844,
    "critic_loss": 25.696998596191406,
    "ent_coef": 0.0947684720158577,
    "learning_rate": 0.001
  },
  {
    "episode": 2600,
    "reward": 88.164828,
    "length": 65,
    "time": 43714.623682,
    "actor_loss": -62.868343353271484,
    "critic_loss": 668.6590576171875,
    "ent_coef": 0.095968097448349,
    "learning_rate": 0.001
  },
  {
    "episode": 2601,
    "reward": 85.41179,
    "length": 71,
    "time": 43728.756512,
    "actor_loss": -60.69647216796875,
    "critic_loss": 6.159537315368652,
    "ent_coef": 0.09346328675746918,
    "learning_rate": 0.001
  },
  {
    "episode": 2602,
    "reward": 75.592324,
    "length": 85,
    "time": 43745.496799,
    "actor_loss": -61.44309616088867,
    "critic_loss": 8.229104995727539,
    "ent_coef": 0.09263937920331955,
    "learning_rate": 0.001
  },
  {
    "episode": 2603,
    "reward": 89.772338,
    "length": 64,
    "time": 43758.839597,
    "actor_loss": -58.98290252685547,
    "critic_loss": 40.54552459716797,
    "ent_coef": 0.10070386528968811,
    "learning_rate": 0.001
  },
  {
    "episode": 2604,
    "reward": 86.299471,
    "length": 70,
    "time": 43773.460809,
    "actor_loss": -63.89411544799805,
    "critic_loss": 23.577037811279297,
    "ent_coef": 0.10936074703931808,
    "learning_rate": 0.001
  },
  {
    "episode": 2605,
    "reward": 65.365619,
    "length": 102,
    "time": 43789.764832,
    "actor_loss": -55.443809509277344,
    "critic_loss": 4.822057723999023,
    "ent_coef": 0.10579149425029755,
    "learning_rate": 0.001
  },
  {
    "episode": 2606,
    "reward": 84.006606,
    "length": 73,
    "time": 43802.443369,
    "actor_loss": -59.51924133300781,
    "critic_loss": 48.5864372253418,
    "ent_coef": 0.09955374896526337,
    "learning_rate": 0.001
  },
  {
    "episode": 2607,
    "reward": 68.083434,
    "length": 89,
    "time": 43819.575194,
    "actor_loss": -58.37446212768555,
    "critic_loss": 19.862869262695312,
    "ent_coef": 0.10202586650848389,
    "learning_rate": 0.001
  },
  {
    "episode": 2608,
    "reward": 87.713821,
    "length": 66,
    "time": 43831.996626,
    "actor_loss": -62.26701354980469,
    "critic_loss": 36.67626190185547,
    "ent_coef": 0.10512813180685043,
    "learning_rate": 0.001
  },
  {
    "episode": 2609,
    "reward": 88.248079,
    "length": 67,
    "time": 43843.890596,
    "actor_loss": -55.04670333862305,
    "critic_loss": 22.298831939697266,
    "ent_coef": 0.10322806984186172,
    "learning_rate": 0.001
  },
  {
    "episode": 2610,
    "reward": 90.401585,
    "length": 62,
    "time": 43855.307042,
    "actor_loss": -61.734580993652344,
    "critic_loss": 8.535112380981445,
    "ent_coef": 0.10678357630968094,
    "learning_rate": 0.001
  },
  {
    "episode": 2611,
    "reward": 55.246996,
    "length": 108,
    "time": 43873.477241,
    "actor_loss": -63.515708923339844,
    "critic_loss": 92.20053100585938,
    "ent_coef": 0.10458516329526901,
    "learning_rate": 0.001
  },
  {
    "episode": 2612,
    "reward": 77.793928,
    "length": 90,
    "time": 43888.775403,
    "actor_loss": -54.62968444824219,
    "critic_loss": 4.830456733703613,
    "ent_coef": 0.10288625210523605,
    "learning_rate": 0.001
  },
  {
    "episode": 2613,
    "reward": 88.839721,
    "length": 66,
    "time": 43902.076164,
    "actor_loss": -61.63921356201172,
    "critic_loss": 8.332305908203125,
    "ent_coef": 0.10245195776224136,
    "learning_rate": 0.001
  },
  {
    "episode": 2614,
    "reward": 89.974,
    "length": 65,
    "time": 43914.299503,
    "actor_loss": -57.787322998046875,
    "critic_loss": 35.264923095703125,
    "ent_coef": 0.10777734220027924,
    "learning_rate": 0.001
  },
  {
    "episode": 2615,
    "reward": 86.63417,
    "length": 68,
    "time": 43928.008691,
    "actor_loss": -60.28368377685547,
    "critic_loss": 2.015925884246826,
    "ent_coef": 0.10310474783182144,
    "learning_rate": 0.001
  },
  {
    "episode": 2616,
    "reward": 86.711827,
    "length": 71,
    "time": 43941.306566,
    "actor_loss": -58.477996826171875,
    "critic_loss": 156.2231903076172,
    "ent_coef": 0.09638670831918716,
    "learning_rate": 0.001
  },
  {
    "episode": 2617,
    "reward": 84.737168,
    "length": 71,
    "time": 43955.435933,
    "actor_loss": -64.94212341308594,
    "critic_loss": 84.22940063476562,
    "ent_coef": 0.09723038226366043,
    "learning_rate": 0.001
  },
  {
    "episode": 2618,
    "reward": 86.210323,
    "length": 74,
    "time": 43968.068413,
    "actor_loss": -66.24137878417969,
    "critic_loss": 8.462614059448242,
    "ent_coef": 0.10046353191137314,
    "learning_rate": 0.001
  },
  {
    "episode": 2619,
    "reward": 87.301935,
    "length": 69,
    "time": 43982.262289,
    "actor_loss": -63.43638610839844,
    "critic_loss": 11.294992446899414,
    "ent_coef": 0.09802456200122833,
    "learning_rate": 0.001
  },
  {
    "episode": 2620,
    "reward": 76.325256,
    "length": 87,
    "time": 43999.376523,
    "actor_loss": -63.03709030151367,
    "critic_loss": 34.38165283203125,
    "ent_coef": 0.09091565012931824,
    "learning_rate": 0.001
  },
  {
    "episode": 2621,
    "reward": 85.058147,
    "length": 76,
    "time": 44018.627446,
    "actor_loss": -60.79997253417969,
    "critic_loss": 17.190509796142578,
    "ent_coef": 0.08875500410795212,
    "learning_rate": 0.001
  },
  {
    "episode": 2622,
    "reward": 86.305728,
    "length": 71,
    "time": 44031.504634,
    "actor_loss": -61.76856231689453,
    "critic_loss": 33.939666748046875,
    "ent_coef": 0.08668901026248932,
    "learning_rate": 0.001
  },
  {
    "episode": 2623,
    "reward": 86.800115,
    "length": 68,
    "time": 44044.45961,
    "actor_loss": -56.794776916503906,
    "critic_loss": 8.686758041381836,
    "ent_coef": 0.08523464947938919,
    "learning_rate": 0.001
  },
  {
    "episode": 2624,
    "reward": 71.515657,
    "length": 92,
    "time": 44060.315437,
    "actor_loss": -65.24900817871094,
    "critic_loss": 16.957439422607422,
    "ent_coef": 0.08169165998697281,
    "learning_rate": 0.001
  },
  {
    "episode": 2625,
    "reward": 85.856072,
    "length": 71,
    "time": 44074.739603,
    "actor_loss": -61.700645446777344,
    "critic_loss": 2.955076217651367,
    "ent_coef": 0.08093973249197006,
    "learning_rate": 0.001
  },
  {
    "episode": 2626,
    "reward": 87.937774,
    "length": 66,
    "time": 44087.314249,
    "actor_loss": -59.996795654296875,
    "critic_loss": 19.557090759277344,
    "ent_coef": 0.0828266516327858,
    "learning_rate": 0.001
  },
  {
    "episode": 2627,
    "reward": 86.550088,
    "length": 70,
    "time": 44100.373172,
    "actor_loss": -66.08021545410156,
    "critic_loss": 11.187089920043945,
    "ent_coef": 0.08178006857633591,
    "learning_rate": 0.001
  },
  {
    "episode": 2628,
    "reward": 81.064798,
    "length": 79,
    "time": 44113.674978,
    "actor_loss": -60.10731506347656,
    "critic_loss": 13.311013221740723,
    "ent_coef": 0.07979290187358856,
    "learning_rate": 0.001
  },
  {
    "episode": 2629,
    "reward": 87.213754,
    "length": 66,
    "time": 44126.970771,
    "actor_loss": -59.70793151855469,
    "critic_loss": 55.215850830078125,
    "ent_coef": 0.0811208114027977,
    "learning_rate": 0.001
  },
  {
    "episode": 2630,
    "reward": 86.692495,
    "length": 70,
    "time": 44141.327561,
    "actor_loss": -64.58153533935547,
    "critic_loss": 3.7473957538604736,
    "ent_coef": 0.08116284757852554,
    "learning_rate": 0.001
  },
  {
    "episode": 2631,
    "reward": 85.04373,
    "length": 70,
    "time": 44156.451709,
    "actor_loss": -61.09660339355469,
    "critic_loss": 49.31065368652344,
    "ent_coef": 0.08387966454029083,
    "learning_rate": 0.001
  },
  {
    "episode": 2632,
    "reward": 90.605961,
    "length": 61,
    "time": 44170.328795,
    "actor_loss": -58.80923080444336,
    "critic_loss": 31.047197341918945,
    "ent_coef": 0.08557610213756561,
    "learning_rate": 0.001
  },
  {
    "episode": 2633,
    "reward": 88.599006,
    "length": 67,
    "time": 44183.402199,
    "actor_loss": -60.29822540283203,
    "critic_loss": 6.163736820220947,
    "ent_coef": 0.08736837655305862,
    "learning_rate": 0.001
  },
  {
    "episode": 2634,
    "reward": 88.306663,
    "length": 66,
    "time": 44196.427048,
    "actor_loss": -65.72460174560547,
    "critic_loss": 6.014711380004883,
    "ent_coef": 0.09208022058010101,
    "learning_rate": 0.001
  },
  {
    "episode": 2635,
    "reward": 87.645726,
    "length": 67,
    "time": 44208.425001,
    "actor_loss": -60.76633071899414,
    "critic_loss": 6.948032379150391,
    "ent_coef": 0.09376609325408936,
    "learning_rate": 0.001
  },
  {
    "episode": 2636,
    "reward": 85.270916,
    "length": 70,
    "time": 44225.236463,
    "actor_loss": -62.928749084472656,
    "critic_loss": 7.424583435058594,
    "ent_coef": 0.09068946540355682,
    "learning_rate": 0.001
  },
  {
    "episode": 2637,
    "reward": 84.370481,
    "length": 73,
    "time": 44240.666579,
    "actor_loss": -69.33068084716797,
    "critic_loss": 3.8675296306610107,
    "ent_coef": 0.0884675532579422,
    "learning_rate": 0.001
  },
  {
    "episode": 2638,
    "reward": 85.772384,
    "length": 70,
    "time": 44253.633629,
    "actor_loss": -63.3697624206543,
    "critic_loss": 30.611328125,
    "ent_coef": 0.08994513005018234,
    "learning_rate": 0.001
  },
  {
    "episode": 2639,
    "reward": 86.323686,
    "length": 68,
    "time": 44266.998661,
    "actor_loss": -65.2568359375,
    "critic_loss": 6.317054748535156,
    "ent_coef": 0.09495766460895538,
    "learning_rate": 0.001
  },
  {
    "episode": 2640,
    "reward": 85.242499,
    "length": 71,
    "time": 44280.666709,
    "actor_loss": -59.271751403808594,
    "critic_loss": 5.271971702575684,
    "ent_coef": 0.09681250900030136,
    "learning_rate": 0.001
  },
  {
    "episode": 2641,
    "reward": 88.138795,
    "length": 69,
    "time": 44293.045801,
    "actor_loss": -60.22813034057617,
    "critic_loss": 18.25928497314453,
    "ent_coef": 0.09611278772354126,
    "learning_rate": 0.001
  },
  {
    "episode": 2642,
    "reward": 75.08847,
    "length": 86,
    "time": 44307.210207,
    "actor_loss": -69.27184295654297,
    "critic_loss": 9.185367584228516,
    "ent_coef": 0.08925638347864151,
    "learning_rate": 0.001
  },
  {
    "episode": 2643,
    "reward": 81.141311,
    "length": 85,
    "time": 44322.212817,
    "actor_loss": -65.1584701538086,
    "critic_loss": 26.052949905395508,
    "ent_coef": 0.08765093982219696,
    "learning_rate": 0.001
  },
  {
    "episode": 2644,
    "reward": 78.505818,
    "length": 85,
    "time": 44337.878541,
    "actor_loss": -59.816654205322266,
    "critic_loss": 32.87856674194336,
    "ent_coef": 0.08729442209005356,
    "learning_rate": 0.001
  },
  {
    "episode": 2645,
    "reward": 84.841203,
    "length": 71,
    "time": 44354.423793,
    "actor_loss": -65.27555084228516,
    "critic_loss": 2.1113767623901367,
    "ent_coef": 0.08767163008451462,
    "learning_rate": 0.001
  },
  {
    "episode": 2646,
    "reward": 81.637039,
    "length": 76,
    "time": 44367.44978,
    "actor_loss": -63.7975959777832,
    "critic_loss": 2.686056613922119,
    "ent_coef": 0.0885508805513382,
    "learning_rate": 0.001
  },
  {
    "episode": 2647,
    "reward": 83.11794,
    "length": 77,
    "time": 44382.311989,
    "actor_loss": -65.20185852050781,
    "critic_loss": 6.153695106506348,
    "ent_coef": 0.08626911789178848,
    "learning_rate": 0.001
  },
  {
    "episode": 2648,
    "reward": 86.844976,
    "length": 69,
    "time": 44395.961372,
    "actor_loss": -61.95173645019531,
    "critic_loss": 13.047906875610352,
    "ent_coef": 0.08860116451978683,
    "learning_rate": 0.001
  },
  {
    "episode": 2649,
    "reward": 85.356144,
    "length": 70,
    "time": 44408.068567,
    "actor_loss": -65.59624481201172,
    "critic_loss": 9.263275146484375,
    "ent_coef": 0.08948595076799393,
    "learning_rate": 0.001
  },
  {
    "episode": 2650,
    "reward": 91.055649,
    "length": 61,
    "time": 44421.463478,
    "actor_loss": -58.591712951660156,
    "critic_loss": 17.398380279541016,
    "ent_coef": 0.0930221825838089,
    "learning_rate": 0.001
  },
  {
    "episode": 2651,
    "reward": 86.364575,
    "length": 69,
    "time": 44435.306694,
    "actor_loss": -68.5399169921875,
    "critic_loss": 9.24222183227539,
    "ent_coef": 0.09259407222270966,
    "learning_rate": 0.001
  },
  {
    "episode": 2652,
    "reward": 88.249258,
    "length": 64,
    "time": 44446.616334,
    "actor_loss": -68.12933349609375,
    "critic_loss": 4.200395107269287,
    "ent_coef": 0.09245454519987106,
    "learning_rate": 0.001
  },
  {
    "episode": 2653,
    "reward": 86.462939,
    "length": 68,
    "time": 44458.882214,
    "actor_loss": -63.196311950683594,
    "critic_loss": 6.616237640380859,
    "ent_coef": 0.0913313701748848,
    "learning_rate": 0.001
  },
  {
    "episode": 2654,
    "reward": 86.907488,
    "length": 69,
    "time": 44472.399825,
    "actor_loss": -60.654563903808594,
    "critic_loss": 7.612933158874512,
    "ent_coef": 0.09192047268152237,
    "learning_rate": 0.001
  },
  {
    "episode": 2655,
    "reward": 89.797483,
    "length": 63,
    "time": 44483.643669,
    "actor_loss": -62.44932556152344,
    "critic_loss": 56.13304138183594,
    "ent_coef": 0.09606538712978363,
    "learning_rate": 0.001
  },
  {
    "episode": 2656,
    "reward": 84.346189,
    "length": 72,
    "time": 44498.580761,
    "actor_loss": -64.4534683227539,
    "critic_loss": 23.323978424072266,
    "ent_coef": 0.09546783566474915,
    "learning_rate": 0.001
  },
  {
    "episode": 2657,
    "reward": 86.317717,
    "length": 69,
    "time": 44511.577492,
    "actor_loss": -65.63143920898438,
    "critic_loss": 21.209854125976562,
    "ent_coef": 0.09926366806030273,
    "learning_rate": 0.001
  },
  {
    "episode": 2658,
    "reward": 69.7803,
    "length": 95,
    "time": 44529.88947,
    "actor_loss": -60.27073669433594,
    "critic_loss": 12.847320556640625,
    "ent_coef": 0.09476641565561295,
    "learning_rate": 0.001
  },
  {
    "episode": 2659,
    "reward": 84.451355,
    "length": 74,
    "time": 44543.279774,
    "actor_loss": -63.81726837158203,
    "critic_loss": 17.43175506591797,
    "ent_coef": 0.09359728544950485,
    "learning_rate": 0.001
  },
  {
    "episode": 2660,
    "reward": 80.545551,
    "length": 79,
    "time": 44559.517102,
    "actor_loss": -61.51477813720703,
    "critic_loss": 3.618154525756836,
    "ent_coef": 0.0958605706691742,
    "learning_rate": 0.001
  },
  {
    "episode": 2661,
    "reward": 84.816608,
    "length": 73,
    "time": 44575.253813,
    "actor_loss": -67.26217651367188,
    "critic_loss": 16.728965759277344,
    "ent_coef": 0.09411459416151047,
    "learning_rate": 0.001
  },
  {
    "episode": 2662,
    "reward": 83.198991,
    "length": 75,
    "time": 44588.194288,
    "actor_loss": -60.33326721191406,
    "critic_loss": 2.801038980484009,
    "ent_coef": 0.09393281489610672,
    "learning_rate": 0.001
  },
  {
    "episode": 2663,
    "reward": 78.017476,
    "length": 82,
    "time": 44602.499351,
    "actor_loss": -62.088890075683594,
    "critic_loss": 4.8828630447387695,
    "ent_coef": 0.09414457529783249,
    "learning_rate": 0.001
  },
  {
    "episode": 2664,
    "reward": 74.354725,
    "length": 93,
    "time": 44618.173802,
    "actor_loss": -59.20467758178711,
    "critic_loss": 55.24687194824219,
    "ent_coef": 0.09137207269668579,
    "learning_rate": 0.001
  },
  {
    "episode": 2665,
    "reward": -150.048705,
    "length": 89,
    "time": 44632.992881,
    "actor_loss": -61.959510803222656,
    "critic_loss": 3.6801443099975586,
    "ent_coef": 0.08545637875795364,
    "learning_rate": 0.001
  },
  {
    "episode": 2666,
    "reward": 92.920162,
    "length": 72,
    "time": 44646.37534,
    "actor_loss": -58.42437744140625,
    "critic_loss": 2.5769989490509033,
    "ent_coef": 0.08341196924448013,
    "learning_rate": 0.001
  },
  {
    "episode": 2667,
    "reward": 88.064945,
    "length": 66,
    "time": 44658.064904,
    "actor_loss": -54.800296783447266,
    "critic_loss": 54.194087982177734,
    "ent_coef": 0.08459614962339401,
    "learning_rate": 0.001
  },
  {
    "episode": 2668,
    "reward": 88.951187,
    "length": 64,
    "time": 44669.937021,
    "actor_loss": -62.01251220703125,
    "critic_loss": 13.101363182067871,
    "ent_coef": 0.09022792428731918,
    "learning_rate": 0.001
  },
  {
    "episode": 2669,
    "reward": 91.993197,
    "length": 60,
    "time": 44682.91883,
    "actor_loss": -57.2662353515625,
    "critic_loss": 11.043659210205078,
    "ent_coef": 0.09680325537919998,
    "learning_rate": 0.001
  },
  {
    "episode": 2670,
    "reward": 78.854948,
    "length": 80,
    "time": 44696.691664,
    "actor_loss": -65.94322204589844,
    "critic_loss": 5.792983055114746,
    "ent_coef": 0.09499867260456085,
    "learning_rate": 0.001
  },
  {
    "episode": 2671,
    "reward": 79.774516,
    "length": 80,
    "time": 44712.754075,
    "actor_loss": -62.39232635498047,
    "critic_loss": 11.846712112426758,
    "ent_coef": 0.09680391848087311,
    "learning_rate": 0.001
  },
  {
    "episode": 2672,
    "reward": 83.42865,
    "length": 73,
    "time": 44726.622197,
    "actor_loss": -67.38108825683594,
    "critic_loss": 27.187795639038086,
    "ent_coef": 0.10132651031017303,
    "learning_rate": 0.001
  },
  {
    "episode": 2673,
    "reward": 91.234072,
    "length": 61,
    "time": 44740.160583,
    "actor_loss": -65.75455474853516,
    "critic_loss": 8.475519180297852,
    "ent_coef": 0.11020958423614502,
    "learning_rate": 0.001
  },
  {
    "episode": 2674,
    "reward": 81.813158,
    "length": 78,
    "time": 44754.729041,
    "actor_loss": -63.17977523803711,
    "critic_loss": 72.10127258300781,
    "ent_coef": 0.10861755162477493,
    "learning_rate": 0.001
  },
  {
    "episode": 2675,
    "reward": 72.566188,
    "length": 94,
    "time": 44774.812254,
    "actor_loss": -61.74903869628906,
    "critic_loss": 4.015514373779297,
    "ent_coef": 0.10310980677604675,
    "learning_rate": 0.001
  },
  {
    "episode": 2676,
    "reward": 71.931713,
    "length": 91,
    "time": 44790.814637,
    "actor_loss": -61.7208251953125,
    "critic_loss": 18.146114349365234,
    "ent_coef": 0.10297483950853348,
    "learning_rate": 0.001
  },
  {
    "episode": 2677,
    "reward": 82.467833,
    "length": 76,
    "time": 44804.516899,
    "actor_loss": -61.44258117675781,
    "critic_loss": 3.851750612258911,
    "ent_coef": 0.09774219989776611,
    "learning_rate": 0.001
  },
  {
    "episode": 2678,
    "reward": 70.552924,
    "length": 94,
    "time": 44820.87081,
    "actor_loss": -67.56832885742188,
    "critic_loss": 3.8406693935394287,
    "ent_coef": 0.09343534708023071,
    "learning_rate": 0.001
  },
  {
    "episode": 2679,
    "reward": 87.807762,
    "length": 67,
    "time": 44832.597283,
    "actor_loss": -64.89904022216797,
    "critic_loss": 7.4206438064575195,
    "ent_coef": 0.09357370436191559,
    "learning_rate": 0.001
  },
  {
    "episode": 2680,
    "reward": 76.919053,
    "length": 89,
    "time": 44853.498776,
    "actor_loss": -58.277320861816406,
    "critic_loss": 18.727230072021484,
    "ent_coef": 0.08956208825111389,
    "learning_rate": 0.001
  },
  {
    "episode": 2681,
    "reward": 76.862206,
    "length": 88,
    "time": 44867.857352,
    "actor_loss": -61.249107360839844,
    "critic_loss": 7.015239238739014,
    "ent_coef": 0.08598899096250534,
    "learning_rate": 0.001
  },
  {
    "episode": 2682,
    "reward": 87.918118,
    "length": 67,
    "time": 44879.863276,
    "actor_loss": -61.238441467285156,
    "critic_loss": 72.90298461914062,
    "ent_coef": 0.08852730691432953,
    "learning_rate": 0.001
  },
  {
    "episode": 2683,
    "reward": 83.805456,
    "length": 74,
    "time": 44892.979341,
    "actor_loss": -59.54440689086914,
    "critic_loss": 14.652030944824219,
    "ent_coef": 0.0866422951221466,
    "learning_rate": 0.001
  },
  {
    "episode": 2684,
    "reward": 84.312914,
    "length": 74,
    "time": 44910.032412,
    "actor_loss": -59.47495651245117,
    "critic_loss": 8.310799598693848,
    "ent_coef": 0.08756045997142792,
    "learning_rate": 0.001
  },
  {
    "episode": 2685,
    "reward": 79.581595,
    "length": 83,
    "time": 44923.743503,
    "actor_loss": -59.306949615478516,
    "critic_loss": 5.366375923156738,
    "ent_coef": 0.08738120645284653,
    "learning_rate": 0.001
  },
  {
    "episode": 2686,
    "reward": 83.693276,
    "length": 75,
    "time": 44937.282279,
    "actor_loss": -68.49783325195312,
    "critic_loss": 50.961875915527344,
    "ent_coef": 0.08987826853990555,
    "learning_rate": 0.001
  },
  {
    "episode": 2687,
    "reward": 74.815911,
    "length": 94,
    "time": 44952.765462,
    "actor_loss": -61.053184509277344,
    "critic_loss": 19.763507843017578,
    "ent_coef": 0.08818232268095016,
    "learning_rate": 0.001
  },
  {
    "episode": 2688,
    "reward": 84.389101,
    "length": 72,
    "time": 44964.987753,
    "actor_loss": -60.29220962524414,
    "critic_loss": 6.776932716369629,
    "ent_coef": 0.08774097263813019,
    "learning_rate": 0.001
  },
  {
    "episode": 2689,
    "reward": 77.851719,
    "length": 83,
    "time": 44980.353812,
    "actor_loss": -60.36753463745117,
    "critic_loss": 19.966304779052734,
    "ent_coef": 0.08809664845466614,
    "learning_rate": 0.001
  },
  {
    "episode": 2690,
    "reward": 85.944485,
    "length": 71,
    "time": 44994.691155,
    "actor_loss": -64.12869262695312,
    "critic_loss": 23.42437744140625,
    "ent_coef": 0.09453132003545761,
    "learning_rate": 0.001
  },
  {
    "episode": 2691,
    "reward": 87.849709,
    "length": 67,
    "time": 45006.367625,
    "actor_loss": -65.82598876953125,
    "critic_loss": 336.70623779296875,
    "ent_coef": 0.09593439847230911,
    "learning_rate": 0.001
  },
  {
    "episode": 2692,
    "reward": 83.030356,
    "length": 74,
    "time": 45021.1366,
    "actor_loss": -56.48212814331055,
    "critic_loss": 5.074542999267578,
    "ent_coef": 0.09605425596237183,
    "learning_rate": 0.001
  },
  {
    "episode": 2693,
    "reward": 86.06438,
    "length": 72,
    "time": 45035.673802,
    "actor_loss": -65.25764465332031,
    "critic_loss": 4.755277633666992,
    "ent_coef": 0.09565231204032898,
    "learning_rate": 0.001
  },
  {
    "episode": 2694,
    "reward": 86.568036,
    "length": 70,
    "time": 45050.352178,
    "actor_loss": -64.41388702392578,
    "critic_loss": 3.387662410736084,
    "ent_coef": 0.0972227081656456,
    "learning_rate": 0.001
  },
  {
    "episode": 2695,
    "reward": 86.097486,
    "length": 70,
    "time": 45062.271826,
    "actor_loss": -65.2081298828125,
    "critic_loss": 19.381444931030273,
    "ent_coef": 0.10157116502523422,
    "learning_rate": 0.001
  },
  {
    "episode": 2696,
    "reward": 88.744347,
    "length": 65,
    "time": 45074.801609,
    "actor_loss": -62.703853607177734,
    "critic_loss": 7.758335113525391,
    "ent_coef": 0.10320572555065155,
    "learning_rate": 0.001
  },
  {
    "episode": 2697,
    "reward": 85.653278,
    "length": 73,
    "time": 45089.731863,
    "actor_loss": -64.2170181274414,
    "critic_loss": 23.805049896240234,
    "ent_coef": 0.10537060350179672,
    "learning_rate": 0.001
  },
  {
    "episode": 2698,
    "reward": 79.013822,
    "length": 80,
    "time": 45103.343658,
    "actor_loss": -68.04653930664062,
    "critic_loss": 3.000792980194092,
    "ent_coef": 0.10641541332006454,
    "learning_rate": 0.001
  },
  {
    "episode": 2699,
    "reward": 85.296935,
    "length": 72,
    "time": 45116.681849,
    "actor_loss": -55.02642059326172,
    "critic_loss": 41.854896545410156,
    "ent_coef": 0.10471123456954956,
    "learning_rate": 0.001
  },
  {
    "episode": 2700,
    "reward": 86.397301,
    "length": 70,
    "time": 45129.707999,
    "actor_loss": -57.06584930419922,
    "critic_loss": 3.896836996078491,
    "ent_coef": 0.10398522764444351,
    "learning_rate": 0.001
  },
  {
    "episode": 2701,
    "reward": 86.491104,
    "length": 70,
    "time": 45143.647702,
    "actor_loss": -56.84459686279297,
    "critic_loss": 3.9921188354492188,
    "ent_coef": 0.10285850614309311,
    "learning_rate": 0.001
  },
  {
    "episode": 2702,
    "reward": 75.340904,
    "length": 87,
    "time": 45158.929255,
    "actor_loss": -61.857215881347656,
    "critic_loss": 29.18345832824707,
    "ent_coef": 0.10105756670236588,
    "learning_rate": 0.001
  },
  {
    "episode": 2703,
    "reward": 82.614028,
    "length": 79,
    "time": 45172.187468,
    "actor_loss": -65.26763153076172,
    "critic_loss": 26.801307678222656,
    "ent_coef": 0.09989609569311142,
    "learning_rate": 0.001
  },
  {
    "episode": 2704,
    "reward": 88.199602,
    "length": 66,
    "time": 45188.003912,
    "actor_loss": -58.999786376953125,
    "critic_loss": 5.337535858154297,
    "ent_coef": 0.10694773495197296,
    "learning_rate": 0.001
  },
  {
    "episode": 2705,
    "reward": 85.635998,
    "length": 71,
    "time": 45200.279532,
    "actor_loss": -61.126060485839844,
    "critic_loss": 3.30153489112854,
    "ent_coef": 0.10937493294477463,
    "learning_rate": 0.001
  },
  {
    "episode": 2706,
    "reward": 87.192534,
    "length": 69,
    "time": 45213.51486,
    "actor_loss": -65.79927062988281,
    "critic_loss": 14.085119247436523,
    "ent_coef": 0.10815966129302979,
    "learning_rate": 0.001
  },
  {
    "episode": 2707,
    "reward": 83.359144,
    "length": 76,
    "time": 45228.872545,
    "actor_loss": -62.56514358520508,
    "critic_loss": 8.092926025390625,
    "ent_coef": 0.10394743084907532,
    "learning_rate": 0.001
  },
  {
    "episode": 2708,
    "reward": 85.529616,
    "length": 72,
    "time": 45242.073642,
    "actor_loss": -59.89129638671875,
    "critic_loss": 33.1134033203125,
    "ent_coef": 0.10373656451702118,
    "learning_rate": 0.001
  },
  {
    "episode": 2709,
    "reward": 90.512906,
    "length": 62,
    "time": 45254.587159,
    "actor_loss": -61.88444900512695,
    "critic_loss": 2.9851841926574707,
    "ent_coef": 0.1098417341709137,
    "learning_rate": 0.001
  },
  {
    "episode": 2710,
    "reward": 85.295146,
    "length": 72,
    "time": 45269.380408,
    "actor_loss": -63.72380447387695,
    "critic_loss": 3.50075364112854,
    "ent_coef": 0.10809718817472458,
    "learning_rate": 0.001
  },
  {
    "episode": 2711,
    "reward": 87.952643,
    "length": 65,
    "time": 45281.069645,
    "actor_loss": -63.34038543701172,
    "critic_loss": 732.4556884765625,
    "ent_coef": 0.11520979553461075,
    "learning_rate": 0.001
  },
  {
    "episode": 2712,
    "reward": 86.969177,
    "length": 68,
    "time": 45292.960985,
    "actor_loss": -59.5479850769043,
    "critic_loss": 48.20520782470703,
    "ent_coef": 0.1187324970960617,
    "learning_rate": 0.001
  },
  {
    "episode": 2713,
    "reward": 81.153794,
    "length": 79,
    "time": 45306.151574,
    "actor_loss": -63.41982650756836,
    "critic_loss": 28.87569808959961,
    "ent_coef": 0.10997191816568375,
    "learning_rate": 0.001
  },
  {
    "episode": 2714,
    "reward": 86.676839,
    "length": 69,
    "time": 45318.088881,
    "actor_loss": -54.67873764038086,
    "critic_loss": 6.055546760559082,
    "ent_coef": 0.10540088266134262,
    "learning_rate": 0.001
  },
  {
    "episode": 2715,
    "reward": 85.400653,
    "length": 74,
    "time": 45330.974082,
    "actor_loss": -64.03047180175781,
    "critic_loss": 8.541470527648926,
    "ent_coef": 0.10116931051015854,
    "learning_rate": 0.001
  },
  {
    "episode": 2716,
    "reward": 86.111123,
    "length": 70,
    "time": 45344.12764,
    "actor_loss": -57.42341232299805,
    "critic_loss": 49.89974594116211,
    "ent_coef": 0.09588155895471573,
    "learning_rate": 0.001
  },
  {
    "episode": 2717,
    "reward": 90.488144,
    "length": 62,
    "time": 45355.21471,
    "actor_loss": -61.47224807739258,
    "critic_loss": 6.303742408752441,
    "ent_coef": 0.09896663576364517,
    "learning_rate": 0.001
  },
  {
    "episode": 2718,
    "reward": 84.629751,
    "length": 71,
    "time": 45367.591325,
    "actor_loss": -63.197608947753906,
    "critic_loss": 3.6838648319244385,
    "ent_coef": 0.10114704817533493,
    "learning_rate": 0.001
  },
  {
    "episode": 2719,
    "reward": 84.348896,
    "length": 71,
    "time": 45381.669372,
    "actor_loss": -60.660316467285156,
    "critic_loss": 5.079649448394775,
    "ent_coef": 0.09980634599924088,
    "learning_rate": 0.001
  },
  {
    "episode": 2720,
    "reward": -167.583191,
    "length": 118,
    "time": 45405.914901,
    "actor_loss": -63.34032440185547,
    "critic_loss": 4.380120277404785,
    "ent_coef": 0.09787692129611969,
    "learning_rate": 0.001
  },
  {
    "episode": 2721,
    "reward": 86.876592,
    "length": 87,
    "time": 45420.471351,
    "actor_loss": -54.80853271484375,
    "critic_loss": 14.885082244873047,
    "ent_coef": 0.09448026865720749,
    "learning_rate": 0.001
  },
  {
    "episode": 2722,
    "reward": 83.354164,
    "length": 76,
    "time": 45433.393176,
    "actor_loss": -59.469356536865234,
    "critic_loss": 37.67378234863281,
    "ent_coef": 0.09103955328464508,
    "learning_rate": 0.001
  },
  {
    "episode": 2723,
    "reward": 63.509284,
    "length": 102,
    "time": 45450.576578,
    "actor_loss": -61.27276611328125,
    "critic_loss": 22.729122161865234,
    "ent_coef": 0.0860096737742424,
    "learning_rate": 0.001
  },
  {
    "episode": 2724,
    "reward": 77.565642,
    "length": 87,
    "time": 45469.555639,
    "actor_loss": -58.00267028808594,
    "critic_loss": 89.26467895507812,
    "ent_coef": 0.08534950017929077,
    "learning_rate": 0.001
  },
  {
    "episode": 2725,
    "reward": 85.121549,
    "length": 74,
    "time": 45482.205701,
    "actor_loss": -64.2548828125,
    "critic_loss": 10.14961051940918,
    "ent_coef": 0.08602597564458847,
    "learning_rate": 0.001
  },
  {
    "episode": 2726,
    "reward": 83.295089,
    "length": 74,
    "time": 45496.334694,
    "actor_loss": -66.44757080078125,
    "critic_loss": 58.947723388671875,
    "ent_coef": 0.08993563055992126,
    "learning_rate": 0.001
  },
  {
    "episode": 2727,
    "reward": 79.192743,
    "length": 84,
    "time": 45511.573473,
    "actor_loss": -59.87716293334961,
    "critic_loss": 18.68301010131836,
    "ent_coef": 0.09015202522277832,
    "learning_rate": 0.001
  },
  {
    "episode": 2728,
    "reward": 82.567901,
    "length": 78,
    "time": 45526.611888,
    "actor_loss": -56.61254119873047,
    "critic_loss": 5.854427814483643,
    "ent_coef": 0.08986202627420425,
    "learning_rate": 0.001
  },
  {
    "episode": 2729,
    "reward": 73.628925,
    "length": 93,
    "time": 45542.762667,
    "actor_loss": -60.385311126708984,
    "critic_loss": 6.05788516998291,
    "ent_coef": 0.08786829560995102,
    "learning_rate": 0.001
  },
  {
    "episode": 2730,
    "reward": 83.059191,
    "length": 76,
    "time": 45558.019717,
    "actor_loss": -62.151092529296875,
    "critic_loss": 4.329785346984863,
    "ent_coef": 0.09181942790746689,
    "learning_rate": 0.001
  },
  {
    "episode": 2731,
    "reward": 84.906153,
    "length": 74,
    "time": 45573.233358,
    "actor_loss": -56.426666259765625,
    "critic_loss": 7.545942783355713,
    "ent_coef": 0.0956137552857399,
    "learning_rate": 0.001
  },
  {
    "episode": 2732,
    "reward": 80.329053,
    "length": 84,
    "time": 45588.993711,
    "actor_loss": -59.422306060791016,
    "critic_loss": 3.2545461654663086,
    "ent_coef": 0.09684852510690689,
    "learning_rate": 0.001
  },
  {
    "episode": 2733,
    "reward": 78.444874,
    "length": 86,
    "time": 45604.637275,
    "actor_loss": -62.91893005371094,
    "critic_loss": 35.00910186767578,
    "ent_coef": 0.0939273089170456,
    "learning_rate": 0.001
  },
  {
    "episode": 2734,
    "reward": 84.816792,
    "length": 73,
    "time": 45617.613386,
    "actor_loss": -62.46870422363281,
    "critic_loss": 4.694640636444092,
    "ent_coef": 0.08904697746038437,
    "learning_rate": 0.001
  },
  {
    "episode": 2735,
    "reward": 81.200025,
    "length": 81,
    "time": 45631.145536,
    "actor_loss": -61.51331329345703,
    "critic_loss": 4.015105247497559,
    "ent_coef": 0.08471342921257019,
    "learning_rate": 0.001
  },
  {
    "episode": 2736,
    "reward": 77.870986,
    "length": 87,
    "time": 45649.155573,
    "actor_loss": -61.303462982177734,
    "critic_loss": 5.955239295959473,
    "ent_coef": 0.08140362054109573,
    "learning_rate": 0.001
  },
  {
    "episode": 2737,
    "reward": 85.814201,
    "length": 69,
    "time": 45662.232671,
    "actor_loss": -59.821815490722656,
    "critic_loss": 3.301194190979004,
    "ent_coef": 0.08649212121963501,
    "learning_rate": 0.001
  },
  {
    "episode": 2738,
    "reward": 81.206965,
    "length": 80,
    "time": 45678.651634,
    "actor_loss": -60.90989303588867,
    "critic_loss": 3.837695598602295,
    "ent_coef": 0.09030736237764359,
    "learning_rate": 0.001
  },
  {
    "episode": 2739,
    "reward": 86.619783,
    "length": 68,
    "time": 45690.41759,
    "actor_loss": -59.51158142089844,
    "critic_loss": 5.123140335083008,
    "ent_coef": 0.10007265210151672,
    "learning_rate": 0.001
  },
  {
    "episode": 2740,
    "reward": 88.66812,
    "length": 64,
    "time": 45701.991693,
    "actor_loss": -60.70148468017578,
    "critic_loss": 3.5799107551574707,
    "ent_coef": 0.107290118932724,
    "learning_rate": 0.001
  },
  {
    "episode": 2741,
    "reward": 84.050655,
    "length": 74,
    "time": 45715.782584,
    "actor_loss": -66.9874267578125,
    "critic_loss": 63.07777786254883,
    "ent_coef": 0.1061168760061264,
    "learning_rate": 0.001
  },
  {
    "episode": 2742,
    "reward": 85.332168,
    "length": 71,
    "time": 45728.765451,
    "actor_loss": -65.57058715820312,
    "critic_loss": 36.37736511230469,
    "ent_coef": 0.10746117681264877,
    "learning_rate": 0.001
  },
  {
    "episode": 2743,
    "reward": 84.490417,
    "length": 74,
    "time": 45744.031483,
    "actor_loss": -59.183143615722656,
    "critic_loss": 3.089779853820801,
    "ent_coef": 0.10369846224784851,
    "learning_rate": 0.001
  },
  {
    "episode": 2744,
    "reward": 84.094552,
    "length": 75,
    "time": 45758.832818,
    "actor_loss": -61.1392936706543,
    "critic_loss": 4.859349250793457,
    "ent_coef": 0.09896896779537201,
    "learning_rate": 0.001
  },
  {
    "episode": 2745,
    "reward": 90.154885,
    "length": 63,
    "time": 45769.825768,
    "actor_loss": -56.67530822753906,
    "critic_loss": 5.988831520080566,
    "ent_coef": 0.10018611699342728,
    "learning_rate": 0.001
  },
  {
    "episode": 2746,
    "reward": 85.042078,
    "length": 69,
    "time": 45783.596212,
    "actor_loss": -61.481040954589844,
    "critic_loss": 13.735077857971191,
    "ent_coef": 0.10510514676570892,
    "learning_rate": 0.001
  },
  {
    "episode": 2747,
    "reward": 85.544405,
    "length": 73,
    "time": 45796.026464,
    "actor_loss": -56.00579833984375,
    "critic_loss": 6.967219829559326,
    "ent_coef": 0.10223951935768127,
    "learning_rate": 0.001
  },
  {
    "episode": 2748,
    "reward": 86.150516,
    "length": 68,
    "time": 45810.248857,
    "actor_loss": -66.70372772216797,
    "critic_loss": 2.8225154876708984,
    "ent_coef": 0.10805132240056992,
    "learning_rate": 0.001
  },
  {
    "episode": 2749,
    "reward": 83.495393,
    "length": 77,
    "time": 45825.235398,
    "actor_loss": -60.70286560058594,
    "critic_loss": 12.44466495513916,
    "ent_coef": 0.10903827100992203,
    "learning_rate": 0.001
  },
  {
    "episode": 2750,
    "reward": 73.832573,
    "length": 85,
    "time": 45840.691726,
    "actor_loss": -59.903419494628906,
    "critic_loss": 87.27151489257812,
    "ent_coef": 0.11542297899723053,
    "learning_rate": 0.001
  },
  {
    "episode": 2751,
    "reward": 88.543673,
    "length": 66,
    "time": 45852.370636,
    "actor_loss": -62.05323028564453,
    "critic_loss": 29.05899429321289,
    "ent_coef": 0.1148529052734375,
    "learning_rate": 0.001
  },
  {
    "episode": 2752,
    "reward": 86.970682,
    "length": 68,
    "time": 45864.494271,
    "actor_loss": -60.15876007080078,
    "critic_loss": 309.10919189453125,
    "ent_coef": 0.11306917667388916,
    "learning_rate": 0.001
  },
  {
    "episode": 2753,
    "reward": 88.824421,
    "length": 65,
    "time": 45875.839102,
    "actor_loss": -60.633087158203125,
    "critic_loss": 2.6857028007507324,
    "ent_coef": 0.11133354157209396,
    "learning_rate": 0.001
  },
  {
    "episode": 2754,
    "reward": 87.697581,
    "length": 67,
    "time": 45889.894922,
    "actor_loss": -60.2396240234375,
    "critic_loss": 12.303295135498047,
    "ent_coef": 0.10964923352003098,
    "learning_rate": 0.001
  },
  {
    "episode": 2755,
    "reward": 76.896736,
    "length": 81,
    "time": 45903.651899,
    "actor_loss": -51.20521926879883,
    "critic_loss": 6.432828426361084,
    "ent_coef": 0.11388181895017624,
    "learning_rate": 0.001
  },
  {
    "episode": 2756,
    "reward": 82.130828,
    "length": 79,
    "time": 45916.925782,
    "actor_loss": -59.16331481933594,
    "critic_loss": 7.179933547973633,
    "ent_coef": 0.10911805927753448,
    "learning_rate": 0.001
  },
  {
    "episode": 2757,
    "reward": 90.686693,
    "length": 62,
    "time": 45931.474596,
    "actor_loss": -60.68886184692383,
    "critic_loss": 4.540317535400391,
    "ent_coef": 0.10892046242952347,
    "learning_rate": 0.001
  },
  {
    "episode": 2758,
    "reward": 83.144346,
    "length": 76,
    "time": 45945.223226,
    "actor_loss": -59.533592224121094,
    "critic_loss": 36.26011657714844,
    "ent_coef": 0.10661581158638,
    "learning_rate": 0.001
  },
  {
    "episode": 2759,
    "reward": 87.077366,
    "length": 69,
    "time": 45957.603987,
    "actor_loss": -61.90019989013672,
    "critic_loss": 166.22744750976562,
    "ent_coef": 0.10389524698257446,
    "learning_rate": 0.001
  },
  {
    "episode": 2760,
    "reward": 87.612937,
    "length": 68,
    "time": 45971.265415,
    "actor_loss": -62.558902740478516,
    "critic_loss": 5.064160346984863,
    "ent_coef": 0.10485225915908813,
    "learning_rate": 0.001
  },
  {
    "episode": 2761,
    "reward": 84.134685,
    "length": 72,
    "time": 45985.027335,
    "actor_loss": -59.68523025512695,
    "critic_loss": 27.965240478515625,
    "ent_coef": 0.10110579431056976,
    "learning_rate": 0.001
  },
  {
    "episode": 2762,
    "reward": 83.653476,
    "length": 72,
    "time": 45997.294068,
    "actor_loss": -59.372772216796875,
    "critic_loss": 16.193031311035156,
    "ent_coef": 0.10162568837404251,
    "learning_rate": 0.001
  },
  {
    "episode": 2763,
    "reward": 88.771354,
    "length": 66,
    "time": 46008.787886,
    "actor_loss": -57.337039947509766,
    "critic_loss": 4.39619779586792,
    "ent_coef": 0.1044648140668869,
    "learning_rate": 0.001
  },
  {
    "episode": 2764,
    "reward": 83.06393,
    "length": 73,
    "time": 46021.37078,
    "actor_loss": -62.655029296875,
    "critic_loss": 3.320145606994629,
    "ent_coef": 0.10728251934051514,
    "learning_rate": 0.001
  },
  {
    "episode": 2765,
    "reward": 89.791055,
    "length": 62,
    "time": 46032.536565,
    "actor_loss": -64.57888793945312,
    "critic_loss": 5.335518836975098,
    "ent_coef": 0.11001329123973846,
    "learning_rate": 0.001
  },
  {
    "episode": 2766,
    "reward": 85.426963,
    "length": 70,
    "time": 46046.248872,
    "actor_loss": -55.33717346191406,
    "critic_loss": 47.8447265625,
    "ent_coef": 0.11172625422477722,
    "learning_rate": 0.001
  },
  {
    "episode": 2767,
    "reward": 86.119624,
    "length": 70,
    "time": 46059.749833,
    "actor_loss": -64.17879486083984,
    "critic_loss": 4.091687202453613,
    "ent_coef": 0.10880587249994278,
    "learning_rate": 0.001
  },
  {
    "episode": 2768,
    "reward": 87.810469,
    "length": 66,
    "time": 46074.073162,
    "actor_loss": -59.286033630371094,
    "critic_loss": 4.21351957321167,
    "ent_coef": 0.10663637518882751,
    "learning_rate": 0.001
  },
  {
    "episode": 2769,
    "reward": 87.58299,
    "length": 67,
    "time": 46085.810436,
    "actor_loss": -55.511573791503906,
    "critic_loss": 6.202506065368652,
    "ent_coef": 0.10231809318065643,
    "learning_rate": 0.001
  },
  {
    "episode": 2770,
    "reward": 86.252391,
    "length": 70,
    "time": 46100.468417,
    "actor_loss": -61.3017578125,
    "critic_loss": 6.36257266998291,
    "ent_coef": 0.10311213880777359,
    "learning_rate": 0.001
  },
  {
    "episode": 2771,
    "reward": 87.032296,
    "length": 69,
    "time": 46115.340739,
    "actor_loss": -59.71092987060547,
    "critic_loss": 4.454533576965332,
    "ent_coef": 0.09611184149980545,
    "learning_rate": 0.001
  },
  {
    "episode": 2772,
    "reward": 68.265309,
    "length": 95,
    "time": 46132.925918,
    "actor_loss": -63.054439544677734,
    "critic_loss": 4.139265060424805,
    "ent_coef": 0.08995042741298676,
    "learning_rate": 0.001
  },
  {
    "episode": 2773,
    "reward": 87.379409,
    "length": 66,
    "time": 46144.217834,
    "actor_loss": -61.41341781616211,
    "critic_loss": 34.02565002441406,
    "ent_coef": 0.09352470189332962,
    "learning_rate": 0.001
  },
  {
    "episode": 2774,
    "reward": 86.953245,
    "length": 67,
    "time": 46157.102475,
    "actor_loss": -58.84348678588867,
    "critic_loss": 69.60165405273438,
    "ent_coef": 0.09359487146139145,
    "learning_rate": 0.001
  },
  {
    "episode": 2775,
    "reward": 90.620662,
    "length": 61,
    "time": 46168.022327,
    "actor_loss": -56.54700469970703,
    "critic_loss": 8.340646743774414,
    "ent_coef": 0.10014043003320694,
    "learning_rate": 0.001
  },
  {
    "episode": 2776,
    "reward": 86.435887,
    "length": 70,
    "time": 46181.352791,
    "actor_loss": -58.29563903808594,
    "critic_loss": 4.607504844665527,
    "ent_coef": 0.09994970262050629,
    "learning_rate": 0.001
  },
  {
    "episode": 2777,
    "reward": 87.198763,
    "length": 69,
    "time": 46193.577785,
    "actor_loss": -55.222328186035156,
    "critic_loss": 12.635406494140625,
    "ent_coef": 0.10005100816488266,
    "learning_rate": 0.001
  },
  {
    "episode": 2778,
    "reward": 85.96356,
    "length": 72,
    "time": 46208.509081,
    "actor_loss": -64.66969299316406,
    "critic_loss": 24.955951690673828,
    "ent_coef": 0.09863518178462982,
    "learning_rate": 0.001
  },
  {
    "episode": 2779,
    "reward": 83.010948,
    "length": 72,
    "time": 46220.873886,
    "actor_loss": -63.19390106201172,
    "critic_loss": 2.746058464050293,
    "ent_coef": 0.10124003142118454,
    "learning_rate": 0.001
  },
  {
    "episode": 2780,
    "reward": 89.937806,
    "length": 65,
    "time": 46233.229089,
    "actor_loss": -59.46125793457031,
    "critic_loss": 2.770311117172241,
    "ent_coef": 0.1015075147151947,
    "learning_rate": 0.001
  },
  {
    "episode": 2781,
    "reward": 89.546147,
    "length": 63,
    "time": 46244.892176,
    "actor_loss": -60.29467010498047,
    "critic_loss": 11.301834106445312,
    "ent_coef": 0.1076875701546669,
    "learning_rate": 0.001
  },
  {
    "episode": 2782,
    "reward": 88.083149,
    "length": 67,
    "time": 46256.517946,
    "actor_loss": -66.1562728881836,
    "critic_loss": 5.540585994720459,
    "ent_coef": 0.11033780872821808,
    "learning_rate": 0.001
  },
  {
    "episode": 2783,
    "reward": 87.20278,
    "length": 67,
    "time": 46269.096364,
    "actor_loss": -64.93563079833984,
    "critic_loss": 65.30204010009766,
    "ent_coef": 0.1081739142537117,
    "learning_rate": 0.001
  },
  {
    "episode": 2784,
    "reward": 83.127397,
    "length": 75,
    "time": 46282.881603,
    "actor_loss": -62.210533142089844,
    "critic_loss": 2.099283218383789,
    "ent_coef": 0.10675626248121262,
    "learning_rate": 0.001
  },
  {
    "episode": 2785,
    "reward": 89.164208,
    "length": 64,
    "time": 46296.845197,
    "actor_loss": -66.71907806396484,
    "critic_loss": 20.859216690063477,
    "ent_coef": 0.10512439906597137,
    "learning_rate": 0.001
  },
  {
    "episode": 2786,
    "reward": 89.156794,
    "length": 64,
    "time": 46311.646577,
    "actor_loss": -57.605430603027344,
    "critic_loss": 25.88039779663086,
    "ent_coef": 0.10877947509288788,
    "learning_rate": 0.001
  },
  {
    "episode": 2787,
    "reward": 85.319748,
    "length": 72,
    "time": 46328.560758,
    "actor_loss": -65.40786743164062,
    "critic_loss": 3.5561513900756836,
    "ent_coef": 0.11209037154912949,
    "learning_rate": 0.001
  },
  {
    "episode": 2788,
    "reward": 84.460502,
    "length": 72,
    "time": 46342.944664,
    "actor_loss": -59.30144500732422,
    "critic_loss": 7.810944080352783,
    "ent_coef": 0.11425402015447617,
    "learning_rate": 0.001
  },
  {
    "episode": 2789,
    "reward": 89.101354,
    "length": 64,
    "time": 46355.208776,
    "actor_loss": -60.61124038696289,
    "critic_loss": 4.958969593048096,
    "ent_coef": 0.11686724424362183,
    "learning_rate": 0.001
  },
  {
    "episode": 2790,
    "reward": 85.745029,
    "length": 70,
    "time": 46370.466635,
    "actor_loss": -59.05433654785156,
    "critic_loss": 3.2159061431884766,
    "ent_coef": 0.11667684465646744,
    "learning_rate": 0.001
  },
  {
    "episode": 2791,
    "reward": 80.777867,
    "length": 77,
    "time": 46386.312731,
    "actor_loss": -61.94832992553711,
    "critic_loss": 4.846466064453125,
    "ent_coef": 0.1118900403380394,
    "learning_rate": 0.001
  },
  {
    "episode": 2792,
    "reward": 83.113436,
    "length": 73,
    "time": 46400.821698,
    "actor_loss": -61.897422790527344,
    "critic_loss": 2.758862018585205,
    "ent_coef": 0.11018358170986176,
    "learning_rate": 0.001
  },
  {
    "episode": 2793,
    "reward": 87.877435,
    "length": 67,
    "time": 46412.360013,
    "actor_loss": -66.82008361816406,
    "critic_loss": 5.009273529052734,
    "ent_coef": 0.10621435940265656,
    "learning_rate": 0.001
  },
  {
    "episode": 2794,
    "reward": 87.69948,
    "length": 66,
    "time": 46423.959196,
    "actor_loss": -57.20875930786133,
    "critic_loss": 18.806671142578125,
    "ent_coef": 0.10367685556411743,
    "learning_rate": 0.001
  },
  {
    "episode": 2795,
    "reward": 85.98563,
    "length": 69,
    "time": 46436.205573,
    "actor_loss": -58.85021209716797,
    "critic_loss": 32.24024963378906,
    "ent_coef": 0.1055804118514061,
    "learning_rate": 0.001
  },
  {
    "episode": 2796,
    "reward": 88.435653,
    "length": 66,
    "time": 46450.653033,
    "actor_loss": -61.851173400878906,
    "critic_loss": 9.33781909942627,
    "ent_coef": 0.1122845858335495,
    "learning_rate": 0.001
  },
  {
    "episode": 2797,
    "reward": 78.720579,
    "length": 81,
    "time": 46466.022782,
    "actor_loss": -56.780677795410156,
    "critic_loss": 21.727136611938477,
    "ent_coef": 0.10662735253572464,
    "learning_rate": 0.001
  },
  {
    "episode": 2798,
    "reward": 72.453287,
    "length": 89,
    "time": 46483.87189,
    "actor_loss": -61.7679557800293,
    "critic_loss": 8.730110168457031,
    "ent_coef": 0.09704418480396271,
    "learning_rate": 0.001
  },
  {
    "episode": 2799,
    "reward": 88.905885,
    "length": 65,
    "time": 46497.12295,
    "actor_loss": -64.7544937133789,
    "critic_loss": 4.3426642417907715,
    "ent_coef": 0.09475690126419067,
    "learning_rate": 0.001
  },
  {
    "episode": 2800,
    "reward": 81.153947,
    "length": 76,
    "time": 46512.235213,
    "actor_loss": -55.909263610839844,
    "critic_loss": 37.381263732910156,
    "ent_coef": 0.09453488141298294,
    "learning_rate": 0.001
  },
  {
    "episode": 2801,
    "reward": 85.556371,
    "length": 70,
    "time": 46525.415985,
    "actor_loss": -60.40816116333008,
    "critic_loss": 7.562994003295898,
    "ent_coef": 0.0927581787109375,
    "learning_rate": 0.001
  },
  {
    "episode": 2802,
    "reward": 83.962442,
    "length": 77,
    "time": 46538.299808,
    "actor_loss": -56.375511169433594,
    "critic_loss": 2.731323719024658,
    "ent_coef": 0.09368819743394852,
    "learning_rate": 0.001
  },
  {
    "episode": 2803,
    "reward": 79.729106,
    "length": 77,
    "time": 46551.550336,
    "actor_loss": -63.781341552734375,
    "critic_loss": 10.572261810302734,
    "ent_coef": 0.0942036509513855,
    "learning_rate": 0.001
  },
  {
    "episode": 2804,
    "reward": 84.860828,
    "length": 72,
    "time": 46566.056155,
    "actor_loss": -58.27660369873047,
    "critic_loss": 66.66329956054688,
    "ent_coef": 0.0914425402879715,
    "learning_rate": 0.001
  },
  {
    "episode": 2805,
    "reward": 86.993147,
    "length": 68,
    "time": 46578.62838,
    "actor_loss": -60.86613845825195,
    "critic_loss": 5.490936756134033,
    "ent_coef": 0.08812299370765686,
    "learning_rate": 0.001
  },
  {
    "episode": 2806,
    "reward": 89.786576,
    "length": 63,
    "time": 46589.679096,
    "actor_loss": -59.29429244995117,
    "critic_loss": 6.519810676574707,
    "ent_coef": 0.09201005846261978,
    "learning_rate": 0.001
  },
  {
    "episode": 2807,
    "reward": 87.846896,
    "length": 66,
    "time": 46604.131317,
    "actor_loss": -60.32275390625,
    "critic_loss": 5.054917812347412,
    "ent_coef": 0.09151285141706467,
    "learning_rate": 0.001
  },
  {
    "episode": 2808,
    "reward": 84.098132,
    "length": 74,
    "time": 46620.396953,
    "actor_loss": -64.16748046875,
    "critic_loss": 21.91900634765625,
    "ent_coef": 0.0862339586019516,
    "learning_rate": 0.001
  },
  {
    "episode": 2809,
    "reward": 85.052416,
    "length": 71,
    "time": 46633.699988,
    "actor_loss": -61.177547454833984,
    "critic_loss": 51.64330291748047,
    "ent_coef": 0.0832473412156105,
    "learning_rate": 0.001
  },
  {
    "episode": 2810,
    "reward": 80.348847,
    "length": 77,
    "time": 46646.664719,
    "actor_loss": -59.48391342163086,
    "critic_loss": 5.77680778503418,
    "ent_coef": 0.08069764077663422,
    "learning_rate": 0.001
  },
  {
    "episode": 2811,
    "reward": 88.168237,
    "length": 66,
    "time": 46661.284279,
    "actor_loss": -56.453956604003906,
    "critic_loss": 45.40789794921875,
    "ent_coef": 0.07990239560604095,
    "learning_rate": 0.001
  },
  {
    "episode": 2812,
    "reward": 90.758846,
    "length": 62,
    "time": 46674.01814,
    "actor_loss": -62.61050796508789,
    "critic_loss": 3.6741394996643066,
    "ent_coef": 0.08677097409963608,
    "learning_rate": 0.001
  },
  {
    "episode": 2813,
    "reward": 88.384377,
    "length": 65,
    "time": 46685.340647,
    "actor_loss": -64.59648132324219,
    "critic_loss": 8.309782028198242,
    "ent_coef": 0.08743174374103546,
    "learning_rate": 0.001
  },
  {
    "episode": 2814,
    "reward": 89.722956,
    "length": 63,
    "time": 46696.700916,
    "actor_loss": -58.981632232666016,
    "critic_loss": 3.149571657180786,
    "ent_coef": 0.09267638623714447,
    "learning_rate": 0.001
  },
  {
    "episode": 2815,
    "reward": 89.829224,
    "length": 63,
    "time": 46708.792606,
    "actor_loss": -56.97549819946289,
    "critic_loss": 4.421864986419678,
    "ent_coef": 0.09505920857191086,
    "learning_rate": 0.001
  },
  {
    "episode": 2816,
    "reward": 91.14911,
    "length": 61,
    "time": 46721.372187,
    "actor_loss": -62.536441802978516,
    "critic_loss": 1.9661989212036133,
    "ent_coef": 0.09801525622606277,
    "learning_rate": 0.001
  },
  {
    "episode": 2817,
    "reward": 87.745013,
    "length": 66,
    "time": 46735.285228,
    "actor_loss": -61.675018310546875,
    "critic_loss": 91.02799987792969,
    "ent_coef": 0.09751223772764206,
    "learning_rate": 0.001
  },
  {
    "episode": 2818,
    "reward": 90.05021,
    "length": 63,
    "time": 46748.979816,
    "actor_loss": -62.39122009277344,
    "critic_loss": 5.974109172821045,
    "ent_coef": 0.09948937594890594,
    "learning_rate": 0.001
  },
  {
    "episode": 2819,
    "reward": 87.776115,
    "length": 67,
    "time": 46761.148459,
    "actor_loss": -66.14222717285156,
    "critic_loss": 4.1698760986328125,
    "ent_coef": 0.09741411358118057,
    "learning_rate": 0.001
  },
  {
    "episode": 2820,
    "reward": 83.421204,
    "length": 74,
    "time": 46774.481523,
    "actor_loss": -53.605289459228516,
    "critic_loss": 42.38976287841797,
    "ent_coef": 0.09578408300876617,
    "learning_rate": 0.001
  },
  {
    "episode": 2821,
    "reward": 85.716445,
    "length": 72,
    "time": 46787.391443,
    "actor_loss": -57.673683166503906,
    "critic_loss": 7.988083839416504,
    "ent_coef": 0.09298939257860184,
    "learning_rate": 0.001
  },
  {
    "episode": 2822,
    "reward": 83.496237,
    "length": 74,
    "time": 46801.207389,
    "actor_loss": -59.6524543762207,
    "critic_loss": 6.229604721069336,
    "ent_coef": 0.08954314887523651,
    "learning_rate": 0.001
  },
  {
    "episode": 2823,
    "reward": 82.164134,
    "length": 77,
    "time": 46814.501875,
    "actor_loss": -63.95177459716797,
    "critic_loss": 9.477312088012695,
    "ent_coef": 0.08712407201528549,
    "learning_rate": 0.001
  },
  {
    "episode": 2824,
    "reward": 89.039526,
    "length": 65,
    "time": 46826.029564,
    "actor_loss": -61.40745162963867,
    "critic_loss": 46.83577346801758,
    "ent_coef": 0.09218873828649521,
    "learning_rate": 0.001
  },
  {
    "episode": 2825,
    "reward": 90.660882,
    "length": 62,
    "time": 46837.491044,
    "actor_loss": -59.93522644042969,
    "critic_loss": 11.16097640991211,
    "ent_coef": 0.09362225234508514,
    "learning_rate": 0.001
  },
  {
    "episode": 2826,
    "reward": 87.528941,
    "length": 68,
    "time": 46850.321019,
    "actor_loss": -62.774078369140625,
    "critic_loss": 2.405913829803467,
    "ent_coef": 0.09183931350708008,
    "learning_rate": 0.001
  },
  {
    "episode": 2827,
    "reward": 82.918713,
    "length": 73,
    "time": 46863.12936,
    "actor_loss": -57.916099548339844,
    "critic_loss": 6.078214645385742,
    "ent_coef": 0.09250465780496597,
    "learning_rate": 0.001
  },
  {
    "episode": 2828,
    "reward": 86.140647,
    "length": 69,
    "time": 46875.624761,
    "actor_loss": -54.82633972167969,
    "critic_loss": 5.986952304840088,
    "ent_coef": 0.09112628549337387,
    "learning_rate": 0.001
  },
  {
    "episode": 2829,
    "reward": 82.942146,
    "length": 75,
    "time": 46888.781937,
    "actor_loss": -58.878761291503906,
    "critic_loss": 4.567838668823242,
    "ent_coef": 0.09075476229190826,
    "learning_rate": 0.001
  },
  {
    "episode": 2830,
    "reward": 76.784732,
    "length": 82,
    "time": 46903.173446,
    "actor_loss": -61.43036651611328,
    "critic_loss": 105.49617004394531,
    "ent_coef": 0.0907701700925827,
    "learning_rate": 0.001
  },
  {
    "episode": 2831,
    "reward": 88.521505,
    "length": 66,
    "time": 46915.931267,
    "actor_loss": -54.49039077758789,
    "critic_loss": 3.4858639240264893,
    "ent_coef": 0.08909019082784653,
    "learning_rate": 0.001
  },
  {
    "episode": 2832,
    "reward": 88.511731,
    "length": 66,
    "time": 46928.110985,
    "actor_loss": -60.41901397705078,
    "critic_loss": 4.246088981628418,
    "ent_coef": 0.09041670709848404,
    "learning_rate": 0.001
  },
  {
    "episode": 2833,
    "reward": 79.482092,
    "length": 79,
    "time": 46944.673441,
    "actor_loss": -67.23016357421875,
    "critic_loss": 4.908504009246826,
    "ent_coef": 0.09471862018108368,
    "learning_rate": 0.001
  },
  {
    "episode": 2834,
    "reward": 85.74929,
    "length": 71,
    "time": 46958.286759,
    "actor_loss": -59.863460540771484,
    "critic_loss": 10.046201705932617,
    "ent_coef": 0.0929574966430664,
    "learning_rate": 0.001
  },
  {
    "episode": 2835,
    "reward": 88.394709,
    "length": 65,
    "time": 46971.382535,
    "actor_loss": -61.5111198425293,
    "critic_loss": 6.470794677734375,
    "ent_coef": 0.09359384328126907,
    "learning_rate": 0.001
  },
  {
    "episode": 2836,
    "reward": 82.742339,
    "length": 73,
    "time": 46985.731625,
    "actor_loss": -59.6788330078125,
    "critic_loss": 12.19730281829834,
    "ent_coef": 0.09743241220712662,
    "learning_rate": 0.001
  },
  {
    "episode": 2837,
    "reward": 89.183279,
    "length": 64,
    "time": 46998.721728,
    "actor_loss": -65.83534240722656,
    "critic_loss": 43.464866638183594,
    "ent_coef": 0.09531748294830322,
    "learning_rate": 0.001
  },
  {
    "episode": 2838,
    "reward": 88.741466,
    "length": 66,
    "time": 47010.620747,
    "actor_loss": -57.35646057128906,
    "critic_loss": 5.8771820068359375,
    "ent_coef": 0.09459253400564194,
    "learning_rate": 0.001
  },
  {
    "episode": 2839,
    "reward": 88.186887,
    "length": 65,
    "time": 47022.240909,
    "actor_loss": -65.75191497802734,
    "critic_loss": 7.406116485595703,
    "ent_coef": 0.09947285801172256,
    "learning_rate": 0.001
  },
  {
    "episode": 2840,
    "reward": 87.704155,
    "length": 66,
    "time": 47034.198742,
    "actor_loss": -62.53642654418945,
    "critic_loss": 7.952784061431885,
    "ent_coef": 0.10034783184528351,
    "learning_rate": 0.001
  },
  {
    "episode": 2841,
    "reward": 85.932583,
    "length": 69,
    "time": 47048.600537,
    "actor_loss": -71.81610870361328,
    "critic_loss": 62.86615753173828,
    "ent_coef": 0.09659000486135483,
    "learning_rate": 0.001
  },
  {
    "episode": 2842,
    "reward": 74.183542,
    "length": 86,
    "time": 47064.129475,
    "actor_loss": -58.32416915893555,
    "critic_loss": 13.338299751281738,
    "ent_coef": 0.0946333184838295,
    "learning_rate": 0.001
  },
  {
    "episode": 2843,
    "reward": 87.55264,
    "length": 67,
    "time": 47076.165528,
    "actor_loss": -60.44292449951172,
    "critic_loss": 212.543701171875,
    "ent_coef": 0.09289909154176712,
    "learning_rate": 0.001
  },
  {
    "episode": 2844,
    "reward": 88.569713,
    "length": 66,
    "time": 47088.862015,
    "actor_loss": -56.68843460083008,
    "critic_loss": 2.6929869651794434,
    "ent_coef": 0.09856481850147247,
    "learning_rate": 0.001
  },
  {
    "episode": 2845,
    "reward": 85.992324,
    "length": 68,
    "time": 47100.853517,
    "actor_loss": -57.1802978515625,
    "critic_loss": 3.3274765014648438,
    "ent_coef": 0.1018456295132637,
    "learning_rate": 0.001
  },
  {
    "episode": 2846,
    "reward": 89.314951,
    "length": 64,
    "time": 47112.123325,
    "actor_loss": -67.044677734375,
    "critic_loss": 29.03364372253418,
    "ent_coef": 0.10153966397047043,
    "learning_rate": 0.001
  },
  {
    "episode": 2847,
    "reward": 86.291199,
    "length": 72,
    "time": 47124.918717,
    "actor_loss": -64.54432678222656,
    "critic_loss": 19.577299118041992,
    "ent_coef": 0.09812576323747635,
    "learning_rate": 0.001
  },
  {
    "episode": 2848,
    "reward": 72.651052,
    "length": 86,
    "time": 47140.491179,
    "actor_loss": -63.10338592529297,
    "critic_loss": 5.071060657501221,
    "ent_coef": 0.09280062466859818,
    "learning_rate": 0.001
  },
  {
    "episode": 2849,
    "reward": 86.705063,
    "length": 69,
    "time": 47155.07757,
    "actor_loss": -58.626731872558594,
    "critic_loss": 14.693156242370605,
    "ent_coef": 0.08845916390419006,
    "learning_rate": 0.001
  },
  {
    "episode": 2850,
    "reward": 88.492256,
    "length": 65,
    "time": 47170.393666,
    "actor_loss": -61.364532470703125,
    "critic_loss": 66.08161163330078,
    "ent_coef": 0.08799053728580475,
    "learning_rate": 0.001
  },
  {
    "episode": 2851,
    "reward": 89.468401,
    "length": 63,
    "time": 47183.802707,
    "actor_loss": -62.346923828125,
    "critic_loss": 3.0372180938720703,
    "ent_coef": 0.087948277592659,
    "learning_rate": 0.001
  },
  {
    "episode": 2852,
    "reward": 84.399029,
    "length": 72,
    "time": 47196.084169,
    "actor_loss": -61.27392578125,
    "critic_loss": 4.326889514923096,
    "ent_coef": 0.09125114232301712,
    "learning_rate": 0.001
  },
  {
    "episode": 2853,
    "reward": 84.468427,
    "length": 72,
    "time": 47210.829993,
    "actor_loss": -56.97853469848633,
    "critic_loss": 7.685616493225098,
    "ent_coef": 0.09424469619989395,
    "learning_rate": 0.001
  },
  {
    "episode": 2854,
    "reward": 80.563049,
    "length": 77,
    "time": 47225.042884,
    "actor_loss": -62.37920379638672,
    "critic_loss": 4.313569068908691,
    "ent_coef": 0.09216265380382538,
    "learning_rate": 0.001
  },
  {
    "episode": 2855,
    "reward": 83.180498,
    "length": 73,
    "time": 47239.487357,
    "actor_loss": -62.369110107421875,
    "critic_loss": 12.075511932373047,
    "ent_coef": 0.09139475971460342,
    "learning_rate": 0.001
  },
  {
    "episode": 2856,
    "reward": 91.591427,
    "length": 61,
    "time": 47251.372583,
    "actor_loss": -62.670570373535156,
    "critic_loss": 2.566640615463257,
    "ent_coef": 0.09851637482643127,
    "learning_rate": 0.001
  },
  {
    "episode": 2857,
    "reward": 88.954059,
    "length": 65,
    "time": 47265.211359,
    "actor_loss": -62.380950927734375,
    "critic_loss": 4.737906455993652,
    "ent_coef": 0.09977587312459946,
    "learning_rate": 0.001
  },
  {
    "episode": 2858,
    "reward": 81.163569,
    "length": 78,
    "time": 47280.399855,
    "actor_loss": -65.83114624023438,
    "critic_loss": 2.2048535346984863,
    "ent_coef": 0.09578444808721542,
    "learning_rate": 0.001
  },
  {
    "episode": 2859,
    "reward": 86.859534,
    "length": 69,
    "time": 47292.370019,
    "actor_loss": -64.2428207397461,
    "critic_loss": 4.073949337005615,
    "ent_coef": 0.09292611479759216,
    "learning_rate": 0.001
  },
  {
    "episode": 2860,
    "reward": 84.976238,
    "length": 71,
    "time": 47304.832841,
    "actor_loss": -64.93930053710938,
    "critic_loss": 9.392556190490723,
    "ent_coef": 0.08827805519104004,
    "learning_rate": 0.001
  },
  {
    "episode": 2861,
    "reward": 86.66406,
    "length": 69,
    "time": 47317.120573,
    "actor_loss": -58.899818420410156,
    "critic_loss": 34.09149169921875,
    "ent_coef": 0.08869659900665283,
    "learning_rate": 0.001
  },
  {
    "episode": 2862,
    "reward": 87.331367,
    "length": 68,
    "time": 47328.938973,
    "actor_loss": -59.80500030517578,
    "critic_loss": 4.301390647888184,
    "ent_coef": 0.09023096412420273,
    "learning_rate": 0.001
  },
  {
    "episode": 2863,
    "reward": 74.874338,
    "length": 88,
    "time": 47345.34654,
    "actor_loss": -56.69273376464844,
    "critic_loss": 3.733201026916504,
    "ent_coef": 0.08724762499332428,
    "learning_rate": 0.001
  },
  {
    "episode": 2864,
    "reward": 85.390284,
    "length": 71,
    "time": 47357.623331,
    "actor_loss": -60.561519622802734,
    "critic_loss": 103.6212158203125,
    "ent_coef": 0.08526535332202911,
    "learning_rate": 0.001
  },
  {
    "episode": 2865,
    "reward": 88.567205,
    "length": 66,
    "time": 47372.037686,
    "actor_loss": -57.93068313598633,
    "critic_loss": 12.104082107543945,
    "ent_coef": 0.08834545314311981,
    "learning_rate": 0.001
  },
  {
    "episode": 2866,
    "reward": 87.043836,
    "length": 69,
    "time": 47384.640062,
    "actor_loss": -63.4486198425293,
    "critic_loss": 20.77242660522461,
    "ent_coef": 0.09094064682722092,
    "learning_rate": 0.001
  },
  {
    "episode": 2867,
    "reward": 85.677726,
    "length": 70,
    "time": 47399.666163,
    "actor_loss": -63.97935485839844,
    "critic_loss": 6.605008125305176,
    "ent_coef": 0.09091658145189285,
    "learning_rate": 0.001
  },
  {
    "episode": 2868,
    "reward": 87.40649,
    "length": 68,
    "time": 47412.532726,
    "actor_loss": -61.04131317138672,
    "critic_loss": 120.51962280273438,
    "ent_coef": 0.09302014857530594,
    "learning_rate": 0.001
  },
  {
    "episode": 2869,
    "reward": 76.912293,
    "length": 82,
    "time": 47427.04685,
    "actor_loss": -63.271888732910156,
    "critic_loss": 4.293246269226074,
    "ent_coef": 0.09319248795509338,
    "learning_rate": 0.001
  },
  {
    "episode": 2870,
    "reward": 80.798592,
    "length": 84,
    "time": 47442.748158,
    "actor_loss": -54.878475189208984,
    "critic_loss": 8.576658248901367,
    "ent_coef": 0.09685293585062027,
    "learning_rate": 0.001
  },
  {
    "episode": 2871,
    "reward": 84.255787,
    "length": 74,
    "time": 47460.078783,
    "actor_loss": -64.64234161376953,
    "critic_loss": 80.05690002441406,
    "ent_coef": 0.09877651184797287,
    "learning_rate": 0.001
  },
  {
    "episode": 2872,
    "reward": 82.183568,
    "length": 74,
    "time": 47473.637829,
    "actor_loss": -62.86687469482422,
    "critic_loss": 3.3691351413726807,
    "ent_coef": 0.10404357314109802,
    "learning_rate": 0.001
  },
  {
    "episode": 2873,
    "reward": 90.727584,
    "length": 62,
    "time": 47486.635147,
    "actor_loss": -66.15458679199219,
    "critic_loss": 15.990592956542969,
    "ent_coef": 0.10895275324583054,
    "learning_rate": 0.001
  },
  {
    "episode": 2874,
    "reward": 86.970559,
    "length": 69,
    "time": 47498.976751,
    "actor_loss": -66.62992858886719,
    "critic_loss": 5.013603687286377,
    "ent_coef": 0.10741952061653137,
    "learning_rate": 0.001
  },
  {
    "episode": 2875,
    "reward": 87.166854,
    "length": 70,
    "time": 47513.389529,
    "actor_loss": -60.97643280029297,
    "critic_loss": 8.96908187866211,
    "ent_coef": 0.10265085846185684,
    "learning_rate": 0.001
  },
  {
    "episode": 2876,
    "reward": 87.556424,
    "length": 67,
    "time": 47526.92335,
    "actor_loss": -69.19160461425781,
    "critic_loss": 12.766167640686035,
    "ent_coef": 0.09919203072786331,
    "learning_rate": 0.001
  },
  {
    "episode": 2877,
    "reward": 87.04927,
    "length": 71,
    "time": 47539.195953,
    "actor_loss": -62.09149932861328,
    "critic_loss": 11.887134552001953,
    "ent_coef": 0.09517570585012436,
    "learning_rate": 0.001
  },
  {
    "episode": 2878,
    "reward": 86.657775,
    "length": 71,
    "time": 47555.485787,
    "actor_loss": -66.96134948730469,
    "critic_loss": 77.57108306884766,
    "ent_coef": 0.09127254784107208,
    "learning_rate": 0.001
  },
  {
    "episode": 2879,
    "reward": 83.795838,
    "length": 74,
    "time": 47569.373705,
    "actor_loss": -59.117454528808594,
    "critic_loss": 22.772336959838867,
    "ent_coef": 0.08969137072563171,
    "learning_rate": 0.001
  },
  {
    "episode": 2880,
    "reward": 85.165468,
    "length": 71,
    "time": 47581.792634,
    "actor_loss": -59.4962272644043,
    "critic_loss": 8.903739929199219,
    "ent_coef": 0.09463609755039215,
    "learning_rate": 0.001
  },
  {
    "episode": 2881,
    "reward": 89.602736,
    "length": 64,
    "time": 47594.461421,
    "actor_loss": -61.674339294433594,
    "critic_loss": 3.504587173461914,
    "ent_coef": 0.09679563343524933,
    "learning_rate": 0.001
  },
  {
    "episode": 2882,
    "reward": 87.22566,
    "length": 69,
    "time": 47607.598935,
    "actor_loss": -58.28764343261719,
    "critic_loss": 18.619037628173828,
    "ent_coef": 0.09299927949905396,
    "learning_rate": 0.001
  },
  {
    "episode": 2883,
    "reward": 88.752464,
    "length": 67,
    "time": 47620.309579,
    "actor_loss": -60.468910217285156,
    "critic_loss": 17.524250030517578,
    "ent_coef": 0.08997929841279984,
    "learning_rate": 0.001
  },
  {
    "episode": 2884,
    "reward": 90.014663,
    "length": 64,
    "time": 47635.662371,
    "actor_loss": -59.84719467163086,
    "critic_loss": 4.387139320373535,
    "ent_coef": 0.08895276486873627,
    "learning_rate": 0.001
  },
  {
    "episode": 2885,
    "reward": 80.29243,
    "length": 82,
    "time": 47649.447892,
    "actor_loss": -59.91592788696289,
    "critic_loss": 7.390877723693848,
    "ent_coef": 0.07983681559562683,
    "learning_rate": 0.001
  },
  {
    "episode": 2886,
    "reward": 84.728092,
    "length": 72,
    "time": 47663.895558,
    "actor_loss": -56.867431640625,
    "critic_loss": 54.752830505371094,
    "ent_coef": 0.07623299956321716,
    "learning_rate": 0.001
  },
  {
    "episode": 2887,
    "reward": 87.308533,
    "length": 71,
    "time": 47676.049967,
    "actor_loss": -63.60155487060547,
    "critic_loss": 17.621726989746094,
    "ent_coef": 0.07856260240077972,
    "learning_rate": 0.001
  },
  {
    "episode": 2888,
    "reward": 87.695513,
    "length": 69,
    "time": 47690.434694,
    "actor_loss": -63.72923278808594,
    "critic_loss": 2.7062809467315674,
    "ent_coef": 0.08245144784450531,
    "learning_rate": 0.001
  },
  {
    "episode": 2889,
    "reward": 79.34508,
    "length": 85,
    "time": 47707.256825,
    "actor_loss": -67.70044708251953,
    "critic_loss": 6.559532642364502,
    "ent_coef": 0.08443035930395126,
    "learning_rate": 0.001
  },
  {
    "episode": 2890,
    "reward": 70.926439,
    "length": 92,
    "time": 47722.91897,
    "actor_loss": -65.32826232910156,
    "critic_loss": 18.640716552734375,
    "ent_coef": 0.08199336379766464,
    "learning_rate": 0.001
  },
  {
    "episode": 2891,
    "reward": 83.266309,
    "length": 77,
    "time": 47738.55889,
    "actor_loss": -62.763954162597656,
    "critic_loss": 3.4674670696258545,
    "ent_coef": 0.08363673090934753,
    "learning_rate": 0.001
  },
  {
    "episode": 2892,
    "reward": 62.919359,
    "length": 117,
    "time": 47757.870475,
    "actor_loss": -62.059661865234375,
    "critic_loss": 45.69557189941406,
    "ent_coef": 0.08219859004020691,
    "learning_rate": 0.001
  },
  {
    "episode": 2893,
    "reward": 82.595746,
    "length": 75,
    "time": 47773.437675,
    "actor_loss": -55.878990173339844,
    "critic_loss": 36.79466247558594,
    "ent_coef": 0.08241027593612671,
    "learning_rate": 0.001
  },
  {
    "episode": 2894,
    "reward": 30.468507,
    "length": 181,
    "time": 47802.508135,
    "actor_loss": -61.59337615966797,
    "critic_loss": 2.7171995639801025,
    "ent_coef": 0.08285883814096451,
    "learning_rate": 0.001
  },
  {
    "episode": 2895,
    "reward": 85.191499,
    "length": 78,
    "time": 47816.510253,
    "actor_loss": -67.76712036132812,
    "critic_loss": 92.73681640625,
    "ent_coef": 0.0860297754406929,
    "learning_rate": 0.001
  },
  {
    "episode": 2896,
    "reward": 86.428134,
    "length": 76,
    "time": 47830.78469,
    "actor_loss": -60.78935241699219,
    "critic_loss": 4.662591934204102,
    "ent_coef": 0.08947630971670151,
    "learning_rate": 0.001
  },
  {
    "episode": 2897,
    "reward": 71.846176,
    "length": 109,
    "time": 47849.709915,
    "actor_loss": -58.702606201171875,
    "critic_loss": 13.898200035095215,
    "ent_coef": 0.08802106231451035,
    "learning_rate": 0.001
  },
  {
    "episode": 2898,
    "reward": 86.304988,
    "length": 71,
    "time": 47862.939859,
    "actor_loss": -63.095375061035156,
    "critic_loss": 9.485736846923828,
    "ent_coef": 0.08892142027616501,
    "learning_rate": 0.001
  },
  {
    "episode": 2899,
    "reward": 84.677437,
    "length": 80,
    "time": 47876.252441,
    "actor_loss": -59.515769958496094,
    "critic_loss": 4.662907600402832,
    "ent_coef": 0.09814628213644028,
    "learning_rate": 0.001
  },
  {
    "episode": 2900,
    "reward": 85.016161,
    "length": 77,
    "time": 47889.14678,
    "actor_loss": -68.493408203125,
    "critic_loss": 52.75542068481445,
    "ent_coef": 0.10503179579973221,
    "learning_rate": 0.001
  },
  {
    "episode": 2901,
    "reward": 87.106309,
    "length": 72,
    "time": 47902.516896,
    "actor_loss": -64.44886016845703,
    "critic_loss": 7.329473495483398,
    "ent_coef": 0.10296167433261871,
    "learning_rate": 0.001
  },
  {
    "episode": 2902,
    "reward": 85.633683,
    "length": 76,
    "time": 47918.735315,
    "actor_loss": -58.198585510253906,
    "critic_loss": 3.116985321044922,
    "ent_coef": 0.10009559988975525,
    "learning_rate": 0.001
  },
  {
    "episode": 2903,
    "reward": 86.13473,
    "length": 72,
    "time": 47931.968689,
    "actor_loss": -60.80638122558594,
    "critic_loss": 11.409734725952148,
    "ent_coef": 0.09816636145114899,
    "learning_rate": 0.001
  },
  {
    "episode": 2904,
    "reward": 90.013497,
    "length": 64,
    "time": 47943.308686,
    "actor_loss": -63.759761810302734,
    "critic_loss": 3.31453275680542,
    "ent_coef": 0.09746386855840683,
    "learning_rate": 0.001
  },
  {
    "episode": 2905,
    "reward": 86.095258,
    "length": 72,
    "time": 47958.014693,
    "actor_loss": -64.78468322753906,
    "critic_loss": 9.676538467407227,
    "ent_coef": 0.09574773162603378,
    "learning_rate": 0.001
  },
  {
    "episode": 2906,
    "reward": 79.84893,
    "length": 83,
    "time": 47973.873019,
    "actor_loss": -54.44601821899414,
    "critic_loss": 6.782676696777344,
    "ent_coef": 0.09229631721973419,
    "learning_rate": 0.001
  },
  {
    "episode": 2907,
    "reward": 81.525428,
    "length": 83,
    "time": 47987.587949,
    "actor_loss": -64.04985809326172,
    "critic_loss": 17.98525047302246,
    "ent_coef": 0.08577225357294083,
    "learning_rate": 0.001
  },
  {
    "episode": 2908,
    "reward": 87.338112,
    "length": 68,
    "time": 47999.47079,
    "actor_loss": -57.90068817138672,
    "critic_loss": 4.765602111816406,
    "ent_coef": 0.08539161086082458,
    "learning_rate": 0.001
  },
  {
    "episode": 2909,
    "reward": 91.453904,
    "length": 61,
    "time": 48012.688431,
    "actor_loss": -59.37735366821289,
    "critic_loss": 65.8082046508789,
    "ent_coef": 0.09402593225240707,
    "learning_rate": 0.001
  },
  {
    "episode": 2910,
    "reward": 86.162903,
    "length": 74,
    "time": 48026.273988,
    "actor_loss": -67.93763732910156,
    "critic_loss": 3.7654380798339844,
    "ent_coef": 0.09932039678096771,
    "learning_rate": 0.001
  },
  {
    "episode": 2911,
    "reward": 83.85294,
    "length": 75,
    "time": 48041.139335,
    "actor_loss": -59.571624755859375,
    "critic_loss": 5.425673484802246,
    "ent_coef": 0.09905578941106796,
    "learning_rate": 0.001
  },
  {
    "episode": 2912,
    "reward": 84.903274,
    "length": 71,
    "time": 48053.233798,
    "actor_loss": -65.55874633789062,
    "critic_loss": 11.152412414550781,
    "ent_coef": 0.10009634494781494,
    "learning_rate": 0.001
  },
  {
    "episode": 2913,
    "reward": 85.411844,
    "length": 71,
    "time": 48066.822834,
    "actor_loss": -55.194313049316406,
    "critic_loss": 56.82288360595703,
    "ent_coef": 0.10640085488557816,
    "learning_rate": 0.001
  },
  {
    "episode": 2914,
    "reward": 87.933151,
    "length": 66,
    "time": 48080.442983,
    "actor_loss": -63.17052459716797,
    "critic_loss": 2.9409866333007812,
    "ent_coef": 0.1064164787530899,
    "learning_rate": 0.001
  },
  {
    "episode": 2915,
    "reward": 85.509828,
    "length": 72,
    "time": 48095.595438,
    "actor_loss": -62.34967803955078,
    "critic_loss": 53.57062530517578,
    "ent_coef": 0.10284756869077682,
    "learning_rate": 0.001
  },
  {
    "episode": 2916,
    "reward": 87.081824,
    "length": 67,
    "time": 48110.243312,
    "actor_loss": -61.78242492675781,
    "critic_loss": 62.22564697265625,
    "ent_coef": 0.10310017317533493,
    "learning_rate": 0.001
  },
  {
    "episode": 2917,
    "reward": 87.352373,
    "length": 71,
    "time": 48125.618747,
    "actor_loss": -54.753849029541016,
    "critic_loss": 70.58373260498047,
    "ent_coef": 0.10369890928268433,
    "learning_rate": 0.001
  },
  {
    "episode": 2918,
    "reward": 83.557566,
    "length": 74,
    "time": 48140.976916,
    "actor_loss": -64.23715209960938,
    "critic_loss": 34.75407409667969,
    "ent_coef": 0.09921204298734665,
    "learning_rate": 0.001
  },
  {
    "episode": 2919,
    "reward": 82.64021,
    "length": 75,
    "time": 48153.596091,
    "actor_loss": -60.39653015136719,
    "critic_loss": 79.9398193359375,
    "ent_coef": 0.09550809115171432,
    "learning_rate": 0.001
  },
  {
    "episode": 2920,
    "reward": 84.652916,
    "length": 73,
    "time": 48166.069928,
    "actor_loss": -58.77934646606445,
    "critic_loss": 2.8999342918395996,
    "ent_coef": 0.09775585681200027,
    "learning_rate": 0.001
  },
  {
    "episode": 2921,
    "reward": 86.083995,
    "length": 70,
    "time": 48178.772977,
    "actor_loss": -64.40792083740234,
    "critic_loss": 18.76280975341797,
    "ent_coef": 0.09821927547454834,
    "learning_rate": 0.001
  },
  {
    "episode": 2922,
    "reward": 55.441434,
    "length": 114,
    "time": 48196.457036,
    "actor_loss": -68.13651275634766,
    "critic_loss": 6.011648654937744,
    "ent_coef": 0.09451436996459961,
    "learning_rate": 0.001
  },
  {
    "episode": 2923,
    "reward": 89.823198,
    "length": 63,
    "time": 48208.678926,
    "actor_loss": -61.68656921386719,
    "critic_loss": 2.6646299362182617,
    "ent_coef": 0.09715934097766876,
    "learning_rate": 0.001
  },
  {
    "episode": 2924,
    "reward": 86.837839,
    "length": 68,
    "time": 48221.370127,
    "actor_loss": -63.40789794921875,
    "critic_loss": 11.496044158935547,
    "ent_coef": 0.10090218484401703,
    "learning_rate": 0.001
  },
  {
    "episode": 2925,
    "reward": 88.304205,
    "length": 67,
    "time": 48234.490818,
    "actor_loss": -60.07499313354492,
    "critic_loss": 4.682377338409424,
    "ent_coef": 0.09972447901964188,
    "learning_rate": 0.001
  },
  {
    "episode": 2926,
    "reward": 84.941971,
    "length": 73,
    "time": 48248.853693,
    "actor_loss": -63.36576461791992,
    "critic_loss": 4.310764789581299,
    "ent_coef": 0.10346617549657822,
    "learning_rate": 0.001
  },
  {
    "episode": 2927,
    "reward": 80.600953,
    "length": 81,
    "time": 48263.21825,
    "actor_loss": -62.766685485839844,
    "critic_loss": 11.376907348632812,
    "ent_coef": 0.10539701581001282,
    "learning_rate": 0.001
  },
  {
    "episode": 2928,
    "reward": 91.126337,
    "length": 62,
    "time": 48274.301626,
    "actor_loss": -59.37337875366211,
    "critic_loss": 2.4253897666931152,
    "ent_coef": 0.11001566052436829,
    "learning_rate": 0.001
  },
  {
    "episode": 2929,
    "reward": 79.010804,
    "length": 80,
    "time": 48288.812981,
    "actor_loss": -62.07697677612305,
    "critic_loss": 9.014859199523926,
    "ent_coef": 0.1101522371172905,
    "learning_rate": 0.001
  },
  {
    "episode": 2930,
    "reward": 87.126384,
    "length": 68,
    "time": 48300.629964,
    "actor_loss": -65.63961029052734,
    "critic_loss": 30.39350700378418,
    "ent_coef": 0.11613962054252625,
    "learning_rate": 0.001
  },
  {
    "episode": 2931,
    "reward": 88.536707,
    "length": 64,
    "time": 48312.695275,
    "actor_loss": -61.167816162109375,
    "critic_loss": 5.424249649047852,
    "ent_coef": 0.11594843864440918,
    "learning_rate": 0.001
  },
  {
    "episode": 2932,
    "reward": 87.911404,
    "length": 66,
    "time": 48326.234569,
    "actor_loss": -59.12641906738281,
    "critic_loss": 4.679561614990234,
    "ent_coef": 0.11737498641014099,
    "learning_rate": 0.001
  },
  {
    "episode": 2933,
    "reward": 86.41476,
    "length": 69,
    "time": 48338.116485,
    "actor_loss": -63.878211975097656,
    "critic_loss": 50.23509979248047,
    "ent_coef": 0.11411496251821518,
    "learning_rate": 0.001
  },
  {
    "episode": 2934,
    "reward": 86.839962,
    "length": 67,
    "time": 48349.851497,
    "actor_loss": -60.603031158447266,
    "critic_loss": 4.382164001464844,
    "ent_coef": 0.11036559194326401,
    "learning_rate": 0.001
  },
  {
    "episode": 2935,
    "reward": 84.049329,
    "length": 73,
    "time": 48365.757298,
    "actor_loss": -64.18802642822266,
    "critic_loss": 2.817976474761963,
    "ent_coef": 0.10361950099468231,
    "learning_rate": 0.001
  },
  {
    "episode": 2936,
    "reward": 81.745009,
    "length": 76,
    "time": 48382.183443,
    "actor_loss": -58.80183410644531,
    "critic_loss": 14.656319618225098,
    "ent_coef": 0.09916165471076965,
    "learning_rate": 0.001
  },
  {
    "episode": 2937,
    "reward": 84.899022,
    "length": 73,
    "time": 48394.476771,
    "actor_loss": -62.70374298095703,
    "critic_loss": 6.158463954925537,
    "ent_coef": 0.0940047949552536,
    "learning_rate": 0.001
  },
  {
    "episode": 2938,
    "reward": 82.250123,
    "length": 76,
    "time": 48409.295358,
    "actor_loss": -60.185546875,
    "critic_loss": 8.672414779663086,
    "ent_coef": 0.08836906403303146,
    "learning_rate": 0.001
  },
  {
    "episode": 2939,
    "reward": 87.459046,
    "length": 69,
    "time": 48421.156716,
    "actor_loss": -56.014862060546875,
    "critic_loss": 76.33486938476562,
    "ent_coef": 0.08641207218170166,
    "learning_rate": 0.001
  },
  {
    "episode": 2940,
    "reward": 85.124558,
    "length": 72,
    "time": 48436.409503,
    "actor_loss": -65.12860107421875,
    "critic_loss": 11.500693321228027,
    "ent_coef": 0.08510462194681168,
    "learning_rate": 0.001
  },
  {
    "episode": 2941,
    "reward": 85.036841,
    "length": 71,
    "time": 48448.504334,
    "actor_loss": -59.751251220703125,
    "critic_loss": 45.89124298095703,
    "ent_coef": 0.08391468971967697,
    "learning_rate": 0.001
  },
  {
    "episode": 2942,
    "reward": 81.935277,
    "length": 76,
    "time": 48464.046799,
    "actor_loss": -61.682594299316406,
    "critic_loss": 7.169309139251709,
    "ent_coef": 0.08334703743457794,
    "learning_rate": 0.001
  },
  {
    "episode": 2943,
    "reward": 86.226911,
    "length": 70,
    "time": 48477.428107,
    "actor_loss": -61.45795822143555,
    "critic_loss": 3.797884464263916,
    "ent_coef": 0.08336598426103592,
    "learning_rate": 0.001
  },
  {
    "episode": 2944,
    "reward": 80.497141,
    "length": 78,
    "time": 48490.420056,
    "actor_loss": -60.67928695678711,
    "critic_loss": 3.834523916244507,
    "ent_coef": 0.08136013150215149,
    "learning_rate": 0.001
  },
  {
    "episode": 2945,
    "reward": 80.703375,
    "length": 79,
    "time": 48506.087184,
    "actor_loss": -57.88232421875,
    "critic_loss": 2.434475898742676,
    "ent_coef": 0.080576092004776,
    "learning_rate": 0.001
  },
  {
    "episode": 2946,
    "reward": 80.815867,
    "length": 77,
    "time": 48520.942775,
    "actor_loss": -61.046165466308594,
    "critic_loss": 163.7812042236328,
    "ent_coef": 0.08195976167917252,
    "learning_rate": 0.001
  },
  {
    "episode": 2947,
    "reward": 88.679592,
    "length": 66,
    "time": 48535.359934,
    "actor_loss": -61.99108123779297,
    "critic_loss": 6.890156269073486,
    "ent_coef": 0.08523871004581451,
    "learning_rate": 0.001
  },
  {
    "episode": 2948,
    "reward": 89.736078,
    "length": 63,
    "time": 48547.859881,
    "actor_loss": -67.49453735351562,
    "critic_loss": 3.2274129390716553,
    "ent_coef": 0.08991421014070511,
    "learning_rate": 0.001
  },
  {
    "episode": 2949,
    "reward": 88.538196,
    "length": 66,
    "time": 48561.434671,
    "actor_loss": -60.656517028808594,
    "critic_loss": 64.61595916748047,
    "ent_coef": 0.08940913528203964,
    "learning_rate": 0.001
  },
  {
    "episode": 2950,
    "reward": 87.380133,
    "length": 68,
    "time": 48573.820683,
    "actor_loss": -62.09650802612305,
    "critic_loss": 3.9796142578125,
    "ent_coef": 0.08868511021137238,
    "learning_rate": 0.001
  },
  {
    "episode": 2951,
    "reward": 89.638511,
    "length": 63,
    "time": 48591.153088,
    "actor_loss": -64.23240661621094,
    "critic_loss": 3.3459949493408203,
    "ent_coef": 0.08622686564922333,
    "learning_rate": 0.001
  },
  {
    "episode": 2952,
    "reward": 87.433684,
    "length": 68,
    "time": 48605.235866,
    "actor_loss": -70.03514099121094,
    "critic_loss": 19.026927947998047,
    "ent_coef": 0.08515904098749161,
    "learning_rate": 0.001
  },
  {
    "episode": 2953,
    "reward": 88.298996,
    "length": 65,
    "time": 48618.413618,
    "actor_loss": -59.56702423095703,
    "critic_loss": 10.277144432067871,
    "ent_coef": 0.0917825922369957,
    "learning_rate": 0.001
  },
  {
    "episode": 2954,
    "reward": 91.305407,
    "length": 60,
    "time": 48631.633228,
    "actor_loss": -63.4302978515625,
    "critic_loss": 9.674696922302246,
    "ent_coef": 0.10056360810995102,
    "learning_rate": 0.001
  },
  {
    "episode": 2955,
    "reward": 87.590852,
    "length": 67,
    "time": 48647.070118,
    "actor_loss": -66.91207885742188,
    "critic_loss": 7.070633888244629,
    "ent_coef": 0.10264826565980911,
    "learning_rate": 0.001
  },
  {
    "episode": 2956,
    "reward": 85.527141,
    "length": 70,
    "time": 48659.984468,
    "actor_loss": -66.16448974609375,
    "critic_loss": 6.038155555725098,
    "ent_coef": 0.10348407924175262,
    "learning_rate": 0.001
  },
  {
    "episode": 2957,
    "reward": 88.352158,
    "length": 65,
    "time": 48672.392831,
    "actor_loss": -59.735313415527344,
    "critic_loss": 3.4724836349487305,
    "ent_coef": 0.10341294854879379,
    "learning_rate": 0.001
  },
  {
    "episode": 2958,
    "reward": 87.116233,
    "length": 69,
    "time": 48686.874111,
    "actor_loss": -60.84843826293945,
    "critic_loss": 39.58979797363281,
    "ent_coef": 0.10252577811479568,
    "learning_rate": 0.001
  },
  {
    "episode": 2959,
    "reward": 82.872188,
    "length": 74,
    "time": 48699.624146,
    "actor_loss": -70.7140884399414,
    "critic_loss": 2.1122355461120605,
    "ent_coef": 0.09817347675561905,
    "learning_rate": 0.001
  },
  {
    "episode": 2960,
    "reward": 88.840981,
    "length": 67,
    "time": 48711.35462,
    "actor_loss": -61.371700286865234,
    "critic_loss": 5.72172737121582,
    "ent_coef": 0.09599104523658752,
    "learning_rate": 0.001
  },
  {
    "episode": 2961,
    "reward": 85.622363,
    "length": 70,
    "time": 48723.457975,
    "actor_loss": -65.3232421875,
    "critic_loss": 11.923091888427734,
    "ent_coef": 0.09469877183437347,
    "learning_rate": 0.001
  },
  {
    "episode": 2962,
    "reward": 85.298506,
    "length": 70,
    "time": 48737.662627,
    "actor_loss": -63.60169982910156,
    "critic_loss": 2.2305214405059814,
    "ent_coef": 0.09342394769191742,
    "learning_rate": 0.001
  },
  {
    "episode": 2963,
    "reward": 83.800097,
    "length": 73,
    "time": 48753.112753,
    "actor_loss": -58.616180419921875,
    "critic_loss": 65.10089874267578,
    "ent_coef": 0.0955716148018837,
    "learning_rate": 0.001
  },
  {
    "episode": 2964,
    "reward": 88.751556,
    "length": 65,
    "time": 48765.460308,
    "actor_loss": -66.95011901855469,
    "critic_loss": 76.75418090820312,
    "ent_coef": 0.1001293733716011,
    "learning_rate": 0.001
  },
  {
    "episode": 2965,
    "reward": 85.528623,
    "length": 70,
    "time": 48778.398888,
    "actor_loss": -60.52210998535156,
    "critic_loss": 2.9458608627319336,
    "ent_coef": 0.10359785705804825,
    "learning_rate": 0.001
  },
  {
    "episode": 2966,
    "reward": 89.13385,
    "length": 64,
    "time": 48790.532601,
    "actor_loss": -59.94696807861328,
    "critic_loss": 4.292173862457275,
    "ent_coef": 0.1078273355960846,
    "learning_rate": 0.001
  },
  {
    "episode": 2967,
    "reward": 87.46335,
    "length": 67,
    "time": 48803.616786,
    "actor_loss": -60.762977600097656,
    "critic_loss": 58.40660095214844,
    "ent_coef": 0.10289019346237183,
    "learning_rate": 0.001
  },
  {
    "episode": 2968,
    "reward": 88.52772,
    "length": 65,
    "time": 48816.39,
    "actor_loss": -64.61247253417969,
    "critic_loss": 11.566009521484375,
    "ent_coef": 0.09874121844768524,
    "learning_rate": 0.001
  },
  {
    "episode": 2969,
    "reward": 89.171019,
    "length": 65,
    "time": 48827.703453,
    "actor_loss": -63.61212921142578,
    "critic_loss": 10.762022972106934,
    "ent_coef": 0.09581076353788376,
    "learning_rate": 0.001
  },
  {
    "episode": 2970,
    "reward": 87.464391,
    "length": 67,
    "time": 48839.724788,
    "actor_loss": -63.366790771484375,
    "critic_loss": 3.5236363410949707,
    "ent_coef": 0.09443509578704834,
    "learning_rate": 0.001
  },
  {
    "episode": 2971,
    "reward": 84.919602,
    "length": 71,
    "time": 48853.232056,
    "actor_loss": -62.17742156982422,
    "critic_loss": 4.864449977874756,
    "ent_coef": 0.09183865785598755,
    "learning_rate": 0.001
  },
  {
    "episode": 2972,
    "reward": 80.082479,
    "length": 78,
    "time": 48869.926655,
    "actor_loss": -58.134098052978516,
    "critic_loss": 51.942604064941406,
    "ent_coef": 0.09072890877723694,
    "learning_rate": 0.001
  },
  {
    "episode": 2973,
    "reward": 87.010705,
    "length": 68,
    "time": 48884.605804,
    "actor_loss": -61.68276596069336,
    "critic_loss": 2.5546789169311523,
    "ent_coef": 0.09034710377454758,
    "learning_rate": 0.001
  },
  {
    "episode": 2974,
    "reward": 77.716273,
    "length": 82,
    "time": 48899.110962,
    "actor_loss": -66.34988403320312,
    "critic_loss": 5.2046380043029785,
    "ent_coef": 0.0841478705406189,
    "learning_rate": 0.001
  },
  {
    "episode": 2975,
    "reward": 88.756498,
    "length": 65,
    "time": 48912.418144,
    "actor_loss": -60.296363830566406,
    "critic_loss": 10.853635787963867,
    "ent_coef": 0.08199246227741241,
    "learning_rate": 0.001
  },
  {
    "episode": 2976,
    "reward": 89.899454,
    "length": 63,
    "time": 48923.616696,
    "actor_loss": -68.90005493164062,
    "critic_loss": 7.706198215484619,
    "ent_coef": 0.0849473625421524,
    "learning_rate": 0.001
  },
  {
    "episode": 2977,
    "reward": 91.012844,
    "length": 61,
    "time": 48934.689526,
    "actor_loss": -60.367374420166016,
    "critic_loss": 7.011534690856934,
    "ent_coef": 0.09288870543241501,
    "learning_rate": 0.001
  },
  {
    "episode": 2978,
    "reward": 90.645831,
    "length": 62,
    "time": 48946.110882,
    "actor_loss": -69.38470458984375,
    "critic_loss": 10.930896759033203,
    "ent_coef": 0.09789248555898666,
    "learning_rate": 0.001
  },
  {
    "episode": 2979,
    "reward": 89.921851,
    "length": 62,
    "time": 48957.225724,
    "actor_loss": -62.84026336669922,
    "critic_loss": 4.616002559661865,
    "ent_coef": 0.10001511126756668,
    "learning_rate": 0.001
  },
  {
    "episode": 2980,
    "reward": 86.531183,
    "length": 68,
    "time": 48971.731644,
    "actor_loss": -63.286285400390625,
    "critic_loss": 6.5643205642700195,
    "ent_coef": 0.09891364723443985,
    "learning_rate": 0.001
  },
  {
    "episode": 2981,
    "reward": 88.395565,
    "length": 66,
    "time": 48984.616575,
    "actor_loss": -60.32567596435547,
    "critic_loss": 6.651454925537109,
    "ent_coef": 0.0981878787279129,
    "learning_rate": 0.001
  },
  {
    "episode": 2982,
    "reward": 88.957764,
    "length": 64,
    "time": 48995.802224,
    "actor_loss": -56.46563720703125,
    "critic_loss": 3.6185781955718994,
    "ent_coef": 0.09475177526473999,
    "learning_rate": 0.001
  },
  {
    "episode": 2983,
    "reward": 87.375659,
    "length": 67,
    "time": 49010.342906,
    "actor_loss": -68.20156860351562,
    "critic_loss": 5.01946496963501,
    "ent_coef": 0.09361819177865982,
    "learning_rate": 0.001
  },
  {
    "episode": 2984,
    "reward": 89.865074,
    "length": 65,
    "time": 49025.153042,
    "actor_loss": -67.65731048583984,
    "critic_loss": 10.362064361572266,
    "ent_coef": 0.0907050296664238,
    "learning_rate": 0.001
  },
  {
    "episode": 2985,
    "reward": 89.18065,
    "length": 64,
    "time": 49038.509981,
    "actor_loss": -58.3369255065918,
    "critic_loss": 7.665287017822266,
    "ent_coef": 0.08984821289777756,
    "learning_rate": 0.001
  },
  {
    "episode": 2986,
    "reward": 87.236323,
    "length": 68,
    "time": 49052.446943,
    "actor_loss": -64.16598510742188,
    "critic_loss": 4.230773448944092,
    "ent_coef": 0.08840147405862808,
    "learning_rate": 0.001
  },
  {
    "episode": 2987,
    "reward": 86.317804,
    "length": 70,
    "time": 49065.392133,
    "actor_loss": -65.54045867919922,
    "critic_loss": 4.2300944328308105,
    "ent_coef": 0.0871158018708229,
    "learning_rate": 0.001
  },
  {
    "episode": 2988,
    "reward": 86.092689,
    "length": 68,
    "time": 49077.915688,
    "actor_loss": -66.34129333496094,
    "critic_loss": 12.536715507507324,
    "ent_coef": 0.08982730656862259,
    "learning_rate": 0.001
  },
  {
    "episode": 2989,
    "reward": 89.729888,
    "length": 64,
    "time": 49090.953875,
    "actor_loss": -57.678985595703125,
    "critic_loss": 8.19935417175293,
    "ent_coef": 0.09071391820907593,
    "learning_rate": 0.001
  },
  {
    "episode": 2990,
    "reward": 86.162664,
    "length": 69,
    "time": 49104.930787,
    "actor_loss": -66.36375427246094,
    "critic_loss": 8.596781730651855,
    "ent_coef": 0.08967629075050354,
    "learning_rate": 0.001
  },
  {
    "episode": 2991,
    "reward": 87.232615,
    "length": 67,
    "time": 49116.635459,
    "actor_loss": -61.790321350097656,
    "critic_loss": 43.16349792480469,
    "ent_coef": 0.09138248860836029,
    "learning_rate": 0.001
  },
  {
    "episode": 2992,
    "reward": 87.264149,
    "length": 68,
    "time": 49128.887009,
    "actor_loss": -58.707542419433594,
    "critic_loss": 6.527950286865234,
    "ent_coef": 0.08966481685638428,
    "learning_rate": 0.001
  },
  {
    "episode": 2993,
    "reward": 87.611625,
    "length": 67,
    "time": 49140.773937,
    "actor_loss": -64.0286865234375,
    "critic_loss": 4.425425052642822,
    "ent_coef": 0.08504803478717804,
    "learning_rate": 0.001
  },
  {
    "episode": 2994,
    "reward": 90.102641,
    "length": 63,
    "time": 49154.020898,
    "actor_loss": -59.34962844848633,
    "critic_loss": 5.348677635192871,
    "ent_coef": 0.08461414277553558,
    "learning_rate": 0.001
  },
  {
    "episode": 2995,
    "reward": 87.237783,
    "length": 68,
    "time": 49167.707533,
    "actor_loss": -66.02787780761719,
    "critic_loss": 6.165643215179443,
    "ent_coef": 0.08047332614660263,
    "learning_rate": 0.001
  },
  {
    "episode": 2996,
    "reward": 88.225319,
    "length": 66,
    "time": 49181.34582,
    "actor_loss": -58.666751861572266,
    "critic_loss": 4.922114372253418,
    "ent_coef": 0.07986383885145187,
    "learning_rate": 0.001
  },
  {
    "episode": 2997,
    "reward": 87.988787,
    "length": 67,
    "time": 49193.319438,
    "actor_loss": -62.816192626953125,
    "critic_loss": 3.0865254402160645,
    "ent_coef": 0.08300860226154327,
    "learning_rate": 0.001
  },
  {
    "episode": 2998,
    "reward": 85.043751,
    "length": 71,
    "time": 49208.233316,
    "actor_loss": -65.80573272705078,
    "critic_loss": 3.2759625911712646,
    "ent_coef": 0.08480554074048996,
    "learning_rate": 0.001
  },
  {
    "episode": 2999,
    "reward": 87.617845,
    "length": 67,
    "time": 49222.559055,
    "actor_loss": -60.55228805541992,
    "critic_loss": 4.64634895324707,
    "ent_coef": 0.08882380276918411,
    "learning_rate": 0.001
  },
  {
    "episode": 3000,
    "reward": 85.365798,
    "length": 72,
    "time": 49236.183906,
    "actor_loss": -64.32974243164062,
    "critic_loss": 13.199811935424805,
    "ent_coef": 0.08845844119787216,
    "learning_rate": 0.001
  },
  {
    "episode": 3001,
    "reward": 90.478001,
    "length": 62,
    "time": 49249.851091,
    "actor_loss": -62.59791946411133,
    "critic_loss": 41.31146240234375,
    "ent_coef": 0.09331657737493515,
    "learning_rate": 0.001
  },
  {
    "episode": 3002,
    "reward": 90.041809,
    "length": 63,
    "time": 49263.388407,
    "actor_loss": -65.40389251708984,
    "critic_loss": 4.075080394744873,
    "ent_coef": 0.09351662546396255,
    "learning_rate": 0.001
  },
  {
    "episode": 3003,
    "reward": 84.820205,
    "length": 72,
    "time": 49282.125753,
    "actor_loss": -61.73634338378906,
    "critic_loss": 37.34134292602539,
    "ent_coef": 0.09248046576976776,
    "learning_rate": 0.001
  },
  {
    "episode": 3004,
    "reward": 40.744911,
    "length": 128,
    "time": 49306.271992,
    "actor_loss": -66.98973083496094,
    "critic_loss": 3.2025084495544434,
    "ent_coef": 0.08699098229408264,
    "learning_rate": 0.001
  },
  {
    "episode": 3005,
    "reward": 88.352475,
    "length": 66,
    "time": 49318.486108,
    "actor_loss": -65.10592651367188,
    "critic_loss": 9.118334770202637,
    "ent_coef": 0.08449512720108032,
    "learning_rate": 0.001
  },
  {
    "episode": 3006,
    "reward": 85.038675,
    "length": 73,
    "time": 49334.292184,
    "actor_loss": -60.18426513671875,
    "critic_loss": 137.66055297851562,
    "ent_coef": 0.08332749456167221,
    "learning_rate": 0.001
  },
  {
    "episode": 3007,
    "reward": 85.1795,
    "length": 70,
    "time": 49352.998141,
    "actor_loss": -65.57174682617188,
    "critic_loss": 10.9927978515625,
    "ent_coef": 0.084325410425663,
    "learning_rate": 0.001
  },
  {
    "episode": 3008,
    "reward": 87.474317,
    "length": 67,
    "time": 49365.540414,
    "actor_loss": -59.6397705078125,
    "critic_loss": 10.372140884399414,
    "ent_coef": 0.08558329939842224,
    "learning_rate": 0.001
  },
  {
    "episode": 3009,
    "reward": 87.558616,
    "length": 68,
    "time": 49377.526569,
    "actor_loss": -60.27072525024414,
    "critic_loss": 10.655862808227539,
    "ent_coef": 0.08545371145009995,
    "learning_rate": 0.001
  },
  {
    "episode": 3010,
    "reward": 87.977922,
    "length": 66,
    "time": 49389.6653,
    "actor_loss": -64.37853240966797,
    "critic_loss": 5.217210292816162,
    "ent_coef": 0.0902428850531578,
    "learning_rate": 0.001
  },
  {
    "episode": 3011,
    "reward": 88.183785,
    "length": 66,
    "time": 49401.810024,
    "actor_loss": -55.704490661621094,
    "critic_loss": 7.216436862945557,
    "ent_coef": 0.09445913881063461,
    "learning_rate": 0.001
  },
  {
    "episode": 3012,
    "reward": 84.563504,
    "length": 71,
    "time": 49414.345947,
    "actor_loss": -65.79390716552734,
    "critic_loss": 5.370051383972168,
    "ent_coef": 0.09915004670619965,
    "learning_rate": 0.001
  },
  {
    "episode": 3013,
    "reward": 81.515322,
    "length": 78,
    "time": 49428.372809,
    "actor_loss": -63.89394760131836,
    "critic_loss": 36.82543182373047,
    "ent_coef": 0.09178023785352707,
    "learning_rate": 0.001
  },
  {
    "episode": 3014,
    "reward": 85.652534,
    "length": 70,
    "time": 49440.440564,
    "actor_loss": -58.08784103393555,
    "critic_loss": 74.14622497558594,
    "ent_coef": 0.08850715309381485,
    "learning_rate": 0.001
  },
  {
    "episode": 3015,
    "reward": 88.060151,
    "length": 66,
    "time": 49452.775005,
    "actor_loss": -65.10418701171875,
    "critic_loss": 81.02745056152344,
    "ent_coef": 0.09053318202495575,
    "learning_rate": 0.001
  },
  {
    "episode": 3016,
    "reward": 88.265273,
    "length": 65,
    "time": 49466.144506,
    "actor_loss": -65.43537902832031,
    "critic_loss": 3.0625271797180176,
    "ent_coef": 0.09546858817338943,
    "learning_rate": 0.001
  },
  {
    "episode": 3017,
    "reward": 89.268297,
    "length": 65,
    "time": 49478.407458,
    "actor_loss": -57.15583801269531,
    "critic_loss": 12.381012916564941,
    "ent_coef": 0.0963280126452446,
    "learning_rate": 0.001
  },
  {
    "episode": 3018,
    "reward": 85.230863,
    "length": 73,
    "time": 49491.521509,
    "actor_loss": -61.40055847167969,
    "critic_loss": 9.268012046813965,
    "ent_coef": 0.09687960892915726,
    "learning_rate": 0.001
  },
  {
    "episode": 3019,
    "reward": 85.08436,
    "length": 70,
    "time": 49504.583911,
    "actor_loss": -56.897674560546875,
    "critic_loss": 4.586846351623535,
    "ent_coef": 0.09737201780080795,
    "learning_rate": 0.001
  },
  {
    "episode": 3020,
    "reward": 88.334944,
    "length": 65,
    "time": 49517.571262,
    "actor_loss": -58.399940490722656,
    "critic_loss": 6.360138416290283,
    "ent_coef": 0.10020603239536285,
    "learning_rate": 0.001
  },
  {
    "episode": 3021,
    "reward": 79.449856,
    "length": 78,
    "time": 49532.073781,
    "actor_loss": -69.84553527832031,
    "critic_loss": 172.79229736328125,
    "ent_coef": 0.09797751903533936,
    "learning_rate": 0.001
  },
  {
    "episode": 3022,
    "reward": 85.376097,
    "length": 71,
    "time": 49547.834527,
    "actor_loss": -62.188995361328125,
    "critic_loss": 5.686854362487793,
    "ent_coef": 0.09863066673278809,
    "learning_rate": 0.001
  },
  {
    "episode": 3023,
    "reward": 89.89012,
    "length": 63,
    "time": 49561.435283,
    "actor_loss": -64.50129699707031,
    "critic_loss": 2.550368547439575,
    "ent_coef": 0.09922562539577484,
    "learning_rate": 0.001
  },
  {
    "episode": 3024,
    "reward": 87.724767,
    "length": 66,
    "time": 49572.956273,
    "actor_loss": -56.476890563964844,
    "critic_loss": 7.6151442527771,
    "ent_coef": 0.09793238341808319,
    "learning_rate": 0.001
  },
  {
    "episode": 3025,
    "reward": 85.21777,
    "length": 70,
    "time": 49585.978568,
    "actor_loss": -63.45612716674805,
    "critic_loss": 5.054066181182861,
    "ent_coef": 0.09472595900297165,
    "learning_rate": 0.001
  },
  {
    "episode": 3026,
    "reward": 89.095815,
    "length": 63,
    "time": 49597.237486,
    "actor_loss": -69.13544464111328,
    "critic_loss": 12.192873001098633,
    "ent_coef": 0.09677240252494812,
    "learning_rate": 0.001
  },
  {
    "episode": 3027,
    "reward": 88.029085,
    "length": 66,
    "time": 49609.95484,
    "actor_loss": -62.6180305480957,
    "critic_loss": 37.3233642578125,
    "ent_coef": 0.09598756581544876,
    "learning_rate": 0.001
  },
  {
    "episode": 3028,
    "reward": 88.751804,
    "length": 65,
    "time": 49621.361624,
    "actor_loss": -63.26327896118164,
    "critic_loss": 17.078075408935547,
    "ent_coef": 0.09727691859006882,
    "learning_rate": 0.001
  },
  {
    "episode": 3029,
    "reward": 86.741114,
    "length": 68,
    "time": 49633.337185,
    "actor_loss": -60.65123748779297,
    "critic_loss": 21.042171478271484,
    "ent_coef": 0.0981091782450676,
    "learning_rate": 0.001
  },
  {
    "episode": 3030,
    "reward": 87.294639,
    "length": 74,
    "time": 49646.69176,
    "actor_loss": -68.65526580810547,
    "critic_loss": 2.292499303817749,
    "ent_coef": 0.09727835655212402,
    "learning_rate": 0.001
  },
  {
    "episode": 3031,
    "reward": 82.093775,
    "length": 73,
    "time": 49660.208045,
    "actor_loss": -58.15331268310547,
    "critic_loss": 3.2164647579193115,
    "ent_coef": 0.09562454372644424,
    "learning_rate": 0.001
  },
  {
    "episode": 3032,
    "reward": 87.250722,
    "length": 67,
    "time": 49673.073695,
    "actor_loss": -68.4051513671875,
    "critic_loss": 1.6423676013946533,
    "ent_coef": 0.09792879223823547,
    "learning_rate": 0.001
  },
  {
    "episode": 3033,
    "reward": 87.34527,
    "length": 68,
    "time": 49684.720227,
    "actor_loss": -60.66785430908203,
    "critic_loss": 3.694519519805908,
    "ent_coef": 0.0943356528878212,
    "learning_rate": 0.001
  },
  {
    "episode": 3034,
    "reward": 87.936551,
    "length": 67,
    "time": 49696.328784,
    "actor_loss": -64.42327880859375,
    "critic_loss": 2.796137571334839,
    "ent_coef": 0.0924326553940773,
    "learning_rate": 0.001
  },
  {
    "episode": 3035,
    "reward": 88.32826,
    "length": 66,
    "time": 49710.945579,
    "actor_loss": -61.10228729248047,
    "critic_loss": 12.984989166259766,
    "ent_coef": 0.0946054756641388,
    "learning_rate": 0.001
  },
  {
    "episode": 3036,
    "reward": 89.731833,
    "length": 62,
    "time": 49722.381043,
    "actor_loss": -57.19940185546875,
    "critic_loss": 93.14916229248047,
    "ent_coef": 0.09638487547636032,
    "learning_rate": 0.001
  },
  {
    "episode": 3037,
    "reward": 88.997769,
    "length": 65,
    "time": 49734.412976,
    "actor_loss": -59.043113708496094,
    "critic_loss": 7.4594621658325195,
    "ent_coef": 0.09689939022064209,
    "learning_rate": 0.001
  },
  {
    "episode": 3038,
    "reward": 88.556901,
    "length": 66,
    "time": 49746.845379,
    "actor_loss": -58.96345901489258,
    "critic_loss": 54.70490646362305,
    "ent_coef": 0.09486434608697891,
    "learning_rate": 0.001
  },
  {
    "episode": 3039,
    "reward": 87.066746,
    "length": 68,
    "time": 49758.820414,
    "actor_loss": -63.58784866333008,
    "critic_loss": 4.918349266052246,
    "ent_coef": 0.0917523130774498,
    "learning_rate": 0.001
  },
  {
    "episode": 3040,
    "reward": 90.187883,
    "length": 63,
    "time": 49770.255393,
    "actor_loss": -61.87266540527344,
    "critic_loss": 2.4007315635681152,
    "ent_coef": 0.09411288797855377,
    "learning_rate": 0.001
  },
  {
    "episode": 3041,
    "reward": 89.641284,
    "length": 64,
    "time": 49783.329647,
    "actor_loss": -61.25553894042969,
    "critic_loss": 4.550199508666992,
    "ent_coef": 0.09406735002994537,
    "learning_rate": 0.001
  },
  {
    "episode": 3042,
    "reward": 89.542151,
    "length": 65,
    "time": 49799.523298,
    "actor_loss": -63.37393569946289,
    "critic_loss": 2.946268081665039,
    "ent_coef": 0.09129546582698822,
    "learning_rate": 0.001
  },
  {
    "episode": 3043,
    "reward": 87.124692,
    "length": 69,
    "time": 49811.39844,
    "actor_loss": -60.554691314697266,
    "critic_loss": 6.2143096923828125,
    "ent_coef": 0.08755114674568176,
    "learning_rate": 0.001
  },
  {
    "episode": 3044,
    "reward": 88.351312,
    "length": 66,
    "time": 49822.911687,
    "actor_loss": -63.213706970214844,
    "critic_loss": 17.73310089111328,
    "ent_coef": 0.08626467734575272,
    "learning_rate": 0.001
  },
  {
    "episode": 3045,
    "reward": 87.366106,
    "length": 68,
    "time": 49834.895494,
    "actor_loss": -61.0421142578125,
    "critic_loss": 3.231520652770996,
    "ent_coef": 0.08396371454000473,
    "learning_rate": 0.001
  },
  {
    "episode": 3046,
    "reward": 85.47302,
    "length": 72,
    "time": 49847.33065,
    "actor_loss": -60.243064880371094,
    "critic_loss": 5.962285041809082,
    "ent_coef": 0.08418942987918854,
    "learning_rate": 0.001
  },
  {
    "episode": 3047,
    "reward": 84.582055,
    "length": 73,
    "time": 49862.390019,
    "actor_loss": -70.69758605957031,
    "critic_loss": 8.790481567382812,
    "ent_coef": 0.08102775365114212,
    "learning_rate": 0.001
  },
  {
    "episode": 3048,
    "reward": 88.1326,
    "length": 65,
    "time": 49873.77562,
    "actor_loss": -67.85775756835938,
    "critic_loss": 14.84348201751709,
    "ent_coef": 0.08028875291347504,
    "learning_rate": 0.001
  },
  {
    "episode": 3049,
    "reward": 89.463831,
    "length": 64,
    "time": 49886.174847,
    "actor_loss": -66.07041931152344,
    "critic_loss": 6.5115203857421875,
    "ent_coef": 0.08266239613294601,
    "learning_rate": 0.001
  },
  {
    "episode": 3050,
    "reward": 88.204801,
    "length": 66,
    "time": 49899.826593,
    "actor_loss": -59.828941345214844,
    "critic_loss": 3.4996211528778076,
    "ent_coef": 0.08440958708524704,
    "learning_rate": 0.001
  },
  {
    "episode": 3051,
    "reward": 89.985429,
    "length": 64,
    "time": 49913.419043,
    "actor_loss": -60.22795104980469,
    "critic_loss": 12.413379669189453,
    "ent_coef": 0.08437319099903107,
    "learning_rate": 0.001
  },
  {
    "episode": 3052,
    "reward": 87.741037,
    "length": 67,
    "time": 49925.000042,
    "actor_loss": -61.33606719970703,
    "critic_loss": 4.033522129058838,
    "ent_coef": 0.08489477634429932,
    "learning_rate": 0.001
  },
  {
    "episode": 3053,
    "reward": 89.194309,
    "length": 67,
    "time": 49937.890168,
    "actor_loss": -64.72235107421875,
    "critic_loss": 68.13941955566406,
    "ent_coef": 0.08669918030500412,
    "learning_rate": 0.001
  },
  {
    "episode": 3054,
    "reward": 84.537468,
    "length": 70,
    "time": 49950.868086,
    "actor_loss": -65.71864318847656,
    "critic_loss": 16.407617568969727,
    "ent_coef": 0.08440228551626205,
    "learning_rate": 0.001
  },
  {
    "episode": 3055,
    "reward": 86.017173,
    "length": 70,
    "time": 49968.299526,
    "actor_loss": -65.25218200683594,
    "critic_loss": 9.694403648376465,
    "ent_coef": 0.08463990688323975,
    "learning_rate": 0.001
  },
  {
    "episode": 3056,
    "reward": 80.541981,
    "length": 85,
    "time": 49983.277902,
    "actor_loss": -65.55070495605469,
    "critic_loss": 5.524855613708496,
    "ent_coef": 0.08160409331321716,
    "learning_rate": 0.001
  },
  {
    "episode": 3057,
    "reward": 88.519439,
    "length": 65,
    "time": 49997.337053,
    "actor_loss": -66.0679702758789,
    "critic_loss": 10.253626823425293,
    "ent_coef": 0.08430957049131393,
    "learning_rate": 0.001
  },
  {
    "episode": 3058,
    "reward": 86.954039,
    "length": 68,
    "time": 50012.499926,
    "actor_loss": -55.50902557373047,
    "critic_loss": 15.798440933227539,
    "ent_coef": 0.08555549383163452,
    "learning_rate": 0.001
  },
  {
    "episode": 3059,
    "reward": 90.096735,
    "length": 64,
    "time": 50024.092229,
    "actor_loss": -60.670013427734375,
    "critic_loss": 4.7727556228637695,
    "ent_coef": 0.08943331241607666,
    "learning_rate": 0.001
  },
  {
    "episode": 3060,
    "reward": 87.311915,
    "length": 66,
    "time": 50036.014024,
    "actor_loss": -63.271812438964844,
    "critic_loss": 2.3227286338806152,
    "ent_coef": 0.0954514741897583,
    "learning_rate": 0.001
  },
  {
    "episode": 3061,
    "reward": 89.158829,
    "length": 63,
    "time": 50049.254547,
    "actor_loss": -65.0204086303711,
    "critic_loss": 4.219388961791992,
    "ent_coef": 0.09601961076259613,
    "learning_rate": 0.001
  },
  {
    "episode": 3062,
    "reward": 89.000006,
    "length": 65,
    "time": 50063.218543,
    "actor_loss": -59.80303955078125,
    "critic_loss": 6.971721172332764,
    "ent_coef": 0.09386173635721207,
    "learning_rate": 0.001
  },
  {
    "episode": 3063,
    "reward": 88.025369,
    "length": 67,
    "time": 50076.946738,
    "actor_loss": -62.38643264770508,
    "critic_loss": 37.77256774902344,
    "ent_coef": 0.09206002205610275,
    "learning_rate": 0.001
  },
  {
    "episode": 3064,
    "reward": 84.490236,
    "length": 72,
    "time": 50089.892007,
    "actor_loss": -66.14791870117188,
    "critic_loss": 4.207864761352539,
    "ent_coef": 0.09133927524089813,
    "learning_rate": 0.001
  },
  {
    "episode": 3065,
    "reward": 91.154646,
    "length": 61,
    "time": 50101.63255,
    "actor_loss": -65.15211486816406,
    "critic_loss": 2.2221884727478027,
    "ent_coef": 0.0956680029630661,
    "learning_rate": 0.001
  },
  {
    "episode": 3066,
    "reward": 90.622057,
    "length": 62,
    "time": 50115.190325,
    "actor_loss": -67.2509994506836,
    "critic_loss": 3.8956878185272217,
    "ent_coef": 0.10123220831155777,
    "learning_rate": 0.001
  },
  {
    "episode": 3067,
    "reward": 88.039782,
    "length": 67,
    "time": 50127.9653,
    "actor_loss": -62.64009094238281,
    "critic_loss": 2.2491202354431152,
    "ent_coef": 0.09931397438049316,
    "learning_rate": 0.001
  },
  {
    "episode": 3068,
    "reward": 53.551748,
    "length": 117,
    "time": 50146.72454,
    "actor_loss": -58.37800598144531,
    "critic_loss": 3.092925548553467,
    "ent_coef": 0.0966961532831192,
    "learning_rate": 0.001
  },
  {
    "episode": 3069,
    "reward": 88.090486,
    "length": 66,
    "time": 50161.083637,
    "actor_loss": -60.696327209472656,
    "critic_loss": 11.904884338378906,
    "ent_coef": 0.09794097393751144,
    "learning_rate": 0.001
  },
  {
    "episode": 3070,
    "reward": 90.254066,
    "length": 62,
    "time": 50173.159067,
    "actor_loss": -59.028282165527344,
    "critic_loss": 13.179744720458984,
    "ent_coef": 0.09487178921699524,
    "learning_rate": 0.001
  },
  {
    "episode": 3071,
    "reward": 88.088349,
    "length": 66,
    "time": 50187.845917,
    "actor_loss": -61.5841064453125,
    "critic_loss": 7.876247406005859,
    "ent_coef": 0.09379126876592636,
    "learning_rate": 0.001
  },
  {
    "episode": 3072,
    "reward": 88.815084,
    "length": 65,
    "time": 50199.550268,
    "actor_loss": -64.24520874023438,
    "critic_loss": 3.7527103424072266,
    "ent_coef": 0.09374508261680603,
    "learning_rate": 0.001
  },
  {
    "episode": 3073,
    "reward": 88.215182,
    "length": 66,
    "time": 50211.085504,
    "actor_loss": -57.9364013671875,
    "critic_loss": 3.76004958152771,
    "ent_coef": 0.09679051488637924,
    "learning_rate": 0.001
  },
  {
    "episode": 3074,
    "reward": 88.235785,
    "length": 66,
    "time": 50222.871466,
    "actor_loss": -65.35997009277344,
    "critic_loss": 5.255222797393799,
    "ent_coef": 0.096738301217556,
    "learning_rate": 0.001
  },
  {
    "episode": 3075,
    "reward": 83.290196,
    "length": 73,
    "time": 50237.400235,
    "actor_loss": -62.7398681640625,
    "critic_loss": 4.507765769958496,
    "ent_coef": 0.09443209320306778,
    "learning_rate": 0.001
  },
  {
    "episode": 3076,
    "reward": 83.06363,
    "length": 76,
    "time": 50251.342078,
    "actor_loss": -60.10933303833008,
    "critic_loss": 37.162933349609375,
    "ent_coef": 0.09104697406291962,
    "learning_rate": 0.001
  },
  {
    "episode": 3077,
    "reward": 88.048676,
    "length": 66,
    "time": 50267.991486,
    "actor_loss": -60.79937744140625,
    "critic_loss": 22.81900405883789,
    "ent_coef": 0.08928173035383224,
    "learning_rate": 0.001
  },
  {
    "episode": 3078,
    "reward": 88.797956,
    "length": 66,
    "time": 50279.809074,
    "actor_loss": -70.1771011352539,
    "critic_loss": 6.2393269538879395,
    "ent_coef": 0.09280870109796524,
    "learning_rate": 0.001
  },
  {
    "episode": 3079,
    "reward": 88.008678,
    "length": 67,
    "time": 50292.555886,
    "actor_loss": -62.344459533691406,
    "critic_loss": 9.611217498779297,
    "ent_coef": 0.09408175200223923,
    "learning_rate": 0.001
  },
  {
    "episode": 3080,
    "reward": 89.442974,
    "length": 63,
    "time": 50306.255644,
    "actor_loss": -62.68329620361328,
    "critic_loss": 2.629727363586426,
    "ent_coef": 0.09846518188714981,
    "learning_rate": 0.001
  },
  {
    "episode": 3081,
    "reward": 84.559115,
    "length": 72,
    "time": 50320.602932,
    "actor_loss": -67.880859375,
    "critic_loss": 32.72247314453125,
    "ent_coef": 0.09789025038480759,
    "learning_rate": 0.001
  },
  {
    "episode": 3082,
    "reward": 89.013373,
    "length": 65,
    "time": 50331.948213,
    "actor_loss": -62.876792907714844,
    "critic_loss": 10.203245162963867,
    "ent_coef": 0.10011742264032364,
    "learning_rate": 0.001
  },
  {
    "episode": 3083,
    "reward": 82.575257,
    "length": 75,
    "time": 50346.436087,
    "actor_loss": -60.95648956298828,
    "critic_loss": 3.4226431846618652,
    "ent_coef": 0.09406710416078568,
    "learning_rate": 0.001
  },
  {
    "episode": 3084,
    "reward": 89.287363,
    "length": 65,
    "time": 50358.459085,
    "actor_loss": -62.394744873046875,
    "critic_loss": 10.126237869262695,
    "ent_coef": 0.08929307758808136,
    "learning_rate": 0.001
  },
  {
    "episode": 3085,
    "reward": 85.078984,
    "length": 70,
    "time": 50370.611451,
    "actor_loss": -61.75807571411133,
    "critic_loss": 26.456300735473633,
    "ent_coef": 0.09069893509149551,
    "learning_rate": 0.001
  },
  {
    "episode": 3086,
    "reward": 90.270651,
    "length": 63,
    "time": 50383.937369,
    "actor_loss": -58.65956115722656,
    "critic_loss": 6.832585334777832,
    "ent_coef": 0.0924261137843132,
    "learning_rate": 0.001
  },
  {
    "episode": 3087,
    "reward": 87.317806,
    "length": 68,
    "time": 50395.625881,
    "actor_loss": -59.88180160522461,
    "critic_loss": 45.18885040283203,
    "ent_coef": 0.09147916734218597,
    "learning_rate": 0.001
  },
  {
    "episode": 3088,
    "reward": 84.693189,
    "length": 72,
    "time": 50410.278709,
    "actor_loss": -64.33979797363281,
    "critic_loss": 20.178068161010742,
    "ent_coef": 0.08643607050180435,
    "learning_rate": 0.001
  },
  {
    "episode": 3089,
    "reward": 85.158628,
    "length": 71,
    "time": 50422.391977,
    "actor_loss": -63.579010009765625,
    "critic_loss": 2.1443586349487305,
    "ent_coef": 0.08381675183773041,
    "learning_rate": 0.001
  },
  {
    "episode": 3090,
    "reward": 88.916936,
    "length": 64,
    "time": 50434.656167,
    "actor_loss": -56.530967712402344,
    "critic_loss": 3.418146848678589,
    "ent_coef": 0.08264521509408951,
    "learning_rate": 0.001
  },
  {
    "episode": 3091,
    "reward": 76.480961,
    "length": 84,
    "time": 50449.689303,
    "actor_loss": -59.253761291503906,
    "critic_loss": 29.17230987548828,
    "ent_coef": 0.07916232198476791,
    "learning_rate": 0.001
  },
  {
    "episode": 3092,
    "reward": 89.228179,
    "length": 63,
    "time": 50461.046642,
    "actor_loss": -59.55189514160156,
    "critic_loss": 3.1568713188171387,
    "ent_coef": 0.08586790412664413,
    "learning_rate": 0.001
  },
  {
    "episode": 3093,
    "reward": 91.614554,
    "length": 60,
    "time": 50472.850717,
    "actor_loss": -64.04290771484375,
    "critic_loss": 49.101234436035156,
    "ent_coef": 0.09441773593425751,
    "learning_rate": 0.001
  },
  {
    "episode": 3094,
    "reward": 82.322692,
    "length": 75,
    "time": 50487.354695,
    "actor_loss": -58.32126998901367,
    "critic_loss": 3.4820427894592285,
    "ent_coef": 0.09445320069789886,
    "learning_rate": 0.001
  },
  {
    "episode": 3095,
    "reward": 85.358019,
    "length": 69,
    "time": 50501.573009,
    "actor_loss": -58.091346740722656,
    "critic_loss": 20.38565444946289,
    "ent_coef": 0.0943106859922409,
    "learning_rate": 0.001
  },
  {
    "episode": 3096,
    "reward": 90.195848,
    "length": 63,
    "time": 50513.557605,
    "actor_loss": -58.712554931640625,
    "critic_loss": 3.53157114982605,
    "ent_coef": 0.09607218950986862,
    "learning_rate": 0.001
  },
  {
    "episode": 3097,
    "reward": 89.074277,
    "length": 64,
    "time": 50526.505496,
    "actor_loss": -55.29209518432617,
    "critic_loss": 7.952297687530518,
    "ent_coef": 0.09322953969240189,
    "learning_rate": 0.001
  },
  {
    "episode": 3098,
    "reward": 86.046666,
    "length": 68,
    "time": 50538.596567,
    "actor_loss": -63.25220489501953,
    "critic_loss": 2.2895913124084473,
    "ent_coef": 0.09005314856767654,
    "learning_rate": 0.001
  },
  {
    "episode": 3099,
    "reward": 88.362397,
    "length": 65,
    "time": 50550.485938,
    "actor_loss": -58.8383903503418,
    "critic_loss": 5.092220306396484,
    "ent_coef": 0.09197703003883362,
    "learning_rate": 0.001
  },
  {
    "episode": 3100,
    "reward": 87.966388,
    "length": 65,
    "time": 50562.891945,
    "actor_loss": -56.123653411865234,
    "critic_loss": 7.281057357788086,
    "ent_coef": 0.08877719938755035,
    "learning_rate": 0.001
  },
  {
    "episode": 3101,
    "reward": 83.113013,
    "length": 74,
    "time": 50575.519668,
    "actor_loss": -61.943260192871094,
    "critic_loss": 21.837528228759766,
    "ent_coef": 0.08399812132120132,
    "learning_rate": 0.001
  },
  {
    "episode": 3102,
    "reward": 89.236779,
    "length": 64,
    "time": 50588.386574,
    "actor_loss": -61.228797912597656,
    "critic_loss": 7.003129482269287,
    "ent_coef": 0.08927866816520691,
    "learning_rate": 0.001
  },
  {
    "episode": 3103,
    "reward": 88.308216,
    "length": 66,
    "time": 50600.761065,
    "actor_loss": -64.55302429199219,
    "critic_loss": 6.242063522338867,
    "ent_coef": 0.09093199670314789,
    "learning_rate": 0.001
  },
  {
    "episode": 3104,
    "reward": 88.743948,
    "length": 66,
    "time": 50615.260474,
    "actor_loss": -67.5462646484375,
    "critic_loss": 14.743484497070312,
    "ent_coef": 0.09141436964273453,
    "learning_rate": 0.001
  },
  {
    "episode": 3105,
    "reward": 78.688713,
    "length": 83,
    "time": 50630.687099,
    "actor_loss": -59.448036193847656,
    "critic_loss": 5.2951202392578125,
    "ent_coef": 0.0872010812163353,
    "learning_rate": 0.001
  },
  {
    "episode": 3106,
    "reward": 85.404887,
    "length": 69,
    "time": 50649.507317,
    "actor_loss": -61.74964141845703,
    "critic_loss": 3.616518974304199,
    "ent_coef": 0.08661433309316635,
    "learning_rate": 0.001
  },
  {
    "episode": 3107,
    "reward": 90.515071,
    "length": 61,
    "time": 50661.525828,
    "actor_loss": -65.5853500366211,
    "critic_loss": 4.201208591461182,
    "ent_coef": 0.08830668032169342,
    "learning_rate": 0.001
  },
  {
    "episode": 3108,
    "reward": 83.536184,
    "length": 73,
    "time": 50675.797415,
    "actor_loss": -62.931495666503906,
    "critic_loss": 15.78109359741211,
    "ent_coef": 0.08506142348051071,
    "learning_rate": 0.001
  },
  {
    "episode": 3109,
    "reward": 74.934151,
    "length": 86,
    "time": 50690.032074,
    "actor_loss": -54.608909606933594,
    "critic_loss": 25.33211898803711,
    "ent_coef": 0.08274509012699127,
    "learning_rate": 0.001
  },
  {
    "episode": 3110,
    "reward": 90.463136,
    "length": 62,
    "time": 50704.871241,
    "actor_loss": -60.01939010620117,
    "critic_loss": 6.461741924285889,
    "ent_coef": 0.08510340750217438,
    "learning_rate": 0.001
  },
  {
    "episode": 3111,
    "reward": 85.730477,
    "length": 69,
    "time": 50718.091471,
    "actor_loss": -62.27225875854492,
    "critic_loss": 11.237418174743652,
    "ent_coef": 0.08689364045858383,
    "learning_rate": 0.001
  },
  {
    "episode": 3112,
    "reward": 88.450371,
    "length": 65,
    "time": 50732.212531,
    "actor_loss": -59.17493438720703,
    "critic_loss": 2.7160840034484863,
    "ent_coef": 0.09185332804918289,
    "learning_rate": 0.001
  },
  {
    "episode": 3113,
    "reward": 81.691154,
    "length": 74,
    "time": 50745.699266,
    "actor_loss": -67.73429870605469,
    "critic_loss": 104.77909088134766,
    "ent_coef": 0.09791970252990723,
    "learning_rate": 0.001
  },
  {
    "episode": 3114,
    "reward": 89.161046,
    "length": 63,
    "time": 50758.831686,
    "actor_loss": -62.6724853515625,
    "critic_loss": 10.474225044250488,
    "ent_coef": 0.10466250777244568,
    "learning_rate": 0.001
  },
  {
    "episode": 3115,
    "reward": 86.904282,
    "length": 72,
    "time": 50772.130363,
    "actor_loss": -66.52738189697266,
    "critic_loss": 21.91130828857422,
    "ent_coef": 0.10590451955795288,
    "learning_rate": 0.001
  },
  {
    "episode": 3116,
    "reward": 71.320095,
    "length": 91,
    "time": 50789.721798,
    "actor_loss": -57.7149658203125,
    "critic_loss": 2.9925763607025146,
    "ent_coef": 0.096917062997818,
    "learning_rate": 0.001
  },
  {
    "episode": 3117,
    "reward": 76.231849,
    "length": 82,
    "time": 50803.54144,
    "actor_loss": -62.740657806396484,
    "critic_loss": 34.963165283203125,
    "ent_coef": 0.0924873873591423,
    "learning_rate": 0.001
  },
  {
    "episode": 3118,
    "reward": 87.27334,
    "length": 66,
    "time": 50818.545093,
    "actor_loss": -64.64067077636719,
    "critic_loss": 2.526510000228882,
    "ent_coef": 0.09183574467897415,
    "learning_rate": 0.001
  },
  {
    "episode": 3119,
    "reward": 80.596209,
    "length": 77,
    "time": 50832.486483,
    "actor_loss": -66.63066101074219,
    "critic_loss": 4.181923866271973,
    "ent_coef": 0.08614259958267212,
    "learning_rate": 0.001
  },
  {
    "episode": 3120,
    "reward": 90.699522,
    "length": 61,
    "time": 50845.758432,
    "actor_loss": -61.24936294555664,
    "critic_loss": 13.841569900512695,
    "ent_coef": 0.08938754349946976,
    "learning_rate": 0.001
  },
  {
    "episode": 3121,
    "reward": 87.30186,
    "length": 67,
    "time": 50858.613624,
    "actor_loss": -59.04564666748047,
    "critic_loss": 4.649270057678223,
    "ent_coef": 0.08952382951974869,
    "learning_rate": 0.001
  },
  {
    "episode": 3122,
    "reward": 90.671589,
    "length": 61,
    "time": 50872.957886,
    "actor_loss": -64.61668395996094,
    "critic_loss": 27.468669891357422,
    "ent_coef": 0.09499210864305496,
    "learning_rate": 0.001
  },
  {
    "episode": 3123,
    "reward": 86.467819,
    "length": 70,
    "time": 50888.702315,
    "actor_loss": -63.9304313659668,
    "critic_loss": 11.219463348388672,
    "ent_coef": 0.10080374032258987,
    "learning_rate": 0.001
  },
  {
    "episode": 3124,
    "reward": 86.403511,
    "length": 68,
    "time": 50903.951364,
    "actor_loss": -70.32296752929688,
    "critic_loss": 22.86156463623047,
    "ent_coef": 0.1009456142783165,
    "learning_rate": 0.001
  },
  {
    "episode": 3125,
    "reward": 82.093431,
    "length": 76,
    "time": 50916.742705,
    "actor_loss": -67.24192810058594,
    "critic_loss": 52.16853332519531,
    "ent_coef": 0.09950713813304901,
    "learning_rate": 0.001
  },
  {
    "episode": 3126,
    "reward": 85.371779,
    "length": 71,
    "time": 50930.235742,
    "actor_loss": -64.86724853515625,
    "critic_loss": 76.27092742919922,
    "ent_coef": 0.08988551050424576,
    "learning_rate": 0.001
  },
  {
    "episode": 3127,
    "reward": 84.433196,
    "length": 71,
    "time": 50942.888539,
    "actor_loss": -66.0621109008789,
    "critic_loss": 2.590071678161621,
    "ent_coef": 0.08739610761404037,
    "learning_rate": 0.001
  },
  {
    "episode": 3128,
    "reward": 87.33907,
    "length": 69,
    "time": 50959.933976,
    "actor_loss": -66.40275573730469,
    "critic_loss": 6.201091289520264,
    "ent_coef": 0.08243794739246368,
    "learning_rate": 0.001
  },
  {
    "episode": 3129,
    "reward": 82.717694,
    "length": 75,
    "time": 50973.386096,
    "actor_loss": -60.48826217651367,
    "critic_loss": 20.47856903076172,
    "ent_coef": 0.07872477173805237,
    "learning_rate": 0.001
  },
  {
    "episode": 3130,
    "reward": 86.559234,
    "length": 70,
    "time": 50987.804446,
    "actor_loss": -61.40864562988281,
    "critic_loss": 3.0459542274475098,
    "ent_coef": 0.07734572887420654,
    "learning_rate": 0.001
  },
  {
    "episode": 3131,
    "reward": -280.92533,
    "length": 194,
    "time": 51017.468239,
    "actor_loss": -60.8153190612793,
    "critic_loss": 2.3360376358032227,
    "ent_coef": 0.0665210410952568,
    "learning_rate": 0.001
  },
  {
    "episode": 3132,
    "reward": 114.220394,
    "length": 68,
    "time": 51029.680189,
    "actor_loss": -67.44662475585938,
    "critic_loss": 2.260417938232422,
    "ent_coef": 0.06634979695081711,
    "learning_rate": 0.001
  },
  {
    "episode": 3133,
    "reward": 88.088068,
    "length": 66,
    "time": 51041.489048,
    "actor_loss": -57.5775032043457,
    "critic_loss": 70.52375030517578,
    "ent_coef": 0.07003308832645416,
    "learning_rate": 0.001
  },
  {
    "episode": 3134,
    "reward": 74.889952,
    "length": 88,
    "time": 51059.240777,
    "actor_loss": -64.72740173339844,
    "critic_loss": 2.3310210704803467,
    "ent_coef": 0.0674513503909111,
    "learning_rate": 0.001
  },
  {
    "episode": 3135,
    "reward": 83.001112,
    "length": 74,
    "time": 51071.893046,
    "actor_loss": -61.60625457763672,
    "critic_loss": 2.8651976585388184,
    "ent_coef": 0.06827648729085922,
    "learning_rate": 0.001
  },
  {
    "episode": 3136,
    "reward": 86.263293,
    "length": 68,
    "time": 51084.914909,
    "actor_loss": -61.16450119018555,
    "critic_loss": 3.4597318172454834,
    "ent_coef": 0.06982574611902237,
    "learning_rate": 0.001
  },
  {
    "episode": 3137,
    "reward": 90.162371,
    "length": 61,
    "time": 51096.216045,
    "actor_loss": -60.08238220214844,
    "critic_loss": 53.73418426513672,
    "ent_coef": 0.0711820125579834,
    "learning_rate": 0.001
  },
  {
    "episode": 3138,
    "reward": 88.30639,
    "length": 66,
    "time": 51110.220691,
    "actor_loss": -67.22047424316406,
    "critic_loss": 13.546631813049316,
    "ent_coef": 0.07281515002250671,
    "learning_rate": 0.001
  },
  {
    "episode": 3139,
    "reward": 83.14242,
    "length": 73,
    "time": 51123.200808,
    "actor_loss": -64.69681549072266,
    "critic_loss": 13.10390853881836,
    "ent_coef": 0.07195062935352325,
    "learning_rate": 0.001
  },
  {
    "episode": 3140,
    "reward": 89.700619,
    "length": 63,
    "time": 51135.338604,
    "actor_loss": -64.98812866210938,
    "critic_loss": 73.93314361572266,
    "ent_coef": 0.07245062291622162,
    "learning_rate": 0.001
  },
  {
    "episode": 3141,
    "reward": 90.310048,
    "length": 63,
    "time": 51146.580382,
    "actor_loss": -58.02796173095703,
    "critic_loss": 24.430618286132812,
    "ent_coef": 0.07715284079313278,
    "learning_rate": 0.001
  },
  {
    "episode": 3142,
    "reward": 86.611794,
    "length": 68,
    "time": 51159.579882,
    "actor_loss": -63.67094802856445,
    "critic_loss": 10.971796989440918,
    "ent_coef": 0.078461654484272,
    "learning_rate": 0.001
  },
  {
    "episode": 3143,
    "reward": 89.129753,
    "length": 64,
    "time": 51171.969309,
    "actor_loss": -60.444488525390625,
    "critic_loss": 4.403831958770752,
    "ent_coef": 0.08136643469333649,
    "learning_rate": 0.001
  },
  {
    "episode": 3144,
    "reward": 87.970342,
    "length": 66,
    "time": 51185.351574,
    "actor_loss": -60.634090423583984,
    "critic_loss": 3.9181299209594727,
    "ent_coef": 0.08235330134630203,
    "learning_rate": 0.001
  },
  {
    "episode": 3145,
    "reward": 87.167743,
    "length": 69,
    "time": 51197.171864,
    "actor_loss": -60.197669982910156,
    "critic_loss": 18.702987670898438,
    "ent_coef": 0.082551971077919,
    "learning_rate": 0.001
  },
  {
    "episode": 3146,
    "reward": 82.899462,
    "length": 74,
    "time": 51209.702282,
    "actor_loss": -62.04612350463867,
    "critic_loss": 2.2732126712799072,
    "ent_coef": 0.07894882559776306,
    "learning_rate": 0.001
  },
  {
    "episode": 3147,
    "reward": 61.987009,
    "length": 103,
    "time": 51226.917052,
    "actor_loss": -63.51274490356445,
    "critic_loss": 5.0442214012146,
    "ent_coef": 0.07568380236625671,
    "learning_rate": 0.001
  },
  {
    "episode": 3148,
    "reward": 75.436032,
    "length": 84,
    "time": 51243.705979,
    "actor_loss": -64.15176391601562,
    "critic_loss": 23.605438232421875,
    "ent_coef": 0.07524533569812775,
    "learning_rate": 0.001
  },
  {
    "episode": 3149,
    "reward": 82.881646,
    "length": 72,
    "time": 51258.041853,
    "actor_loss": -59.926513671875,
    "critic_loss": 5.660715103149414,
    "ent_coef": 0.07927451282739639,
    "learning_rate": 0.001
  },
  {
    "episode": 3150,
    "reward": 84.580435,
    "length": 72,
    "time": 51273.027266,
    "actor_loss": -64.24913787841797,
    "critic_loss": 5.116669654846191,
    "ent_coef": 0.07741978019475937,
    "learning_rate": 0.001
  },
  {
    "episode": 3151,
    "reward": 86.973528,
    "length": 68,
    "time": 51287.657598,
    "actor_loss": -61.30594253540039,
    "critic_loss": 11.420732498168945,
    "ent_coef": 0.07759108394384384,
    "learning_rate": 0.001
  },
  {
    "episode": 3152,
    "reward": 86.57305,
    "length": 68,
    "time": 51300.878885,
    "actor_loss": -60.09961700439453,
    "critic_loss": 11.82375431060791,
    "ent_coef": 0.07717505842447281,
    "learning_rate": 0.001
  },
  {
    "episode": 3153,
    "reward": 88.978566,
    "length": 64,
    "time": 51313.360983,
    "actor_loss": -59.41527557373047,
    "critic_loss": 4.523741722106934,
    "ent_coef": 0.07804702967405319,
    "learning_rate": 0.001
  },
  {
    "episode": 3154,
    "reward": 85.708234,
    "length": 69,
    "time": 51326.372563,
    "actor_loss": -64.6892318725586,
    "critic_loss": 58.887901306152344,
    "ent_coef": 0.07980825006961823,
    "learning_rate": 0.001
  },
  {
    "episode": 3155,
    "reward": 89.064358,
    "length": 64,
    "time": 51339.631314,
    "actor_loss": -64.17097473144531,
    "critic_loss": 5.285722732543945,
    "ent_coef": 0.08661764860153198,
    "learning_rate": 0.001
  },
  {
    "episode": 3156,
    "reward": 86.888798,
    "length": 67,
    "time": 51351.701794,
    "actor_loss": -62.36370849609375,
    "critic_loss": 88.15336608886719,
    "ent_coef": 0.08862795680761337,
    "learning_rate": 0.001
  },
  {
    "episode": 3157,
    "reward": 88.343065,
    "length": 66,
    "time": 51365.313428,
    "actor_loss": -61.44203186035156,
    "critic_loss": 4.119044303894043,
    "ent_coef": 0.08981332182884216,
    "learning_rate": 0.001
  },
  {
    "episode": 3158,
    "reward": 86.812548,
    "length": 68,
    "time": 51377.13234,
    "actor_loss": -62.45608901977539,
    "critic_loss": 4.723841190338135,
    "ent_coef": 0.09414374828338623,
    "learning_rate": 0.001
  },
  {
    "episode": 3159,
    "reward": 65.422091,
    "length": 98,
    "time": 51394.754146,
    "actor_loss": -62.48538589477539,
    "critic_loss": 3.5966029167175293,
    "ent_coef": 0.0950445756316185,
    "learning_rate": 0.001
  },
  {
    "episode": 3160,
    "reward": 88.507043,
    "length": 65,
    "time": 51406.533695,
    "actor_loss": -64.86444091796875,
    "critic_loss": 3.6631598472595215,
    "ent_coef": 0.09474033117294312,
    "learning_rate": 0.001
  },
  {
    "episode": 3161,
    "reward": 90.548108,
    "length": 62,
    "time": 51418.474302,
    "actor_loss": -57.99681091308594,
    "critic_loss": 2.356139659881592,
    "ent_coef": 0.09529725462198257,
    "learning_rate": 0.001
  },
  {
    "episode": 3162,
    "reward": 90.364094,
    "length": 63,
    "time": 51432.236937,
    "actor_loss": -62.27949142456055,
    "critic_loss": 7.903054237365723,
    "ent_coef": 0.09314590692520142,
    "learning_rate": 0.001
  },
  {
    "episode": 3163,
    "reward": 84.32348,
    "length": 72,
    "time": 51445.424434,
    "actor_loss": -62.917362213134766,
    "critic_loss": 12.154922485351562,
    "ent_coef": 0.09098884463310242,
    "learning_rate": 0.001
  },
  {
    "episode": 3164,
    "reward": 82.559998,
    "length": 74,
    "time": 51459.272631,
    "actor_loss": -57.86740493774414,
    "critic_loss": 3.449190616607666,
    "ent_coef": 0.09168601036071777,
    "learning_rate": 0.001
  },
  {
    "episode": 3165,
    "reward": 87.230113,
    "length": 66,
    "time": 51473.353656,
    "actor_loss": -69.58537292480469,
    "critic_loss": 6.870781898498535,
    "ent_coef": 0.09395400434732437,
    "learning_rate": 0.001
  },
  {
    "episode": 3166,
    "reward": 88.906468,
    "length": 65,
    "time": 51485.593349,
    "actor_loss": -59.80664825439453,
    "critic_loss": 3.308870792388916,
    "ent_coef": 0.09594669938087463,
    "learning_rate": 0.001
  },
  {
    "episode": 3167,
    "reward": 83.918001,
    "length": 72,
    "time": 51499.452731,
    "actor_loss": -64.32775115966797,
    "critic_loss": 15.706411361694336,
    "ent_coef": 0.0973171666264534,
    "learning_rate": 0.001
  },
  {
    "episode": 3168,
    "reward": 86.804915,
    "length": 68,
    "time": 51514.138011,
    "actor_loss": -62.3147087097168,
    "critic_loss": 6.098417282104492,
    "ent_coef": 0.09618448466062546,
    "learning_rate": 0.001
  },
  {
    "episode": 3169,
    "reward": 88.403615,
    "length": 66,
    "time": 51525.75984,
    "actor_loss": -65.24151611328125,
    "critic_loss": 4.369247913360596,
    "ent_coef": 0.10122069716453552,
    "learning_rate": 0.001
  },
  {
    "episode": 3170,
    "reward": 89.8937,
    "length": 63,
    "time": 51538.06696,
    "actor_loss": -57.143375396728516,
    "critic_loss": 93.43476867675781,
    "ent_coef": 0.10338246077299118,
    "learning_rate": 0.001
  },
  {
    "episode": 3171,
    "reward": 86.750506,
    "length": 67,
    "time": 51549.892928,
    "actor_loss": -64.88853454589844,
    "critic_loss": 7.8785505294799805,
    "ent_coef": 0.10283614695072174,
    "learning_rate": 0.001
  },
  {
    "episode": 3172,
    "reward": 87.011009,
    "length": 69,
    "time": 51563.635365,
    "actor_loss": -65.07955932617188,
    "critic_loss": 14.463277816772461,
    "ent_coef": 0.09732566028833389,
    "learning_rate": 0.001
  },
  {
    "episode": 3173,
    "reward": 88.945253,
    "length": 65,
    "time": 51576.00631,
    "actor_loss": -58.84772491455078,
    "critic_loss": 2.9118690490722656,
    "ent_coef": 0.09398186951875687,
    "learning_rate": 0.001
  },
  {
    "episode": 3174,
    "reward": 90.51994,
    "length": 62,
    "time": 51589.722587,
    "actor_loss": -67.8719482421875,
    "critic_loss": 4.226342678070068,
    "ent_coef": 0.09546353667974472,
    "learning_rate": 0.001
  },
  {
    "episode": 3175,
    "reward": 87.495276,
    "length": 67,
    "time": 51602.569739,
    "actor_loss": -67.0963363647461,
    "critic_loss": 33.215606689453125,
    "ent_coef": 0.09476277977228165,
    "learning_rate": 0.001
  },
  {
    "episode": 3176,
    "reward": 87.251493,
    "length": 67,
    "time": 51615.870382,
    "actor_loss": -64.08717346191406,
    "critic_loss": 9.718766212463379,
    "ent_coef": 0.09332122653722763,
    "learning_rate": 0.001
  },
  {
    "episode": 3177,
    "reward": 88.34807,
    "length": 65,
    "time": 51628.297665,
    "actor_loss": -58.367645263671875,
    "critic_loss": 24.07119369506836,
    "ent_coef": 0.09579619020223618,
    "learning_rate": 0.001
  },
  {
    "episode": 3178,
    "reward": 89.453782,
    "length": 65,
    "time": 51640.818911,
    "actor_loss": -60.743099212646484,
    "critic_loss": 2.1857900619506836,
    "ent_coef": 0.100922591984272,
    "learning_rate": 0.001
  },
  {
    "episode": 3179,
    "reward": 88.71181,
    "length": 66,
    "time": 51653.504877,
    "actor_loss": -62.29292678833008,
    "critic_loss": 3.425605535507202,
    "ent_coef": 0.0996364951133728,
    "learning_rate": 0.001
  },
  {
    "episode": 3180,
    "reward": 83.479122,
    "length": 75,
    "time": 51666.353651,
    "actor_loss": -64.42292785644531,
    "critic_loss": 10.131847381591797,
    "ent_coef": 0.09311246871948242,
    "learning_rate": 0.001
  },
  {
    "episode": 3181,
    "reward": 89.717644,
    "length": 63,
    "time": 51679.978794,
    "actor_loss": -65.29057312011719,
    "critic_loss": 13.143656730651855,
    "ent_coef": 0.09598376601934433,
    "learning_rate": 0.001
  },
  {
    "episode": 3182,
    "reward": 87.557839,
    "length": 68,
    "time": 51691.732054,
    "actor_loss": -57.357112884521484,
    "critic_loss": 51.552703857421875,
    "ent_coef": 0.09613505750894547,
    "learning_rate": 0.001
  },
  {
    "episode": 3183,
    "reward": 88.813178,
    "length": 65,
    "time": 51707.335273,
    "actor_loss": -66.56513977050781,
    "critic_loss": 3.276886463165283,
    "ent_coef": 0.09438721835613251,
    "learning_rate": 0.001
  },
  {
    "episode": 3184,
    "reward": 88.06949,
    "length": 66,
    "time": 51721.605706,
    "actor_loss": -58.608436584472656,
    "critic_loss": 3.117137908935547,
    "ent_coef": 0.09102800488471985,
    "learning_rate": 0.001
  },
  {
    "episode": 3185,
    "reward": 88.036065,
    "length": 67,
    "time": 51734.484371,
    "actor_loss": -65.5125732421875,
    "critic_loss": 3.5664544105529785,
    "ent_coef": 0.09062090516090393,
    "learning_rate": 0.001
  },
  {
    "episode": 3186,
    "reward": 88.761457,
    "length": 65,
    "time": 51747.14786,
    "actor_loss": -65.08655548095703,
    "critic_loss": 8.298394203186035,
    "ent_coef": 0.09292839467525482,
    "learning_rate": 0.001
  },
  {
    "episode": 3187,
    "reward": 88.052413,
    "length": 67,
    "time": 51761.828192,
    "actor_loss": -71.82029724121094,
    "critic_loss": 4.4412336349487305,
    "ent_coef": 0.08930087089538574,
    "learning_rate": 0.001
  },
  {
    "episode": 3188,
    "reward": 86.784799,
    "length": 68,
    "time": 51776.64258,
    "actor_loss": -63.73589324951172,
    "critic_loss": 9.351428985595703,
    "ent_coef": 0.08822416514158249,
    "learning_rate": 0.001
  },
  {
    "episode": 3189,
    "reward": 88.695906,
    "length": 66,
    "time": 51788.534686,
    "actor_loss": -58.997100830078125,
    "critic_loss": 5.092981338500977,
    "ent_coef": 0.08695629239082336,
    "learning_rate": 0.001
  },
  {
    "episode": 3190,
    "reward": 89.569262,
    "length": 63,
    "time": 51800.543337,
    "actor_loss": -62.95368957519531,
    "critic_loss": 7.297718048095703,
    "ent_coef": 0.08881327509880066,
    "learning_rate": 0.001
  },
  {
    "episode": 3191,
    "reward": 89.463285,
    "length": 64,
    "time": 51813.805151,
    "actor_loss": -61.368927001953125,
    "critic_loss": 4.888007640838623,
    "ent_coef": 0.08734246343374252,
    "learning_rate": 0.001
  },
  {
    "episode": 3192,
    "reward": 89.363664,
    "length": 64,
    "time": 51827.167403,
    "actor_loss": -66.846923828125,
    "critic_loss": 11.266888618469238,
    "ent_coef": 0.09553787857294083,
    "learning_rate": 0.001
  },
  {
    "episode": 3193,
    "reward": 88.701418,
    "length": 65,
    "time": 51839.746907,
    "actor_loss": -64.28931427001953,
    "critic_loss": 5.322683334350586,
    "ent_coef": 0.09639202058315277,
    "learning_rate": 0.001
  },
  {
    "episode": 3194,
    "reward": 88.505331,
    "length": 65,
    "time": 51853.263519,
    "actor_loss": -57.06879425048828,
    "critic_loss": 3.3150930404663086,
    "ent_coef": 0.09782251715660095,
    "learning_rate": 0.001
  },
  {
    "episode": 3195,
    "reward": 84.783464,
    "length": 71,
    "time": 51867.076891,
    "actor_loss": -60.34770202636719,
    "critic_loss": 3.313508987426758,
    "ent_coef": 0.09476614743471146,
    "learning_rate": 0.001
  },
  {
    "episode": 3196,
    "reward": 89.278367,
    "length": 64,
    "time": 51881.06076,
    "actor_loss": -64.09866333007812,
    "critic_loss": 43.0269775390625,
    "ent_coef": 0.09177537262439728,
    "learning_rate": 0.001
  },
  {
    "episode": 3197,
    "reward": 90.262382,
    "length": 62,
    "time": 51892.943669,
    "actor_loss": -63.39004898071289,
    "critic_loss": 22.316120147705078,
    "ent_coef": 0.09308943152427673,
    "learning_rate": 0.001
  },
  {
    "episode": 3198,
    "reward": 89.331391,
    "length": 65,
    "time": 51906.745651,
    "actor_loss": -54.85639572143555,
    "critic_loss": 9.404472351074219,
    "ent_coef": 0.09346553683280945,
    "learning_rate": 0.001
  },
  {
    "episode": 3199,
    "reward": 87.830042,
    "length": 68,
    "time": 51920.59988,
    "actor_loss": -62.74972915649414,
    "critic_loss": 8.92105484008789,
    "ent_coef": 0.08990748226642609,
    "learning_rate": 0.001
  },
  {
    "episode": 3200,
    "reward": 89.318821,
    "length": 64,
    "time": 51931.829301,
    "actor_loss": -56.829002380371094,
    "critic_loss": 21.136314392089844,
    "ent_coef": 0.08634394407272339,
    "learning_rate": 0.001
  },
  {
    "episode": 3201,
    "reward": 86.745179,
    "length": 69,
    "time": 51946.27015,
    "actor_loss": -59.55780792236328,
    "critic_loss": 70.8336181640625,
    "ent_coef": 0.08139078319072723,
    "learning_rate": 0.001
  },
  {
    "episode": 3202,
    "reward": 89.213653,
    "length": 65,
    "time": 51958.408989,
    "actor_loss": -60.623268127441406,
    "critic_loss": 19.190860748291016,
    "ent_coef": 0.07723766565322876,
    "learning_rate": 0.001
  },
  {
    "episode": 3203,
    "reward": 89.189521,
    "length": 65,
    "time": 51971.00109,
    "actor_loss": -65.43954467773438,
    "critic_loss": 47.03562927246094,
    "ent_coef": 0.0761406198143959,
    "learning_rate": 0.001
  },
  {
    "episode": 3204,
    "reward": 90.421222,
    "length": 62,
    "time": 51984.12628,
    "actor_loss": -67.67410278320312,
    "critic_loss": 5.357963562011719,
    "ent_coef": 0.0784359723329544,
    "learning_rate": 0.001
  },
  {
    "episode": 3205,
    "reward": 89.086068,
    "length": 65,
    "time": 51995.727129,
    "actor_loss": -60.434913635253906,
    "critic_loss": 4.568065643310547,
    "ent_coef": 0.0795198380947113,
    "learning_rate": 0.001
  },
  {
    "episode": 3206,
    "reward": 87.596703,
    "length": 67,
    "time": 52009.34941,
    "actor_loss": -71.95657348632812,
    "critic_loss": 4.173910617828369,
    "ent_coef": 0.08155066519975662,
    "learning_rate": 0.001
  },
  {
    "episode": 3207,
    "reward": 86.028755,
    "length": 70,
    "time": 52022.832979,
    "actor_loss": -64.0941162109375,
    "critic_loss": 22.549209594726562,
    "ent_coef": 0.08299518376588821,
    "learning_rate": 0.001
  },
  {
    "episode": 3208,
    "reward": 87.547541,
    "length": 67,
    "time": 52037.486015,
    "actor_loss": -65.74199676513672,
    "critic_loss": 41.31922149658203,
    "ent_coef": 0.0870935395359993,
    "learning_rate": 0.001
  },
  {
    "episode": 3209,
    "reward": 89.072383,
    "length": 64,
    "time": 52052.15776,
    "actor_loss": -60.34109115600586,
    "critic_loss": 43.9017219543457,
    "ent_coef": 0.08794418722391129,
    "learning_rate": 0.001
  },
  {
    "episode": 3210,
    "reward": 89.742852,
    "length": 63,
    "time": 52064.17546,
    "actor_loss": -59.37640380859375,
    "critic_loss": 157.88189697265625,
    "ent_coef": 0.08799806982278824,
    "learning_rate": 0.001
  },
  {
    "episode": 3211,
    "reward": 90.186801,
    "length": 62,
    "time": 52076.182792,
    "actor_loss": -59.44660186767578,
    "critic_loss": 2.597623586654663,
    "ent_coef": 0.08738400042057037,
    "learning_rate": 0.001
  },
  {
    "episode": 3212,
    "reward": 90.186381,
    "length": 63,
    "time": 52087.994086,
    "actor_loss": -58.761085510253906,
    "critic_loss": 5.837104797363281,
    "ent_coef": 0.08543519675731659,
    "learning_rate": 0.001
  },
  {
    "episode": 3213,
    "reward": 88.098336,
    "length": 67,
    "time": 52100.375656,
    "actor_loss": -67.17475128173828,
    "critic_loss": 17.737133026123047,
    "ent_coef": 0.0846949964761734,
    "learning_rate": 0.001
  },
  {
    "episode": 3214,
    "reward": 86.139016,
    "length": 68,
    "time": 52112.447484,
    "actor_loss": -68.51899719238281,
    "critic_loss": 30.965473175048828,
    "ent_coef": 0.08532901108264923,
    "learning_rate": 0.001
  },
  {
    "episode": 3215,
    "reward": 89.679637,
    "length": 64,
    "time": 52124.618026,
    "actor_loss": -65.92201232910156,
    "critic_loss": 2.8164753913879395,
    "ent_coef": 0.08660431206226349,
    "learning_rate": 0.001
  },
  {
    "episode": 3216,
    "reward": 90.524496,
    "length": 61,
    "time": 52141.869396,
    "actor_loss": -64.02210235595703,
    "critic_loss": 11.768163681030273,
    "ent_coef": 0.09457584470510483,
    "learning_rate": 0.001
  },
  {
    "episode": 3217,
    "reward": 87.677017,
    "length": 67,
    "time": 52154.347952,
    "actor_loss": -57.99327087402344,
    "critic_loss": 55.3296012878418,
    "ent_coef": 0.09617357701063156,
    "learning_rate": 0.001
  },
  {
    "episode": 3218,
    "reward": 87.460479,
    "length": 67,
    "time": 52165.924724,
    "actor_loss": -58.05765151977539,
    "critic_loss": 3.8322865962982178,
    "ent_coef": 0.09488821029663086,
    "learning_rate": 0.001
  },
  {
    "episode": 3219,
    "reward": 90.313957,
    "length": 62,
    "time": 52177.837902,
    "actor_loss": -61.10747528076172,
    "critic_loss": 4.147257328033447,
    "ent_coef": 0.09765341132879257,
    "learning_rate": 0.001
  },
  {
    "episode": 3220,
    "reward": 88.855314,
    "length": 64,
    "time": 52190.281717,
    "actor_loss": -60.799556732177734,
    "critic_loss": 4.01447868347168,
    "ent_coef": 0.09684991091489792,
    "learning_rate": 0.001
  },
  {
    "episode": 3221,
    "reward": 88.760328,
    "length": 66,
    "time": 52204.713983,
    "actor_loss": -64.90765380859375,
    "critic_loss": 67.79413604736328,
    "ent_coef": 0.0951385498046875,
    "learning_rate": 0.001
  },
  {
    "episode": 3222,
    "reward": 90.881234,
    "length": 61,
    "time": 52216.509792,
    "actor_loss": -62.52953338623047,
    "critic_loss": 3.946396589279175,
    "ent_coef": 0.09707415103912354,
    "learning_rate": 0.001
  },
  {
    "episode": 3223,
    "reward": 90.517062,
    "length": 61,
    "time": 52228.514116,
    "actor_loss": -66.2604751586914,
    "critic_loss": 40.36416244506836,
    "ent_coef": 0.09750939905643463,
    "learning_rate": 0.001
  },
  {
    "episode": 3224,
    "reward": 87.804583,
    "length": 67,
    "time": 52241.580395,
    "actor_loss": -58.98289489746094,
    "critic_loss": 16.84151840209961,
    "ent_coef": 0.09532015770673752,
    "learning_rate": 0.001
  },
  {
    "episode": 3225,
    "reward": 85.981573,
    "length": 74,
    "time": 52255.576671,
    "actor_loss": -65.33245849609375,
    "critic_loss": 15.458650588989258,
    "ent_coef": 0.09417705982923508,
    "learning_rate": 0.001
  },
  {
    "episode": 3226,
    "reward": 79.02147,
    "length": 81,
    "time": 52270.518916,
    "actor_loss": -61.447181701660156,
    "critic_loss": 5.960020542144775,
    "ent_coef": 0.08479266613721848,
    "learning_rate": 0.001
  },
  {
    "episode": 3227,
    "reward": 86.839048,
    "length": 67,
    "time": 52283.492614,
    "actor_loss": -59.510467529296875,
    "critic_loss": 2.5278446674346924,
    "ent_coef": 0.08243918418884277,
    "learning_rate": 0.001
  },
  {
    "episode": 3228,
    "reward": 88.446638,
    "length": 66,
    "time": 52295.790749,
    "actor_loss": -63.394447326660156,
    "critic_loss": 38.1986198425293,
    "ent_coef": 0.08242104947566986,
    "learning_rate": 0.001
  },
  {
    "episode": 3229,
    "reward": 88.974688,
    "length": 65,
    "time": 52308.478048,
    "actor_loss": -64.96279907226562,
    "critic_loss": 3.2222962379455566,
    "ent_coef": 0.08322585374116898,
    "learning_rate": 0.001
  },
  {
    "episode": 3230,
    "reward": 89.979524,
    "length": 64,
    "time": 52321.642265,
    "actor_loss": -61.24278259277344,
    "critic_loss": 4.354347229003906,
    "ent_coef": 0.08222365379333496,
    "learning_rate": 0.001
  },
  {
    "episode": 3231,
    "reward": 88.67018,
    "length": 64,
    "time": 52333.233477,
    "actor_loss": -61.281333923339844,
    "critic_loss": 6.5105133056640625,
    "ent_coef": 0.08305159956216812,
    "learning_rate": 0.001
  },
  {
    "episode": 3232,
    "reward": 89.527217,
    "length": 63,
    "time": 52344.850752,
    "actor_loss": -62.0057373046875,
    "critic_loss": 6.009867191314697,
    "ent_coef": 0.08480942249298096,
    "learning_rate": 0.001
  },
  {
    "episode": 3233,
    "reward": 90.033492,
    "length": 63,
    "time": 52356.9673,
    "actor_loss": -61.71350860595703,
    "critic_loss": 5.144109725952148,
    "ent_coef": 0.08592699468135834,
    "learning_rate": 0.001
  },
  {
    "episode": 3234,
    "reward": 88.061126,
    "length": 66,
    "time": 52369.523627,
    "actor_loss": -55.844993591308594,
    "critic_loss": 93.51527404785156,
    "ent_coef": 0.08905911445617676,
    "learning_rate": 0.001
  },
  {
    "episode": 3235,
    "reward": 79.874692,
    "length": 78,
    "time": 52382.6078,
    "actor_loss": -59.51921081542969,
    "critic_loss": 3.3467206954956055,
    "ent_coef": 0.08721871674060822,
    "learning_rate": 0.001
  },
  {
    "episode": 3236,
    "reward": 89.604215,
    "length": 63,
    "time": 52397.105401,
    "actor_loss": -69.13916778564453,
    "critic_loss": 4.354728698730469,
    "ent_coef": 0.08855023235082626,
    "learning_rate": 0.001
  },
  {
    "episode": 3237,
    "reward": 90.137533,
    "length": 63,
    "time": 52409.395188,
    "actor_loss": -64.88825988769531,
    "critic_loss": 7.19495153427124,
    "ent_coef": 0.08882755041122437,
    "learning_rate": 0.001
  },
  {
    "episode": 3238,
    "reward": 89.010817,
    "length": 64,
    "time": 52424.077647,
    "actor_loss": -65.74462890625,
    "critic_loss": 36.877925872802734,
    "ent_coef": 0.08842387795448303,
    "learning_rate": 0.001
  },
  {
    "episode": 3239,
    "reward": 87.864293,
    "length": 68,
    "time": 52437.865638,
    "actor_loss": -63.10618591308594,
    "critic_loss": 7.927351951599121,
    "ent_coef": 0.08776513487100601,
    "learning_rate": 0.001
  },
  {
    "episode": 3240,
    "reward": 86.550464,
    "length": 68,
    "time": 52449.474791,
    "actor_loss": -67.0169677734375,
    "critic_loss": 5.439373970031738,
    "ent_coef": 0.08690030872821808,
    "learning_rate": 0.001
  },
  {
    "episode": 3241,
    "reward": 88.16048,
    "length": 66,
    "time": 52463.660315,
    "actor_loss": -70.36068725585938,
    "critic_loss": 3.370565891265869,
    "ent_coef": 0.08594731986522675,
    "learning_rate": 0.001
  },
  {
    "episode": 3242,
    "reward": 88.769612,
    "length": 66,
    "time": 52475.236816,
    "actor_loss": -65.72784423828125,
    "critic_loss": 59.774192810058594,
    "ent_coef": 0.08464732021093369,
    "learning_rate": 0.001
  },
  {
    "episode": 3243,
    "reward": 88.62713,
    "length": 71,
    "time": 52488.067668,
    "actor_loss": -67.40277099609375,
    "critic_loss": 23.133037567138672,
    "ent_coef": 0.0832851231098175,
    "learning_rate": 0.001
  },
  {
    "episode": 3244,
    "reward": 88.726754,
    "length": 65,
    "time": 52502.173954,
    "actor_loss": -65.84980773925781,
    "critic_loss": 5.104534149169922,
    "ent_coef": 0.08674836903810501,
    "learning_rate": 0.001
  },
  {
    "episode": 3245,
    "reward": 91.098514,
    "length": 60,
    "time": 52514.746461,
    "actor_loss": -62.69851303100586,
    "critic_loss": 24.326923370361328,
    "ent_coef": 0.09484288096427917,
    "learning_rate": 0.001
  },
  {
    "episode": 3246,
    "reward": 88.839162,
    "length": 65,
    "time": 52527.534758,
    "actor_loss": -61.05694580078125,
    "critic_loss": 14.062665939331055,
    "ent_coef": 0.09481769800186157,
    "learning_rate": 0.001
  },
  {
    "episode": 3247,
    "reward": 84.514313,
    "length": 72,
    "time": 52540.506755,
    "actor_loss": -64.91950988769531,
    "critic_loss": 5.807098865509033,
    "ent_coef": 0.09167090803384781,
    "learning_rate": 0.001
  },
  {
    "episode": 3248,
    "reward": 86.071993,
    "length": 69,
    "time": 52554.998012,
    "actor_loss": -64.33926391601562,
    "critic_loss": 6.238347053527832,
    "ent_coef": 0.09099903702735901,
    "learning_rate": 0.001
  },
  {
    "episode": 3249,
    "reward": 88.122835,
    "length": 65,
    "time": 52568.175772,
    "actor_loss": -61.29341125488281,
    "critic_loss": 2.5244150161743164,
    "ent_coef": 0.09019196778535843,
    "learning_rate": 0.001
  },
  {
    "episode": 3250,
    "reward": 89.611837,
    "length": 64,
    "time": 52582.246194,
    "actor_loss": -67.45220947265625,
    "critic_loss": 7.80967903137207,
    "ent_coef": 0.089143306016922,
    "learning_rate": 0.001
  },
  {
    "episode": 3251,
    "reward": 88.544656,
    "length": 66,
    "time": 52596.746947,
    "actor_loss": -59.21521759033203,
    "critic_loss": 4.351696014404297,
    "ent_coef": 0.08627169579267502,
    "learning_rate": 0.001
  },
  {
    "episode": 3252,
    "reward": 89.290985,
    "length": 64,
    "time": 52614.382706,
    "actor_loss": -61.490657806396484,
    "critic_loss": 4.569719314575195,
    "ent_coef": 0.08817321807146072,
    "learning_rate": 0.001
  },
  {
    "episode": 3253,
    "reward": 87.477197,
    "length": 67,
    "time": 52628.587354,
    "actor_loss": -65.67720794677734,
    "critic_loss": 6.36223840713501,
    "ent_coef": 0.08722108602523804,
    "learning_rate": 0.001
  },
  {
    "episode": 3254,
    "reward": 89.911797,
    "length": 64,
    "time": 52640.132111,
    "actor_loss": -67.28138732910156,
    "critic_loss": 4.020596504211426,
    "ent_coef": 0.08397985249757767,
    "learning_rate": 0.001
  },
  {
    "episode": 3255,
    "reward": 89.880997,
    "length": 62,
    "time": 52653.096338,
    "actor_loss": -58.09735107421875,
    "critic_loss": 4.5475544929504395,
    "ent_coef": 0.08830571174621582,
    "learning_rate": 0.001
  },
  {
    "episode": 3256,
    "reward": 88.676549,
    "length": 64,
    "time": 52667.141577,
    "actor_loss": -62.917930603027344,
    "critic_loss": 5.148407459259033,
    "ent_coef": 0.08951036632061005,
    "learning_rate": 0.001
  },
  {
    "episode": 3257,
    "reward": 89.331575,
    "length": 64,
    "time": 52679.509299,
    "actor_loss": -63.32050704956055,
    "critic_loss": 2.9458346366882324,
    "ent_coef": 0.0909331738948822,
    "learning_rate": 0.001
  },
  {
    "episode": 3258,
    "reward": 89.431758,
    "length": 64,
    "time": 52691.328433,
    "actor_loss": -61.003173828125,
    "critic_loss": 90.31477355957031,
    "ent_coef": 0.09366112947463989,
    "learning_rate": 0.001
  },
  {
    "episode": 3259,
    "reward": 89.077101,
    "length": 64,
    "time": 52703.568694,
    "actor_loss": -65.88646697998047,
    "critic_loss": 3.5570554733276367,
    "ent_coef": 0.09599273651838303,
    "learning_rate": 0.001
  },
  {
    "episode": 3260,
    "reward": 88.409051,
    "length": 65,
    "time": 52715.970371,
    "actor_loss": -57.160728454589844,
    "critic_loss": 75.55680084228516,
    "ent_coef": 0.10094800591468811,
    "learning_rate": 0.001
  },
  {
    "episode": 3261,
    "reward": 85.788021,
    "length": 70,
    "time": 52730.889795,
    "actor_loss": -62.96998977661133,
    "critic_loss": 5.205766677856445,
    "ent_coef": 0.09899693727493286,
    "learning_rate": 0.001
  },
  {
    "episode": 3262,
    "reward": 80.480587,
    "length": 78,
    "time": 52744.973184,
    "actor_loss": -71.46092987060547,
    "critic_loss": 3.4420108795166016,
    "ent_coef": 0.09707683324813843,
    "learning_rate": 0.001
  },
  {
    "episode": 3263,
    "reward": 86.416774,
    "length": 68,
    "time": 52756.796767,
    "actor_loss": -61.03980255126953,
    "critic_loss": 8.997579574584961,
    "ent_coef": 0.09692787379026413,
    "learning_rate": 0.001
  },
  {
    "episode": 3264,
    "reward": 82.55555,
    "length": 75,
    "time": 52769.489121,
    "actor_loss": -63.4467887878418,
    "critic_loss": 2.233009099960327,
    "ent_coef": 0.09168568253517151,
    "learning_rate": 0.001
  },
  {
    "episode": 3265,
    "reward": 88.936607,
    "length": 65,
    "time": 52781.70842,
    "actor_loss": -69.74002075195312,
    "critic_loss": 44.718902587890625,
    "ent_coef": 0.09307527542114258,
    "learning_rate": 0.001
  },
  {
    "episode": 3266,
    "reward": 88.899581,
    "length": 64,
    "time": 52796.120152,
    "actor_loss": -57.48365020751953,
    "critic_loss": 3.3699734210968018,
    "ent_coef": 0.09698901325464249,
    "learning_rate": 0.001
  },
  {
    "episode": 3267,
    "reward": 89.26069,
    "length": 64,
    "time": 52808.183172,
    "actor_loss": -71.17973327636719,
    "critic_loss": 3.13887357711792,
    "ent_coef": 0.09479174762964249,
    "learning_rate": 0.001
  },
  {
    "episode": 3268,
    "reward": 87.793964,
    "length": 67,
    "time": 52821.953816,
    "actor_loss": -66.13914489746094,
    "critic_loss": 4.862508773803711,
    "ent_coef": 0.09323883056640625,
    "learning_rate": 0.001
  },
  {
    "episode": 3269,
    "reward": 87.195569,
    "length": 68,
    "time": 52834.036282,
    "actor_loss": -66.77418518066406,
    "critic_loss": 8.448816299438477,
    "ent_coef": 0.08950524032115936,
    "learning_rate": 0.001
  },
  {
    "episode": 3270,
    "reward": 88.045897,
    "length": 65,
    "time": 52847.405681,
    "actor_loss": -63.97511672973633,
    "critic_loss": 12.065614700317383,
    "ent_coef": 0.08769670128822327,
    "learning_rate": 0.001
  },
  {
    "episode": 3271,
    "reward": 89.428009,
    "length": 64,
    "time": 52861.352404,
    "actor_loss": -58.227874755859375,
    "critic_loss": 28.96349334716797,
    "ent_coef": 0.08707655221223831,
    "learning_rate": 0.001
  },
  {
    "episode": 3272,
    "reward": 90.977149,
    "length": 61,
    "time": 52873.739925,
    "actor_loss": -61.659889221191406,
    "critic_loss": 4.771310806274414,
    "ent_coef": 0.09147895127534866,
    "learning_rate": 0.001
  },
  {
    "episode": 3273,
    "reward": 90.686966,
    "length": 62,
    "time": 52885.724818,
    "actor_loss": -67.62339782714844,
    "critic_loss": 5.704113006591797,
    "ent_coef": 0.09401838481426239,
    "learning_rate": 0.001
  },
  {
    "episode": 3274,
    "reward": 89.166719,
    "length": 63,
    "time": 52898.268313,
    "actor_loss": -65.285888671875,
    "critic_loss": 27.74448013305664,
    "ent_coef": 0.09699958562850952,
    "learning_rate": 0.001
  },
  {
    "episode": 3275,
    "reward": 87.288771,
    "length": 67,
    "time": 52912.155607,
    "actor_loss": -64.66570281982422,
    "critic_loss": 18.75494384765625,
    "ent_coef": 0.09409984946250916,
    "learning_rate": 0.001
  },
  {
    "episode": 3276,
    "reward": 88.761773,
    "length": 66,
    "time": 52924.79774,
    "actor_loss": -65.64680480957031,
    "critic_loss": 82.63825988769531,
    "ent_coef": 0.0909586027264595,
    "learning_rate": 0.001
  },
  {
    "episode": 3277,
    "reward": 89.092855,
    "length": 65,
    "time": 52937.036905,
    "actor_loss": -66.25780487060547,
    "critic_loss": 13.559685707092285,
    "ent_coef": 0.09474632889032364,
    "learning_rate": 0.001
  },
  {
    "episode": 3278,
    "reward": 88.123837,
    "length": 66,
    "time": 52950.537091,
    "actor_loss": -63.79753494262695,
    "critic_loss": 7.915117263793945,
    "ent_coef": 0.09679510444402695,
    "learning_rate": 0.001
  },
  {
    "episode": 3279,
    "reward": 84.78655,
    "length": 72,
    "time": 52964.181132,
    "actor_loss": -61.49169921875,
    "critic_loss": 2.8621578216552734,
    "ent_coef": 0.09422002732753754,
    "learning_rate": 0.001
  },
  {
    "episode": 3280,
    "reward": 87.114118,
    "length": 72,
    "time": 52977.201594,
    "actor_loss": -59.977386474609375,
    "critic_loss": 5.909904479980469,
    "ent_coef": 0.09748508781194687,
    "learning_rate": 0.001
  },
  {
    "episode": 3281,
    "reward": 88.287024,
    "length": 65,
    "time": 52991.156995,
    "actor_loss": -62.381004333496094,
    "critic_loss": 6.207158088684082,
    "ent_coef": 0.09833648055791855,
    "learning_rate": 0.001
  },
  {
    "episode": 3282,
    "reward": 89.66986,
    "length": 63,
    "time": 53003.283,
    "actor_loss": -64.47811126708984,
    "critic_loss": 6.29936408996582,
    "ent_coef": 0.09593091905117035,
    "learning_rate": 0.001
  },
  {
    "episode": 3283,
    "reward": 84.15456,
    "length": 72,
    "time": 53019.057706,
    "actor_loss": -63.31005096435547,
    "critic_loss": 6.127251625061035,
    "ent_coef": 0.09279486536979675,
    "learning_rate": 0.001
  },
  {
    "episode": 3284,
    "reward": 88.468595,
    "length": 65,
    "time": 53031.544174,
    "actor_loss": -60.9881591796875,
    "critic_loss": 3.0473618507385254,
    "ent_coef": 0.0939907506108284,
    "learning_rate": 0.001
  },
  {
    "episode": 3285,
    "reward": 88.871379,
    "length": 64,
    "time": 53044.131629,
    "actor_loss": -61.94537353515625,
    "critic_loss": 5.639965057373047,
    "ent_coef": 0.09293404221534729,
    "learning_rate": 0.001
  },
  {
    "episode": 3286,
    "reward": 87.356409,
    "length": 68,
    "time": 53057.267611,
    "actor_loss": -68.77107238769531,
    "critic_loss": 4.740946292877197,
    "ent_coef": 0.0898781418800354,
    "learning_rate": 0.001
  },
  {
    "episode": 3287,
    "reward": 81.7553,
    "length": 74,
    "time": 53070.542511,
    "actor_loss": -63.021820068359375,
    "critic_loss": 4.158443450927734,
    "ent_coef": 0.0849081501364708,
    "learning_rate": 0.001
  },
  {
    "episode": 3288,
    "reward": 87.931624,
    "length": 68,
    "time": 53083.216302,
    "actor_loss": -69.47541046142578,
    "critic_loss": 84.20741271972656,
    "ent_coef": 0.08157705515623093,
    "learning_rate": 0.001
  },
  {
    "episode": 3289,
    "reward": 86.897055,
    "length": 67,
    "time": 53098.789824,
    "actor_loss": -64.0000991821289,
    "critic_loss": 85.88710021972656,
    "ent_coef": 0.08182919770479202,
    "learning_rate": 0.001
  },
  {
    "episode": 3290,
    "reward": 90.786833,
    "length": 62,
    "time": 53110.124253,
    "actor_loss": -66.80526733398438,
    "critic_loss": 11.580390930175781,
    "ent_coef": 0.08111680299043655,
    "learning_rate": 0.001
  },
  {
    "episode": 3291,
    "reward": 85.564084,
    "length": 70,
    "time": 53122.194622,
    "actor_loss": -62.2997932434082,
    "critic_loss": 3.050039052963257,
    "ent_coef": 0.08044969290494919,
    "learning_rate": 0.001
  },
  {
    "episode": 3292,
    "reward": 86.685167,
    "length": 68,
    "time": 53135.86355,
    "actor_loss": -61.68086242675781,
    "critic_loss": 3.154082775115967,
    "ent_coef": 0.08302655071020126,
    "learning_rate": 0.001
  },
  {
    "episode": 3293,
    "reward": 68.493156,
    "length": 93,
    "time": 53153.902854,
    "actor_loss": -62.35454559326172,
    "critic_loss": 4.401811599731445,
    "ent_coef": 0.08737146109342575,
    "learning_rate": 0.001
  },
  {
    "episode": 3294,
    "reward": 86.068881,
    "length": 68,
    "time": 53168.473179,
    "actor_loss": -66.8272705078125,
    "critic_loss": 4.546604156494141,
    "ent_coef": 0.08464928716421127,
    "learning_rate": 0.001
  },
  {
    "episode": 3295,
    "reward": 88.001953,
    "length": 67,
    "time": 53180.60038,
    "actor_loss": -69.85564422607422,
    "critic_loss": 8.95846939086914,
    "ent_coef": 0.08175359666347504,
    "learning_rate": 0.001
  },
  {
    "episode": 3296,
    "reward": 90.162802,
    "length": 63,
    "time": 53191.606462,
    "actor_loss": -64.4110107421875,
    "critic_loss": 27.082355499267578,
    "ent_coef": 0.08386368304491043,
    "learning_rate": 0.001
  },
  {
    "episode": 3297,
    "reward": 89.566735,
    "length": 64,
    "time": 53205.718085,
    "actor_loss": -69.20924377441406,
    "critic_loss": 56.42017364501953,
    "ent_coef": 0.08573169261217117,
    "learning_rate": 0.001
  },
  {
    "episode": 3298,
    "reward": 84.363616,
    "length": 72,
    "time": 53218.31516,
    "actor_loss": -60.619293212890625,
    "critic_loss": 4.441138744354248,
    "ent_coef": 0.0859944224357605,
    "learning_rate": 0.001
  },
  {
    "episode": 3299,
    "reward": 90.403638,
    "length": 62,
    "time": 53229.693357,
    "actor_loss": -69.35488891601562,
    "critic_loss": 27.160411834716797,
    "ent_coef": 0.08651074767112732,
    "learning_rate": 0.001
  },
  {
    "episode": 3300,
    "reward": 89.158876,
    "length": 67,
    "time": 53243.613949,
    "actor_loss": -62.5454216003418,
    "critic_loss": 175.06622314453125,
    "ent_coef": 0.08480926603078842,
    "learning_rate": 0.001
  },
  {
    "episode": 3301,
    "reward": 89.966072,
    "length": 63,
    "time": 53255.012059,
    "actor_loss": -60.85471725463867,
    "critic_loss": 4.514266014099121,
    "ent_coef": 0.08758273720741272,
    "learning_rate": 0.001
  },
  {
    "episode": 3302,
    "reward": 83.741126,
    "length": 72,
    "time": 53267.979496,
    "actor_loss": -67.22862243652344,
    "critic_loss": 14.103056907653809,
    "ent_coef": 0.08859221637248993,
    "learning_rate": 0.001
  },
  {
    "episode": 3303,
    "reward": 87.112214,
    "length": 67,
    "time": 53281.00309,
    "actor_loss": -62.66248321533203,
    "critic_loss": 8.034268379211426,
    "ent_coef": 0.08680350333452225,
    "learning_rate": 0.001
  },
  {
    "episode": 3304,
    "reward": 85.705263,
    "length": 69,
    "time": 53293.226547,
    "actor_loss": -64.10891723632812,
    "critic_loss": 4.242236137390137,
    "ent_coef": 0.08745389431715012,
    "learning_rate": 0.001
  },
  {
    "episode": 3305,
    "reward": 89.680064,
    "length": 64,
    "time": 53305.483688,
    "actor_loss": -67.8844985961914,
    "critic_loss": 24.995220184326172,
    "ent_coef": 0.08999809622764587,
    "learning_rate": 0.001
  },
  {
    "episode": 3306,
    "reward": 89.095504,
    "length": 65,
    "time": 53318.762243,
    "actor_loss": -59.99092102050781,
    "critic_loss": 2.898303747177124,
    "ent_coef": 0.09115109592676163,
    "learning_rate": 0.001
  },
  {
    "episode": 3307,
    "reward": 88.512137,
    "length": 65,
    "time": 53329.995025,
    "actor_loss": -68.3188247680664,
    "critic_loss": 126.76252746582031,
    "ent_coef": 0.09068489819765091,
    "learning_rate": 0.001
  },
  {
    "episode": 3308,
    "reward": 83.144645,
    "length": 73,
    "time": 53343.647622,
    "actor_loss": -65.86785125732422,
    "critic_loss": 2.8669495582580566,
    "ent_coef": 0.08828670531511307,
    "learning_rate": 0.001
  },
  {
    "episode": 3309,
    "reward": 88.53613,
    "length": 66,
    "time": 53355.204263,
    "actor_loss": -62.874942779541016,
    "critic_loss": 5.649013042449951,
    "ent_coef": 0.08485399931669235,
    "learning_rate": 0.001
  },
  {
    "episode": 3310,
    "reward": 87.933281,
    "length": 67,
    "time": 53367.933896,
    "actor_loss": -65.71475219726562,
    "critic_loss": 3.763300895690918,
    "ent_coef": 0.08325310051441193,
    "learning_rate": 0.001
  },
  {
    "episode": 3311,
    "reward": 86.44564,
    "length": 69,
    "time": 53381.737895,
    "actor_loss": -58.388153076171875,
    "critic_loss": 135.96241760253906,
    "ent_coef": 0.07897783070802689,
    "learning_rate": 0.001
  },
  {
    "episode": 3312,
    "reward": 90.333673,
    "length": 61,
    "time": 53392.898711,
    "actor_loss": -64.54706573486328,
    "critic_loss": 14.322993278503418,
    "ent_coef": 0.08122780919075012,
    "learning_rate": 0.001
  },
  {
    "episode": 3313,
    "reward": 88.274781,
    "length": 66,
    "time": 53405.527459,
    "actor_loss": -64.58943939208984,
    "critic_loss": 2.857977867126465,
    "ent_coef": 0.08070117980241776,
    "learning_rate": 0.001
  },
  {
    "episode": 3314,
    "reward": 85.740825,
    "length": 72,
    "time": 53417.925668,
    "actor_loss": -62.592254638671875,
    "critic_loss": 13.666688919067383,
    "ent_coef": 0.07627129554748535,
    "learning_rate": 0.001
  },
  {
    "episode": 3315,
    "reward": 84.633575,
    "length": 71,
    "time": 53432.910635,
    "actor_loss": -65.98666381835938,
    "critic_loss": 3.3316755294799805,
    "ent_coef": 0.07637794315814972,
    "learning_rate": 0.001
  },
  {
    "episode": 3316,
    "reward": 88.486753,
    "length": 66,
    "time": 53444.834318,
    "actor_loss": -69.62005615234375,
    "critic_loss": 7.169110298156738,
    "ent_coef": 0.07691505551338196,
    "learning_rate": 0.001
  },
  {
    "episode": 3317,
    "reward": 88.756168,
    "length": 65,
    "time": 53457.807016,
    "actor_loss": -57.96977233886719,
    "critic_loss": 4.542228698730469,
    "ent_coef": 0.08129310607910156,
    "learning_rate": 0.001
  },
  {
    "episode": 3318,
    "reward": 84.643697,
    "length": 71,
    "time": 53470.350717,
    "actor_loss": -63.0651969909668,
    "critic_loss": 3.5537099838256836,
    "ent_coef": 0.07989653199911118,
    "learning_rate": 0.001
  },
  {
    "episode": 3319,
    "reward": 89.624708,
    "length": 63,
    "time": 53482.038691,
    "actor_loss": -57.945457458496094,
    "critic_loss": 5.290289878845215,
    "ent_coef": 0.07878108322620392,
    "learning_rate": 0.001
  },
  {
    "episode": 3320,
    "reward": 89.083872,
    "length": 65,
    "time": 53493.966497,
    "actor_loss": -66.63638305664062,
    "critic_loss": 24.604190826416016,
    "ent_coef": 0.08014596253633499,
    "learning_rate": 0.001
  },
  {
    "episode": 3321,
    "reward": 88.849415,
    "length": 65,
    "time": 53506.576764,
    "actor_loss": -67.6988525390625,
    "critic_loss": 1.9705451726913452,
    "ent_coef": 0.07954611629247665,
    "learning_rate": 0.001
  },
  {
    "episode": 3322,
    "reward": 90.322005,
    "length": 63,
    "time": 53518.210979,
    "actor_loss": -67.29131317138672,
    "critic_loss": 52.128536224365234,
    "ent_coef": 0.08237792551517487,
    "learning_rate": 0.001
  },
  {
    "episode": 3323,
    "reward": 90.314386,
    "length": 62,
    "time": 53533.863551,
    "actor_loss": -65.59986114501953,
    "critic_loss": 22.826505661010742,
    "ent_coef": 0.08661108464002609,
    "learning_rate": 0.001
  },
  {
    "episode": 3324,
    "reward": 88.957359,
    "length": 65,
    "time": 53546.371089,
    "actor_loss": -63.98102569580078,
    "critic_loss": 4.470142364501953,
    "ent_coef": 0.08575327694416046,
    "learning_rate": 0.001
  },
  {
    "episode": 3325,
    "reward": 87.036154,
    "length": 69,
    "time": 53558.710121,
    "actor_loss": -68.25959777832031,
    "critic_loss": 3.2852725982666016,
    "ent_coef": 0.08156619966030121,
    "learning_rate": 0.001
  },
  {
    "episode": 3326,
    "reward": 80.934461,
    "length": 80,
    "time": 53573.148154,
    "actor_loss": -62.32671356201172,
    "critic_loss": 73.54301452636719,
    "ent_coef": 0.07865588366985321,
    "learning_rate": 0.001
  },
  {
    "episode": 3327,
    "reward": 89.016776,
    "length": 65,
    "time": 53584.934434,
    "actor_loss": -61.6358757019043,
    "critic_loss": 2.9958715438842773,
    "ent_coef": 0.07956242561340332,
    "learning_rate": 0.001
  },
  {
    "episode": 3328,
    "reward": 90.847985,
    "length": 62,
    "time": 53597.709494,
    "actor_loss": -62.609832763671875,
    "critic_loss": 4.024742603302002,
    "ent_coef": 0.08208929002285004,
    "learning_rate": 0.001
  },
  {
    "episode": 3329,
    "reward": 87.039373,
    "length": 67,
    "time": 53610.283638,
    "actor_loss": -63.28677749633789,
    "critic_loss": 3.2624783515930176,
    "ent_coef": 0.08718541264533997,
    "learning_rate": 0.001
  },
  {
    "episode": 3330,
    "reward": 89.467392,
    "length": 64,
    "time": 53622.465237,
    "actor_loss": -63.895774841308594,
    "critic_loss": 37.39405059814453,
    "ent_coef": 0.08877784013748169,
    "learning_rate": 0.001
  },
  {
    "episode": 3331,
    "reward": 90.177471,
    "length": 61,
    "time": 53633.952551,
    "actor_loss": -59.915260314941406,
    "critic_loss": 5.241238594055176,
    "ent_coef": 0.09375328570604324,
    "learning_rate": 0.001
  },
  {
    "episode": 3332,
    "reward": 88.798536,
    "length": 66,
    "time": 53648.686468,
    "actor_loss": -65.66230773925781,
    "critic_loss": 37.50585174560547,
    "ent_coef": 0.09455548226833344,
    "learning_rate": 0.001
  },
  {
    "episode": 3333,
    "reward": 87.143549,
    "length": 68,
    "time": 53661.180999,
    "actor_loss": -62.154144287109375,
    "critic_loss": 10.613709449768066,
    "ent_coef": 0.09278248250484467,
    "learning_rate": 0.001
  },
  {
    "episode": 3334,
    "reward": 86.512417,
    "length": 67,
    "time": 53675.449661,
    "actor_loss": -67.39700317382812,
    "critic_loss": 4.1508378982543945,
    "ent_coef": 0.09178011864423752,
    "learning_rate": 0.001
  },
  {
    "episode": 3335,
    "reward": 88.939442,
    "length": 65,
    "time": 53686.852235,
    "actor_loss": -64.96707916259766,
    "critic_loss": 2.3566226959228516,
    "ent_coef": 0.09639780968427658,
    "learning_rate": 0.001
  },
  {
    "episode": 3336,
    "reward": 86.788222,
    "length": 68,
    "time": 53698.625121,
    "actor_loss": -63.64971160888672,
    "critic_loss": 5.253478050231934,
    "ent_coef": 0.09925089031457901,
    "learning_rate": 0.001
  },
  {
    "episode": 3337,
    "reward": 85.761634,
    "length": 69,
    "time": 53711.522722,
    "actor_loss": -64.63465118408203,
    "critic_loss": 2.5727944374084473,
    "ent_coef": 0.09925815463066101,
    "learning_rate": 0.001
  },
  {
    "episode": 3338,
    "reward": 90.335925,
    "length": 62,
    "time": 53722.612998,
    "actor_loss": -60.253173828125,
    "critic_loss": 3.8683319091796875,
    "ent_coef": 0.09638103097677231,
    "learning_rate": 0.001
  },
  {
    "episode": 3339,
    "reward": 88.844274,
    "length": 66,
    "time": 53738.649268,
    "actor_loss": -68.60432434082031,
    "critic_loss": 2.358478307723999,
    "ent_coef": 0.09399125725030899,
    "learning_rate": 0.001
  },
  {
    "episode": 3340,
    "reward": 89.446142,
    "length": 63,
    "time": 53749.936205,
    "actor_loss": -64.93231201171875,
    "critic_loss": 3.693199872970581,
    "ent_coef": 0.09188254177570343,
    "learning_rate": 0.001
  },
  {
    "episode": 3341,
    "reward": 87.827241,
    "length": 67,
    "time": 53762.768479,
    "actor_loss": -61.4265251159668,
    "critic_loss": 2.9242501258850098,
    "ent_coef": 0.0867588147521019,
    "learning_rate": 0.001
  },
  {
    "episode": 3342,
    "reward": 90.592494,
    "length": 62,
    "time": 53777.019721,
    "actor_loss": -71.6231918334961,
    "critic_loss": 2.523167848587036,
    "ent_coef": 0.08773975819349289,
    "learning_rate": 0.001
  },
  {
    "episode": 3343,
    "reward": 91.080684,
    "length": 61,
    "time": 53789.970017,
    "actor_loss": -63.212493896484375,
    "critic_loss": 4.522121906280518,
    "ent_coef": 0.09193561226129532,
    "learning_rate": 0.001
  },
  {
    "episode": 3344,
    "reward": 85.971305,
    "length": 76,
    "time": 53803.074611,
    "actor_loss": -67.47241973876953,
    "critic_loss": 3.4824347496032715,
    "ent_coef": 0.09443214535713196,
    "learning_rate": 0.001
  },
  {
    "episode": 3345,
    "reward": 88.403201,
    "length": 66,
    "time": 53815.105608,
    "actor_loss": -68.84709167480469,
    "critic_loss": 3.8016533851623535,
    "ent_coef": 0.0948365330696106,
    "learning_rate": 0.001
  },
  {
    "episode": 3346,
    "reward": 88.876545,
    "length": 64,
    "time": 53827.28551,
    "actor_loss": -60.310325622558594,
    "critic_loss": 15.444565773010254,
    "ent_coef": 0.09490595012903214,
    "learning_rate": 0.001
  },
  {
    "episode": 3347,
    "reward": 89.846854,
    "length": 63,
    "time": 53838.579531,
    "actor_loss": -67.73356628417969,
    "critic_loss": 96.43319702148438,
    "ent_coef": 0.09423819929361343,
    "learning_rate": 0.001
  },
  {
    "episode": 3348,
    "reward": 87.701262,
    "length": 67,
    "time": 53852.747204,
    "actor_loss": -57.34174346923828,
    "critic_loss": 2.6727843284606934,
    "ent_coef": 0.09377197176218033,
    "learning_rate": 0.001
  },
  {
    "episode": 3349,
    "reward": 88.239023,
    "length": 65,
    "time": 53866.489263,
    "actor_loss": -65.7979507446289,
    "critic_loss": 2.9329326152801514,
    "ent_coef": 0.09325974434614182,
    "learning_rate": 0.001
  },
  {
    "episode": 3350,
    "reward": 82.530471,
    "length": 75,
    "time": 53882.552532,
    "actor_loss": -61.52202606201172,
    "critic_loss": 3.147059440612793,
    "ent_coef": 0.08890796452760696,
    "learning_rate": 0.001
  },
  {
    "episode": 3351,
    "reward": 85.953652,
    "length": 70,
    "time": 53896.942498,
    "actor_loss": -68.71162414550781,
    "critic_loss": 2.615690231323242,
    "ent_coef": 0.08407466113567352,
    "learning_rate": 0.001
  },
  {
    "episode": 3352,
    "reward": 87.669794,
    "length": 67,
    "time": 53908.61421,
    "actor_loss": -58.031646728515625,
    "critic_loss": 7.243170738220215,
    "ent_coef": 0.08506770431995392,
    "learning_rate": 0.001
  },
  {
    "episode": 3353,
    "reward": 90.573555,
    "length": 63,
    "time": 53919.782048,
    "actor_loss": -64.31979370117188,
    "critic_loss": 60.23027038574219,
    "ent_coef": 0.08944310247898102,
    "learning_rate": 0.001
  },
  {
    "episode": 3354,
    "reward": 87.298007,
    "length": 69,
    "time": 53933.920239,
    "actor_loss": -62.296974182128906,
    "critic_loss": 2.0952706336975098,
    "ent_coef": 0.08655210584402084,
    "learning_rate": 0.001
  },
  {
    "episode": 3355,
    "reward": 90.502597,
    "length": 62,
    "time": 53946.112962,
    "actor_loss": -53.64872741699219,
    "critic_loss": 9.136789321899414,
    "ent_coef": 0.08895252645015717,
    "learning_rate": 0.001
  },
  {
    "episode": 3356,
    "reward": 87.479791,
    "length": 67,
    "time": 53960.644942,
    "actor_loss": -62.308433532714844,
    "critic_loss": 10.832518577575684,
    "ent_coef": 0.08840180933475494,
    "learning_rate": 0.001
  },
  {
    "episode": 3357,
    "reward": 85.309168,
    "length": 70,
    "time": 53972.887487,
    "actor_loss": -61.08262252807617,
    "critic_loss": 2.2709717750549316,
    "ent_coef": 0.08686060458421707,
    "learning_rate": 0.001
  },
  {
    "episode": 3358,
    "reward": 86.615954,
    "length": 70,
    "time": 53984.750667,
    "actor_loss": -63.46453857421875,
    "critic_loss": 4.942046165466309,
    "ent_coef": 0.08421716094017029,
    "learning_rate": 0.001
  },
  {
    "episode": 3359,
    "reward": 86.752975,
    "length": 69,
    "time": 53996.90203,
    "actor_loss": -65.77760314941406,
    "critic_loss": 55.68834686279297,
    "ent_coef": 0.0811142697930336,
    "learning_rate": 0.001
  },
  {
    "episode": 3360,
    "reward": 87.289261,
    "length": 68,
    "time": 54011.750026,
    "actor_loss": -66.1720199584961,
    "critic_loss": 149.88507080078125,
    "ent_coef": 0.07755707204341888,
    "learning_rate": 0.001
  },
  {
    "episode": 3361,
    "reward": 85.689719,
    "length": 69,
    "time": 54024.030401,
    "actor_loss": -68.34796905517578,
    "critic_loss": 3.5237789154052734,
    "ent_coef": 0.0753619521856308,
    "learning_rate": 0.001
  },
  {
    "episode": 3362,
    "reward": 88.823216,
    "length": 64,
    "time": 54036.34393,
    "actor_loss": -64.67327117919922,
    "critic_loss": 2.489068031311035,
    "ent_coef": 0.07770528644323349,
    "learning_rate": 0.001
  },
  {
    "episode": 3363,
    "reward": 86.02174,
    "length": 70,
    "time": 54049.452607,
    "actor_loss": -59.09231948852539,
    "critic_loss": 2.012239933013916,
    "ent_coef": 0.07721461355686188,
    "learning_rate": 0.001
  },
  {
    "episode": 3364,
    "reward": 89.116535,
    "length": 64,
    "time": 54062.36079,
    "actor_loss": -62.91156768798828,
    "critic_loss": 36.086456298828125,
    "ent_coef": 0.07801021635532379,
    "learning_rate": 0.001
  },
  {
    "episode": 3365,
    "reward": 88.945972,
    "length": 65,
    "time": 54073.880768,
    "actor_loss": -59.119571685791016,
    "critic_loss": 33.35582733154297,
    "ent_coef": 0.07941701263189316,
    "learning_rate": 0.001
  },
  {
    "episode": 3366,
    "reward": 90.25235,
    "length": 62,
    "time": 54085.790585,
    "actor_loss": -61.41570281982422,
    "critic_loss": 145.1853485107422,
    "ent_coef": 0.08017809689044952,
    "learning_rate": 0.001
  },
  {
    "episode": 3367,
    "reward": 87.758741,
    "length": 68,
    "time": 54097.724912,
    "actor_loss": -58.15141296386719,
    "critic_loss": 35.661964416503906,
    "ent_coef": 0.07919100672006607,
    "learning_rate": 0.001
  },
  {
    "episode": 3368,
    "reward": 89.530206,
    "length": 63,
    "time": 54109.435431,
    "actor_loss": -63.81767272949219,
    "critic_loss": 5.330716133117676,
    "ent_coef": 0.08152113854885101,
    "learning_rate": 0.001
  },
  {
    "episode": 3369,
    "reward": 89.527526,
    "length": 63,
    "time": 54121.996489,
    "actor_loss": -69.1143798828125,
    "critic_loss": 177.0263671875,
    "ent_coef": 0.08748279511928558,
    "learning_rate": 0.001
  },
  {
    "episode": 3370,
    "reward": 89.734799,
    "length": 63,
    "time": 54135.844936,
    "actor_loss": -66.81167602539062,
    "critic_loss": 4.85189151763916,
    "ent_coef": 0.09059357643127441,
    "learning_rate": 0.001
  },
  {
    "episode": 3371,
    "reward": 90.017134,
    "length": 63,
    "time": 54147.013555,
    "actor_loss": -58.05897521972656,
    "critic_loss": 8.18637752532959,
    "ent_coef": 0.09280529618263245,
    "learning_rate": 0.001
  },
  {
    "episode": 3372,
    "reward": 86.596854,
    "length": 68,
    "time": 54161.264019,
    "actor_loss": -64.67355346679688,
    "critic_loss": 3.838163137435913,
    "ent_coef": 0.092075414955616,
    "learning_rate": 0.001
  },
  {
    "episode": 3373,
    "reward": 89.404729,
    "length": 65,
    "time": 54172.629581,
    "actor_loss": -62.98211669921875,
    "critic_loss": 8.567081451416016,
    "ent_coef": 0.09091155230998993,
    "learning_rate": 0.001
  },
  {
    "episode": 3374,
    "reward": 83.152806,
    "length": 75,
    "time": 54187.99397,
    "actor_loss": -59.48819351196289,
    "critic_loss": 8.159270286560059,
    "ent_coef": 0.08608470112085342,
    "learning_rate": 0.001
  },
  {
    "episode": 3375,
    "reward": 86.797414,
    "length": 69,
    "time": 54199.869637,
    "actor_loss": -66.76995849609375,
    "critic_loss": 3.132082462310791,
    "ent_coef": 0.08184012770652771,
    "learning_rate": 0.001
  },
  {
    "episode": 3376,
    "reward": 84.35863,
    "length": 71,
    "time": 54213.041975,
    "actor_loss": -62.25038528442383,
    "critic_loss": 6.336688041687012,
    "ent_coef": 0.08255348354578018,
    "learning_rate": 0.001
  },
  {
    "episode": 3377,
    "reward": 89.163177,
    "length": 65,
    "time": 54225.441764,
    "actor_loss": -63.211448669433594,
    "critic_loss": 5.213140487670898,
    "ent_coef": 0.08478878438472748,
    "learning_rate": 0.001
  },
  {
    "episode": 3378,
    "reward": 90.133203,
    "length": 63,
    "time": 54236.634629,
    "actor_loss": -62.504005432128906,
    "critic_loss": 6.276862144470215,
    "ent_coef": 0.0915648341178894,
    "learning_rate": 0.001
  },
  {
    "episode": 3379,
    "reward": 87.941288,
    "length": 66,
    "time": 54248.411044,
    "actor_loss": -64.06666564941406,
    "critic_loss": 15.688163757324219,
    "ent_coef": 0.09054151922464371,
    "learning_rate": 0.001
  },
  {
    "episode": 3380,
    "reward": 83.364147,
    "length": 74,
    "time": 54261.567934,
    "actor_loss": -66.69210052490234,
    "critic_loss": 82.00379943847656,
    "ent_coef": 0.08710543811321259,
    "learning_rate": 0.001
  },
  {
    "episode": 3381,
    "reward": 89.577313,
    "length": 64,
    "time": 54274.735229,
    "actor_loss": -63.55172348022461,
    "critic_loss": 105.59014892578125,
    "ent_coef": 0.08591359853744507,
    "learning_rate": 0.001
  },
  {
    "episode": 3382,
    "reward": 86.09156,
    "length": 69,
    "time": 54287.500873,
    "actor_loss": -66.19708251953125,
    "critic_loss": 4.6913604736328125,
    "ent_coef": 0.08356844633817673,
    "learning_rate": 0.001
  },
  {
    "episode": 3383,
    "reward": 85.651572,
    "length": 71,
    "time": 54299.530193,
    "actor_loss": -66.01580047607422,
    "critic_loss": 4.399072647094727,
    "ent_coef": 0.0801168903708458,
    "learning_rate": 0.001
  },
  {
    "episode": 3384,
    "reward": 89.369282,
    "length": 63,
    "time": 54312.307693,
    "actor_loss": -71.11394500732422,
    "critic_loss": 12.376729965209961,
    "ent_coef": 0.08345340192317963,
    "learning_rate": 0.001
  },
  {
    "episode": 3385,
    "reward": 89.327172,
    "length": 64,
    "time": 54324.516362,
    "actor_loss": -62.39889907836914,
    "critic_loss": 48.81156921386719,
    "ent_coef": 0.08579971641302109,
    "learning_rate": 0.001
  },
  {
    "episode": 3386,
    "reward": 90.544312,
    "length": 62,
    "time": 54337.87591,
    "actor_loss": -57.6636962890625,
    "critic_loss": 3.1185266971588135,
    "ent_coef": 0.08621915429830551,
    "learning_rate": 0.001
  },
  {
    "episode": 3387,
    "reward": 88.889473,
    "length": 66,
    "time": 54350.268495,
    "actor_loss": -70.43193054199219,
    "critic_loss": 8.056367874145508,
    "ent_coef": 0.08708512783050537,
    "learning_rate": 0.001
  },
  {
    "episode": 3388,
    "reward": 87.48559,
    "length": 68,
    "time": 54362.908411,
    "actor_loss": -63.117698669433594,
    "critic_loss": 1.7704131603240967,
    "ent_coef": 0.0882771909236908,
    "learning_rate": 0.001
  },
  {
    "episode": 3389,
    "reward": 89.250373,
    "length": 63,
    "time": 54376.982362,
    "actor_loss": -62.13265609741211,
    "critic_loss": 5.487862586975098,
    "ent_coef": 0.09051838517189026,
    "learning_rate": 0.001
  },
  {
    "episode": 3390,
    "reward": 89.354322,
    "length": 64,
    "time": 54388.408047,
    "actor_loss": -71.29971313476562,
    "critic_loss": 19.992658615112305,
    "ent_coef": 0.09266144782304764,
    "learning_rate": 0.001
  },
  {
    "episode": 3391,
    "reward": 89.791107,
    "length": 63,
    "time": 54399.755237,
    "actor_loss": -66.16332244873047,
    "critic_loss": 4.782507419586182,
    "ent_coef": 0.09243600070476532,
    "learning_rate": 0.001
  },
  {
    "episode": 3392,
    "reward": 89.868511,
    "length": 63,
    "time": 54413.222991,
    "actor_loss": -64.19696807861328,
    "critic_loss": 2.5449647903442383,
    "ent_coef": 0.09427891671657562,
    "learning_rate": 0.001
  },
  {
    "episode": 3393,
    "reward": 89.616521,
    "length": 64,
    "time": 54427.856182,
    "actor_loss": -64.42960357666016,
    "critic_loss": 3.3571677207946777,
    "ent_coef": 0.09505286812782288,
    "learning_rate": 0.001
  },
  {
    "episode": 3394,
    "reward": 87.549583,
    "length": 67,
    "time": 54443.544234,
    "actor_loss": -67.33878326416016,
    "critic_loss": 40.623069763183594,
    "ent_coef": 0.09175889939069748,
    "learning_rate": 0.001
  },
  {
    "episode": 3395,
    "reward": 88.617604,
    "length": 65,
    "time": 54455.949757,
    "actor_loss": -67.76031494140625,
    "critic_loss": 1.4755008220672607,
    "ent_coef": 0.09114907681941986,
    "learning_rate": 0.001
  },
  {
    "episode": 3396,
    "reward": 89.611232,
    "length": 63,
    "time": 54469.242218,
    "actor_loss": -63.89185333251953,
    "critic_loss": 5.48068904876709,
    "ent_coef": 0.08789534121751785,
    "learning_rate": 0.001
  },
  {
    "episode": 3397,
    "reward": 90.113382,
    "length": 63,
    "time": 54480.523808,
    "actor_loss": -66.4163818359375,
    "critic_loss": 11.117788314819336,
    "ent_coef": 0.08323987573385239,
    "learning_rate": 0.001
  },
  {
    "episode": 3398,
    "reward": 85.72926,
    "length": 70,
    "time": 54493.218875,
    "actor_loss": -66.3256607055664,
    "critic_loss": 13.834178924560547,
    "ent_coef": 0.08093071728944778,
    "learning_rate": 0.001
  },
  {
    "episode": 3399,
    "reward": 88.436054,
    "length": 67,
    "time": 54509.074368,
    "actor_loss": -61.716285705566406,
    "critic_loss": 17.993595123291016,
    "ent_coef": 0.0786256194114685,
    "learning_rate": 0.001
  },
  {
    "episode": 3400,
    "reward": 83.221137,
    "length": 74,
    "time": 54525.53881,
    "actor_loss": -64.12332153320312,
    "critic_loss": 2.7157464027404785,
    "ent_coef": 0.07335849851369858,
    "learning_rate": 0.001
  },
  {
    "episode": 3401,
    "reward": 85.032471,
    "length": 71,
    "time": 54537.931952,
    "actor_loss": -61.81813049316406,
    "critic_loss": 41.067840576171875,
    "ent_coef": 0.07085584104061127,
    "learning_rate": 0.001
  },
  {
    "episode": 3402,
    "reward": 88.861663,
    "length": 65,
    "time": 54549.433948,
    "actor_loss": -65.73550415039062,
    "critic_loss": 2.5539188385009766,
    "ent_coef": 0.06866361945867538,
    "learning_rate": 0.001
  },
  {
    "episode": 3403,
    "reward": 71.609515,
    "length": 93,
    "time": 54564.616233,
    "actor_loss": -66.32014465332031,
    "critic_loss": 6.016325950622559,
    "ent_coef": 0.06655952334403992,
    "learning_rate": 0.001
  },
  {
    "episode": 3404,
    "reward": 89.056851,
    "length": 65,
    "time": 54578.288689,
    "actor_loss": -68.39155578613281,
    "critic_loss": 8.573173522949219,
    "ent_coef": 0.07053887844085693,
    "learning_rate": 0.001
  },
  {
    "episode": 3405,
    "reward": 88.763759,
    "length": 65,
    "time": 54589.854394,
    "actor_loss": -69.52407836914062,
    "critic_loss": 26.313278198242188,
    "ent_coef": 0.07287365943193436,
    "learning_rate": 0.001
  },
  {
    "episode": 3406,
    "reward": 80.722141,
    "length": 80,
    "time": 54605.905791,
    "actor_loss": -60.34441375732422,
    "critic_loss": 11.655776977539062,
    "ent_coef": 0.07157515734434128,
    "learning_rate": 0.001
  },
  {
    "episode": 3407,
    "reward": 62.514985,
    "length": 113,
    "time": 54623.512196,
    "actor_loss": -67.06559753417969,
    "critic_loss": 4.01954984664917,
    "ent_coef": 0.0695989727973938,
    "learning_rate": 0.001
  },
  {
    "episode": 3408,
    "reward": -208.139514,
    "length": 224,
    "time": 54655.631666,
    "actor_loss": -59.87848663330078,
    "critic_loss": 7.517776012420654,
    "ent_coef": 0.11204435676336288,
    "learning_rate": 0.001
  },
  {
    "episode": 3409,
    "reward": -118.580671,
    "length": 437,
    "time": 54716.724999,
    "actor_loss": -64.11476135253906,
    "critic_loss": 2.3881301879882812,
    "ent_coef": 0.1536603420972824,
    "learning_rate": 0.001
  },
  {
    "episode": 3410,
    "reward": 81.89825,
    "length": 84,
    "time": 54731.600769,
    "actor_loss": -69.68186950683594,
    "critic_loss": 4.680996894836426,
    "ent_coef": 0.14723432064056396,
    "learning_rate": 0.001
  },
  {
    "episode": 3411,
    "reward": 84.358777,
    "length": 72,
    "time": 54745.566626,
    "actor_loss": -60.77820587158203,
    "critic_loss": 15.629237174987793,
    "ent_coef": 0.1428142637014389,
    "learning_rate": 0.001
  },
  {
    "episode": 3412,
    "reward": 79.869102,
    "length": 85,
    "time": 54762.531972,
    "actor_loss": -61.03026580810547,
    "critic_loss": 4.053186416625977,
    "ent_coef": 0.13702385127544403,
    "learning_rate": 0.001
  },
  {
    "episode": 3413,
    "reward": 81.05303,
    "length": 76,
    "time": 54776.055181,
    "actor_loss": -63.284053802490234,
    "critic_loss": 19.048192977905273,
    "ent_coef": 0.13207662105560303,
    "learning_rate": 0.001
  },
  {
    "episode": 3414,
    "reward": 86.931536,
    "length": 73,
    "time": 54790.4643,
    "actor_loss": -66.33992004394531,
    "critic_loss": 7.229130268096924,
    "ent_coef": 0.1292302906513214,
    "learning_rate": 0.001
  },
  {
    "episode": 3415,
    "reward": 87.241718,
    "length": 67,
    "time": 54803.812352,
    "actor_loss": -68.866455078125,
    "critic_loss": 45.885223388671875,
    "ent_coef": 0.12573157250881195,
    "learning_rate": 0.001
  },
  {
    "episode": 3416,
    "reward": 83.877057,
    "length": 77,
    "time": 54817.597183,
    "actor_loss": -58.42303466796875,
    "critic_loss": 3.799147844314575,
    "ent_coef": 0.12070953100919724,
    "learning_rate": 0.001
  },
  {
    "episode": 3417,
    "reward": 81.6259,
    "length": 77,
    "time": 54831.700113,
    "actor_loss": -63.11985778808594,
    "critic_loss": 1.9659552574157715,
    "ent_coef": 0.11476892977952957,
    "learning_rate": 0.001
  },
  {
    "episode": 3418,
    "reward": 90.345548,
    "length": 63,
    "time": 54845.266618,
    "actor_loss": -61.791839599609375,
    "critic_loss": 2.121826171875,
    "ent_coef": 0.11197308450937271,
    "learning_rate": 0.001
  },
  {
    "episode": 3419,
    "reward": 84.434361,
    "length": 72,
    "time": 54857.567905,
    "actor_loss": -58.787967681884766,
    "critic_loss": 14.320487022399902,
    "ent_coef": 0.10747750103473663,
    "learning_rate": 0.001
  },
  {
    "episode": 3420,
    "reward": 89.263094,
    "length": 63,
    "time": 54868.948468,
    "actor_loss": -64.50023651123047,
    "critic_loss": 2.238863945007324,
    "ent_coef": 0.10562559962272644,
    "learning_rate": 0.001
  },
  {
    "episode": 3421,
    "reward": 85.049466,
    "length": 73,
    "time": 54883.801589,
    "actor_loss": -69.31572723388672,
    "critic_loss": 62.517738342285156,
    "ent_coef": 0.10189078003168106,
    "learning_rate": 0.001
  },
  {
    "episode": 3422,
    "reward": 81.220846,
    "length": 76,
    "time": 54899.016898,
    "actor_loss": -68.24030303955078,
    "critic_loss": 10.757678985595703,
    "ent_coef": 0.0977398231625557,
    "learning_rate": 0.001
  },
  {
    "episode": 3423,
    "reward": 77.551855,
    "length": 92,
    "time": 54914.97578,
    "actor_loss": -61.945716857910156,
    "critic_loss": 3.2563395500183105,
    "ent_coef": 0.0948919877409935,
    "learning_rate": 0.001
  },
  {
    "episode": 3424,
    "reward": 88.553962,
    "length": 65,
    "time": 54929.56359,
    "actor_loss": -62.169677734375,
    "critic_loss": 1.8039209842681885,
    "ent_coef": 0.09472548961639404,
    "learning_rate": 0.001
  },
  {
    "episode": 3425,
    "reward": 88.974693,
    "length": 64,
    "time": 54942.400551,
    "actor_loss": -64.05907440185547,
    "critic_loss": 24.831388473510742,
    "ent_coef": 0.09749630838632584,
    "learning_rate": 0.001
  },
  {
    "episode": 3426,
    "reward": 84.858753,
    "length": 73,
    "time": 54957.550978,
    "actor_loss": -67.1993408203125,
    "critic_loss": 18.08211898803711,
    "ent_coef": 0.09716510772705078,
    "learning_rate": 0.001
  },
  {
    "episode": 3427,
    "reward": 87.862261,
    "length": 65,
    "time": 54969.194997,
    "actor_loss": -60.18284606933594,
    "critic_loss": 2.2478184700012207,
    "ent_coef": 0.097617007791996,
    "learning_rate": 0.001
  },
  {
    "episode": 3428,
    "reward": 87.23764,
    "length": 72,
    "time": 54982.562259,
    "actor_loss": -63.51287841796875,
    "critic_loss": 3.08138108253479,
    "ent_coef": 0.09788748621940613,
    "learning_rate": 0.001
  },
  {
    "episode": 3429,
    "reward": 84.673081,
    "length": 71,
    "time": 54998.567631,
    "actor_loss": -65.82608032226562,
    "critic_loss": 48.08203125,
    "ent_coef": 0.09637443721294403,
    "learning_rate": 0.001
  },
  {
    "episode": 3430,
    "reward": 89.380278,
    "length": 64,
    "time": 55010.145811,
    "actor_loss": -62.081336975097656,
    "critic_loss": 7.608489036560059,
    "ent_coef": 0.09519459307193756,
    "learning_rate": 0.001
  },
  {
    "episode": 3431,
    "reward": 87.342872,
    "length": 67,
    "time": 55022.68207,
    "actor_loss": -65.03718566894531,
    "critic_loss": 9.511676788330078,
    "ent_coef": 0.09108012914657593,
    "learning_rate": 0.001
  },
  {
    "episode": 3432,
    "reward": 84.947128,
    "length": 72,
    "time": 55037.181794,
    "actor_loss": -67.36839294433594,
    "critic_loss": 3.281923770904541,
    "ent_coef": 0.08968859165906906,
    "learning_rate": 0.001
  },
  {
    "episode": 3433,
    "reward": 87.511916,
    "length": 67,
    "time": 55049.749596,
    "actor_loss": -65.22219848632812,
    "critic_loss": 5.503221035003662,
    "ent_coef": 0.0903540551662445,
    "learning_rate": 0.001
  },
  {
    "episode": 3434,
    "reward": 86.698454,
    "length": 69,
    "time": 55061.984094,
    "actor_loss": -59.88812255859375,
    "critic_loss": 5.749589920043945,
    "ent_coef": 0.09164754301309586,
    "learning_rate": 0.001
  },
  {
    "episode": 3435,
    "reward": 86.68471,
    "length": 72,
    "time": 55077.261444,
    "actor_loss": -64.83263397216797,
    "critic_loss": 8.925048828125,
    "ent_coef": 0.09291984885931015,
    "learning_rate": 0.001
  },
  {
    "episode": 3436,
    "reward": 88.723068,
    "length": 66,
    "time": 55088.881512,
    "actor_loss": -63.218658447265625,
    "critic_loss": 5.442768096923828,
    "ent_coef": 0.09329637140035629,
    "learning_rate": 0.001
  },
  {
    "episode": 3437,
    "reward": 87.048481,
    "length": 69,
    "time": 55103.746555,
    "actor_loss": -64.75614166259766,
    "critic_loss": 2.8152828216552734,
    "ent_coef": 0.09271012991666794,
    "learning_rate": 0.001
  },
  {
    "episode": 3438,
    "reward": 87.263223,
    "length": 68,
    "time": 55115.703609,
    "actor_loss": -60.651947021484375,
    "critic_loss": 29.274028778076172,
    "ent_coef": 0.09075312316417694,
    "learning_rate": 0.001
  },
  {
    "episode": 3439,
    "reward": 87.925865,
    "length": 66,
    "time": 55129.696504,
    "actor_loss": -57.15084457397461,
    "critic_loss": 11.57073974609375,
    "ent_coef": 0.0899563729763031,
    "learning_rate": 0.001
  },
  {
    "episode": 3440,
    "reward": 86.238544,
    "length": 68,
    "time": 55142.834979,
    "actor_loss": -68.54756164550781,
    "critic_loss": 8.40024185180664,
    "ent_coef": 0.09085896611213684,
    "learning_rate": 0.001
  },
  {
    "episode": 3441,
    "reward": 89.462306,
    "length": 63,
    "time": 55155.248687,
    "actor_loss": -72.68795013427734,
    "critic_loss": 3.776651382446289,
    "ent_coef": 0.0907992571592331,
    "learning_rate": 0.001
  },
  {
    "episode": 3442,
    "reward": 89.375294,
    "length": 64,
    "time": 55166.456366,
    "actor_loss": -61.05311965942383,
    "critic_loss": 50.16943359375,
    "ent_coef": 0.09090724587440491,
    "learning_rate": 0.001
  },
  {
    "episode": 3443,
    "reward": 85.915649,
    "length": 69,
    "time": 55178.387503,
    "actor_loss": -63.22257995605469,
    "critic_loss": 7.2181243896484375,
    "ent_coef": 0.08887529373168945,
    "learning_rate": 0.001
  },
  {
    "episode": 3444,
    "reward": 86.652522,
    "length": 68,
    "time": 55192.998074,
    "actor_loss": -64.9250717163086,
    "critic_loss": 2.6984691619873047,
    "ent_coef": 0.08780289441347122,
    "learning_rate": 0.001
  },
  {
    "episode": 3445,
    "reward": 83.826824,
    "length": 71,
    "time": 55205.268408,
    "actor_loss": -65.2870101928711,
    "critic_loss": 3.3095216751098633,
    "ent_coef": 0.08649985492229462,
    "learning_rate": 0.001
  },
  {
    "episode": 3446,
    "reward": 86.716719,
    "length": 68,
    "time": 55217.058005,
    "actor_loss": -59.90372085571289,
    "critic_loss": 6.881043910980225,
    "ent_coef": 0.08554423600435257,
    "learning_rate": 0.001
  },
  {
    "episode": 3447,
    "reward": 89.672697,
    "length": 63,
    "time": 55228.713976,
    "actor_loss": -59.86200714111328,
    "critic_loss": 3.9911985397338867,
    "ent_coef": 0.08591396361589432,
    "learning_rate": 0.001
  },
  {
    "episode": 3448,
    "reward": 87.998179,
    "length": 66,
    "time": 55242.665439,
    "actor_loss": -62.38239669799805,
    "critic_loss": 3.423825263977051,
    "ent_coef": 0.0855986475944519,
    "learning_rate": 0.001
  },
  {
    "episode": 3449,
    "reward": 87.306466,
    "length": 69,
    "time": 55256.887868,
    "actor_loss": -61.80363082885742,
    "critic_loss": 2.6189093589782715,
    "ent_coef": 0.08505391329526901,
    "learning_rate": 0.001
  },
  {
    "episode": 3450,
    "reward": 83.480884,
    "length": 72,
    "time": 55270.117417,
    "actor_loss": -66.30762481689453,
    "critic_loss": 2.4799325466156006,
    "ent_coef": 0.08567027002573013,
    "learning_rate": 0.001
  },
  {
    "episode": 3451,
    "reward": 89.313248,
    "length": 64,
    "time": 55281.488579,
    "actor_loss": -66.52515411376953,
    "critic_loss": 5.375441551208496,
    "ent_coef": 0.08914105594158173,
    "learning_rate": 0.001
  },
  {
    "episode": 3452,
    "reward": 90.192904,
    "length": 62,
    "time": 55293.306894,
    "actor_loss": -69.07902526855469,
    "critic_loss": 5.316786766052246,
    "ent_coef": 0.09206105768680573,
    "learning_rate": 0.001
  },
  {
    "episode": 3453,
    "reward": 88.721206,
    "length": 65,
    "time": 55304.830167,
    "actor_loss": -62.4301643371582,
    "critic_loss": 2.878085136413574,
    "ent_coef": 0.09008876979351044,
    "learning_rate": 0.001
  },
  {
    "episode": 3454,
    "reward": 86.849417,
    "length": 68,
    "time": 55316.705884,
    "actor_loss": -62.624603271484375,
    "critic_loss": 5.044169902801514,
    "ent_coef": 0.08945605158805847,
    "learning_rate": 0.001
  },
  {
    "episode": 3455,
    "reward": 88.169681,
    "length": 65,
    "time": 55331.359224,
    "actor_loss": -64.21051788330078,
    "critic_loss": 2.646575927734375,
    "ent_coef": 0.08996246010065079,
    "learning_rate": 0.001
  },
  {
    "episode": 3456,
    "reward": 88.226397,
    "length": 66,
    "time": 55345.038137,
    "actor_loss": -64.12580871582031,
    "critic_loss": 2.4308104515075684,
    "ent_coef": 0.09049716591835022,
    "learning_rate": 0.001
  },
  {
    "episode": 3457,
    "reward": 88.580788,
    "length": 65,
    "time": 55358.600058,
    "actor_loss": -68.48126220703125,
    "critic_loss": 14.578941345214844,
    "ent_coef": 0.09208257496356964,
    "learning_rate": 0.001
  },
  {
    "episode": 3458,
    "reward": 88.850975,
    "length": 65,
    "time": 55370.093895,
    "actor_loss": -67.01242065429688,
    "critic_loss": 38.769508361816406,
    "ent_coef": 0.09187270700931549,
    "learning_rate": 0.001
  },
  {
    "episode": 3459,
    "reward": 87.200029,
    "length": 68,
    "time": 55383.914128,
    "actor_loss": -66.1946029663086,
    "critic_loss": 3.2983875274658203,
    "ent_coef": 0.08898655325174332,
    "learning_rate": 0.001
  },
  {
    "episode": 3460,
    "reward": 89.804116,
    "length": 64,
    "time": 55397.129586,
    "actor_loss": -62.128387451171875,
    "critic_loss": 32.405799865722656,
    "ent_coef": 0.08867934346199036,
    "learning_rate": 0.001
  },
  {
    "episode": 3461,
    "reward": 87.456074,
    "length": 65,
    "time": 55412.779741,
    "actor_loss": -61.85894775390625,
    "critic_loss": 6.670015335083008,
    "ent_coef": 0.08855123072862625,
    "learning_rate": 0.001
  },
  {
    "episode": 3462,
    "reward": 88.579405,
    "length": 65,
    "time": 55433.215661,
    "actor_loss": -64.32662963867188,
    "critic_loss": 49.87303161621094,
    "ent_coef": 0.08969666808843613,
    "learning_rate": 0.001
  },
  {
    "episode": 3463,
    "reward": 89.929287,
    "length": 62,
    "time": 55444.100197,
    "actor_loss": -64.38337707519531,
    "critic_loss": 1.4097214937210083,
    "ent_coef": 0.09223292022943497,
    "learning_rate": 0.001
  },
  {
    "episode": 3464,
    "reward": 88.169336,
    "length": 66,
    "time": 55455.846477,
    "actor_loss": -63.01716232299805,
    "critic_loss": 2.4042716026306152,
    "ent_coef": 0.09150229394435883,
    "learning_rate": 0.001
  },
  {
    "episode": 3465,
    "reward": 85.503049,
    "length": 69,
    "time": 55468.203217,
    "actor_loss": -61.43735122680664,
    "critic_loss": 4.120538711547852,
    "ent_coef": 0.09052470326423645,
    "learning_rate": 0.001
  },
  {
    "episode": 3466,
    "reward": 86.755313,
    "length": 69,
    "time": 55482.040469,
    "actor_loss": -62.227481842041016,
    "critic_loss": 8.824321746826172,
    "ent_coef": 0.08912099152803421,
    "learning_rate": 0.001
  },
  {
    "episode": 3467,
    "reward": 86.88717,
    "length": 68,
    "time": 55494.258258,
    "actor_loss": -60.96601486206055,
    "critic_loss": 18.39498519897461,
    "ent_coef": 0.08817639946937561,
    "learning_rate": 0.001
  },
  {
    "episode": 3468,
    "reward": 90.115532,
    "length": 63,
    "time": 55506.358517,
    "actor_loss": -64.89688110351562,
    "critic_loss": 3.5659027099609375,
    "ent_coef": 0.08748775720596313,
    "learning_rate": 0.001
  },
  {
    "episode": 3469,
    "reward": 87.954352,
    "length": 67,
    "time": 55520.691536,
    "actor_loss": -61.50615692138672,
    "critic_loss": 3.504082679748535,
    "ent_coef": 0.08807121217250824,
    "learning_rate": 0.001
  },
  {
    "episode": 3470,
    "reward": 84.632084,
    "length": 72,
    "time": 55534.059827,
    "actor_loss": -67.73112487792969,
    "critic_loss": 3.8575057983398438,
    "ent_coef": 0.08853287994861603,
    "learning_rate": 0.001
  },
  {
    "episode": 3471,
    "reward": 88.543879,
    "length": 65,
    "time": 55546.769233,
    "actor_loss": -67.19043731689453,
    "critic_loss": 7.391962051391602,
    "ent_coef": 0.08755367249250412,
    "learning_rate": 0.001
  },
  {
    "episode": 3472,
    "reward": 90.087571,
    "length": 62,
    "time": 55558.939172,
    "actor_loss": -65.14417266845703,
    "critic_loss": 7.341900825500488,
    "ent_coef": 0.08651445806026459,
    "learning_rate": 0.001
  },
  {
    "episode": 3473,
    "reward": 88.084185,
    "length": 66,
    "time": 55571.369855,
    "actor_loss": -61.32435989379883,
    "critic_loss": 3.543705463409424,
    "ent_coef": 0.08738627284765244,
    "learning_rate": 0.001
  },
  {
    "episode": 3474,
    "reward": 88.42305,
    "length": 65,
    "time": 55582.828095,
    "actor_loss": -62.51976776123047,
    "critic_loss": 2.030125617980957,
    "ent_coef": 0.08516326546669006,
    "learning_rate": 0.001
  },
  {
    "episode": 3475,
    "reward": 89.489843,
    "length": 63,
    "time": 55596.483952,
    "actor_loss": -68.06160736083984,
    "critic_loss": 6.69683837890625,
    "ent_coef": 0.08395134657621384,
    "learning_rate": 0.001
  },
  {
    "episode": 3476,
    "reward": 85.896183,
    "length": 69,
    "time": 55608.55893,
    "actor_loss": -63.91731262207031,
    "critic_loss": 2.45898175239563,
    "ent_coef": 0.08530576527118683,
    "learning_rate": 0.001
  },
  {
    "episode": 3477,
    "reward": 89.359209,
    "length": 64,
    "time": 55620.702515,
    "actor_loss": -58.4522705078125,
    "critic_loss": 4.649072647094727,
    "ent_coef": 0.08485561609268188,
    "learning_rate": 0.001
  },
  {
    "episode": 3478,
    "reward": 87.820669,
    "length": 66,
    "time": 55634.528554,
    "actor_loss": -65.297607421875,
    "critic_loss": 37.20055389404297,
    "ent_coef": 0.081495001912117,
    "learning_rate": 0.001
  },
  {
    "episode": 3479,
    "reward": 87.335844,
    "length": 68,
    "time": 55651.792034,
    "actor_loss": -67.70683288574219,
    "critic_loss": 18.599964141845703,
    "ent_coef": 0.08018066734075546,
    "learning_rate": 0.001
  },
  {
    "episode": 3480,
    "reward": 87.150986,
    "length": 68,
    "time": 55664.441549,
    "actor_loss": -62.993675231933594,
    "critic_loss": 33.846092224121094,
    "ent_coef": 0.07907778769731522,
    "learning_rate": 0.001
  },
  {
    "episode": 3481,
    "reward": 87.708804,
    "length": 66,
    "time": 55679.552619,
    "actor_loss": -64.49467468261719,
    "critic_loss": 3.6319336891174316,
    "ent_coef": 0.07793254405260086,
    "learning_rate": 0.001
  },
  {
    "episode": 3482,
    "reward": 88.545345,
    "length": 65,
    "time": 55691.611758,
    "actor_loss": -64.67007446289062,
    "critic_loss": 2.105072021484375,
    "ent_coef": 0.07875695079565048,
    "learning_rate": 0.001
  },
  {
    "episode": 3483,
    "reward": 87.138368,
    "length": 67,
    "time": 55704.883412,
    "actor_loss": -62.205135345458984,
    "critic_loss": 26.452350616455078,
    "ent_coef": 0.08117876946926117,
    "learning_rate": 0.001
  },
  {
    "episode": 3484,
    "reward": 88.993898,
    "length": 64,
    "time": 55716.535855,
    "actor_loss": -68.99473571777344,
    "critic_loss": 9.817537307739258,
    "ent_coef": 0.0799698457121849,
    "learning_rate": 0.001
  },
  {
    "episode": 3485,
    "reward": 88.659445,
    "length": 65,
    "time": 55730.506886,
    "actor_loss": -64.76657104492188,
    "critic_loss": 9.673375129699707,
    "ent_coef": 0.08151289820671082,
    "learning_rate": 0.001
  },
  {
    "episode": 3486,
    "reward": 90.053639,
    "length": 64,
    "time": 55743.573338,
    "actor_loss": -64.83375549316406,
    "critic_loss": 3.080807685852051,
    "ent_coef": 0.08610250055789948,
    "learning_rate": 0.001
  },
  {
    "episode": 3487,
    "reward": 86.34189,
    "length": 71,
    "time": 55756.500164,
    "actor_loss": -64.83241271972656,
    "critic_loss": 33.18008041381836,
    "ent_coef": 0.08550763130187988,
    "learning_rate": 0.001
  },
  {
    "episode": 3488,
    "reward": 90.028693,
    "length": 64,
    "time": 55769.233746,
    "actor_loss": -64.86251831054688,
    "critic_loss": 3.0383570194244385,
    "ent_coef": 0.0856332927942276,
    "learning_rate": 0.001
  },
  {
    "episode": 3489,
    "reward": 86.697716,
    "length": 69,
    "time": 55784.142756,
    "actor_loss": -63.64754867553711,
    "critic_loss": 23.658737182617188,
    "ent_coef": 0.08232507109642029,
    "learning_rate": 0.001
  },
  {
    "episode": 3490,
    "reward": 78.337925,
    "length": 89,
    "time": 55798.717957,
    "actor_loss": -69.3243408203125,
    "critic_loss": 2.0168845653533936,
    "ent_coef": 0.0763959214091301,
    "learning_rate": 0.001
  },
  {
    "episode": 3491,
    "reward": 80.423269,
    "length": 82,
    "time": 55815.325818,
    "actor_loss": -66.6556396484375,
    "critic_loss": 5.328578472137451,
    "ent_coef": 0.07380794733762741,
    "learning_rate": 0.001
  },
  {
    "episode": 3492,
    "reward": 84.736824,
    "length": 73,
    "time": 55828.596273,
    "actor_loss": -61.56731414794922,
    "critic_loss": 1.7062819004058838,
    "ent_coef": 0.07404952496290207,
    "learning_rate": 0.001
  },
  {
    "episode": 3493,
    "reward": 88.964697,
    "length": 65,
    "time": 55840.006383,
    "actor_loss": -68.05793762207031,
    "critic_loss": 9.414729118347168,
    "ent_coef": 0.08259880542755127,
    "learning_rate": 0.001
  },
  {
    "episode": 3494,
    "reward": 87.387749,
    "length": 66,
    "time": 55852.203936,
    "actor_loss": -67.09416961669922,
    "critic_loss": 6.807164192199707,
    "ent_coef": 0.0854446068406105,
    "learning_rate": 0.001
  },
  {
    "episode": 3495,
    "reward": 87.678646,
    "length": 67,
    "time": 55864.94962,
    "actor_loss": -60.401824951171875,
    "critic_loss": 2.0467348098754883,
    "ent_coef": 0.08799752593040466,
    "learning_rate": 0.001
  },
  {
    "episode": 3496,
    "reward": 90.41405,
    "length": 63,
    "time": 55877.095055,
    "actor_loss": -65.65876007080078,
    "critic_loss": 2.35593318939209,
    "ent_coef": 0.09246157109737396,
    "learning_rate": 0.001
  },
  {
    "episode": 3497,
    "reward": 87.0378,
    "length": 68,
    "time": 55891.033812,
    "actor_loss": -68.5782241821289,
    "critic_loss": 44.824832916259766,
    "ent_coef": 0.09096946567296982,
    "learning_rate": 0.001
  },
  {
    "episode": 3498,
    "reward": 87.210993,
    "length": 69,
    "time": 55904.196465,
    "actor_loss": -64.59678649902344,
    "critic_loss": 5.245935916900635,
    "ent_coef": 0.09256989508867264,
    "learning_rate": 0.001
  },
  {
    "episode": 3499,
    "reward": 87.134611,
    "length": 68,
    "time": 55917.04903,
    "actor_loss": -62.374141693115234,
    "critic_loss": 5.357947826385498,
    "ent_coef": 0.09260895103216171,
    "learning_rate": 0.001
  },
  {
    "episode": 3500,
    "reward": 87.869953,
    "length": 68,
    "time": 55930.015641,
    "actor_loss": -59.101417541503906,
    "critic_loss": 3.2122933864593506,
    "ent_coef": 0.0906851664185524,
    "learning_rate": 0.001
  },
  {
    "episode": 3501,
    "reward": 87.281508,
    "length": 67,
    "time": 55941.853539,
    "actor_loss": -61.843109130859375,
    "critic_loss": 23.920578002929688,
    "ent_coef": 0.08903323858976364,
    "learning_rate": 0.001
  },
  {
    "episode": 3502,
    "reward": 89.29594,
    "length": 64,
    "time": 55953.173925,
    "actor_loss": -63.249717712402344,
    "critic_loss": 19.349674224853516,
    "ent_coef": 0.08655767887830734,
    "learning_rate": 0.001
  },
  {
    "episode": 3503,
    "reward": 89.142423,
    "length": 65,
    "time": 55964.667452,
    "actor_loss": -70.56489562988281,
    "critic_loss": 3.3417859077453613,
    "ent_coef": 0.0831066444516182,
    "learning_rate": 0.001
  },
  {
    "episode": 3504,
    "reward": 85.945708,
    "length": 69,
    "time": 55978.49865,
    "actor_loss": -61.867889404296875,
    "critic_loss": 8.582691192626953,
    "ent_coef": 0.08080587536096573,
    "learning_rate": 0.001
  },
  {
    "episode": 3505,
    "reward": 88.833042,
    "length": 65,
    "time": 55990.192603,
    "actor_loss": -59.42928695678711,
    "critic_loss": 3.0648653507232666,
    "ent_coef": 0.0817975178360939,
    "learning_rate": 0.001
  },
  {
    "episode": 3506,
    "reward": 89.102339,
    "length": 65,
    "time": 56003.319515,
    "actor_loss": -65.07394409179688,
    "critic_loss": 31.843353271484375,
    "ent_coef": 0.08041960000991821,
    "learning_rate": 0.001
  },
  {
    "episode": 3507,
    "reward": 87.270664,
    "length": 67,
    "time": 56017.155284,
    "actor_loss": -61.52953338623047,
    "critic_loss": 4.025073051452637,
    "ent_coef": 0.07936103641986847,
    "learning_rate": 0.001
  },
  {
    "episode": 3508,
    "reward": 88.482831,
    "length": 65,
    "time": 56029.642926,
    "actor_loss": -62.41676712036133,
    "critic_loss": 9.092672348022461,
    "ent_coef": 0.07736240327358246,
    "learning_rate": 0.001
  },
  {
    "episode": 3509,
    "reward": 86.507504,
    "length": 69,
    "time": 56045.066871,
    "actor_loss": -56.04987716674805,
    "critic_loss": 3.2125282287597656,
    "ent_coef": 0.07520534843206406,
    "learning_rate": 0.001
  },
  {
    "episode": 3510,
    "reward": 86.452586,
    "length": 68,
    "time": 56057.082433,
    "actor_loss": -69.01213073730469,
    "critic_loss": 1.94186532497406,
    "ent_coef": 0.0729144960641861,
    "learning_rate": 0.001
  },
  {
    "episode": 3511,
    "reward": 86.552966,
    "length": 73,
    "time": 56070.731904,
    "actor_loss": -62.88908004760742,
    "critic_loss": 2.3683652877807617,
    "ent_coef": 0.06977132707834244,
    "learning_rate": 0.001
  },
  {
    "episode": 3512,
    "reward": 89.113068,
    "length": 65,
    "time": 56082.963831,
    "actor_loss": -65.83618927001953,
    "critic_loss": 3.642979621887207,
    "ent_coef": 0.06803375482559204,
    "learning_rate": 0.001
  },
  {
    "episode": 3513,
    "reward": 88.035386,
    "length": 65,
    "time": 56095.008706,
    "actor_loss": -67.05079650878906,
    "critic_loss": 1.8616470098495483,
    "ent_coef": 0.06911254674196243,
    "learning_rate": 0.001
  },
  {
    "episode": 3514,
    "reward": 81.475663,
    "length": 75,
    "time": 56109.867687,
    "actor_loss": -69.94837951660156,
    "critic_loss": 16.925819396972656,
    "ent_coef": 0.07001221925020218,
    "learning_rate": 0.001
  },
  {
    "episode": 3515,
    "reward": 91.235039,
    "length": 61,
    "time": 56121.238895,
    "actor_loss": -62.79719543457031,
    "critic_loss": 9.209921836853027,
    "ent_coef": 0.07252279669046402,
    "learning_rate": 0.001
  },
  {
    "episode": 3516,
    "reward": 87.341415,
    "length": 67,
    "time": 56135.706518,
    "actor_loss": -70.67532348632812,
    "critic_loss": 1.733360767364502,
    "ent_coef": 0.07393629848957062,
    "learning_rate": 0.001
  },
  {
    "episode": 3517,
    "reward": 88.505282,
    "length": 65,
    "time": 56147.483291,
    "actor_loss": -68.05723571777344,
    "critic_loss": 2.4983034133911133,
    "ent_coef": 0.0740148052573204,
    "learning_rate": 0.001
  },
  {
    "episode": 3518,
    "reward": 88.776474,
    "length": 64,
    "time": 56158.794983,
    "actor_loss": -65.24057006835938,
    "critic_loss": 3.288872480392456,
    "ent_coef": 0.0756545215845108,
    "learning_rate": 0.001
  },
  {
    "episode": 3519,
    "reward": 87.680543,
    "length": 66,
    "time": 56171.433978,
    "actor_loss": -67.5727310180664,
    "critic_loss": 2.6129727363586426,
    "ent_coef": 0.07421166449785233,
    "learning_rate": 0.001
  },
  {
    "episode": 3520,
    "reward": 88.359949,
    "length": 66,
    "time": 56183.966103,
    "actor_loss": -67.17992401123047,
    "critic_loss": 1.3564852476119995,
    "ent_coef": 0.07417662441730499,
    "learning_rate": 0.001
  },
  {
    "episode": 3521,
    "reward": 83.187373,
    "length": 93,
    "time": 56200.010609,
    "actor_loss": -56.288970947265625,
    "critic_loss": 10.875096321105957,
    "ent_coef": 0.07719120383262634,
    "learning_rate": 0.001
  },
  {
    "episode": 3522,
    "reward": 88.578815,
    "length": 66,
    "time": 56211.433273,
    "actor_loss": -64.81571960449219,
    "critic_loss": 6.50413703918457,
    "ent_coef": 0.0752832368016243,
    "learning_rate": 0.001
  },
  {
    "episode": 3523,
    "reward": 86.746873,
    "length": 69,
    "time": 56225.833453,
    "actor_loss": -67.1397933959961,
    "critic_loss": 8.55795955657959,
    "ent_coef": 0.07364378869533539,
    "learning_rate": 0.001
  },
  {
    "episode": 3524,
    "reward": 87.822728,
    "length": 68,
    "time": 56238.571243,
    "actor_loss": -63.5592041015625,
    "critic_loss": 15.022397994995117,
    "ent_coef": 0.07304120063781738,
    "learning_rate": 0.001
  },
  {
    "episode": 3525,
    "reward": 81.026336,
    "length": 98,
    "time": 56254.682971,
    "actor_loss": -64.71237182617188,
    "critic_loss": 7.087218284606934,
    "ent_coef": 0.07608576118946075,
    "learning_rate": 0.001
  },
  {
    "episode": 3526,
    "reward": 87.946254,
    "length": 66,
    "time": 56267.603315,
    "actor_loss": -71.32330322265625,
    "critic_loss": 1.9928275346755981,
    "ent_coef": 0.07988378405570984,
    "learning_rate": 0.001
  },
  {
    "episode": 3527,
    "reward": 87.018362,
    "length": 68,
    "time": 56282.993587,
    "actor_loss": -63.22019577026367,
    "critic_loss": 59.74952697753906,
    "ent_coef": 0.08232127875089645,
    "learning_rate": 0.001
  },
  {
    "episode": 3528,
    "reward": 89.936548,
    "length": 62,
    "time": 56295.818933,
    "actor_loss": -69.38140869140625,
    "critic_loss": 13.130941390991211,
    "ent_coef": 0.08677976578474045,
    "learning_rate": 0.001
  },
  {
    "episode": 3529,
    "reward": 88.605936,
    "length": 66,
    "time": 56307.386058,
    "actor_loss": -64.57202911376953,
    "critic_loss": 3.040128231048584,
    "ent_coef": 0.08767016977071762,
    "learning_rate": 0.001
  },
  {
    "episode": 3530,
    "reward": 86.982642,
    "length": 69,
    "time": 56319.815044,
    "actor_loss": -64.30030822753906,
    "critic_loss": 3.1995739936828613,
    "ent_coef": 0.08465849608182907,
    "learning_rate": 0.001
  },
  {
    "episode": 3531,
    "reward": 87.228591,
    "length": 68,
    "time": 56334.026206,
    "actor_loss": -65.27460479736328,
    "critic_loss": 9.348806381225586,
    "ent_coef": 0.08346185833215714,
    "learning_rate": 0.001
  },
  {
    "episode": 3532,
    "reward": 90.037892,
    "length": 63,
    "time": 56347.646178,
    "actor_loss": -64.9904556274414,
    "critic_loss": 4.071487903594971,
    "ent_coef": 0.08498289436101913,
    "learning_rate": 0.001
  },
  {
    "episode": 3533,
    "reward": 77.14182,
    "length": 107,
    "time": 56364.443846,
    "actor_loss": -69.94416809082031,
    "critic_loss": 422.46197509765625,
    "ent_coef": 0.08597039431333542,
    "learning_rate": 0.001
  },
  {
    "episode": 3534,
    "reward": 78.680919,
    "length": 79,
    "time": 56377.748911,
    "actor_loss": -63.34996795654297,
    "critic_loss": 3.185412883758545,
    "ent_coef": 0.0883040726184845,
    "learning_rate": 0.001
  },
  {
    "episode": 3535,
    "reward": 86.268563,
    "length": 73,
    "time": 56393.663427,
    "actor_loss": -58.306400299072266,
    "critic_loss": 4.4220662117004395,
    "ent_coef": 0.08807934075593948,
    "learning_rate": 0.001
  },
  {
    "episode": 3536,
    "reward": 86.88174,
    "length": 68,
    "time": 56407.24919,
    "actor_loss": -65.27828216552734,
    "critic_loss": 3.4437458515167236,
    "ent_coef": 0.08761218190193176,
    "learning_rate": 0.001
  },
  {
    "episode": 3537,
    "reward": 89.192545,
    "length": 64,
    "time": 56420.662241,
    "actor_loss": -61.10688781738281,
    "critic_loss": 11.711387634277344,
    "ent_coef": 0.08681325614452362,
    "learning_rate": 0.001
  },
  {
    "episode": 3538,
    "reward": 85.426203,
    "length": 71,
    "time": 56432.79862,
    "actor_loss": -65.49778747558594,
    "critic_loss": 3.966547966003418,
    "ent_coef": 0.08455521613359451,
    "learning_rate": 0.001
  },
  {
    "episode": 3539,
    "reward": 86.835589,
    "length": 68,
    "time": 56445.979702,
    "actor_loss": -63.02072525024414,
    "critic_loss": 1.937196135520935,
    "ent_coef": 0.08372479677200317,
    "learning_rate": 0.001
  },
  {
    "episode": 3540,
    "reward": 88.118215,
    "length": 66,
    "time": 56459.839392,
    "actor_loss": -67.34017944335938,
    "critic_loss": 3.6184799671173096,
    "ent_coef": 0.08251888304948807,
    "learning_rate": 0.001
  },
  {
    "episode": 3541,
    "reward": 87.811821,
    "length": 65,
    "time": 56471.889554,
    "actor_loss": -60.94636535644531,
    "critic_loss": 3.3450756072998047,
    "ent_coef": 0.08230748027563095,
    "learning_rate": 0.001
  },
  {
    "episode": 3542,
    "reward": 86.498745,
    "length": 69,
    "time": 56483.529983,
    "actor_loss": -70.3039779663086,
    "critic_loss": 3.2467219829559326,
    "ent_coef": 0.08020161092281342,
    "learning_rate": 0.001
  },
  {
    "episode": 3543,
    "reward": 86.734401,
    "length": 67,
    "time": 56496.119,
    "actor_loss": -60.97489547729492,
    "critic_loss": 2.475587844848633,
    "ent_coef": 0.0796353667974472,
    "learning_rate": 0.001
  },
  {
    "episode": 3544,
    "reward": 84.619086,
    "length": 80,
    "time": 56511.4821,
    "actor_loss": -63.21818923950195,
    "critic_loss": 2.5869104862213135,
    "ent_coef": 0.07822511345148087,
    "learning_rate": 0.001
  },
  {
    "episode": 3545,
    "reward": 87.048396,
    "length": 73,
    "time": 56524.627188,
    "actor_loss": -68.22964477539062,
    "critic_loss": 2.1465892791748047,
    "ent_coef": 0.07881328463554382,
    "learning_rate": 0.001
  },
  {
    "episode": 3546,
    "reward": 85.21328,
    "length": 72,
    "time": 56541.245595,
    "actor_loss": -64.78396606445312,
    "critic_loss": 2.7026641368865967,
    "ent_coef": 0.07926270365715027,
    "learning_rate": 0.001
  },
  {
    "episode": 3547,
    "reward": 87.693415,
    "length": 68,
    "time": 56552.934987,
    "actor_loss": -61.82318878173828,
    "critic_loss": 3.438527822494507,
    "ent_coef": 0.07867274433374405,
    "learning_rate": 0.001
  },
  {
    "episode": 3548,
    "reward": 85.399351,
    "length": 69,
    "time": 56565.964263,
    "actor_loss": -68.72402954101562,
    "critic_loss": 2.3996245861053467,
    "ent_coef": 0.07866261899471283,
    "learning_rate": 0.001
  },
  {
    "episode": 3549,
    "reward": 87.551144,
    "length": 67,
    "time": 56579.769471,
    "actor_loss": -67.09024047851562,
    "critic_loss": 13.331382751464844,
    "ent_coef": 0.07875984162092209,
    "learning_rate": 0.001
  },
  {
    "episode": 3550,
    "reward": 86.900935,
    "length": 68,
    "time": 56593.319251,
    "actor_loss": -60.38817596435547,
    "critic_loss": 3.1868503093719482,
    "ent_coef": 0.07931383699178696,
    "learning_rate": 0.001
  },
  {
    "episode": 3551,
    "reward": 87.375397,
    "length": 67,
    "time": 56606.007658,
    "actor_loss": -64.80546569824219,
    "critic_loss": 53.46250915527344,
    "ent_coef": 0.07869493216276169,
    "learning_rate": 0.001
  },
  {
    "episode": 3552,
    "reward": 90.419274,
    "length": 63,
    "time": 56618.234904,
    "actor_loss": -58.67071533203125,
    "critic_loss": 3.7820944786071777,
    "ent_coef": 0.08074731379747391,
    "learning_rate": 0.001
  },
  {
    "episode": 3553,
    "reward": 87.774723,
    "length": 66,
    "time": 56630.805655,
    "actor_loss": -64.64662170410156,
    "critic_loss": 4.267161846160889,
    "ent_coef": 0.08315186947584152,
    "learning_rate": 0.001
  },
  {
    "episode": 3554,
    "reward": 82.519095,
    "length": 76,
    "time": 56644.533968,
    "actor_loss": -64.26280975341797,
    "critic_loss": 15.01613712310791,
    "ent_coef": 0.07936308532953262,
    "learning_rate": 0.001
  },
  {
    "episode": 3555,
    "reward": 82.547843,
    "length": 82,
    "time": 56662.556486,
    "actor_loss": -65.8566665649414,
    "critic_loss": 10.54862117767334,
    "ent_coef": 0.07871167361736298,
    "learning_rate": 0.001
  },
  {
    "episode": 3556,
    "reward": 85.342856,
    "length": 75,
    "time": 56678.968955,
    "actor_loss": -61.260066986083984,
    "critic_loss": 1.5954166650772095,
    "ent_coef": 0.08863941580057144,
    "learning_rate": 0.001
  },
  {
    "episode": 3557,
    "reward": -26.875505,
    "length": 215,
    "time": 56710.76792,
    "actor_loss": -64.02604675292969,
    "critic_loss": 3.789933681488037,
    "ent_coef": 0.0907302126288414,
    "learning_rate": 0.001
  },
  {
    "episode": 3558,
    "reward": -24.86451,
    "length": 208,
    "time": 56740.801233,
    "actor_loss": -67.56929779052734,
    "critic_loss": 2.440692186355591,
    "ent_coef": 0.08791781216859818,
    "learning_rate": 0.001
  },
  {
    "episode": 3559,
    "reward": 78.448602,
    "length": 85,
    "time": 56755.597037,
    "actor_loss": -67.99530792236328,
    "critic_loss": 13.774080276489258,
    "ent_coef": 0.0864858329296112,
    "learning_rate": 0.001
  },
  {
    "episode": 3560,
    "reward": 17.780328,
    "length": 161,
    "time": 56780.160762,
    "actor_loss": -67.71831512451172,
    "critic_loss": 4.586498260498047,
    "ent_coef": 0.08776559680700302,
    "learning_rate": 0.001
  },
  {
    "episode": 3561,
    "reward": 89.696869,
    "length": 63,
    "time": 56792.089567,
    "actor_loss": -61.35211181640625,
    "critic_loss": 13.999975204467773,
    "ent_coef": 0.09166990220546722,
    "learning_rate": 0.001
  },
  {
    "episode": 3562,
    "reward": 81.407144,
    "length": 76,
    "time": 56805.946738,
    "actor_loss": -63.12668991088867,
    "critic_loss": 62.627235412597656,
    "ent_coef": 0.08946496248245239,
    "learning_rate": 0.001
  },
  {
    "episode": 3563,
    "reward": 88.10463,
    "length": 66,
    "time": 56819.83844,
    "actor_loss": -73.55340576171875,
    "critic_loss": 7.499043941497803,
    "ent_coef": 0.08925887197256088,
    "learning_rate": 0.001
  },
  {
    "episode": 3564,
    "reward": 87.7864,
    "length": 66,
    "time": 56831.527086,
    "actor_loss": -65.45806884765625,
    "critic_loss": 3.478933811187744,
    "ent_coef": 0.08832158893346786,
    "learning_rate": 0.001
  },
  {
    "episode": 3565,
    "reward": 88.262679,
    "length": 66,
    "time": 56844.463971,
    "actor_loss": -65.46104431152344,
    "critic_loss": 6.779843807220459,
    "ent_coef": 0.08660660684108734,
    "learning_rate": 0.001
  },
  {
    "episode": 3566,
    "reward": 84.618419,
    "length": 83,
    "time": 56858.077224,
    "actor_loss": -60.41407775878906,
    "critic_loss": 2.798936605453491,
    "ent_coef": 0.08564404398202896,
    "learning_rate": 0.001
  },
  {
    "episode": 3567,
    "reward": 79.655373,
    "length": 78,
    "time": 56872.123198,
    "actor_loss": -69.4785385131836,
    "critic_loss": 3.190795421600342,
    "ent_coef": 0.08495976775884628,
    "learning_rate": 0.001
  },
  {
    "episode": 3568,
    "reward": 87.029486,
    "length": 67,
    "time": 56884.733944,
    "actor_loss": -62.35653305053711,
    "critic_loss": 2.8868448734283447,
    "ent_coef": 0.08581657707691193,
    "learning_rate": 0.001
  },
  {
    "episode": 3569,
    "reward": 90.384026,
    "length": 63,
    "time": 56899.676235,
    "actor_loss": -68.90171813964844,
    "critic_loss": 4.430359363555908,
    "ent_coef": 0.08477899432182312,
    "learning_rate": 0.001
  },
  {
    "episode": 3570,
    "reward": 87.40326,
    "length": 68,
    "time": 56912.271618,
    "actor_loss": -63.166419982910156,
    "critic_loss": 6.24685001373291,
    "ent_coef": 0.08114174008369446,
    "learning_rate": 0.001
  },
  {
    "episode": 3571,
    "reward": 86.200712,
    "length": 69,
    "time": 56925.09044,
    "actor_loss": -61.61607360839844,
    "critic_loss": 21.050785064697266,
    "ent_coef": 0.08139682561159134,
    "learning_rate": 0.001
  },
  {
    "episode": 3572,
    "reward": 84.383238,
    "length": 70,
    "time": 56940.335104,
    "actor_loss": -60.90507507324219,
    "critic_loss": 13.443552017211914,
    "ent_coef": 0.08444122970104218,
    "learning_rate": 0.001
  },
  {
    "episode": 3573,
    "reward": 89.184149,
    "length": 66,
    "time": 56951.988169,
    "actor_loss": -65.60722351074219,
    "critic_loss": 11.507917404174805,
    "ent_coef": 0.08642556518316269,
    "learning_rate": 0.001
  },
  {
    "episode": 3574,
    "reward": 88.362269,
    "length": 66,
    "time": 56964.463002,
    "actor_loss": -69.25118255615234,
    "critic_loss": 5.155935287475586,
    "ent_coef": 0.08909434825181961,
    "learning_rate": 0.001
  },
  {
    "episode": 3575,
    "reward": 87.211709,
    "length": 69,
    "time": 56978.930268,
    "actor_loss": -65.84866333007812,
    "critic_loss": 50.993980407714844,
    "ent_coef": 0.08821974694728851,
    "learning_rate": 0.001
  },
  {
    "episode": 3576,
    "reward": 87.714687,
    "length": 67,
    "time": 56993.93892,
    "actor_loss": -66.03581237792969,
    "critic_loss": 2.264707565307617,
    "ent_coef": 0.08799882978200912,
    "learning_rate": 0.001
  },
  {
    "episode": 3577,
    "reward": 89.588444,
    "length": 65,
    "time": 57007.203184,
    "actor_loss": -68.58676147460938,
    "critic_loss": 2.252561569213867,
    "ent_coef": 0.08789008855819702,
    "learning_rate": 0.001
  },
  {
    "episode": 3578,
    "reward": 80.058364,
    "length": 78,
    "time": 57020.411194,
    "actor_loss": -66.3126449584961,
    "critic_loss": 35.58855438232422,
    "ent_coef": 0.08862466365098953,
    "learning_rate": 0.001
  },
  {
    "episode": 3579,
    "reward": 87.543482,
    "length": 67,
    "time": 57034.053751,
    "actor_loss": -64.83253479003906,
    "critic_loss": 3.3391733169555664,
    "ent_coef": 0.08893983066082001,
    "learning_rate": 0.001
  },
  {
    "episode": 3580,
    "reward": 84.337423,
    "length": 73,
    "time": 57048.446775,
    "actor_loss": -64.3692398071289,
    "critic_loss": 12.101751327514648,
    "ent_coef": 0.09119454771280289,
    "learning_rate": 0.001
  },
  {
    "episode": 3581,
    "reward": 90.785923,
    "length": 62,
    "time": 57061.043725,
    "actor_loss": -64.32611083984375,
    "critic_loss": 3.300910472869873,
    "ent_coef": 0.09048379212617874,
    "learning_rate": 0.001
  },
  {
    "episode": 3582,
    "reward": 87.947665,
    "length": 66,
    "time": 57072.77073,
    "actor_loss": -67.89833068847656,
    "critic_loss": 2.927872657775879,
    "ent_coef": 0.08708390593528748,
    "learning_rate": 0.001
  },
  {
    "episode": 3583,
    "reward": 86.634914,
    "length": 70,
    "time": 57087.335959,
    "actor_loss": -60.141910552978516,
    "critic_loss": 6.275938987731934,
    "ent_coef": 0.08607450127601624,
    "learning_rate": 0.001
  },
  {
    "episode": 3584,
    "reward": 86.87984,
    "length": 68,
    "time": 57101.870145,
    "actor_loss": -63.682281494140625,
    "critic_loss": 3.164755344390869,
    "ent_coef": 0.08467381447553635,
    "learning_rate": 0.001
  },
  {
    "episode": 3585,
    "reward": 89.429098,
    "length": 63,
    "time": 57114.529876,
    "actor_loss": -68.40449523925781,
    "critic_loss": 10.136089324951172,
    "ent_coef": 0.08523222804069519,
    "learning_rate": 0.001
  },
  {
    "episode": 3586,
    "reward": 90.589774,
    "length": 63,
    "time": 57126.427678,
    "actor_loss": -61.22508239746094,
    "critic_loss": 2.5152523517608643,
    "ent_coef": 0.08310061693191528,
    "learning_rate": 0.001
  },
  {
    "episode": 3587,
    "reward": 84.773531,
    "length": 72,
    "time": 57139.404918,
    "actor_loss": -59.489967346191406,
    "critic_loss": 4.120497703552246,
    "ent_coef": 0.0824027955532074,
    "learning_rate": 0.001
  },
  {
    "episode": 3588,
    "reward": 87.06957,
    "length": 76,
    "time": 57155.275608,
    "actor_loss": -58.153358459472656,
    "critic_loss": 2.590385675430298,
    "ent_coef": 0.08232855796813965,
    "learning_rate": 0.001
  },
  {
    "episode": 3589,
    "reward": 88.801366,
    "length": 66,
    "time": 57166.879977,
    "actor_loss": -61.01210403442383,
    "critic_loss": 28.769899368286133,
    "ent_coef": 0.0828685462474823,
    "learning_rate": 0.001
  },
  {
    "episode": 3590,
    "reward": 88.689942,
    "length": 65,
    "time": 57178.526148,
    "actor_loss": -66.1033935546875,
    "critic_loss": 1.8298887014389038,
    "ent_coef": 0.08427047729492188,
    "learning_rate": 0.001
  },
  {
    "episode": 3591,
    "reward": 87.581034,
    "length": 66,
    "time": 57190.230114,
    "actor_loss": -65.94461822509766,
    "critic_loss": 8.156732559204102,
    "ent_coef": 0.08284100890159607,
    "learning_rate": 0.001
  },
  {
    "episode": 3592,
    "reward": 87.143365,
    "length": 69,
    "time": 57201.937592,
    "actor_loss": -65.60198974609375,
    "critic_loss": 8.732121467590332,
    "ent_coef": 0.08280166983604431,
    "learning_rate": 0.001
  },
  {
    "episode": 3593,
    "reward": 85.043524,
    "length": 71,
    "time": 57216.500751,
    "actor_loss": -64.31034851074219,
    "critic_loss": 3.713489055633545,
    "ent_coef": 0.08234185725450516,
    "learning_rate": 0.001
  },
  {
    "episode": 3594,
    "reward": 86.444336,
    "length": 68,
    "time": 57228.155904,
    "actor_loss": -68.56033325195312,
    "critic_loss": 3.126039981842041,
    "ent_coef": 0.08102315664291382,
    "learning_rate": 0.001
  },
  {
    "episode": 3595,
    "reward": 89.61794,
    "length": 64,
    "time": 57242.500242,
    "actor_loss": -68.51605224609375,
    "critic_loss": 3.3108763694763184,
    "ent_coef": 0.08038933575153351,
    "learning_rate": 0.001
  },
  {
    "episode": 3596,
    "reward": 90.084239,
    "length": 64,
    "time": 57255.534759,
    "actor_loss": -64.67755126953125,
    "critic_loss": 2.269650936126709,
    "ent_coef": 0.08066394180059433,
    "learning_rate": 0.001
  },
  {
    "episode": 3597,
    "reward": 85.794245,
    "length": 70,
    "time": 57267.966734,
    "actor_loss": -63.30488586425781,
    "critic_loss": 2.6922545433044434,
    "ent_coef": 0.07978184521198273,
    "learning_rate": 0.001
  },
  {
    "episode": 3598,
    "reward": 88.265569,
    "length": 66,
    "time": 57281.138802,
    "actor_loss": -67.42134094238281,
    "critic_loss": 3.1146178245544434,
    "ent_coef": 0.07960250228643417,
    "learning_rate": 0.001
  },
  {
    "episode": 3599,
    "reward": 88.539032,
    "length": 65,
    "time": 57293.367666,
    "actor_loss": -63.21057891845703,
    "critic_loss": 2.846644401550293,
    "ent_coef": 0.0791274830698967,
    "learning_rate": 0.001
  },
  {
    "episode": 3600,
    "reward": 87.125017,
    "length": 67,
    "time": 57308.714619,
    "actor_loss": -66.41752624511719,
    "critic_loss": 4.3098859786987305,
    "ent_coef": 0.07976647466421127,
    "learning_rate": 0.001
  },
  {
    "episode": 3601,
    "reward": 88.049308,
    "length": 67,
    "time": 57320.47318,
    "actor_loss": -65.5647201538086,
    "critic_loss": 8.35750675201416,
    "ent_coef": 0.07981744408607483,
    "learning_rate": 0.001
  },
  {
    "episode": 3602,
    "reward": 89.682419,
    "length": 63,
    "time": 57331.810486,
    "actor_loss": -64.43502807617188,
    "critic_loss": 27.779170989990234,
    "ent_coef": 0.08196748048067093,
    "learning_rate": 0.001
  },
  {
    "episode": 3603,
    "reward": 77.455103,
    "length": 83,
    "time": 57345.596366,
    "actor_loss": -69.05535888671875,
    "critic_loss": 67.76522064208984,
    "ent_coef": 0.07951532304286957,
    "learning_rate": 0.001
  },
  {
    "episode": 3604,
    "reward": 85.544243,
    "length": 72,
    "time": 57360.361745,
    "actor_loss": -71.28913879394531,
    "critic_loss": 34.52228546142578,
    "ent_coef": 0.07604363560676575,
    "learning_rate": 0.001
  },
  {
    "episode": 3605,
    "reward": 88.717477,
    "length": 67,
    "time": 57372.929523,
    "actor_loss": -63.114036560058594,
    "critic_loss": 5.9585442543029785,
    "ent_coef": 0.07569938153028488,
    "learning_rate": 0.001
  },
  {
    "episode": 3606,
    "reward": 86.305355,
    "length": 74,
    "time": 57387.749562,
    "actor_loss": -67.27677917480469,
    "critic_loss": 9.322957038879395,
    "ent_coef": 0.07543215900659561,
    "learning_rate": 0.001
  },
  {
    "episode": 3607,
    "reward": 82.644772,
    "length": 74,
    "time": 57402.55053,
    "actor_loss": -62.48918151855469,
    "critic_loss": 4.0006818771362305,
    "ent_coef": 0.07569065690040588,
    "learning_rate": 0.001
  },
  {
    "episode": 3608,
    "reward": 88.606641,
    "length": 65,
    "time": 57414.143799,
    "actor_loss": -63.91154098510742,
    "critic_loss": 7.336407661437988,
    "ent_coef": 0.07515820115804672,
    "learning_rate": 0.001
  },
  {
    "episode": 3609,
    "reward": 88.000564,
    "length": 66,
    "time": 57426.753893,
    "actor_loss": -56.312225341796875,
    "critic_loss": 58.36121368408203,
    "ent_coef": 0.07743512839078903,
    "learning_rate": 0.001
  },
  {
    "episode": 3610,
    "reward": 88.163532,
    "length": 68,
    "time": 57441.169862,
    "actor_loss": -63.82038116455078,
    "critic_loss": 3.6311306953430176,
    "ent_coef": 0.07761319726705551,
    "learning_rate": 0.001
  },
  {
    "episode": 3611,
    "reward": 81.548784,
    "length": 76,
    "time": 57455.907991,
    "actor_loss": -64.40934753417969,
    "critic_loss": 9.463366508483887,
    "ent_coef": 0.07791867107152939,
    "learning_rate": 0.001
  },
  {
    "episode": 3612,
    "reward": 87.880539,
    "length": 68,
    "time": 57469.56561,
    "actor_loss": -63.69636535644531,
    "critic_loss": 12.556962966918945,
    "ent_coef": 0.07683947682380676,
    "learning_rate": 0.001
  },
  {
    "episode": 3613,
    "reward": 87.217998,
    "length": 68,
    "time": 57481.995248,
    "actor_loss": -67.09176635742188,
    "critic_loss": 3.003506660461426,
    "ent_coef": 0.07738680392503738,
    "learning_rate": 0.001
  },
  {
    "episode": 3614,
    "reward": 87.252747,
    "length": 66,
    "time": 57494.926944,
    "actor_loss": -64.27653503417969,
    "critic_loss": 6.277951240539551,
    "ent_coef": 0.07684195786714554,
    "learning_rate": 0.001
  },
  {
    "episode": 3615,
    "reward": 90.499018,
    "length": 62,
    "time": 57506.383037,
    "actor_loss": -62.44993591308594,
    "critic_loss": 4.268049240112305,
    "ent_coef": 0.07624490559101105,
    "learning_rate": 0.001
  },
  {
    "episode": 3616,
    "reward": 90.584515,
    "length": 61,
    "time": 57518.936527,
    "actor_loss": -74.69123077392578,
    "critic_loss": 2.609750986099243,
    "ent_coef": 0.08158355206251144,
    "learning_rate": 0.001
  },
  {
    "episode": 3617,
    "reward": 90.049381,
    "length": 64,
    "time": 57532.143861,
    "actor_loss": -66.86332702636719,
    "critic_loss": 39.26043701171875,
    "ent_coef": 0.08088131994009018,
    "learning_rate": 0.001
  },
  {
    "episode": 3618,
    "reward": 84.081766,
    "length": 86,
    "time": 57546.692255,
    "actor_loss": -66.87257385253906,
    "critic_loss": 10.531913757324219,
    "ent_coef": 0.07741725444793701,
    "learning_rate": 0.001
  },
  {
    "episode": 3619,
    "reward": 59.424469,
    "length": 103,
    "time": 57564.249568,
    "actor_loss": -64.74891662597656,
    "critic_loss": 2.772144317626953,
    "ent_coef": 0.07775958627462387,
    "learning_rate": 0.001
  },
  {
    "episode": 3620,
    "reward": 89.994974,
    "length": 63,
    "time": 57575.958487,
    "actor_loss": -63.13146209716797,
    "critic_loss": 26.726781845092773,
    "ent_coef": 0.07850918173789978,
    "learning_rate": 0.001
  },
  {
    "episode": 3621,
    "reward": 88.003552,
    "length": 66,
    "time": 57590.756146,
    "actor_loss": -68.63683319091797,
    "critic_loss": 2.581176519393921,
    "ent_coef": 0.07991497218608856,
    "learning_rate": 0.001
  },
  {
    "episode": 3622,
    "reward": 88.079883,
    "length": 67,
    "time": 57604.133675,
    "actor_loss": -66.20487213134766,
    "critic_loss": 2.38389253616333,
    "ent_coef": 0.08101459592580795,
    "learning_rate": 0.001
  },
  {
    "episode": 3623,
    "reward": 86.742995,
    "length": 68,
    "time": 57617.100667,
    "actor_loss": -63.62662124633789,
    "critic_loss": 2.4064579010009766,
    "ent_coef": 0.07943568378686905,
    "learning_rate": 0.001
  },
  {
    "episode": 3624,
    "reward": 88.974174,
    "length": 65,
    "time": 57632.510484,
    "actor_loss": -63.89865493774414,
    "critic_loss": 5.83059024810791,
    "ent_coef": 0.07938401401042938,
    "learning_rate": 0.001
  },
  {
    "episode": 3625,
    "reward": 86.311334,
    "length": 69,
    "time": 57648.086904,
    "actor_loss": -64.90512084960938,
    "critic_loss": 2.749451160430908,
    "ent_coef": 0.0794890895485878,
    "learning_rate": 0.001
  },
  {
    "episode": 3626,
    "reward": 87.618825,
    "length": 67,
    "time": 57660.98853,
    "actor_loss": -67.56495666503906,
    "critic_loss": 4.498265266418457,
    "ent_coef": 0.07870219647884369,
    "learning_rate": 0.001
  },
  {
    "episode": 3627,
    "reward": 82.927794,
    "length": 86,
    "time": 57675.219867,
    "actor_loss": -65.17921447753906,
    "critic_loss": 28.193368911743164,
    "ent_coef": 0.07834310084581375,
    "learning_rate": 0.001
  },
  {
    "episode": 3628,
    "reward": 89.249544,
    "length": 64,
    "time": 57687.299617,
    "actor_loss": -61.8258171081543,
    "critic_loss": 1.9149770736694336,
    "ent_coef": 0.0787244513630867,
    "learning_rate": 0.001
  },
  {
    "episode": 3629,
    "reward": 79.426984,
    "length": 78,
    "time": 57701.233212,
    "actor_loss": -68.99962615966797,
    "critic_loss": 29.48822021484375,
    "ent_coef": 0.07939476519823074,
    "learning_rate": 0.001
  },
  {
    "episode": 3630,
    "reward": 85.321118,
    "length": 70,
    "time": 57713.382682,
    "actor_loss": -59.46387481689453,
    "critic_loss": 9.796014785766602,
    "ent_coef": 0.0764741525053978,
    "learning_rate": 0.001
  },
  {
    "episode": 3631,
    "reward": 81.873939,
    "length": 89,
    "time": 57727.92277,
    "actor_loss": -64.30314636230469,
    "critic_loss": 4.710982799530029,
    "ent_coef": 0.07812120020389557,
    "learning_rate": 0.001
  },
  {
    "episode": 3632,
    "reward": 84.845393,
    "length": 72,
    "time": 57742.149673,
    "actor_loss": -65.41926574707031,
    "critic_loss": 3.0159592628479004,
    "ent_coef": 0.0777573212981224,
    "learning_rate": 0.001
  },
  {
    "episode": 3633,
    "reward": 88.240381,
    "length": 66,
    "time": 57753.577485,
    "actor_loss": -62.478111267089844,
    "critic_loss": 3.623990535736084,
    "ent_coef": 0.07750843465328217,
    "learning_rate": 0.001
  },
  {
    "episode": 3634,
    "reward": 86.674172,
    "length": 75,
    "time": 57766.419794,
    "actor_loss": -70.63226318359375,
    "critic_loss": 41.208988189697266,
    "ent_coef": 0.07584880292415619,
    "learning_rate": 0.001
  },
  {
    "episode": 3635,
    "reward": 85.263299,
    "length": 73,
    "time": 57778.660828,
    "actor_loss": -66.6751937866211,
    "critic_loss": 5.3155741691589355,
    "ent_coef": 0.07394839823246002,
    "learning_rate": 0.001
  },
  {
    "episode": 3636,
    "reward": 87.623545,
    "length": 67,
    "time": 57793.907056,
    "actor_loss": -69.24449157714844,
    "critic_loss": 37.240577697753906,
    "ent_coef": 0.07354088127613068,
    "learning_rate": 0.001
  },
  {
    "episode": 3637,
    "reward": 83.973769,
    "length": 72,
    "time": 57807.567871,
    "actor_loss": -72.24114990234375,
    "critic_loss": 163.81507873535156,
    "ent_coef": 0.07478223741054535,
    "learning_rate": 0.001
  },
  {
    "episode": 3638,
    "reward": 88.934556,
    "length": 65,
    "time": 57819.935811,
    "actor_loss": -61.9385986328125,
    "critic_loss": 14.615486145019531,
    "ent_coef": 0.07771167159080505,
    "learning_rate": 0.001
  },
  {
    "episode": 3639,
    "reward": 78.298603,
    "length": 92,
    "time": 57836.873845,
    "actor_loss": -69.04043579101562,
    "critic_loss": 2.641873836517334,
    "ent_coef": 0.07999172061681747,
    "learning_rate": 0.001
  },
  {
    "episode": 3640,
    "reward": 85.866146,
    "length": 69,
    "time": 57852.186918,
    "actor_loss": -66.7513427734375,
    "critic_loss": 11.915475845336914,
    "ent_coef": 0.07826689630746841,
    "learning_rate": 0.001
  },
  {
    "episode": 3641,
    "reward": 87.15469,
    "length": 74,
    "time": 57865.788906,
    "actor_loss": -65.65553283691406,
    "critic_loss": 336.66009521484375,
    "ent_coef": 0.08030495047569275,
    "learning_rate": 0.001
  },
  {
    "episode": 3642,
    "reward": 87.515338,
    "length": 67,
    "time": 57881.768172,
    "actor_loss": -62.76769256591797,
    "critic_loss": 8.821117401123047,
    "ent_coef": 0.08183438330888748,
    "learning_rate": 0.001
  },
  {
    "episode": 3643,
    "reward": 89.098869,
    "length": 65,
    "time": 57894.699266,
    "actor_loss": -65.06852722167969,
    "critic_loss": 3.19236159324646,
    "ent_coef": 0.08101971447467804,
    "learning_rate": 0.001
  },
  {
    "episode": 3644,
    "reward": 89.027094,
    "length": 66,
    "time": 57906.188267,
    "actor_loss": -59.73981475830078,
    "critic_loss": 3.178997278213501,
    "ent_coef": 0.08068932592868805,
    "learning_rate": 0.001
  },
  {
    "episode": 3645,
    "reward": 88.757093,
    "length": 64,
    "time": 57920.561638,
    "actor_loss": -65.06022644042969,
    "critic_loss": 13.828397750854492,
    "ent_coef": 0.08042845875024796,
    "learning_rate": 0.001
  },
  {
    "episode": 3646,
    "reward": 84.817105,
    "length": 84,
    "time": 57934.920183,
    "actor_loss": -64.33399963378906,
    "critic_loss": 5.002856254577637,
    "ent_coef": 0.08080838620662689,
    "learning_rate": 0.001
  },
  {
    "episode": 3647,
    "reward": 83.974972,
    "length": 73,
    "time": 57947.485116,
    "actor_loss": -61.47087860107422,
    "critic_loss": 2.772829532623291,
    "ent_coef": 0.08164402842521667,
    "learning_rate": 0.001
  },
  {
    "episode": 3648,
    "reward": 86.510011,
    "length": 68,
    "time": 57961.125482,
    "actor_loss": -66.30815887451172,
    "critic_loss": 31.89623260498047,
    "ent_coef": 0.08308593928813934,
    "learning_rate": 0.001
  },
  {
    "episode": 3649,
    "reward": 87.492727,
    "length": 66,
    "time": 57974.714729,
    "actor_loss": -72.491455078125,
    "critic_loss": 129.93154907226562,
    "ent_coef": 0.08669936656951904,
    "learning_rate": 0.001
  },
  {
    "episode": 3650,
    "reward": 84.748714,
    "length": 81,
    "time": 57991.73953,
    "actor_loss": -63.43161392211914,
    "critic_loss": 10.252704620361328,
    "ent_coef": 0.0883699283003807,
    "learning_rate": 0.001
  },
  {
    "episode": 3651,
    "reward": 87.929127,
    "length": 66,
    "time": 58003.376516,
    "actor_loss": -62.33876037597656,
    "critic_loss": 4.075055122375488,
    "ent_coef": 0.08507366478443146,
    "learning_rate": 0.001
  },
  {
    "episode": 3652,
    "reward": 84.360463,
    "length": 78,
    "time": 58018.098799,
    "actor_loss": -70.77742004394531,
    "critic_loss": 2.509042263031006,
    "ent_coef": 0.08574652671813965,
    "learning_rate": 0.001
  },
  {
    "episode": 3653,
    "reward": 88.254972,
    "length": 66,
    "time": 58029.506205,
    "actor_loss": -60.75987243652344,
    "critic_loss": 4.132720470428467,
    "ent_coef": 0.08434602618217468,
    "learning_rate": 0.001
  },
  {
    "episode": 3654,
    "reward": 85.914544,
    "length": 68,
    "time": 58042.210669,
    "actor_loss": -66.51847839355469,
    "critic_loss": 16.978086471557617,
    "ent_coef": 0.08442088216543198,
    "learning_rate": 0.001
  },
  {
    "episode": 3655,
    "reward": 88.277003,
    "length": 67,
    "time": 58054.736853,
    "actor_loss": -68.92181396484375,
    "critic_loss": 2.3749537467956543,
    "ent_coef": 0.08281315863132477,
    "learning_rate": 0.001
  },
  {
    "episode": 3656,
    "reward": 88.925052,
    "length": 65,
    "time": 58067.567506,
    "actor_loss": -73.49240112304688,
    "critic_loss": 7.9254655838012695,
    "ent_coef": 0.08351938426494598,
    "learning_rate": 0.001
  },
  {
    "episode": 3657,
    "reward": 83.568872,
    "length": 91,
    "time": 58082.427862,
    "actor_loss": -62.096805572509766,
    "critic_loss": 42.346702575683594,
    "ent_coef": 0.07995419949293137,
    "learning_rate": 0.001
  },
  {
    "episode": 3658,
    "reward": 86.192471,
    "length": 74,
    "time": 58095.139996,
    "actor_loss": -65.23816680908203,
    "critic_loss": 4.479766845703125,
    "ent_coef": 0.0767989531159401,
    "learning_rate": 0.001
  },
  {
    "episode": 3659,
    "reward": 88.149178,
    "length": 66,
    "time": 58106.754569,
    "actor_loss": -63.53416061401367,
    "critic_loss": 9.622153282165527,
    "ent_coef": 0.07663414627313614,
    "learning_rate": 0.001
  },
  {
    "episode": 3660,
    "reward": 89.332018,
    "length": 64,
    "time": 58124.25858,
    "actor_loss": -65.21953582763672,
    "critic_loss": 3.8943653106689453,
    "ent_coef": 0.07755313068628311,
    "learning_rate": 0.001
  },
  {
    "episode": 3661,
    "reward": 85.618624,
    "length": 76,
    "time": 58139.286686,
    "actor_loss": -64.66032409667969,
    "critic_loss": 3.329904556274414,
    "ent_coef": 0.07598736137151718,
    "learning_rate": 0.001
  },
  {
    "episode": 3662,
    "reward": 87.558987,
    "length": 68,
    "time": 58150.941082,
    "actor_loss": -72.0501708984375,
    "critic_loss": 18.78716278076172,
    "ent_coef": 0.07529670000076294,
    "learning_rate": 0.001
  },
  {
    "episode": 3663,
    "reward": 82.270308,
    "length": 79,
    "time": 58165.339014,
    "actor_loss": -68.0411376953125,
    "critic_loss": 3.231210708618164,
    "ent_coef": 0.07792270183563232,
    "learning_rate": 0.001
  },
  {
    "episode": 3664,
    "reward": 85.999382,
    "length": 71,
    "time": 58179.606485,
    "actor_loss": -65.81766510009766,
    "critic_loss": 3.2835640907287598,
    "ent_coef": 0.07758661359548569,
    "learning_rate": 0.001
  },
  {
    "episode": 3665,
    "reward": 85.983146,
    "length": 70,
    "time": 58197.829181,
    "actor_loss": -60.605045318603516,
    "critic_loss": 15.609676361083984,
    "ent_coef": 0.07631723582744598,
    "learning_rate": 0.001
  },
  {
    "episode": 3666,
    "reward": 87.006275,
    "length": 67,
    "time": 58212.016069,
    "actor_loss": -69.45632934570312,
    "critic_loss": 37.29704284667969,
    "ent_coef": 0.07601532340049744,
    "learning_rate": 0.001
  },
  {
    "episode": 3667,
    "reward": 85.30191,
    "length": 70,
    "time": 58225.33689,
    "actor_loss": -66.31071472167969,
    "critic_loss": 2.7565340995788574,
    "ent_coef": 0.07630052417516708,
    "learning_rate": 0.001
  },
  {
    "episode": 3668,
    "reward": 89.980172,
    "length": 64,
    "time": 58247.850332,
    "actor_loss": -59.569515228271484,
    "critic_loss": 129.10556030273438,
    "ent_coef": 0.07843104004859924,
    "learning_rate": 0.001
  },
  {
    "episode": 3669,
    "reward": 89.80267,
    "length": 64,
    "time": 58259.343455,
    "actor_loss": -67.69506072998047,
    "critic_loss": 4.74166202545166,
    "ent_coef": 0.07840590924024582,
    "learning_rate": 0.001
  },
  {
    "episode": 3670,
    "reward": 89.944572,
    "length": 64,
    "time": 58270.667266,
    "actor_loss": -68.85791015625,
    "critic_loss": 2.069396734237671,
    "ent_coef": 0.07504913210868835,
    "learning_rate": 0.001
  },
  {
    "episode": 3671,
    "reward": 82.815789,
    "length": 77,
    "time": 58285.669614,
    "actor_loss": -72.26054382324219,
    "critic_loss": 1.599881649017334,
    "ent_coef": 0.06990139931440353,
    "learning_rate": 0.001
  },
  {
    "episode": 3672,
    "reward": 85.391699,
    "length": 70,
    "time": 58302.531804,
    "actor_loss": -66.51669311523438,
    "critic_loss": 2.525752067565918,
    "ent_coef": 0.06683148443698883,
    "learning_rate": 0.001
  },
  {
    "episode": 3673,
    "reward": 87.40301,
    "length": 67,
    "time": 58314.964504,
    "actor_loss": -63.37090301513672,
    "critic_loss": 2.313236951828003,
    "ent_coef": 0.06798627972602844,
    "learning_rate": 0.001
  },
  {
    "episode": 3674,
    "reward": 90.909831,
    "length": 61,
    "time": 58327.578939,
    "actor_loss": -64.06175231933594,
    "critic_loss": 9.16659927368164,
    "ent_coef": 0.07107111811637878,
    "learning_rate": 0.001
  },
  {
    "episode": 3675,
    "reward": 88.576099,
    "length": 66,
    "time": 58340.486239,
    "actor_loss": -67.818359375,
    "critic_loss": 45.24561309814453,
    "ent_coef": 0.07175570726394653,
    "learning_rate": 0.001
  },
  {
    "episode": 3676,
    "reward": 91.10493,
    "length": 61,
    "time": 58351.999604,
    "actor_loss": -63.70838928222656,
    "critic_loss": 16.685832977294922,
    "ent_coef": 0.07247768342494965,
    "learning_rate": 0.001
  },
  {
    "episode": 3677,
    "reward": 88.347889,
    "length": 66,
    "time": 58367.655532,
    "actor_loss": -71.35896301269531,
    "critic_loss": 2.3755757808685303,
    "ent_coef": 0.07151172310113907,
    "learning_rate": 0.001
  },
  {
    "episode": 3678,
    "reward": 88.785992,
    "length": 65,
    "time": 58380.863952,
    "actor_loss": -63.31959533691406,
    "critic_loss": 4.287772178649902,
    "ent_coef": 0.07195553183555603,
    "learning_rate": 0.001
  },
  {
    "episode": 3679,
    "reward": 80.498287,
    "length": 84,
    "time": 58397.087612,
    "actor_loss": -70.24312591552734,
    "critic_loss": 3.364784002304077,
    "ent_coef": 0.06630592048168182,
    "learning_rate": 0.001
  },
  {
    "episode": 3680,
    "reward": 81.083618,
    "length": 90,
    "time": 58411.793823,
    "actor_loss": -67.69087982177734,
    "critic_loss": 3.288968801498413,
    "ent_coef": 0.06895153224468231,
    "learning_rate": 0.001
  },
  {
    "episode": 3681,
    "reward": 87.959558,
    "length": 68,
    "time": 58428.063176,
    "actor_loss": -68.68682861328125,
    "critic_loss": 3.841078281402588,
    "ent_coef": 0.0707792416214943,
    "learning_rate": 0.001
  },
  {
    "episode": 3682,
    "reward": 87.593917,
    "length": 66,
    "time": 58440.411106,
    "actor_loss": -66.81827545166016,
    "critic_loss": 3.034235715866089,
    "ent_coef": 0.07138878107070923,
    "learning_rate": 0.001
  },
  {
    "episode": 3683,
    "reward": 83.178644,
    "length": 75,
    "time": 58453.835881,
    "actor_loss": -66.74737548828125,
    "critic_loss": 3.7096400260925293,
    "ent_coef": 0.0731290727853775,
    "learning_rate": 0.001
  },
  {
    "episode": 3684,
    "reward": 86.894819,
    "length": 69,
    "time": 58470.458225,
    "actor_loss": -63.06642150878906,
    "critic_loss": 2.776808738708496,
    "ent_coef": 0.07050524652004242,
    "learning_rate": 0.001
  },
  {
    "episode": 3685,
    "reward": 87.448999,
    "length": 68,
    "time": 58484.955596,
    "actor_loss": -63.02410125732422,
    "critic_loss": 2.495089054107666,
    "ent_coef": 0.06776034086942673,
    "learning_rate": 0.001
  },
  {
    "episode": 3686,
    "reward": 87.707985,
    "length": 66,
    "time": 58496.428808,
    "actor_loss": -58.246055603027344,
    "critic_loss": 3.779075860977173,
    "ent_coef": 0.0673167034983635,
    "learning_rate": 0.001
  },
  {
    "episode": 3687,
    "reward": 87.974996,
    "length": 70,
    "time": 58508.325932,
    "actor_loss": -68.64996337890625,
    "critic_loss": 31.717973709106445,
    "ent_coef": 0.06963107734918594,
    "learning_rate": 0.001
  },
  {
    "episode": 3688,
    "reward": 86.571849,
    "length": 71,
    "time": 58520.239969,
    "actor_loss": -61.02918243408203,
    "critic_loss": 3.7062792778015137,
    "ent_coef": 0.06714454293251038,
    "learning_rate": 0.001
  },
  {
    "episode": 3689,
    "reward": 83.758342,
    "length": 73,
    "time": 58534.414486,
    "actor_loss": -63.160377502441406,
    "critic_loss": 2.612481117248535,
    "ent_coef": 0.06572951376438141,
    "learning_rate": 0.001
  },
  {
    "episode": 3690,
    "reward": 88.075424,
    "length": 68,
    "time": 58547.994002,
    "actor_loss": -69.3887939453125,
    "critic_loss": 21.944366455078125,
    "ent_coef": 0.06673967093229294,
    "learning_rate": 0.001
  },
  {
    "episode": 3691,
    "reward": 87.557856,
    "length": 67,
    "time": 58559.973552,
    "actor_loss": -66.80325317382812,
    "critic_loss": 59.50190353393555,
    "ent_coef": 0.06575573235750198,
    "learning_rate": 0.001
  },
  {
    "episode": 3692,
    "reward": 86.703861,
    "length": 68,
    "time": 58571.766017,
    "actor_loss": -66.16593933105469,
    "critic_loss": 2.4192800521850586,
    "ent_coef": 0.06715387105941772,
    "learning_rate": 0.001
  },
  {
    "episode": 3693,
    "reward": 86.108948,
    "length": 69,
    "time": 58587.994653,
    "actor_loss": -64.18515014648438,
    "critic_loss": 2.571739673614502,
    "ent_coef": 0.06996027380228043,
    "learning_rate": 0.001
  },
  {
    "episode": 3694,
    "reward": 85.222237,
    "length": 78,
    "time": 58603.258443,
    "actor_loss": -62.72461700439453,
    "critic_loss": 4.95475959777832,
    "ent_coef": 0.07406868785619736,
    "learning_rate": 0.001
  },
  {
    "episode": 3695,
    "reward": 83.584345,
    "length": 74,
    "time": 58616.315598,
    "actor_loss": -62.70484924316406,
    "critic_loss": 11.887932777404785,
    "ent_coef": 0.07175441086292267,
    "learning_rate": 0.001
  },
  {
    "episode": 3696,
    "reward": 87.601133,
    "length": 67,
    "time": 58630.617336,
    "actor_loss": -63.930198669433594,
    "critic_loss": 2.539109706878662,
    "ent_coef": 0.07110855728387833,
    "learning_rate": 0.001
  },
  {
    "episode": 3697,
    "reward": 88.857687,
    "length": 65,
    "time": 58643.341962,
    "actor_loss": -65.42982482910156,
    "critic_loss": 5.693645000457764,
    "ent_coef": 0.07262997329235077,
    "learning_rate": 0.001
  },
  {
    "episode": 3698,
    "reward": 89.890268,
    "length": 62,
    "time": 58656.308716,
    "actor_loss": -68.09088134765625,
    "critic_loss": 2.5165772438049316,
    "ent_coef": 0.07568665593862534,
    "learning_rate": 0.001
  },
  {
    "episode": 3699,
    "reward": 86.955555,
    "length": 71,
    "time": 58670.040321,
    "actor_loss": -62.57682800292969,
    "critic_loss": 3.391367197036743,
    "ent_coef": 0.07778331637382507,
    "learning_rate": 0.001
  },
  {
    "episode": 3700,
    "reward": 80.562364,
    "length": 79,
    "time": 58685.514682,
    "actor_loss": -64.24102783203125,
    "critic_loss": 2.605130672454834,
    "ent_coef": 0.07538683712482452,
    "learning_rate": 0.001
  },
  {
    "episode": 3701,
    "reward": 81.00697,
    "length": 77,
    "time": 58701.39777,
    "actor_loss": -67.07807922363281,
    "critic_loss": 5.421773910522461,
    "ent_coef": 0.07228238880634308,
    "learning_rate": 0.001
  },
  {
    "episode": 3702,
    "reward": 89.255072,
    "length": 64,
    "time": 58715.272006,
    "actor_loss": -70.50906372070312,
    "critic_loss": 25.45376205444336,
    "ent_coef": 0.07378021627664566,
    "learning_rate": 0.001
  },
  {
    "episode": 3703,
    "reward": 86.346844,
    "length": 69,
    "time": 58730.963803,
    "actor_loss": -74.83161926269531,
    "critic_loss": 5.329553604125977,
    "ent_coef": 0.07338815182447433,
    "learning_rate": 0.001
  },
  {
    "episode": 3704,
    "reward": 87.129869,
    "length": 67,
    "time": 58742.763112,
    "actor_loss": -58.528690338134766,
    "critic_loss": 2.5754330158233643,
    "ent_coef": 0.07118126004934311,
    "learning_rate": 0.001
  },
  {
    "episode": 3705,
    "reward": 88.244252,
    "length": 66,
    "time": 58754.439225,
    "actor_loss": -70.45225524902344,
    "critic_loss": 3.028038501739502,
    "ent_coef": 0.07022277265787125,
    "learning_rate": 0.001
  },
  {
    "episode": 3706,
    "reward": 90.37968,
    "length": 64,
    "time": 58767.660117,
    "actor_loss": -64.69188690185547,
    "critic_loss": 4.102397441864014,
    "ent_coef": 0.06960831582546234,
    "learning_rate": 0.001
  },
  {
    "episode": 3707,
    "reward": 89.390623,
    "length": 65,
    "time": 58780.104835,
    "actor_loss": -65.83433532714844,
    "critic_loss": 15.506301879882812,
    "ent_coef": 0.07376820594072342,
    "learning_rate": 0.001
  },
  {
    "episode": 3708,
    "reward": 89.127753,
    "length": 64,
    "time": 58793.410628,
    "actor_loss": -68.16484832763672,
    "critic_loss": 12.381049156188965,
    "ent_coef": 0.0808412954211235,
    "learning_rate": 0.001
  },
  {
    "episode": 3709,
    "reward": 87.566097,
    "length": 66,
    "time": 58806.115381,
    "actor_loss": -65.39169311523438,
    "critic_loss": 7.331160545349121,
    "ent_coef": 0.08319073915481567,
    "learning_rate": 0.001
  },
  {
    "episode": 3710,
    "reward": 89.704234,
    "length": 63,
    "time": 58820.375451,
    "actor_loss": -63.611698150634766,
    "critic_loss": 3.1039845943450928,
    "ent_coef": 0.0849255919456482,
    "learning_rate": 0.001
  },
  {
    "episode": 3711,
    "reward": 88.53861,
    "length": 66,
    "time": 58832.338674,
    "actor_loss": -63.899864196777344,
    "critic_loss": 307.3101501464844,
    "ent_coef": 0.0841090977191925,
    "learning_rate": 0.001
  },
  {
    "episode": 3712,
    "reward": 84.351882,
    "length": 73,
    "time": 58846.74818,
    "actor_loss": -63.561363220214844,
    "critic_loss": 27.831378936767578,
    "ent_coef": 0.08195620030164719,
    "learning_rate": 0.001
  },
  {
    "episode": 3713,
    "reward": 84.203053,
    "length": 72,
    "time": 58858.988392,
    "actor_loss": -71.0479736328125,
    "critic_loss": 3.042965888977051,
    "ent_coef": 0.0803006961941719,
    "learning_rate": 0.001
  },
  {
    "episode": 3714,
    "reward": 86.942805,
    "length": 68,
    "time": 58871.697864,
    "actor_loss": -65.40591430664062,
    "critic_loss": 3.8016433715820312,
    "ent_coef": 0.08099929988384247,
    "learning_rate": 0.001
  },
  {
    "episode": 3715,
    "reward": 85.201857,
    "length": 70,
    "time": 58885.573411,
    "actor_loss": -70.63200378417969,
    "critic_loss": 3.2244277000427246,
    "ent_coef": 0.08015958964824677,
    "learning_rate": 0.001
  },
  {
    "episode": 3716,
    "reward": 83.477621,
    "length": 74,
    "time": 58898.938788,
    "actor_loss": -65.75588989257812,
    "critic_loss": 2.0436885356903076,
    "ent_coef": 0.07669150829315186,
    "learning_rate": 0.001
  },
  {
    "episode": 3717,
    "reward": 86.410671,
    "length": 69,
    "time": 58911.041845,
    "actor_loss": -66.49828338623047,
    "critic_loss": 3.7645938396453857,
    "ent_coef": 0.07386797666549683,
    "learning_rate": 0.001
  },
  {
    "episode": 3718,
    "reward": 85.776205,
    "length": 75,
    "time": 58924.269146,
    "actor_loss": -68.81002807617188,
    "critic_loss": 9.20266056060791,
    "ent_coef": 0.07078195363283157,
    "learning_rate": 0.001
  },
  {
    "episode": 3719,
    "reward": 84.448853,
    "length": 72,
    "time": 58937.55603,
    "actor_loss": -65.42106628417969,
    "critic_loss": 2.8041272163391113,
    "ent_coef": 0.06818677484989166,
    "learning_rate": 0.001
  },
  {
    "episode": 3720,
    "reward": 85.925103,
    "length": 69,
    "time": 58953.0354,
    "actor_loss": -64.3690185546875,
    "critic_loss": 2.6321539878845215,
    "ent_coef": 0.0692201778292656,
    "learning_rate": 0.001
  },
  {
    "episode": 3721,
    "reward": 88.243903,
    "length": 66,
    "time": 58964.702256,
    "actor_loss": -65.82821655273438,
    "critic_loss": 5.233339309692383,
    "ent_coef": 0.07047763466835022,
    "learning_rate": 0.001
  },
  {
    "episode": 3722,
    "reward": 86.595301,
    "length": 67,
    "time": 58977.216303,
    "actor_loss": -66.80711364746094,
    "critic_loss": 43.74789047241211,
    "ent_coef": 0.06933189928531647,
    "learning_rate": 0.001
  },
  {
    "episode": 3723,
    "reward": 86.844097,
    "length": 68,
    "time": 58988.773833,
    "actor_loss": -67.65440368652344,
    "critic_loss": 12.42625904083252,
    "ent_coef": 0.07006128132343292,
    "learning_rate": 0.001
  },
  {
    "episode": 3724,
    "reward": 87.546759,
    "length": 66,
    "time": 59001.428354,
    "actor_loss": -63.130943298339844,
    "critic_loss": 10.843538284301758,
    "ent_coef": 0.06998617947101593,
    "learning_rate": 0.001
  },
  {
    "episode": 3725,
    "reward": 87.651232,
    "length": 66,
    "time": 59015.51253,
    "actor_loss": -67.82414245605469,
    "critic_loss": 3.8783178329467773,
    "ent_coef": 0.06893441826105118,
    "learning_rate": 0.001
  },
  {
    "episode": 3726,
    "reward": 88.441987,
    "length": 66,
    "time": 59028.226188,
    "actor_loss": -63.179962158203125,
    "critic_loss": 4.290795803070068,
    "ent_coef": 0.07011669129133224,
    "learning_rate": 0.001
  },
  {
    "episode": 3727,
    "reward": 87.52738,
    "length": 67,
    "time": 59039.96589,
    "actor_loss": -67.73509216308594,
    "critic_loss": 36.81431198120117,
    "ent_coef": 0.07062442600727081,
    "learning_rate": 0.001
  },
  {
    "episode": 3728,
    "reward": 87.574647,
    "length": 67,
    "time": 59052.464046,
    "actor_loss": -69.80264282226562,
    "critic_loss": 62.45510482788086,
    "ent_coef": 0.07029854506254196,
    "learning_rate": 0.001
  },
  {
    "episode": 3729,
    "reward": 85.454949,
    "length": 70,
    "time": 59065.247795,
    "actor_loss": -68.57234191894531,
    "critic_loss": 3.451578140258789,
    "ent_coef": 0.07102450728416443,
    "learning_rate": 0.001
  },
  {
    "episode": 3730,
    "reward": 88.809365,
    "length": 65,
    "time": 59076.637588,
    "actor_loss": -64.78611755371094,
    "critic_loss": 50.170677185058594,
    "ent_coef": 0.07174253463745117,
    "learning_rate": 0.001
  },
  {
    "episode": 3731,
    "reward": 80.524692,
    "length": 85,
    "time": 59090.962367,
    "actor_loss": -66.35099792480469,
    "critic_loss": 2.78544020652771,
    "ent_coef": 0.07227779924869537,
    "learning_rate": 0.001
  },
  {
    "episode": 3732,
    "reward": 84.377155,
    "length": 70,
    "time": 59102.917752,
    "actor_loss": -61.296836853027344,
    "critic_loss": 4.675448894500732,
    "ent_coef": 0.073288694024086,
    "learning_rate": 0.001
  },
  {
    "episode": 3733,
    "reward": 86.5188,
    "length": 69,
    "time": 59114.734931,
    "actor_loss": -65.4620590209961,
    "critic_loss": 4.003693103790283,
    "ent_coef": 0.07428343594074249,
    "learning_rate": 0.001
  },
  {
    "episode": 3734,
    "reward": 86.012779,
    "length": 69,
    "time": 59126.783443,
    "actor_loss": -71.34292602539062,
    "critic_loss": 3.3601932525634766,
    "ent_coef": 0.07233712077140808,
    "learning_rate": 0.001
  },
  {
    "episode": 3735,
    "reward": 89.009492,
    "length": 65,
    "time": 59138.909709,
    "actor_loss": -66.5330810546875,
    "critic_loss": 33.10193634033203,
    "ent_coef": 0.07393771409988403,
    "learning_rate": 0.001
  },
  {
    "episode": 3736,
    "reward": 90.520609,
    "length": 62,
    "time": 59150.865662,
    "actor_loss": -64.47891235351562,
    "critic_loss": 7.932150840759277,
    "ent_coef": 0.07977844029664993,
    "learning_rate": 0.001
  },
  {
    "episode": 3737,
    "reward": 87.085925,
    "length": 68,
    "time": 59163.182606,
    "actor_loss": -64.54052734375,
    "critic_loss": 83.89300537109375,
    "ent_coef": 0.07934781908988953,
    "learning_rate": 0.001
  },
  {
    "episode": 3738,
    "reward": 88.721578,
    "length": 65,
    "time": 59174.677061,
    "actor_loss": -63.5804443359375,
    "critic_loss": 3.0657734870910645,
    "ent_coef": 0.08102019876241684,
    "learning_rate": 0.001
  },
  {
    "episode": 3739,
    "reward": 84.083937,
    "length": 73,
    "time": 59187.987656,
    "actor_loss": -54.855430603027344,
    "critic_loss": 8.563793182373047,
    "ent_coef": 0.07719862461090088,
    "learning_rate": 0.001
  },
  {
    "episode": 3740,
    "reward": 88.809206,
    "length": 64,
    "time": 59199.240504,
    "actor_loss": -70.52745056152344,
    "critic_loss": 40.21330261230469,
    "ent_coef": 0.07455454766750336,
    "learning_rate": 0.001
  },
  {
    "episode": 3741,
    "reward": 88.179002,
    "length": 67,
    "time": 59213.329897,
    "actor_loss": -62.96678924560547,
    "critic_loss": 4.8776092529296875,
    "ent_coef": 0.071965791285038,
    "learning_rate": 0.001
  },
  {
    "episode": 3742,
    "reward": 89.295502,
    "length": 64,
    "time": 59225.266323,
    "actor_loss": -67.94749450683594,
    "critic_loss": 115.62471008300781,
    "ent_coef": 0.07391676306724548,
    "learning_rate": 0.001
  },
  {
    "episode": 3743,
    "reward": 86.485982,
    "length": 70,
    "time": 59238.105835,
    "actor_loss": -71.41124725341797,
    "critic_loss": 27.888553619384766,
    "ent_coef": 0.07517486810684204,
    "learning_rate": 0.001
  },
  {
    "episode": 3744,
    "reward": 84.51413,
    "length": 71,
    "time": 59251.711506,
    "actor_loss": -63.65733337402344,
    "critic_loss": 3.49725604057312,
    "ent_coef": 0.07148439437150955,
    "learning_rate": 0.001
  },
  {
    "episode": 3745,
    "reward": 82.222589,
    "length": 81,
    "time": 59266.447176,
    "actor_loss": -62.456077575683594,
    "critic_loss": 5.741921901702881,
    "ent_coef": 0.07159209251403809,
    "learning_rate": 0.001
  },
  {
    "episode": 3746,
    "reward": 86.93826,
    "length": 67,
    "time": 59281.068978,
    "actor_loss": -68.31664276123047,
    "critic_loss": 46.43340301513672,
    "ent_coef": 0.07373401522636414,
    "learning_rate": 0.001
  },
  {
    "episode": 3747,
    "reward": 89.199702,
    "length": 64,
    "time": 59292.336788,
    "actor_loss": -67.22854614257812,
    "critic_loss": 4.385106563568115,
    "ent_coef": 0.08172786980867386,
    "learning_rate": 0.001
  },
  {
    "episode": 3748,
    "reward": 85.162677,
    "length": 77,
    "time": 59306.462903,
    "actor_loss": -69.36510467529297,
    "critic_loss": 1.6884706020355225,
    "ent_coef": 0.08226153999567032,
    "learning_rate": 0.001
  },
  {
    "episode": 3749,
    "reward": 88.221462,
    "length": 66,
    "time": 59321.230803,
    "actor_loss": -57.23228454589844,
    "critic_loss": 11.704980850219727,
    "ent_coef": 0.08110649138689041,
    "learning_rate": 0.001
  },
  {
    "episode": 3750,
    "reward": 87.026391,
    "length": 69,
    "time": 59333.225955,
    "actor_loss": -65.4854507446289,
    "critic_loss": 39.497947692871094,
    "ent_coef": 0.0795801505446434,
    "learning_rate": 0.001
  },
  {
    "episode": 3751,
    "reward": 85.681651,
    "length": 68,
    "time": 59349.055727,
    "actor_loss": -64.46894073486328,
    "critic_loss": 2.3868064880371094,
    "ent_coef": 0.07981184870004654,
    "learning_rate": 0.001
  },
  {
    "episode": 3752,
    "reward": 84.484224,
    "length": 72,
    "time": 59362.94378,
    "actor_loss": -69.11141967773438,
    "critic_loss": 10.01620864868164,
    "ent_coef": 0.07945796102285385,
    "learning_rate": 0.001
  },
  {
    "episode": 3753,
    "reward": 89.100521,
    "length": 66,
    "time": 59374.384954,
    "actor_loss": -62.86771011352539,
    "critic_loss": 22.78329849243164,
    "ent_coef": 0.08164552599191666,
    "learning_rate": 0.001
  },
  {
    "episode": 3754,
    "reward": 87.552215,
    "length": 69,
    "time": 59386.077782,
    "actor_loss": -66.30615234375,
    "critic_loss": 3.6221728324890137,
    "ent_coef": 0.08340246230363846,
    "learning_rate": 0.001
  },
  {
    "episode": 3755,
    "reward": 85.846475,
    "length": 70,
    "time": 59400.290108,
    "actor_loss": -60.070552825927734,
    "critic_loss": 88.2406234741211,
    "ent_coef": 0.08211271464824677,
    "learning_rate": 0.001
  },
  {
    "episode": 3756,
    "reward": 88.122148,
    "length": 66,
    "time": 59412.704381,
    "actor_loss": -66.83265686035156,
    "critic_loss": 62.11103820800781,
    "ent_coef": 0.0805254727602005,
    "learning_rate": 0.001
  },
  {
    "episode": 3757,
    "reward": 86.877967,
    "length": 68,
    "time": 59424.947834,
    "actor_loss": -63.51263427734375,
    "critic_loss": 2.542160987854004,
    "ent_coef": 0.07784183323383331,
    "learning_rate": 0.001
  },
  {
    "episode": 3758,
    "reward": 84.839174,
    "length": 71,
    "time": 59439.201473,
    "actor_loss": -65.20963287353516,
    "critic_loss": 4.988595962524414,
    "ent_coef": 0.07470961660146713,
    "learning_rate": 0.001
  },
  {
    "episode": 3759,
    "reward": 88.536956,
    "length": 66,
    "time": 59451.141017,
    "actor_loss": -67.22087097167969,
    "critic_loss": 15.08159065246582,
    "ent_coef": 0.0753844827413559,
    "learning_rate": 0.001
  },
  {
    "episode": 3760,
    "reward": 87.988079,
    "length": 66,
    "time": 59463.447967,
    "actor_loss": -66.15925598144531,
    "critic_loss": 17.31960678100586,
    "ent_coef": 0.0742940753698349,
    "learning_rate": 0.001
  },
  {
    "episode": 3761,
    "reward": 88.182021,
    "length": 68,
    "time": 59478.112658,
    "actor_loss": -64.20928955078125,
    "critic_loss": 4.697933197021484,
    "ent_coef": 0.07667098939418793,
    "learning_rate": 0.001
  },
  {
    "episode": 3762,
    "reward": 84.970217,
    "length": 70,
    "time": 59493.047216,
    "actor_loss": -59.48277282714844,
    "critic_loss": 8.559625625610352,
    "ent_coef": 0.0777391791343689,
    "learning_rate": 0.001
  },
  {
    "episode": 3763,
    "reward": 86.131946,
    "length": 70,
    "time": 59506.962603,
    "actor_loss": -60.61065673828125,
    "critic_loss": 2.8245339393615723,
    "ent_coef": 0.07471611350774765,
    "learning_rate": 0.001
  },
  {
    "episode": 3764,
    "reward": 86.323684,
    "length": 69,
    "time": 59519.956863,
    "actor_loss": -61.449913024902344,
    "critic_loss": 3.740074634552002,
    "ent_coef": 0.07200890779495239,
    "learning_rate": 0.001
  },
  {
    "episode": 3765,
    "reward": 88.374072,
    "length": 66,
    "time": 59531.851136,
    "actor_loss": -66.09307861328125,
    "critic_loss": 120.37184143066406,
    "ent_coef": 0.07053831964731216,
    "learning_rate": 0.001
  },
  {
    "episode": 3766,
    "reward": 88.67978,
    "length": 65,
    "time": 59544.024024,
    "actor_loss": -61.2215461730957,
    "critic_loss": 3.320746421813965,
    "ent_coef": 0.06953351199626923,
    "learning_rate": 0.001
  },
  {
    "episode": 3767,
    "reward": 81.969583,
    "length": 90,
    "time": 59561.68728,
    "actor_loss": -69.74796295166016,
    "critic_loss": 3.773749351501465,
    "ent_coef": 0.0689297541975975,
    "learning_rate": 0.001
  },
  {
    "episode": 3768,
    "reward": 83.794029,
    "length": 72,
    "time": 59575.719098,
    "actor_loss": -64.23371887207031,
    "critic_loss": 15.930243492126465,
    "ent_coef": 0.07234900444746017,
    "learning_rate": 0.001
  },
  {
    "episode": 3769,
    "reward": 88.649006,
    "length": 65,
    "time": 59586.901964,
    "actor_loss": -64.41754150390625,
    "critic_loss": 2.8192968368530273,
    "ent_coef": 0.07337731868028641,
    "learning_rate": 0.001
  },
  {
    "episode": 3770,
    "reward": 83.257177,
    "length": 73,
    "time": 59599.921458,
    "actor_loss": -66.44393920898438,
    "critic_loss": 7.271736145019531,
    "ent_coef": 0.07254920154809952,
    "learning_rate": 0.001
  },
  {
    "episode": 3771,
    "reward": 89.359467,
    "length": 64,
    "time": 59615.360075,
    "actor_loss": -66.743408203125,
    "critic_loss": 43.88031005859375,
    "ent_coef": 0.07391452044248581,
    "learning_rate": 0.001
  },
  {
    "episode": 3772,
    "reward": 83.311246,
    "length": 91,
    "time": 59632.208982,
    "actor_loss": -66.20022583007812,
    "critic_loss": 1.704122543334961,
    "ent_coef": 0.07353008538484573,
    "learning_rate": 0.001
  },
  {
    "episode": 3773,
    "reward": 73.930696,
    "length": 94,
    "time": 59647.523824,
    "actor_loss": -61.04766845703125,
    "critic_loss": 5.05704402923584,
    "ent_coef": 0.07322947680950165,
    "learning_rate": 0.001
  },
  {
    "episode": 3774,
    "reward": 83.680398,
    "length": 80,
    "time": 59661.724924,
    "actor_loss": -71.14903259277344,
    "critic_loss": 36.295654296875,
    "ent_coef": 0.07736153155565262,
    "learning_rate": 0.001
  },
  {
    "episode": 3775,
    "reward": 78.563882,
    "length": 103,
    "time": 59680.305233,
    "actor_loss": -67.51266479492188,
    "critic_loss": 4.774516582489014,
    "ent_coef": 0.08192916959524155,
    "learning_rate": 0.001
  },
  {
    "episode": 3776,
    "reward": 86.713848,
    "length": 72,
    "time": 59694.291977,
    "actor_loss": -60.5097770690918,
    "critic_loss": 36.96391296386719,
    "ent_coef": 0.08840464055538177,
    "learning_rate": 0.001
  },
  {
    "episode": 3777,
    "reward": 89.982159,
    "length": 64,
    "time": 59708.386482,
    "actor_loss": -71.1720199584961,
    "critic_loss": 3.912644624710083,
    "ent_coef": 0.09129529446363449,
    "learning_rate": 0.001
  },
  {
    "episode": 3778,
    "reward": 88.882228,
    "length": 65,
    "time": 59720.499675,
    "actor_loss": -65.15015411376953,
    "critic_loss": 5.740342617034912,
    "ent_coef": 0.08933347463607788,
    "learning_rate": 0.001
  },
  {
    "episode": 3779,
    "reward": 89.916539,
    "length": 63,
    "time": 59731.955203,
    "actor_loss": -65.53021240234375,
    "critic_loss": 36.64313507080078,
    "ent_coef": 0.08670017868280411,
    "learning_rate": 0.001
  },
  {
    "episode": 3780,
    "reward": 85.864024,
    "length": 71,
    "time": 59743.933119,
    "actor_loss": -69.46786499023438,
    "critic_loss": 3.140489101409912,
    "ent_coef": 0.08110949397087097,
    "learning_rate": 0.001
  },
  {
    "episode": 3781,
    "reward": 83.718016,
    "length": 72,
    "time": 59756.455211,
    "actor_loss": -68.022216796875,
    "critic_loss": 3.7120096683502197,
    "ent_coef": 0.07909877598285675,
    "learning_rate": 0.001
  },
  {
    "episode": 3782,
    "reward": 87.186191,
    "length": 69,
    "time": 59768.187129,
    "actor_loss": -65.5516357421875,
    "critic_loss": 2.079019069671631,
    "ent_coef": 0.0780116617679596,
    "learning_rate": 0.001
  },
  {
    "episode": 3783,
    "reward": 82.05875,
    "length": 74,
    "time": 59781.376943,
    "actor_loss": -61.07258987426758,
    "critic_loss": 2.0988411903381348,
    "ent_coef": 0.07671765983104706,
    "learning_rate": 0.001
  },
  {
    "episode": 3784,
    "reward": 89.949478,
    "length": 63,
    "time": 59793.345567,
    "actor_loss": -63.79607391357422,
    "critic_loss": 29.47966766357422,
    "ent_coef": 0.07712922245264053,
    "learning_rate": 0.001
  },
  {
    "episode": 3785,
    "reward": 90.364371,
    "length": 63,
    "time": 59807.244494,
    "actor_loss": -64.21379089355469,
    "critic_loss": 4.627920150756836,
    "ent_coef": 0.07717888802289963,
    "learning_rate": 0.001
  },
  {
    "episode": 3786,
    "reward": 90.567371,
    "length": 62,
    "time": 59818.175246,
    "actor_loss": -65.08982849121094,
    "critic_loss": 3.206296443939209,
    "ent_coef": 0.07682280987501144,
    "learning_rate": 0.001
  },
  {
    "episode": 3787,
    "reward": 87.890164,
    "length": 67,
    "time": 59831.827625,
    "actor_loss": -66.33561706542969,
    "critic_loss": 194.65103149414062,
    "ent_coef": 0.08056017011404037,
    "learning_rate": 0.001
  },
  {
    "episode": 3788,
    "reward": 84.94834,
    "length": 71,
    "time": 59843.934613,
    "actor_loss": -64.79585266113281,
    "critic_loss": 4.300783157348633,
    "ent_coef": 0.07813681662082672,
    "learning_rate": 0.001
  },
  {
    "episode": 3789,
    "reward": 85.457722,
    "length": 70,
    "time": 59857.418617,
    "actor_loss": -68.55390930175781,
    "critic_loss": 18.124996185302734,
    "ent_coef": 0.07601270824670792,
    "learning_rate": 0.001
  },
  {
    "episode": 3790,
    "reward": 51.963249,
    "length": 116,
    "time": 59883.382978,
    "actor_loss": -63.14919662475586,
    "critic_loss": 15.401739120483398,
    "ent_coef": 0.07475151866674423,
    "learning_rate": 0.001
  },
  {
    "episode": 3791,
    "reward": 79.299937,
    "length": 111,
    "time": 59901.701058,
    "actor_loss": -70.04782104492188,
    "critic_loss": 8.725961685180664,
    "ent_coef": 0.07481417059898376,
    "learning_rate": 0.001
  },
  {
    "episode": 3792,
    "reward": 88.997332,
    "length": 64,
    "time": 59914.956904,
    "actor_loss": -65.87901306152344,
    "critic_loss": 5.54841423034668,
    "ent_coef": 0.07602766156196594,
    "learning_rate": 0.001
  },
  {
    "episode": 3793,
    "reward": 83.057261,
    "length": 73,
    "time": 59928.284544,
    "actor_loss": -59.83009719848633,
    "critic_loss": 81.02241516113281,
    "ent_coef": 0.07518889009952545,
    "learning_rate": 0.001
  },
  {
    "episode": 3794,
    "reward": 88.620279,
    "length": 65,
    "time": 59942.412466,
    "actor_loss": -62.52656173706055,
    "critic_loss": 3.0205628871917725,
    "ent_coef": 0.07762163132429123,
    "learning_rate": 0.001
  },
  {
    "episode": 3795,
    "reward": 86.111548,
    "length": 71,
    "time": 59955.401479,
    "actor_loss": -63.446556091308594,
    "critic_loss": 9.727222442626953,
    "ent_coef": 0.07832715660333633,
    "learning_rate": 0.001
  },
  {
    "episode": 3796,
    "reward": 85.847409,
    "length": 69,
    "time": 59968.3143,
    "actor_loss": -72.56134033203125,
    "critic_loss": 180.53192138671875,
    "ent_coef": 0.07806123048067093,
    "learning_rate": 0.001
  },
  {
    "episode": 3797,
    "reward": 88.830644,
    "length": 65,
    "time": 59981.478862,
    "actor_loss": -70.28868103027344,
    "critic_loss": 2.6576383113861084,
    "ent_coef": 0.08244708925485611,
    "learning_rate": 0.001
  },
  {
    "episode": 3798,
    "reward": 87.371117,
    "length": 66,
    "time": 59992.826719,
    "actor_loss": -55.88976287841797,
    "critic_loss": 11.475041389465332,
    "ent_coef": 0.08690397441387177,
    "learning_rate": 0.001
  },
  {
    "episode": 3799,
    "reward": 87.800988,
    "length": 66,
    "time": 60005.062469,
    "actor_loss": -60.2415771484375,
    "critic_loss": 2.6773955821990967,
    "ent_coef": 0.08511387556791306,
    "learning_rate": 0.001
  },
  {
    "episode": 3800,
    "reward": 89.155356,
    "length": 65,
    "time": 60020.615703,
    "actor_loss": -63.40534973144531,
    "critic_loss": 44.09638214111328,
    "ent_coef": 0.08433245122432709,
    "learning_rate": 0.001
  },
  {
    "episode": 3801,
    "reward": 87.611845,
    "length": 68,
    "time": 60033.356651,
    "actor_loss": -64.58316040039062,
    "critic_loss": 2.623030185699463,
    "ent_coef": 0.08318497240543365,
    "learning_rate": 0.001
  },
  {
    "episode": 3802,
    "reward": 85.353855,
    "length": 70,
    "time": 60048.185767,
    "actor_loss": -62.86052703857422,
    "critic_loss": 6.562373161315918,
    "ent_coef": 0.07886803895235062,
    "learning_rate": 0.001
  },
  {
    "episode": 3803,
    "reward": 89.830188,
    "length": 63,
    "time": 60060.215488,
    "actor_loss": -66.04663848876953,
    "critic_loss": 4.802386283874512,
    "ent_coef": 0.07574476301670074,
    "learning_rate": 0.001
  },
  {
    "episode": 3804,
    "reward": 88.244698,
    "length": 66,
    "time": 60071.568928,
    "actor_loss": -66.21125793457031,
    "critic_loss": 2.8616251945495605,
    "ent_coef": 0.07584073394536972,
    "learning_rate": 0.001
  },
  {
    "episode": 3805,
    "reward": 88.106804,
    "length": 66,
    "time": 60083.100686,
    "actor_loss": -57.37178039550781,
    "critic_loss": 2.1557488441467285,
    "ent_coef": 0.07702215015888214,
    "learning_rate": 0.001
  },
  {
    "episode": 3806,
    "reward": 87.993429,
    "length": 65,
    "time": 60096.864315,
    "actor_loss": -64.795166015625,
    "critic_loss": 35.6664924621582,
    "ent_coef": 0.079078808426857,
    "learning_rate": 0.001
  },
  {
    "episode": 3807,
    "reward": 88.847849,
    "length": 64,
    "time": 60108.393641,
    "actor_loss": -64.88016510009766,
    "critic_loss": 5.070690155029297,
    "ent_coef": 0.07946892827749252,
    "learning_rate": 0.001
  },
  {
    "episode": 3808,
    "reward": 90.011469,
    "length": 63,
    "time": 60121.363752,
    "actor_loss": -70.24641418457031,
    "critic_loss": 2.151663303375244,
    "ent_coef": 0.08127116411924362,
    "learning_rate": 0.001
  },
  {
    "episode": 3809,
    "reward": 88.936872,
    "length": 65,
    "time": 60133.757161,
    "actor_loss": -66.27987670898438,
    "critic_loss": 3.0981404781341553,
    "ent_coef": 0.08125969022512436,
    "learning_rate": 0.001
  },
  {
    "episode": 3810,
    "reward": 88.090471,
    "length": 66,
    "time": 60145.517299,
    "actor_loss": -59.77547836303711,
    "critic_loss": 39.31932830810547,
    "ent_coef": 0.07958974689245224,
    "learning_rate": 0.001
  },
  {
    "episode": 3811,
    "reward": 85.029238,
    "length": 69,
    "time": 60158.44588,
    "actor_loss": -66.03633117675781,
    "critic_loss": 5.419810771942139,
    "ent_coef": 0.07922989130020142,
    "learning_rate": 0.001
  },
  {
    "episode": 3812,
    "reward": 90.87604,
    "length": 62,
    "time": 60170.115148,
    "actor_loss": -65.59477233886719,
    "critic_loss": 3.3607537746429443,
    "ent_coef": 0.08422968536615372,
    "learning_rate": 0.001
  },
  {
    "episode": 3813,
    "reward": 78.218814,
    "length": 80,
    "time": 60183.246143,
    "actor_loss": -66.65876770019531,
    "critic_loss": 108.07310485839844,
    "ent_coef": 0.08079396933317184,
    "learning_rate": 0.001
  },
  {
    "episode": 3814,
    "reward": 85.577196,
    "length": 71,
    "time": 60196.623169,
    "actor_loss": -66.29733276367188,
    "critic_loss": 2.8638551235198975,
    "ent_coef": 0.08014146983623505,
    "learning_rate": 0.001
  },
  {
    "episode": 3815,
    "reward": 90.214644,
    "length": 62,
    "time": 60207.628098,
    "actor_loss": -66.71062469482422,
    "critic_loss": 2.8903584480285645,
    "ent_coef": 0.08216496556997299,
    "learning_rate": 0.001
  },
  {
    "episode": 3816,
    "reward": 88.265408,
    "length": 67,
    "time": 60221.854369,
    "actor_loss": -67.53666687011719,
    "critic_loss": 3.332573890686035,
    "ent_coef": 0.08019569516181946,
    "learning_rate": 0.001
  },
  {
    "episode": 3817,
    "reward": 88.225168,
    "length": 66,
    "time": 60235.240885,
    "actor_loss": -65.34327697753906,
    "critic_loss": 4.4752960205078125,
    "ent_coef": 0.07700400054454803,
    "learning_rate": 0.001
  },
  {
    "episode": 3818,
    "reward": 89.307207,
    "length": 65,
    "time": 60247.71217,
    "actor_loss": -65.74816131591797,
    "critic_loss": 16.443527221679688,
    "ent_coef": 0.07929734140634537,
    "learning_rate": 0.001
  },
  {
    "episode": 3819,
    "reward": 78.391517,
    "length": 80,
    "time": 60261.949674,
    "actor_loss": -62.37200927734375,
    "critic_loss": 4.172912120819092,
    "ent_coef": 0.08034951239824295,
    "learning_rate": 0.001
  },
  {
    "episode": 3820,
    "reward": 85.477137,
    "length": 69,
    "time": 60274.645718,
    "actor_loss": -62.44286346435547,
    "critic_loss": 2.598597288131714,
    "ent_coef": 0.07823707908391953,
    "learning_rate": 0.001
  },
  {
    "episode": 3821,
    "reward": 85.42195,
    "length": 71,
    "time": 60288.236362,
    "actor_loss": -66.72028350830078,
    "critic_loss": 4.448544979095459,
    "ent_coef": 0.07320378720760345,
    "learning_rate": 0.001
  },
  {
    "episode": 3822,
    "reward": 88.688067,
    "length": 66,
    "time": 60300.825948,
    "actor_loss": -63.97685623168945,
    "critic_loss": 3.3580234050750732,
    "ent_coef": 0.0701943188905716,
    "learning_rate": 0.001
  },
  {
    "episode": 3823,
    "reward": 88.580586,
    "length": 67,
    "time": 60313.273509,
    "actor_loss": -65.9758071899414,
    "critic_loss": 27.16294288635254,
    "ent_coef": 0.06907926499843597,
    "learning_rate": 0.001
  },
  {
    "episode": 3824,
    "reward": 89.296959,
    "length": 64,
    "time": 60324.823546,
    "actor_loss": -61.98103713989258,
    "critic_loss": 4.065927982330322,
    "ent_coef": 0.06758002936840057,
    "learning_rate": 0.001
  },
  {
    "episode": 3825,
    "reward": 86.091056,
    "length": 71,
    "time": 60337.137309,
    "actor_loss": -58.55706787109375,
    "critic_loss": 5.175848007202148,
    "ent_coef": 0.06313694268465042,
    "learning_rate": 0.001
  },
  {
    "episode": 3826,
    "reward": 86.932856,
    "length": 68,
    "time": 60349.619614,
    "actor_loss": -63.37406539916992,
    "critic_loss": 11.557809829711914,
    "ent_coef": 0.060655783861875534,
    "learning_rate": 0.001
  },
  {
    "episode": 3827,
    "reward": 85.330555,
    "length": 71,
    "time": 60363.683074,
    "actor_loss": -65.46958923339844,
    "critic_loss": 2.2392799854278564,
    "ent_coef": 0.05817810818552971,
    "learning_rate": 0.001
  },
  {
    "episode": 3828,
    "reward": 86.374854,
    "length": 69,
    "time": 60375.635087,
    "actor_loss": -63.79363250732422,
    "critic_loss": 22.715991973876953,
    "ent_coef": 0.05868062749505043,
    "learning_rate": 0.001
  },
  {
    "episode": 3829,
    "reward": 89.376958,
    "length": 65,
    "time": 60387.72354,
    "actor_loss": -65.44214630126953,
    "critic_loss": 21.248563766479492,
    "ent_coef": 0.059462770819664,
    "learning_rate": 0.001
  },
  {
    "episode": 3830,
    "reward": 89.476482,
    "length": 65,
    "time": 60401.450687,
    "actor_loss": -62.12163162231445,
    "critic_loss": 6.006749629974365,
    "ent_coef": 0.06096098944544792,
    "learning_rate": 0.001
  },
  {
    "episode": 3831,
    "reward": 89.703905,
    "length": 64,
    "time": 60413.501487,
    "actor_loss": -65.6669921875,
    "critic_loss": 3.72769832611084,
    "ent_coef": 0.06397043168544769,
    "learning_rate": 0.001
  },
  {
    "episode": 3832,
    "reward": 89.46341,
    "length": 64,
    "time": 60425.78643,
    "actor_loss": -65.65507507324219,
    "critic_loss": 3.543088912963867,
    "ent_coef": 0.0673554465174675,
    "learning_rate": 0.001
  },
  {
    "episode": 3833,
    "reward": 88.169484,
    "length": 66,
    "time": 60439.931367,
    "actor_loss": -69.83030700683594,
    "critic_loss": 3.8986690044403076,
    "ent_coef": 0.06756367534399033,
    "learning_rate": 0.001
  },
  {
    "episode": 3834,
    "reward": 88.329458,
    "length": 67,
    "time": 60453.86208,
    "actor_loss": -68.665771484375,
    "critic_loss": 2.840414524078369,
    "ent_coef": 0.07063879072666168,
    "learning_rate": 0.001
  },
  {
    "episode": 3835,
    "reward": 85.926798,
    "length": 71,
    "time": 60466.13278,
    "actor_loss": -64.31668090820312,
    "critic_loss": 5.441188812255859,
    "ent_coef": 0.06993532925844193,
    "learning_rate": 0.001
  },
  {
    "episode": 3836,
    "reward": 84.549395,
    "length": 72,
    "time": 60478.412845,
    "actor_loss": -66.01194763183594,
    "critic_loss": 27.221446990966797,
    "ent_coef": 0.07011065632104874,
    "learning_rate": 0.001
  },
  {
    "episode": 3837,
    "reward": 88.091707,
    "length": 66,
    "time": 60490.850398,
    "actor_loss": -66.40237426757812,
    "critic_loss": 6.180120468139648,
    "ent_coef": 0.07045411318540573,
    "learning_rate": 0.001
  },
  {
    "episode": 3838,
    "reward": 84.012694,
    "length": 73,
    "time": 60504.154311,
    "actor_loss": -64.9613265991211,
    "critic_loss": 8.98337459564209,
    "ent_coef": 0.06864164024591446,
    "learning_rate": 0.001
  },
  {
    "episode": 3839,
    "reward": 85.866738,
    "length": 70,
    "time": 60516.052598,
    "actor_loss": -68.3564682006836,
    "critic_loss": 15.239958763122559,
    "ent_coef": 0.07018337398767471,
    "learning_rate": 0.001
  },
  {
    "episode": 3840,
    "reward": 89.762853,
    "length": 62,
    "time": 60530.181577,
    "actor_loss": -66.77291107177734,
    "critic_loss": 2.1003458499908447,
    "ent_coef": 0.07691895216703415,
    "learning_rate": 0.001
  },
  {
    "episode": 3841,
    "reward": 89.238796,
    "length": 64,
    "time": 60542.341768,
    "actor_loss": -64.10311126708984,
    "critic_loss": 13.523712158203125,
    "ent_coef": 0.08399215340614319,
    "learning_rate": 0.001
  },
  {
    "episode": 3842,
    "reward": 88.547616,
    "length": 65,
    "time": 60553.644513,
    "actor_loss": -64.85843658447266,
    "critic_loss": 77.89666748046875,
    "ent_coef": 0.08463692665100098,
    "learning_rate": 0.001
  },
  {
    "episode": 3843,
    "reward": 88.157604,
    "length": 67,
    "time": 60568.315273,
    "actor_loss": -60.22258758544922,
    "critic_loss": 18.378150939941406,
    "ent_coef": 0.08329550921916962,
    "learning_rate": 0.001
  },
  {
    "episode": 3844,
    "reward": 87.468792,
    "length": 68,
    "time": 60581.165329,
    "actor_loss": -69.43765258789062,
    "critic_loss": 3.2596311569213867,
    "ent_coef": 0.07800529152154922,
    "learning_rate": 0.001
  },
  {
    "episode": 3845,
    "reward": 88.728956,
    "length": 65,
    "time": 60595.472221,
    "actor_loss": -67.15811157226562,
    "critic_loss": 9.825983047485352,
    "ent_coef": 0.0764705091714859,
    "learning_rate": 0.001
  },
  {
    "episode": 3846,
    "reward": 87.84126,
    "length": 67,
    "time": 60608.749675,
    "actor_loss": -62.36275100708008,
    "critic_loss": 45.07726287841797,
    "ent_coef": 0.07703564316034317,
    "learning_rate": 0.001
  },
  {
    "episode": 3847,
    "reward": 86.128314,
    "length": 73,
    "time": 60622.081226,
    "actor_loss": -65.19053649902344,
    "critic_loss": 9.515949249267578,
    "ent_coef": 0.07803037762641907,
    "learning_rate": 0.001
  },
  {
    "episode": 3848,
    "reward": 89.055226,
    "length": 64,
    "time": 60633.123799,
    "actor_loss": -61.280120849609375,
    "critic_loss": 79.35429382324219,
    "ent_coef": 0.07933825999498367,
    "learning_rate": 0.001
  },
  {
    "episode": 3849,
    "reward": 82.135495,
    "length": 87,
    "time": 60647.431575,
    "actor_loss": -68.21652221679688,
    "critic_loss": 42.87633514404297,
    "ent_coef": 0.07945267111063004,
    "learning_rate": 0.001
  },
  {
    "episode": 3850,
    "reward": 85.268159,
    "length": 71,
    "time": 60660.400205,
    "actor_loss": -63.07623291015625,
    "critic_loss": 25.716203689575195,
    "ent_coef": 0.07916701585054398,
    "learning_rate": 0.001
  },
  {
    "episode": 3851,
    "reward": 87.470667,
    "length": 68,
    "time": 60674.093193,
    "actor_loss": -61.000831604003906,
    "critic_loss": 2.6612401008605957,
    "ent_coef": 0.07960387319326401,
    "learning_rate": 0.001
  },
  {
    "episode": 3852,
    "reward": 84.841858,
    "length": 72,
    "time": 60687.384379,
    "actor_loss": -68.35899353027344,
    "critic_loss": 21.88650131225586,
    "ent_coef": 0.07756073027849197,
    "learning_rate": 0.001
  },
  {
    "episode": 3853,
    "reward": 85.024551,
    "length": 71,
    "time": 60700.404665,
    "actor_loss": -63.72566223144531,
    "critic_loss": 4.498672008514404,
    "ent_coef": 0.07972755283117294,
    "learning_rate": 0.001
  },
  {
    "episode": 3854,
    "reward": 87.153234,
    "length": 69,
    "time": 60713.238298,
    "actor_loss": -66.33680725097656,
    "critic_loss": 3.5848028659820557,
    "ent_coef": 0.07967241108417511,
    "learning_rate": 0.001
  },
  {
    "episode": 3855,
    "reward": 87.997194,
    "length": 67,
    "time": 60724.748691,
    "actor_loss": -69.23102569580078,
    "critic_loss": 3.2613086700439453,
    "ent_coef": 0.08086660504341125,
    "learning_rate": 0.001
  },
  {
    "episode": 3856,
    "reward": 90.029482,
    "length": 63,
    "time": 60739.530079,
    "actor_loss": -59.757118225097656,
    "critic_loss": 10.537067413330078,
    "ent_coef": 0.08228405565023422,
    "learning_rate": 0.001
  },
  {
    "episode": 3857,
    "reward": 86.55291,
    "length": 68,
    "time": 60751.310286,
    "actor_loss": -63.63069534301758,
    "critic_loss": 2.5251545906066895,
    "ent_coef": 0.08074117451906204,
    "learning_rate": 0.001
  },
  {
    "episode": 3858,
    "reward": 90.149026,
    "length": 63,
    "time": 60763.219647,
    "actor_loss": -63.61177062988281,
    "critic_loss": 2.3380563259124756,
    "ent_coef": 0.07931764423847198,
    "learning_rate": 0.001
  },
  {
    "episode": 3859,
    "reward": 88.194323,
    "length": 66,
    "time": 60774.949488,
    "actor_loss": -64.7610092163086,
    "critic_loss": 14.576350212097168,
    "ent_coef": 0.07784879207611084,
    "learning_rate": 0.001
  },
  {
    "episode": 3860,
    "reward": 83.376921,
    "length": 74,
    "time": 60788.141636,
    "actor_loss": -65.56549072265625,
    "critic_loss": 13.580354690551758,
    "ent_coef": 0.07475854456424713,
    "learning_rate": 0.001
  },
  {
    "episode": 3861,
    "reward": 86.40571,
    "length": 69,
    "time": 60801.305143,
    "actor_loss": -67.10292053222656,
    "critic_loss": 3.2280635833740234,
    "ent_coef": 0.07146280258893967,
    "learning_rate": 0.001
  },
  {
    "episode": 3862,
    "reward": 88.958265,
    "length": 65,
    "time": 60815.640127,
    "actor_loss": -68.88314056396484,
    "critic_loss": 12.03415584564209,
    "ent_coef": 0.07090265303850174,
    "learning_rate": 0.001
  },
  {
    "episode": 3863,
    "reward": 89.10542,
    "length": 64,
    "time": 60828.966758,
    "actor_loss": -67.15655517578125,
    "critic_loss": 1.9616036415100098,
    "ent_coef": 0.0719299390912056,
    "learning_rate": 0.001
  },
  {
    "episode": 3864,
    "reward": 89.439212,
    "length": 65,
    "time": 60840.841648,
    "actor_loss": -68.03948974609375,
    "critic_loss": 3.338155746459961,
    "ent_coef": 0.07239992916584015,
    "learning_rate": 0.001
  },
  {
    "episode": 3865,
    "reward": 88.690489,
    "length": 66,
    "time": 60853.091459,
    "actor_loss": -68.24137878417969,
    "critic_loss": 52.992103576660156,
    "ent_coef": 0.07217143476009369,
    "learning_rate": 0.001
  },
  {
    "episode": 3866,
    "reward": 86.269743,
    "length": 73,
    "time": 60867.679055,
    "actor_loss": -64.06825256347656,
    "critic_loss": 41.723419189453125,
    "ent_coef": 0.07141252607107162,
    "learning_rate": 0.001
  },
  {
    "episode": 3867,
    "reward": 89.711174,
    "length": 64,
    "time": 60881.063415,
    "actor_loss": -68.74038696289062,
    "critic_loss": 4.619832992553711,
    "ent_coef": 0.07218760997056961,
    "learning_rate": 0.001
  },
  {
    "episode": 3868,
    "reward": 86.162097,
    "length": 69,
    "time": 60897.008256,
    "actor_loss": -62.985313415527344,
    "critic_loss": 5.520869255065918,
    "ent_coef": 0.07168341428041458,
    "learning_rate": 0.001
  },
  {
    "episode": 3869,
    "reward": 86.791559,
    "length": 67,
    "time": 60909.047918,
    "actor_loss": -63.02317810058594,
    "critic_loss": 3.320049524307251,
    "ent_coef": 0.07471635937690735,
    "learning_rate": 0.001
  },
  {
    "episode": 3870,
    "reward": 87.856078,
    "length": 67,
    "time": 60923.791044,
    "actor_loss": -65.0378646850586,
    "critic_loss": 5.851455211639404,
    "ent_coef": 0.07407426089048386,
    "learning_rate": 0.001
  },
  {
    "episode": 3871,
    "reward": 87.112151,
    "length": 67,
    "time": 60935.972143,
    "actor_loss": -60.242332458496094,
    "critic_loss": 17.51246452331543,
    "ent_coef": 0.07374965399503708,
    "learning_rate": 0.001
  },
  {
    "episode": 3872,
    "reward": 89.568139,
    "length": 63,
    "time": 60950.015523,
    "actor_loss": -68.82421112060547,
    "critic_loss": 3.160043239593506,
    "ent_coef": 0.07431760430335999,
    "learning_rate": 0.001
  },
  {
    "episode": 3873,
    "reward": 88.359213,
    "length": 65,
    "time": 60961.379277,
    "actor_loss": -61.557498931884766,
    "critic_loss": 11.467748641967773,
    "ent_coef": 0.0754271075129509,
    "learning_rate": 0.001
  },
  {
    "episode": 3874,
    "reward": 90.119617,
    "length": 62,
    "time": 60980.282381,
    "actor_loss": -69.55448913574219,
    "critic_loss": 35.75629806518555,
    "ent_coef": 0.08093269169330597,
    "learning_rate": 0.001
  },
  {
    "episode": 3875,
    "reward": 86.889743,
    "length": 72,
    "time": 60994.716995,
    "actor_loss": -61.10283279418945,
    "critic_loss": 3.716341018676758,
    "ent_coef": 0.07860809564590454,
    "learning_rate": 0.001
  },
  {
    "episode": 3876,
    "reward": 90.915491,
    "length": 62,
    "time": 61006.688196,
    "actor_loss": -58.55927276611328,
    "critic_loss": 9.66604995727539,
    "ent_coef": 0.07891715317964554,
    "learning_rate": 0.001
  },
  {
    "episode": 3877,
    "reward": 84.563195,
    "length": 73,
    "time": 61021.981067,
    "actor_loss": -69.07677459716797,
    "critic_loss": 3.8200793266296387,
    "ent_coef": 0.07660692930221558,
    "learning_rate": 0.001
  },
  {
    "episode": 3878,
    "reward": 88.379567,
    "length": 65,
    "time": 61033.281895,
    "actor_loss": -59.99468231201172,
    "critic_loss": 17.3007755279541,
    "ent_coef": 0.07655241340398788,
    "learning_rate": 0.001
  },
  {
    "episode": 3879,
    "reward": 89.733134,
    "length": 64,
    "time": 61044.449444,
    "actor_loss": -65.09017944335938,
    "critic_loss": 6.31483793258667,
    "ent_coef": 0.07536293566226959,
    "learning_rate": 0.001
  },
  {
    "episode": 3880,
    "reward": 88.064954,
    "length": 67,
    "time": 61056.10603,
    "actor_loss": -61.35319519042969,
    "critic_loss": 320.77850341796875,
    "ent_coef": 0.07279200851917267,
    "learning_rate": 0.001
  },
  {
    "episode": 3881,
    "reward": 85.926741,
    "length": 71,
    "time": 61071.547268,
    "actor_loss": -62.73844528198242,
    "critic_loss": 3.828042984008789,
    "ent_coef": 0.07363320142030716,
    "learning_rate": 0.001
  },
  {
    "episode": 3882,
    "reward": 83.923421,
    "length": 74,
    "time": 61086.829468,
    "actor_loss": -65.30715942382812,
    "critic_loss": 28.18794822692871,
    "ent_coef": 0.07115688174962997,
    "learning_rate": 0.001
  },
  {
    "episode": 3883,
    "reward": 86.434295,
    "length": 68,
    "time": 61101.055923,
    "actor_loss": -64.14025115966797,
    "critic_loss": 4.1380205154418945,
    "ent_coef": 0.07296650856733322,
    "learning_rate": 0.001
  },
  {
    "episode": 3884,
    "reward": 90.417733,
    "length": 62,
    "time": 61113.500317,
    "actor_loss": -63.48200225830078,
    "critic_loss": 22.63006591796875,
    "ent_coef": 0.07654547691345215,
    "learning_rate": 0.001
  },
  {
    "episode": 3885,
    "reward": 87.075044,
    "length": 69,
    "time": 61125.463429,
    "actor_loss": -57.59834289550781,
    "critic_loss": 13.064155578613281,
    "ent_coef": 0.07491959631443024,
    "learning_rate": 0.001
  },
  {
    "episode": 3886,
    "reward": 85.841148,
    "length": 69,
    "time": 61137.546193,
    "actor_loss": -69.50948333740234,
    "critic_loss": 3.8409664630889893,
    "ent_coef": 0.07524801045656204,
    "learning_rate": 0.001
  },
  {
    "episode": 3887,
    "reward": 86.631069,
    "length": 70,
    "time": 61150.501255,
    "actor_loss": -75.35267639160156,
    "critic_loss": 119.91703796386719,
    "ent_coef": 0.07554591447114944,
    "learning_rate": 0.001
  },
  {
    "episode": 3888,
    "reward": 90.458274,
    "length": 62,
    "time": 61161.471245,
    "actor_loss": -63.817481994628906,
    "critic_loss": 3.3667523860931396,
    "ent_coef": 0.08042984455823898,
    "learning_rate": 0.001
  },
  {
    "episode": 3889,
    "reward": 88.038779,
    "length": 66,
    "time": 61175.6899,
    "actor_loss": -65.06747436523438,
    "critic_loss": 17.947465896606445,
    "ent_coef": 0.07977259904146194,
    "learning_rate": 0.001
  },
  {
    "episode": 3890,
    "reward": 89.228155,
    "length": 64,
    "time": 61190.483798,
    "actor_loss": -65.01237487792969,
    "critic_loss": 2.1786532402038574,
    "ent_coef": 0.08213793486356735,
    "learning_rate": 0.001
  },
  {
    "episode": 3891,
    "reward": 88.546799,
    "length": 67,
    "time": 61204.227108,
    "actor_loss": -67.83817291259766,
    "critic_loss": 4.455714225769043,
    "ent_coef": 0.08246729522943497,
    "learning_rate": 0.001
  },
  {
    "episode": 3892,
    "reward": 90.746578,
    "length": 62,
    "time": 61215.109528,
    "actor_loss": -66.46965026855469,
    "critic_loss": 9.182992935180664,
    "ent_coef": 0.0837884396314621,
    "learning_rate": 0.001
  },
  {
    "episode": 3893,
    "reward": 89.548943,
    "length": 65,
    "time": 61227.280838,
    "actor_loss": -65.4766845703125,
    "critic_loss": 6.3278045654296875,
    "ent_coef": 0.08217190206050873,
    "learning_rate": 0.001
  },
  {
    "episode": 3894,
    "reward": 88.199895,
    "length": 67,
    "time": 61239.759893,
    "actor_loss": -66.86836242675781,
    "critic_loss": 4.7935285568237305,
    "ent_coef": 0.07805593311786652,
    "learning_rate": 0.001
  },
  {
    "episode": 3895,
    "reward": 90.820135,
    "length": 61,
    "time": 61251.815643,
    "actor_loss": -64.35784912109375,
    "critic_loss": 2.643550157546997,
    "ent_coef": 0.07669273018836975,
    "learning_rate": 0.001
  },
  {
    "episode": 3896,
    "reward": 89.463616,
    "length": 65,
    "time": 61263.068758,
    "actor_loss": -68.54872131347656,
    "critic_loss": 3.4307732582092285,
    "ent_coef": 0.07482987642288208,
    "learning_rate": 0.001
  },
  {
    "episode": 3897,
    "reward": 86.076263,
    "length": 70,
    "time": 61276.743383,
    "actor_loss": -58.21942138671875,
    "critic_loss": 3.7032599449157715,
    "ent_coef": 0.07273925095796585,
    "learning_rate": 0.001
  },
  {
    "episode": 3898,
    "reward": 88.646507,
    "length": 65,
    "time": 61290.669881,
    "actor_loss": -63.166011810302734,
    "critic_loss": 3.9777274131774902,
    "ent_coef": 0.07489803433418274,
    "learning_rate": 0.001
  },
  {
    "episode": 3899,
    "reward": 87.33056,
    "length": 72,
    "time": 61303.668161,
    "actor_loss": -71.68821716308594,
    "critic_loss": 18.551380157470703,
    "ent_coef": 0.07861583679914474,
    "learning_rate": 0.001
  },
  {
    "episode": 3900,
    "reward": 89.228595,
    "length": 65,
    "time": 61319.779948,
    "actor_loss": -61.317291259765625,
    "critic_loss": 18.459537506103516,
    "ent_coef": 0.07994033396244049,
    "learning_rate": 0.001
  },
  {
    "episode": 3901,
    "reward": 88.866091,
    "length": 65,
    "time": 61331.785976,
    "actor_loss": -67.60057067871094,
    "critic_loss": 2.7605061531066895,
    "ent_coef": 0.0783773884177208,
    "learning_rate": 0.001
  },
  {
    "episode": 3902,
    "reward": 80.501976,
    "length": 77,
    "time": 61345.312092,
    "actor_loss": -63.35142517089844,
    "critic_loss": 14.231986999511719,
    "ent_coef": 0.07472829520702362,
    "learning_rate": 0.001
  },
  {
    "episode": 3903,
    "reward": 88.409924,
    "length": 66,
    "time": 61357.135583,
    "actor_loss": -69.1243896484375,
    "critic_loss": 3.513031005859375,
    "ent_coef": 0.07432719320058823,
    "learning_rate": 0.001
  },
  {
    "episode": 3904,
    "reward": 90.35176,
    "length": 62,
    "time": 61370.204751,
    "actor_loss": -61.55348205566406,
    "critic_loss": 12.812098503112793,
    "ent_coef": 0.07681804895401001,
    "learning_rate": 0.001
  },
  {
    "episode": 3905,
    "reward": 87.940953,
    "length": 67,
    "time": 61385.937147,
    "actor_loss": -61.437782287597656,
    "critic_loss": 4.294098854064941,
    "ent_coef": 0.07757843285799026,
    "learning_rate": 0.001
  },
  {
    "episode": 3906,
    "reward": 87.972855,
    "length": 68,
    "time": 61399.283407,
    "actor_loss": -62.3502197265625,
    "critic_loss": 3.6921050548553467,
    "ent_coef": 0.07831032574176788,
    "learning_rate": 0.001
  },
  {
    "episode": 3907,
    "reward": 87.453397,
    "length": 67,
    "time": 61410.892185,
    "actor_loss": -66.31582641601562,
    "critic_loss": 5.506204605102539,
    "ent_coef": 0.07780520617961884,
    "learning_rate": 0.001
  },
  {
    "episode": 3908,
    "reward": 87.335313,
    "length": 68,
    "time": 61422.694916,
    "actor_loss": -64.80345153808594,
    "critic_loss": 5.449342727661133,
    "ent_coef": 0.07512523978948593,
    "learning_rate": 0.001
  },
  {
    "episode": 3909,
    "reward": 88.478205,
    "length": 69,
    "time": 61435.448559,
    "actor_loss": -78.4271240234375,
    "critic_loss": 83.38908386230469,
    "ent_coef": 0.07430630177259445,
    "learning_rate": 0.001
  },
  {
    "episode": 3910,
    "reward": 88.239109,
    "length": 67,
    "time": 61447.05215,
    "actor_loss": -71.6507339477539,
    "critic_loss": 28.472393035888672,
    "ent_coef": 0.07158985733985901,
    "learning_rate": 0.001
  },
  {
    "episode": 3911,
    "reward": 87.652759,
    "length": 72,
    "time": 61461.380903,
    "actor_loss": -67.06085205078125,
    "critic_loss": 18.739322662353516,
    "ent_coef": 0.07107055932283401,
    "learning_rate": 0.001
  },
  {
    "episode": 3912,
    "reward": 91.905521,
    "length": 59,
    "time": 61472.12209,
    "actor_loss": -65.732177734375,
    "critic_loss": 30.629859924316406,
    "ent_coef": 0.07292346656322479,
    "learning_rate": 0.001
  },
  {
    "episode": 3913,
    "reward": -423.154969,
    "length": 350,
    "time": 61522.42598,
    "actor_loss": -72.69001770019531,
    "critic_loss": 4.446572303771973,
    "ent_coef": 0.0710449293255806,
    "learning_rate": 0.001
  },
  {
    "episode": 3914,
    "reward": 103.418408,
    "length": 68,
    "time": 61534.333017,
    "actor_loss": -70.48835754394531,
    "critic_loss": 14.148092269897461,
    "ent_coef": 0.07148765027523041,
    "learning_rate": 0.001
  },
  {
    "episode": 3915,
    "reward": 91.057774,
    "length": 61,
    "time": 61546.771208,
    "actor_loss": -61.11766815185547,
    "critic_loss": 5.342287063598633,
    "ent_coef": 0.07450778782367706,
    "learning_rate": 0.001
  },
  {
    "episode": 3916,
    "reward": 88.845366,
    "length": 65,
    "time": 61560.199834,
    "actor_loss": -64.37012481689453,
    "critic_loss": 3.2559990882873535,
    "ent_coef": 0.0751270055770874,
    "learning_rate": 0.001
  },
  {
    "episode": 3917,
    "reward": 89.028175,
    "length": 64,
    "time": 61572.593951,
    "actor_loss": -62.94970703125,
    "critic_loss": 8.225069046020508,
    "ent_coef": 0.07529788464307785,
    "learning_rate": 0.001
  },
  {
    "episode": 3918,
    "reward": 88.242216,
    "length": 65,
    "time": 61584.116133,
    "actor_loss": -70.1736068725586,
    "critic_loss": 1.1960735321044922,
    "ent_coef": 0.07454574108123779,
    "learning_rate": 0.001
  },
  {
    "episode": 3919,
    "reward": 88.355336,
    "length": 66,
    "time": 61596.649061,
    "actor_loss": -67.80477142333984,
    "critic_loss": 8.232179641723633,
    "ent_coef": 0.07127682119607925,
    "learning_rate": 0.001
  },
  {
    "episode": 3920,
    "reward": 83.73127,
    "length": 75,
    "time": 61610.245132,
    "actor_loss": -71.35950469970703,
    "critic_loss": 5.5134077072143555,
    "ent_coef": 0.0667954534292221,
    "learning_rate": 0.001
  },
  {
    "episode": 3921,
    "reward": 85.855085,
    "length": 69,
    "time": 61622.073983,
    "actor_loss": -62.35446548461914,
    "critic_loss": 4.317987442016602,
    "ent_coef": 0.06433162838220596,
    "learning_rate": 0.001
  },
  {
    "episode": 3922,
    "reward": 88.265539,
    "length": 65,
    "time": 61633.281229,
    "actor_loss": -63.22401428222656,
    "critic_loss": 3.254117488861084,
    "ent_coef": 0.06552894413471222,
    "learning_rate": 0.001
  },
  {
    "episode": 3923,
    "reward": 87.043254,
    "length": 67,
    "time": 61645.073876,
    "actor_loss": -66.77763366699219,
    "critic_loss": 3.1337332725524902,
    "ent_coef": 0.0645371675491333,
    "learning_rate": 0.001
  },
  {
    "episode": 3924,
    "reward": 85.904671,
    "length": 69,
    "time": 61658.237598,
    "actor_loss": -68.14189147949219,
    "critic_loss": 6.2242326736450195,
    "ent_coef": 0.06358155608177185,
    "learning_rate": 0.001
  },
  {
    "episode": 3925,
    "reward": 88.179843,
    "length": 66,
    "time": 61671.898669,
    "actor_loss": -66.12263488769531,
    "critic_loss": 27.53104019165039,
    "ent_coef": 0.06412369012832642,
    "learning_rate": 0.001
  },
  {
    "episode": 3926,
    "reward": 89.174306,
    "length": 64,
    "time": 61683.987155,
    "actor_loss": -63.90031051635742,
    "critic_loss": 3.3897619247436523,
    "ent_coef": 0.06706111878156662,
    "learning_rate": 0.001
  },
  {
    "episode": 3927,
    "reward": 91.022965,
    "length": 62,
    "time": 61697.096958,
    "actor_loss": -75.14122009277344,
    "critic_loss": 76.22845458984375,
    "ent_coef": 0.06895903497934341,
    "learning_rate": 0.001
  },
  {
    "episode": 3928,
    "reward": 87.851978,
    "length": 67,
    "time": 61710.018209,
    "actor_loss": -71.93930053710938,
    "critic_loss": 20.539077758789062,
    "ent_coef": 0.06975138932466507,
    "learning_rate": 0.001
  },
  {
    "episode": 3929,
    "reward": 89.429464,
    "length": 64,
    "time": 61722.261665,
    "actor_loss": -69.27411651611328,
    "critic_loss": 7.756914138793945,
    "ent_coef": 0.06998518109321594,
    "learning_rate": 0.001
  },
  {
    "episode": 3930,
    "reward": 87.550492,
    "length": 68,
    "time": 61735.039886,
    "actor_loss": -65.00947570800781,
    "critic_loss": 55.64854431152344,
    "ent_coef": 0.07003553956747055,
    "learning_rate": 0.001
  },
  {
    "episode": 3931,
    "reward": 87.281098,
    "length": 67,
    "time": 61747.831231,
    "actor_loss": -67.38070678710938,
    "critic_loss": 2.4666836261749268,
    "ent_coef": 0.07064957171678543,
    "learning_rate": 0.001
  },
  {
    "episode": 3932,
    "reward": 88.329631,
    "length": 66,
    "time": 61759.394645,
    "actor_loss": -63.363338470458984,
    "critic_loss": 3.3139705657958984,
    "ent_coef": 0.0712079256772995,
    "learning_rate": 0.001
  },
  {
    "episode": 3933,
    "reward": 87.636154,
    "length": 67,
    "time": 61771.89518,
    "actor_loss": -69.00934600830078,
    "critic_loss": 81.57939147949219,
    "ent_coef": 0.07168324291706085,
    "learning_rate": 0.001
  },
  {
    "episode": 3934,
    "reward": 90.26876,
    "length": 63,
    "time": 61787.461187,
    "actor_loss": -65.54385375976562,
    "critic_loss": 2.09311580657959,
    "ent_coef": 0.0734262615442276,
    "learning_rate": 0.001
  },
  {
    "episode": 3935,
    "reward": 84.471944,
    "length": 73,
    "time": 61805.529508,
    "actor_loss": -62.84860610961914,
    "critic_loss": 12.904479026794434,
    "ent_coef": 0.07328100502490997,
    "learning_rate": 0.001
  },
  {
    "episode": 3936,
    "reward": 85.508413,
    "length": 80,
    "time": 61820.694624,
    "actor_loss": -63.5150260925293,
    "critic_loss": 2.5008509159088135,
    "ent_coef": 0.07478161156177521,
    "learning_rate": 0.001
  },
  {
    "episode": 3937,
    "reward": 86.401027,
    "length": 68,
    "time": 61832.353139,
    "actor_loss": -68.79509735107422,
    "critic_loss": 6.605343818664551,
    "ent_coef": 0.07524282485246658,
    "learning_rate": 0.001
  },
  {
    "episode": 3938,
    "reward": 88.696668,
    "length": 65,
    "time": 61844.654776,
    "actor_loss": -65.3563232421875,
    "critic_loss": 2.2558186054229736,
    "ent_coef": 0.07645934820175171,
    "learning_rate": 0.001
  },
  {
    "episode": 3939,
    "reward": 90.73405,
    "length": 62,
    "time": 61859.058316,
    "actor_loss": -61.84466552734375,
    "critic_loss": 5.506278038024902,
    "ent_coef": 0.08074092119932175,
    "learning_rate": 0.001
  },
  {
    "episode": 3940,
    "reward": 89.788088,
    "length": 63,
    "time": 61872.793189,
    "actor_loss": -62.625404357910156,
    "critic_loss": 6.304721832275391,
    "ent_coef": 0.08027522265911102,
    "learning_rate": 0.001
  },
  {
    "episode": 3941,
    "reward": 89.349285,
    "length": 65,
    "time": 61884.810481,
    "actor_loss": -66.76193237304688,
    "critic_loss": 4.33547306060791,
    "ent_coef": 0.0813208743929863,
    "learning_rate": 0.001
  },
  {
    "episode": 3942,
    "reward": 85.392461,
    "length": 73,
    "time": 61897.091942,
    "actor_loss": -63.371002197265625,
    "critic_loss": 5.02359676361084,
    "ent_coef": 0.08502057939767838,
    "learning_rate": 0.001
  },
  {
    "episode": 3943,
    "reward": 87.319445,
    "length": 67,
    "time": 61908.596119,
    "actor_loss": -65.10011291503906,
    "critic_loss": 19.78714370727539,
    "ent_coef": 0.08538901060819626,
    "learning_rate": 0.001
  },
  {
    "episode": 3944,
    "reward": 87.310582,
    "length": 69,
    "time": 61923.243799,
    "actor_loss": -60.344635009765625,
    "critic_loss": 3.380852222442627,
    "ent_coef": 0.08414285629987717,
    "learning_rate": 0.001
  },
  {
    "episode": 3945,
    "reward": 89.917594,
    "length": 63,
    "time": 61934.50989,
    "actor_loss": -66.44015502929688,
    "critic_loss": 3.2548272609710693,
    "ent_coef": 0.08392304927110672,
    "learning_rate": 0.001
  },
  {
    "episode": 3946,
    "reward": 90.002817,
    "length": 64,
    "time": 61947.780606,
    "actor_loss": -65.02536010742188,
    "critic_loss": 4.871095657348633,
    "ent_coef": 0.0856296718120575,
    "learning_rate": 0.001
  },
  {
    "episode": 3947,
    "reward": 89.158849,
    "length": 65,
    "time": 61958.982354,
    "actor_loss": -62.788108825683594,
    "critic_loss": 3.747772216796875,
    "ent_coef": 0.08527493476867676,
    "learning_rate": 0.001
  },
  {
    "episode": 3948,
    "reward": 89.87165,
    "length": 64,
    "time": 61971.766654,
    "actor_loss": -71.43328857421875,
    "critic_loss": 3.458670139312744,
    "ent_coef": 0.08478918671607971,
    "learning_rate": 0.001
  },
  {
    "episode": 3949,
    "reward": 86.751811,
    "length": 68,
    "time": 61988.750473,
    "actor_loss": -65.37857055664062,
    "critic_loss": 13.214288711547852,
    "ent_coef": 0.08218951523303986,
    "learning_rate": 0.001
  },
  {
    "episode": 3950,
    "reward": 87.311898,
    "length": 67,
    "time": 62001.352182,
    "actor_loss": -60.763526916503906,
    "critic_loss": 8.511444091796875,
    "ent_coef": 0.08404310792684555,
    "learning_rate": 0.001
  },
  {
    "episode": 3951,
    "reward": 89.496143,
    "length": 64,
    "time": 62012.473193,
    "actor_loss": -65.44475555419922,
    "critic_loss": 3.0973377227783203,
    "ent_coef": 0.08602294325828552,
    "learning_rate": 0.001
  },
  {
    "episode": 3952,
    "reward": 81.583439,
    "length": 75,
    "time": 62025.283453,
    "actor_loss": -59.75485610961914,
    "critic_loss": 8.762706756591797,
    "ent_coef": 0.08582951128482819,
    "learning_rate": 0.001
  },
  {
    "episode": 3953,
    "reward": 84.980001,
    "length": 71,
    "time": 62037.444207,
    "actor_loss": -66.10636138916016,
    "critic_loss": 8.676136016845703,
    "ent_coef": 0.08415457606315613,
    "learning_rate": 0.001
  },
  {
    "episode": 3954,
    "reward": 85.161208,
    "length": 71,
    "time": 62049.379081,
    "actor_loss": -70.93585968017578,
    "critic_loss": 4.265440940856934,
    "ent_coef": 0.08192674070596695,
    "learning_rate": 0.001
  },
  {
    "episode": 3955,
    "reward": 89.33491,
    "length": 64,
    "time": 62061.573215,
    "actor_loss": -65.79701232910156,
    "critic_loss": 34.91658401489258,
    "ent_coef": 0.08326882123947144,
    "learning_rate": 0.001
  },
  {
    "episode": 3956,
    "reward": 87.244554,
    "length": 67,
    "time": 62074.006957,
    "actor_loss": -63.771793365478516,
    "critic_loss": 4.228335380554199,
    "ent_coef": 0.0817827433347702,
    "learning_rate": 0.001
  },
  {
    "episode": 3957,
    "reward": 83.960195,
    "length": 74,
    "time": 62087.440953,
    "actor_loss": -68.05215454101562,
    "critic_loss": 6.222465515136719,
    "ent_coef": 0.07728421688079834,
    "learning_rate": 0.001
  },
  {
    "episode": 3958,
    "reward": 90.037197,
    "length": 63,
    "time": 62098.541397,
    "actor_loss": -63.64210891723633,
    "critic_loss": 2.484011173248291,
    "ent_coef": 0.07675430178642273,
    "learning_rate": 0.001
  },
  {
    "episode": 3959,
    "reward": 88.316951,
    "length": 66,
    "time": 62109.929718,
    "actor_loss": -65.84005737304688,
    "critic_loss": 5.066298007965088,
    "ent_coef": 0.07448708266019821,
    "learning_rate": 0.001
  },
  {
    "episode": 3960,
    "reward": 80.590261,
    "length": 78,
    "time": 62124.029807,
    "actor_loss": -62.72622299194336,
    "critic_loss": 7.8459672927856445,
    "ent_coef": 0.07017930597066879,
    "learning_rate": 0.001
  },
  {
    "episode": 3961,
    "reward": 88.438376,
    "length": 67,
    "time": 62138.83932,
    "actor_loss": -65.04149627685547,
    "critic_loss": 2.2011165618896484,
    "ent_coef": 0.06805212050676346,
    "learning_rate": 0.001
  },
  {
    "episode": 3962,
    "reward": 88.131027,
    "length": 66,
    "time": 62151.928574,
    "actor_loss": -65.0715103149414,
    "critic_loss": 2.253973960876465,
    "ent_coef": 0.0651605874300003,
    "learning_rate": 0.001
  },
  {
    "episode": 3963,
    "reward": 84.75818,
    "length": 71,
    "time": 62166.262043,
    "actor_loss": -63.84465026855469,
    "critic_loss": 2.600611925125122,
    "ent_coef": 0.06418051570653915,
    "learning_rate": 0.001
  },
  {
    "episode": 3964,
    "reward": 86.527501,
    "length": 69,
    "time": 62181.367723,
    "actor_loss": -71.26809692382812,
    "critic_loss": 21.466445922851562,
    "ent_coef": 0.06215152516961098,
    "learning_rate": 0.001
  },
  {
    "episode": 3965,
    "reward": 88.265346,
    "length": 66,
    "time": 62193.900944,
    "actor_loss": -65.92686462402344,
    "critic_loss": 3.459477663040161,
    "ent_coef": 0.06298606097698212,
    "learning_rate": 0.001
  },
  {
    "episode": 3966,
    "reward": 87.595726,
    "length": 67,
    "time": 62205.517634,
    "actor_loss": -66.16083526611328,
    "critic_loss": 7.581684589385986,
    "ent_coef": 0.06465473026037216,
    "learning_rate": 0.001
  },
  {
    "episode": 3967,
    "reward": 88.015749,
    "length": 66,
    "time": 62216.834666,
    "actor_loss": -64.81204223632812,
    "critic_loss": 68.90438842773438,
    "ent_coef": 0.06353729218244553,
    "learning_rate": 0.001
  },
  {
    "episode": 3968,
    "reward": 91.314545,
    "length": 61,
    "time": 62230.442505,
    "actor_loss": -62.02983093261719,
    "critic_loss": 2.1405444145202637,
    "ent_coef": 0.06496521085500717,
    "learning_rate": 0.001
  },
  {
    "episode": 3969,
    "reward": 90.278037,
    "length": 62,
    "time": 62242.323218,
    "actor_loss": -66.8885498046875,
    "critic_loss": 2.7821693420410156,
    "ent_coef": 0.0660763829946518,
    "learning_rate": 0.001
  },
  {
    "episode": 3970,
    "reward": 85.313412,
    "length": 70,
    "time": 62256.157068,
    "actor_loss": -68.40992736816406,
    "critic_loss": 3.435239553451538,
    "ent_coef": 0.06577834486961365,
    "learning_rate": 0.001
  },
  {
    "episode": 3971,
    "reward": 87.7188,
    "length": 66,
    "time": 62268.017466,
    "actor_loss": -68.10169982910156,
    "critic_loss": 2.5820698738098145,
    "ent_coef": 0.06677532196044922,
    "learning_rate": 0.001
  },
  {
    "episode": 3972,
    "reward": 89.424495,
    "length": 64,
    "time": 62279.560116,
    "actor_loss": -67.60364532470703,
    "critic_loss": 4.871092319488525,
    "ent_coef": 0.07006373256444931,
    "learning_rate": 0.001
  },
  {
    "episode": 3973,
    "reward": 84.519264,
    "length": 72,
    "time": 62295.405225,
    "actor_loss": -65.35256958007812,
    "critic_loss": 9.141866683959961,
    "ent_coef": 0.06993737816810608,
    "learning_rate": 0.001
  },
  {
    "episode": 3974,
    "reward": 86.801601,
    "length": 68,
    "time": 62307.119611,
    "actor_loss": -64.21025848388672,
    "critic_loss": 5.920373916625977,
    "ent_coef": 0.0685809999704361,
    "learning_rate": 0.001
  },
  {
    "episode": 3975,
    "reward": 88.953584,
    "length": 64,
    "time": 62319.802458,
    "actor_loss": -63.229366302490234,
    "critic_loss": 6.380092620849609,
    "ent_coef": 0.06900900602340698,
    "learning_rate": 0.001
  },
  {
    "episode": 3976,
    "reward": 87.904199,
    "length": 66,
    "time": 62331.927227,
    "actor_loss": -66.10340881347656,
    "critic_loss": 43.99979019165039,
    "ent_coef": 0.06933983415365219,
    "learning_rate": 0.001
  },
  {
    "episode": 3977,
    "reward": 89.194547,
    "length": 63,
    "time": 62344.722804,
    "actor_loss": -60.574798583984375,
    "critic_loss": 3.9639627933502197,
    "ent_coef": 0.07310670614242554,
    "learning_rate": 0.001
  },
  {
    "episode": 3978,
    "reward": 87.911521,
    "length": 66,
    "time": 62357.593062,
    "actor_loss": -63.923316955566406,
    "critic_loss": 1.734283208847046,
    "ent_coef": 0.07315316796302795,
    "learning_rate": 0.001
  },
  {
    "episode": 3979,
    "reward": 88.775234,
    "length": 64,
    "time": 62371.653573,
    "actor_loss": -60.449310302734375,
    "critic_loss": 5.200239658355713,
    "ent_coef": 0.0731927677989006,
    "learning_rate": 0.001
  },
  {
    "episode": 3980,
    "reward": 86.840476,
    "length": 71,
    "time": 62384.621089,
    "actor_loss": -71.39041137695312,
    "critic_loss": 5.182218551635742,
    "ent_coef": 0.07652221620082855,
    "learning_rate": 0.001
  },
  {
    "episode": 3981,
    "reward": 86.758205,
    "length": 68,
    "time": 62398.518856,
    "actor_loss": -58.40334701538086,
    "critic_loss": 44.358097076416016,
    "ent_coef": 0.07773260027170181,
    "learning_rate": 0.001
  },
  {
    "episode": 3982,
    "reward": 86.827698,
    "length": 68,
    "time": 62410.281036,
    "actor_loss": -61.02521514892578,
    "critic_loss": 3.5356040000915527,
    "ent_coef": 0.07564976066350937,
    "learning_rate": 0.001
  },
  {
    "episode": 3983,
    "reward": 77.816268,
    "length": 96,
    "time": 62427.509277,
    "actor_loss": -65.89985656738281,
    "critic_loss": 2.448873519897461,
    "ent_coef": 0.07098240405321121,
    "learning_rate": 0.001
  },
  {
    "episode": 3984,
    "reward": 85.939785,
    "length": 68,
    "time": 62440.086799,
    "actor_loss": -66.38185119628906,
    "critic_loss": 10.487067222595215,
    "ent_coef": 0.06961861252784729,
    "learning_rate": 0.001
  },
  {
    "episode": 3985,
    "reward": 87.94322,
    "length": 67,
    "time": 62451.608535,
    "actor_loss": -69.69692993164062,
    "critic_loss": 4.360558032989502,
    "ent_coef": 0.06893052160739899,
    "learning_rate": 0.001
  },
  {
    "episode": 3986,
    "reward": 87.888183,
    "length": 66,
    "time": 62463.838908,
    "actor_loss": -66.39741516113281,
    "critic_loss": 13.383102416992188,
    "ent_coef": 0.06870017200708389,
    "learning_rate": 0.001
  },
  {
    "episode": 3987,
    "reward": 83.007298,
    "length": 73,
    "time": 62476.919065,
    "actor_loss": -68.39369201660156,
    "critic_loss": 3.8489952087402344,
    "ent_coef": 0.0665813535451889,
    "learning_rate": 0.001
  },
  {
    "episode": 3988,
    "reward": 86.624338,
    "length": 77,
    "time": 62491.044171,
    "actor_loss": -62.37736511230469,
    "critic_loss": 8.426277160644531,
    "ent_coef": 0.07041458785533905,
    "learning_rate": 0.001
  },
  {
    "episode": 3989,
    "reward": 84.303959,
    "length": 70,
    "time": 62505.34163,
    "actor_loss": -67.62776947021484,
    "critic_loss": 4.03834342956543,
    "ent_coef": 0.06911000609397888,
    "learning_rate": 0.001
  },
  {
    "episode": 3990,
    "reward": 85.741626,
    "length": 71,
    "time": 62518.693961,
    "actor_loss": -66.30511474609375,
    "critic_loss": 4.210389614105225,
    "ent_coef": 0.06796413660049438,
    "learning_rate": 0.001
  },
  {
    "episode": 3991,
    "reward": 79.865071,
    "length": 89,
    "time": 62534.845173,
    "actor_loss": -59.27910232543945,
    "critic_loss": 2.495479106903076,
    "ent_coef": 0.06531807035207748,
    "learning_rate": 0.001
  },
  {
    "episode": 3992,
    "reward": 85.860348,
    "length": 69,
    "time": 62548.452251,
    "actor_loss": -61.975337982177734,
    "critic_loss": 3.1419410705566406,
    "ent_coef": 0.0658375546336174,
    "learning_rate": 0.001
  },
  {
    "episode": 3993,
    "reward": 88.445437,
    "length": 65,
    "time": 62561.615799,
    "actor_loss": -68.62352752685547,
    "critic_loss": 5.140668869018555,
    "ent_coef": 0.06647045165300369,
    "learning_rate": 0.001
  },
  {
    "episode": 3994,
    "reward": 80.466226,
    "length": 89,
    "time": 62576.797173,
    "actor_loss": -60.41050720214844,
    "critic_loss": 17.865066528320312,
    "ent_coef": 0.06439170986413956,
    "learning_rate": 0.001
  },
  {
    "episode": 3995,
    "reward": 77.799828,
    "length": 93,
    "time": 62592.635239,
    "actor_loss": -64.23139953613281,
    "critic_loss": 2.713031768798828,
    "ent_coef": 0.06358205527067184,
    "learning_rate": 0.001
  },
  {
    "episode": 3996,
    "reward": 81.010825,
    "length": 88,
    "time": 62608.112282,
    "actor_loss": -61.04133605957031,
    "critic_loss": 26.444719314575195,
    "ent_coef": 0.06276121735572815,
    "learning_rate": 0.001
  },
  {
    "episode": 3997,
    "reward": -52.68754,
    "length": 229,
    "time": 62641.724378,
    "actor_loss": -63.35369873046875,
    "critic_loss": 18.97681427001953,
    "ent_coef": 0.06526844948530197,
    "learning_rate": 0.001
  },
  {
    "episode": 3998,
    "reward": 49.185918,
    "length": 117,
    "time": 62659.878856,
    "actor_loss": -64.67311096191406,
    "critic_loss": 7.3254523277282715,
    "ent_coef": 0.0680050328373909,
    "learning_rate": 0.001
  },
  {
    "episode": 3999,
    "reward": 85.397667,
    "length": 70,
    "time": 62676.302096,
    "actor_loss": -65.2794189453125,
    "critic_loss": 4.039259433746338,
    "ent_coef": 0.0687364786863327,
    "learning_rate": 0.001
  },
  {
    "episode": 4000,
    "reward": 85.39405,
    "length": 69,
    "time": 62689.54216,
    "actor_loss": -64.55030822753906,
    "critic_loss": 4.776461601257324,
    "ent_coef": 0.07000967860221863,
    "learning_rate": 0.001
  },
  {
    "episode": 4001,
    "reward": 6.885062,
    "length": 171,
    "time": 62714.803165,
    "actor_loss": -67.38720703125,
    "critic_loss": 37.3199577331543,
    "ent_coef": 0.07585929334163666,
    "learning_rate": 0.001
  },
  {
    "episode": 4002,
    "reward": 83.185359,
    "length": 73,
    "time": 62729.215074,
    "actor_loss": -63.272361755371094,
    "critic_loss": 5.992981433868408,
    "ent_coef": 0.07498487085103989,
    "learning_rate": 0.001
  },
  {
    "episode": 4003,
    "reward": 88.370842,
    "length": 66,
    "time": 62741.980462,
    "actor_loss": -63.53997802734375,
    "critic_loss": 6.883718490600586,
    "ent_coef": 0.07382691651582718,
    "learning_rate": 0.001
  },
  {
    "episode": 4004,
    "reward": 90.09309,
    "length": 62,
    "time": 62752.961141,
    "actor_loss": -65.08729553222656,
    "critic_loss": 2.9120798110961914,
    "ent_coef": 0.07657922804355621,
    "learning_rate": 0.001
  },
  {
    "episode": 4005,
    "reward": 84.835423,
    "length": 71,
    "time": 62764.963299,
    "actor_loss": -72.91055297851562,
    "critic_loss": 15.622919082641602,
    "ent_coef": 0.07637925446033478,
    "learning_rate": 0.001
  },
  {
    "episode": 4006,
    "reward": 86.906757,
    "length": 68,
    "time": 62780.307256,
    "actor_loss": -64.87165832519531,
    "critic_loss": 4.09672737121582,
    "ent_coef": 0.07722646743059158,
    "learning_rate": 0.001
  },
  {
    "episode": 4007,
    "reward": 85.053438,
    "length": 72,
    "time": 62792.587486,
    "actor_loss": -69.85613250732422,
    "critic_loss": 19.156408309936523,
    "ent_coef": 0.07564004510641098,
    "learning_rate": 0.001
  },
  {
    "episode": 4008,
    "reward": 76.414095,
    "length": 83,
    "time": 62807.172999,
    "actor_loss": -67.81947326660156,
    "critic_loss": 2.1956911087036133,
    "ent_coef": 0.07391529530286789,
    "learning_rate": 0.001
  },
  {
    "episode": 4009,
    "reward": 78.722885,
    "length": 80,
    "time": 62823.332098,
    "actor_loss": -68.46361541748047,
    "critic_loss": 27.683372497558594,
    "ent_coef": 0.07312668114900589,
    "learning_rate": 0.001
  },
  {
    "episode": 4010,
    "reward": 89.5803,
    "length": 64,
    "time": 62834.558839,
    "actor_loss": -63.823707580566406,
    "critic_loss": 2.7044363021850586,
    "ent_coef": 0.07374101877212524,
    "learning_rate": 0.001
  },
  {
    "episode": 4011,
    "reward": -207.146742,
    "length": 139,
    "time": 62858.468074,
    "actor_loss": -66.6403579711914,
    "critic_loss": 55.16181182861328,
    "ent_coef": 0.06977766752243042,
    "learning_rate": 0.001
  },
  {
    "episode": 4012,
    "reward": 97.227597,
    "length": 67,
    "time": 62874.039663,
    "actor_loss": -63.0224494934082,
    "critic_loss": 139.37167358398438,
    "ent_coef": 0.07007088512182236,
    "learning_rate": 0.001
  },
  {
    "episode": 4013,
    "reward": 84.523195,
    "length": 72,
    "time": 62887.086728,
    "actor_loss": -62.38581085205078,
    "critic_loss": 20.44415283203125,
    "ent_coef": 0.0742959976196289,
    "learning_rate": 0.001
  },
  {
    "episode": 4014,
    "reward": 88.452444,
    "length": 65,
    "time": 62900.56896,
    "actor_loss": -63.56550598144531,
    "critic_loss": 29.092674255371094,
    "ent_coef": 0.07835139334201813,
    "learning_rate": 0.001
  },
  {
    "episode": 4015,
    "reward": 87.95786,
    "length": 67,
    "time": 62912.588481,
    "actor_loss": -71.86762237548828,
    "critic_loss": 2.9361839294433594,
    "ent_coef": 0.07912617921829224,
    "learning_rate": 0.001
  },
  {
    "episode": 4016,
    "reward": 87.188698,
    "length": 68,
    "time": 62928.337685,
    "actor_loss": -59.50542449951172,
    "critic_loss": 2.5921545028686523,
    "ent_coef": 0.07905516773462296,
    "learning_rate": 0.001
  },
  {
    "episode": 4017,
    "reward": 88.569084,
    "length": 66,
    "time": 62942.658607,
    "actor_loss": -64.8765869140625,
    "critic_loss": 2.2398786544799805,
    "ent_coef": 0.08136998862028122,
    "learning_rate": 0.001
  },
  {
    "episode": 4018,
    "reward": 88.41256,
    "length": 65,
    "time": 62955.762193,
    "actor_loss": -62.22917556762695,
    "critic_loss": 3.4298691749572754,
    "ent_coef": 0.08000234514474869,
    "learning_rate": 0.001
  },
  {
    "episode": 4019,
    "reward": 87.867547,
    "length": 68,
    "time": 62969.27104,
    "actor_loss": -62.96537780761719,
    "critic_loss": 5.731398582458496,
    "ent_coef": 0.07672119140625,
    "learning_rate": 0.001
  },
  {
    "episode": 4020,
    "reward": 83.789471,
    "length": 74,
    "time": 62984.194323,
    "actor_loss": -67.65055847167969,
    "critic_loss": 16.50422477722168,
    "ent_coef": 0.0716993436217308,
    "learning_rate": 0.001
  },
  {
    "episode": 4021,
    "reward": 70.669585,
    "length": 95,
    "time": 63001.192307,
    "actor_loss": -61.92310333251953,
    "critic_loss": 2.272327423095703,
    "ent_coef": 0.0655020922422409,
    "learning_rate": 0.001
  },
  {
    "episode": 4022,
    "reward": 83.647765,
    "length": 75,
    "time": 63014.042011,
    "actor_loss": -68.13792419433594,
    "critic_loss": 8.364551544189453,
    "ent_coef": 0.06442409753799438,
    "learning_rate": 0.001
  },
  {
    "episode": 4023,
    "reward": 83.050677,
    "length": 74,
    "time": 63027.969123,
    "actor_loss": -63.92517852783203,
    "critic_loss": 4.915999412536621,
    "ent_coef": 0.06638796627521515,
    "learning_rate": 0.001
  },
  {
    "episode": 4024,
    "reward": 87.873884,
    "length": 67,
    "time": 63045.115435,
    "actor_loss": -67.77774047851562,
    "critic_loss": 3.163078784942627,
    "ent_coef": 0.06572891026735306,
    "learning_rate": 0.001
  },
  {
    "episode": 4025,
    "reward": 77.12398,
    "length": 81,
    "time": 63058.532626,
    "actor_loss": -64.35346984863281,
    "critic_loss": 20.84684181213379,
    "ent_coef": 0.06451967358589172,
    "learning_rate": 0.001
  },
  {
    "episode": 4026,
    "reward": 86.29757,
    "length": 69,
    "time": 63072.318057,
    "actor_loss": -71.9747314453125,
    "critic_loss": 2.346822738647461,
    "ent_coef": 0.06578439474105835,
    "learning_rate": 0.001
  },
  {
    "episode": 4027,
    "reward": 85.006918,
    "length": 71,
    "time": 63087.322836,
    "actor_loss": -60.35133361816406,
    "critic_loss": 2.9798920154571533,
    "ent_coef": 0.06634149700403214,
    "learning_rate": 0.001
  },
  {
    "episode": 4028,
    "reward": 87.514153,
    "length": 68,
    "time": 63099.11836,
    "actor_loss": -66.31071472167969,
    "critic_loss": 3.0598316192626953,
    "ent_coef": 0.06581718474626541,
    "learning_rate": 0.001
  },
  {
    "episode": 4029,
    "reward": 91.069158,
    "length": 61,
    "time": 63111.547496,
    "actor_loss": -65.61327362060547,
    "critic_loss": 3.6845297813415527,
    "ent_coef": 0.07190985232591629,
    "learning_rate": 0.001
  },
  {
    "episode": 4030,
    "reward": 88.69856,
    "length": 66,
    "time": 63125.692233,
    "actor_loss": -59.10411071777344,
    "critic_loss": 8.174421310424805,
    "ent_coef": 0.07458940893411636,
    "learning_rate": 0.001
  },
  {
    "episode": 4031,
    "reward": 85.810427,
    "length": 69,
    "time": 63138.213936,
    "actor_loss": -61.85027313232422,
    "critic_loss": 5.068904876708984,
    "ent_coef": 0.07373066246509552,
    "learning_rate": 0.001
  },
  {
    "episode": 4032,
    "reward": 88.761691,
    "length": 65,
    "time": 63150.876462,
    "actor_loss": -69.48225402832031,
    "critic_loss": 29.92894744873047,
    "ent_coef": 0.07494236528873444,
    "learning_rate": 0.001
  },
  {
    "episode": 4033,
    "reward": 86.80583,
    "length": 69,
    "time": 63165.323127,
    "actor_loss": -64.19404602050781,
    "critic_loss": 42.123260498046875,
    "ent_coef": 0.07411457598209381,
    "learning_rate": 0.001
  },
  {
    "episode": 4034,
    "reward": 85.048677,
    "length": 72,
    "time": 63177.672885,
    "actor_loss": -62.66741180419922,
    "critic_loss": 2.5758190155029297,
    "ent_coef": 0.07100646942853928,
    "learning_rate": 0.001
  },
  {
    "episode": 4035,
    "reward": 87.741687,
    "length": 67,
    "time": 63191.092904,
    "actor_loss": -66.17031860351562,
    "critic_loss": 2.7962610721588135,
    "ent_coef": 0.06921999901533127,
    "learning_rate": 0.001
  },
  {
    "episode": 4036,
    "reward": 87.105431,
    "length": 68,
    "time": 63205.28001,
    "actor_loss": -64.37513732910156,
    "critic_loss": 12.217212677001953,
    "ent_coef": 0.06885702162981033,
    "learning_rate": 0.001
  },
  {
    "episode": 4037,
    "reward": 89.054217,
    "length": 64,
    "time": 63216.74527,
    "actor_loss": -70.51518249511719,
    "critic_loss": 2.871854305267334,
    "ent_coef": 0.0712282732129097,
    "learning_rate": 0.001
  },
  {
    "episode": 4038,
    "reward": 88.086508,
    "length": 66,
    "time": 63229.328905,
    "actor_loss": -64.5792007446289,
    "critic_loss": 1.9732928276062012,
    "ent_coef": 0.06990142166614532,
    "learning_rate": 0.001
  },
  {
    "episode": 4039,
    "reward": 90.148209,
    "length": 62,
    "time": 63242.202456,
    "actor_loss": -71.06983947753906,
    "critic_loss": 8.919517517089844,
    "ent_coef": 0.07261303812265396,
    "learning_rate": 0.001
  },
  {
    "episode": 4040,
    "reward": 87.055986,
    "length": 68,
    "time": 63253.882552,
    "actor_loss": -65.47529602050781,
    "critic_loss": 16.55874252319336,
    "ent_coef": 0.07358178496360779,
    "learning_rate": 0.001
  },
  {
    "episode": 4041,
    "reward": 88.652372,
    "length": 65,
    "time": 63266.47067,
    "actor_loss": -58.3774528503418,
    "critic_loss": 2.676258087158203,
    "ent_coef": 0.07129987329244614,
    "learning_rate": 0.001
  },
  {
    "episode": 4042,
    "reward": 88.551042,
    "length": 65,
    "time": 63278.152928,
    "actor_loss": -56.360496520996094,
    "critic_loss": 3.563307285308838,
    "ent_coef": 0.070826455950737,
    "learning_rate": 0.001
  },
  {
    "episode": 4043,
    "reward": 88.613386,
    "length": 68,
    "time": 63289.834422,
    "actor_loss": -63.65314865112305,
    "critic_loss": 2.577061176300049,
    "ent_coef": 0.07131318002939224,
    "learning_rate": 0.001
  },
  {
    "episode": 4044,
    "reward": 86.937431,
    "length": 67,
    "time": 63301.569614,
    "actor_loss": -70.4986801147461,
    "critic_loss": 11.814960479736328,
    "ent_coef": 0.07226568460464478,
    "learning_rate": 0.001
  },
  {
    "episode": 4045,
    "reward": 90.326651,
    "length": 62,
    "time": 63314.348416,
    "actor_loss": -72.16372680664062,
    "critic_loss": 60.969390869140625,
    "ent_coef": 0.07579515129327774,
    "learning_rate": 0.001
  },
  {
    "episode": 4046,
    "reward": 87.437707,
    "length": 67,
    "time": 63327.661731,
    "actor_loss": -62.55155944824219,
    "critic_loss": 4.691897869110107,
    "ent_coef": 0.07713761180639267,
    "learning_rate": 0.001
  },
  {
    "episode": 4047,
    "reward": 87.862383,
    "length": 67,
    "time": 63339.314765,
    "actor_loss": -66.97444152832031,
    "critic_loss": 1.927722454071045,
    "ent_coef": 0.07619422674179077,
    "learning_rate": 0.001
  },
  {
    "episode": 4048,
    "reward": 87.939791,
    "length": 71,
    "time": 63352.611254,
    "actor_loss": -64.0886001586914,
    "critic_loss": 19.946243286132812,
    "ent_coef": 0.07861973345279694,
    "learning_rate": 0.001
  },
  {
    "episode": 4049,
    "reward": 86.791631,
    "length": 69,
    "time": 63364.283185,
    "actor_loss": -63.91078567504883,
    "critic_loss": 2.2370662689208984,
    "ent_coef": 0.07783422619104385,
    "learning_rate": 0.001
  },
  {
    "episode": 4050,
    "reward": 87.119581,
    "length": 68,
    "time": 63376.590039,
    "actor_loss": -66.44135284423828,
    "critic_loss": 2.0203869342803955,
    "ent_coef": 0.07614807784557343,
    "learning_rate": 0.001
  },
  {
    "episode": 4051,
    "reward": 88.444963,
    "length": 66,
    "time": 63392.772904,
    "actor_loss": -64.96967315673828,
    "critic_loss": 9.753061294555664,
    "ent_coef": 0.07727010548114777,
    "learning_rate": 0.001
  },
  {
    "episode": 4052,
    "reward": 90.001835,
    "length": 63,
    "time": 63404.698451,
    "actor_loss": -63.36711120605469,
    "critic_loss": 32.35273742675781,
    "ent_coef": 0.07707460969686508,
    "learning_rate": 0.001
  },
  {
    "episode": 4053,
    "reward": 86.033604,
    "length": 70,
    "time": 63418.747112,
    "actor_loss": -62.39586639404297,
    "critic_loss": 17.280048370361328,
    "ent_coef": 0.07415816187858582,
    "learning_rate": 0.001
  },
  {
    "episode": 4054,
    "reward": 88.449378,
    "length": 67,
    "time": 63430.328805,
    "actor_loss": -60.95937728881836,
    "critic_loss": 28.732173919677734,
    "ent_coef": 0.07249768823385239,
    "learning_rate": 0.001
  },
  {
    "episode": 4055,
    "reward": 88.111884,
    "length": 66,
    "time": 63441.936843,
    "actor_loss": -67.66824340820312,
    "critic_loss": 2.108135223388672,
    "ent_coef": 0.07025785744190216,
    "learning_rate": 0.001
  },
  {
    "episode": 4056,
    "reward": 84.845108,
    "length": 72,
    "time": 63454.427028,
    "actor_loss": -67.26373291015625,
    "critic_loss": 3.4701108932495117,
    "ent_coef": 0.06606071442365646,
    "learning_rate": 0.001
  },
  {
    "episode": 4057,
    "reward": 86.828506,
    "length": 69,
    "time": 63466.590965,
    "actor_loss": -69.8565673828125,
    "critic_loss": 3.3288064002990723,
    "ent_coef": 0.06400507688522339,
    "learning_rate": 0.001
  },
  {
    "episode": 4058,
    "reward": 85.416598,
    "length": 72,
    "time": 63478.662654,
    "actor_loss": -69.8727035522461,
    "critic_loss": 17.31678009033203,
    "ent_coef": 0.061626311391592026,
    "learning_rate": 0.001
  },
  {
    "episode": 4059,
    "reward": 87.93634,
    "length": 67,
    "time": 63494.172188,
    "actor_loss": -61.05146026611328,
    "critic_loss": 2.4497880935668945,
    "ent_coef": 0.0619896724820137,
    "learning_rate": 0.001
  },
  {
    "episode": 4060,
    "reward": 88.4058,
    "length": 65,
    "time": 63508.980754,
    "actor_loss": -63.85737228393555,
    "critic_loss": 27.028766632080078,
    "ent_coef": 0.06455416977405548,
    "learning_rate": 0.001
  },
  {
    "episode": 4061,
    "reward": 90.094705,
    "length": 63,
    "time": 63520.355383,
    "actor_loss": -67.7362060546875,
    "critic_loss": 29.732812881469727,
    "ent_coef": 0.06662725657224655,
    "learning_rate": 0.001
  },
  {
    "episode": 4062,
    "reward": 90.109711,
    "length": 63,
    "time": 63533.507381,
    "actor_loss": -63.91908264160156,
    "critic_loss": 3.6853291988372803,
    "ent_coef": 0.0705544501543045,
    "learning_rate": 0.001
  },
  {
    "episode": 4063,
    "reward": 81.388882,
    "length": 76,
    "time": 63547.118712,
    "actor_loss": -65.643310546875,
    "critic_loss": 6.056135654449463,
    "ent_coef": 0.06724407523870468,
    "learning_rate": 0.001
  },
  {
    "episode": 4064,
    "reward": 89.533306,
    "length": 64,
    "time": 63560.108438,
    "actor_loss": -69.47004699707031,
    "critic_loss": 18.08859634399414,
    "ent_coef": 0.06612460315227509,
    "learning_rate": 0.001
  },
  {
    "episode": 4065,
    "reward": 87.139844,
    "length": 72,
    "time": 63573.68943,
    "actor_loss": -61.35313415527344,
    "critic_loss": 2.9768154621124268,
    "ent_coef": 0.06498183310031891,
    "learning_rate": 0.001
  },
  {
    "episode": 4066,
    "reward": 85.26319,
    "length": 73,
    "time": 63586.911525,
    "actor_loss": -64.10902404785156,
    "critic_loss": 2.761456251144409,
    "ent_coef": 0.0632483959197998,
    "learning_rate": 0.001
  },
  {
    "episode": 4067,
    "reward": 83.716551,
    "length": 74,
    "time": 63599.932275,
    "actor_loss": -60.12259292602539,
    "critic_loss": 3.1311123371124268,
    "ent_coef": 0.06411103159189224,
    "learning_rate": 0.001
  },
  {
    "episode": 4068,
    "reward": 87.863084,
    "length": 66,
    "time": 63611.466037,
    "actor_loss": -61.36924743652344,
    "critic_loss": 6.843092441558838,
    "ent_coef": 0.06770659983158112,
    "learning_rate": 0.001
  },
  {
    "episode": 4069,
    "reward": 85.935828,
    "length": 74,
    "time": 63624.710155,
    "actor_loss": -68.50830078125,
    "critic_loss": 2.5681872367858887,
    "ent_coef": 0.0664537325501442,
    "learning_rate": 0.001
  },
  {
    "episode": 4070,
    "reward": 90.793062,
    "length": 62,
    "time": 63638.330976,
    "actor_loss": -68.27633666992188,
    "critic_loss": 11.175572395324707,
    "ent_coef": 0.06950458884239197,
    "learning_rate": 0.001
  },
  {
    "episode": 4071,
    "reward": 83.384083,
    "length": 76,
    "time": 63651.228333,
    "actor_loss": -63.07529830932617,
    "critic_loss": 22.664154052734375,
    "ent_coef": 0.06654659658670425,
    "learning_rate": 0.001
  },
  {
    "episode": 4072,
    "reward": 85.372547,
    "length": 70,
    "time": 63663.246035,
    "actor_loss": -60.76482391357422,
    "critic_loss": 13.820290565490723,
    "ent_coef": 0.06607368588447571,
    "learning_rate": 0.001
  },
  {
    "episode": 4073,
    "reward": 87.42742,
    "length": 71,
    "time": 63676.447077,
    "actor_loss": -59.37518310546875,
    "critic_loss": 3.776590585708618,
    "ent_coef": 0.0708424299955368,
    "learning_rate": 0.001
  },
  {
    "episode": 4074,
    "reward": 87.729473,
    "length": 65,
    "time": 63688.134566,
    "actor_loss": -60.627357482910156,
    "critic_loss": 3.64914608001709,
    "ent_coef": 0.0714806318283081,
    "learning_rate": 0.001
  },
  {
    "episode": 4075,
    "reward": 88.030845,
    "length": 66,
    "time": 63699.900162,
    "actor_loss": -60.674957275390625,
    "critic_loss": 1.8579418659210205,
    "ent_coef": 0.07105633616447449,
    "learning_rate": 0.001
  },
  {
    "episode": 4076,
    "reward": 85.248941,
    "length": 71,
    "time": 63712.739909,
    "actor_loss": -67.19747161865234,
    "critic_loss": 6.569370269775391,
    "ent_coef": 0.07016948610544205,
    "learning_rate": 0.001
  },
  {
    "episode": 4077,
    "reward": 88.721737,
    "length": 66,
    "time": 63724.362947,
    "actor_loss": -64.91786193847656,
    "critic_loss": 5.442058563232422,
    "ent_coef": 0.06935840100049973,
    "learning_rate": 0.001
  },
  {
    "episode": 4078,
    "reward": 82.457843,
    "length": 80,
    "time": 63737.581548,
    "actor_loss": -71.02197265625,
    "critic_loss": 10.521868705749512,
    "ent_coef": 0.07094959169626236,
    "learning_rate": 0.001
  },
  {
    "episode": 4079,
    "reward": 86.538082,
    "length": 70,
    "time": 63749.748289,
    "actor_loss": -63.021785736083984,
    "critic_loss": 3.802299737930298,
    "ent_coef": 0.06887426227331161,
    "learning_rate": 0.001
  },
  {
    "episode": 4080,
    "reward": 81.183324,
    "length": 79,
    "time": 63766.422635,
    "actor_loss": -66.91229248046875,
    "critic_loss": 5.551166534423828,
    "ent_coef": 0.06372392177581787,
    "learning_rate": 0.001
  },
  {
    "episode": 4081,
    "reward": 88.02393,
    "length": 66,
    "time": 63779.958907,
    "actor_loss": -61.28102111816406,
    "critic_loss": 2.463855266571045,
    "ent_coef": 0.06397277861833572,
    "learning_rate": 0.001
  },
  {
    "episode": 4082,
    "reward": 88.426982,
    "length": 66,
    "time": 63794.728521,
    "actor_loss": -64.9278335571289,
    "critic_loss": 2.9383318424224854,
    "ent_coef": 0.06476158648729324,
    "learning_rate": 0.001
  },
  {
    "episode": 4083,
    "reward": 89.410363,
    "length": 65,
    "time": 63806.075665,
    "actor_loss": -69.3809814453125,
    "critic_loss": 11.670222282409668,
    "ent_coef": 0.06374238431453705,
    "learning_rate": 0.001
  },
  {
    "episode": 4084,
    "reward": 87.857939,
    "length": 67,
    "time": 63817.669673,
    "actor_loss": -64.9317626953125,
    "critic_loss": 14.074451446533203,
    "ent_coef": 0.062264084815979004,
    "learning_rate": 0.001
  },
  {
    "episode": 4085,
    "reward": 80.557594,
    "length": 83,
    "time": 63831.079494,
    "actor_loss": -59.216129302978516,
    "critic_loss": 8.279787063598633,
    "ent_coef": 0.06005784869194031,
    "learning_rate": 0.001
  },
  {
    "episode": 4086,
    "reward": 85.701539,
    "length": 70,
    "time": 63843.288061,
    "actor_loss": -61.421573638916016,
    "critic_loss": 4.607814788818359,
    "ent_coef": 0.06269383430480957,
    "learning_rate": 0.001
  },
  {
    "episode": 4087,
    "reward": 87.936869,
    "length": 66,
    "time": 63857.79087,
    "actor_loss": -64.00044250488281,
    "critic_loss": 2.821553945541382,
    "ent_coef": 0.0636252835392952,
    "learning_rate": 0.001
  },
  {
    "episode": 4088,
    "reward": 86.850695,
    "length": 69,
    "time": 63870.1362,
    "actor_loss": -67.70597839355469,
    "critic_loss": 4.116382122039795,
    "ent_coef": 0.061491094529628754,
    "learning_rate": 0.001
  },
  {
    "episode": 4089,
    "reward": 87.165173,
    "length": 67,
    "time": 63882.704403,
    "actor_loss": -66.99365234375,
    "critic_loss": 72.10356903076172,
    "ent_coef": 0.06303069740533829,
    "learning_rate": 0.001
  },
  {
    "episode": 4090,
    "reward": 88.036338,
    "length": 67,
    "time": 63895.269418,
    "actor_loss": -66.73350524902344,
    "critic_loss": 2.5712873935699463,
    "ent_coef": 0.0643165111541748,
    "learning_rate": 0.001
  },
  {
    "episode": 4091,
    "reward": 88.38084,
    "length": 65,
    "time": 63906.704266,
    "actor_loss": -59.71685791015625,
    "critic_loss": 9.084005355834961,
    "ent_coef": 0.06530444324016571,
    "learning_rate": 0.001
  },
  {
    "episode": 4092,
    "reward": 90.148079,
    "length": 62,
    "time": 63918.707529,
    "actor_loss": -67.28839874267578,
    "critic_loss": 20.13857650756836,
    "ent_coef": 0.06628254055976868,
    "learning_rate": 0.001
  },
  {
    "episode": 4093,
    "reward": 88.830849,
    "length": 64,
    "time": 63931.095008,
    "actor_loss": -65.4789047241211,
    "critic_loss": 5.302189826965332,
    "ent_coef": 0.06521334499120712,
    "learning_rate": 0.001
  },
  {
    "episode": 4094,
    "reward": 84.830689,
    "length": 76,
    "time": 63944.407011,
    "actor_loss": -61.10134506225586,
    "critic_loss": 3.1759352684020996,
    "ent_coef": 0.0687696561217308,
    "learning_rate": 0.001
  },
  {
    "episode": 4095,
    "reward": 87.283064,
    "length": 68,
    "time": 63957.054403,
    "actor_loss": -70.22443389892578,
    "critic_loss": 4.981910705566406,
    "ent_coef": 0.07157206535339355,
    "learning_rate": 0.001
  },
  {
    "episode": 4096,
    "reward": 88.446634,
    "length": 65,
    "time": 63970.333473,
    "actor_loss": -64.60977172851562,
    "critic_loss": 6.601539611816406,
    "ent_coef": 0.07455237209796906,
    "learning_rate": 0.001
  },
  {
    "episode": 4097,
    "reward": 79.339116,
    "length": 86,
    "time": 63984.624135,
    "actor_loss": -63.50324249267578,
    "critic_loss": 24.208526611328125,
    "ent_coef": 0.07758146524429321,
    "learning_rate": 0.001
  },
  {
    "episode": 4098,
    "reward": 84.435294,
    "length": 77,
    "time": 63998.006292,
    "actor_loss": -63.33866882324219,
    "critic_loss": 6.609666347503662,
    "ent_coef": 0.07903848588466644,
    "learning_rate": 0.001
  },
  {
    "episode": 4099,
    "reward": 82.334503,
    "length": 78,
    "time": 64013.82332,
    "actor_loss": -62.322044372558594,
    "critic_loss": 3.256619453430176,
    "ent_coef": 0.08240707218647003,
    "learning_rate": 0.001
  },
  {
    "episode": 4100,
    "reward": 85.705463,
    "length": 75,
    "time": 64026.874583,
    "actor_loss": -69.41604614257812,
    "critic_loss": 3.7492616176605225,
    "ent_coef": 0.08375760167837143,
    "learning_rate": 0.001
  },
  {
    "episode": 4101,
    "reward": 78.125336,
    "length": 88,
    "time": 64042.141814,
    "actor_loss": -65.55665588378906,
    "critic_loss": 4.377513885498047,
    "ent_coef": 0.08679768443107605,
    "learning_rate": 0.001
  },
  {
    "episode": 4102,
    "reward": 81.178472,
    "length": 96,
    "time": 64057.963027,
    "actor_loss": -65.61344146728516,
    "critic_loss": 2.229595184326172,
    "ent_coef": 0.08262897282838821,
    "learning_rate": 0.001
  },
  {
    "episode": 4103,
    "reward": 82.513791,
    "length": 89,
    "time": 64076.363003,
    "actor_loss": -73.00518798828125,
    "critic_loss": 4.482812404632568,
    "ent_coef": 0.08117793500423431,
    "learning_rate": 0.001
  },
  {
    "episode": 4104,
    "reward": 75.590267,
    "length": 93,
    "time": 64093.110101,
    "actor_loss": -69.28893280029297,
    "critic_loss": 2.88449764251709,
    "ent_coef": 0.07318703085184097,
    "learning_rate": 0.001
  },
  {
    "episode": 4105,
    "reward": 89.594974,
    "length": 64,
    "time": 64106.468323,
    "actor_loss": -65.91886901855469,
    "critic_loss": 19.900718688964844,
    "ent_coef": 0.07134681940078735,
    "learning_rate": 0.001
  },
  {
    "episode": 4106,
    "reward": 84.4868,
    "length": 74,
    "time": 64119.831251,
    "actor_loss": -70.29014587402344,
    "critic_loss": 22.92934799194336,
    "ent_coef": 0.06784814596176147,
    "learning_rate": 0.001
  },
  {
    "episode": 4107,
    "reward": 84.385842,
    "length": 76,
    "time": 64132.547809,
    "actor_loss": -67.92950439453125,
    "critic_loss": 7.480952262878418,
    "ent_coef": 0.0667467713356018,
    "learning_rate": 0.001
  },
  {
    "episode": 4108,
    "reward": 70.050035,
    "length": 120,
    "time": 64152.340083,
    "actor_loss": -64.01296997070312,
    "critic_loss": 14.495853424072266,
    "ent_coef": 0.0688200294971466,
    "learning_rate": 0.001
  },
  {
    "episode": 4109,
    "reward": 90.179587,
    "length": 63,
    "time": 64164.884755,
    "actor_loss": -64.05989074707031,
    "critic_loss": 2.1908583641052246,
    "ent_coef": 0.07015610486268997,
    "learning_rate": 0.001
  },
  {
    "episode": 4110,
    "reward": 87.866465,
    "length": 69,
    "time": 64177.308634,
    "actor_loss": -62.722415924072266,
    "critic_loss": 9.219986915588379,
    "ent_coef": 0.0795028880238533,
    "learning_rate": 0.001
  },
  {
    "episode": 4111,
    "reward": 89.733796,
    "length": 64,
    "time": 64188.927405,
    "actor_loss": -62.08708953857422,
    "critic_loss": 4.306025505065918,
    "ent_coef": 0.08461598306894302,
    "learning_rate": 0.001
  },
  {
    "episode": 4112,
    "reward": 87.176793,
    "length": 67,
    "time": 64201.400926,
    "actor_loss": -63.49928283691406,
    "critic_loss": 2.8319010734558105,
    "ent_coef": 0.082548126578331,
    "learning_rate": 0.001
  },
  {
    "episode": 4113,
    "reward": 82.961058,
    "length": 81,
    "time": 64214.941701,
    "actor_loss": -62.512908935546875,
    "critic_loss": 3.4280810356140137,
    "ent_coef": 0.07896198332309723,
    "learning_rate": 0.001
  },
  {
    "episode": 4114,
    "reward": 80.536788,
    "length": 94,
    "time": 64231.022791,
    "actor_loss": -65.38311767578125,
    "critic_loss": 31.01412582397461,
    "ent_coef": 0.073306605219841,
    "learning_rate": 0.001
  },
  {
    "episode": 4115,
    "reward": 86.252376,
    "length": 68,
    "time": 64245.240778,
    "actor_loss": -61.82164001464844,
    "critic_loss": 32.83821105957031,
    "ent_coef": 0.07370584458112717,
    "learning_rate": 0.001
  },
  {
    "episode": 4116,
    "reward": 82.08881,
    "length": 86,
    "time": 64260.666911,
    "actor_loss": -62.70770263671875,
    "critic_loss": 4.786341190338135,
    "ent_coef": 0.0735633447766304,
    "learning_rate": 0.001
  },
  {
    "episode": 4117,
    "reward": 90.499398,
    "length": 63,
    "time": 64272.659163,
    "actor_loss": -64.55525207519531,
    "critic_loss": 6.202509880065918,
    "ent_coef": 0.07610026001930237,
    "learning_rate": 0.001
  },
  {
    "episode": 4118,
    "reward": 79.990948,
    "length": 80,
    "time": 64287.64276,
    "actor_loss": -72.05757904052734,
    "critic_loss": 2.6229515075683594,
    "ent_coef": 0.0706225261092186,
    "learning_rate": 0.001
  },
  {
    "episode": 4119,
    "reward": 80.325208,
    "length": 78,
    "time": 64301.69425,
    "actor_loss": -62.15620422363281,
    "critic_loss": 9.027994155883789,
    "ent_coef": 0.0685940682888031,
    "learning_rate": 0.001
  },
  {
    "episode": 4120,
    "reward": 90.871558,
    "length": 61,
    "time": 64312.784874,
    "actor_loss": -64.60264587402344,
    "critic_loss": 34.03716278076172,
    "ent_coef": 0.0715031623840332,
    "learning_rate": 0.001
  },
  {
    "episode": 4121,
    "reward": 91.193195,
    "length": 61,
    "time": 64323.791939,
    "actor_loss": -60.46297073364258,
    "critic_loss": 13.666028022766113,
    "ent_coef": 0.07231771945953369,
    "learning_rate": 0.001
  },
  {
    "episode": 4122,
    "reward": 88.839842,
    "length": 66,
    "time": 64336.29186,
    "actor_loss": -59.23948287963867,
    "critic_loss": 41.392486572265625,
    "ent_coef": 0.07226668298244476,
    "learning_rate": 0.001
  },
  {
    "episode": 4123,
    "reward": 82.347672,
    "length": 79,
    "time": 64349.501734,
    "actor_loss": -71.55426025390625,
    "critic_loss": 21.76378631591797,
    "ent_coef": 0.06939639896154404,
    "learning_rate": 0.001
  },
  {
    "episode": 4124,
    "reward": 90.833887,
    "length": 62,
    "time": 64360.601756,
    "actor_loss": -67.43257904052734,
    "critic_loss": 3.39355731010437,
    "ent_coef": 0.06975957006216049,
    "learning_rate": 0.001
  },
  {
    "episode": 4125,
    "reward": 84.819989,
    "length": 75,
    "time": 64373.114128,
    "actor_loss": -59.60215759277344,
    "critic_loss": 7.001216411590576,
    "ent_coef": 0.0684363842010498,
    "learning_rate": 0.001
  },
  {
    "episode": 4126,
    "reward": 86.37239,
    "length": 73,
    "time": 64386.420703,
    "actor_loss": -61.1304817199707,
    "critic_loss": 12.49178695678711,
    "ent_coef": 0.06928209215402603,
    "learning_rate": 0.001
  },
  {
    "episode": 4127,
    "reward": 89.124797,
    "length": 65,
    "time": 64397.78192,
    "actor_loss": -64.8133544921875,
    "critic_loss": 11.569247245788574,
    "ent_coef": 0.07285124063491821,
    "learning_rate": 0.001
  },
  {
    "episode": 4128,
    "reward": 86.548366,
    "length": 70,
    "time": 64413.314888,
    "actor_loss": -63.51003646850586,
    "critic_loss": 3.859111785888672,
    "ent_coef": 0.0729856863617897,
    "learning_rate": 0.001
  },
  {
    "episode": 4129,
    "reward": 87.815247,
    "length": 67,
    "time": 64424.859714,
    "actor_loss": -62.033653259277344,
    "critic_loss": 2.7684519290924072,
    "ent_coef": 0.07317826896905899,
    "learning_rate": 0.001
  },
  {
    "episode": 4130,
    "reward": 89.058838,
    "length": 65,
    "time": 64437.999867,
    "actor_loss": -62.284873962402344,
    "critic_loss": 26.155269622802734,
    "ent_coef": 0.07334814220666885,
    "learning_rate": 0.001
  },
  {
    "episode": 4131,
    "reward": 85.653128,
    "length": 70,
    "time": 64451.802982,
    "actor_loss": -67.757080078125,
    "critic_loss": 7.047519207000732,
    "ent_coef": 0.07358855754137039,
    "learning_rate": 0.001
  },
  {
    "episode": 4132,
    "reward": 84.028882,
    "length": 78,
    "time": 64464.768794,
    "actor_loss": -61.948123931884766,
    "critic_loss": 4.923620223999023,
    "ent_coef": 0.09342648833990097,
    "learning_rate": 0.001
  },
  {
    "episode": 4133,
    "reward": 86.828374,
    "length": 68,
    "time": 64477.174868,
    "actor_loss": -62.74782180786133,
    "critic_loss": 7.258029937744141,
    "ent_coef": 0.1097077876329422,
    "learning_rate": 0.001
  },
  {
    "episode": 4134,
    "reward": 80.400503,
    "length": 90,
    "time": 64492.006315,
    "actor_loss": -62.8807487487793,
    "critic_loss": 2.9761252403259277,
    "ent_coef": 0.1133919209241867,
    "learning_rate": 0.001
  },
  {
    "episode": 4135,
    "reward": 85.08361,
    "length": 81,
    "time": 64506.330253,
    "actor_loss": -61.731483459472656,
    "critic_loss": 2.5709595680236816,
    "ent_coef": 0.11757239699363708,
    "learning_rate": 0.001
  },
  {
    "episode": 4136,
    "reward": 62.866728,
    "length": 118,
    "time": 64525.860982,
    "actor_loss": -65.29507446289062,
    "critic_loss": 15.094602584838867,
    "ent_coef": 0.12709467113018036,
    "learning_rate": 0.001
  },
  {
    "episode": 4137,
    "reward": 83.635405,
    "length": 84,
    "time": 64541.121856,
    "actor_loss": -63.300621032714844,
    "critic_loss": 9.702574729919434,
    "ent_coef": 0.1295625865459442,
    "learning_rate": 0.001
  },
  {
    "episode": 4138,
    "reward": 76.463467,
    "length": 98,
    "time": 64557.730693,
    "actor_loss": -65.4949722290039,
    "critic_loss": 5.565224647521973,
    "ent_coef": 0.12288583815097809,
    "learning_rate": 0.001
  },
  {
    "episode": 4139,
    "reward": 78.600612,
    "length": 93,
    "time": 64575.302976,
    "actor_loss": -60.83806610107422,
    "critic_loss": 4.502789497375488,
    "ent_coef": 0.11714880913496017,
    "learning_rate": 0.001
  },
  {
    "episode": 4140,
    "reward": 74.203248,
    "length": 101,
    "time": 64591.695028,
    "actor_loss": -66.56682586669922,
    "critic_loss": 10.596970558166504,
    "ent_coef": 0.11368326842784882,
    "learning_rate": 0.001
  },
  {
    "episode": 4141,
    "reward": 79.152801,
    "length": 94,
    "time": 64609.883492,
    "actor_loss": -66.2883529663086,
    "critic_loss": 44.70219039916992,
    "ent_coef": 0.10773007571697235,
    "learning_rate": 0.001
  },
  {
    "episode": 4142,
    "reward": 79.246766,
    "length": 93,
    "time": 64625.741872,
    "actor_loss": -67.18264770507812,
    "critic_loss": 7.194771766662598,
    "ent_coef": 0.1002545952796936,
    "learning_rate": 0.001
  },
  {
    "episode": 4143,
    "reward": 75.287091,
    "length": 103,
    "time": 64643.974471,
    "actor_loss": -66.35285949707031,
    "critic_loss": 13.37881088256836,
    "ent_coef": 0.09373410791158676,
    "learning_rate": 0.001
  },
  {
    "episode": 4144,
    "reward": 77.856127,
    "length": 98,
    "time": 64659.705991,
    "actor_loss": -66.17572784423828,
    "critic_loss": 21.91445541381836,
    "ent_coef": 0.08735615015029907,
    "learning_rate": 0.001
  },
  {
    "episode": 4145,
    "reward": 82.972849,
    "length": 88,
    "time": 64673.901537,
    "actor_loss": -64.65617370605469,
    "critic_loss": 1.9656777381896973,
    "ent_coef": 0.08432788401842117,
    "learning_rate": 0.001
  },
  {
    "episode": 4146,
    "reward": 78.076537,
    "length": 95,
    "time": 64689.240067,
    "actor_loss": -65.37300109863281,
    "critic_loss": 21.336387634277344,
    "ent_coef": 0.08089323341846466,
    "learning_rate": 0.001
  },
  {
    "episode": 4147,
    "reward": 85.955595,
    "length": 74,
    "time": 64705.039189,
    "actor_loss": -64.09648132324219,
    "critic_loss": 10.459033966064453,
    "ent_coef": 0.07904548197984695,
    "learning_rate": 0.001
  },
  {
    "episode": 4148,
    "reward": 82.220201,
    "length": 89,
    "time": 64719.657222,
    "actor_loss": -66.39224243164062,
    "critic_loss": 10.045116424560547,
    "ent_coef": 0.08001575618982315,
    "learning_rate": 0.001
  },
  {
    "episode": 4149,
    "reward": 84.284687,
    "length": 88,
    "time": 64734.352287,
    "actor_loss": -63.83269119262695,
    "critic_loss": 13.062551498413086,
    "ent_coef": 0.08186980336904526,
    "learning_rate": 0.001
  },
  {
    "episode": 4150,
    "reward": 82.649059,
    "length": 90,
    "time": 64751.960489,
    "actor_loss": -65.22183227539062,
    "critic_loss": 35.47027587890625,
    "ent_coef": 0.08262614160776138,
    "learning_rate": 0.001
  },
  {
    "episode": 4151,
    "reward": 89.091422,
    "length": 65,
    "time": 64766.008702,
    "actor_loss": -72.26725006103516,
    "critic_loss": 26.130815505981445,
    "ent_coef": 0.0830756425857544,
    "learning_rate": 0.001
  },
  {
    "episode": 4152,
    "reward": -159.135292,
    "length": 151,
    "time": 64791.010704,
    "actor_loss": -82.114990234375,
    "critic_loss": 34.95012283325195,
    "ent_coef": 0.08054638653993607,
    "learning_rate": 0.001
  },
  {
    "episode": 4153,
    "reward": 90.753099,
    "length": 69,
    "time": 64804.489529,
    "actor_loss": -64.1244888305664,
    "critic_loss": 16.702762603759766,
    "ent_coef": 0.08062554150819778,
    "learning_rate": 0.001
  },
  {
    "episode": 4154,
    "reward": 77.468581,
    "length": 97,
    "time": 64820.641648,
    "actor_loss": -60.27356719970703,
    "critic_loss": 33.33527755737305,
    "ent_coef": 0.07791616022586823,
    "learning_rate": 0.001
  },
  {
    "episode": 4155,
    "reward": 87.161782,
    "length": 69,
    "time": 64834.414499,
    "actor_loss": -64.45922088623047,
    "critic_loss": 1.8879727125167847,
    "ent_coef": 0.075884148478508,
    "learning_rate": 0.001
  },
  {
    "episode": 4156,
    "reward": 85.280724,
    "length": 75,
    "time": 64846.926011,
    "actor_loss": -59.649375915527344,
    "critic_loss": 6.236086845397949,
    "ent_coef": 0.07352079451084137,
    "learning_rate": 0.001
  },
  {
    "episode": 4157,
    "reward": 85.908365,
    "length": 71,
    "time": 64860.700568,
    "actor_loss": -69.26813507080078,
    "critic_loss": 3.4417996406555176,
    "ent_coef": 0.0717020258307457,
    "learning_rate": 0.001
  },
  {
    "episode": 4158,
    "reward": 84.428438,
    "length": 74,
    "time": 64875.923307,
    "actor_loss": -67.9898681640625,
    "critic_loss": 5.115082740783691,
    "ent_coef": 0.06963532418012619,
    "learning_rate": 0.001
  },
  {
    "episode": 4159,
    "reward": 85.771074,
    "length": 71,
    "time": 64888.081696,
    "actor_loss": -82.20376586914062,
    "critic_loss": 20.358501434326172,
    "ent_coef": 0.06943346560001373,
    "learning_rate": 0.001
  },
  {
    "episode": 4160,
    "reward": 79.668502,
    "length": 79,
    "time": 64902.082738,
    "actor_loss": -62.21727752685547,
    "critic_loss": 27.571168899536133,
    "ent_coef": 0.07006265968084335,
    "learning_rate": 0.001
  },
  {
    "episode": 4161,
    "reward": 81.021004,
    "length": 92,
    "time": 64917.074479,
    "actor_loss": -65.90673828125,
    "critic_loss": 20.477313995361328,
    "ent_coef": 0.06884177029132843,
    "learning_rate": 0.001
  },
  {
    "episode": 4162,
    "reward": 77.045411,
    "length": 97,
    "time": 64934.111907,
    "actor_loss": -64.8687744140625,
    "critic_loss": 16.578842163085938,
    "ent_coef": 0.06830325722694397,
    "learning_rate": 0.001
  },
  {
    "episode": 4163,
    "reward": 81.825017,
    "length": 86,
    "time": 64951.701324,
    "actor_loss": -67.66305541992188,
    "critic_loss": 6.348783493041992,
    "ent_coef": 0.07372342050075531,
    "learning_rate": 0.001
  },
  {
    "episode": 4164,
    "reward": 91.013662,
    "length": 62,
    "time": 64964.170231,
    "actor_loss": -65.82268524169922,
    "critic_loss": 7.620686054229736,
    "ent_coef": 0.08237344771623611,
    "learning_rate": 0.001
  },
  {
    "episode": 4165,
    "reward": 89.273508,
    "length": 65,
    "time": 64977.024868,
    "actor_loss": -67.85258483886719,
    "critic_loss": 4.909867286682129,
    "ent_coef": 0.08413607627153397,
    "learning_rate": 0.001
  },
  {
    "episode": 4166,
    "reward": 84.498312,
    "length": 73,
    "time": 64991.203846,
    "actor_loss": -63.76322937011719,
    "critic_loss": 19.222232818603516,
    "ent_coef": 0.08166959136724472,
    "learning_rate": 0.001
  },
  {
    "episode": 4167,
    "reward": 77.474435,
    "length": 97,
    "time": 65006.957606,
    "actor_loss": -66.12078857421875,
    "critic_loss": 6.303053855895996,
    "ent_coef": 0.07825930416584015,
    "learning_rate": 0.001
  },
  {
    "episode": 4168,
    "reward": 83.282338,
    "length": 75,
    "time": 65021.38079,
    "actor_loss": -67.20464324951172,
    "critic_loss": 7.4720306396484375,
    "ent_coef": 0.0760260671377182,
    "learning_rate": 0.001
  },
  {
    "episode": 4169,
    "reward": 79.155157,
    "length": 95,
    "time": 65037.473888,
    "actor_loss": -62.13496398925781,
    "critic_loss": 6.441230773925781,
    "ent_coef": 0.07172981649637222,
    "learning_rate": 0.001
  },
  {
    "episode": 4170,
    "reward": 83.553266,
    "length": 86,
    "time": 65051.788106,
    "actor_loss": -56.766937255859375,
    "critic_loss": 5.514558792114258,
    "ent_coef": 0.07235444337129593,
    "learning_rate": 0.001
  },
  {
    "episode": 4171,
    "reward": 80.888267,
    "length": 91,
    "time": 65070.489856,
    "actor_loss": -60.238014221191406,
    "critic_loss": 106.79843139648438,
    "ent_coef": 0.07306025177240372,
    "learning_rate": 0.001
  },
  {
    "episode": 4172,
    "reward": 82.222263,
    "length": 86,
    "time": 65086.821679,
    "actor_loss": -58.013702392578125,
    "critic_loss": 16.971458435058594,
    "ent_coef": 0.07273443043231964,
    "learning_rate": 0.001
  },
  {
    "episode": 4173,
    "reward": 86.362711,
    "length": 71,
    "time": 65099.96339,
    "actor_loss": -61.12221145629883,
    "critic_loss": 6.794014930725098,
    "ent_coef": 0.0719885528087616,
    "learning_rate": 0.001
  },
  {
    "episode": 4174,
    "reward": 80.917954,
    "length": 91,
    "time": 65115.343493,
    "actor_loss": -63.76422882080078,
    "critic_loss": 11.509917259216309,
    "ent_coef": 0.06832126528024673,
    "learning_rate": 0.001
  },
  {
    "episode": 4175,
    "reward": 85.732273,
    "length": 68,
    "time": 65129.384334,
    "actor_loss": -65.10975646972656,
    "critic_loss": 19.49872589111328,
    "ent_coef": 0.06877058744430542,
    "learning_rate": 0.001
  },
  {
    "episode": 4176,
    "reward": 87.96705,
    "length": 72,
    "time": 65141.673954,
    "actor_loss": -64.11660766601562,
    "critic_loss": 3.8205196857452393,
    "ent_coef": 0.07170558720827103,
    "learning_rate": 0.001
  },
  {
    "episode": 4177,
    "reward": 73.76856,
    "length": 90,
    "time": 65159.846078,
    "actor_loss": -62.89630126953125,
    "critic_loss": 11.786338806152344,
    "ent_coef": 0.06975383311510086,
    "learning_rate": 0.001
  },
  {
    "episode": 4178,
    "reward": 86.001468,
    "length": 71,
    "time": 65172.151361,
    "actor_loss": -66.72379302978516,
    "critic_loss": 10.328150749206543,
    "ent_coef": 0.06629794836044312,
    "learning_rate": 0.001
  },
  {
    "episode": 4179,
    "reward": 86.355643,
    "length": 71,
    "time": 65187.542305,
    "actor_loss": -63.4869499206543,
    "critic_loss": 3.523101806640625,
    "ent_coef": 0.06364208459854126,
    "learning_rate": 0.001
  },
  {
    "episode": 4180,
    "reward": 85.354237,
    "length": 75,
    "time": 65200.133321,
    "actor_loss": -62.494075775146484,
    "critic_loss": 13.169665336608887,
    "ent_coef": 0.06087131053209305,
    "learning_rate": 0.001
  },
  {
    "episode": 4181,
    "reward": 84.011163,
    "length": 78,
    "time": 65214.525979,
    "actor_loss": -70.5966567993164,
    "critic_loss": 29.95987319946289,
    "ent_coef": 0.05836787819862366,
    "learning_rate": 0.001
  },
  {
    "episode": 4182,
    "reward": 87.577325,
    "length": 67,
    "time": 65227.651494,
    "actor_loss": -59.45845031738281,
    "critic_loss": 3.36613130569458,
    "ent_coef": 0.06040225550532341,
    "learning_rate": 0.001
  },
  {
    "episode": 4183,
    "reward": 84.360438,
    "length": 73,
    "time": 65241.053252,
    "actor_loss": -65.6092758178711,
    "critic_loss": 16.12245750427246,
    "ent_coef": 0.0603809617459774,
    "learning_rate": 0.001
  },
  {
    "episode": 4184,
    "reward": 87.197757,
    "length": 69,
    "time": 65256.38327,
    "actor_loss": -61.923301696777344,
    "critic_loss": 6.079643249511719,
    "ent_coef": 0.060985077172517776,
    "learning_rate": 0.001
  },
  {
    "episode": 4185,
    "reward": 88.483783,
    "length": 68,
    "time": 65269.037886,
    "actor_loss": -60.04726791381836,
    "critic_loss": 12.919105529785156,
    "ent_coef": 0.06324522942304611,
    "learning_rate": 0.001
  },
  {
    "episode": 4186,
    "reward": 85.192008,
    "length": 74,
    "time": 65281.825071,
    "actor_loss": -56.75286865234375,
    "critic_loss": 13.00656795501709,
    "ent_coef": 0.06345685571432114,
    "learning_rate": 0.001
  },
  {
    "episode": 4187,
    "reward": 85.898501,
    "length": 74,
    "time": 65295.961916,
    "actor_loss": -64.09944152832031,
    "critic_loss": 50.040245056152344,
    "ent_coef": 0.06123439595103264,
    "learning_rate": 0.001
  },
  {
    "episode": 4188,
    "reward": 88.542772,
    "length": 65,
    "time": 65307.604322,
    "actor_loss": -59.66929626464844,
    "critic_loss": 52.33586120605469,
    "ent_coef": 0.06335670500993729,
    "learning_rate": 0.001
  },
  {
    "episode": 4189,
    "reward": 88.226519,
    "length": 67,
    "time": 65320.326248,
    "actor_loss": -60.520042419433594,
    "critic_loss": 45.78765106201172,
    "ent_coef": 0.06524061411619186,
    "learning_rate": 0.001
  },
  {
    "episode": 4190,
    "reward": 89.138453,
    "length": 64,
    "time": 65332.27445,
    "actor_loss": -60.300418853759766,
    "critic_loss": 13.666996002197266,
    "ent_coef": 0.06873546540737152,
    "learning_rate": 0.001
  },
  {
    "episode": 4191,
    "reward": 87.58875,
    "length": 69,
    "time": 65344.264821,
    "actor_loss": -59.397308349609375,
    "critic_loss": 9.082122802734375,
    "ent_coef": 0.06784356385469437,
    "learning_rate": 0.001
  },
  {
    "episode": 4192,
    "reward": 89.523677,
    "length": 64,
    "time": 65357.751328,
    "actor_loss": -77.06706237792969,
    "critic_loss": 8.810190200805664,
    "ent_coef": 0.06920232623815536,
    "learning_rate": 0.001
  },
  {
    "episode": 4193,
    "reward": 88.014149,
    "length": 72,
    "time": 65371.279312,
    "actor_loss": -62.53578186035156,
    "critic_loss": 1.70540452003479,
    "ent_coef": 0.06893888860940933,
    "learning_rate": 0.001
  },
  {
    "episode": 4194,
    "reward": 86.768446,
    "length": 74,
    "time": 65385.350997,
    "actor_loss": -56.54826354980469,
    "critic_loss": 11.34195327758789,
    "ent_coef": 0.07244746387004852,
    "learning_rate": 0.001
  },
  {
    "episode": 4195,
    "reward": -152.69327,
    "length": 128,
    "time": 65407.691414,
    "actor_loss": -64.47492980957031,
    "critic_loss": 30.150558471679688,
    "ent_coef": 0.08637264370918274,
    "learning_rate": 0.001
  },
  {
    "episode": 4196,
    "reward": 84.696842,
    "length": 87,
    "time": 65423.657997,
    "actor_loss": -59.83839797973633,
    "critic_loss": 4.4900665283203125,
    "ent_coef": 0.0953078642487526,
    "learning_rate": 0.001
  },
  {
    "episode": 4197,
    "reward": 89.184051,
    "length": 65,
    "time": 65435.317752,
    "actor_loss": -59.448516845703125,
    "critic_loss": 7.131972312927246,
    "ent_coef": 0.09950213134288788,
    "learning_rate": 0.001
  },
  {
    "episode": 4198,
    "reward": 80.704688,
    "length": 79,
    "time": 65451.882253,
    "actor_loss": -58.427616119384766,
    "critic_loss": 30.0562686920166,
    "ent_coef": 0.10758833587169647,
    "learning_rate": 0.001
  },
  {
    "episode": 4199,
    "reward": 84.39939,
    "length": 74,
    "time": 65464.4783,
    "actor_loss": -58.501258850097656,
    "critic_loss": 2.7487406730651855,
    "ent_coef": 0.11134365200996399,
    "learning_rate": 0.001
  },
  {
    "episode": 4200,
    "reward": 84.484066,
    "length": 73,
    "time": 65477.908942,
    "actor_loss": -60.64931869506836,
    "critic_loss": 7.119235992431641,
    "ent_coef": 0.1147368922829628,
    "learning_rate": 0.001
  },
  {
    "episode": 4201,
    "reward": 84.720119,
    "length": 73,
    "time": 65490.216147,
    "actor_loss": -60.043880462646484,
    "critic_loss": 15.356429100036621,
    "ent_coef": 0.11790286749601364,
    "learning_rate": 0.001
  },
  {
    "episode": 4202,
    "reward": 84.563455,
    "length": 72,
    "time": 65503.958876,
    "actor_loss": -63.12157440185547,
    "critic_loss": 6.087837219238281,
    "ent_coef": 0.12206295132637024,
    "learning_rate": 0.001
  },
  {
    "episode": 4203,
    "reward": -159.024466,
    "length": 136,
    "time": 65526.887265,
    "actor_loss": -64.22854614257812,
    "critic_loss": 4.359072685241699,
    "ent_coef": 0.12232039868831635,
    "learning_rate": 0.001
  },
  {
    "episode": 4204,
    "reward": -164.768384,
    "length": 146,
    "time": 65549.504758,
    "actor_loss": -71.86479187011719,
    "critic_loss": 110.45379638671875,
    "ent_coef": 0.11255529522895813,
    "learning_rate": 0.001
  },
  {
    "episode": 4205,
    "reward": 82.886047,
    "length": 79,
    "time": 65562.793047,
    "actor_loss": -64.542236328125,
    "critic_loss": 24.1567325592041,
    "ent_coef": 0.10743158310651779,
    "learning_rate": 0.001
  },
  {
    "episode": 4206,
    "reward": 82.589915,
    "length": 75,
    "time": 65576.30851,
    "actor_loss": -64.45863342285156,
    "critic_loss": 2.498417377471924,
    "ent_coef": 0.10442408174276352,
    "learning_rate": 0.001
  },
  {
    "episode": 4207,
    "reward": 86.248359,
    "length": 70,
    "time": 65592.413235,
    "actor_loss": -59.063697814941406,
    "critic_loss": 9.82335090637207,
    "ent_coef": 0.09862576425075531,
    "learning_rate": 0.001
  },
  {
    "episode": 4208,
    "reward": -155.174594,
    "length": 133,
    "time": 65613.063868,
    "actor_loss": -59.62519836425781,
    "critic_loss": 34.93352508544922,
    "ent_coef": 0.09955782443284988,
    "learning_rate": 0.001
  },
  {
    "episode": 4209,
    "reward": -164.362439,
    "length": 154,
    "time": 65636.768296,
    "actor_loss": -71.55216217041016,
    "critic_loss": 70.5649185180664,
    "ent_coef": 0.09626423567533493,
    "learning_rate": 0.001
  },
  {
    "episode": 4210,
    "reward": 85.095818,
    "length": 77,
    "time": 65651.669321,
    "actor_loss": -60.198707580566406,
    "critic_loss": 34.18358612060547,
    "ent_coef": 0.09867767989635468,
    "learning_rate": 0.001
  },
  {
    "episode": 4211,
    "reward": 74.006731,
    "length": 96,
    "time": 65670.777275,
    "actor_loss": -58.124427795410156,
    "critic_loss": 3.8963072299957275,
    "ent_coef": 0.09533654898405075,
    "learning_rate": 0.001
  },
  {
    "episode": 4212,
    "reward": 76.776418,
    "length": 91,
    "time": 65686.419998,
    "actor_loss": -63.45059585571289,
    "critic_loss": 19.196741104125977,
    "ent_coef": 0.09047017991542816,
    "learning_rate": 0.001
  },
  {
    "episode": 4213,
    "reward": 82.820532,
    "length": 80,
    "time": 65701.803503,
    "actor_loss": -63.027645111083984,
    "critic_loss": 2.343815565109253,
    "ent_coef": 0.09149548411369324,
    "learning_rate": 0.001
  },
  {
    "episode": 4214,
    "reward": 85.6096,
    "length": 73,
    "time": 65715.729453,
    "actor_loss": -60.56909942626953,
    "critic_loss": 4.3649373054504395,
    "ent_coef": 0.09389808773994446,
    "learning_rate": 0.001
  },
  {
    "episode": 4215,
    "reward": 84.120421,
    "length": 79,
    "time": 65729.977632,
    "actor_loss": -62.51471710205078,
    "critic_loss": 13.018930435180664,
    "ent_coef": 0.0981391966342926,
    "learning_rate": 0.001
  },
  {
    "episode": 4216,
    "reward": 70.162559,
    "length": 94,
    "time": 65747.019437,
    "actor_loss": -60.05695724487305,
    "critic_loss": 5.167671203613281,
    "ent_coef": 0.11418735980987549,
    "learning_rate": 0.001
  },
  {
    "episode": 4217,
    "reward": 71.138501,
    "length": 103,
    "time": 65765.939042,
    "actor_loss": -63.07729721069336,
    "critic_loss": 41.42637634277344,
    "ent_coef": 0.12260975688695908,
    "learning_rate": 0.001
  },
  {
    "episode": 4218,
    "reward": 87.570217,
    "length": 70,
    "time": 65779.798186,
    "actor_loss": -64.53897857666016,
    "critic_loss": 34.02333068847656,
    "ent_coef": 0.1239028126001358,
    "learning_rate": 0.001
  },
  {
    "episode": 4219,
    "reward": 77.557526,
    "length": 85,
    "time": 65797.522883,
    "actor_loss": -59.82513427734375,
    "critic_loss": 11.99663257598877,
    "ent_coef": 0.12482405453920364,
    "learning_rate": 0.001
  },
  {
    "episode": 4220,
    "reward": 83.726554,
    "length": 81,
    "time": 65811.987159,
    "actor_loss": -60.678733825683594,
    "critic_loss": 46.27068328857422,
    "ent_coef": 0.12426838278770447,
    "learning_rate": 0.001
  },
  {
    "episode": 4221,
    "reward": 87.489023,
    "length": 69,
    "time": 65826.384523,
    "actor_loss": -59.07400894165039,
    "critic_loss": 13.278276443481445,
    "ent_coef": 0.12086373567581177,
    "learning_rate": 0.001
  },
  {
    "episode": 4222,
    "reward": 81.346206,
    "length": 81,
    "time": 65840.84134,
    "actor_loss": -54.41916275024414,
    "critic_loss": 36.07799530029297,
    "ent_coef": 0.1136220321059227,
    "learning_rate": 0.001
  },
  {
    "episode": 4223,
    "reward": 88.09965,
    "length": 66,
    "time": 65854.336196,
    "actor_loss": -61.82505798339844,
    "critic_loss": 3.6016085147857666,
    "ent_coef": 0.11314382404088974,
    "learning_rate": 0.001
  },
  {
    "episode": 4224,
    "reward": 84.634061,
    "length": 73,
    "time": 65868.793144,
    "actor_loss": -58.416969299316406,
    "critic_loss": 15.056804656982422,
    "ent_coef": 0.1107141301035881,
    "learning_rate": 0.001
  },
  {
    "episode": 4225,
    "reward": 86.116207,
    "length": 71,
    "time": 65881.215996,
    "actor_loss": -61.07429504394531,
    "critic_loss": 8.27320671081543,
    "ent_coef": 0.1059790849685669,
    "learning_rate": 0.001
  },
  {
    "episode": 4226,
    "reward": 87.413912,
    "length": 69,
    "time": 65895.615125,
    "actor_loss": -60.27252960205078,
    "critic_loss": 4.298343181610107,
    "ent_coef": 0.10443620383739471,
    "learning_rate": 0.001
  },
  {
    "episode": 4227,
    "reward": 81.431358,
    "length": 84,
    "time": 65909.428788,
    "actor_loss": -65.38139343261719,
    "critic_loss": 32.96441650390625,
    "ent_coef": 0.09908465296030045,
    "learning_rate": 0.001
  },
  {
    "episode": 4228,
    "reward": 84.862146,
    "length": 78,
    "time": 65923.518138,
    "actor_loss": -68.16143798828125,
    "critic_loss": 86.03336334228516,
    "ent_coef": 0.10470094531774521,
    "learning_rate": 0.001
  },
  {
    "episode": 4229,
    "reward": 75.384083,
    "length": 89,
    "time": 65938.815937,
    "actor_loss": -60.270172119140625,
    "critic_loss": 5.727241516113281,
    "ent_coef": 0.10330084711313248,
    "learning_rate": 0.001
  },
  {
    "episode": 4230,
    "reward": 89.212651,
    "length": 65,
    "time": 65953.274774,
    "actor_loss": -59.71276092529297,
    "critic_loss": 19.554786682128906,
    "ent_coef": 0.10465525090694427,
    "learning_rate": 0.001
  },
  {
    "episode": 4231,
    "reward": 78.88237,
    "length": 86,
    "time": 65969.478489,
    "actor_loss": -57.818031311035156,
    "critic_loss": 8.616121292114258,
    "ent_coef": 0.1051139235496521,
    "learning_rate": 0.001
  },
  {
    "episode": 4232,
    "reward": 74.629838,
    "length": 87,
    "time": 65985.881763,
    "actor_loss": -63.45750045776367,
    "critic_loss": 10.199821472167969,
    "ent_coef": 0.09565117210149765,
    "learning_rate": 0.001
  },
  {
    "episode": 4233,
    "reward": 66.888514,
    "length": 99,
    "time": 66001.605134,
    "actor_loss": -59.28858947753906,
    "critic_loss": 2.3986830711364746,
    "ent_coef": 0.09068157523870468,
    "learning_rate": 0.001
  },
  {
    "episode": 4234,
    "reward": 81.002872,
    "length": 85,
    "time": 66016.663524,
    "actor_loss": -62.624935150146484,
    "critic_loss": 6.662232398986816,
    "ent_coef": 0.09048593044281006,
    "learning_rate": 0.001
  },
  {
    "episode": 4235,
    "reward": 88.045427,
    "length": 67,
    "time": 66031.28728,
    "actor_loss": -56.16888427734375,
    "critic_loss": 15.542272567749023,
    "ent_coef": 0.0898454487323761,
    "learning_rate": 0.001
  },
  {
    "episode": 4236,
    "reward": 87.346947,
    "length": 69,
    "time": 66043.670087,
    "actor_loss": -60.44590377807617,
    "critic_loss": 18.835012435913086,
    "ent_coef": 0.08852074295282364,
    "learning_rate": 0.001
  },
  {
    "episode": 4237,
    "reward": 88.273097,
    "length": 71,
    "time": 66055.706341,
    "actor_loss": -63.073848724365234,
    "critic_loss": 1.7190523147583008,
    "ent_coef": 0.09493669867515564,
    "learning_rate": 0.001
  },
  {
    "episode": 4238,
    "reward": -698.255978,
    "length": 597,
    "time": 66135.800632,
    "actor_loss": -56.72789001464844,
    "critic_loss": 4.040460586547852,
    "ent_coef": 0.08700244873762131,
    "learning_rate": 0.001
  },
  {
    "episode": 4239,
    "reward": 71.267374,
    "length": 131,
    "time": 66156.402444,
    "actor_loss": -62.00898742675781,
    "critic_loss": 455.0682373046875,
    "ent_coef": 0.08885835111141205,
    "learning_rate": 0.001
  },
  {
    "episode": 4240,
    "reward": 72.10611,
    "length": 100,
    "time": 66174.829492,
    "actor_loss": -58.393577575683594,
    "critic_loss": 5.915531158447266,
    "ent_coef": 0.08624179661273956,
    "learning_rate": 0.001
  },
  {
    "episode": 4241,
    "reward": -578.158263,
    "length": 579,
    "time": 66254.93887,
    "actor_loss": -61.401729583740234,
    "critic_loss": 10.860822677612305,
    "ent_coef": 0.09100892394781113,
    "learning_rate": 0.001
  },
  {
    "episode": 4242,
    "reward": 95.094495,
    "length": 69,
    "time": 66267.436147,
    "actor_loss": -59.23065185546875,
    "critic_loss": 4.159050941467285,
    "ent_coef": 0.0924370214343071,
    "learning_rate": 0.001
  },
  {
    "episode": 4243,
    "reward": 88.65926,
    "length": 68,
    "time": 66279.985663,
    "actor_loss": -65.37793731689453,
    "critic_loss": 3.696424961090088,
    "ent_coef": 0.0978827103972435,
    "learning_rate": 0.001
  },
  {
    "episode": 4244,
    "reward": 84.798037,
    "length": 78,
    "time": 66293.670616,
    "actor_loss": -52.904640197753906,
    "critic_loss": 5.7822160720825195,
    "ent_coef": 0.09490054100751877,
    "learning_rate": 0.001
  },
  {
    "episode": 4245,
    "reward": 88.505075,
    "length": 65,
    "time": 66305.989238,
    "actor_loss": -65.69583129882812,
    "critic_loss": 69.92000579833984,
    "ent_coef": 0.09309730678796768,
    "learning_rate": 0.001
  },
  {
    "episode": 4246,
    "reward": 88.065949,
    "length": 66,
    "time": 66320.938909,
    "actor_loss": -64.87301635742188,
    "critic_loss": 16.986736297607422,
    "ent_coef": 0.09415124356746674,
    "learning_rate": 0.001
  },
  {
    "episode": 4247,
    "reward": 85.302309,
    "length": 76,
    "time": 66334.204714,
    "actor_loss": -59.88519287109375,
    "critic_loss": 47.78370666503906,
    "ent_coef": 0.0953143909573555,
    "learning_rate": 0.001
  },
  {
    "episode": 4248,
    "reward": 87.139944,
    "length": 70,
    "time": 66348.404845,
    "actor_loss": -54.75669860839844,
    "critic_loss": 9.172029495239258,
    "ent_coef": 0.09808442741632462,
    "learning_rate": 0.001
  },
  {
    "episode": 4249,
    "reward": 86.299725,
    "length": 76,
    "time": 66364.182509,
    "actor_loss": -56.71155548095703,
    "critic_loss": 6.426743507385254,
    "ent_coef": 0.10467459261417389,
    "learning_rate": 0.001
  },
  {
    "episode": 4250,
    "reward": 85.854581,
    "length": 74,
    "time": 66376.822631,
    "actor_loss": -61.844268798828125,
    "critic_loss": 7.7396931648254395,
    "ent_coef": 0.10740915685892105,
    "learning_rate": 0.001
  },
  {
    "episode": 4251,
    "reward": 78.598329,
    "length": 85,
    "time": 66391.847976,
    "actor_loss": -61.94247817993164,
    "critic_loss": 28.59210777282715,
    "ent_coef": 0.10782939195632935,
    "learning_rate": 0.001
  },
  {
    "episode": 4252,
    "reward": 72.64322,
    "length": 101,
    "time": 66410.78925,
    "actor_loss": -59.484405517578125,
    "critic_loss": 34.728599548339844,
    "ent_coef": 0.10858117043972015,
    "learning_rate": 0.001
  },
  {
    "episode": 4253,
    "reward": -385.519982,
    "length": 294,
    "time": 66452.970052,
    "actor_loss": -60.23689270019531,
    "critic_loss": 20.450271606445312,
    "ent_coef": 0.11616301536560059,
    "learning_rate": 0.001
  },
  {
    "episode": 4254,
    "reward": 90.379775,
    "length": 100,
    "time": 66469.254918,
    "actor_loss": -59.652565002441406,
    "critic_loss": 69.90778350830078,
    "ent_coef": 0.1176205649971962,
    "learning_rate": 0.001
  },
  {
    "episode": 4255,
    "reward": -173.475578,
    "length": 380,
    "time": 66523.243188,
    "actor_loss": -60.8394889831543,
    "critic_loss": 22.4024600982666,
    "ent_coef": 0.11411795020103455,
    "learning_rate": 0.001
  },
  {
    "episode": 4256,
    "reward": 88.13632,
    "length": 69,
    "time": 66535.012287,
    "actor_loss": -61.30046081542969,
    "critic_loss": 187.03756713867188,
    "ent_coef": 0.11441490799188614,
    "learning_rate": 0.001
  },
  {
    "episode": 4257,
    "reward": 81.703753,
    "length": 85,
    "time": 66548.900021,
    "actor_loss": -57.148963928222656,
    "critic_loss": 46.96109390258789,
    "ent_coef": 0.11013659089803696,
    "learning_rate": 0.001
  },
  {
    "episode": 4258,
    "reward": 83.405494,
    "length": 82,
    "time": 66566.188895,
    "actor_loss": -63.624996185302734,
    "critic_loss": 80.02535247802734,
    "ent_coef": 0.10708069056272507,
    "learning_rate": 0.001
  },
  {
    "episode": 4259,
    "reward": 78.888268,
    "length": 94,
    "time": 66582.378628,
    "actor_loss": -62.2030029296875,
    "critic_loss": 23.333354949951172,
    "ent_coef": 0.10550285875797272,
    "learning_rate": 0.001
  },
  {
    "episode": 4260,
    "reward": 76.43176,
    "length": 99,
    "time": 66597.901668,
    "actor_loss": -66.34396362304688,
    "critic_loss": 92.61863708496094,
    "ent_coef": 0.10335470736026764,
    "learning_rate": 0.001
  },
  {
    "episode": 4261,
    "reward": -305.226441,
    "length": 590,
    "time": 66677.935866,
    "actor_loss": -66.21864318847656,
    "critic_loss": 36.534461975097656,
    "ent_coef": 0.1404619961977005,
    "learning_rate": 0.001
  },
  {
    "episode": 4262,
    "reward": -285.102803,
    "length": 594,
    "time": 66758.049979,
    "actor_loss": -70.7633056640625,
    "critic_loss": 12.567078590393066,
    "ent_coef": 0.13203972578048706,
    "learning_rate": 0.001
  },
  {
    "episode": 4263,
    "reward": -369.862682,
    "length": 399,
    "time": 66812.607453,
    "actor_loss": -60.53742980957031,
    "critic_loss": 98.82501220703125,
    "ent_coef": 0.1704971194267273,
    "learning_rate": 0.001
  },
  {
    "episode": 4264,
    "reward": -254.877431,
    "length": 583,
    "time": 66892.646432,
    "actor_loss": -70.32667541503906,
    "critic_loss": 51.00709533691406,
    "ent_coef": 0.11805695295333862,
    "learning_rate": 0.001
  },
  {
    "episode": 4265,
    "reward": -56.329909,
    "length": 487,
    "time": 66958.341879,
    "actor_loss": -65.76498413085938,
    "critic_loss": 15.134514808654785,
    "ent_coef": 0.09020128101110458,
    "learning_rate": 0.001
  },
  {
    "episode": 4266,
    "reward": 75.194421,
    "length": 97,
    "time": 66973.584945,
    "actor_loss": -80.88365936279297,
    "critic_loss": 23034.3046875,
    "ent_coef": 0.09552862495183945,
    "learning_rate": 0.001
  },
  {
    "episode": 4267,
    "reward": 89.137938,
    "length": 63,
    "time": 66985.21832,
    "actor_loss": -72.89370727539062,
    "critic_loss": 36.15445327758789,
    "ent_coef": 0.10044649988412857,
    "learning_rate": 0.001
  },
  {
    "episode": 4268,
    "reward": 88.653197,
    "length": 67,
    "time": 66997.519825,
    "actor_loss": -74.91473388671875,
    "critic_loss": 89.66493225097656,
    "ent_coef": 0.09916983544826508,
    "learning_rate": 0.001
  },
  {
    "episode": 4269,
    "reward": 84.957642,
    "length": 83,
    "time": 67011.662173,
    "actor_loss": -69.56863403320312,
    "critic_loss": 53.616600036621094,
    "ent_coef": 0.10385574400424957,
    "learning_rate": 0.001
  },
  {
    "episode": 4270,
    "reward": 89.264559,
    "length": 65,
    "time": 67023.890494,
    "actor_loss": -80.98956298828125,
    "critic_loss": 117.65367126464844,
    "ent_coef": 0.10661415010690689,
    "learning_rate": 0.001
  },
  {
    "episode": 4271,
    "reward": 86.6608,
    "length": 78,
    "time": 67037.274217,
    "actor_loss": -61.483028411865234,
    "critic_loss": 51.14772033691406,
    "ent_coef": 0.11078190803527832,
    "learning_rate": 0.001
  },
  {
    "episode": 4272,
    "reward": 86.498319,
    "length": 70,
    "time": 67051.574136,
    "actor_loss": -62.31866455078125,
    "critic_loss": 21.406206130981445,
    "ent_coef": 0.10654846578836441,
    "learning_rate": 0.001
  },
  {
    "episode": 4273,
    "reward": 87.355853,
    "length": 68,
    "time": 67065.344638,
    "actor_loss": -71.15727233886719,
    "critic_loss": 24.27676773071289,
    "ent_coef": 0.10307242721319199,
    "learning_rate": 0.001
  },
  {
    "episode": 4274,
    "reward": 78.163768,
    "length": 78,
    "time": 67079.742434,
    "actor_loss": -66.2095947265625,
    "critic_loss": 10.178396224975586,
    "ent_coef": 0.10752842575311661,
    "learning_rate": 0.001
  },
  {
    "episode": 4275,
    "reward": 90.963288,
    "length": 62,
    "time": 67092.825419,
    "actor_loss": -66.21214294433594,
    "critic_loss": 77.40531158447266,
    "ent_coef": 0.1113319918513298,
    "learning_rate": 0.001
  },
  {
    "episode": 4276,
    "reward": 87.525121,
    "length": 69,
    "time": 67105.703448,
    "actor_loss": -93.93412017822266,
    "critic_loss": 186.01333618164062,
    "ent_coef": 0.1138276606798172,
    "learning_rate": 0.001
  },
  {
    "episode": 4277,
    "reward": 85.135262,
    "length": 72,
    "time": 67118.776093,
    "actor_loss": -68.79330444335938,
    "critic_loss": 6.415983200073242,
    "ent_coef": 0.11657557636499405,
    "learning_rate": 0.001
  },
  {
    "episode": 4278,
    "reward": 85.353662,
    "length": 74,
    "time": 67131.328625,
    "actor_loss": -69.27287292480469,
    "critic_loss": 6.683398246765137,
    "ent_coef": 0.11737807095050812,
    "learning_rate": 0.001
  },
  {
    "episode": 4279,
    "reward": 85.629458,
    "length": 71,
    "time": 67143.367838,
    "actor_loss": -61.3453369140625,
    "critic_loss": 39.17340850830078,
    "ent_coef": 0.11714040488004684,
    "learning_rate": 0.001
  },
  {
    "episode": 4280,
    "reward": 81.794742,
    "length": 81,
    "time": 67157.868123,
    "actor_loss": -65.01126098632812,
    "critic_loss": 8.611759185791016,
    "ent_coef": 0.11234678328037262,
    "learning_rate": 0.001
  },
  {
    "episode": 4281,
    "reward": 83.731592,
    "length": 78,
    "time": 67172.834074,
    "actor_loss": -88.55526733398438,
    "critic_loss": 87.0675048828125,
    "ent_coef": 0.11309031397104263,
    "learning_rate": 0.001
  },
  {
    "episode": 4282,
    "reward": 82.072597,
    "length": 78,
    "time": 67185.837865,
    "actor_loss": -72.66592407226562,
    "critic_loss": 79.68836975097656,
    "ent_coef": 0.11466084420681,
    "learning_rate": 0.001
  },
  {
    "episode": 4283,
    "reward": 79.608689,
    "length": 80,
    "time": 67201.550826,
    "actor_loss": -64.77999114990234,
    "critic_loss": 43.92285919189453,
    "ent_coef": 0.12032493203878403,
    "learning_rate": 0.001
  },
  {
    "episode": 4284,
    "reward": 86.60497,
    "length": 71,
    "time": 67215.579059,
    "actor_loss": -67.58694458007812,
    "critic_loss": 74.98406982421875,
    "ent_coef": 0.11982522904872894,
    "learning_rate": 0.001
  },
  {
    "episode": 4285,
    "reward": 80.659971,
    "length": 89,
    "time": 67231.158004,
    "actor_loss": -65.56109619140625,
    "critic_loss": 88.03704833984375,
    "ent_coef": 0.11426946520805359,
    "learning_rate": 0.001
  },
  {
    "episode": 4286,
    "reward": 86.481988,
    "length": 71,
    "time": 67243.788485,
    "actor_loss": -60.84650421142578,
    "critic_loss": 37.21843719482422,
    "ent_coef": 0.11077266931533813,
    "learning_rate": 0.001
  },
  {
    "episode": 4287,
    "reward": 84.004128,
    "length": 72,
    "time": 67256.984421,
    "actor_loss": -81.19161987304688,
    "critic_loss": 367.2005615234375,
    "ent_coef": 0.10887056589126587,
    "learning_rate": 0.001
  },
  {
    "episode": 4288,
    "reward": 86.144661,
    "length": 72,
    "time": 67270.098433,
    "actor_loss": -69.97341918945312,
    "critic_loss": 118.41110229492188,
    "ent_coef": 0.10707522928714752,
    "learning_rate": 0.001
  },
  {
    "episode": 4289,
    "reward": 87.365976,
    "length": 69,
    "time": 67282.661628,
    "actor_loss": -69.117431640625,
    "critic_loss": 21.648515701293945,
    "ent_coef": 0.10565103590488434,
    "learning_rate": 0.001
  },
  {
    "episode": 4290,
    "reward": 87.003245,
    "length": 70,
    "time": 67295.014582,
    "actor_loss": -64.98658752441406,
    "critic_loss": 40.826873779296875,
    "ent_coef": 0.11101779341697693,
    "learning_rate": 0.001
  },
  {
    "episode": 4291,
    "reward": 88.138537,
    "length": 66,
    "time": 67311.161828,
    "actor_loss": -71.43463134765625,
    "critic_loss": 140.79638671875,
    "ent_coef": 0.11150798946619034,
    "learning_rate": 0.001
  },
  {
    "episode": 4292,
    "reward": 89.428859,
    "length": 65,
    "time": 67323.36935,
    "actor_loss": -74.42638397216797,
    "critic_loss": 15.823429107666016,
    "ent_coef": 0.11526762694120407,
    "learning_rate": 0.001
  },
  {
    "episode": 4293,
    "reward": 79.646731,
    "length": 84,
    "time": 67337.266819,
    "actor_loss": -72.40222930908203,
    "critic_loss": 12.74046516418457,
    "ent_coef": 0.11136902868747711,
    "learning_rate": 0.001
  },
  {
    "episode": 4294,
    "reward": 84.950719,
    "length": 74,
    "time": 67351.325528,
    "actor_loss": -63.840030670166016,
    "critic_loss": 25.86141586303711,
    "ent_coef": 0.10567285865545273,
    "learning_rate": 0.001
  },
  {
    "episode": 4295,
    "reward": 86.760762,
    "length": 73,
    "time": 67364.482473,
    "actor_loss": -63.98012161254883,
    "critic_loss": 88.22494506835938,
    "ent_coef": 0.10693909227848053,
    "learning_rate": 0.001
  },
  {
    "episode": 4296,
    "reward": 88.988888,
    "length": 66,
    "time": 67376.835139,
    "actor_loss": -66.06299591064453,
    "critic_loss": 126.3973388671875,
    "ent_coef": 0.10736798495054245,
    "learning_rate": 0.001
  },
  {
    "episode": 4297,
    "reward": 69.781692,
    "length": 105,
    "time": 67393.406238,
    "actor_loss": -63.234336853027344,
    "critic_loss": 228.29193115234375,
    "ent_coef": 0.10268194228410721,
    "learning_rate": 0.001
  },
  {
    "episode": 4298,
    "reward": 64.722045,
    "length": 109,
    "time": 67411.491002,
    "actor_loss": -72.2236099243164,
    "critic_loss": 52.03356170654297,
    "ent_coef": 0.09821266680955887,
    "learning_rate": 0.001
  },
  {
    "episode": 4299,
    "reward": 75.271441,
    "length": 98,
    "time": 67427.309359,
    "actor_loss": -68.34911346435547,
    "critic_loss": 30.35095977783203,
    "ent_coef": 0.09283660352230072,
    "learning_rate": 0.001
  },
  {
    "episode": 4300,
    "reward": 82.121765,
    "length": 78,
    "time": 67441.445577,
    "actor_loss": -64.77749633789062,
    "critic_loss": 7.4645795822143555,
    "ent_coef": 0.09241394698619843,
    "learning_rate": 0.001
  },
  {
    "episode": 4301,
    "reward": 86.178968,
    "length": 70,
    "time": 67453.711123,
    "actor_loss": -64.4325942993164,
    "critic_loss": 20.851669311523438,
    "ent_coef": 0.09136690944433212,
    "learning_rate": 0.001
  },
  {
    "episode": 4302,
    "reward": 88.018405,
    "length": 67,
    "time": 67466.799725,
    "actor_loss": -79.03530883789062,
    "critic_loss": 118.65957641601562,
    "ent_coef": 0.09238645434379578,
    "learning_rate": 0.001
  },
  {
    "episode": 4303,
    "reward": 82.998829,
    "length": 87,
    "time": 67481.114125,
    "actor_loss": -70.78053283691406,
    "critic_loss": 151.1982879638672,
    "ent_coef": 0.09659875184297562,
    "learning_rate": 0.001
  },
  {
    "episode": 4304,
    "reward": 85.635537,
    "length": 71,
    "time": 67494.172573,
    "actor_loss": -70.03914642333984,
    "critic_loss": 14.188535690307617,
    "ent_coef": 0.09465455263853073,
    "learning_rate": 0.001
  },
  {
    "episode": 4305,
    "reward": 87.256843,
    "length": 68,
    "time": 67506.467932,
    "actor_loss": -62.73406219482422,
    "critic_loss": 12.856183052062988,
    "ent_coef": 0.09255647659301758,
    "learning_rate": 0.001
  },
  {
    "episode": 4306,
    "reward": 85.312352,
    "length": 78,
    "time": 67520.697678,
    "actor_loss": -76.04927825927734,
    "critic_loss": 41.0533447265625,
    "ent_coef": 0.09557054191827774,
    "learning_rate": 0.001
  },
  {
    "episode": 4307,
    "reward": 80.932219,
    "length": 96,
    "time": 67537.88597,
    "actor_loss": -79.34443664550781,
    "critic_loss": 37.54130935668945,
    "ent_coef": 0.10352735966444016,
    "learning_rate": 0.001
  },
  {
    "episode": 4308,
    "reward": 86.329344,
    "length": 69,
    "time": 67550.998508,
    "actor_loss": -79.01748657226562,
    "critic_loss": 210.27896118164062,
    "ent_coef": 0.10550589859485626,
    "learning_rate": 0.001
  },
  {
    "episode": 4309,
    "reward": 82.960982,
    "length": 76,
    "time": 67565.731497,
    "actor_loss": -69.46835327148438,
    "critic_loss": 9.45941162109375,
    "ent_coef": 0.10215684771537781,
    "learning_rate": 0.001
  },
  {
    "episode": 4310,
    "reward": 78.638396,
    "length": 83,
    "time": 67583.047029,
    "actor_loss": -63.2332649230957,
    "critic_loss": 45.857276916503906,
    "ent_coef": 0.09524472057819366,
    "learning_rate": 0.001
  },
  {
    "episode": 4311,
    "reward": 73.606542,
    "length": 90,
    "time": 67599.255767,
    "actor_loss": -67.8494873046875,
    "critic_loss": 20.221878051757812,
    "ent_coef": 0.09197069704532623,
    "learning_rate": 0.001
  },
  {
    "episode": 4312,
    "reward": 80.465972,
    "length": 91,
    "time": 67614.278217,
    "actor_loss": -76.1146469116211,
    "critic_loss": 19.997087478637695,
    "ent_coef": 0.09165075421333313,
    "learning_rate": 0.001
  },
  {
    "episode": 4313,
    "reward": 60.866356,
    "length": 120,
    "time": 67634.738024,
    "actor_loss": -70.05450439453125,
    "critic_loss": 26.35572052001953,
    "ent_coef": 0.10133534669876099,
    "learning_rate": 0.001
  },
  {
    "episode": 4314,
    "reward": 66.137486,
    "length": 111,
    "time": 67652.764534,
    "actor_loss": -72.3851547241211,
    "critic_loss": 27.708663940429688,
    "ent_coef": 0.11072493344545364,
    "learning_rate": 0.001
  },
  {
    "episode": 4315,
    "reward": 75.248027,
    "length": 87,
    "time": 67668.815436,
    "actor_loss": -87.4373779296875,
    "critic_loss": 1043.795166015625,
    "ent_coef": 0.11180192977190018,
    "learning_rate": 0.001
  },
  {
    "episode": 4316,
    "reward": 82.599269,
    "length": 76,
    "time": 67684.246918,
    "actor_loss": -96.71805572509766,
    "critic_loss": 200.23138427734375,
    "ent_coef": 0.10663090646266937,
    "learning_rate": 0.001
  },
  {
    "episode": 4317,
    "reward": 78.482183,
    "length": 90,
    "time": 67699.578003,
    "actor_loss": -79.9779052734375,
    "critic_loss": 23.588573455810547,
    "ent_coef": 0.1051485612988472,
    "learning_rate": 0.001
  },
  {
    "episode": 4318,
    "reward": 76.356572,
    "length": 85,
    "time": 67715.127627,
    "actor_loss": -91.07350158691406,
    "critic_loss": 297.1098937988281,
    "ent_coef": 0.10257511585950851,
    "learning_rate": 0.001
  },
  {
    "episode": 4319,
    "reward": 82.161422,
    "length": 84,
    "time": 67730.234041,
    "actor_loss": -74.24171447753906,
    "critic_loss": 118.9764175415039,
    "ent_coef": 0.10549356788396835,
    "learning_rate": 0.001
  },
  {
    "episode": 4320,
    "reward": 82.387379,
    "length": 84,
    "time": 67744.43118,
    "actor_loss": -81.04781341552734,
    "critic_loss": 15.286092758178711,
    "ent_coef": 0.10903957486152649,
    "learning_rate": 0.001
  },
  {
    "episode": 4321,
    "reward": 86.571086,
    "length": 69,
    "time": 67757.724546,
    "actor_loss": -62.291786193847656,
    "critic_loss": 56.407867431640625,
    "ent_coef": 0.10952865332365036,
    "learning_rate": 0.001
  },
  {
    "episode": 4322,
    "reward": 87.759052,
    "length": 68,
    "time": 67771.409608,
    "actor_loss": -70.47128295898438,
    "critic_loss": 68.12711334228516,
    "ent_coef": 0.11805099248886108,
    "learning_rate": 0.001
  },
  {
    "episode": 4323,
    "reward": 84.696312,
    "length": 78,
    "time": 67784.594696,
    "actor_loss": -77.90469360351562,
    "critic_loss": 28.304534912109375,
    "ent_coef": 0.11891552805900574,
    "learning_rate": 0.001
  },
  {
    "episode": 4324,
    "reward": 89.932921,
    "length": 63,
    "time": 67795.589422,
    "actor_loss": -93.86199188232422,
    "critic_loss": 39.413612365722656,
    "ent_coef": 0.11881231516599655,
    "learning_rate": 0.001
  },
  {
    "episode": 4325,
    "reward": 87.628923,
    "length": 67,
    "time": 67809.059538,
    "actor_loss": -74.85738372802734,
    "critic_loss": 9.924529075622559,
    "ent_coef": 0.11749841272830963,
    "learning_rate": 0.001
  },
  {
    "episode": 4326,
    "reward": 87.673657,
    "length": 68,
    "time": 67821.76426,
    "actor_loss": -77.75882720947266,
    "critic_loss": 32.76189422607422,
    "ent_coef": 0.12077049911022186,
    "learning_rate": 0.001
  },
  {
    "episode": 4327,
    "reward": 88.718779,
    "length": 65,
    "time": 67834.092252,
    "actor_loss": -84.62313842773438,
    "critic_loss": 211.72027587890625,
    "ent_coef": 0.12442337721586227,
    "learning_rate": 0.001
  },
  {
    "episode": 4328,
    "reward": 87.391305,
    "length": 67,
    "time": 67846.411696,
    "actor_loss": -74.14649963378906,
    "critic_loss": 8.111849784851074,
    "ent_coef": 0.1285497397184372,
    "learning_rate": 0.001
  },
  {
    "episode": 4329,
    "reward": 86.384949,
    "length": 70,
    "time": 67858.708828,
    "actor_loss": -70.75873565673828,
    "critic_loss": 13.644646644592285,
    "ent_coef": 0.1281159222126007,
    "learning_rate": 0.001
  },
  {
    "episode": 4330,
    "reward": -162.545784,
    "length": 150,
    "time": 67882.060163,
    "actor_loss": -78.32876586914062,
    "critic_loss": 36.26500701904297,
    "ent_coef": 0.13895851373672485,
    "learning_rate": 0.001
  },
  {
    "episode": 4331,
    "reward": 77.046143,
    "length": 88,
    "time": 67897.064913,
    "actor_loss": -99.12492370605469,
    "critic_loss": 144.75732421875,
    "ent_coef": 0.13234899938106537,
    "learning_rate": 0.001
  },
  {
    "episode": 4332,
    "reward": 84.736527,
    "length": 92,
    "time": 67912.308942,
    "actor_loss": -71.05699920654297,
    "critic_loss": 101.95073699951172,
    "ent_coef": 0.12433280795812607,
    "learning_rate": 0.001
  },
  {
    "episode": 4333,
    "reward": 87.207231,
    "length": 72,
    "time": 67924.788775,
    "actor_loss": -81.48068237304688,
    "critic_loss": 43.4783935546875,
    "ent_coef": 0.1307893544435501,
    "learning_rate": 0.001
  },
  {
    "episode": 4334,
    "reward": 87.742997,
    "length": 71,
    "time": 67937.719377,
    "actor_loss": -93.35830688476562,
    "critic_loss": 145.75665283203125,
    "ent_coef": 0.14135681092739105,
    "learning_rate": 0.001
  },
  {
    "episode": 4335,
    "reward": 84.394715,
    "length": 73,
    "time": 67950.80458,
    "actor_loss": -78.09567260742188,
    "critic_loss": 155.76683044433594,
    "ent_coef": 0.13420335948467255,
    "learning_rate": 0.001
  },
  {
    "episode": 4336,
    "reward": 85.831543,
    "length": 70,
    "time": 67962.84088,
    "actor_loss": -80.20136260986328,
    "critic_loss": 30.217336654663086,
    "ent_coef": 0.13135212659835815,
    "learning_rate": 0.001
  },
  {
    "episode": 4337,
    "reward": 84.986187,
    "length": 78,
    "time": 67976.738163,
    "actor_loss": -75.77752685546875,
    "critic_loss": 13.265499114990234,
    "ent_coef": 0.1279304325580597,
    "learning_rate": 0.001
  },
  {
    "episode": 4338,
    "reward": 85.899258,
    "length": 69,
    "time": 67988.543382,
    "actor_loss": -71.99801635742188,
    "critic_loss": 163.84616088867188,
    "ent_coef": 0.12727831304073334,
    "learning_rate": 0.001
  },
  {
    "episode": 4339,
    "reward": 89.184213,
    "length": 65,
    "time": 68000.036906,
    "actor_loss": -83.9394302368164,
    "critic_loss": 700.38671875,
    "ent_coef": 0.13495108485221863,
    "learning_rate": 0.001
  },
  {
    "episode": 4340,
    "reward": 83.227592,
    "length": 75,
    "time": 68013.700112,
    "actor_loss": -75.49977111816406,
    "critic_loss": 27.94654083251953,
    "ent_coef": 0.13119956851005554,
    "learning_rate": 0.001
  },
  {
    "episode": 4341,
    "reward": 83.903158,
    "length": 73,
    "time": 68027.271233,
    "actor_loss": -67.97559356689453,
    "critic_loss": 28.662700653076172,
    "ent_coef": 0.12555544078350067,
    "learning_rate": 0.001
  },
  {
    "episode": 4342,
    "reward": 84.080907,
    "length": 73,
    "time": 68040.74087,
    "actor_loss": -89.96562194824219,
    "critic_loss": 68.02725219726562,
    "ent_coef": 0.12229561805725098,
    "learning_rate": 0.001
  },
  {
    "episode": 4343,
    "reward": 86.166937,
    "length": 70,
    "time": 68053.642814,
    "actor_loss": -88.22169494628906,
    "critic_loss": 566.02294921875,
    "ent_coef": 0.11703039705753326,
    "learning_rate": 0.001
  },
  {
    "episode": 4344,
    "reward": 85.122809,
    "length": 71,
    "time": 68066.193517,
    "actor_loss": -70.2281723022461,
    "critic_loss": 112.33381652832031,
    "ent_coef": 0.1116366758942604,
    "learning_rate": 0.001
  },
  {
    "episode": 4345,
    "reward": 80.679345,
    "length": 85,
    "time": 68087.439063,
    "actor_loss": -94.55320739746094,
    "critic_loss": 46.100059509277344,
    "ent_coef": 0.11838766187429428,
    "learning_rate": 0.001
  },
  {
    "episode": 4346,
    "reward": 89.095549,
    "length": 65,
    "time": 68099.591934,
    "actor_loss": -63.98539733886719,
    "critic_loss": 10.280058860778809,
    "ent_coef": 0.1261446177959442,
    "learning_rate": 0.001
  },
  {
    "episode": 4347,
    "reward": 86.946302,
    "length": 68,
    "time": 68112.065474,
    "actor_loss": -86.7720947265625,
    "critic_loss": 81.60436248779297,
    "ent_coef": 0.1299510896205902,
    "learning_rate": 0.001
  },
  {
    "episode": 4348,
    "reward": 86.791672,
    "length": 67,
    "time": 68124.492769,
    "actor_loss": -85.607177734375,
    "critic_loss": 269.77166748046875,
    "ent_coef": 0.13195250928401947,
    "learning_rate": 0.001
  },
  {
    "episode": 4349,
    "reward": 81.272933,
    "length": 77,
    "time": 68138.58377,
    "actor_loss": -86.56660461425781,
    "critic_loss": 37.169029235839844,
    "ent_coef": 0.12906257808208466,
    "learning_rate": 0.001
  },
  {
    "episode": 4350,
    "reward": 86.429133,
    "length": 66,
    "time": 68150.071537,
    "actor_loss": -93.05748748779297,
    "critic_loss": 60.33067321777344,
    "ent_coef": 0.13688400387763977,
    "learning_rate": 0.001
  },
  {
    "episode": 4351,
    "reward": 86.700608,
    "length": 68,
    "time": 68163.79838,
    "actor_loss": -91.15475463867188,
    "critic_loss": 674.675048828125,
    "ent_coef": 0.13846275210380554,
    "learning_rate": 0.001
  },
  {
    "episode": 4352,
    "reward": 85.996983,
    "length": 69,
    "time": 68177.702802,
    "actor_loss": -75.89617919921875,
    "critic_loss": 31.808372497558594,
    "ent_coef": 0.14012645184993744,
    "learning_rate": 0.001
  },
  {
    "episode": 4353,
    "reward": 84.074952,
    "length": 76,
    "time": 68191.538736,
    "actor_loss": -84.3526840209961,
    "critic_loss": 137.55535888671875,
    "ent_coef": 0.14778606593608856,
    "learning_rate": 0.001
  },
  {
    "episode": 4354,
    "reward": 88.96909,
    "length": 64,
    "time": 68203.98278,
    "actor_loss": -79.25947570800781,
    "critic_loss": 10.236970901489258,
    "ent_coef": 0.16023534536361694,
    "learning_rate": 0.001
  },
  {
    "episode": 4355,
    "reward": 84.795703,
    "length": 71,
    "time": 68218.78379,
    "actor_loss": -79.62699890136719,
    "critic_loss": 19.504009246826172,
    "ent_coef": 0.15350544452667236,
    "learning_rate": 0.001
  },
  {
    "episode": 4356,
    "reward": 82.744398,
    "length": 77,
    "time": 68235.740262,
    "actor_loss": -82.22240447998047,
    "critic_loss": 32.64366149902344,
    "ent_coef": 0.14912496507167816,
    "learning_rate": 0.001
  },
  {
    "episode": 4357,
    "reward": 88.074747,
    "length": 66,
    "time": 68247.151659,
    "actor_loss": -98.767822265625,
    "critic_loss": 201.4580078125,
    "ent_coef": 0.16686353087425232,
    "learning_rate": 0.001
  },
  {
    "episode": 4358,
    "reward": 85.610475,
    "length": 131,
    "time": 68266.681284,
    "actor_loss": -80.2457504272461,
    "critic_loss": 57.851585388183594,
    "ent_coef": 0.18360577523708344,
    "learning_rate": 0.001
  },
  {
    "episode": 4359,
    "reward": 86.607909,
    "length": 71,
    "time": 68278.906357,
    "actor_loss": -76.82308959960938,
    "critic_loss": 104.24954223632812,
    "ent_coef": 0.1822548806667328,
    "learning_rate": 0.001
  },
  {
    "episode": 4360,
    "reward": 84.038295,
    "length": 85,
    "time": 68293.352412,
    "actor_loss": -92.71076965332031,
    "critic_loss": 190.2191619873047,
    "ent_coef": 0.1810285449028015,
    "learning_rate": 0.001
  },
  {
    "episode": 4361,
    "reward": 79.440622,
    "length": 90,
    "time": 68308.371301,
    "actor_loss": -81.9649658203125,
    "critic_loss": 17.999818801879883,
    "ent_coef": 0.17932362854480743,
    "learning_rate": 0.001
  },
  {
    "episode": 4362,
    "reward": 78.91984,
    "length": 92,
    "time": 68323.595464,
    "actor_loss": -79.37875366210938,
    "critic_loss": 375.56689453125,
    "ent_coef": 0.17872697114944458,
    "learning_rate": 0.001
  },
  {
    "episode": 4363,
    "reward": 87.456922,
    "length": 67,
    "time": 68335.464986,
    "actor_loss": -82.82401275634766,
    "critic_loss": 25.365081787109375,
    "ent_coef": 0.18261827528476715,
    "learning_rate": 0.001
  },
  {
    "episode": 4364,
    "reward": 85.238071,
    "length": 75,
    "time": 68349.398664,
    "actor_loss": -92.84422302246094,
    "critic_loss": 112.8134994506836,
    "ent_coef": 0.18414275348186493,
    "learning_rate": 0.001
  },
  {
    "episode": 4365,
    "reward": 85.380642,
    "length": 70,
    "time": 68361.7621,
    "actor_loss": -85.84150695800781,
    "critic_loss": 298.128173828125,
    "ent_coef": 0.18415817618370056,
    "learning_rate": 0.001
  },
  {
    "episode": 4366,
    "reward": 89.891899,
    "length": 62,
    "time": 68375.387536,
    "actor_loss": -92.88806915283203,
    "critic_loss": 61.32716369628906,
    "ent_coef": 0.1868385523557663,
    "learning_rate": 0.001
  },
  {
    "episode": 4367,
    "reward": 87.600989,
    "length": 67,
    "time": 68388.915796,
    "actor_loss": -85.37257385253906,
    "critic_loss": 32.13654708862305,
    "ent_coef": 0.19009384512901306,
    "learning_rate": 0.001
  },
  {
    "episode": 4368,
    "reward": 88.285549,
    "length": 65,
    "time": 68400.322984,
    "actor_loss": -78.45411682128906,
    "critic_loss": 58.75811004638672,
    "ent_coef": 0.1862851232290268,
    "learning_rate": 0.001
  },
  {
    "episode": 4369,
    "reward": 87.828566,
    "length": 67,
    "time": 68414.964061,
    "actor_loss": -88.52290344238281,
    "critic_loss": 150.63241577148438,
    "ent_coef": 0.1871490180492401,
    "learning_rate": 0.001
  },
  {
    "episode": 4370,
    "reward": 87.309587,
    "length": 66,
    "time": 68427.738658,
    "actor_loss": -80.89019012451172,
    "critic_loss": 35.511863708496094,
    "ent_coef": 0.19141018390655518,
    "learning_rate": 0.001
  },
  {
    "episode": 4371,
    "reward": 88.08388,
    "length": 65,
    "time": 68440.214936,
    "actor_loss": -110.56884765625,
    "critic_loss": 3879.96728515625,
    "ent_coef": 0.1939024031162262,
    "learning_rate": 0.001
  },
  {
    "episode": 4372,
    "reward": 87.486806,
    "length": 71,
    "time": 68454.417749,
    "actor_loss": -88.88493347167969,
    "critic_loss": 99.90403747558594,
    "ent_coef": 0.1997489035129547,
    "learning_rate": 0.001
  },
  {
    "episode": 4373,
    "reward": 89.492066,
    "length": 63,
    "time": 68465.54753,
    "actor_loss": -85.22564697265625,
    "critic_loss": 22.84933090209961,
    "ent_coef": 0.20024730265140533,
    "learning_rate": 0.001
  },
  {
    "episode": 4374,
    "reward": 84.341871,
    "length": 76,
    "time": 68478.381471,
    "actor_loss": -82.1524658203125,
    "critic_loss": 73.63566589355469,
    "ent_coef": 0.1963612288236618,
    "learning_rate": 0.001
  },
  {
    "episode": 4375,
    "reward": 88.63824,
    "length": 65,
    "time": 68491.138618,
    "actor_loss": -77.55593872070312,
    "critic_loss": 43.81000518798828,
    "ent_coef": 0.19803215563297272,
    "learning_rate": 0.001
  },
  {
    "episode": 4376,
    "reward": 87.879597,
    "length": 67,
    "time": 68503.380795,
    "actor_loss": -89.34493255615234,
    "critic_loss": 55.2260627746582,
    "ent_coef": 0.20068879425525665,
    "learning_rate": 0.001
  },
  {
    "episode": 4377,
    "reward": 85.389057,
    "length": 69,
    "time": 68516.237024,
    "actor_loss": -75.68599700927734,
    "critic_loss": 25.246902465820312,
    "ent_coef": 0.19580486416816711,
    "learning_rate": 0.001
  },
  {
    "episode": 4378,
    "reward": 80.930832,
    "length": 86,
    "time": 68530.231642,
    "actor_loss": -83.36788940429688,
    "critic_loss": 49.22789764404297,
    "ent_coef": 0.18776319921016693,
    "learning_rate": 0.001
  },
  {
    "episode": 4379,
    "reward": 84.596397,
    "length": 72,
    "time": 68544.893108,
    "actor_loss": -76.15410614013672,
    "critic_loss": 32.4266357421875,
    "ent_coef": 0.17552059888839722,
    "learning_rate": 0.001
  },
  {
    "episode": 4380,
    "reward": 85.899891,
    "length": 70,
    "time": 68558.058144,
    "actor_loss": -81.94691467285156,
    "critic_loss": 55.180503845214844,
    "ent_coef": 0.17453338205814362,
    "learning_rate": 0.001
  },
  {
    "episode": 4381,
    "reward": 85.281573,
    "length": 71,
    "time": 68577.704485,
    "actor_loss": -88.81010437011719,
    "critic_loss": 58.06989288330078,
    "ent_coef": 0.17717134952545166,
    "learning_rate": 0.001
  },
  {
    "episode": 4382,
    "reward": 86.120393,
    "length": 71,
    "time": 68590.826965,
    "actor_loss": -79.81640625,
    "critic_loss": 29.277183532714844,
    "ent_coef": 0.1948605179786682,
    "learning_rate": 0.001
  },
  {
    "episode": 4383,
    "reward": 82.431022,
    "length": 73,
    "time": 68604.912593,
    "actor_loss": -92.06463623046875,
    "critic_loss": 54.479774475097656,
    "ent_coef": 0.20177046954631805,
    "learning_rate": 0.001
  },
  {
    "episode": 4384,
    "reward": 83.03429,
    "length": 77,
    "time": 68618.67445,
    "actor_loss": -82.41572570800781,
    "critic_loss": 60.558433532714844,
    "ent_coef": 0.2062700241804123,
    "learning_rate": 0.001
  },
  {
    "episode": 4385,
    "reward": 83.402333,
    "length": 77,
    "time": 68632.299838,
    "actor_loss": -78.69259643554688,
    "critic_loss": 42.204322814941406,
    "ent_coef": 0.20977246761322021,
    "learning_rate": 0.001
  },
  {
    "episode": 4386,
    "reward": 84.803243,
    "length": 69,
    "time": 68646.420896,
    "actor_loss": -84.39041900634766,
    "critic_loss": 25.49573516845703,
    "ent_coef": 0.21417006850242615,
    "learning_rate": 0.001
  },
  {
    "episode": 4387,
    "reward": 80.13572,
    "length": 83,
    "time": 68663.108685,
    "actor_loss": -90.50677490234375,
    "critic_loss": 19.837003707885742,
    "ent_coef": 0.2129031866788864,
    "learning_rate": 0.001
  },
  {
    "episode": 4388,
    "reward": 79.994791,
    "length": 114,
    "time": 68682.264007,
    "actor_loss": -86.21321105957031,
    "critic_loss": 2772.470703125,
    "ent_coef": 0.21944351494312286,
    "learning_rate": 0.001
  },
  {
    "episode": 4389,
    "reward": 80.178471,
    "length": 80,
    "time": 68696.396803,
    "actor_loss": -85.43504333496094,
    "critic_loss": 14.758652687072754,
    "ent_coef": 0.22874073684215546,
    "learning_rate": 0.001
  },
  {
    "episode": 4390,
    "reward": 87.660551,
    "length": 67,
    "time": 68709.244984,
    "actor_loss": -95.1132583618164,
    "critic_loss": 25.909168243408203,
    "ent_coef": 0.23579922318458557,
    "learning_rate": 0.001
  },
  {
    "episode": 4391,
    "reward": 85.455628,
    "length": 74,
    "time": 68723.33279,
    "actor_loss": -83.97334289550781,
    "critic_loss": 230.59896850585938,
    "ent_coef": 0.233550563454628,
    "learning_rate": 0.001
  },
  {
    "episode": 4392,
    "reward": -161.956179,
    "length": 158,
    "time": 68748.661914,
    "actor_loss": -84.39352416992188,
    "critic_loss": 16.238765716552734,
    "ent_coef": 0.23459239304065704,
    "learning_rate": 0.001
  },
  {
    "episode": 4393,
    "reward": 79.071407,
    "length": 79,
    "time": 68762.646843,
    "actor_loss": -83.02462005615234,
    "critic_loss": 17.112815856933594,
    "ent_coef": 0.24046485126018524,
    "learning_rate": 0.001
  },
  {
    "episode": 4394,
    "reward": 83.045737,
    "length": 100,
    "time": 68778.365239,
    "actor_loss": -83.45355224609375,
    "critic_loss": 182.923095703125,
    "ent_coef": 0.2443889081478119,
    "learning_rate": 0.001
  },
  {
    "episode": 4395,
    "reward": 81.570019,
    "length": 90,
    "time": 68794.409497,
    "actor_loss": -87.68916320800781,
    "critic_loss": 57.6663932800293,
    "ent_coef": 0.255374550819397,
    "learning_rate": 0.001
  },
  {
    "episode": 4396,
    "reward": 84.632339,
    "length": 74,
    "time": 68806.858438,
    "actor_loss": -85.94866943359375,
    "critic_loss": 30.40290069580078,
    "ent_coef": 0.2678413987159729,
    "learning_rate": 0.001
  },
  {
    "episode": 4397,
    "reward": 85.266284,
    "length": 73,
    "time": 68822.05826,
    "actor_loss": -95.20487976074219,
    "critic_loss": 139.37258911132812,
    "ent_coef": 0.27581727504730225,
    "learning_rate": 0.001
  },
  {
    "episode": 4398,
    "reward": 81.991463,
    "length": 87,
    "time": 68837.797601,
    "actor_loss": -94.54708862304688,
    "critic_loss": 102.85063171386719,
    "ent_coef": 0.2617358863353729,
    "learning_rate": 0.001
  },
  {
    "episode": 4399,
    "reward": 81.026482,
    "length": 90,
    "time": 68854.501398,
    "actor_loss": -86.22913360595703,
    "critic_loss": 121.19400024414062,
    "ent_coef": 0.25481855869293213,
    "learning_rate": 0.001
  },
  {
    "episode": 4400,
    "reward": 82.892802,
    "length": 88,
    "time": 68870.595991,
    "actor_loss": -95.86006927490234,
    "critic_loss": 47.048004150390625,
    "ent_coef": 0.25668320059776306,
    "learning_rate": 0.001
  },
  {
    "episode": 4401,
    "reward": 84.19541,
    "length": 74,
    "time": 68887.113073,
    "actor_loss": -107.35844421386719,
    "critic_loss": 198.75015258789062,
    "ent_coef": 0.26004916429519653,
    "learning_rate": 0.001
  },
  {
    "episode": 4402,
    "reward": 83.632421,
    "length": 84,
    "time": 68902.746903,
    "actor_loss": -81.99919128417969,
    "critic_loss": 40.597572326660156,
    "ent_coef": 0.26968899369239807,
    "learning_rate": 0.001
  },
  {
    "episode": 4403,
    "reward": 83.923255,
    "length": 75,
    "time": 68917.166673,
    "actor_loss": -85.05482482910156,
    "critic_loss": 84.39197540283203,
    "ent_coef": 0.2748333513736725,
    "learning_rate": 0.001
  },
  {
    "episode": 4404,
    "reward": 84.618074,
    "length": 76,
    "time": 68930.922201,
    "actor_loss": -92.02088928222656,
    "critic_loss": 69.23750305175781,
    "ent_coef": 0.26337718963623047,
    "learning_rate": 0.001
  },
  {
    "episode": 4405,
    "reward": 88.070771,
    "length": 68,
    "time": 68943.736703,
    "actor_loss": -88.37234497070312,
    "critic_loss": 58.70829391479492,
    "ent_coef": 0.2636427879333496,
    "learning_rate": 0.001
  },
  {
    "episode": 4406,
    "reward": 88.598983,
    "length": 66,
    "time": 68956.185151,
    "actor_loss": -91.6868896484375,
    "critic_loss": 42.51835250854492,
    "ent_coef": 0.2646673619747162,
    "learning_rate": 0.001
  },
  {
    "episode": 4407,
    "reward": 85.084764,
    "length": 80,
    "time": 68971.803003,
    "actor_loss": -73.5380859375,
    "critic_loss": 95.45552062988281,
    "ent_coef": 0.26421135663986206,
    "learning_rate": 0.001
  },
  {
    "episode": 4408,
    "reward": 85.238017,
    "length": 74,
    "time": 68984.467818,
    "actor_loss": -101.42269897460938,
    "critic_loss": 44.472381591796875,
    "ent_coef": 0.2639050781726837,
    "learning_rate": 0.001
  },
  {
    "episode": 4409,
    "reward": 88.245173,
    "length": 68,
    "time": 68997.072933,
    "actor_loss": -86.2611312866211,
    "critic_loss": 147.7835693359375,
    "ent_coef": 0.27508312463760376,
    "learning_rate": 0.001
  },
  {
    "episode": 4410,
    "reward": -155.917969,
    "length": 142,
    "time": 69020.856725,
    "actor_loss": -83.34898376464844,
    "critic_loss": 24.043821334838867,
    "ent_coef": 0.28274792432785034,
    "learning_rate": 0.001
  },
  {
    "episode": 4411,
    "reward": 81.654507,
    "length": 87,
    "time": 69036.179291,
    "actor_loss": -102.66776275634766,
    "critic_loss": 18.826311111450195,
    "ent_coef": 0.26289305090904236,
    "learning_rate": 0.001
  },
  {
    "episode": 4412,
    "reward": 81.290316,
    "length": 80,
    "time": 69052.615692,
    "actor_loss": -86.78425598144531,
    "critic_loss": 123.8426742553711,
    "ent_coef": 0.23896819353103638,
    "learning_rate": 0.001
  },
  {
    "episode": 4413,
    "reward": 80.567689,
    "length": 90,
    "time": 69069.173945,
    "actor_loss": -91.40907287597656,
    "critic_loss": 679.609375,
    "ent_coef": 0.24074846506118774,
    "learning_rate": 0.001
  },
  {
    "episode": 4414,
    "reward": 80.866107,
    "length": 76,
    "time": 69084.475472,
    "actor_loss": -91.47300720214844,
    "critic_loss": 33.36302947998047,
    "ent_coef": 0.2586895525455475,
    "learning_rate": 0.001
  },
  {
    "episode": 4415,
    "reward": 80.362801,
    "length": 83,
    "time": 69101.19651,
    "actor_loss": -92.63475036621094,
    "critic_loss": 53.206382751464844,
    "ent_coef": 0.25049465894699097,
    "learning_rate": 0.001
  },
  {
    "episode": 4416,
    "reward": 86.138506,
    "length": 70,
    "time": 69113.074006,
    "actor_loss": -91.12330627441406,
    "critic_loss": 39.061641693115234,
    "ent_coef": 0.24412041902542114,
    "learning_rate": 0.001
  },
  {
    "episode": 4417,
    "reward": 82.36865,
    "length": 77,
    "time": 69126.288247,
    "actor_loss": -92.23255920410156,
    "critic_loss": 46.09628677368164,
    "ent_coef": 0.23568406701087952,
    "learning_rate": 0.001
  },
  {
    "episode": 4418,
    "reward": 86.174766,
    "length": 68,
    "time": 69138.434292,
    "actor_loss": -69.36306762695312,
    "critic_loss": 149.16790771484375,
    "ent_coef": 0.2296309620141983,
    "learning_rate": 0.001
  },
  {
    "episode": 4419,
    "reward": 84.098156,
    "length": 74,
    "time": 69153.998374,
    "actor_loss": -91.60498046875,
    "critic_loss": 68.66954040527344,
    "ent_coef": 0.23417937755584717,
    "learning_rate": 0.001
  },
  {
    "episode": 4420,
    "reward": 88.524869,
    "length": 68,
    "time": 69166.410597,
    "actor_loss": -90.04595947265625,
    "critic_loss": 759.1421508789062,
    "ent_coef": 0.23636093735694885,
    "learning_rate": 0.001
  },
  {
    "episode": 4421,
    "reward": 78.964639,
    "length": 103,
    "time": 69184.810808,
    "actor_loss": -93.25630187988281,
    "critic_loss": 47.104549407958984,
    "ent_coef": 0.24091081321239471,
    "learning_rate": 0.001
  },
  {
    "episode": 4422,
    "reward": 87.513968,
    "length": 69,
    "time": 69196.692912,
    "actor_loss": -86.42500305175781,
    "critic_loss": 56.484046936035156,
    "ent_coef": 0.2441815733909607,
    "learning_rate": 0.001
  },
  {
    "episode": 4423,
    "reward": 76.648285,
    "length": 102,
    "time": 69213.885866,
    "actor_loss": -85.67669677734375,
    "critic_loss": 28.323991775512695,
    "ent_coef": 0.24982838332653046,
    "learning_rate": 0.001
  },
  {
    "episode": 4424,
    "reward": 79.664393,
    "length": 96,
    "time": 69229.22442,
    "actor_loss": -91.58033752441406,
    "critic_loss": 21.45901107788086,
    "ent_coef": 0.25963538885116577,
    "learning_rate": 0.001
  },
  {
    "episode": 4425,
    "reward": 77.985556,
    "length": 131,
    "time": 69249.615509,
    "actor_loss": -100.12240600585938,
    "critic_loss": 344.5934143066406,
    "ent_coef": 0.2557562291622162,
    "learning_rate": 0.001
  },
  {
    "episode": 4426,
    "reward": 85.013029,
    "length": 72,
    "time": 69261.954099,
    "actor_loss": -87.54769897460938,
    "critic_loss": 139.99844360351562,
    "ent_coef": 0.27172040939331055,
    "learning_rate": 0.001
  },
  {
    "episode": 4427,
    "reward": 83.214719,
    "length": 75,
    "time": 69277.160275,
    "actor_loss": -94.78020477294922,
    "critic_loss": 41.893096923828125,
    "ent_coef": 0.27690890431404114,
    "learning_rate": 0.001
  },
  {
    "episode": 4428,
    "reward": 85.175982,
    "length": 73,
    "time": 69290.608499,
    "actor_loss": -102.1181640625,
    "critic_loss": 18.02480697631836,
    "ent_coef": 0.2728869318962097,
    "learning_rate": 0.001
  },
  {
    "episode": 4429,
    "reward": 81.083993,
    "length": 83,
    "time": 69304.396851,
    "actor_loss": -85.50419616699219,
    "critic_loss": 40.70030975341797,
    "ent_coef": 0.2518974840641022,
    "learning_rate": 0.001
  },
  {
    "episode": 4430,
    "reward": 88.045299,
    "length": 66,
    "time": 69317.89034,
    "actor_loss": -83.37631225585938,
    "critic_loss": 95.86831665039062,
    "ent_coef": 0.24115130305290222,
    "learning_rate": 0.001
  },
  {
    "episode": 4431,
    "reward": 83.414254,
    "length": 79,
    "time": 69331.487984,
    "actor_loss": -93.90923309326172,
    "critic_loss": 190.85104370117188,
    "ent_coef": 0.23506812751293182,
    "learning_rate": 0.001
  },
  {
    "episode": 4432,
    "reward": 85.850786,
    "length": 73,
    "time": 69346.025357,
    "actor_loss": -91.95707702636719,
    "critic_loss": 42.27656555175781,
    "ent_coef": 0.23570281267166138,
    "learning_rate": 0.001
  },
  {
    "episode": 4433,
    "reward": 83.513686,
    "length": 76,
    "time": 69359.785244,
    "actor_loss": -95.73934936523438,
    "critic_loss": 110.15660095214844,
    "ent_coef": 0.23378603160381317,
    "learning_rate": 0.001
  },
  {
    "episode": 4434,
    "reward": 85.566656,
    "length": 74,
    "time": 69372.231554,
    "actor_loss": -93.62197875976562,
    "critic_loss": 21.10260772705078,
    "ent_coef": 0.2297736406326294,
    "learning_rate": 0.001
  },
  {
    "episode": 4435,
    "reward": 85.510825,
    "length": 74,
    "time": 69386.713581,
    "actor_loss": -97.68293762207031,
    "critic_loss": 216.0084686279297,
    "ent_coef": 0.2402593493461609,
    "learning_rate": 0.001
  },
  {
    "episode": 4436,
    "reward": 85.677221,
    "length": 75,
    "time": 69399.291799,
    "actor_loss": -81.53418731689453,
    "critic_loss": 116.73125457763672,
    "ent_coef": 0.2403908222913742,
    "learning_rate": 0.001
  },
  {
    "episode": 4437,
    "reward": 85.348277,
    "length": 73,
    "time": 69413.490096,
    "actor_loss": -89.08792877197266,
    "critic_loss": 132.52764892578125,
    "ent_coef": 0.25403285026550293,
    "learning_rate": 0.001
  },
  {
    "episode": 4438,
    "reward": 81.893903,
    "length": 74,
    "time": 69425.982041,
    "actor_loss": -86.28359985351562,
    "critic_loss": 28.977603912353516,
    "ent_coef": 0.2677943706512451,
    "learning_rate": 0.001
  },
  {
    "episode": 4439,
    "reward": 83.18189,
    "length": 76,
    "time": 69442.097602,
    "actor_loss": -93.59524536132812,
    "critic_loss": 55.7640380859375,
    "ent_coef": 0.2732127606868744,
    "learning_rate": 0.001
  },
  {
    "episode": 4440,
    "reward": 83.961154,
    "length": 77,
    "time": 69455.592671,
    "actor_loss": -80.80844116210938,
    "critic_loss": 18.49147605895996,
    "ent_coef": 0.2537154257297516,
    "learning_rate": 0.001
  },
  {
    "episode": 4441,
    "reward": 82.701305,
    "length": 79,
    "time": 69469.97862,
    "actor_loss": -89.23605346679688,
    "critic_loss": 21.999874114990234,
    "ent_coef": 0.2478822022676468,
    "learning_rate": 0.001
  },
  {
    "episode": 4442,
    "reward": 85.999748,
    "length": 73,
    "time": 69485.403977,
    "actor_loss": -86.13174438476562,
    "critic_loss": 346.42144775390625,
    "ent_coef": 0.23817218840122223,
    "learning_rate": 0.001
  },
  {
    "episode": 4443,
    "reward": 87.092213,
    "length": 69,
    "time": 69498.371571,
    "actor_loss": -87.0300521850586,
    "critic_loss": 760.1566772460938,
    "ent_coef": 0.22936515510082245,
    "learning_rate": 0.001
  },
  {
    "episode": 4444,
    "reward": 82.806234,
    "length": 78,
    "time": 69511.440509,
    "actor_loss": -97.52647399902344,
    "critic_loss": 347.1559143066406,
    "ent_coef": 0.223598912358284,
    "learning_rate": 0.001
  },
  {
    "episode": 4445,
    "reward": 79.863958,
    "length": 82,
    "time": 69526.912104,
    "actor_loss": -83.33422088623047,
    "critic_loss": 34.085166931152344,
    "ent_coef": 0.2215781956911087,
    "learning_rate": 0.001
  },
  {
    "episode": 4446,
    "reward": 79.667644,
    "length": 105,
    "time": 69544.703034,
    "actor_loss": -103.2443618774414,
    "critic_loss": 18.645538330078125,
    "ent_coef": 0.22031809389591217,
    "learning_rate": 0.001
  },
  {
    "episode": 4447,
    "reward": 86.556071,
    "length": 70,
    "time": 69556.731077,
    "actor_loss": -99.27747344970703,
    "critic_loss": 70.48651123046875,
    "ent_coef": 0.21598824858665466,
    "learning_rate": 0.001
  },
  {
    "episode": 4448,
    "reward": 87.150039,
    "length": 71,
    "time": 69570.648506,
    "actor_loss": -78.92829132080078,
    "critic_loss": 73.68724060058594,
    "ent_coef": 0.2052295058965683,
    "learning_rate": 0.001
  },
  {
    "episode": 4449,
    "reward": 83.418846,
    "length": 80,
    "time": 69585.90615,
    "actor_loss": -83.93336486816406,
    "critic_loss": 50.351600646972656,
    "ent_coef": 0.19881974160671234,
    "learning_rate": 0.001
  },
  {
    "episode": 4450,
    "reward": 86.807821,
    "length": 70,
    "time": 69598.678585,
    "actor_loss": -83.5473861694336,
    "critic_loss": 21.443553924560547,
    "ent_coef": 0.19365759193897247,
    "learning_rate": 0.001
  },
  {
    "episode": 4451,
    "reward": 85.553335,
    "length": 72,
    "time": 69612.975716,
    "actor_loss": -99.61123657226562,
    "critic_loss": 491.5873107910156,
    "ent_coef": 0.1971762329339981,
    "learning_rate": 0.001
  },
  {
    "episode": 4452,
    "reward": 79.687904,
    "length": 83,
    "time": 69626.540092,
    "actor_loss": -89.4657974243164,
    "critic_loss": 16.65117645263672,
    "ent_coef": 0.20483441650867462,
    "learning_rate": 0.001
  },
  {
    "episode": 4453,
    "reward": 70.800905,
    "length": 87,
    "time": 69640.667742,
    "actor_loss": -97.07485961914062,
    "critic_loss": 713.810302734375,
    "ent_coef": 0.21423467993736267,
    "learning_rate": 0.001
  },
  {
    "episode": 4454,
    "reward": 74.780583,
    "length": 84,
    "time": 69655.800712,
    "actor_loss": -93.87419891357422,
    "critic_loss": 1035.69677734375,
    "ent_coef": 0.21916939318180084,
    "learning_rate": 0.001
  },
  {
    "episode": 4455,
    "reward": 83.559445,
    "length": 82,
    "time": 69670.235049,
    "actor_loss": -85.71636962890625,
    "critic_loss": 859.7818603515625,
    "ent_coef": 0.20685167610645294,
    "learning_rate": 0.001
  },
  {
    "episode": 4456,
    "reward": 81.591704,
    "length": 85,
    "time": 69686.492376,
    "actor_loss": -81.28266143798828,
    "critic_loss": 101.499267578125,
    "ent_coef": 0.19839362800121307,
    "learning_rate": 0.001
  },
  {
    "episode": 4457,
    "reward": 83.969226,
    "length": 77,
    "time": 69699.596373,
    "actor_loss": -92.00131225585938,
    "critic_loss": 37.6785774230957,
    "ent_coef": 0.18906337022781372,
    "learning_rate": 0.001
  },
  {
    "episode": 4458,
    "reward": 86.084041,
    "length": 73,
    "time": 69713.000451,
    "actor_loss": -95.20262145996094,
    "critic_loss": 839.1353759765625,
    "ent_coef": 0.1839950829744339,
    "learning_rate": 0.001
  },
  {
    "episode": 4459,
    "reward": 84.764418,
    "length": 73,
    "time": 69727.028747,
    "actor_loss": -89.61156463623047,
    "critic_loss": 700.8350830078125,
    "ent_coef": 0.17942561209201813,
    "learning_rate": 0.001
  },
  {
    "episode": 4460,
    "reward": 83.074359,
    "length": 79,
    "time": 69741.213043,
    "actor_loss": -95.13177490234375,
    "critic_loss": 21.933849334716797,
    "ent_coef": 0.17436566948890686,
    "learning_rate": 0.001
  },
  {
    "episode": 4461,
    "reward": 85.313534,
    "length": 73,
    "time": 69753.885714,
    "actor_loss": -88.03146362304688,
    "critic_loss": 21.03116226196289,
    "ent_coef": 0.1696213185787201,
    "learning_rate": 0.001
  },
  {
    "episode": 4462,
    "reward": 86.364964,
    "length": 70,
    "time": 69768.378879,
    "actor_loss": -85.50968933105469,
    "critic_loss": 35.73200225830078,
    "ent_coef": 0.17226120829582214,
    "learning_rate": 0.001
  },
  {
    "episode": 4463,
    "reward": 84.815148,
    "length": 76,
    "time": 69784.47323,
    "actor_loss": -83.69889831542969,
    "critic_loss": 40.70905303955078,
    "ent_coef": 0.16839206218719482,
    "learning_rate": 0.001
  },
  {
    "episode": 4464,
    "reward": 75.633344,
    "length": 115,
    "time": 69802.506615,
    "actor_loss": -94.03741455078125,
    "critic_loss": 253.20509338378906,
    "ent_coef": 0.1654379963874817,
    "learning_rate": 0.001
  },
  {
    "episode": 4465,
    "reward": 84.987588,
    "length": 74,
    "time": 69817.109422,
    "actor_loss": -84.95599365234375,
    "critic_loss": 13.170684814453125,
    "ent_coef": 0.16992972791194916,
    "learning_rate": 0.001
  },
  {
    "episode": 4466,
    "reward": 86.773421,
    "length": 72,
    "time": 69831.716506,
    "actor_loss": -77.40151977539062,
    "critic_loss": 64.30189514160156,
    "ent_coef": 0.17289073765277863,
    "learning_rate": 0.001
  },
  {
    "episode": 4467,
    "reward": 82.660636,
    "length": 78,
    "time": 69847.541449,
    "actor_loss": -97.17317199707031,
    "critic_loss": 402.460693359375,
    "ent_coef": 0.18328852951526642,
    "learning_rate": 0.001
  },
  {
    "episode": 4468,
    "reward": 84.190245,
    "length": 75,
    "time": 69862.470893,
    "actor_loss": -83.87725067138672,
    "critic_loss": 13.292651176452637,
    "ent_coef": 0.18355488777160645,
    "learning_rate": 0.001
  },
  {
    "episode": 4469,
    "reward": 83.382871,
    "length": 78,
    "time": 69875.395236,
    "actor_loss": -89.76248168945312,
    "critic_loss": 101.80917358398438,
    "ent_coef": 0.178754523396492,
    "learning_rate": 0.001
  },
  {
    "episode": 4470,
    "reward": 80.543121,
    "length": 83,
    "time": 69890.226982,
    "actor_loss": -82.47706604003906,
    "critic_loss": 15.140334129333496,
    "ent_coef": 0.17853428423404694,
    "learning_rate": 0.001
  },
  {
    "episode": 4471,
    "reward": 84.454841,
    "length": 74,
    "time": 69903.015587,
    "actor_loss": -95.13094329833984,
    "critic_loss": 50.4344482421875,
    "ent_coef": 0.18138544261455536,
    "learning_rate": 0.001
  },
  {
    "episode": 4472,
    "reward": 82.889131,
    "length": 78,
    "time": 69917.783676,
    "actor_loss": -84.46917724609375,
    "critic_loss": 20.395225524902344,
    "ent_coef": 0.18223457038402557,
    "learning_rate": 0.001
  },
  {
    "episode": 4473,
    "reward": 84.481854,
    "length": 73,
    "time": 69930.074972,
    "actor_loss": -76.04121398925781,
    "critic_loss": 373.314453125,
    "ent_coef": 0.18503542244434357,
    "learning_rate": 0.001
  },
  {
    "episode": 4474,
    "reward": 87.84734,
    "length": 68,
    "time": 69941.952429,
    "actor_loss": -97.9017333984375,
    "critic_loss": 21.290081024169922,
    "ent_coef": 0.1830558180809021,
    "learning_rate": 0.001
  },
  {
    "episode": 4475,
    "reward": 83.61253,
    "length": 78,
    "time": 69955.872519,
    "actor_loss": -84.37957763671875,
    "critic_loss": 164.22390747070312,
    "ent_coef": 0.18305674195289612,
    "learning_rate": 0.001
  },
  {
    "episode": 4476,
    "reward": 83.045612,
    "length": 77,
    "time": 69972.748252,
    "actor_loss": -90.01725006103516,
    "critic_loss": 184.7540283203125,
    "ent_coef": 0.18701279163360596,
    "learning_rate": 0.001
  },
  {
    "episode": 4477,
    "reward": 86.91507,
    "length": 70,
    "time": 69985.209447,
    "actor_loss": -83.44352722167969,
    "critic_loss": 56.31925964355469,
    "ent_coef": 0.19172145426273346,
    "learning_rate": 0.001
  },
  {
    "episode": 4478,
    "reward": -163.077912,
    "length": 151,
    "time": 70007.647844,
    "actor_loss": -83.89421081542969,
    "critic_loss": 48.114830017089844,
    "ent_coef": 0.18973152339458466,
    "learning_rate": 0.001
  },
  {
    "episode": 4479,
    "reward": 80.63726,
    "length": 80,
    "time": 70020.925932,
    "actor_loss": -82.22554779052734,
    "critic_loss": 20.905567169189453,
    "ent_coef": 0.19166353344917297,
    "learning_rate": 0.001
  },
  {
    "episode": 4480,
    "reward": 82.870137,
    "length": 76,
    "time": 70033.714971,
    "actor_loss": -98.52543640136719,
    "critic_loss": 196.9842987060547,
    "ent_coef": 0.19415006041526794,
    "learning_rate": 0.001
  },
  {
    "episode": 4481,
    "reward": 82.18012,
    "length": 78,
    "time": 70047.817451,
    "actor_loss": -86.43485260009766,
    "critic_loss": 49.47010040283203,
    "ent_coef": 0.19499535858631134,
    "learning_rate": 0.001
  },
  {
    "episode": 4482,
    "reward": 84.881487,
    "length": 74,
    "time": 70061.370416,
    "actor_loss": -75.03713989257812,
    "critic_loss": 28.07202911376953,
    "ent_coef": 0.19340592622756958,
    "learning_rate": 0.001
  },
  {
    "episode": 4483,
    "reward": 83.651834,
    "length": 73,
    "time": 70073.62427,
    "actor_loss": -83.65670776367188,
    "critic_loss": 21.072391510009766,
    "ent_coef": 0.19186773896217346,
    "learning_rate": 0.001
  },
  {
    "episode": 4484,
    "reward": 83.740842,
    "length": 76,
    "time": 70086.573637,
    "actor_loss": -88.96649932861328,
    "critic_loss": 125.03799438476562,
    "ent_coef": 0.18661589920520782,
    "learning_rate": 0.001
  },
  {
    "episode": 4485,
    "reward": 83.191913,
    "length": 77,
    "time": 70101.695174,
    "actor_loss": -83.87588500976562,
    "critic_loss": 15.734114646911621,
    "ent_coef": 0.1817598044872284,
    "learning_rate": 0.001
  },
  {
    "episode": 4486,
    "reward": 81.810122,
    "length": 83,
    "time": 70116.318451,
    "actor_loss": -85.59204864501953,
    "critic_loss": 115.96434020996094,
    "ent_coef": 0.17641502618789673,
    "learning_rate": 0.001
  },
  {
    "episode": 4487,
    "reward": 61.57312,
    "length": 112,
    "time": 70135.116496,
    "actor_loss": -83.34320831298828,
    "critic_loss": 19.771928787231445,
    "ent_coef": 0.1767461895942688,
    "learning_rate": 0.001
  },
  {
    "episode": 4488,
    "reward": 84.904872,
    "length": 72,
    "time": 70147.805753,
    "actor_loss": -84.21601867675781,
    "critic_loss": 40.201927185058594,
    "ent_coef": 0.17689839005470276,
    "learning_rate": 0.001
  },
  {
    "episode": 4489,
    "reward": 83.809244,
    "length": 76,
    "time": 70161.533288,
    "actor_loss": -79.00952911376953,
    "critic_loss": 78.61735534667969,
    "ent_coef": 0.1744236946105957,
    "learning_rate": 0.001
  },
  {
    "episode": 4490,
    "reward": 78.018671,
    "length": 86,
    "time": 70175.678495,
    "actor_loss": -83.86066436767578,
    "critic_loss": 117.01380920410156,
    "ent_coef": 0.17048673331737518,
    "learning_rate": 0.001
  },
  {
    "episode": 4491,
    "reward": 62.885051,
    "length": 114,
    "time": 70195.384286,
    "actor_loss": -82.934326171875,
    "critic_loss": 83.56472778320312,
    "ent_coef": 0.16447770595550537,
    "learning_rate": 0.001
  },
  {
    "episode": 4492,
    "reward": 80.93524,
    "length": 83,
    "time": 70210.337297,
    "actor_loss": -78.7426528930664,
    "critic_loss": 777.3065185546875,
    "ent_coef": 0.17147018015384674,
    "learning_rate": 0.001
  },
  {
    "episode": 4493,
    "reward": 70.564405,
    "length": 96,
    "time": 70228.079756,
    "actor_loss": -87.78762817382812,
    "critic_loss": 32.64286422729492,
    "ent_coef": 0.18714004755020142,
    "learning_rate": 0.001
  },
  {
    "episode": 4494,
    "reward": 85.548975,
    "length": 75,
    "time": 70243.052902,
    "actor_loss": -83.40113830566406,
    "critic_loss": 12.403907775878906,
    "ent_coef": 0.18149131536483765,
    "learning_rate": 0.001
  },
  {
    "episode": 4495,
    "reward": 84.050349,
    "length": 80,
    "time": 70258.801175,
    "actor_loss": -84.33273315429688,
    "critic_loss": 45.27894592285156,
    "ent_coef": 0.17622558772563934,
    "learning_rate": 0.001
  },
  {
    "episode": 4496,
    "reward": 80.538954,
    "length": 81,
    "time": 70272.793185,
    "actor_loss": -79.61347961425781,
    "critic_loss": 8.862051963806152,
    "ent_coef": 0.1778983324766159,
    "learning_rate": 0.001
  },
  {
    "episode": 4497,
    "reward": 86.919074,
    "length": 72,
    "time": 70284.914704,
    "actor_loss": -86.97634887695312,
    "critic_loss": 47.868385314941406,
    "ent_coef": 0.1832003891468048,
    "learning_rate": 0.001
  },
  {
    "episode": 4498,
    "reward": 84.363882,
    "length": 79,
    "time": 70298.202618,
    "actor_loss": -83.51934814453125,
    "critic_loss": 78.18319702148438,
    "ent_coef": 0.17892926931381226,
    "learning_rate": 0.001
  },
  {
    "episode": 4499,
    "reward": 77.120739,
    "length": 87,
    "time": 70313.72946,
    "actor_loss": -80.99845886230469,
    "critic_loss": 107.81090545654297,
    "ent_coef": 0.1743156611919403,
    "learning_rate": 0.001
  },
  {
    "episode": 4500,
    "reward": 82.756074,
    "length": 77,
    "time": 70327.442276,
    "actor_loss": -79.6785659790039,
    "critic_loss": 21.742435455322266,
    "ent_coef": 0.17195458710193634,
    "learning_rate": 0.001
  },
  {
    "episode": 4501,
    "reward": 81.730353,
    "length": 79,
    "time": 70343.018614,
    "actor_loss": -79.75531768798828,
    "critic_loss": 23.47692108154297,
    "ent_coef": 0.1772233098745346,
    "learning_rate": 0.001
  },
  {
    "episode": 4502,
    "reward": 87.478686,
    "length": 71,
    "time": 70356.033565,
    "actor_loss": -78.41630554199219,
    "critic_loss": 35.961273193359375,
    "ent_coef": 0.18185022473335266,
    "learning_rate": 0.001
  },
  {
    "episode": 4503,
    "reward": 82.648225,
    "length": 74,
    "time": 70369.697692,
    "actor_loss": -90.00133514404297,
    "critic_loss": 93.20390319824219,
    "ent_coef": 0.18428853154182434,
    "learning_rate": 0.001
  },
  {
    "episode": 4504,
    "reward": 80.254249,
    "length": 83,
    "time": 70383.294483,
    "actor_loss": -76.76994323730469,
    "critic_loss": 83.61507415771484,
    "ent_coef": 0.17947745323181152,
    "learning_rate": 0.001
  },
  {
    "episode": 4505,
    "reward": 72.443469,
    "length": 95,
    "time": 70400.127656,
    "actor_loss": -86.10860443115234,
    "critic_loss": 27.919036865234375,
    "ent_coef": 0.16496261954307556,
    "learning_rate": 0.001
  },
  {
    "episode": 4506,
    "reward": 80.08012,
    "length": 82,
    "time": 70415.275243,
    "actor_loss": -79.10305786132812,
    "critic_loss": 76.32872009277344,
    "ent_coef": 0.15827319025993347,
    "learning_rate": 0.001
  },
  {
    "episode": 4507,
    "reward": 77.416874,
    "length": 92,
    "time": 70430.815683,
    "actor_loss": -84.19229888916016,
    "critic_loss": 28.10054588317871,
    "ent_coef": 0.16485831141471863,
    "learning_rate": 0.001
  },
  {
    "episode": 4508,
    "reward": 78.451202,
    "length": 87,
    "time": 70446.101928,
    "actor_loss": -76.96250915527344,
    "critic_loss": 6.634077548980713,
    "ent_coef": 0.1673664003610611,
    "learning_rate": 0.001
  },
  {
    "episode": 4509,
    "reward": 84.627358,
    "length": 79,
    "time": 70459.483479,
    "actor_loss": -78.9478759765625,
    "critic_loss": 12.292428970336914,
    "ent_coef": 0.16688697040081024,
    "learning_rate": 0.001
  },
  {
    "episode": 4510,
    "reward": 86.939253,
    "length": 70,
    "time": 70472.593531,
    "actor_loss": -74.94991302490234,
    "critic_loss": 11.652168273925781,
    "ent_coef": 0.16600657999515533,
    "learning_rate": 0.001
  },
  {
    "episode": 4511,
    "reward": 67.526703,
    "length": 104,
    "time": 70490.317955,
    "actor_loss": -83.99630737304688,
    "critic_loss": 12.476572036743164,
    "ent_coef": 0.16374410688877106,
    "learning_rate": 0.001
  },
  {
    "episode": 4512,
    "reward": 73.29502,
    "length": 111,
    "time": 70508.806946,
    "actor_loss": -76.58828735351562,
    "critic_loss": 14.20671558380127,
    "ent_coef": 0.15574197471141815,
    "learning_rate": 0.001
  },
  {
    "episode": 4513,
    "reward": -199.499949,
    "length": 595,
    "time": 70588.938802,
    "actor_loss": -76.38053894042969,
    "critic_loss": 93.14158630371094,
    "ent_coef": 0.13394317030906677,
    "learning_rate": 0.001
  },
  {
    "episode": 4514,
    "reward": -171.715826,
    "length": 180,
    "time": 70615.239246,
    "actor_loss": -83.52519226074219,
    "critic_loss": 10.080061912536621,
    "ent_coef": 0.12414077669382095,
    "learning_rate": 0.001
  },
  {
    "episode": 4515,
    "reward": -207.852789,
    "length": 296,
    "time": 70656.776817,
    "actor_loss": -78.5707015991211,
    "critic_loss": 4.379904747009277,
    "ent_coef": 0.13470275700092316,
    "learning_rate": 0.001
  },
  {
    "episode": 4516,
    "reward": -170.735017,
    "length": 172,
    "time": 70683.214894,
    "actor_loss": -85.3682861328125,
    "critic_loss": 12.112814903259277,
    "ent_coef": 0.14376221597194672,
    "learning_rate": 0.001
  },
  {
    "episode": 4517,
    "reward": -168.364603,
    "length": 172,
    "time": 70711.598907,
    "actor_loss": -86.72637939453125,
    "critic_loss": 73.45699310302734,
    "ent_coef": 0.1435209959745407,
    "learning_rate": 0.001
  },
  {
    "episode": 4518,
    "reward": 76.847865,
    "length": 93,
    "time": 70728.110834,
    "actor_loss": -73.95878601074219,
    "critic_loss": 67.63875579833984,
    "ent_coef": 0.14765430986881256,
    "learning_rate": 0.001
  },
  {
    "episode": 4519,
    "reward": 79.467467,
    "length": 89,
    "time": 70746.162744,
    "actor_loss": -77.69231414794922,
    "critic_loss": 33.55241394042969,
    "ent_coef": 0.1544569581747055,
    "learning_rate": 0.001
  },
  {
    "episode": 4520,
    "reward": 77.188394,
    "length": 94,
    "time": 70761.897593,
    "actor_loss": -70.16676330566406,
    "critic_loss": 36.284324645996094,
    "ent_coef": 0.1500767171382904,
    "learning_rate": 0.001
  },
  {
    "episode": 4521,
    "reward": 63.399417,
    "length": 134,
    "time": 70785.155837,
    "actor_loss": -78.0842056274414,
    "critic_loss": 100.74737548828125,
    "ent_coef": 0.1474032700061798,
    "learning_rate": 0.001
  },
  {
    "episode": 4522,
    "reward": 78.230435,
    "length": 95,
    "time": 70800.240685,
    "actor_loss": -83.06786346435547,
    "critic_loss": 8.148076057434082,
    "ent_coef": 0.1459304541349411,
    "learning_rate": 0.001
  },
  {
    "episode": 4523,
    "reward": 76.416924,
    "length": 96,
    "time": 70818.975392,
    "actor_loss": -82.60285949707031,
    "critic_loss": 16.875167846679688,
    "ent_coef": 0.13691522181034088,
    "learning_rate": 0.001
  },
  {
    "episode": 4524,
    "reward": 78.374812,
    "length": 88,
    "time": 70834.529932,
    "actor_loss": -77.85589599609375,
    "critic_loss": 95.45481872558594,
    "ent_coef": 0.1366751492023468,
    "learning_rate": 0.001
  },
  {
    "episode": 4525,
    "reward": 79.342349,
    "length": 89,
    "time": 70851.293224,
    "actor_loss": -77.0406265258789,
    "critic_loss": 89.07687377929688,
    "ent_coef": 0.14956025779247284,
    "learning_rate": 0.001
  },
  {
    "episode": 4526,
    "reward": 78.822756,
    "length": 88,
    "time": 70868.941897,
    "actor_loss": -84.38417053222656,
    "critic_loss": 8.639199256896973,
    "ent_coef": 0.15772783756256104,
    "learning_rate": 0.001
  },
  {
    "episode": 4527,
    "reward": 79.671288,
    "length": 86,
    "time": 70883.725279,
    "actor_loss": -79.32669830322266,
    "critic_loss": 38.19691848754883,
    "ent_coef": 0.1599743664264679,
    "learning_rate": 0.001
  },
  {
    "episode": 4528,
    "reward": 76.986489,
    "length": 91,
    "time": 70900.406921,
    "actor_loss": -73.00971221923828,
    "critic_loss": 12.041264533996582,
    "ent_coef": 0.15590336918830872,
    "learning_rate": 0.001
  },
  {
    "episode": 4529,
    "reward": 82.037163,
    "length": 81,
    "time": 70916.131264,
    "actor_loss": -72.30857849121094,
    "critic_loss": 15.181926727294922,
    "ent_coef": 0.16095960140228271,
    "learning_rate": 0.001
  },
  {
    "episode": 4530,
    "reward": 85.155605,
    "length": 76,
    "time": 70932.14446,
    "actor_loss": -83.63214111328125,
    "critic_loss": 13.54007339477539,
    "ent_coef": 0.1696462482213974,
    "learning_rate": 0.001
  },
  {
    "episode": 4531,
    "reward": 80.379384,
    "length": 88,
    "time": 70948.382424,
    "actor_loss": -77.07486724853516,
    "critic_loss": 36.657752990722656,
    "ent_coef": 0.1657617837190628,
    "learning_rate": 0.001
  },
  {
    "episode": 4532,
    "reward": 78.690169,
    "length": 90,
    "time": 70964.914953,
    "actor_loss": -71.07296752929688,
    "critic_loss": 30.484146118164062,
    "ent_coef": 0.15964952111244202,
    "learning_rate": 0.001
  },
  {
    "episode": 4533,
    "reward": 69.190512,
    "length": 109,
    "time": 70982.174105,
    "actor_loss": -75.81231689453125,
    "critic_loss": 62.32001495361328,
    "ent_coef": 0.14652949571609497,
    "learning_rate": 0.001
  },
  {
    "episode": 4534,
    "reward": 81.62805,
    "length": 82,
    "time": 70995.805745,
    "actor_loss": -73.61509704589844,
    "critic_loss": 31.16680335998535,
    "ent_coef": 0.143781840801239,
    "learning_rate": 0.001
  },
  {
    "episode": 4535,
    "reward": 82.115669,
    "length": 81,
    "time": 71010.201187,
    "actor_loss": -74.93817138671875,
    "critic_loss": 134.08436584472656,
    "ent_coef": 0.143009752035141,
    "learning_rate": 0.001
  },
  {
    "episode": 4536,
    "reward": 73.17582,
    "length": 101,
    "time": 71029.571428,
    "actor_loss": -71.58475494384766,
    "critic_loss": 7.521756172180176,
    "ent_coef": 0.13812769949436188,
    "learning_rate": 0.001
  },
  {
    "episode": 4537,
    "reward": 73.418984,
    "length": 102,
    "time": 71045.975977,
    "actor_loss": -75.27693176269531,
    "critic_loss": 6.120351791381836,
    "ent_coef": 0.13933175802230835,
    "learning_rate": 0.001
  },
  {
    "episode": 4538,
    "reward": 64.714098,
    "length": 124,
    "time": 71066.019619,
    "actor_loss": -71.46551513671875,
    "critic_loss": 41.587188720703125,
    "ent_coef": 0.13347762823104858,
    "learning_rate": 0.001
  },
  {
    "episode": 4539,
    "reward": 61.895913,
    "length": 126,
    "time": 71089.15191,
    "actor_loss": -77.7666015625,
    "critic_loss": 19.135770797729492,
    "ent_coef": 0.12919220328330994,
    "learning_rate": 0.001
  },
  {
    "episode": 4540,
    "reward": 66.014587,
    "length": 120,
    "time": 71108.482457,
    "actor_loss": -76.86376190185547,
    "critic_loss": 12.360475540161133,
    "ent_coef": 0.1324658989906311,
    "learning_rate": 0.001
  },
  {
    "episode": 4541,
    "reward": -3.974177,
    "length": 291,
    "time": 71150.001726,
    "actor_loss": -79.15290832519531,
    "critic_loss": 5.861764430999756,
    "ent_coef": 0.13596689701080322,
    "learning_rate": 0.001
  },
  {
    "episode": 4542,
    "reward": 6.125206,
    "length": 257,
    "time": 71188.658034,
    "actor_loss": -75.57113647460938,
    "critic_loss": 13.703666687011719,
    "ent_coef": 0.14309608936309814,
    "learning_rate": 0.001
  },
  {
    "episode": 4543,
    "reward": -261.928419,
    "length": 594,
    "time": 71268.71611,
    "actor_loss": -71.4340591430664,
    "critic_loss": 17.958587646484375,
    "ent_coef": 0.1556559056043625,
    "learning_rate": 0.001
  },
  {
    "episode": 4544,
    "reward": -255.406277,
    "length": 577,
    "time": 71348.829138,
    "actor_loss": -71.85374450683594,
    "critic_loss": 28.18250274658203,
    "ent_coef": 0.1393415331840515,
    "learning_rate": 0.001
  },
  {
    "episode": 4545,
    "reward": -261.159134,
    "length": 592,
    "time": 71428.934367,
    "actor_loss": -79.70443725585938,
    "critic_loss": 59.312705993652344,
    "ent_coef": 0.14802910387516022,
    "learning_rate": 0.001
  },
  {
    "episode": 4546,
    "reward": 64.676124,
    "length": 135,
    "time": 71450.568564,
    "actor_loss": -77.06143188476562,
    "critic_loss": 30.46004867553711,
    "ent_coef": 0.1514965146780014,
    "learning_rate": 0.001
  },
  {
    "episode": 4547,
    "reward": 60.853408,
    "length": 136,
    "time": 71474.152365,
    "actor_loss": -69.99983978271484,
    "critic_loss": 7.258689880371094,
    "ent_coef": 0.15047964453697205,
    "learning_rate": 0.001
  },
  {
    "episode": 4548,
    "reward": 64.190743,
    "length": 129,
    "time": 71493.671019,
    "actor_loss": -65.41496276855469,
    "critic_loss": 43.61371994018555,
    "ent_coef": 0.15383754670619965,
    "learning_rate": 0.001
  },
  {
    "episode": 4549,
    "reward": 19.700763,
    "length": 233,
    "time": 71526.886035,
    "actor_loss": -74.39300537109375,
    "critic_loss": 1072.918212890625,
    "ent_coef": 0.14534829556941986,
    "learning_rate": 0.001
  },
  {
    "episode": 4550,
    "reward": -163.143169,
    "length": 155,
    "time": 71551.066319,
    "actor_loss": -67.57290649414062,
    "critic_loss": 62.88727569580078,
    "ent_coef": 0.1560768038034439,
    "learning_rate": 0.001
  },
  {
    "episode": 4551,
    "reward": 81.841661,
    "length": 87,
    "time": 71565.082202,
    "actor_loss": -66.06024169921875,
    "critic_loss": 23.549266815185547,
    "ent_coef": 0.15789462625980377,
    "learning_rate": 0.001
  },
  {
    "episode": 4552,
    "reward": 81.589725,
    "length": 81,
    "time": 71578.92909,
    "actor_loss": -69.38601684570312,
    "critic_loss": 45.620574951171875,
    "ent_coef": 0.1598273664712906,
    "learning_rate": 0.001
  },
  {
    "episode": 4553,
    "reward": -154.696888,
    "length": 138,
    "time": 71601.128573,
    "actor_loss": -66.12092590332031,
    "critic_loss": 73.60884094238281,
    "ent_coef": 0.15520766377449036,
    "learning_rate": 0.001
  },
  {
    "episode": 4554,
    "reward": -160.895438,
    "length": 144,
    "time": 71622.774707,
    "actor_loss": -68.61360168457031,
    "critic_loss": 12.29697036743164,
    "ent_coef": 0.1395723819732666,
    "learning_rate": 0.001
  },
  {
    "episode": 4555,
    "reward": -156.764419,
    "length": 140,
    "time": 71646.502607,
    "actor_loss": -65.9156265258789,
    "critic_loss": 9.464057922363281,
    "ent_coef": 0.13943254947662354,
    "learning_rate": 0.001
  },
  {
    "episode": 4556,
    "reward": 78.936683,
    "length": 84,
    "time": 71661.626148,
    "actor_loss": -68.57298278808594,
    "critic_loss": 7.082707405090332,
    "ent_coef": 0.14142175018787384,
    "learning_rate": 0.001
  },
  {
    "episode": 4557,
    "reward": -160.602082,
    "length": 146,
    "time": 71685.488395,
    "actor_loss": -72.41470336914062,
    "critic_loss": 38.6068115234375,
    "ent_coef": 0.1380642205476761,
    "learning_rate": 0.001
  },
  {
    "episode": 4558,
    "reward": -168.094379,
    "length": 162,
    "time": 71708.970269,
    "actor_loss": -67.1300277709961,
    "critic_loss": 77.30076599121094,
    "ent_coef": 0.12100231647491455,
    "learning_rate": 0.001
  },
  {
    "episode": 4559,
    "reward": -159.946615,
    "length": 146,
    "time": 71731.541187,
    "actor_loss": -72.23100280761719,
    "critic_loss": 1475.16650390625,
    "ent_coef": 0.12352871149778366,
    "learning_rate": 0.001
  },
  {
    "episode": 4560,
    "reward": 71.679726,
    "length": 96,
    "time": 71748.896853,
    "actor_loss": -68.11595153808594,
    "critic_loss": 45.73811340332031,
    "ent_coef": 0.12187285721302032,
    "learning_rate": 0.001
  },
  {
    "episode": 4561,
    "reward": -156.090587,
    "length": 139,
    "time": 71769.716856,
    "actor_loss": -69.45957946777344,
    "critic_loss": 7.849318027496338,
    "ent_coef": 0.1260249763727188,
    "learning_rate": 0.001
  },
  {
    "episode": 4562,
    "reward": 80.668206,
    "length": 78,
    "time": 71783.832573,
    "actor_loss": -69.60566711425781,
    "critic_loss": 25.835289001464844,
    "ent_coef": 0.12968000769615173,
    "learning_rate": 0.001
  },
  {
    "episode": 4563,
    "reward": 84.984208,
    "length": 73,
    "time": 71800.125591,
    "actor_loss": -62.6890869140625,
    "critic_loss": 39.80853271484375,
    "ent_coef": 0.12917572259902954,
    "learning_rate": 0.001
  },
  {
    "episode": 4564,
    "reward": -158.430577,
    "length": 142,
    "time": 71821.66175,
    "actor_loss": -66.07024383544922,
    "critic_loss": 10.146174430847168,
    "ent_coef": 0.13409627974033356,
    "learning_rate": 0.001
  },
  {
    "episode": 4565,
    "reward": -157.006441,
    "length": 141,
    "time": 71843.853569,
    "actor_loss": -71.58218383789062,
    "critic_loss": 55.18735885620117,
    "ent_coef": 0.13076718151569366,
    "learning_rate": 0.001
  },
  {
    "episode": 4566,
    "reward": 83.326176,
    "length": 89,
    "time": 71860.286273,
    "actor_loss": -63.0988883972168,
    "critic_loss": 42.4612922668457,
    "ent_coef": 0.12669512629508972,
    "learning_rate": 0.001
  },
  {
    "episode": 4567,
    "reward": 70.092702,
    "length": 94,
    "time": 71875.90341,
    "actor_loss": -67.21649932861328,
    "critic_loss": 37.31273651123047,
    "ent_coef": 0.12038096785545349,
    "learning_rate": 0.001
  },
  {
    "episode": 4568,
    "reward": 79.698869,
    "length": 82,
    "time": 71891.121784,
    "actor_loss": -71.10813903808594,
    "critic_loss": 5.286991596221924,
    "ent_coef": 0.1176702082157135,
    "learning_rate": 0.001
  },
  {
    "episode": 4569,
    "reward": 80.742127,
    "length": 78,
    "time": 71905.316198,
    "actor_loss": -66.44760131835938,
    "critic_loss": 113.12470245361328,
    "ent_coef": 0.12061813473701477,
    "learning_rate": 0.001
  },
  {
    "episode": 4570,
    "reward": 77.537269,
    "length": 88,
    "time": 71920.371881,
    "actor_loss": -67.14247131347656,
    "critic_loss": 49.493133544921875,
    "ent_coef": 0.11583932489156723,
    "learning_rate": 0.001
  },
  {
    "episode": 4571,
    "reward": 87.729289,
    "length": 68,
    "time": 71934.417051,
    "actor_loss": -62.1546745300293,
    "critic_loss": 4.207842826843262,
    "ent_coef": 0.11512217670679092,
    "learning_rate": 0.001
  },
  {
    "episode": 4572,
    "reward": 79.747463,
    "length": 85,
    "time": 71950.304257,
    "actor_loss": -65.18407440185547,
    "critic_loss": 6.8576741218566895,
    "ent_coef": 0.11406896263360977,
    "learning_rate": 0.001
  },
  {
    "episode": 4573,
    "reward": 83.196428,
    "length": 78,
    "time": 71965.495819,
    "actor_loss": -67.3505859375,
    "critic_loss": 4.754590034484863,
    "ent_coef": 0.115339495241642,
    "learning_rate": 0.001
  },
  {
    "episode": 4574,
    "reward": 81.209074,
    "length": 80,
    "time": 71984.244232,
    "actor_loss": -66.63299560546875,
    "critic_loss": 37.683895111083984,
    "ent_coef": 0.11853358894586563,
    "learning_rate": 0.001
  },
  {
    "episode": 4575,
    "reward": 79.491849,
    "length": 84,
    "time": 71998.771086,
    "actor_loss": -68.811767578125,
    "critic_loss": 68.92803955078125,
    "ent_coef": 0.11759394407272339,
    "learning_rate": 0.001
  },
  {
    "episode": 4576,
    "reward": 89.642328,
    "length": 64,
    "time": 72010.900729,
    "actor_loss": -59.73276901245117,
    "critic_loss": 4.633415699005127,
    "ent_coef": 0.11712833493947983,
    "learning_rate": 0.001
  },
  {
    "episode": 4577,
    "reward": 86.299238,
    "length": 72,
    "time": 72023.303097,
    "actor_loss": -68.65399169921875,
    "critic_loss": 37.68583679199219,
    "ent_coef": 0.11593422293663025,
    "learning_rate": 0.001
  },
  {
    "episode": 4578,
    "reward": 81.454943,
    "length": 79,
    "time": 72039.31707,
    "actor_loss": -70.6395034790039,
    "critic_loss": 15.47606086730957,
    "ent_coef": 0.1194046139717102,
    "learning_rate": 0.001
  },
  {
    "episode": 4579,
    "reward": 85.86961,
    "length": 72,
    "time": 72051.630092,
    "actor_loss": -66.57803344726562,
    "critic_loss": 11.771995544433594,
    "ent_coef": 0.12337353825569153,
    "learning_rate": 0.001
  },
  {
    "episode": 4580,
    "reward": 80.4406,
    "length": 83,
    "time": 72065.604864,
    "actor_loss": -63.30794143676758,
    "critic_loss": 11.705291748046875,
    "ent_coef": 0.12454565614461899,
    "learning_rate": 0.001
  },
  {
    "episode": 4581,
    "reward": 84.850813,
    "length": 72,
    "time": 72080.387457,
    "actor_loss": -62.88056945800781,
    "critic_loss": 68.75537109375,
    "ent_coef": 0.12803374230861664,
    "learning_rate": 0.001
  },
  {
    "episode": 4582,
    "reward": 77.217103,
    "length": 84,
    "time": 72094.149255,
    "actor_loss": -67.84490966796875,
    "critic_loss": 17.182353973388672,
    "ent_coef": 0.12355648726224899,
    "learning_rate": 0.001
  },
  {
    "episode": 4583,
    "reward": 74.450658,
    "length": 92,
    "time": 72111.269471,
    "actor_loss": -61.752464294433594,
    "critic_loss": 81.81532287597656,
    "ent_coef": 0.12023001164197922,
    "learning_rate": 0.001
  },
  {
    "episode": 4584,
    "reward": 83.342002,
    "length": 74,
    "time": 72125.414737,
    "actor_loss": -63.17686462402344,
    "critic_loss": 18.605566024780273,
    "ent_coef": 0.12951363623142242,
    "learning_rate": 0.001
  },
  {
    "episode": 4585,
    "reward": 75.056647,
    "length": 91,
    "time": 72142.245935,
    "actor_loss": -66.93090057373047,
    "critic_loss": 19.30426025390625,
    "ent_coef": 0.12913456559181213,
    "learning_rate": 0.001
  },
  {
    "episode": 4586,
    "reward": 83.45848,
    "length": 78,
    "time": 72155.45769,
    "actor_loss": -63.42603302001953,
    "critic_loss": 5.787683010101318,
    "ent_coef": 0.12747196853160858,
    "learning_rate": 0.001
  },
  {
    "episode": 4587,
    "reward": 84.890754,
    "length": 73,
    "time": 72169.115461,
    "actor_loss": -67.25735473632812,
    "critic_loss": 15.996600151062012,
    "ent_coef": 0.12504465878009796,
    "learning_rate": 0.001
  },
  {
    "episode": 4588,
    "reward": 81.550968,
    "length": 80,
    "time": 72184.904258,
    "actor_loss": -65.35279083251953,
    "critic_loss": 8.618103981018066,
    "ent_coef": 0.12497615814208984,
    "learning_rate": 0.001
  },
  {
    "episode": 4589,
    "reward": 82.191985,
    "length": 80,
    "time": 72202.891424,
    "actor_loss": -65.04861450195312,
    "critic_loss": 8.92439079284668,
    "ent_coef": 0.1255778819322586,
    "learning_rate": 0.001
  },
  {
    "episode": 4590,
    "reward": 80.624162,
    "length": 81,
    "time": 72217.427519,
    "actor_loss": -68.45597839355469,
    "critic_loss": 7.480461120605469,
    "ent_coef": 0.12721140682697296,
    "learning_rate": 0.001
  },
  {
    "episode": 4591,
    "reward": 81.556298,
    "length": 80,
    "time": 72230.811746,
    "actor_loss": -68.76677703857422,
    "critic_loss": 53.48562240600586,
    "ent_coef": 0.1309891939163208,
    "learning_rate": 0.001
  },
  {
    "episode": 4592,
    "reward": 74.595161,
    "length": 93,
    "time": 72249.273203,
    "actor_loss": -62.56011962890625,
    "critic_loss": 12.191259384155273,
    "ent_coef": 0.1345411241054535,
    "learning_rate": 0.001
  },
  {
    "episode": 4593,
    "reward": 75.319749,
    "length": 137,
    "time": 72273.354852,
    "actor_loss": -59.914432525634766,
    "critic_loss": 13.392180442810059,
    "ent_coef": 0.1363661140203476,
    "learning_rate": 0.001
  },
  {
    "episode": 4594,
    "reward": 82.436806,
    "length": 77,
    "time": 72286.239699,
    "actor_loss": -60.793758392333984,
    "critic_loss": 27.658065795898438,
    "ent_coef": 0.12774202227592468,
    "learning_rate": 0.001
  },
  {
    "episode": 4595,
    "reward": 84.597156,
    "length": 76,
    "time": 72301.20895,
    "actor_loss": -62.542884826660156,
    "critic_loss": 67.20199584960938,
    "ent_coef": 0.1264711618423462,
    "learning_rate": 0.001
  },
  {
    "episode": 4596,
    "reward": 80.46693,
    "length": 79,
    "time": 72315.389162,
    "actor_loss": -58.61799621582031,
    "critic_loss": 24.88288116455078,
    "ent_coef": 0.12241858243942261,
    "learning_rate": 0.001
  },
  {
    "episode": 4597,
    "reward": 85.724956,
    "length": 73,
    "time": 72327.749626,
    "actor_loss": -62.428138732910156,
    "critic_loss": 28.023292541503906,
    "ent_coef": 0.12706485390663147,
    "learning_rate": 0.001
  },
  {
    "episode": 4598,
    "reward": 88.215675,
    "length": 66,
    "time": 72341.577268,
    "actor_loss": -65.83103942871094,
    "critic_loss": 15.95862102508545,
    "ent_coef": 0.12642063200473785,
    "learning_rate": 0.001
  },
  {
    "episode": 4599,
    "reward": 79.336364,
    "length": 80,
    "time": 72356.112219,
    "actor_loss": -59.558319091796875,
    "critic_loss": 93.98463439941406,
    "ent_coef": 0.12500357627868652,
    "learning_rate": 0.001
  },
  {
    "episode": 4600,
    "reward": 75.98043,
    "length": 91,
    "time": 72370.912248,
    "actor_loss": -63.15685272216797,
    "critic_loss": 76.68281555175781,
    "ent_coef": 0.11697995662689209,
    "learning_rate": 0.001
  },
  {
    "episode": 4601,
    "reward": 81.77846,
    "length": 80,
    "time": 72386.146936,
    "actor_loss": -67.51446533203125,
    "critic_loss": 8.93903636932373,
    "ent_coef": 0.11815185099840164,
    "learning_rate": 0.001
  },
  {
    "episode": 4602,
    "reward": 80.985613,
    "length": 81,
    "time": 72401.260052,
    "actor_loss": -63.350379943847656,
    "critic_loss": 5.598757743835449,
    "ent_coef": 0.11362568289041519,
    "learning_rate": 0.001
  },
  {
    "episode": 4603,
    "reward": 84.822556,
    "length": 75,
    "time": 72416.668177,
    "actor_loss": -62.311256408691406,
    "critic_loss": 25.872737884521484,
    "ent_coef": 0.11044247448444366,
    "learning_rate": 0.001
  },
  {
    "episode": 4604,
    "reward": 84.440367,
    "length": 77,
    "time": 72431.227744,
    "actor_loss": -62.700069427490234,
    "critic_loss": 2.7992923259735107,
    "ent_coef": 0.1130518764257431,
    "learning_rate": 0.001
  },
  {
    "episode": 4605,
    "reward": 83.664774,
    "length": 73,
    "time": 72447.205232,
    "actor_loss": -64.92044830322266,
    "critic_loss": 57.89710998535156,
    "ent_coef": 0.11748432368040085,
    "learning_rate": 0.001
  },
  {
    "episode": 4606,
    "reward": 80.537813,
    "length": 87,
    "time": 72461.821497,
    "actor_loss": -60.993995666503906,
    "critic_loss": 28.72249984741211,
    "ent_coef": 0.11250107735395432,
    "learning_rate": 0.001
  },
  {
    "episode": 4607,
    "reward": 86.256935,
    "length": 74,
    "time": 72475.448433,
    "actor_loss": -67.80577087402344,
    "critic_loss": 30.437847137451172,
    "ent_coef": 0.11216570436954498,
    "learning_rate": 0.001
  },
  {
    "episode": 4608,
    "reward": 78.551093,
    "length": 84,
    "time": 72489.649114,
    "actor_loss": -61.9025764465332,
    "critic_loss": 27.22247314453125,
    "ent_coef": 0.10783980041742325,
    "learning_rate": 0.001
  },
  {
    "episode": 4609,
    "reward": 82.665368,
    "length": 77,
    "time": 72502.643597,
    "actor_loss": -63.95587921142578,
    "critic_loss": 12.054622650146484,
    "ent_coef": 0.1086614802479744,
    "learning_rate": 0.001
  },
  {
    "episode": 4610,
    "reward": 87.628064,
    "length": 70,
    "time": 72514.556093,
    "actor_loss": -60.21034240722656,
    "critic_loss": 49.310157775878906,
    "ent_coef": 0.11100132763385773,
    "learning_rate": 0.001
  },
  {
    "episode": 4611,
    "reward": 84.228565,
    "length": 77,
    "time": 72528.786018,
    "actor_loss": -59.55754852294922,
    "critic_loss": 63.196693420410156,
    "ent_coef": 0.11559119075536728,
    "learning_rate": 0.001
  },
  {
    "episode": 4612,
    "reward": 90.387916,
    "length": 64,
    "time": 72541.285541,
    "actor_loss": -59.40559387207031,
    "critic_loss": 19.443866729736328,
    "ent_coef": 0.12576134502887726,
    "learning_rate": 0.001
  },
  {
    "episode": 4613,
    "reward": 81.984367,
    "length": 78,
    "time": 72560.66269,
    "actor_loss": -65.41783905029297,
    "critic_loss": 73.96005249023438,
    "ent_coef": 0.12652556598186493,
    "learning_rate": 0.001
  },
  {
    "episode": 4614,
    "reward": 87.140441,
    "length": 70,
    "time": 72574.110432,
    "actor_loss": -56.94270324707031,
    "critic_loss": 27.510807037353516,
    "ent_coef": 0.12642908096313477,
    "learning_rate": 0.001
  },
  {
    "episode": 4615,
    "reward": 81.069922,
    "length": 78,
    "time": 72588.001224,
    "actor_loss": -53.42820739746094,
    "critic_loss": 18.36330795288086,
    "ent_coef": 0.12364813685417175,
    "learning_rate": 0.001
  },
  {
    "episode": 4616,
    "reward": 75.921342,
    "length": 92,
    "time": 72603.441468,
    "actor_loss": -57.1790771484375,
    "critic_loss": 62.042327880859375,
    "ent_coef": 0.11994568258523941,
    "learning_rate": 0.001
  },
  {
    "episode": 4617,
    "reward": 76.00581,
    "length": 94,
    "time": 72618.706561,
    "actor_loss": -59.000518798828125,
    "critic_loss": 63.365501403808594,
    "ent_coef": 0.11698190867900848,
    "learning_rate": 0.001
  },
  {
    "episode": 4618,
    "reward": 88.352807,
    "length": 66,
    "time": 72631.181627,
    "actor_loss": -59.18157196044922,
    "critic_loss": 19.21450424194336,
    "ent_coef": 0.12192540615797043,
    "learning_rate": 0.001
  },
  {
    "episode": 4619,
    "reward": 83.784769,
    "length": 78,
    "time": 72646.92107,
    "actor_loss": -60.23054504394531,
    "critic_loss": 8.724128723144531,
    "ent_coef": 0.12891028821468353,
    "learning_rate": 0.001
  },
  {
    "episode": 4620,
    "reward": 80.687489,
    "length": 83,
    "time": 72660.622559,
    "actor_loss": -60.374359130859375,
    "critic_loss": 8.543533325195312,
    "ent_coef": 0.13058704137802124,
    "learning_rate": 0.001
  },
  {
    "episode": 4621,
    "reward": 89.493454,
    "length": 64,
    "time": 72675.271845,
    "actor_loss": -61.946659088134766,
    "critic_loss": 8.630884170532227,
    "ent_coef": 0.1306481957435608,
    "learning_rate": 0.001
  },
  {
    "episode": 4622,
    "reward": 89.087046,
    "length": 64,
    "time": 72689.824901,
    "actor_loss": -58.01306915283203,
    "critic_loss": 29.449304580688477,
    "ent_coef": 0.12711197137832642,
    "learning_rate": 0.001
  },
  {
    "episode": 4623,
    "reward": 85.374395,
    "length": 72,
    "time": 72702.0372,
    "actor_loss": -64.28710174560547,
    "critic_loss": 12.642011642456055,
    "ent_coef": 0.1274222582578659,
    "learning_rate": 0.001
  },
  {
    "episode": 4624,
    "reward": 84.539302,
    "length": 79,
    "time": 72716.11555,
    "actor_loss": -64.07072448730469,
    "critic_loss": 18.09793472290039,
    "ent_coef": 0.12986506521701813,
    "learning_rate": 0.001
  },
  {
    "episode": 4625,
    "reward": 88.11275,
    "length": 67,
    "time": 72727.803145,
    "actor_loss": -60.013397216796875,
    "critic_loss": 50.55949020385742,
    "ent_coef": 0.13131366670131683,
    "learning_rate": 0.001
  },
  {
    "episode": 4626,
    "reward": 84.870409,
    "length": 73,
    "time": 72740.392825,
    "actor_loss": -58.22962188720703,
    "critic_loss": 32.28350830078125,
    "ent_coef": 0.1376017928123474,
    "learning_rate": 0.001
  },
  {
    "episode": 4627,
    "reward": 78.931665,
    "length": 81,
    "time": 72756.602398,
    "actor_loss": -56.962303161621094,
    "critic_loss": 12.469867706298828,
    "ent_coef": 0.13503238558769226,
    "learning_rate": 0.001
  },
  {
    "episode": 4628,
    "reward": 88.151276,
    "length": 67,
    "time": 72768.436337,
    "actor_loss": -59.863182067871094,
    "critic_loss": 63.58636474609375,
    "ent_coef": 0.13422508537769318,
    "learning_rate": 0.001
  },
  {
    "episode": 4629,
    "reward": 84.207957,
    "length": 76,
    "time": 72782.163121,
    "actor_loss": -60.76390838623047,
    "critic_loss": 787.3516845703125,
    "ent_coef": 0.13502836227416992,
    "learning_rate": 0.001
  },
  {
    "episode": 4630,
    "reward": 86.263074,
    "length": 71,
    "time": 72795.140617,
    "actor_loss": -61.453392028808594,
    "critic_loss": 13.204872131347656,
    "ent_coef": 0.13045674562454224,
    "learning_rate": 0.001
  },
  {
    "episode": 4631,
    "reward": 83.923332,
    "length": 78,
    "time": 72810.280663,
    "actor_loss": -65.12996673583984,
    "critic_loss": 15.70865535736084,
    "ent_coef": 0.12537842988967896,
    "learning_rate": 0.001
  },
  {
    "episode": 4632,
    "reward": 80.835397,
    "length": 82,
    "time": 72827.135165,
    "actor_loss": -62.018959045410156,
    "critic_loss": 14.8017578125,
    "ent_coef": 0.12142518907785416,
    "learning_rate": 0.001
  },
  {
    "episode": 4633,
    "reward": 87.980682,
    "length": 69,
    "time": 72838.971895,
    "actor_loss": -58.26935577392578,
    "critic_loss": 5.715857028961182,
    "ent_coef": 0.1253872513771057,
    "learning_rate": 0.001
  },
  {
    "episode": 4634,
    "reward": 85.219465,
    "length": 72,
    "time": 72856.063517,
    "actor_loss": -60.03617858886719,
    "critic_loss": 8.648723602294922,
    "ent_coef": 0.12460066378116608,
    "learning_rate": 0.001
  },
  {
    "episode": 4635,
    "reward": 79.441104,
    "length": 83,
    "time": 72870.962276,
    "actor_loss": -59.93646240234375,
    "critic_loss": 16.195911407470703,
    "ent_coef": 0.12370463460683823,
    "learning_rate": 0.001
  },
  {
    "episode": 4636,
    "reward": -157.677361,
    "length": 147,
    "time": 72893.489229,
    "actor_loss": -58.38241958618164,
    "critic_loss": 51.23570251464844,
    "ent_coef": 0.12209588289260864,
    "learning_rate": 0.001
  },
  {
    "episode": 4637,
    "reward": 87.852105,
    "length": 68,
    "time": 72906.118219,
    "actor_loss": -59.389732360839844,
    "critic_loss": 55.370513916015625,
    "ent_coef": 0.12579409778118134,
    "learning_rate": 0.001
  },
  {
    "episode": 4638,
    "reward": 83.629222,
    "length": 73,
    "time": 72919.084644,
    "actor_loss": -61.20362854003906,
    "critic_loss": 6.0732622146606445,
    "ent_coef": 0.12265805155038834,
    "learning_rate": 0.001
  },
  {
    "episode": 4639,
    "reward": 83.287626,
    "length": 74,
    "time": 72932.846141,
    "actor_loss": -60.800323486328125,
    "critic_loss": 12.369426727294922,
    "ent_coef": 0.12062449008226395,
    "learning_rate": 0.001
  },
  {
    "episode": 4640,
    "reward": 88.386751,
    "length": 68,
    "time": 72944.682429,
    "actor_loss": -61.84138488769531,
    "critic_loss": 8.605769157409668,
    "ent_coef": 0.11866315454244614,
    "learning_rate": 0.001
  },
  {
    "episode": 4641,
    "reward": 79.761884,
    "length": 82,
    "time": 72958.419061,
    "actor_loss": -60.612205505371094,
    "critic_loss": 10.061410903930664,
    "ent_coef": 0.1174561157822609,
    "learning_rate": 0.001
  },
  {
    "episode": 4642,
    "reward": 88.318064,
    "length": 68,
    "time": 72970.4637,
    "actor_loss": -63.810890197753906,
    "critic_loss": 120.43511199951172,
    "ent_coef": 0.12325052917003632,
    "learning_rate": 0.001
  },
  {
    "episode": 4643,
    "reward": 87.917361,
    "length": 69,
    "time": 72983.50141,
    "actor_loss": -56.61027526855469,
    "critic_loss": 3.982131004333496,
    "ent_coef": 0.12753340601921082,
    "learning_rate": 0.001
  },
  {
    "episode": 4644,
    "reward": 75.618934,
    "length": 92,
    "time": 73001.084208,
    "actor_loss": -57.91168975830078,
    "critic_loss": 55.701515197753906,
    "ent_coef": 0.1268119513988495,
    "learning_rate": 0.001
  },
  {
    "episode": 4645,
    "reward": 85.322999,
    "length": 71,
    "time": 73014.192835,
    "actor_loss": -66.13758850097656,
    "critic_loss": 18.643537521362305,
    "ent_coef": 0.12272153049707413,
    "learning_rate": 0.001
  },
  {
    "episode": 4646,
    "reward": 87.794201,
    "length": 69,
    "time": 73025.99057,
    "actor_loss": -59.46242141723633,
    "critic_loss": 7.953339099884033,
    "ent_coef": 0.11785413324832916,
    "learning_rate": 0.001
  },
  {
    "episode": 4647,
    "reward": 89.324734,
    "length": 64,
    "time": 73040.879932,
    "actor_loss": -56.837371826171875,
    "critic_loss": 64.13062286376953,
    "ent_coef": 0.11983276903629303,
    "learning_rate": 0.001
  },
  {
    "episode": 4648,
    "reward": 81.539557,
    "length": 77,
    "time": 73055.612955,
    "actor_loss": -59.874698638916016,
    "critic_loss": 19.459558486938477,
    "ent_coef": 0.12322299927473068,
    "learning_rate": 0.001
  },
  {
    "episode": 4649,
    "reward": 87.472069,
    "length": 69,
    "time": 73071.54526,
    "actor_loss": -53.34180450439453,
    "critic_loss": 7.312097072601318,
    "ent_coef": 0.12454015761613846,
    "learning_rate": 0.001
  },
  {
    "episode": 4650,
    "reward": 89.078037,
    "length": 64,
    "time": 73082.858485,
    "actor_loss": -58.58262634277344,
    "critic_loss": 19.157821655273438,
    "ent_coef": 0.1275392770767212,
    "learning_rate": 0.001
  },
  {
    "episode": 4651,
    "reward": 84.871939,
    "length": 75,
    "time": 73098.597702,
    "actor_loss": -58.96271514892578,
    "critic_loss": 6.830782890319824,
    "ent_coef": 0.12487109005451202,
    "learning_rate": 0.001
  },
  {
    "episode": 4652,
    "reward": 82.808325,
    "length": 75,
    "time": 73112.662377,
    "actor_loss": -58.813751220703125,
    "critic_loss": 714.5499267578125,
    "ent_coef": 0.1276581585407257,
    "learning_rate": 0.001
  },
  {
    "episode": 4653,
    "reward": 81.492964,
    "length": 80,
    "time": 73130.060424,
    "actor_loss": -56.827083587646484,
    "critic_loss": 3.5128254890441895,
    "ent_coef": 0.12259554117918015,
    "learning_rate": 0.001
  },
  {
    "episode": 4654,
    "reward": 83.725686,
    "length": 74,
    "time": 73142.814537,
    "actor_loss": -65.45704650878906,
    "critic_loss": 13.794076919555664,
    "ent_coef": 0.122471384704113,
    "learning_rate": 0.001
  },
  {
    "episode": 4655,
    "reward": 85.438083,
    "length": 74,
    "time": 73156.195145,
    "actor_loss": -66.94903564453125,
    "critic_loss": 5.52540922164917,
    "ent_coef": 0.12372412532567978,
    "learning_rate": 0.001
  },
  {
    "episode": 4656,
    "reward": 81.75712,
    "length": 79,
    "time": 73171.925377,
    "actor_loss": -59.350868225097656,
    "critic_loss": 9.234916687011719,
    "ent_coef": 0.12355386465787888,
    "learning_rate": 0.001
  },
  {
    "episode": 4657,
    "reward": 81.341188,
    "length": 84,
    "time": 73189.890285,
    "actor_loss": -61.67229461669922,
    "critic_loss": 34.30458068847656,
    "ent_coef": 0.12336263060569763,
    "learning_rate": 0.001
  },
  {
    "episode": 4658,
    "reward": 88.563102,
    "length": 66,
    "time": 73202.382377,
    "actor_loss": -60.82621765136719,
    "critic_loss": 77.07149505615234,
    "ent_coef": 0.1239064410328865,
    "learning_rate": 0.001
  },
  {
    "episode": 4659,
    "reward": 87.985066,
    "length": 67,
    "time": 73215.417184,
    "actor_loss": -56.880287170410156,
    "critic_loss": 51.183746337890625,
    "ent_coef": 0.13094370067119598,
    "learning_rate": 0.001
  },
  {
    "episode": 4660,
    "reward": 82.15253,
    "length": 78,
    "time": 73228.387774,
    "actor_loss": -53.6866569519043,
    "critic_loss": 88.17827606201172,
    "ent_coef": 0.1292855143547058,
    "learning_rate": 0.001
  },
  {
    "episode": 4661,
    "reward": 85.698456,
    "length": 70,
    "time": 73245.836116,
    "actor_loss": -56.49564743041992,
    "critic_loss": 56.70110321044922,
    "ent_coef": 0.12520696222782135,
    "learning_rate": 0.001
  },
  {
    "episode": 4662,
    "reward": 83.711027,
    "length": 76,
    "time": 73259.742314,
    "actor_loss": -59.89740753173828,
    "critic_loss": 27.872310638427734,
    "ent_coef": 0.12055043131113052,
    "learning_rate": 0.001
  },
  {
    "episode": 4663,
    "reward": 86.348862,
    "length": 68,
    "time": 73273.569663,
    "actor_loss": -56.311466217041016,
    "critic_loss": 27.966144561767578,
    "ent_coef": 0.12046965956687927,
    "learning_rate": 0.001
  },
  {
    "episode": 4664,
    "reward": 80.466264,
    "length": 82,
    "time": 73289.457872,
    "actor_loss": -60.0523681640625,
    "critic_loss": 15.041440963745117,
    "ent_coef": 0.11408387124538422,
    "learning_rate": 0.001
  },
  {
    "episode": 4665,
    "reward": 80.284206,
    "length": 81,
    "time": 73305.734043,
    "actor_loss": -54.74019241333008,
    "critic_loss": 29.729736328125,
    "ent_coef": 0.10696132481098175,
    "learning_rate": 0.001
  },
  {
    "episode": 4666,
    "reward": 77.553586,
    "length": 84,
    "time": 73319.899593,
    "actor_loss": -59.46541976928711,
    "critic_loss": 66.87920379638672,
    "ent_coef": 0.10500179976224899,
    "learning_rate": 0.001
  },
  {
    "episode": 4667,
    "reward": 88.134989,
    "length": 66,
    "time": 73338.625098,
    "actor_loss": -59.260536193847656,
    "critic_loss": 4.3644890785217285,
    "ent_coef": 0.10718804597854614,
    "learning_rate": 0.001
  },
  {
    "episode": 4668,
    "reward": 83.195706,
    "length": 74,
    "time": 73353.16541,
    "actor_loss": -56.922203063964844,
    "critic_loss": 12.803876876831055,
    "ent_coef": 0.10730116814374924,
    "learning_rate": 0.001
  },
  {
    "episode": 4669,
    "reward": 87.012134,
    "length": 68,
    "time": 73365.61552,
    "actor_loss": -57.24381637573242,
    "critic_loss": 27.958179473876953,
    "ent_coef": 0.10901080071926117,
    "learning_rate": 0.001
  },
  {
    "episode": 4670,
    "reward": 86.853894,
    "length": 72,
    "time": 73377.906603,
    "actor_loss": -63.01969909667969,
    "critic_loss": 47.29484558105469,
    "ent_coef": 0.10811113566160202,
    "learning_rate": 0.001
  },
  {
    "episode": 4671,
    "reward": 89.576229,
    "length": 63,
    "time": 73390.238397,
    "actor_loss": -53.5009765625,
    "critic_loss": 8.596439361572266,
    "ent_coef": 0.10904721915721893,
    "learning_rate": 0.001
  },
  {
    "episode": 4672,
    "reward": 87.598073,
    "length": 67,
    "time": 73404.27931,
    "actor_loss": -58.289512634277344,
    "critic_loss": 186.00921630859375,
    "ent_coef": 0.11136961728334427,
    "learning_rate": 0.001
  },
  {
    "episode": 4673,
    "reward": 85.201874,
    "length": 71,
    "time": 73419.871654,
    "actor_loss": -56.365814208984375,
    "critic_loss": 55.3857421875,
    "ent_coef": 0.11032333970069885,
    "learning_rate": 0.001
  },
  {
    "episode": 4674,
    "reward": 88.931964,
    "length": 65,
    "time": 73431.219758,
    "actor_loss": -57.53324890136719,
    "critic_loss": 9.139835357666016,
    "ent_coef": 0.1139690950512886,
    "learning_rate": 0.001
  },
  {
    "episode": 4675,
    "reward": 90.786896,
    "length": 61,
    "time": 73445.667189,
    "actor_loss": -60.17111587524414,
    "critic_loss": 45.927310943603516,
    "ent_coef": 0.11624882370233536,
    "learning_rate": 0.001
  },
  {
    "episode": 4676,
    "reward": 84.505481,
    "length": 71,
    "time": 73458.765099,
    "actor_loss": -57.91994094848633,
    "critic_loss": 7.221894264221191,
    "ent_coef": 0.11040522903203964,
    "learning_rate": 0.001
  },
  {
    "episode": 4677,
    "reward": 78.376653,
    "length": 78,
    "time": 73474.791364,
    "actor_loss": -57.524898529052734,
    "critic_loss": 6.7691779136657715,
    "ent_coef": 0.10359780490398407,
    "learning_rate": 0.001
  },
  {
    "episode": 4678,
    "reward": 89.257054,
    "length": 63,
    "time": 73486.968223,
    "actor_loss": -57.19809341430664,
    "critic_loss": 11.80589485168457,
    "ent_coef": 0.10338132083415985,
    "learning_rate": 0.001
  },
  {
    "episode": 4679,
    "reward": 88.307975,
    "length": 66,
    "time": 73501.501553,
    "actor_loss": -62.31270980834961,
    "critic_loss": 8.804316520690918,
    "ent_coef": 0.10524670034646988,
    "learning_rate": 0.001
  },
  {
    "episode": 4680,
    "reward": 88.739867,
    "length": 65,
    "time": 73514.04563,
    "actor_loss": -57.01863479614258,
    "critic_loss": 121.89956665039062,
    "ent_coef": 0.11116211116313934,
    "learning_rate": 0.001
  },
  {
    "episode": 4681,
    "reward": 86.696859,
    "length": 69,
    "time": 73529.052521,
    "actor_loss": -58.28465270996094,
    "critic_loss": 4.125977516174316,
    "ent_coef": 0.10947273671627045,
    "learning_rate": 0.001
  },
  {
    "episode": 4682,
    "reward": 86.970828,
    "length": 67,
    "time": 73541.187742,
    "actor_loss": -58.252220153808594,
    "critic_loss": 15.206696510314941,
    "ent_coef": 0.10808020830154419,
    "learning_rate": 0.001
  },
  {
    "episode": 4683,
    "reward": 88.522084,
    "length": 65,
    "time": 73553.379607,
    "actor_loss": -60.52105712890625,
    "critic_loss": 95.56687927246094,
    "ent_coef": 0.1098143458366394,
    "learning_rate": 0.001
  },
  {
    "episode": 4684,
    "reward": 86.086528,
    "length": 71,
    "time": 73566.636927,
    "actor_loss": -59.93708801269531,
    "critic_loss": 9.652106285095215,
    "ent_coef": 0.11019663512706757,
    "learning_rate": 0.001
  },
  {
    "episode": 4685,
    "reward": 84.311142,
    "length": 72,
    "time": 73581.813402,
    "actor_loss": -60.466644287109375,
    "critic_loss": 33.75395202636719,
    "ent_coef": 0.1064637303352356,
    "learning_rate": 0.001
  },
  {
    "episode": 4686,
    "reward": 86.100574,
    "length": 70,
    "time": 73593.86056,
    "actor_loss": -58.948081970214844,
    "critic_loss": 43.6292839050293,
    "ent_coef": 0.10411012917757034,
    "learning_rate": 0.001
  },
  {
    "episode": 4687,
    "reward": 83.714424,
    "length": 76,
    "time": 73609.382653,
    "actor_loss": -62.31498718261719,
    "critic_loss": 71.08251953125,
    "ent_coef": 0.10464956611394882,
    "learning_rate": 0.001
  },
  {
    "episode": 4688,
    "reward": 89.069651,
    "length": 64,
    "time": 73621.693898,
    "actor_loss": -65.6004638671875,
    "critic_loss": 13.7886381149292,
    "ent_coef": 0.10775250196456909,
    "learning_rate": 0.001
  },
  {
    "episode": 4689,
    "reward": 84.490076,
    "length": 75,
    "time": 73636.625251,
    "actor_loss": -61.29606628417969,
    "critic_loss": 6.862101078033447,
    "ent_coef": 0.10457564145326614,
    "learning_rate": 0.001
  },
  {
    "episode": 4690,
    "reward": 89.205159,
    "length": 66,
    "time": 73648.474462,
    "actor_loss": -51.03239440917969,
    "critic_loss": 7.962156295776367,
    "ent_coef": 0.10304493457078934,
    "learning_rate": 0.001
  },
  {
    "episode": 4691,
    "reward": 85.730076,
    "length": 100,
    "time": 73665.102102,
    "actor_loss": -56.214683532714844,
    "critic_loss": 62.1755485534668,
    "ent_coef": 0.10454966127872467,
    "learning_rate": 0.001
  },
  {
    "episode": 4692,
    "reward": 88.284773,
    "length": 66,
    "time": 73676.654887,
    "actor_loss": -58.067848205566406,
    "critic_loss": 14.633163452148438,
    "ent_coef": 0.10262418538331985,
    "learning_rate": 0.001
  },
  {
    "episode": 4693,
    "reward": 87.652208,
    "length": 67,
    "time": 73688.550021,
    "actor_loss": -55.14910125732422,
    "critic_loss": 3.134761333465576,
    "ent_coef": 0.10181718319654465,
    "learning_rate": 0.001
  },
  {
    "episode": 4694,
    "reward": 84.251902,
    "length": 74,
    "time": 73702.217338,
    "actor_loss": -61.574363708496094,
    "critic_loss": 5.5841217041015625,
    "ent_coef": 0.10097122937440872,
    "learning_rate": 0.001
  },
  {
    "episode": 4695,
    "reward": 89.148246,
    "length": 65,
    "time": 73719.032029,
    "actor_loss": -57.830989837646484,
    "critic_loss": 28.138607025146484,
    "ent_coef": 0.10117845237255096,
    "learning_rate": 0.001
  },
  {
    "episode": 4696,
    "reward": 85.498909,
    "length": 70,
    "time": 73731.626113,
    "actor_loss": -63.28412628173828,
    "critic_loss": 611.1007080078125,
    "ent_coef": 0.0988955870270729,
    "learning_rate": 0.001
  },
  {
    "episode": 4697,
    "reward": 88.900289,
    "length": 65,
    "time": 73746.042962,
    "actor_loss": -55.47899627685547,
    "critic_loss": 4.834628105163574,
    "ent_coef": 0.10327016562223434,
    "learning_rate": 0.001
  },
  {
    "episode": 4698,
    "reward": 87.34335,
    "length": 67,
    "time": 73757.920964,
    "actor_loss": -58.58405303955078,
    "critic_loss": 13.378103256225586,
    "ent_coef": 0.10235260426998138,
    "learning_rate": 0.001
  },
  {
    "episode": 4699,
    "reward": 88.176966,
    "length": 66,
    "time": 73771.261262,
    "actor_loss": -62.734134674072266,
    "critic_loss": 253.22091674804688,
    "ent_coef": 0.10168392211198807,
    "learning_rate": 0.001
  },
  {
    "episode": 4700,
    "reward": 84.732254,
    "length": 71,
    "time": 73784.499574,
    "actor_loss": -57.39971923828125,
    "critic_loss": 9.958505630493164,
    "ent_coef": 0.09940209239721298,
    "learning_rate": 0.001
  },
  {
    "episode": 4701,
    "reward": 86.897499,
    "length": 69,
    "time": 73796.790668,
    "actor_loss": -58.289154052734375,
    "critic_loss": 51.19361114501953,
    "ent_coef": 0.09911627322435379,
    "learning_rate": 0.001
  },
  {
    "episode": 4702,
    "reward": 87.206985,
    "length": 68,
    "time": 73809.537986,
    "actor_loss": -63.02936553955078,
    "critic_loss": 139.99032592773438,
    "ent_coef": 0.09936695545911789,
    "learning_rate": 0.001
  },
  {
    "episode": 4703,
    "reward": 86.132157,
    "length": 69,
    "time": 73824.600527,
    "actor_loss": -57.271873474121094,
    "critic_loss": 10.67503547668457,
    "ent_coef": 0.1003112643957138,
    "learning_rate": 0.001
  },
  {
    "episode": 4704,
    "reward": 88.89974,
    "length": 65,
    "time": 73835.970172,
    "actor_loss": -60.09436798095703,
    "critic_loss": 12.317916870117188,
    "ent_coef": 0.10208065807819366,
    "learning_rate": 0.001
  },
  {
    "episode": 4705,
    "reward": 89.483501,
    "length": 64,
    "time": 73847.272367,
    "actor_loss": -59.25827407836914,
    "critic_loss": 6.532868385314941,
    "ent_coef": 0.10097481310367584,
    "learning_rate": 0.001
  },
  {
    "episode": 4706,
    "reward": 85.31555,
    "length": 70,
    "time": 73859.288847,
    "actor_loss": -60.268863677978516,
    "critic_loss": 36.16042709350586,
    "ent_coef": 0.0975668802857399,
    "learning_rate": 0.001
  },
  {
    "episode": 4707,
    "reward": 84.738925,
    "length": 73,
    "time": 73879.31201,
    "actor_loss": -61.73280715942383,
    "critic_loss": 16.53411293029785,
    "ent_coef": 0.09538809210062027,
    "learning_rate": 0.001
  },
  {
    "episode": 4708,
    "reward": 86.513479,
    "length": 68,
    "time": 73891.182483,
    "actor_loss": -53.12854766845703,
    "critic_loss": 5.3605804443359375,
    "ent_coef": 0.098572738468647,
    "learning_rate": 0.001
  },
  {
    "episode": 4709,
    "reward": 88.734145,
    "length": 65,
    "time": 73905.188993,
    "actor_loss": -62.35770797729492,
    "critic_loss": 627.8382568359375,
    "ent_coef": 0.09993825852870941,
    "learning_rate": 0.001
  },
  {
    "episode": 4710,
    "reward": 89.476944,
    "length": 64,
    "time": 73916.919819,
    "actor_loss": -53.173858642578125,
    "critic_loss": 6.237148761749268,
    "ent_coef": 0.10252220928668976,
    "learning_rate": 0.001
  },
  {
    "episode": 4711,
    "reward": 88.581693,
    "length": 66,
    "time": 73935.031588,
    "actor_loss": -60.12004089355469,
    "critic_loss": 78.27108764648438,
    "ent_coef": 0.10114042460918427,
    "learning_rate": 0.001
  },
  {
    "episode": 4712,
    "reward": 86.462173,
    "length": 69,
    "time": 73947.15209,
    "actor_loss": -56.55849075317383,
    "critic_loss": 4.125816345214844,
    "ent_coef": 0.09632941335439682,
    "learning_rate": 0.001
  },
  {
    "episode": 4713,
    "reward": 84.958338,
    "length": 72,
    "time": 73963.047531,
    "actor_loss": -54.2755241394043,
    "critic_loss": 9.225811004638672,
    "ent_coef": 0.09231390804052353,
    "learning_rate": 0.001
  },
  {
    "episode": 4714,
    "reward": 87.415665,
    "length": 67,
    "time": 73974.721841,
    "actor_loss": -62.180320739746094,
    "critic_loss": 213.02157592773438,
    "ent_coef": 0.09347861260175705,
    "learning_rate": 0.001
  },
  {
    "episode": 4715,
    "reward": 85.094084,
    "length": 71,
    "time": 73986.641752,
    "actor_loss": -63.980873107910156,
    "critic_loss": 12.138046264648438,
    "ent_coef": 0.09321942180395126,
    "learning_rate": 0.001
  },
  {
    "episode": 4716,
    "reward": 89.481399,
    "length": 64,
    "time": 73998.961539,
    "actor_loss": -59.686981201171875,
    "critic_loss": 31.019235610961914,
    "ent_coef": 0.09717993438243866,
    "learning_rate": 0.001
  },
  {
    "episode": 4717,
    "reward": 88.461846,
    "length": 65,
    "time": 74011.424864,
    "actor_loss": -58.375099182128906,
    "critic_loss": 9.323055267333984,
    "ent_coef": 0.09977753460407257,
    "learning_rate": 0.001
  },
  {
    "episode": 4718,
    "reward": 87.892147,
    "length": 66,
    "time": 74025.585901,
    "actor_loss": -60.04662322998047,
    "critic_loss": 15.009050369262695,
    "ent_coef": 0.10104148089885712,
    "learning_rate": 0.001
  },
  {
    "episode": 4719,
    "reward": 88.639636,
    "length": 66,
    "time": 74040.613482,
    "actor_loss": -58.054054260253906,
    "critic_loss": 15.938629150390625,
    "ent_coef": 0.10355383157730103,
    "learning_rate": 0.001
  },
  {
    "episode": 4720,
    "reward": 88.249209,
    "length": 66,
    "time": 74053.963648,
    "actor_loss": -58.884056091308594,
    "critic_loss": 6.823027610778809,
    "ent_coef": 0.10228830575942993,
    "learning_rate": 0.001
  },
  {
    "episode": 4721,
    "reward": 88.934233,
    "length": 65,
    "time": 74067.518581,
    "actor_loss": -54.093467712402344,
    "critic_loss": 33.67054748535156,
    "ent_coef": 0.10036889463663101,
    "learning_rate": 0.001
  },
  {
    "episode": 4722,
    "reward": 87.860696,
    "length": 67,
    "time": 74079.656755,
    "actor_loss": -53.86393737792969,
    "critic_loss": 12.548145294189453,
    "ent_coef": 0.09964440762996674,
    "learning_rate": 0.001
  },
  {
    "episode": 4723,
    "reward": 88.090514,
    "length": 68,
    "time": 74094.665516,
    "actor_loss": -55.906036376953125,
    "critic_loss": 10.61203384399414,
    "ent_coef": 0.1061500832438469,
    "learning_rate": 0.001
  },
  {
    "episode": 4724,
    "reward": 87.39776,
    "length": 68,
    "time": 74108.118865,
    "actor_loss": -60.22895050048828,
    "critic_loss": 104.00283813476562,
    "ent_coef": 0.11107765883207321,
    "learning_rate": 0.001
  },
  {
    "episode": 4725,
    "reward": 86.285621,
    "length": 70,
    "time": 74121.987231,
    "actor_loss": -53.62552261352539,
    "critic_loss": 63.189659118652344,
    "ent_coef": 0.11311372369527817,
    "learning_rate": 0.001
  },
  {
    "episode": 4726,
    "reward": 88.621266,
    "length": 65,
    "time": 74133.236696,
    "actor_loss": -55.21376037597656,
    "critic_loss": 46.49351119995117,
    "ent_coef": 0.11246427893638611,
    "learning_rate": 0.001
  },
  {
    "episode": 4727,
    "reward": 78.969443,
    "length": 106,
    "time": 74149.951221,
    "actor_loss": -58.834922790527344,
    "critic_loss": 3.9669711589813232,
    "ent_coef": 0.10889416188001633,
    "learning_rate": 0.001
  },
  {
    "episode": 4728,
    "reward": 87.59282,
    "length": 67,
    "time": 74162.769625,
    "actor_loss": -65.34661865234375,
    "critic_loss": 27.841999053955078,
    "ent_coef": 0.10484018176794052,
    "learning_rate": 0.001
  },
  {
    "episode": 4729,
    "reward": 88.421586,
    "length": 69,
    "time": 74178.762036,
    "actor_loss": -54.86338806152344,
    "critic_loss": 152.5770721435547,
    "ent_coef": 0.10522294044494629,
    "learning_rate": 0.001
  },
  {
    "episode": 4730,
    "reward": 84.604534,
    "length": 73,
    "time": 74192.671928,
    "actor_loss": -61.393272399902344,
    "critic_loss": 28.648094177246094,
    "ent_coef": 0.1030779555439949,
    "learning_rate": 0.001
  },
  {
    "episode": 4731,
    "reward": 87.280152,
    "length": 69,
    "time": 74204.934726,
    "actor_loss": -61.28199005126953,
    "critic_loss": 11.884793281555176,
    "ent_coef": 0.10446660965681076,
    "learning_rate": 0.001
  },
  {
    "episode": 4732,
    "reward": 85.275424,
    "length": 70,
    "time": 74217.784141,
    "actor_loss": -54.99304962158203,
    "critic_loss": 8.017746925354004,
    "ent_coef": 0.1039716973900795,
    "learning_rate": 0.001
  },
  {
    "episode": 4733,
    "reward": 90.964289,
    "length": 62,
    "time": 74229.978631,
    "actor_loss": -56.170265197753906,
    "critic_loss": 63.634857177734375,
    "ent_coef": 0.10941097140312195,
    "learning_rate": 0.001
  },
  {
    "episode": 4734,
    "reward": 88.065311,
    "length": 67,
    "time": 74243.887019,
    "actor_loss": -62.369361877441406,
    "critic_loss": 67.46314239501953,
    "ent_coef": 0.11116298288106918,
    "learning_rate": 0.001
  },
  {
    "episode": 4735,
    "reward": 85.072299,
    "length": 69,
    "time": 74255.604229,
    "actor_loss": -58.274173736572266,
    "critic_loss": 7.679200172424316,
    "ent_coef": 0.11049694567918777,
    "learning_rate": 0.001
  },
  {
    "episode": 4736,
    "reward": 87.255628,
    "length": 69,
    "time": 74272.058503,
    "actor_loss": -58.434322357177734,
    "critic_loss": 10.8433837890625,
    "ent_coef": 0.10782666504383087,
    "learning_rate": 0.001
  },
  {
    "episode": 4737,
    "reward": 86.4981,
    "length": 71,
    "time": 74284.492734,
    "actor_loss": -59.214378356933594,
    "critic_loss": 12.822784423828125,
    "ent_coef": 0.10246770828962326,
    "learning_rate": 0.001
  },
  {
    "episode": 4738,
    "reward": 89.773202,
    "length": 63,
    "time": 74295.571728,
    "actor_loss": -62.22254943847656,
    "critic_loss": 7.497833728790283,
    "ent_coef": 0.1054195836186409,
    "learning_rate": 0.001
  },
  {
    "episode": 4739,
    "reward": 88.903213,
    "length": 65,
    "time": 74306.815141,
    "actor_loss": -59.15562438964844,
    "critic_loss": 67.86904907226562,
    "ent_coef": 0.10543126612901688,
    "learning_rate": 0.001
  },
  {
    "episode": 4740,
    "reward": 88.253977,
    "length": 67,
    "time": 74322.541839,
    "actor_loss": -58.38818359375,
    "critic_loss": 6.6814188957214355,
    "ent_coef": 0.1033453643321991,
    "learning_rate": 0.001
  },
  {
    "episode": 4741,
    "reward": 85.198279,
    "length": 70,
    "time": 74336.273183,
    "actor_loss": -63.19514465332031,
    "critic_loss": 35.31922149658203,
    "ent_coef": 0.10320138186216354,
    "learning_rate": 0.001
  },
  {
    "episode": 4742,
    "reward": 88.319569,
    "length": 66,
    "time": 74347.647898,
    "actor_loss": -58.36258316040039,
    "critic_loss": 5.672313690185547,
    "ent_coef": 0.10309914499521255,
    "learning_rate": 0.001
  },
  {
    "episode": 4743,
    "reward": 84.97591,
    "length": 72,
    "time": 74360.345675,
    "actor_loss": -58.55155563354492,
    "critic_loss": 10.3763427734375,
    "ent_coef": 0.10157414525747299,
    "learning_rate": 0.001
  },
  {
    "episode": 4744,
    "reward": 80.513443,
    "length": 80,
    "time": 74375.271476,
    "actor_loss": -60.46527099609375,
    "critic_loss": 6.7519965171813965,
    "ent_coef": 0.09577679634094238,
    "learning_rate": 0.001
  },
  {
    "episode": 4745,
    "reward": 88.435739,
    "length": 65,
    "time": 74388.423448,
    "actor_loss": -57.697872161865234,
    "critic_loss": 3.114675760269165,
    "ent_coef": 0.09315179288387299,
    "learning_rate": 0.001
  },
  {
    "episode": 4746,
    "reward": 86.825402,
    "length": 69,
    "time": 74400.821553,
    "actor_loss": -58.35147476196289,
    "critic_loss": 5.8755693435668945,
    "ent_coef": 0.09238438308238983,
    "learning_rate": 0.001
  },
  {
    "episode": 4747,
    "reward": 86.764182,
    "length": 68,
    "time": 74415.70835,
    "actor_loss": -61.91712951660156,
    "critic_loss": 77.50769805908203,
    "ent_coef": 0.09243428707122803,
    "learning_rate": 0.001
  },
  {
    "episode": 4748,
    "reward": 85.58784,
    "length": 70,
    "time": 74427.529426,
    "actor_loss": -57.462303161621094,
    "critic_loss": 4.125715255737305,
    "ent_coef": 0.09157667309045792,
    "learning_rate": 0.001
  },
  {
    "episode": 4749,
    "reward": 82.225914,
    "length": 79,
    "time": 74441.285069,
    "actor_loss": -56.496185302734375,
    "critic_loss": 20.496601104736328,
    "ent_coef": 0.09633217006921768,
    "learning_rate": 0.001
  },
  {
    "episode": 4750,
    "reward": 85.329934,
    "length": 70,
    "time": 74453.943213,
    "actor_loss": -53.48432159423828,
    "critic_loss": 7.411116600036621,
    "ent_coef": 0.10058976709842682,
    "learning_rate": 0.001
  },
  {
    "episode": 4751,
    "reward": 84.776847,
    "length": 72,
    "time": 74465.965676,
    "actor_loss": -57.77705383300781,
    "critic_loss": 39.545249938964844,
    "ent_coef": 0.09910989552736282,
    "learning_rate": 0.001
  },
  {
    "episode": 4752,
    "reward": 85.657896,
    "length": 72,
    "time": 74481.523258,
    "actor_loss": -57.23460388183594,
    "critic_loss": 21.83010482788086,
    "ent_coef": 0.09542669355869293,
    "learning_rate": 0.001
  },
  {
    "episode": 4753,
    "reward": 84.406263,
    "length": 73,
    "time": 74496.542364,
    "actor_loss": -58.34975051879883,
    "critic_loss": 11.476322174072266,
    "ent_coef": 0.09685734659433365,
    "learning_rate": 0.001
  },
  {
    "episode": 4754,
    "reward": 85.591539,
    "length": 71,
    "time": 74511.452547,
    "actor_loss": -53.378273010253906,
    "critic_loss": 12.228464126586914,
    "ent_coef": 0.09622318297624588,
    "learning_rate": 0.001
  },
  {
    "episode": 4755,
    "reward": 81.54508,
    "length": 79,
    "time": 74524.260846,
    "actor_loss": -63.067344665527344,
    "critic_loss": 51.0146369934082,
    "ent_coef": 0.09291025251150131,
    "learning_rate": 0.001
  },
  {
    "episode": 4756,
    "reward": 86.026171,
    "length": 70,
    "time": 74539.014338,
    "actor_loss": -60.306182861328125,
    "critic_loss": 25.258750915527344,
    "ent_coef": 0.09428942203521729,
    "learning_rate": 0.001
  },
  {
    "episode": 4757,
    "reward": 85.478668,
    "length": 71,
    "time": 74551.579515,
    "actor_loss": -58.911041259765625,
    "critic_loss": 5.001466751098633,
    "ent_coef": 0.09192691743373871,
    "learning_rate": 0.001
  },
  {
    "episode": 4758,
    "reward": 88.776449,
    "length": 65,
    "time": 74563.705227,
    "actor_loss": -56.74477767944336,
    "critic_loss": 9.235933303833008,
    "ent_coef": 0.09300043433904648,
    "learning_rate": 0.001
  },
  {
    "episode": 4759,
    "reward": 86.942746,
    "length": 70,
    "time": 74576.321827,
    "actor_loss": -57.2105712890625,
    "critic_loss": 68.38240051269531,
    "ent_coef": 0.09585350751876831,
    "learning_rate": 0.001
  },
  {
    "episode": 4760,
    "reward": 88.285939,
    "length": 66,
    "time": 74587.809382,
    "actor_loss": -62.14934539794922,
    "critic_loss": 10.99675178527832,
    "ent_coef": 0.09465169161558151,
    "learning_rate": 0.001
  },
  {
    "episode": 4761,
    "reward": 88.034191,
    "length": 67,
    "time": 74601.758197,
    "actor_loss": -59.86812210083008,
    "critic_loss": 126.31636047363281,
    "ent_coef": 0.09481886774301529,
    "learning_rate": 0.001
  },
  {
    "episode": 4762,
    "reward": 87.478531,
    "length": 68,
    "time": 74614.287897,
    "actor_loss": -58.94432067871094,
    "critic_loss": 33.93202590942383,
    "ent_coef": 0.0952615961432457,
    "learning_rate": 0.001
  },
  {
    "episode": 4763,
    "reward": 87.776854,
    "length": 69,
    "time": 74628.822381,
    "actor_loss": -61.49454116821289,
    "critic_loss": 153.74826049804688,
    "ent_coef": 0.09541747719049454,
    "learning_rate": 0.001
  },
  {
    "episode": 4764,
    "reward": 86.36545,
    "length": 69,
    "time": 74641.769423,
    "actor_loss": -60.52718734741211,
    "critic_loss": 41.98869323730469,
    "ent_coef": 0.09678356349468231,
    "learning_rate": 0.001
  },
  {
    "episode": 4765,
    "reward": 88.871047,
    "length": 65,
    "time": 74655.014054,
    "actor_loss": -55.542388916015625,
    "critic_loss": 9.287352561950684,
    "ent_coef": 0.10332890599966049,
    "learning_rate": 0.001
  },
  {
    "episode": 4766,
    "reward": -157.35124,
    "length": 141,
    "time": 74676.753454,
    "actor_loss": -62.90678787231445,
    "critic_loss": 27.93840980529785,
    "ent_coef": 0.1000099629163742,
    "learning_rate": 0.001
  },
  {
    "episode": 4767,
    "reward": 86.339242,
    "length": 70,
    "time": 74689.104569,
    "actor_loss": -58.654022216796875,
    "critic_loss": 36.513248443603516,
    "ent_coef": 0.09859885275363922,
    "learning_rate": 0.001
  },
  {
    "episode": 4768,
    "reward": 86.890749,
    "length": 68,
    "time": 74703.130647,
    "actor_loss": -57.72401809692383,
    "critic_loss": 42.977195739746094,
    "ent_coef": 0.09903649985790253,
    "learning_rate": 0.001
  },
  {
    "episode": 4769,
    "reward": 86.932967,
    "length": 69,
    "time": 74715.866329,
    "actor_loss": -64.1783676147461,
    "critic_loss": 45.99334716796875,
    "ent_coef": 0.10250619798898697,
    "learning_rate": 0.001
  },
  {
    "episode": 4770,
    "reward": 88.120569,
    "length": 67,
    "time": 74727.540757,
    "actor_loss": -61.46135711669922,
    "critic_loss": 11.300826072692871,
    "ent_coef": 0.10020226240158081,
    "learning_rate": 0.001
  },
  {
    "episode": 4771,
    "reward": 89.185626,
    "length": 65,
    "time": 74742.583924,
    "actor_loss": -58.66453552246094,
    "critic_loss": 66.52127075195312,
    "ent_coef": 0.10200098901987076,
    "learning_rate": 0.001
  },
  {
    "episode": 4772,
    "reward": 88.738291,
    "length": 66,
    "time": 74753.95366,
    "actor_loss": -63.361244201660156,
    "critic_loss": 123.62871551513672,
    "ent_coef": 0.10574549436569214,
    "learning_rate": 0.001
  },
  {
    "episode": 4773,
    "reward": 86.971824,
    "length": 69,
    "time": 74765.58583,
    "actor_loss": -59.086822509765625,
    "critic_loss": 31.14928436279297,
    "ent_coef": 0.1064719557762146,
    "learning_rate": 0.001
  },
  {
    "episode": 4774,
    "reward": 85.420586,
    "length": 70,
    "time": 74778.394027,
    "actor_loss": -60.962215423583984,
    "critic_loss": 106.2874526977539,
    "ent_coef": 0.10610628128051758,
    "learning_rate": 0.001
  },
  {
    "episode": 4775,
    "reward": 89.185837,
    "length": 68,
    "time": 74790.184804,
    "actor_loss": -62.14569091796875,
    "critic_loss": 8.013723373413086,
    "ent_coef": 0.10617025941610336,
    "learning_rate": 0.001
  },
  {
    "episode": 4776,
    "reward": 86.813287,
    "length": 68,
    "time": 74801.547919,
    "actor_loss": -59.07793426513672,
    "critic_loss": 17.737762451171875,
    "ent_coef": 0.10639803856611252,
    "learning_rate": 0.001
  },
  {
    "episode": 4777,
    "reward": 84.600267,
    "length": 73,
    "time": 74816.591218,
    "actor_loss": -59.04349136352539,
    "critic_loss": 6.242316722869873,
    "ent_coef": 0.10094314068555832,
    "learning_rate": 0.001
  },
  {
    "episode": 4778,
    "reward": 85.146335,
    "length": 72,
    "time": 74833.359865,
    "actor_loss": -57.62558364868164,
    "critic_loss": 9.318209648132324,
    "ent_coef": 0.09613675624132156,
    "learning_rate": 0.001
  },
  {
    "episode": 4779,
    "reward": 80.660573,
    "length": 82,
    "time": 74847.891297,
    "actor_loss": -65.75071716308594,
    "critic_loss": 10.980548858642578,
    "ent_coef": 0.09170810878276825,
    "learning_rate": 0.001
  },
  {
    "episode": 4780,
    "reward": 87.513893,
    "length": 68,
    "time": 74860.547953,
    "actor_loss": -65.24882507324219,
    "critic_loss": 10.876424789428711,
    "ent_coef": 0.09055615216493607,
    "learning_rate": 0.001
  },
  {
    "episode": 4781,
    "reward": 87.798768,
    "length": 67,
    "time": 74877.468464,
    "actor_loss": -62.92661666870117,
    "critic_loss": 4.223249435424805,
    "ent_coef": 0.09456430375576019,
    "learning_rate": 0.001
  },
  {
    "episode": 4782,
    "reward": 88.458505,
    "length": 65,
    "time": 74892.581028,
    "actor_loss": -60.181026458740234,
    "critic_loss": 9.30839729309082,
    "ent_coef": 0.09657296538352966,
    "learning_rate": 0.001
  },
  {
    "episode": 4783,
    "reward": 89.540986,
    "length": 64,
    "time": 74904.754297,
    "actor_loss": -59.14612579345703,
    "critic_loss": 32.78369140625,
    "ent_coef": 0.09656239300966263,
    "learning_rate": 0.001
  },
  {
    "episode": 4784,
    "reward": 85.157373,
    "length": 72,
    "time": 74917.481773,
    "actor_loss": -60.85157775878906,
    "critic_loss": 19.184234619140625,
    "ent_coef": 0.0956120491027832,
    "learning_rate": 0.001
  },
  {
    "episode": 4785,
    "reward": 86.982872,
    "length": 69,
    "time": 74930.123774,
    "actor_loss": -63.107757568359375,
    "critic_loss": 9.481546401977539,
    "ent_coef": 0.09458637237548828,
    "learning_rate": 0.001
  },
  {
    "episode": 4786,
    "reward": 88.825599,
    "length": 66,
    "time": 74943.64583,
    "actor_loss": -59.3167724609375,
    "critic_loss": 21.20824432373047,
    "ent_coef": 0.09808401018381119,
    "learning_rate": 0.001
  },
  {
    "episode": 4787,
    "reward": 89.097757,
    "length": 64,
    "time": 74958.137202,
    "actor_loss": -54.245967864990234,
    "critic_loss": 34.71305465698242,
    "ent_coef": 0.10435836762189865,
    "learning_rate": 0.001
  },
  {
    "episode": 4788,
    "reward": 87.542508,
    "length": 67,
    "time": 74975.631516,
    "actor_loss": -61.845367431640625,
    "critic_loss": 26.217966079711914,
    "ent_coef": 0.10537198930978775,
    "learning_rate": 0.001
  },
  {
    "episode": 4789,
    "reward": 86.49699,
    "length": 68,
    "time": 74992.146486,
    "actor_loss": -56.65380859375,
    "critic_loss": 5.035951614379883,
    "ent_coef": 0.10348016023635864,
    "learning_rate": 0.001
  },
  {
    "episode": 4790,
    "reward": 84.959689,
    "length": 72,
    "time": 75007.692163,
    "actor_loss": -59.3511962890625,
    "critic_loss": 47.792579650878906,
    "ent_coef": 0.09978381544351578,
    "learning_rate": 0.001
  },
  {
    "episode": 4791,
    "reward": 88.333257,
    "length": 66,
    "time": 75019.717407,
    "actor_loss": -54.39004135131836,
    "critic_loss": 10.473751068115234,
    "ent_coef": 0.1020205169916153,
    "learning_rate": 0.001
  },
  {
    "episode": 4792,
    "reward": 89.119614,
    "length": 65,
    "time": 75033.411255,
    "actor_loss": -56.91521072387695,
    "critic_loss": 4.846723556518555,
    "ent_coef": 0.1047600582242012,
    "learning_rate": 0.001
  },
  {
    "episode": 4793,
    "reward": 87.074935,
    "length": 69,
    "time": 75046.193852,
    "actor_loss": -62.3412971496582,
    "critic_loss": 6.997611999511719,
    "ent_coef": 0.09908023476600647,
    "learning_rate": 0.001
  },
  {
    "episode": 4794,
    "reward": 87.332631,
    "length": 68,
    "time": 75058.940712,
    "actor_loss": -58.68898010253906,
    "critic_loss": 4.519433975219727,
    "ent_coef": 0.0964207723736763,
    "learning_rate": 0.001
  },
  {
    "episode": 4795,
    "reward": 88.22219,
    "length": 66,
    "time": 75071.085509,
    "actor_loss": -61.071998596191406,
    "critic_loss": 28.445388793945312,
    "ent_coef": 0.0925712063908577,
    "learning_rate": 0.001
  },
  {
    "episode": 4796,
    "reward": 81.503899,
    "length": 79,
    "time": 75084.873765,
    "actor_loss": -58.55481719970703,
    "critic_loss": 24.77290153503418,
    "ent_coef": 0.08664584904909134,
    "learning_rate": 0.001
  },
  {
    "episode": 4797,
    "reward": 85.259662,
    "length": 71,
    "time": 75098.47245,
    "actor_loss": -60.76679611206055,
    "critic_loss": 12.302279472351074,
    "ent_coef": 0.08081237226724625,
    "learning_rate": 0.001
  },
  {
    "episode": 4798,
    "reward": 77.984807,
    "length": 85,
    "time": 75111.938488,
    "actor_loss": -60.868743896484375,
    "critic_loss": 516.7130126953125,
    "ent_coef": 0.07997959107160568,
    "learning_rate": 0.001
  },
  {
    "episode": 4799,
    "reward": 84.953455,
    "length": 75,
    "time": 75126.195951,
    "actor_loss": -57.14887237548828,
    "critic_loss": 58.71352767944336,
    "ent_coef": 0.07985855638980865,
    "learning_rate": 0.001
  },
  {
    "episode": 4800,
    "reward": 64.359671,
    "length": 100,
    "time": 75143.129115,
    "actor_loss": -57.75199508666992,
    "critic_loss": 27.252086639404297,
    "ent_coef": 0.07673028111457825,
    "learning_rate": 0.001
  },
  {
    "episode": 4801,
    "reward": 78.565336,
    "length": 83,
    "time": 75156.719518,
    "actor_loss": -58.50529098510742,
    "critic_loss": 17.147985458374023,
    "ent_coef": 0.07445039600133896,
    "learning_rate": 0.001
  },
  {
    "episode": 4802,
    "reward": 78.674304,
    "length": 83,
    "time": 75171.368478,
    "actor_loss": -52.00713348388672,
    "critic_loss": 31.64482307434082,
    "ent_coef": 0.0739581435918808,
    "learning_rate": 0.001
  },
  {
    "episode": 4803,
    "reward": 78.501589,
    "length": 82,
    "time": 75184.956372,
    "actor_loss": -62.00209426879883,
    "critic_loss": 15.425240516662598,
    "ent_coef": 0.07243452221155167,
    "learning_rate": 0.001
  },
  {
    "episode": 4804,
    "reward": 86.616254,
    "length": 69,
    "time": 75198.905303,
    "actor_loss": -60.3854866027832,
    "critic_loss": 6.5501604080200195,
    "ent_coef": 0.0729169249534607,
    "learning_rate": 0.001
  },
  {
    "episode": 4805,
    "reward": 81.477933,
    "length": 76,
    "time": 75211.436286,
    "actor_loss": -54.28889846801758,
    "critic_loss": 32.07674026489258,
    "ent_coef": 0.07359921932220459,
    "learning_rate": 0.001
  },
  {
    "episode": 4806,
    "reward": 87.069332,
    "length": 67,
    "time": 75225.672193,
    "actor_loss": -64.53482055664062,
    "critic_loss": 5.740652084350586,
    "ent_coef": 0.07431148737668991,
    "learning_rate": 0.001
  },
  {
    "episode": 4807,
    "reward": 60.594568,
    "length": 104,
    "time": 75245.354593,
    "actor_loss": -62.71458435058594,
    "critic_loss": 6.694632530212402,
    "ent_coef": 0.07376913726329803,
    "learning_rate": 0.001
  },
  {
    "episode": 4808,
    "reward": 85.091495,
    "length": 71,
    "time": 75257.359382,
    "actor_loss": -61.43292999267578,
    "critic_loss": 4.971555233001709,
    "ent_coef": 0.07650411874055862,
    "learning_rate": 0.001
  },
  {
    "episode": 4809,
    "reward": 90.500443,
    "length": 62,
    "time": 75268.361908,
    "actor_loss": -63.47460174560547,
    "critic_loss": 5.377997398376465,
    "ent_coef": 0.08236940205097198,
    "learning_rate": 0.001
  },
  {
    "episode": 4810,
    "reward": 87.000623,
    "length": 69,
    "time": 75281.079569,
    "actor_loss": -64.41619873046875,
    "critic_loss": 156.9358367919922,
    "ent_coef": 0.0865698829293251,
    "learning_rate": 0.001
  },
  {
    "episode": 4811,
    "reward": 87.76913,
    "length": 67,
    "time": 75292.659412,
    "actor_loss": -59.372589111328125,
    "critic_loss": 666.7103271484375,
    "ent_coef": 0.08911948651075363,
    "learning_rate": 0.001
  },
  {
    "episode": 4812,
    "reward": 84.023184,
    "length": 74,
    "time": 75305.104228,
    "actor_loss": -61.02601623535156,
    "critic_loss": 21.316862106323242,
    "ent_coef": 0.08639706671237946,
    "learning_rate": 0.001
  },
  {
    "episode": 4813,
    "reward": 88.271941,
    "length": 67,
    "time": 75316.764756,
    "actor_loss": -59.239707946777344,
    "critic_loss": 92.90991973876953,
    "ent_coef": 0.08912809193134308,
    "learning_rate": 0.001
  },
  {
    "episode": 4814,
    "reward": 86.154049,
    "length": 70,
    "time": 75329.279622,
    "actor_loss": -59.51097106933594,
    "critic_loss": 29.607677459716797,
    "ent_coef": 0.08698944002389908,
    "learning_rate": 0.001
  },
  {
    "episode": 4815,
    "reward": 84.369048,
    "length": 71,
    "time": 75343.658912,
    "actor_loss": -61.67412567138672,
    "critic_loss": 16.260421752929688,
    "ent_coef": 0.0865330919623375,
    "learning_rate": 0.001
  },
  {
    "episode": 4816,
    "reward": 83.772421,
    "length": 74,
    "time": 75357.205538,
    "actor_loss": -63.029441833496094,
    "critic_loss": 19.881439208984375,
    "ent_coef": 0.08355634659528732,
    "learning_rate": 0.001
  },
  {
    "episode": 4817,
    "reward": 80.264143,
    "length": 78,
    "time": 75374.101804,
    "actor_loss": -61.64350509643555,
    "critic_loss": 6.744655609130859,
    "ent_coef": 0.08180350810289383,
    "learning_rate": 0.001
  },
  {
    "episode": 4818,
    "reward": 87.172621,
    "length": 67,
    "time": 75385.781175,
    "actor_loss": -63.2286262512207,
    "critic_loss": 39.74168014526367,
    "ent_coef": 0.08626307547092438,
    "learning_rate": 0.001
  },
  {
    "episode": 4819,
    "reward": 86.315042,
    "length": 69,
    "time": 75397.681705,
    "actor_loss": -59.51508331298828,
    "critic_loss": 7.9778594970703125,
    "ent_coef": 0.08830628544092178,
    "learning_rate": 0.001
  },
  {
    "episode": 4820,
    "reward": 86.460691,
    "length": 68,
    "time": 75409.279565,
    "actor_loss": -63.192298889160156,
    "critic_loss": 36.8624267578125,
    "ent_coef": 0.08900102227926254,
    "learning_rate": 0.001
  },
  {
    "episode": 4821,
    "reward": 88.164233,
    "length": 68,
    "time": 75421.953451,
    "actor_loss": -62.95630645751953,
    "critic_loss": 9.892311096191406,
    "ent_coef": 0.09139035642147064,
    "learning_rate": 0.001
  },
  {
    "episode": 4822,
    "reward": 68.828972,
    "length": 96,
    "time": 75439.377735,
    "actor_loss": -62.49031448364258,
    "critic_loss": 40.67331314086914,
    "ent_coef": 0.0896499827504158,
    "learning_rate": 0.001
  },
  {
    "episode": 4823,
    "reward": 88.10092,
    "length": 67,
    "time": 75450.797192,
    "actor_loss": -61.9212646484375,
    "critic_loss": 11.907079696655273,
    "ent_coef": 0.09208559989929199,
    "learning_rate": 0.001
  },
  {
    "episode": 4824,
    "reward": 85.686282,
    "length": 70,
    "time": 75462.935552,
    "actor_loss": -62.484195709228516,
    "critic_loss": 13.369019508361816,
    "ent_coef": 0.09352792799472809,
    "learning_rate": 0.001
  },
  {
    "episode": 4825,
    "reward": 89.678981,
    "length": 63,
    "time": 75474.290756,
    "actor_loss": -63.54216766357422,
    "critic_loss": 102.38507080078125,
    "ent_coef": 0.09563819319009781,
    "learning_rate": 0.001
  },
  {
    "episode": 4826,
    "reward": 89.772105,
    "length": 64,
    "time": 75485.668427,
    "actor_loss": -61.46765899658203,
    "critic_loss": 28.844148635864258,
    "ent_coef": 0.09873943030834198,
    "learning_rate": 0.001
  },
  {
    "episode": 4827,
    "reward": 89.389502,
    "length": 64,
    "time": 75498.4656,
    "actor_loss": -58.03141784667969,
    "critic_loss": 86.4339828491211,
    "ent_coef": 0.09873395413160324,
    "learning_rate": 0.001
  },
  {
    "episode": 4828,
    "reward": 84.961404,
    "length": 72,
    "time": 75510.365722,
    "actor_loss": -55.446502685546875,
    "critic_loss": 6.602317810058594,
    "ent_coef": 0.09944711625576019,
    "learning_rate": 0.001
  },
  {
    "episode": 4829,
    "reward": 89.077507,
    "length": 67,
    "time": 75521.846777,
    "actor_loss": -60.769874572753906,
    "critic_loss": 4.10584831237793,
    "ent_coef": 0.10116605460643768,
    "learning_rate": 0.001
  },
  {
    "episode": 4830,
    "reward": 89.64574,
    "length": 64,
    "time": 75537.328644,
    "actor_loss": -64.26335144042969,
    "critic_loss": 6.662449359893799,
    "ent_coef": 0.10216923803091049,
    "learning_rate": 0.001
  },
  {
    "episode": 4831,
    "reward": 86.363123,
    "length": 70,
    "time": 75550.192386,
    "actor_loss": -55.64002990722656,
    "critic_loss": 79.51968383789062,
    "ent_coef": 0.1006113812327385,
    "learning_rate": 0.001
  },
  {
    "episode": 4832,
    "reward": 83.382795,
    "length": 75,
    "time": 75565.842703,
    "actor_loss": -60.02378845214844,
    "critic_loss": 62.2884635925293,
    "ent_coef": 0.09814997762441635,
    "learning_rate": 0.001
  },
  {
    "episode": 4833,
    "reward": 88.464565,
    "length": 66,
    "time": 75577.107684,
    "actor_loss": -58.479393005371094,
    "critic_loss": 7.436778545379639,
    "ent_coef": 0.1018700897693634,
    "learning_rate": 0.001
  },
  {
    "episode": 4834,
    "reward": 83.424922,
    "length": 79,
    "time": 75590.968866,
    "actor_loss": -62.01244354248047,
    "critic_loss": 7.621352672576904,
    "ent_coef": 0.10056149214506149,
    "learning_rate": 0.001
  },
  {
    "episode": 4835,
    "reward": 87.453348,
    "length": 68,
    "time": 75603.720461,
    "actor_loss": -61.03203201293945,
    "critic_loss": 81.38654327392578,
    "ent_coef": 0.0992823988199234,
    "learning_rate": 0.001
  },
  {
    "episode": 4836,
    "reward": 85.405313,
    "length": 81,
    "time": 75619.26541,
    "actor_loss": -59.75725555419922,
    "critic_loss": 17.9423828125,
    "ent_coef": 0.10394001752138138,
    "learning_rate": 0.001
  },
  {
    "episode": 4837,
    "reward": 88.795468,
    "length": 65,
    "time": 75630.77004,
    "actor_loss": -64.22960662841797,
    "critic_loss": 28.378271102905273,
    "ent_coef": 0.10950202494859695,
    "learning_rate": 0.001
  },
  {
    "episode": 4838,
    "reward": 88.278837,
    "length": 66,
    "time": 75645.464268,
    "actor_loss": -66.50546264648438,
    "critic_loss": 9.292657852172852,
    "ent_coef": 0.10978575795888901,
    "learning_rate": 0.001
  },
  {
    "episode": 4839,
    "reward": 85.027669,
    "length": 71,
    "time": 75658.294843,
    "actor_loss": -57.965614318847656,
    "critic_loss": 9.36953067779541,
    "ent_coef": 0.10462476313114166,
    "learning_rate": 0.001
  },
  {
    "episode": 4840,
    "reward": 89.09908,
    "length": 64,
    "time": 75670.441497,
    "actor_loss": -63.1119499206543,
    "critic_loss": 47.51485061645508,
    "ent_coef": 0.10205168277025223,
    "learning_rate": 0.001
  },
  {
    "episode": 4841,
    "reward": 85.64969,
    "length": 70,
    "time": 75683.494147,
    "actor_loss": -55.68733596801758,
    "critic_loss": 3.04264235496521,
    "ent_coef": 0.09980458766222,
    "learning_rate": 0.001
  },
  {
    "episode": 4842,
    "reward": 83.331933,
    "length": 75,
    "time": 75700.616798,
    "actor_loss": -64.55235290527344,
    "critic_loss": 29.952882766723633,
    "ent_coef": 0.09668273478746414,
    "learning_rate": 0.001
  },
  {
    "episode": 4843,
    "reward": 86.239985,
    "length": 69,
    "time": 75713.05913,
    "actor_loss": -51.52330017089844,
    "critic_loss": 7.536303520202637,
    "ent_coef": 0.093675397336483,
    "learning_rate": 0.001
  },
  {
    "episode": 4844,
    "reward": 86.412418,
    "length": 70,
    "time": 75726.041313,
    "actor_loss": -60.54676055908203,
    "critic_loss": 8.178125381469727,
    "ent_coef": 0.0954609140753746,
    "learning_rate": 0.001
  },
  {
    "episode": 4845,
    "reward": 89.072162,
    "length": 65,
    "time": 75737.966169,
    "actor_loss": -59.752479553222656,
    "critic_loss": 6.54998779296875,
    "ent_coef": 0.09379247575998306,
    "learning_rate": 0.001
  },
  {
    "episode": 4846,
    "reward": 85.808952,
    "length": 70,
    "time": 75750.78602,
    "actor_loss": -61.037628173828125,
    "critic_loss": 73.61956787109375,
    "ent_coef": 0.092036671936512,
    "learning_rate": 0.001
  },
  {
    "episode": 4847,
    "reward": 89.019597,
    "length": 65,
    "time": 75762.768595,
    "actor_loss": -64.06138610839844,
    "critic_loss": 40.16677474975586,
    "ent_coef": 0.0905114933848381,
    "learning_rate": 0.001
  },
  {
    "episode": 4848,
    "reward": 82.546666,
    "length": 76,
    "time": 75778.90089,
    "actor_loss": -56.54570007324219,
    "critic_loss": 17.664350509643555,
    "ent_coef": 0.08446424454450607,
    "learning_rate": 0.001
  },
  {
    "episode": 4849,
    "reward": 88.157539,
    "length": 69,
    "time": 75790.444826,
    "actor_loss": -64.4043960571289,
    "critic_loss": 106.62553405761719,
    "ent_coef": 0.08493129163980484,
    "learning_rate": 0.001
  },
  {
    "episode": 4850,
    "reward": 88.332795,
    "length": 66,
    "time": 75804.394968,
    "actor_loss": -65.33826446533203,
    "critic_loss": 30.399866104125977,
    "ent_coef": 0.08866175264120102,
    "learning_rate": 0.001
  },
  {
    "episode": 4851,
    "reward": 88.842496,
    "length": 65,
    "time": 75817.829781,
    "actor_loss": -55.350830078125,
    "critic_loss": 74.87384033203125,
    "ent_coef": 0.09106064587831497,
    "learning_rate": 0.001
  },
  {
    "episode": 4852,
    "reward": 78.015745,
    "length": 84,
    "time": 75831.450099,
    "actor_loss": -62.03484344482422,
    "critic_loss": 11.827392578125,
    "ent_coef": 0.08891764283180237,
    "learning_rate": 0.001
  },
  {
    "episode": 4853,
    "reward": 89.089202,
    "length": 63,
    "time": 75846.073354,
    "actor_loss": -57.370445251464844,
    "critic_loss": 121.15235900878906,
    "ent_coef": 0.0912439227104187,
    "learning_rate": 0.001
  },
  {
    "episode": 4854,
    "reward": 91.042384,
    "length": 61,
    "time": 75857.907368,
    "actor_loss": -63.55150604248047,
    "critic_loss": 11.587615966796875,
    "ent_coef": 0.09481444209814072,
    "learning_rate": 0.001
  },
  {
    "episode": 4855,
    "reward": 90.091156,
    "length": 63,
    "time": 75872.343135,
    "actor_loss": -57.970069885253906,
    "critic_loss": 40.79533767700195,
    "ent_coef": 0.09651611000299454,
    "learning_rate": 0.001
  },
  {
    "episode": 4856,
    "reward": 90.436921,
    "length": 63,
    "time": 75883.328593,
    "actor_loss": -61.43979263305664,
    "critic_loss": 70.02449035644531,
    "ent_coef": 0.10017343610525131,
    "learning_rate": 0.001
  },
  {
    "episode": 4857,
    "reward": 88.02496,
    "length": 66,
    "time": 75895.576031,
    "actor_loss": -58.942359924316406,
    "critic_loss": 15.891697883605957,
    "ent_coef": 0.10158257186412811,
    "learning_rate": 0.001
  },
  {
    "episode": 4858,
    "reward": 88.996617,
    "length": 66,
    "time": 75908.442865,
    "actor_loss": -64.93017578125,
    "critic_loss": 98.18096923828125,
    "ent_coef": 0.1011563315987587,
    "learning_rate": 0.001
  },
  {
    "episode": 4859,
    "reward": 89.006884,
    "length": 65,
    "time": 75921.274589,
    "actor_loss": -60.54942321777344,
    "critic_loss": 73.53068542480469,
    "ent_coef": 0.09713532030582428,
    "learning_rate": 0.001
  },
  {
    "episode": 4860,
    "reward": 88.999948,
    "length": 66,
    "time": 75932.664553,
    "actor_loss": -62.74836349487305,
    "critic_loss": 38.18206024169922,
    "ent_coef": 0.09686344116926193,
    "learning_rate": 0.001
  },
  {
    "episode": 4861,
    "reward": 88.767057,
    "length": 66,
    "time": 75948.652612,
    "actor_loss": -57.68573760986328,
    "critic_loss": 69.67113494873047,
    "ent_coef": 0.09851279854774475,
    "learning_rate": 0.001
  },
  {
    "episode": 4862,
    "reward": 86.258863,
    "length": 70,
    "time": 75961.091026,
    "actor_loss": -64.30226135253906,
    "critic_loss": 16.586524963378906,
    "ent_coef": 0.0921078473329544,
    "learning_rate": 0.001
  },
  {
    "episode": 4863,
    "reward": 87.352302,
    "length": 67,
    "time": 75972.694782,
    "actor_loss": -62.3599853515625,
    "critic_loss": 24.011096954345703,
    "ent_coef": 0.09239422529935837,
    "learning_rate": 0.001
  },
  {
    "episode": 4864,
    "reward": 89.718905,
    "length": 65,
    "time": 75984.496389,
    "actor_loss": -59.221290588378906,
    "critic_loss": 58.21665573120117,
    "ent_coef": 0.09437024593353271,
    "learning_rate": 0.001
  },
  {
    "episode": 4865,
    "reward": 87.63577,
    "length": 66,
    "time": 76002.319683,
    "actor_loss": -63.725242614746094,
    "critic_loss": 15.18735408782959,
    "ent_coef": 0.09524760395288467,
    "learning_rate": 0.001
  },
  {
    "episode": 4866,
    "reward": 89.799252,
    "length": 64,
    "time": 76014.206671,
    "actor_loss": -66.69087219238281,
    "critic_loss": 7.749377250671387,
    "ent_coef": 0.09824922680854797,
    "learning_rate": 0.001
  },
  {
    "episode": 4867,
    "reward": 88.707788,
    "length": 65,
    "time": 76025.774959,
    "actor_loss": -55.448265075683594,
    "critic_loss": 15.731674194335938,
    "ent_coef": 0.09964374452829361,
    "learning_rate": 0.001
  },
  {
    "episode": 4868,
    "reward": 85.877155,
    "length": 71,
    "time": 76037.774513,
    "actor_loss": -60.70073699951172,
    "critic_loss": 9.43423080444336,
    "ent_coef": 0.09323520958423615,
    "learning_rate": 0.001
  },
  {
    "episode": 4869,
    "reward": 87.105765,
    "length": 68,
    "time": 76052.875527,
    "actor_loss": -46.918418884277344,
    "critic_loss": 156.51568603515625,
    "ent_coef": 0.09165333956480026,
    "learning_rate": 0.001
  },
  {
    "episode": 4870,
    "reward": 82.615188,
    "length": 75,
    "time": 76065.161034,
    "actor_loss": -58.9935417175293,
    "critic_loss": 19.206066131591797,
    "ent_coef": 0.0882478803396225,
    "learning_rate": 0.001
  },
  {
    "episode": 4871,
    "reward": 87.6784,
    "length": 67,
    "time": 76077.950029,
    "actor_loss": -47.48270797729492,
    "critic_loss": 55.593177795410156,
    "ent_coef": 0.08934018760919571,
    "learning_rate": 0.001
  },
  {
    "episode": 4872,
    "reward": 88.552221,
    "length": 65,
    "time": 76092.506975,
    "actor_loss": -64.88003540039062,
    "critic_loss": 6.021542549133301,
    "ent_coef": 0.09206031262874603,
    "learning_rate": 0.001
  },
  {
    "episode": 4873,
    "reward": 86.609214,
    "length": 69,
    "time": 76105.555068,
    "actor_loss": -60.78125762939453,
    "critic_loss": 4.357425212860107,
    "ent_coef": 0.09436161071062088,
    "learning_rate": 0.001
  },
  {
    "episode": 4874,
    "reward": 87.245038,
    "length": 68,
    "time": 76118.041035,
    "actor_loss": -57.69542694091797,
    "critic_loss": 3.715142250061035,
    "ent_coef": 0.09485448896884918,
    "learning_rate": 0.001
  },
  {
    "episode": 4875,
    "reward": 90.640613,
    "length": 62,
    "time": 76131.102437,
    "actor_loss": -61.79083251953125,
    "critic_loss": 26.867671966552734,
    "ent_coef": 0.0953441634774208,
    "learning_rate": 0.001
  },
  {
    "episode": 4876,
    "reward": 86.673128,
    "length": 68,
    "time": 76144.601434,
    "actor_loss": -67.56996154785156,
    "critic_loss": 51.14539337158203,
    "ent_coef": 0.09589790552854538,
    "learning_rate": 0.001
  },
  {
    "episode": 4877,
    "reward": 90.485137,
    "length": 63,
    "time": 76156.24041,
    "actor_loss": -61.407257080078125,
    "critic_loss": 17.127002716064453,
    "ent_coef": 0.09785263240337372,
    "learning_rate": 0.001
  },
  {
    "episode": 4878,
    "reward": 86.347601,
    "length": 70,
    "time": 76168.621676,
    "actor_loss": -63.4586067199707,
    "critic_loss": 12.224089622497559,
    "ent_coef": 0.09754678606987,
    "learning_rate": 0.001
  },
  {
    "episode": 4879,
    "reward": 88.15807,
    "length": 66,
    "time": 76182.467203,
    "actor_loss": -57.71635818481445,
    "critic_loss": 5.761067867279053,
    "ent_coef": 0.09831617772579193,
    "learning_rate": 0.001
  },
  {
    "episode": 4880,
    "reward": 88.761995,
    "length": 66,
    "time": 76194.72192,
    "actor_loss": -56.41792678833008,
    "critic_loss": 32.50849533081055,
    "ent_coef": 0.10325334966182709,
    "learning_rate": 0.001
  },
  {
    "episode": 4881,
    "reward": 88.843609,
    "length": 65,
    "time": 76206.153617,
    "actor_loss": -57.41045379638672,
    "critic_loss": 23.635717391967773,
    "ent_coef": 0.10691046714782715,
    "learning_rate": 0.001
  },
  {
    "episode": 4882,
    "reward": 89.529449,
    "length": 65,
    "time": 76217.500668,
    "actor_loss": -56.99862289428711,
    "critic_loss": 129.32733154296875,
    "ent_coef": 0.10745633393526077,
    "learning_rate": 0.001
  },
  {
    "episode": 4883,
    "reward": 89.080315,
    "length": 65,
    "time": 76229.631869,
    "actor_loss": -63.695716857910156,
    "critic_loss": 9.911197662353516,
    "ent_coef": 0.10414503514766693,
    "learning_rate": 0.001
  },
  {
    "episode": 4884,
    "reward": 87.930641,
    "length": 67,
    "time": 76241.319068,
    "actor_loss": -66.25545501708984,
    "critic_loss": 10.404996871948242,
    "ent_coef": 0.10255070775747299,
    "learning_rate": 0.001
  },
  {
    "episode": 4885,
    "reward": 87.936989,
    "length": 67,
    "time": 76252.682591,
    "actor_loss": -60.49747085571289,
    "critic_loss": 57.8018913269043,
    "ent_coef": 0.09913624078035355,
    "learning_rate": 0.001
  },
  {
    "episode": 4886,
    "reward": 88.767015,
    "length": 66,
    "time": 76266.709189,
    "actor_loss": -60.58720397949219,
    "critic_loss": 10.650375366210938,
    "ent_coef": 0.0972430482506752,
    "learning_rate": 0.001
  },
  {
    "episode": 4887,
    "reward": 88.196219,
    "length": 66,
    "time": 76279.575994,
    "actor_loss": -59.80661392211914,
    "critic_loss": 5.821589946746826,
    "ent_coef": 0.09850571304559708,
    "learning_rate": 0.001
  },
  {
    "episode": 4888,
    "reward": 87.35854,
    "length": 68,
    "time": 76292.072629,
    "actor_loss": -59.56324768066406,
    "critic_loss": 66.09576416015625,
    "ent_coef": 0.09725579619407654,
    "learning_rate": 0.001
  },
  {
    "episode": 4889,
    "reward": 86.042593,
    "length": 70,
    "time": 76304.460514,
    "actor_loss": -63.225372314453125,
    "critic_loss": 24.72686004638672,
    "ent_coef": 0.09222447872161865,
    "learning_rate": 0.001
  },
  {
    "episode": 4890,
    "reward": 87.973242,
    "length": 66,
    "time": 76316.161706,
    "actor_loss": -66.84058380126953,
    "critic_loss": 41.07666015625,
    "ent_coef": 0.09003797173500061,
    "learning_rate": 0.001
  },
  {
    "episode": 4891,
    "reward": 87.018685,
    "length": 69,
    "time": 76327.93625,
    "actor_loss": -56.88337707519531,
    "critic_loss": 6.968817710876465,
    "ent_coef": 0.08774147182703018,
    "learning_rate": 0.001
  },
  {
    "episode": 4892,
    "reward": 87.54939,
    "length": 68,
    "time": 76340.544828,
    "actor_loss": -58.274749755859375,
    "critic_loss": 25.211162567138672,
    "ent_coef": 0.08811044692993164,
    "learning_rate": 0.001
  },
  {
    "episode": 4893,
    "reward": 88.820399,
    "length": 65,
    "time": 76353.386752,
    "actor_loss": -58.1251220703125,
    "critic_loss": 38.58884048461914,
    "ent_coef": 0.08713549375534058,
    "learning_rate": 0.001
  },
  {
    "episode": 4894,
    "reward": 85.710956,
    "length": 72,
    "time": 76366.609546,
    "actor_loss": -59.291255950927734,
    "critic_loss": 3.4458112716674805,
    "ent_coef": 0.08496777713298798,
    "learning_rate": 0.001
  },
  {
    "episode": 4895,
    "reward": 86.581229,
    "length": 69,
    "time": 76380.8631,
    "actor_loss": -60.2281494140625,
    "critic_loss": 6.826757431030273,
    "ent_coef": 0.08499368280172348,
    "learning_rate": 0.001
  },
  {
    "episode": 4896,
    "reward": 88.642849,
    "length": 65,
    "time": 76392.208673,
    "actor_loss": -57.09304428100586,
    "critic_loss": 7.62253999710083,
    "ent_coef": 0.08847848325967789,
    "learning_rate": 0.001
  },
  {
    "episode": 4897,
    "reward": 84.215136,
    "length": 74,
    "time": 76407.067978,
    "actor_loss": -60.53581237792969,
    "critic_loss": 9.934497833251953,
    "ent_coef": 0.08570656925439835,
    "learning_rate": 0.001
  },
  {
    "episode": 4898,
    "reward": 88.928067,
    "length": 66,
    "time": 76418.37667,
    "actor_loss": -62.00444030761719,
    "critic_loss": 11.168375015258789,
    "ent_coef": 0.08778704702854156,
    "learning_rate": 0.001
  },
  {
    "episode": 4899,
    "reward": 89.471776,
    "length": 64,
    "time": 76429.722432,
    "actor_loss": -59.00856399536133,
    "critic_loss": 17.34862518310547,
    "ent_coef": 0.08848993480205536,
    "learning_rate": 0.001
  },
  {
    "episode": 4900,
    "reward": 90.130212,
    "length": 64,
    "time": 76442.604837,
    "actor_loss": -58.475624084472656,
    "critic_loss": 6.4938554763793945,
    "ent_coef": 0.09010449796915054,
    "learning_rate": 0.001
  },
  {
    "episode": 4901,
    "reward": 87.768376,
    "length": 67,
    "time": 76455.825479,
    "actor_loss": -63.834781646728516,
    "critic_loss": 59.17027282714844,
    "ent_coef": 0.09335826337337494,
    "learning_rate": 0.001
  },
  {
    "episode": 4902,
    "reward": 89.11162,
    "length": 65,
    "time": 76467.877845,
    "actor_loss": -57.19439697265625,
    "critic_loss": 5.741032600402832,
    "ent_coef": 0.09488974511623383,
    "learning_rate": 0.001
  },
  {
    "episode": 4903,
    "reward": 89.977039,
    "length": 66,
    "time": 76480.301603,
    "actor_loss": -56.01997756958008,
    "critic_loss": 29.038188934326172,
    "ent_coef": 0.09983764588832855,
    "learning_rate": 0.001
  },
  {
    "episode": 4904,
    "reward": 90.212086,
    "length": 64,
    "time": 76497.616623,
    "actor_loss": -60.40608215332031,
    "critic_loss": 29.539955139160156,
    "ent_coef": 0.10483080893754959,
    "learning_rate": 0.001
  },
  {
    "episode": 4905,
    "reward": 88.789947,
    "length": 66,
    "time": 76510.072126,
    "actor_loss": -62.84370803833008,
    "critic_loss": 74.53019714355469,
    "ent_coef": 0.10812605917453766,
    "learning_rate": 0.001
  },
  {
    "episode": 4906,
    "reward": 88.99887,
    "length": 66,
    "time": 76523.029923,
    "actor_loss": -59.268157958984375,
    "critic_loss": 5.631772994995117,
    "ent_coef": 0.11269352585077286,
    "learning_rate": 0.001
  },
  {
    "episode": 4907,
    "reward": 84.139292,
    "length": 74,
    "time": 76535.642926,
    "actor_loss": -63.4766845703125,
    "critic_loss": 12.9675874710083,
    "ent_coef": 0.10902425646781921,
    "learning_rate": 0.001
  },
  {
    "episode": 4908,
    "reward": 85.163834,
    "length": 72,
    "time": 76548.913946,
    "actor_loss": -61.25129699707031,
    "critic_loss": 17.03926658630371,
    "ent_coef": 0.10518524050712585,
    "learning_rate": 0.001
  },
  {
    "episode": 4909,
    "reward": 84.141721,
    "length": 81,
    "time": 76565.52103,
    "actor_loss": -69.89640808105469,
    "critic_loss": 4.104068279266357,
    "ent_coef": 0.10035158693790436,
    "learning_rate": 0.001
  },
  {
    "episode": 4910,
    "reward": 90.856623,
    "length": 62,
    "time": 76579.339471,
    "actor_loss": -55.04120635986328,
    "critic_loss": 35.57622528076172,
    "ent_coef": 0.102092444896698,
    "learning_rate": 0.001
  },
  {
    "episode": 4911,
    "reward": 87.641582,
    "length": 66,
    "time": 76591.938108,
    "actor_loss": -58.747596740722656,
    "critic_loss": 37.77840805053711,
    "ent_coef": 0.10029956698417664,
    "learning_rate": 0.001
  },
  {
    "episode": 4912,
    "reward": 86.92271,
    "length": 69,
    "time": 76603.49865,
    "actor_loss": -57.382320404052734,
    "critic_loss": 13.996166229248047,
    "ent_coef": 0.09842309355735779,
    "learning_rate": 0.001
  },
  {
    "episode": 4913,
    "reward": 90.523649,
    "length": 62,
    "time": 76615.171498,
    "actor_loss": -59.55561828613281,
    "critic_loss": 25.328989028930664,
    "ent_coef": 0.09520845860242844,
    "learning_rate": 0.001
  },
  {
    "episode": 4914,
    "reward": 88.16091,
    "length": 66,
    "time": 76628.181407,
    "actor_loss": -60.57196044921875,
    "critic_loss": 3.2397804260253906,
    "ent_coef": 0.093851238489151,
    "learning_rate": 0.001
  },
  {
    "episode": 4915,
    "reward": 89.953319,
    "length": 64,
    "time": 76641.38646,
    "actor_loss": -63.616539001464844,
    "critic_loss": 11.563308715820312,
    "ent_coef": 0.09476282447576523,
    "learning_rate": 0.001
  },
  {
    "episode": 4916,
    "reward": 89.488114,
    "length": 64,
    "time": 76654.213893,
    "actor_loss": -55.827484130859375,
    "critic_loss": 5.631834030151367,
    "ent_coef": 0.09769651293754578,
    "learning_rate": 0.001
  },
  {
    "episode": 4917,
    "reward": 89.600723,
    "length": 64,
    "time": 76665.321851,
    "actor_loss": -65.73946380615234,
    "critic_loss": 13.840415954589844,
    "ent_coef": 0.10256929695606232,
    "learning_rate": 0.001
  },
  {
    "episode": 4918,
    "reward": 88.059203,
    "length": 67,
    "time": 76676.659159,
    "actor_loss": -62.135597229003906,
    "critic_loss": 42.07887268066406,
    "ent_coef": 0.10122714936733246,
    "learning_rate": 0.001
  },
  {
    "episode": 4919,
    "reward": 88.195059,
    "length": 66,
    "time": 76688.140726,
    "actor_loss": -62.486637115478516,
    "critic_loss": 4.468792915344238,
    "ent_coef": 0.09969407320022583,
    "learning_rate": 0.001
  },
  {
    "episode": 4920,
    "reward": 90.090369,
    "length": 64,
    "time": 76700.223174,
    "actor_loss": -63.72007369995117,
    "critic_loss": 8.431873321533203,
    "ent_coef": 0.09930163621902466,
    "learning_rate": 0.001
  },
  {
    "episode": 4921,
    "reward": 86.654779,
    "length": 69,
    "time": 76713.025426,
    "actor_loss": -63.45744705200195,
    "critic_loss": 53.59706115722656,
    "ent_coef": 0.0993407592177391,
    "learning_rate": 0.001
  },
  {
    "episode": 4922,
    "reward": 87.389836,
    "length": 68,
    "time": 76725.888861,
    "actor_loss": -60.615966796875,
    "critic_loss": 505.7484436035156,
    "ent_coef": 0.09512115269899368,
    "learning_rate": 0.001
  },
  {
    "episode": 4923,
    "reward": 90.272764,
    "length": 64,
    "time": 76737.704099,
    "actor_loss": -59.459625244140625,
    "critic_loss": 7.665083885192871,
    "ent_coef": 0.09449709206819534,
    "learning_rate": 0.001
  },
  {
    "episode": 4924,
    "reward": 84.369116,
    "length": 73,
    "time": 76753.383068,
    "actor_loss": -60.973114013671875,
    "critic_loss": 61.51292419433594,
    "ent_coef": 0.08945222944021225,
    "learning_rate": 0.001
  },
  {
    "episode": 4925,
    "reward": 84.223775,
    "length": 74,
    "time": 76766.917537,
    "actor_loss": -64.68573760986328,
    "critic_loss": 18.156497955322266,
    "ent_coef": 0.08557785302400589,
    "learning_rate": 0.001
  },
  {
    "episode": 4926,
    "reward": 88.403529,
    "length": 66,
    "time": 76780.104128,
    "actor_loss": -62.48122787475586,
    "critic_loss": 5.161865234375,
    "ent_coef": 0.08947191387414932,
    "learning_rate": 0.001
  },
  {
    "episode": 4927,
    "reward": 86.786577,
    "length": 70,
    "time": 76793.057352,
    "actor_loss": -63.92280960083008,
    "critic_loss": 3.0958456993103027,
    "ent_coef": 0.09125159680843353,
    "learning_rate": 0.001
  },
  {
    "episode": 4928,
    "reward": 86.956909,
    "length": 69,
    "time": 76806.028443,
    "actor_loss": -67.12401580810547,
    "critic_loss": 20.123550415039062,
    "ent_coef": 0.09493253380060196,
    "learning_rate": 0.001
  },
  {
    "episode": 4929,
    "reward": 86.995924,
    "length": 70,
    "time": 76817.690832,
    "actor_loss": -57.95468521118164,
    "critic_loss": 64.63111877441406,
    "ent_coef": 0.09769724309444427,
    "learning_rate": 0.001
  },
  {
    "episode": 4930,
    "reward": 88.858713,
    "length": 64,
    "time": 76830.299919,
    "actor_loss": -56.42718505859375,
    "critic_loss": 12.387796401977539,
    "ent_coef": 0.09858479350805283,
    "learning_rate": 0.001
  },
  {
    "episode": 4931,
    "reward": 89.365705,
    "length": 64,
    "time": 76841.60476,
    "actor_loss": -60.51112365722656,
    "critic_loss": 33.017154693603516,
    "ent_coef": 0.10072919726371765,
    "learning_rate": 0.001
  },
  {
    "episode": 4932,
    "reward": 85.383662,
    "length": 71,
    "time": 76857.313409,
    "actor_loss": -55.161399841308594,
    "critic_loss": 144.06515502929688,
    "ent_coef": 0.09817712754011154,
    "learning_rate": 0.001
  },
  {
    "episode": 4933,
    "reward": 57.131991,
    "length": 130,
    "time": 76878.02499,
    "actor_loss": -56.628807067871094,
    "critic_loss": 11.491450309753418,
    "ent_coef": 0.09356513619422913,
    "learning_rate": 0.001
  },
  {
    "episode": 4934,
    "reward": 87.520444,
    "length": 66,
    "time": 76889.198667,
    "actor_loss": -61.0979118347168,
    "critic_loss": 4.299757957458496,
    "ent_coef": 0.09499914944171906,
    "learning_rate": 0.001
  },
  {
    "episode": 4935,
    "reward": 88.894348,
    "length": 66,
    "time": 76900.689394,
    "actor_loss": -57.81713104248047,
    "critic_loss": 15.379623413085938,
    "ent_coef": 0.09532368928194046,
    "learning_rate": 0.001
  },
  {
    "episode": 4936,
    "reward": 77.339421,
    "length": 84,
    "time": 76917.02978,
    "actor_loss": -56.336238861083984,
    "critic_loss": 22.390445709228516,
    "ent_coef": 0.09208989888429642,
    "learning_rate": 0.001
  },
  {
    "episode": 4937,
    "reward": 90.460601,
    "length": 63,
    "time": 76932.339573,
    "actor_loss": -60.2041130065918,
    "critic_loss": 4.867866516113281,
    "ent_coef": 0.09019207954406738,
    "learning_rate": 0.001
  },
  {
    "episode": 4938,
    "reward": 85.624811,
    "length": 71,
    "time": 76944.236835,
    "actor_loss": -61.213191986083984,
    "critic_loss": 7.570286273956299,
    "ent_coef": 0.0884072557091713,
    "learning_rate": 0.001
  },
  {
    "episode": 4939,
    "reward": 88.521767,
    "length": 66,
    "time": 76957.751686,
    "actor_loss": -62.152320861816406,
    "critic_loss": 23.508102416992188,
    "ent_coef": 0.0906495749950409,
    "learning_rate": 0.001
  },
  {
    "episode": 4940,
    "reward": 83.193076,
    "length": 76,
    "time": 76972.931991,
    "actor_loss": -60.77369689941406,
    "critic_loss": 6.45858907699585,
    "ent_coef": 0.08704998344182968,
    "learning_rate": 0.001
  },
  {
    "episode": 4941,
    "reward": 86.87012,
    "length": 68,
    "time": 76985.714333,
    "actor_loss": -57.12348556518555,
    "critic_loss": 25.840309143066406,
    "ent_coef": 0.0848962739109993,
    "learning_rate": 0.001
  },
  {
    "episode": 4942,
    "reward": 89.458902,
    "length": 65,
    "time": 76998.681079,
    "actor_loss": -59.976409912109375,
    "critic_loss": 6.388562202453613,
    "ent_coef": 0.08477841317653656,
    "learning_rate": 0.001
  },
  {
    "episode": 4943,
    "reward": 89.32905,
    "length": 65,
    "time": 77013.390725,
    "actor_loss": -59.145729064941406,
    "critic_loss": 31.942821502685547,
    "ent_coef": 0.08770231902599335,
    "learning_rate": 0.001
  },
  {
    "episode": 4944,
    "reward": 86.502335,
    "length": 70,
    "time": 77025.258398,
    "actor_loss": -55.81573486328125,
    "critic_loss": 75.84619140625,
    "ent_coef": 0.08834666758775711,
    "learning_rate": 0.001
  },
  {
    "episode": 4945,
    "reward": 89.358282,
    "length": 64,
    "time": 77037.212512,
    "actor_loss": -59.25562286376953,
    "critic_loss": 8.307769775390625,
    "ent_coef": 0.0928386002779007,
    "learning_rate": 0.001
  },
  {
    "episode": 4946,
    "reward": 89.453029,
    "length": 64,
    "time": 77048.350664,
    "actor_loss": -60.35499954223633,
    "critic_loss": 10.846400260925293,
    "ent_coef": 0.09526166319847107,
    "learning_rate": 0.001
  },
  {
    "episode": 4947,
    "reward": 89.3463,
    "length": 63,
    "time": 77059.506944,
    "actor_loss": -61.5076904296875,
    "critic_loss": 13.168225288391113,
    "ent_coef": 0.10094425082206726,
    "learning_rate": 0.001
  },
  {
    "episode": 4948,
    "reward": 89.158747,
    "length": 64,
    "time": 77070.41138,
    "actor_loss": -60.875511169433594,
    "critic_loss": 6.021390438079834,
    "ent_coef": 0.10366810113191605,
    "learning_rate": 0.001
  },
  {
    "episode": 4949,
    "reward": 90.185746,
    "length": 63,
    "time": 77085.394522,
    "actor_loss": -65.48114013671875,
    "critic_loss": 9.13385009765625,
    "ent_coef": 0.10367749631404877,
    "learning_rate": 0.001
  },
  {
    "episode": 4950,
    "reward": 88.008271,
    "length": 66,
    "time": 77101.740014,
    "actor_loss": -58.65934753417969,
    "critic_loss": 8.06025505065918,
    "ent_coef": 0.10339710116386414,
    "learning_rate": 0.001
  },
  {
    "episode": 4951,
    "reward": 87.211812,
    "length": 67,
    "time": 77115.936366,
    "actor_loss": -66.66168975830078,
    "critic_loss": 63.85540771484375,
    "ent_coef": 0.1007831022143364,
    "learning_rate": 0.001
  },
  {
    "episode": 4952,
    "reward": 86.046251,
    "length": 70,
    "time": 77128.796537,
    "actor_loss": -58.54521179199219,
    "critic_loss": 7.322237968444824,
    "ent_coef": 0.09873741120100021,
    "learning_rate": 0.001
  },
  {
    "episode": 4953,
    "reward": 86.043852,
    "length": 70,
    "time": 77141.429282,
    "actor_loss": -61.73300552368164,
    "critic_loss": 14.700238227844238,
    "ent_coef": 0.09780873358249664,
    "learning_rate": 0.001
  },
  {
    "episode": 4954,
    "reward": 88.27576,
    "length": 66,
    "time": 77154.681938,
    "actor_loss": -64.04627990722656,
    "critic_loss": 36.05107498168945,
    "ent_coef": 0.09621914476156235,
    "learning_rate": 0.001
  },
  {
    "episode": 4955,
    "reward": 89.483861,
    "length": 64,
    "time": 77168.641861,
    "actor_loss": -65.2452621459961,
    "critic_loss": 26.643918991088867,
    "ent_coef": 0.09851858019828796,
    "learning_rate": 0.001
  },
  {
    "episode": 4956,
    "reward": 87.452539,
    "length": 67,
    "time": 77180.20682,
    "actor_loss": -64.2600326538086,
    "critic_loss": 18.90618896484375,
    "ent_coef": 0.095798559486866,
    "learning_rate": 0.001
  },
  {
    "episode": 4957,
    "reward": 89.320155,
    "length": 64,
    "time": 77191.187249,
    "actor_loss": -66.4818115234375,
    "critic_loss": 4.080899238586426,
    "ent_coef": 0.09666356444358826,
    "learning_rate": 0.001
  },
  {
    "episode": 4958,
    "reward": 88.025179,
    "length": 66,
    "time": 77203.99062,
    "actor_loss": -56.12049102783203,
    "critic_loss": 4.797208309173584,
    "ent_coef": 0.09609697759151459,
    "learning_rate": 0.001
  },
  {
    "episode": 4959,
    "reward": 89.295901,
    "length": 64,
    "time": 77217.37554,
    "actor_loss": -58.865440368652344,
    "critic_loss": 133.84036254882812,
    "ent_coef": 0.09517979621887207,
    "learning_rate": 0.001
  },
  {
    "episode": 4960,
    "reward": 89.419989,
    "length": 64,
    "time": 77228.401649,
    "actor_loss": -61.24779510498047,
    "critic_loss": 12.420550346374512,
    "ent_coef": 0.09725463390350342,
    "learning_rate": 0.001
  },
  {
    "episode": 4961,
    "reward": 90.450481,
    "length": 64,
    "time": 77240.247575,
    "actor_loss": -63.74915313720703,
    "critic_loss": 5.089118003845215,
    "ent_coef": 0.09938913583755493,
    "learning_rate": 0.001
  },
  {
    "episode": 4962,
    "reward": 88.201594,
    "length": 68,
    "time": 77252.931558,
    "actor_loss": -60.73606872558594,
    "critic_loss": 10.920093536376953,
    "ent_coef": 0.09740468114614487,
    "learning_rate": 0.001
  },
  {
    "episode": 4963,
    "reward": 88.206663,
    "length": 67,
    "time": 77266.92475,
    "actor_loss": -56.45295333862305,
    "critic_loss": 191.58859252929688,
    "ent_coef": 0.09492162615060806,
    "learning_rate": 0.001
  },
  {
    "episode": 4964,
    "reward": 89.733414,
    "length": 63,
    "time": 77277.781975,
    "actor_loss": -61.87055969238281,
    "critic_loss": 8.682491302490234,
    "ent_coef": 0.0967370793223381,
    "learning_rate": 0.001
  },
  {
    "episode": 4965,
    "reward": 84.307977,
    "length": 73,
    "time": 77289.798733,
    "actor_loss": -61.6187858581543,
    "critic_loss": 12.218923568725586,
    "ent_coef": 0.09545829892158508,
    "learning_rate": 0.001
  },
  {
    "episode": 4966,
    "reward": 86.212069,
    "length": 71,
    "time": 77303.677125,
    "actor_loss": -60.59767150878906,
    "critic_loss": 3.6729156970977783,
    "ent_coef": 0.09624908119440079,
    "learning_rate": 0.001
  },
  {
    "episode": 4967,
    "reward": 87.815278,
    "length": 68,
    "time": 77316.307903,
    "actor_loss": -55.8985595703125,
    "critic_loss": 9.98492431640625,
    "ent_coef": 0.09619338810443878,
    "learning_rate": 0.001
  },
  {
    "episode": 4968,
    "reward": 87.768587,
    "length": 70,
    "time": 77328.454188,
    "actor_loss": -61.4111328125,
    "critic_loss": 16.06223487854004,
    "ent_coef": 0.09766170382499695,
    "learning_rate": 0.001
  },
  {
    "episode": 4969,
    "reward": 89.784308,
    "length": 63,
    "time": 77339.744106,
    "actor_loss": -61.165626525878906,
    "critic_loss": 9.62683391571045,
    "ent_coef": 0.09858051687479019,
    "learning_rate": 0.001
  },
  {
    "episode": 4970,
    "reward": 89.064675,
    "length": 66,
    "time": 77354.829019,
    "actor_loss": -61.49290466308594,
    "critic_loss": 4.683589935302734,
    "ent_coef": 0.09992870688438416,
    "learning_rate": 0.001
  },
  {
    "episode": 4971,
    "reward": 86.630463,
    "length": 69,
    "time": 77367.60896,
    "actor_loss": -60.57633972167969,
    "critic_loss": 59.624263763427734,
    "ent_coef": 0.0973345935344696,
    "learning_rate": 0.001
  },
  {
    "episode": 4972,
    "reward": 88.88703,
    "length": 66,
    "time": 77379.729926,
    "actor_loss": -53.45096206665039,
    "critic_loss": 24.962383270263672,
    "ent_coef": 0.10241840034723282,
    "learning_rate": 0.001
  },
  {
    "episode": 4973,
    "reward": 89.009822,
    "length": 65,
    "time": 77390.942379,
    "actor_loss": -62.03157043457031,
    "critic_loss": 21.666500091552734,
    "ent_coef": 0.10298667848110199,
    "learning_rate": 0.001
  },
  {
    "episode": 4974,
    "reward": 88.430754,
    "length": 68,
    "time": 77403.447351,
    "actor_loss": -54.765724182128906,
    "critic_loss": 26.402313232421875,
    "ent_coef": 0.10092780739068985,
    "learning_rate": 0.001
  },
  {
    "episode": 4975,
    "reward": 87.469989,
    "length": 68,
    "time": 77419.018137,
    "actor_loss": -64.06195831298828,
    "critic_loss": 4.808442115783691,
    "ent_coef": 0.10124550759792328,
    "learning_rate": 0.001
  },
  {
    "episode": 4976,
    "reward": 87.063283,
    "length": 68,
    "time": 77432.495429,
    "actor_loss": -63.550750732421875,
    "critic_loss": 37.08170700073242,
    "ent_coef": 0.09810524433851242,
    "learning_rate": 0.001
  },
  {
    "episode": 4977,
    "reward": 81.325827,
    "length": 81,
    "time": 77445.54235,
    "actor_loss": -55.824867248535156,
    "critic_loss": 10.552682876586914,
    "ent_coef": 0.0982043594121933,
    "learning_rate": 0.001
  },
  {
    "episode": 4978,
    "reward": 84.807128,
    "length": 72,
    "time": 77458.567349,
    "actor_loss": -56.177703857421875,
    "critic_loss": 6.158550262451172,
    "ent_coef": 0.0963774248957634,
    "learning_rate": 0.001
  },
  {
    "episode": 4979,
    "reward": 87.293053,
    "length": 69,
    "time": 77473.186615,
    "actor_loss": -52.927574157714844,
    "critic_loss": 28.275936126708984,
    "ent_coef": 0.09204652905464172,
    "learning_rate": 0.001
  },
  {
    "episode": 4980,
    "reward": 88.26943,
    "length": 69,
    "time": 77487.102278,
    "actor_loss": -60.48303985595703,
    "critic_loss": 6.040127754211426,
    "ent_coef": 0.09582416713237762,
    "learning_rate": 0.001
  },
  {
    "episode": 4981,
    "reward": 90.077458,
    "length": 63,
    "time": 77499.356106,
    "actor_loss": -65.66557312011719,
    "critic_loss": 49.093929290771484,
    "ent_coef": 0.09894070029258728,
    "learning_rate": 0.001
  },
  {
    "episode": 4982,
    "reward": 86.417239,
    "length": 69,
    "time": 77515.041218,
    "actor_loss": -56.95915603637695,
    "critic_loss": 8.764730453491211,
    "ent_coef": 0.09986735880374908,
    "learning_rate": 0.001
  },
  {
    "episode": 4983,
    "reward": 91.401328,
    "length": 60,
    "time": 77526.517087,
    "actor_loss": -56.351463317871094,
    "critic_loss": 8.145578384399414,
    "ent_coef": 0.10160350054502487,
    "learning_rate": 0.001
  },
  {
    "episode": 4984,
    "reward": 89.406127,
    "length": 64,
    "time": 77537.77638,
    "actor_loss": -61.90193176269531,
    "critic_loss": 4.506869792938232,
    "ent_coef": 0.10179470479488373,
    "learning_rate": 0.001
  },
  {
    "episode": 4985,
    "reward": 87.249493,
    "length": 80,
    "time": 77550.860744,
    "actor_loss": -56.69239807128906,
    "critic_loss": 12.545429229736328,
    "ent_coef": 0.10681260377168655,
    "learning_rate": 0.001
  },
  {
    "episode": 4986,
    "reward": 89.201285,
    "length": 64,
    "time": 77562.347633,
    "actor_loss": -57.26592254638672,
    "critic_loss": 6.716293811798096,
    "ent_coef": 0.10739217698574066,
    "learning_rate": 0.001
  },
  {
    "episode": 4987,
    "reward": 88.898381,
    "length": 65,
    "time": 77574.371985,
    "actor_loss": -67.34371948242188,
    "critic_loss": 17.75462532043457,
    "ent_coef": 0.10577037930488586,
    "learning_rate": 0.001
  },
  {
    "episode": 4988,
    "reward": 88.604998,
    "length": 66,
    "time": 77585.647387,
    "actor_loss": -55.86758041381836,
    "critic_loss": 494.3721008300781,
    "ent_coef": 0.10194601863622665,
    "learning_rate": 0.001
  },
  {
    "episode": 4989,
    "reward": 88.616084,
    "length": 65,
    "time": 77597.252078,
    "actor_loss": -55.64165496826172,
    "critic_loss": 11.722146987915039,
    "ent_coef": 0.10181069374084473,
    "learning_rate": 0.001
  },
  {
    "episode": 4990,
    "reward": 89.333831,
    "length": 64,
    "time": 77610.305879,
    "actor_loss": -60.07379150390625,
    "critic_loss": 53.98771667480469,
    "ent_coef": 0.10079367458820343,
    "learning_rate": 0.001
  },
  {
    "episode": 4991,
    "reward": 87.035959,
    "length": 68,
    "time": 77622.965966,
    "actor_loss": -59.51421356201172,
    "critic_loss": 9.07850456237793,
    "ent_coef": 0.1020248681306839,
    "learning_rate": 0.001
  },
  {
    "episode": 4992,
    "reward": 87.215746,
    "length": 69,
    "time": 77634.79165,
    "actor_loss": -59.47089385986328,
    "critic_loss": 4.485630989074707,
    "ent_coef": 0.10057944804430008,
    "learning_rate": 0.001
  },
  {
    "episode": 4993,
    "reward": 87.49498,
    "length": 68,
    "time": 77646.739166,
    "actor_loss": -63.18357849121094,
    "critic_loss": 26.837236404418945,
    "ent_coef": 0.09861969947814941,
    "learning_rate": 0.001
  },
  {
    "episode": 4994,
    "reward": 89.277104,
    "length": 65,
    "time": 77658.848256,
    "actor_loss": -63.79029846191406,
    "critic_loss": 12.335522651672363,
    "ent_coef": 0.09700733423233032,
    "learning_rate": 0.001
  },
  {
    "episode": 4995,
    "reward": 90.387585,
    "length": 65,
    "time": 77671.729965,
    "actor_loss": -65.04476928710938,
    "critic_loss": 22.116939544677734,
    "ent_coef": 0.09637193381786346,
    "learning_rate": 0.001
  },
  {
    "episode": 4996,
    "reward": 86.989123,
    "length": 70,
    "time": 77686.205098,
    "actor_loss": -59.992549896240234,
    "critic_loss": 3.9766385555267334,
    "ent_coef": 0.09143076092004776,
    "learning_rate": 0.001
  },
  {
    "episode": 4997,
    "reward": 85.844979,
    "length": 71,
    "time": 77698.336657,
    "actor_loss": -63.84807586669922,
    "critic_loss": 24.753326416015625,
    "ent_coef": 0.09335067123174667,
    "learning_rate": 0.001
  },
  {
    "episode": 4998,
    "reward": 89.247839,
    "length": 64,
    "time": 77710.205519,
    "actor_loss": -61.104209899902344,
    "critic_loss": 9.853456497192383,
    "ent_coef": 0.09506381303071976,
    "learning_rate": 0.001
  },
  {
    "episode": 4999,
    "reward": 91.502112,
    "length": 61,
    "time": 77722.39577,
    "actor_loss": -60.50817108154297,
    "critic_loss": 39.06315994262695,
    "ent_coef": 0.09662392735481262,
    "learning_rate": 0.001
  },
  {
    "episode": 5000,
    "reward": 85.389906,
    "length": 72,
    "time": 77736.398389,
    "actor_loss": -61.00865173339844,
    "critic_loss": 8.152647018432617,
    "ent_coef": 0.09843886643648148,
    "learning_rate": 0.001
  },
  {
    "episode": 5001,
    "reward": 88.343002,
    "length": 66,
    "time": 77750.496526,
    "actor_loss": -60.22157669067383,
    "critic_loss": 14.971647262573242,
    "ent_coef": 0.10363145172595978,
    "learning_rate": 0.001
  },
  {
    "episode": 5002,
    "reward": 89.836213,
    "length": 64,
    "time": 77763.336991,
    "actor_loss": -60.041099548339844,
    "critic_loss": 10.942806243896484,
    "ent_coef": 0.10298077762126923,
    "learning_rate": 0.001
  },
  {
    "episode": 5003,
    "reward": 88.730377,
    "length": 65,
    "time": 77778.659055,
    "actor_loss": -63.603233337402344,
    "critic_loss": 11.870285034179688,
    "ent_coef": 0.1030307337641716,
    "learning_rate": 0.001
  },
  {
    "episode": 5004,
    "reward": 86.943299,
    "length": 68,
    "time": 77793.270141,
    "actor_loss": -62.53417205810547,
    "critic_loss": 36.163299560546875,
    "ent_coef": 0.10165498405694962,
    "learning_rate": 0.001
  },
  {
    "episode": 5005,
    "reward": 88.912011,
    "length": 65,
    "time": 77808.021091,
    "actor_loss": -63.78308868408203,
    "critic_loss": 38.5410270690918,
    "ent_coef": 0.10004940629005432,
    "learning_rate": 0.001
  },
  {
    "episode": 5006,
    "reward": 88.848416,
    "length": 67,
    "time": 77820.94956,
    "actor_loss": -59.70664978027344,
    "critic_loss": 24.845897674560547,
    "ent_coef": 0.099188894033432,
    "learning_rate": 0.001
  },
  {
    "episode": 5007,
    "reward": 89.048317,
    "length": 65,
    "time": 77832.38255,
    "actor_loss": -62.41779327392578,
    "critic_loss": 3.1946496963500977,
    "ent_coef": 0.0971873477101326,
    "learning_rate": 0.001
  },
  {
    "episode": 5008,
    "reward": 87.646532,
    "length": 67,
    "time": 77847.23682,
    "actor_loss": -57.77394104003906,
    "critic_loss": 64.20592498779297,
    "ent_coef": 0.09179843962192535,
    "learning_rate": 0.001
  },
  {
    "episode": 5009,
    "reward": 88.941369,
    "length": 65,
    "time": 77861.471925,
    "actor_loss": -59.364871978759766,
    "critic_loss": 10.560266494750977,
    "ent_coef": 0.09470764547586441,
    "learning_rate": 0.001
  },
  {
    "episode": 5010,
    "reward": 89.12802,
    "length": 64,
    "time": 77873.397748,
    "actor_loss": -61.012542724609375,
    "critic_loss": 7.647124767303467,
    "ent_coef": 0.09748838096857071,
    "learning_rate": 0.001
  },
  {
    "episode": 5011,
    "reward": 90.289792,
    "length": 62,
    "time": 77886.375719,
    "actor_loss": -61.371421813964844,
    "critic_loss": 19.694889068603516,
    "ent_coef": 0.09767159819602966,
    "learning_rate": 0.001
  },
  {
    "episode": 5012,
    "reward": 87.891167,
    "length": 67,
    "time": 77901.917162,
    "actor_loss": -54.020713806152344,
    "critic_loss": 17.36728286743164,
    "ent_coef": 0.09579093009233475,
    "learning_rate": 0.001
  },
  {
    "episode": 5013,
    "reward": 86.616809,
    "length": 69,
    "time": 77915.633416,
    "actor_loss": -58.46332550048828,
    "critic_loss": 18.527801513671875,
    "ent_coef": 0.09400881081819534,
    "learning_rate": 0.001
  },
  {
    "episode": 5014,
    "reward": 88.760019,
    "length": 65,
    "time": 77926.584916,
    "actor_loss": -67.0164566040039,
    "critic_loss": 3.442586898803711,
    "ent_coef": 0.09897118806838989,
    "learning_rate": 0.001
  },
  {
    "episode": 5015,
    "reward": 88.741471,
    "length": 65,
    "time": 77940.52056,
    "actor_loss": -59.32801818847656,
    "critic_loss": 32.98200225830078,
    "ent_coef": 0.10045399516820908,
    "learning_rate": 0.001
  },
  {
    "episode": 5016,
    "reward": 89.149059,
    "length": 66,
    "time": 77954.660619,
    "actor_loss": -62.97843551635742,
    "critic_loss": 14.715253829956055,
    "ent_coef": 0.09873691201210022,
    "learning_rate": 0.001
  },
  {
    "episode": 5017,
    "reward": 87.605187,
    "length": 67,
    "time": 77966.129885,
    "actor_loss": -60.10698699951172,
    "critic_loss": 6.0332841873168945,
    "ent_coef": 0.09656815230846405,
    "learning_rate": 0.001
  },
  {
    "episode": 5018,
    "reward": 89.841182,
    "length": 63,
    "time": 77977.050817,
    "actor_loss": -62.66644287109375,
    "critic_loss": 15.054079055786133,
    "ent_coef": 0.10038509219884872,
    "learning_rate": 0.001
  },
  {
    "episode": 5019,
    "reward": 88.622622,
    "length": 66,
    "time": 77989.28169,
    "actor_loss": -57.14798355102539,
    "critic_loss": 4.302629470825195,
    "ent_coef": 0.09936866164207458,
    "learning_rate": 0.001
  },
  {
    "episode": 5020,
    "reward": 88.768546,
    "length": 66,
    "time": 78003.539395,
    "actor_loss": -58.41691207885742,
    "critic_loss": 106.01657104492188,
    "ent_coef": 0.09968867897987366,
    "learning_rate": 0.001
  },
  {
    "episode": 5021,
    "reward": 88.722465,
    "length": 66,
    "time": 78015.906273,
    "actor_loss": -56.73225784301758,
    "critic_loss": 76.87982177734375,
    "ent_coef": 0.10257988423109055,
    "learning_rate": 0.001
  },
  {
    "episode": 5022,
    "reward": 88.773569,
    "length": 65,
    "time": 78028.234263,
    "actor_loss": -61.786502838134766,
    "critic_loss": 14.75936222076416,
    "ent_coef": 0.10533079504966736,
    "learning_rate": 0.001
  },
  {
    "episode": 5023,
    "reward": 90.578198,
    "length": 62,
    "time": 78038.849037,
    "actor_loss": -61.38566589355469,
    "critic_loss": 128.5091552734375,
    "ent_coef": 0.10439960658550262,
    "learning_rate": 0.001
  },
  {
    "episode": 5024,
    "reward": 81.891787,
    "length": 80,
    "time": 78053.728264,
    "actor_loss": -61.45520782470703,
    "critic_loss": 11.556350708007812,
    "ent_coef": 0.09485871344804764,
    "learning_rate": 0.001
  },
  {
    "episode": 5025,
    "reward": 88.042094,
    "length": 70,
    "time": 78065.80549,
    "actor_loss": -65.39407348632812,
    "critic_loss": 8.84719181060791,
    "ent_coef": 0.09136258065700531,
    "learning_rate": 0.001
  },
  {
    "episode": 5026,
    "reward": 85.36915,
    "length": 71,
    "time": 78078.018331,
    "actor_loss": -59.933258056640625,
    "critic_loss": 6.203315734863281,
    "ent_coef": 0.08838605135679245,
    "learning_rate": 0.001
  },
  {
    "episode": 5027,
    "reward": 87.654238,
    "length": 67,
    "time": 78093.634728,
    "actor_loss": -61.13471984863281,
    "critic_loss": 8.45842170715332,
    "ent_coef": 0.08469778299331665,
    "learning_rate": 0.001
  },
  {
    "episode": 5028,
    "reward": 85.75558,
    "length": 74,
    "time": 78106.273673,
    "actor_loss": -56.09557342529297,
    "critic_loss": 10.921913146972656,
    "ent_coef": 0.08698701858520508,
    "learning_rate": 0.001
  },
  {
    "episode": 5029,
    "reward": 88.725574,
    "length": 66,
    "time": 78117.48595,
    "actor_loss": -63.398414611816406,
    "critic_loss": 9.734100341796875,
    "ent_coef": 0.08648251742124557,
    "learning_rate": 0.001
  },
  {
    "episode": 5030,
    "reward": 85.904766,
    "length": 69,
    "time": 78130.037654,
    "actor_loss": -54.85033416748047,
    "critic_loss": 58.09233093261719,
    "ent_coef": 0.08533898741006851,
    "learning_rate": 0.001
  },
  {
    "episode": 5031,
    "reward": 88.540746,
    "length": 66,
    "time": 78141.491676,
    "actor_loss": -60.656612396240234,
    "critic_loss": 8.555015563964844,
    "ent_coef": 0.08258990198373795,
    "learning_rate": 0.001
  },
  {
    "episode": 5032,
    "reward": 87.850488,
    "length": 68,
    "time": 78153.068375,
    "actor_loss": -61.504486083984375,
    "critic_loss": 7.6007280349731445,
    "ent_coef": 0.08473441749811172,
    "learning_rate": 0.001
  },
  {
    "episode": 5033,
    "reward": 79.349451,
    "length": 87,
    "time": 78168.264877,
    "actor_loss": -65.46505737304688,
    "critic_loss": 3.340067148208618,
    "ent_coef": 0.08368967473506927,
    "learning_rate": 0.001
  },
  {
    "episode": 5034,
    "reward": 89.665834,
    "length": 63,
    "time": 78180.371196,
    "actor_loss": -55.797035217285156,
    "critic_loss": 37.362457275390625,
    "ent_coef": 0.08731053024530411,
    "learning_rate": 0.001
  },
  {
    "episode": 5035,
    "reward": 86.27309,
    "length": 69,
    "time": 78192.120596,
    "actor_loss": -59.121376037597656,
    "critic_loss": 3.8988542556762695,
    "ent_coef": 0.08763610571622849,
    "learning_rate": 0.001
  },
  {
    "episode": 5036,
    "reward": 90.130708,
    "length": 63,
    "time": 78207.237458,
    "actor_loss": -65.53223419189453,
    "critic_loss": 19.820377349853516,
    "ent_coef": 0.08682707697153091,
    "learning_rate": 0.001
  },
  {
    "episode": 5037,
    "reward": 87.015027,
    "length": 70,
    "time": 78221.06577,
    "actor_loss": -63.27765655517578,
    "critic_loss": 19.755022048950195,
    "ent_coef": 0.0883760005235672,
    "learning_rate": 0.001
  },
  {
    "episode": 5038,
    "reward": 90.158369,
    "length": 62,
    "time": 78231.952577,
    "actor_loss": -65.46693420410156,
    "critic_loss": 25.281471252441406,
    "ent_coef": 0.09055636823177338,
    "learning_rate": 0.001
  },
  {
    "episode": 5039,
    "reward": 89.15046,
    "length": 64,
    "time": 78245.083406,
    "actor_loss": -58.59354782104492,
    "critic_loss": 19.75438690185547,
    "ent_coef": 0.09486882388591766,
    "learning_rate": 0.001
  },
  {
    "episode": 5040,
    "reward": 88.963321,
    "length": 67,
    "time": 78257.688774,
    "actor_loss": -59.70117950439453,
    "critic_loss": 27.814699172973633,
    "ent_coef": 0.09207519143819809,
    "learning_rate": 0.001
  },
  {
    "episode": 5041,
    "reward": 88.734972,
    "length": 65,
    "time": 78270.665599,
    "actor_loss": -60.70060348510742,
    "critic_loss": 5.241734504699707,
    "ent_coef": 0.09136193990707397,
    "learning_rate": 0.001
  },
  {
    "episode": 5042,
    "reward": 90.627821,
    "length": 63,
    "time": 78282.322922,
    "actor_loss": -56.77940368652344,
    "critic_loss": 74.9359130859375,
    "ent_coef": 0.0942518413066864,
    "learning_rate": 0.001
  },
  {
    "episode": 5043,
    "reward": 87.883419,
    "length": 68,
    "time": 78298.027334,
    "actor_loss": -63.77324676513672,
    "critic_loss": 33.22365188598633,
    "ent_coef": 0.09390003234148026,
    "learning_rate": 0.001
  },
  {
    "episode": 5044,
    "reward": 78.390042,
    "length": 91,
    "time": 78312.357949,
    "actor_loss": -64.04765319824219,
    "critic_loss": 8.14255428314209,
    "ent_coef": 0.08911661803722382,
    "learning_rate": 0.001
  },
  {
    "episode": 5045,
    "reward": 87.448484,
    "length": 67,
    "time": 78326.187926,
    "actor_loss": -60.398193359375,
    "critic_loss": 30.011442184448242,
    "ent_coef": 0.08604540675878525,
    "learning_rate": 0.001
  },
  {
    "episode": 5046,
    "reward": 89.361522,
    "length": 64,
    "time": 78337.308272,
    "actor_loss": -62.97760772705078,
    "critic_loss": 59.38807678222656,
    "ent_coef": 0.08603417873382568,
    "learning_rate": 0.001
  },
  {
    "episode": 5047,
    "reward": 90.70289,
    "length": 63,
    "time": 78350.573067,
    "actor_loss": -63.6532096862793,
    "critic_loss": 31.932329177856445,
    "ent_coef": 0.08887691050767899,
    "learning_rate": 0.001
  },
  {
    "episode": 5048,
    "reward": 91.044188,
    "length": 62,
    "time": 78363.244468,
    "actor_loss": -63.29704284667969,
    "critic_loss": 14.898138046264648,
    "ent_coef": 0.0911572054028511,
    "learning_rate": 0.001
  },
  {
    "episode": 5049,
    "reward": 88.701282,
    "length": 66,
    "time": 78378.699105,
    "actor_loss": -64.49588012695312,
    "critic_loss": 48.49346160888672,
    "ent_coef": 0.0943816602230072,
    "learning_rate": 0.001
  },
  {
    "episode": 5050,
    "reward": 88.338509,
    "length": 69,
    "time": 78392.289632,
    "actor_loss": -58.828773498535156,
    "critic_loss": 597.637451171875,
    "ent_coef": 0.09806640446186066,
    "learning_rate": 0.001
  },
  {
    "episode": 5051,
    "reward": 88.600107,
    "length": 64,
    "time": 78405.300324,
    "actor_loss": -56.78517150878906,
    "critic_loss": 9.071083068847656,
    "ent_coef": 0.10392799973487854,
    "learning_rate": 0.001
  },
  {
    "episode": 5052,
    "reward": 88.653223,
    "length": 66,
    "time": 78416.517556,
    "actor_loss": -61.48052215576172,
    "critic_loss": 11.199379920959473,
    "ent_coef": 0.10623892396688461,
    "learning_rate": 0.001
  },
  {
    "episode": 5053,
    "reward": 89.319995,
    "length": 63,
    "time": 78428.673972,
    "actor_loss": -59.13633728027344,
    "critic_loss": 16.48967170715332,
    "ent_coef": 0.10550262778997421,
    "learning_rate": 0.001
  },
  {
    "episode": 5054,
    "reward": 86.542534,
    "length": 70,
    "time": 78440.555398,
    "actor_loss": -65.49125671386719,
    "critic_loss": 22.720661163330078,
    "ent_coef": 0.10031776875257492,
    "learning_rate": 0.001
  },
  {
    "episode": 5055,
    "reward": 87.484722,
    "length": 68,
    "time": 78452.449939,
    "actor_loss": -64.98567199707031,
    "critic_loss": 4.272217750549316,
    "ent_coef": 0.09663975238800049,
    "learning_rate": 0.001
  },
  {
    "episode": 5056,
    "reward": 82.231853,
    "length": 77,
    "time": 78466.425991,
    "actor_loss": -62.65609359741211,
    "critic_loss": 21.19047737121582,
    "ent_coef": 0.09271138906478882,
    "learning_rate": 0.001
  },
  {
    "episode": 5057,
    "reward": 86.745639,
    "length": 68,
    "time": 78477.855326,
    "actor_loss": -57.53804016113281,
    "critic_loss": 38.304019927978516,
    "ent_coef": 0.09554880857467651,
    "learning_rate": 0.001
  },
  {
    "episode": 5058,
    "reward": 90.357697,
    "length": 63,
    "time": 78490.680703,
    "actor_loss": -56.85625457763672,
    "critic_loss": 14.884923934936523,
    "ent_coef": 0.1015496551990509,
    "learning_rate": 0.001
  },
  {
    "episode": 5059,
    "reward": 88.755145,
    "length": 65,
    "time": 78503.097174,
    "actor_loss": -62.789066314697266,
    "critic_loss": 44.606895446777344,
    "ent_coef": 0.10360689461231232,
    "learning_rate": 0.001
  },
  {
    "episode": 5060,
    "reward": 86.845478,
    "length": 69,
    "time": 78516.258469,
    "actor_loss": -60.69062042236328,
    "critic_loss": 24.399288177490234,
    "ent_coef": 0.10053084045648575,
    "learning_rate": 0.001
  },
  {
    "episode": 5061,
    "reward": 90.680311,
    "length": 62,
    "time": 78527.40829,
    "actor_loss": -56.57759094238281,
    "critic_loss": 49.878150939941406,
    "ent_coef": 0.10175253450870514,
    "learning_rate": 0.001
  },
  {
    "episode": 5062,
    "reward": 88.692677,
    "length": 64,
    "time": 78540.462081,
    "actor_loss": -60.647911071777344,
    "critic_loss": 4.847905158996582,
    "ent_coef": 0.10246065258979797,
    "learning_rate": 0.001
  },
  {
    "episode": 5063,
    "reward": 88.258891,
    "length": 67,
    "time": 78552.994318,
    "actor_loss": -62.40760040283203,
    "critic_loss": 17.797250747680664,
    "ent_coef": 0.09983226656913757,
    "learning_rate": 0.001
  },
  {
    "episode": 5064,
    "reward": 79.23048,
    "length": 82,
    "time": 78566.732485,
    "actor_loss": -58.23773193359375,
    "critic_loss": 21.3297119140625,
    "ent_coef": 0.09327289462089539,
    "learning_rate": 0.001
  },
  {
    "episode": 5065,
    "reward": 91.269429,
    "length": 61,
    "time": 78581.226915,
    "actor_loss": -58.80042266845703,
    "critic_loss": 72.10382843017578,
    "ent_coef": 0.09435304254293442,
    "learning_rate": 0.001
  },
  {
    "episode": 5066,
    "reward": 85.836934,
    "length": 70,
    "time": 78594.991294,
    "actor_loss": -60.791141510009766,
    "critic_loss": 8.740317344665527,
    "ent_coef": 0.09399706870317459,
    "learning_rate": 0.001
  },
  {
    "episode": 5067,
    "reward": 86.576278,
    "length": 69,
    "time": 78606.556026,
    "actor_loss": -59.138572692871094,
    "critic_loss": 13.560752868652344,
    "ent_coef": 0.09236747026443481,
    "learning_rate": 0.001
  },
  {
    "episode": 5068,
    "reward": 70.334447,
    "length": 96,
    "time": 78621.704529,
    "actor_loss": -62.700645446777344,
    "critic_loss": 245.72561645507812,
    "ent_coef": 0.08371137827634811,
    "learning_rate": 0.001
  },
  {
    "episode": 5069,
    "reward": 87.973189,
    "length": 67,
    "time": 78634.12902,
    "actor_loss": -64.66536712646484,
    "critic_loss": 11.699406623840332,
    "ent_coef": 0.08240542560815811,
    "learning_rate": 0.001
  },
  {
    "episode": 5070,
    "reward": 88.789753,
    "length": 64,
    "time": 78648.550142,
    "actor_loss": -62.571929931640625,
    "critic_loss": 14.493016242980957,
    "ent_coef": 0.08189557492733002,
    "learning_rate": 0.001
  },
  {
    "episode": 5071,
    "reward": 89.07118,
    "length": 65,
    "time": 78660.754461,
    "actor_loss": -65.55636596679688,
    "critic_loss": 62.66670227050781,
    "ent_coef": 0.08123058080673218,
    "learning_rate": 0.001
  },
  {
    "episode": 5072,
    "reward": 87.052458,
    "length": 69,
    "time": 78675.123037,
    "actor_loss": -59.74067687988281,
    "critic_loss": 7.740516662597656,
    "ent_coef": 0.07790012657642365,
    "learning_rate": 0.001
  },
  {
    "episode": 5073,
    "reward": 86.758846,
    "length": 69,
    "time": 78686.887777,
    "actor_loss": -58.88140869140625,
    "critic_loss": 13.569433212280273,
    "ent_coef": 0.07864641398191452,
    "learning_rate": 0.001
  },
  {
    "episode": 5074,
    "reward": 85.875015,
    "length": 69,
    "time": 78701.629289,
    "actor_loss": -56.00363540649414,
    "critic_loss": 76.16545104980469,
    "ent_coef": 0.07969828695058823,
    "learning_rate": 0.001
  },
  {
    "episode": 5075,
    "reward": 87.430179,
    "length": 69,
    "time": 78713.478103,
    "actor_loss": -63.558719635009766,
    "critic_loss": 32.048824310302734,
    "ent_coef": 0.08162238448858261,
    "learning_rate": 0.001
  },
  {
    "episode": 5076,
    "reward": 89.001958,
    "length": 66,
    "time": 78725.866506,
    "actor_loss": -63.280303955078125,
    "critic_loss": 4.698422431945801,
    "ent_coef": 0.0822114422917366,
    "learning_rate": 0.001
  },
  {
    "episode": 5077,
    "reward": 87.348992,
    "length": 67,
    "time": 78738.297597,
    "actor_loss": -62.38546371459961,
    "critic_loss": 12.881219863891602,
    "ent_coef": 0.08399541676044464,
    "learning_rate": 0.001
  },
  {
    "episode": 5078,
    "reward": 88.642108,
    "length": 66,
    "time": 78749.538354,
    "actor_loss": -66.18453979492188,
    "critic_loss": 27.988216400146484,
    "ent_coef": 0.0847804993391037,
    "learning_rate": 0.001
  },
  {
    "episode": 5079,
    "reward": 87.54232,
    "length": 69,
    "time": 78761.989081,
    "actor_loss": -61.68244171142578,
    "critic_loss": 37.8631591796875,
    "ent_coef": 0.08509178459644318,
    "learning_rate": 0.001
  },
  {
    "episode": 5080,
    "reward": 88.884421,
    "length": 66,
    "time": 78774.231661,
    "actor_loss": -62.15229797363281,
    "critic_loss": 10.929676055908203,
    "ent_coef": 0.08807265758514404,
    "learning_rate": 0.001
  },
  {
    "episode": 5081,
    "reward": 87.538721,
    "length": 67,
    "time": 78789.283966,
    "actor_loss": -60.800743103027344,
    "critic_loss": 10.615100860595703,
    "ent_coef": 0.08835411071777344,
    "learning_rate": 0.001
  },
  {
    "episode": 5082,
    "reward": 87.88743,
    "length": 66,
    "time": 78801.624849,
    "actor_loss": -61.579158782958984,
    "critic_loss": 10.131022453308105,
    "ent_coef": 0.08935780078172684,
    "learning_rate": 0.001
  },
  {
    "episode": 5083,
    "reward": 87.433865,
    "length": 68,
    "time": 78816.086767,
    "actor_loss": -58.912818908691406,
    "critic_loss": 9.499937057495117,
    "ent_coef": 0.09128084033727646,
    "learning_rate": 0.001
  },
  {
    "episode": 5084,
    "reward": 87.851538,
    "length": 67,
    "time": 78828.715008,
    "actor_loss": -61.05065155029297,
    "critic_loss": 7.829978942871094,
    "ent_coef": 0.09356849640607834,
    "learning_rate": 0.001
  },
  {
    "episode": 5085,
    "reward": 87.745062,
    "length": 67,
    "time": 78840.911907,
    "actor_loss": -61.24485778808594,
    "critic_loss": 34.26273727416992,
    "ent_coef": 0.09373551607131958,
    "learning_rate": 0.001
  },
  {
    "episode": 5086,
    "reward": 86.123863,
    "length": 70,
    "time": 78853.627135,
    "actor_loss": -61.080223083496094,
    "critic_loss": 14.188032150268555,
    "ent_coef": 0.08938754349946976,
    "learning_rate": 0.001
  },
  {
    "episode": 5087,
    "reward": 40.129878,
    "length": 127,
    "time": 78875.195711,
    "actor_loss": -56.94233322143555,
    "critic_loss": 10.327938079833984,
    "ent_coef": 0.08841808885335922,
    "learning_rate": 0.001
  },
  {
    "episode": 5088,
    "reward": 86.829392,
    "length": 70,
    "time": 78888.123218,
    "actor_loss": -62.284889221191406,
    "critic_loss": 9.91142463684082,
    "ent_coef": 0.09310822933912277,
    "learning_rate": 0.001
  },
  {
    "episode": 5089,
    "reward": 89.113312,
    "length": 65,
    "time": 78901.89168,
    "actor_loss": -59.54170227050781,
    "critic_loss": 9.383899688720703,
    "ent_coef": 0.09563308954238892,
    "learning_rate": 0.001
  },
  {
    "episode": 5090,
    "reward": 86.968537,
    "length": 69,
    "time": 78915.301026,
    "actor_loss": -57.92390441894531,
    "critic_loss": 4.78603458404541,
    "ent_coef": 0.09457951784133911,
    "learning_rate": 0.001
  },
  {
    "episode": 5091,
    "reward": 89.30863,
    "length": 65,
    "time": 78927.830859,
    "actor_loss": -60.428672790527344,
    "critic_loss": 4.349406719207764,
    "ent_coef": 0.09528893977403641,
    "learning_rate": 0.001
  },
  {
    "episode": 5092,
    "reward": 90.072626,
    "length": 64,
    "time": 78939.1243,
    "actor_loss": -61.26367950439453,
    "critic_loss": 15.681010246276855,
    "ent_coef": 0.09895570576190948,
    "learning_rate": 0.001
  },
  {
    "episode": 5093,
    "reward": 86.980888,
    "length": 69,
    "time": 78951.720006,
    "actor_loss": -60.46766662597656,
    "critic_loss": 17.19658660888672,
    "ent_coef": 0.09531955420970917,
    "learning_rate": 0.001
  },
  {
    "episode": 5094,
    "reward": 89.973743,
    "length": 64,
    "time": 78969.283525,
    "actor_loss": -64.82432556152344,
    "critic_loss": 6.880575180053711,
    "ent_coef": 0.09481837600469589,
    "learning_rate": 0.001
  },
  {
    "episode": 5095,
    "reward": 90.21857,
    "length": 62,
    "time": 78984.303689,
    "actor_loss": -63.760841369628906,
    "critic_loss": 15.498741149902344,
    "ent_coef": 0.09471997618675232,
    "learning_rate": 0.001
  },
  {
    "episode": 5096,
    "reward": 88.209222,
    "length": 66,
    "time": 78997.947043,
    "actor_loss": -61.707977294921875,
    "critic_loss": 42.934364318847656,
    "ent_coef": 0.09220067411661148,
    "learning_rate": 0.001
  },
  {
    "episode": 5097,
    "reward": 88.77723,
    "length": 65,
    "time": 79010.105138,
    "actor_loss": -58.60183334350586,
    "critic_loss": 21.43255615234375,
    "ent_coef": 0.09024925529956818,
    "learning_rate": 0.001
  },
  {
    "episode": 5098,
    "reward": 89.334925,
    "length": 63,
    "time": 79020.961328,
    "actor_loss": -59.45966339111328,
    "critic_loss": 11.047754287719727,
    "ent_coef": 0.08968959003686905,
    "learning_rate": 0.001
  },
  {
    "episode": 5099,
    "reward": 88.189758,
    "length": 66,
    "time": 79033.978998,
    "actor_loss": -61.448814392089844,
    "critic_loss": 35.852901458740234,
    "ent_coef": 0.09093642234802246,
    "learning_rate": 0.001
  },
  {
    "episode": 5100,
    "reward": 91.360732,
    "length": 60,
    "time": 79046.572227,
    "actor_loss": -58.91471481323242,
    "critic_loss": 7.577352523803711,
    "ent_coef": 0.09451974183320999,
    "learning_rate": 0.001
  },
  {
    "episode": 5101,
    "reward": 86.791568,
    "length": 70,
    "time": 79059.539201,
    "actor_loss": -64.53093719482422,
    "critic_loss": 4.408768653869629,
    "ent_coef": 0.09412229061126709,
    "learning_rate": 0.001
  },
  {
    "episode": 5102,
    "reward": 88.159612,
    "length": 67,
    "time": 79070.925081,
    "actor_loss": -58.903289794921875,
    "critic_loss": 7.142375469207764,
    "ent_coef": 0.0941227376461029,
    "learning_rate": 0.001
  },
  {
    "episode": 5103,
    "reward": 88.327726,
    "length": 65,
    "time": 79083.04703,
    "actor_loss": -62.31397247314453,
    "critic_loss": 55.84720993041992,
    "ent_coef": 0.09631276875734329,
    "learning_rate": 0.001
  },
  {
    "episode": 5104,
    "reward": 90.630513,
    "length": 62,
    "time": 79095.412826,
    "actor_loss": -56.58087921142578,
    "critic_loss": 32.37896728515625,
    "ent_coef": 0.09681206941604614,
    "learning_rate": 0.001
  },
  {
    "episode": 5105,
    "reward": 88.725989,
    "length": 66,
    "time": 79106.543871,
    "actor_loss": -63.16980743408203,
    "critic_loss": 112.60453796386719,
    "ent_coef": 0.09627766162157059,
    "learning_rate": 0.001
  },
  {
    "episode": 5106,
    "reward": 88.052473,
    "length": 66,
    "time": 79119.601456,
    "actor_loss": -64.65957641601562,
    "critic_loss": 44.840110778808594,
    "ent_coef": 0.09813058376312256,
    "learning_rate": 0.001
  },
  {
    "episode": 5107,
    "reward": 83.935074,
    "length": 74,
    "time": 79133.073797,
    "actor_loss": -64.95101165771484,
    "critic_loss": 7.4895734786987305,
    "ent_coef": 0.09047196805477142,
    "learning_rate": 0.001
  },
  {
    "episode": 5108,
    "reward": 33.52964,
    "length": 140,
    "time": 79155.420575,
    "actor_loss": -63.2904052734375,
    "critic_loss": 4.973176956176758,
    "ent_coef": 0.08232946693897247,
    "learning_rate": 0.001
  },
  {
    "episode": 5109,
    "reward": 91.710432,
    "length": 60,
    "time": 79165.89474,
    "actor_loss": -60.46693801879883,
    "critic_loss": 9.867345809936523,
    "ent_coef": 0.08792604506015778,
    "learning_rate": 0.001
  },
  {
    "episode": 5110,
    "reward": 86.060624,
    "length": 73,
    "time": 79180.401499,
    "actor_loss": -58.931427001953125,
    "critic_loss": 4.93179178237915,
    "ent_coef": 0.09177051484584808,
    "learning_rate": 0.001
  },
  {
    "episode": 5111,
    "reward": 89.997349,
    "length": 64,
    "time": 79192.587223,
    "actor_loss": -67.10905456542969,
    "critic_loss": 65.44825744628906,
    "ent_coef": 0.09280670434236526,
    "learning_rate": 0.001
  },
  {
    "episode": 5112,
    "reward": 87.453662,
    "length": 67,
    "time": 79203.900335,
    "actor_loss": -64.91773223876953,
    "critic_loss": 12.556671142578125,
    "ent_coef": 0.08957165479660034,
    "learning_rate": 0.001
  },
  {
    "episode": 5113,
    "reward": 82.549558,
    "length": 77,
    "time": 79216.747812,
    "actor_loss": -60.52207565307617,
    "critic_loss": 6.639566421508789,
    "ent_coef": 0.08468009531497955,
    "learning_rate": 0.001
  },
  {
    "episode": 5114,
    "reward": 82.733423,
    "length": 80,
    "time": 79230.701718,
    "actor_loss": -61.69911193847656,
    "critic_loss": 54.420013427734375,
    "ent_coef": 0.08361862599849701,
    "learning_rate": 0.001
  },
  {
    "episode": 5115,
    "reward": 88.957182,
    "length": 64,
    "time": 79243.648822,
    "actor_loss": -65.7071304321289,
    "critic_loss": 5.131180763244629,
    "ent_coef": 0.08475340902805328,
    "learning_rate": 0.001
  },
  {
    "episode": 5116,
    "reward": 85.99237,
    "length": 73,
    "time": 79257.623569,
    "actor_loss": -66.04196166992188,
    "critic_loss": 5.79426383972168,
    "ent_coef": 0.08241472393274307,
    "learning_rate": 0.001
  },
  {
    "episode": 5117,
    "reward": 87.404709,
    "length": 69,
    "time": 79271.474691,
    "actor_loss": -63.457603454589844,
    "critic_loss": 12.033927917480469,
    "ent_coef": 0.08211954683065414,
    "learning_rate": 0.001
  },
  {
    "episode": 5118,
    "reward": 89.242017,
    "length": 65,
    "time": 79282.593306,
    "actor_loss": -64.21513366699219,
    "critic_loss": 82.6467514038086,
    "ent_coef": 0.08538646250963211,
    "learning_rate": 0.001
  },
  {
    "episode": 5119,
    "reward": 87.606399,
    "length": 70,
    "time": 79295.487451,
    "actor_loss": -66.51685333251953,
    "critic_loss": 54.346961975097656,
    "ent_coef": 0.08577723801136017,
    "learning_rate": 0.001
  },
  {
    "episode": 5120,
    "reward": 89.772332,
    "length": 63,
    "time": 79307.560567,
    "actor_loss": -62.410888671875,
    "critic_loss": 6.367653846740723,
    "ent_coef": 0.08826534450054169,
    "learning_rate": 0.001
  },
  {
    "episode": 5121,
    "reward": 87.4322,
    "length": 70,
    "time": 79319.490102,
    "actor_loss": -55.82223129272461,
    "critic_loss": 31.320480346679688,
    "ent_coef": 0.09289636462926865,
    "learning_rate": 0.001
  },
  {
    "episode": 5122,
    "reward": 87.902027,
    "length": 67,
    "time": 79332.75142,
    "actor_loss": -57.09405517578125,
    "critic_loss": 5.826125621795654,
    "ent_coef": 0.09395485371351242,
    "learning_rate": 0.001
  },
  {
    "episode": 5123,
    "reward": 86.659309,
    "length": 70,
    "time": 79345.347819,
    "actor_loss": -61.834083557128906,
    "critic_loss": 13.475626945495605,
    "ent_coef": 0.09440535306930542,
    "learning_rate": 0.001
  },
  {
    "episode": 5124,
    "reward": 88.690999,
    "length": 66,
    "time": 79358.103585,
    "actor_loss": -60.304908752441406,
    "critic_loss": 5.360176086425781,
    "ent_coef": 0.09297360479831696,
    "learning_rate": 0.001
  },
  {
    "episode": 5125,
    "reward": 86.206378,
    "length": 73,
    "time": 79375.627601,
    "actor_loss": -60.57065200805664,
    "critic_loss": 55.809608459472656,
    "ent_coef": 0.09321542829275131,
    "learning_rate": 0.001
  },
  {
    "episode": 5126,
    "reward": 88.691512,
    "length": 68,
    "time": 79388.302462,
    "actor_loss": -61.40928649902344,
    "critic_loss": 12.159697532653809,
    "ent_coef": 0.09734737873077393,
    "learning_rate": 0.001
  },
  {
    "episode": 5127,
    "reward": 88.20773,
    "length": 67,
    "time": 79399.918037,
    "actor_loss": -64.58738708496094,
    "critic_loss": 17.09076690673828,
    "ent_coef": 0.09705237299203873,
    "learning_rate": 0.001
  },
  {
    "episode": 5128,
    "reward": 89.247994,
    "length": 64,
    "time": 79411.038611,
    "actor_loss": -55.194942474365234,
    "critic_loss": 84.89030456542969,
    "ent_coef": 0.09769891202449799,
    "learning_rate": 0.001
  },
  {
    "episode": 5129,
    "reward": 91.049276,
    "length": 62,
    "time": 79422.886044,
    "actor_loss": -59.221282958984375,
    "critic_loss": 7.014960289001465,
    "ent_coef": 0.10020412504673004,
    "learning_rate": 0.001
  },
  {
    "episode": 5130,
    "reward": 88.372173,
    "length": 65,
    "time": 79434.581921,
    "actor_loss": -60.503936767578125,
    "critic_loss": 13.519012451171875,
    "ent_coef": 0.10107943415641785,
    "learning_rate": 0.001
  },
  {
    "episode": 5131,
    "reward": 90.276893,
    "length": 63,
    "time": 79445.735291,
    "actor_loss": -62.039608001708984,
    "critic_loss": 7.511600494384766,
    "ent_coef": 0.1019146665930748,
    "learning_rate": 0.001
  },
  {
    "episode": 5132,
    "reward": 88.560745,
    "length": 65,
    "time": 79456.813118,
    "actor_loss": -66.53192138671875,
    "critic_loss": 13.570249557495117,
    "ent_coef": 0.10523718595504761,
    "learning_rate": 0.001
  },
  {
    "episode": 5133,
    "reward": 83.382513,
    "length": 82,
    "time": 79471.188447,
    "actor_loss": -66.28495788574219,
    "critic_loss": 47.509071350097656,
    "ent_coef": 0.10005680471658707,
    "learning_rate": 0.001
  },
  {
    "episode": 5134,
    "reward": 88.488669,
    "length": 66,
    "time": 79482.641025,
    "actor_loss": -59.427452087402344,
    "critic_loss": 8.576940536499023,
    "ent_coef": 0.09444175660610199,
    "learning_rate": 0.001
  },
  {
    "episode": 5135,
    "reward": 81.759687,
    "length": 82,
    "time": 79497.75522,
    "actor_loss": -61.980186462402344,
    "critic_loss": 36.26993942260742,
    "ent_coef": 0.09192442148923874,
    "learning_rate": 0.001
  },
  {
    "episode": 5136,
    "reward": 88.906592,
    "length": 67,
    "time": 79510.841375,
    "actor_loss": -60.91972351074219,
    "critic_loss": 929.7957153320312,
    "ent_coef": 0.09260696172714233,
    "learning_rate": 0.001
  },
  {
    "episode": 5137,
    "reward": 86.295237,
    "length": 70,
    "time": 79525.429784,
    "actor_loss": -67.05665588378906,
    "critic_loss": 26.6600284576416,
    "ent_coef": 0.09314578026533127,
    "learning_rate": 0.001
  },
  {
    "episode": 5138,
    "reward": 79.849573,
    "length": 81,
    "time": 79541.593698,
    "actor_loss": -60.52041244506836,
    "critic_loss": 6.640539169311523,
    "ent_coef": 0.09426777064800262,
    "learning_rate": 0.001
  },
  {
    "episode": 5139,
    "reward": 87.108648,
    "length": 69,
    "time": 79558.132893,
    "actor_loss": -63.61017608642578,
    "critic_loss": 35.8896484375,
    "ent_coef": 0.0929364413022995,
    "learning_rate": 0.001
  },
  {
    "episode": 5140,
    "reward": 83.93458,
    "length": 76,
    "time": 79570.529479,
    "actor_loss": -61.11140441894531,
    "critic_loss": 843.7467041015625,
    "ent_coef": 0.0902518555521965,
    "learning_rate": 0.001
  },
  {
    "episode": 5141,
    "reward": 89.376425,
    "length": 64,
    "time": 79582.171993,
    "actor_loss": -61.62361145019531,
    "critic_loss": 13.940462112426758,
    "ent_coef": 0.0908648818731308,
    "learning_rate": 0.001
  },
  {
    "episode": 5142,
    "reward": 88.13398,
    "length": 66,
    "time": 79594.302543,
    "actor_loss": -58.981693267822266,
    "critic_loss": 3.2627787590026855,
    "ent_coef": 0.0923909917473793,
    "learning_rate": 0.001
  },
  {
    "episode": 5143,
    "reward": 89.026317,
    "length": 66,
    "time": 79606.861504,
    "actor_loss": -61.64017105102539,
    "critic_loss": 40.35239791870117,
    "ent_coef": 0.09042109549045563,
    "learning_rate": 0.001
  },
  {
    "episode": 5144,
    "reward": 80.38289,
    "length": 80,
    "time": 79620.611196,
    "actor_loss": -56.56684112548828,
    "critic_loss": 7.298773765563965,
    "ent_coef": 0.08561007678508759,
    "learning_rate": 0.001
  },
  {
    "episode": 5145,
    "reward": 84.960023,
    "length": 72,
    "time": 79632.620442,
    "actor_loss": -61.213340759277344,
    "critic_loss": 14.663973808288574,
    "ent_coef": 0.08511736989021301,
    "learning_rate": 0.001
  },
  {
    "episode": 5146,
    "reward": 86.552186,
    "length": 69,
    "time": 79648.074925,
    "actor_loss": -63.82461166381836,
    "critic_loss": 23.068313598632812,
    "ent_coef": 0.08820603787899017,
    "learning_rate": 0.001
  },
  {
    "episode": 5147,
    "reward": 84.387836,
    "length": 74,
    "time": 79661.032708,
    "actor_loss": -63.41062927246094,
    "critic_loss": 21.804691314697266,
    "ent_coef": 0.08751170337200165,
    "learning_rate": 0.001
  },
  {
    "episode": 5148,
    "reward": 86.107289,
    "length": 70,
    "time": 79675.293467,
    "actor_loss": -66.2530517578125,
    "critic_loss": 25.867733001708984,
    "ent_coef": 0.08804851770401001,
    "learning_rate": 0.001
  },
  {
    "episode": 5149,
    "reward": 82.892006,
    "length": 76,
    "time": 79689.493145,
    "actor_loss": -61.4189453125,
    "critic_loss": 2.87905216217041,
    "ent_coef": 0.08435297757387161,
    "learning_rate": 0.001
  },
  {
    "episode": 5150,
    "reward": 82.028041,
    "length": 77,
    "time": 79702.058135,
    "actor_loss": -56.65449142456055,
    "critic_loss": 10.730934143066406,
    "ent_coef": 0.08421707898378372,
    "learning_rate": 0.001
  },
  {
    "episode": 5151,
    "reward": 85.280018,
    "length": 71,
    "time": 79717.539458,
    "actor_loss": -63.280338287353516,
    "critic_loss": 14.431838989257812,
    "ent_coef": 0.08483544737100601,
    "learning_rate": 0.001
  },
  {
    "episode": 5152,
    "reward": 86.533464,
    "length": 69,
    "time": 79730.244989,
    "actor_loss": -59.23196792602539,
    "critic_loss": 19.516416549682617,
    "ent_coef": 0.08845262229442596,
    "learning_rate": 0.001
  },
  {
    "episode": 5153,
    "reward": 87.742562,
    "length": 68,
    "time": 79744.135279,
    "actor_loss": -55.30017852783203,
    "critic_loss": 12.978521347045898,
    "ent_coef": 0.09395120292901993,
    "learning_rate": 0.001
  },
  {
    "episode": 5154,
    "reward": 87.711134,
    "length": 69,
    "time": 79759.016825,
    "actor_loss": -67.90304565429688,
    "critic_loss": 16.527324676513672,
    "ent_coef": 0.09324783086776733,
    "learning_rate": 0.001
  },
  {
    "episode": 5155,
    "reward": 84.028191,
    "length": 74,
    "time": 79773.753734,
    "actor_loss": -68.44343566894531,
    "critic_loss": 4.835160255432129,
    "ent_coef": 0.09337993711233139,
    "learning_rate": 0.001
  },
  {
    "episode": 5156,
    "reward": 85.506155,
    "length": 74,
    "time": 79785.947999,
    "actor_loss": -61.28424835205078,
    "critic_loss": 11.013524055480957,
    "ent_coef": 0.09670498222112656,
    "learning_rate": 0.001
  },
  {
    "episode": 5157,
    "reward": 89.563566,
    "length": 64,
    "time": 79797.741935,
    "actor_loss": -62.86505126953125,
    "critic_loss": 17.589597702026367,
    "ent_coef": 0.09870065003633499,
    "learning_rate": 0.001
  },
  {
    "episode": 5158,
    "reward": 87.187512,
    "length": 70,
    "time": 79809.293203,
    "actor_loss": -62.031593322753906,
    "critic_loss": 342.3319091796875,
    "ent_coef": 0.1021299809217453,
    "learning_rate": 0.001
  },
  {
    "episode": 5159,
    "reward": 87.466315,
    "length": 68,
    "time": 79821.804489,
    "actor_loss": -60.926177978515625,
    "critic_loss": 5.4162983894348145,
    "ent_coef": 0.1061273068189621,
    "learning_rate": 0.001
  },
  {
    "episode": 5160,
    "reward": 87.430686,
    "length": 69,
    "time": 79834.118755,
    "actor_loss": -62.413429260253906,
    "critic_loss": 9.10235595703125,
    "ent_coef": 0.11072073131799698,
    "learning_rate": 0.001
  },
  {
    "episode": 5161,
    "reward": 88.829444,
    "length": 67,
    "time": 79845.653439,
    "actor_loss": -66.21965789794922,
    "critic_loss": 16.612749099731445,
    "ent_coef": 0.10932373255491257,
    "learning_rate": 0.001
  },
  {
    "episode": 5162,
    "reward": 84.828889,
    "length": 74,
    "time": 79858.013983,
    "actor_loss": -59.841392517089844,
    "critic_loss": 32.449302673339844,
    "ent_coef": 0.10148254036903381,
    "learning_rate": 0.001
  },
  {
    "episode": 5163,
    "reward": 89.700898,
    "length": 64,
    "time": 79869.440978,
    "actor_loss": -70.4520263671875,
    "critic_loss": 26.486492156982422,
    "ent_coef": 0.09779597818851471,
    "learning_rate": 0.001
  },
  {
    "episode": 5164,
    "reward": 87.556985,
    "length": 69,
    "time": 79881.201519,
    "actor_loss": -65.38040161132812,
    "critic_loss": 31.81666374206543,
    "ent_coef": 0.10047401487827301,
    "learning_rate": 0.001
  },
  {
    "episode": 5165,
    "reward": 87.350063,
    "length": 68,
    "time": 79893.442696,
    "actor_loss": -65.7165298461914,
    "critic_loss": 24.407737731933594,
    "ent_coef": 0.09990067034959793,
    "learning_rate": 0.001
  },
  {
    "episode": 5166,
    "reward": 86.750387,
    "length": 71,
    "time": 79907.587973,
    "actor_loss": -63.699222564697266,
    "critic_loss": 9.88538932800293,
    "ent_coef": 0.09736885130405426,
    "learning_rate": 0.001
  },
  {
    "episode": 5167,
    "reward": 86.148811,
    "length": 79,
    "time": 79922.274998,
    "actor_loss": -56.4510498046875,
    "critic_loss": 9.661201477050781,
    "ent_coef": 0.09737728536128998,
    "learning_rate": 0.001
  },
  {
    "episode": 5168,
    "reward": 90.189731,
    "length": 62,
    "time": 79933.975157,
    "actor_loss": -63.74162292480469,
    "critic_loss": 8.718442916870117,
    "ent_coef": 0.09509192407131195,
    "learning_rate": 0.001
  },
  {
    "episode": 5169,
    "reward": 88.702334,
    "length": 69,
    "time": 79947.594888,
    "actor_loss": -64.651123046875,
    "critic_loss": 21.775772094726562,
    "ent_coef": 0.09407652914524078,
    "learning_rate": 0.001
  },
  {
    "episode": 5170,
    "reward": 85.115547,
    "length": 74,
    "time": 79960.093755,
    "actor_loss": -63.041404724121094,
    "critic_loss": 9.857815742492676,
    "ent_coef": 0.08549020439386368,
    "learning_rate": 0.001
  },
  {
    "episode": 5171,
    "reward": 89.374984,
    "length": 67,
    "time": 79973.392685,
    "actor_loss": -57.960689544677734,
    "critic_loss": 8.696930885314941,
    "ent_coef": 0.08280031383037567,
    "learning_rate": 0.001
  },
  {
    "episode": 5172,
    "reward": 88.190423,
    "length": 66,
    "time": 79986.113468,
    "actor_loss": -61.3089485168457,
    "critic_loss": 21.779678344726562,
    "ent_coef": 0.08271393179893494,
    "learning_rate": 0.001
  },
  {
    "episode": 5173,
    "reward": 88.39917,
    "length": 66,
    "time": 80000.725913,
    "actor_loss": -69.20297241210938,
    "critic_loss": 8.704431533813477,
    "ent_coef": 0.08282463252544403,
    "learning_rate": 0.001
  },
  {
    "episode": 5174,
    "reward": 84.674938,
    "length": 74,
    "time": 80013.118435,
    "actor_loss": -64.41510009765625,
    "critic_loss": 4.7425079345703125,
    "ent_coef": 0.07975183427333832,
    "learning_rate": 0.001
  },
  {
    "episode": 5175,
    "reward": 80.979303,
    "length": 80,
    "time": 80026.371455,
    "actor_loss": -60.932376861572266,
    "critic_loss": 9.062553405761719,
    "ent_coef": 0.07441549003124237,
    "learning_rate": 0.001
  },
  {
    "episode": 5176,
    "reward": 79.61081,
    "length": 82,
    "time": 80039.671588,
    "actor_loss": -62.38583755493164,
    "critic_loss": 12.662582397460938,
    "ent_coef": 0.07367482036352158,
    "learning_rate": 0.001
  },
  {
    "episode": 5177,
    "reward": 89.156532,
    "length": 65,
    "time": 80050.935776,
    "actor_loss": -63.43987274169922,
    "critic_loss": 3.6887171268463135,
    "ent_coef": 0.07753358781337738,
    "learning_rate": 0.001
  },
  {
    "episode": 5178,
    "reward": 90.202553,
    "length": 63,
    "time": 80062.059532,
    "actor_loss": -62.82086944580078,
    "critic_loss": 23.2379093170166,
    "ent_coef": 0.0806531310081482,
    "learning_rate": 0.001
  },
  {
    "episode": 5179,
    "reward": 88.598174,
    "length": 64,
    "time": 80073.749095,
    "actor_loss": -56.011470794677734,
    "critic_loss": 63.131675720214844,
    "ent_coef": 0.08329930156469345,
    "learning_rate": 0.001
  },
  {
    "episode": 5180,
    "reward": 90.468082,
    "length": 63,
    "time": 80085.303873,
    "actor_loss": -65.98808288574219,
    "critic_loss": 4.54693078994751,
    "ent_coef": 0.08801046758890152,
    "learning_rate": 0.001
  },
  {
    "episode": 5181,
    "reward": 90.0414,
    "length": 63,
    "time": 80097.503722,
    "actor_loss": -65.85110473632812,
    "critic_loss": 11.886704444885254,
    "ent_coef": 0.09252782166004181,
    "learning_rate": 0.001
  },
  {
    "episode": 5182,
    "reward": 89.093409,
    "length": 65,
    "time": 80109.735442,
    "actor_loss": -66.64594268798828,
    "critic_loss": 7.425664901733398,
    "ent_coef": 0.09538247436285019,
    "learning_rate": 0.001
  },
  {
    "episode": 5183,
    "reward": 89.686085,
    "length": 63,
    "time": 80121.30458,
    "actor_loss": -55.635597229003906,
    "critic_loss": 21.458877563476562,
    "ent_coef": 0.09795781224966049,
    "learning_rate": 0.001
  },
  {
    "episode": 5184,
    "reward": 88.429068,
    "length": 65,
    "time": 80132.399017,
    "actor_loss": -67.7093276977539,
    "critic_loss": 27.930356979370117,
    "ent_coef": 0.10109958052635193,
    "learning_rate": 0.001
  },
  {
    "episode": 5185,
    "reward": 88.775234,
    "length": 64,
    "time": 80145.365412,
    "actor_loss": -58.843902587890625,
    "critic_loss": 38.18714141845703,
    "ent_coef": 0.10488278418779373,
    "learning_rate": 0.001
  },
  {
    "episode": 5186,
    "reward": 89.915835,
    "length": 63,
    "time": 80158.610797,
    "actor_loss": -60.29949951171875,
    "critic_loss": 42.42961502075195,
    "ent_coef": 0.10157964378595352,
    "learning_rate": 0.001
  },
  {
    "episode": 5187,
    "reward": 90.454783,
    "length": 63,
    "time": 80169.78061,
    "actor_loss": -66.0967025756836,
    "critic_loss": 55.60872268676758,
    "ent_coef": 0.09774930775165558,
    "learning_rate": 0.001
  },
  {
    "episode": 5188,
    "reward": 86.044846,
    "length": 71,
    "time": 80182.645984,
    "actor_loss": -61.22471618652344,
    "critic_loss": 6.286864757537842,
    "ent_coef": 0.0959172248840332,
    "learning_rate": 0.001
  },
  {
    "episode": 5189,
    "reward": 90.27005,
    "length": 64,
    "time": 80194.044275,
    "actor_loss": -62.56644821166992,
    "critic_loss": 11.818947792053223,
    "ent_coef": 0.09439774602651596,
    "learning_rate": 0.001
  },
  {
    "episode": 5190,
    "reward": 88.485116,
    "length": 66,
    "time": 80208.781321,
    "actor_loss": -59.49354553222656,
    "critic_loss": 36.25164794921875,
    "ent_coef": 0.09361069649457932,
    "learning_rate": 0.001
  },
  {
    "episode": 5191,
    "reward": 89.118503,
    "length": 66,
    "time": 80223.06938,
    "actor_loss": -57.45627212524414,
    "critic_loss": 135.61207580566406,
    "ent_coef": 0.09023907035589218,
    "learning_rate": 0.001
  },
  {
    "episode": 5192,
    "reward": 88.994563,
    "length": 66,
    "time": 80235.616582,
    "actor_loss": -65.17485046386719,
    "critic_loss": 6.175443649291992,
    "ent_coef": 0.08801330626010895,
    "learning_rate": 0.001
  },
  {
    "episode": 5193,
    "reward": 90.063823,
    "length": 64,
    "time": 80246.598047,
    "actor_loss": -62.571144104003906,
    "critic_loss": 59.075958251953125,
    "ent_coef": 0.08777466416358948,
    "learning_rate": 0.001
  },
  {
    "episode": 5194,
    "reward": 89.34876,
    "length": 66,
    "time": 80258.702429,
    "actor_loss": -63.175453186035156,
    "critic_loss": 6.562010765075684,
    "ent_coef": 0.08352991938591003,
    "learning_rate": 0.001
  },
  {
    "episode": 5195,
    "reward": 87.335245,
    "length": 70,
    "time": 80271.46329,
    "actor_loss": -64.26099395751953,
    "critic_loss": 49.80015563964844,
    "ent_coef": 0.07933540642261505,
    "learning_rate": 0.001
  },
  {
    "episode": 5196,
    "reward": 85.281858,
    "length": 74,
    "time": 80284.593731,
    "actor_loss": -60.48479461669922,
    "critic_loss": 12.977972030639648,
    "ent_coef": 0.07627853006124496,
    "learning_rate": 0.001
  },
  {
    "episode": 5197,
    "reward": 89.320155,
    "length": 64,
    "time": 80296.718151,
    "actor_loss": -60.016231536865234,
    "critic_loss": 5.98870849609375,
    "ent_coef": 0.0781630426645279,
    "learning_rate": 0.001
  },
  {
    "episode": 5198,
    "reward": 88.42589,
    "length": 66,
    "time": 80308.984298,
    "actor_loss": -63.42530059814453,
    "critic_loss": 18.514816284179688,
    "ent_coef": 0.08021845668554306,
    "learning_rate": 0.001
  },
  {
    "episode": 5199,
    "reward": 90.753546,
    "length": 63,
    "time": 80326.759779,
    "actor_loss": -59.42657470703125,
    "critic_loss": 10.831096649169922,
    "ent_coef": 0.08656775206327438,
    "learning_rate": 0.001
  },
  {
    "episode": 5200,
    "reward": 86.92022,
    "length": 71,
    "time": 80341.519022,
    "actor_loss": -64.78401184082031,
    "critic_loss": 8.460919380187988,
    "ent_coef": 0.08657202869653702,
    "learning_rate": 0.001
  },
  {
    "episode": 5201,
    "reward": 89.265558,
    "length": 64,
    "time": 80352.576097,
    "actor_loss": -63.394996643066406,
    "critic_loss": 3.0137696266174316,
    "ent_coef": 0.08888466656208038,
    "learning_rate": 0.001
  },
  {
    "episode": 5202,
    "reward": 87.461067,
    "length": 68,
    "time": 80364.94179,
    "actor_loss": -64.21977996826172,
    "critic_loss": 840.4463500976562,
    "ent_coef": 0.0880499854683876,
    "learning_rate": 0.001
  },
  {
    "episode": 5203,
    "reward": 88.219755,
    "length": 66,
    "time": 80378.407704,
    "actor_loss": -60.946205139160156,
    "critic_loss": 7.193809509277344,
    "ent_coef": 0.08858221769332886,
    "learning_rate": 0.001
  },
  {
    "episode": 5204,
    "reward": 88.571714,
    "length": 65,
    "time": 80389.576619,
    "actor_loss": -62.14714050292969,
    "critic_loss": 4.962700843811035,
    "ent_coef": 0.08987098187208176,
    "learning_rate": 0.001
  },
  {
    "episode": 5205,
    "reward": 86.826359,
    "length": 70,
    "time": 80404.119933,
    "actor_loss": -59.71760940551758,
    "critic_loss": 7.273806571960449,
    "ent_coef": 0.08930186927318573,
    "learning_rate": 0.001
  },
  {
    "episode": 5206,
    "reward": 87.996885,
    "length": 68,
    "time": 80416.517456,
    "actor_loss": -61.86515426635742,
    "critic_loss": 1038.4012451171875,
    "ent_coef": 0.08787110447883606,
    "learning_rate": 0.001
  },
  {
    "episode": 5207,
    "reward": 86.802802,
    "length": 67,
    "time": 80429.146336,
    "actor_loss": -61.276611328125,
    "critic_loss": 4.838621139526367,
    "ent_coef": 0.0912216454744339,
    "learning_rate": 0.001
  },
  {
    "episode": 5208,
    "reward": 89.079316,
    "length": 65,
    "time": 80440.187862,
    "actor_loss": -61.525596618652344,
    "critic_loss": 14.990488052368164,
    "ent_coef": 0.09459217637777328,
    "learning_rate": 0.001
  },
  {
    "episode": 5209,
    "reward": 84.8914,
    "length": 72,
    "time": 80454.047821,
    "actor_loss": -62.28880310058594,
    "critic_loss": 23.351362228393555,
    "ent_coef": 0.09592582285404205,
    "learning_rate": 0.001
  },
  {
    "episode": 5210,
    "reward": 90.041585,
    "length": 64,
    "time": 80465.341806,
    "actor_loss": -63.0438232421875,
    "critic_loss": 4.297314643859863,
    "ent_coef": 0.10065244883298874,
    "learning_rate": 0.001
  },
  {
    "episode": 5211,
    "reward": 87.037905,
    "length": 69,
    "time": 80477.423183,
    "actor_loss": -66.53961944580078,
    "critic_loss": 18.436002731323242,
    "ent_coef": 0.09576459974050522,
    "learning_rate": 0.001
  },
  {
    "episode": 5212,
    "reward": 85.660542,
    "length": 71,
    "time": 80489.336799,
    "actor_loss": -63.85394287109375,
    "critic_loss": 14.230367660522461,
    "ent_coef": 0.09418217837810516,
    "learning_rate": 0.001
  },
  {
    "episode": 5213,
    "reward": 90.231991,
    "length": 63,
    "time": 80500.425262,
    "actor_loss": -61.96221923828125,
    "critic_loss": 10.101694107055664,
    "ent_coef": 0.09466836601495743,
    "learning_rate": 0.001
  },
  {
    "episode": 5214,
    "reward": 87.829306,
    "length": 66,
    "time": 80514.771043,
    "actor_loss": -63.36566162109375,
    "critic_loss": 43.29200744628906,
    "ent_coef": 0.09632498770952225,
    "learning_rate": 0.001
  },
  {
    "episode": 5215,
    "reward": 89.847569,
    "length": 64,
    "time": 80526.411591,
    "actor_loss": -61.496368408203125,
    "critic_loss": 6.827147483825684,
    "ent_coef": 0.09626232832670212,
    "learning_rate": 0.001
  },
  {
    "episode": 5216,
    "reward": 88.958647,
    "length": 65,
    "time": 80537.750061,
    "actor_loss": -65.72224426269531,
    "critic_loss": 13.99189567565918,
    "ent_coef": 0.09773232042789459,
    "learning_rate": 0.001
  },
  {
    "episode": 5217,
    "reward": 87.019996,
    "length": 68,
    "time": 80551.272684,
    "actor_loss": -65.89973449707031,
    "critic_loss": 11.768245697021484,
    "ent_coef": 0.09759091585874557,
    "learning_rate": 0.001
  },
  {
    "episode": 5218,
    "reward": 87.188202,
    "length": 68,
    "time": 80562.769698,
    "actor_loss": -63.483489990234375,
    "critic_loss": 78.10543823242188,
    "ent_coef": 0.0973978266119957,
    "learning_rate": 0.001
  },
  {
    "episode": 5219,
    "reward": 84.025877,
    "length": 75,
    "time": 80575.203737,
    "actor_loss": -65.38026428222656,
    "critic_loss": 30.176876068115234,
    "ent_coef": 0.09265971928834915,
    "learning_rate": 0.001
  },
  {
    "episode": 5220,
    "reward": 81.587554,
    "length": 76,
    "time": 80587.587924,
    "actor_loss": -64.00395202636719,
    "critic_loss": 15.463340759277344,
    "ent_coef": 0.08703699707984924,
    "learning_rate": 0.001
  },
  {
    "episode": 5221,
    "reward": 87.375904,
    "length": 68,
    "time": 80602.268656,
    "actor_loss": -60.345340728759766,
    "critic_loss": 31.15311050415039,
    "ent_coef": 0.08661960810422897,
    "learning_rate": 0.001
  },
  {
    "episode": 5222,
    "reward": 87.506925,
    "length": 67,
    "time": 80616.975233,
    "actor_loss": -64.04022216796875,
    "critic_loss": 26.132808685302734,
    "ent_coef": 0.08620158582925797,
    "learning_rate": 0.001
  },
  {
    "episode": 5223,
    "reward": 89.039971,
    "length": 64,
    "time": 80628.115205,
    "actor_loss": -62.55867004394531,
    "critic_loss": 9.004358291625977,
    "ent_coef": 0.08799781650304794,
    "learning_rate": 0.001
  },
  {
    "episode": 5224,
    "reward": 89.351891,
    "length": 63,
    "time": 80640.853782,
    "actor_loss": -69.47508239746094,
    "critic_loss": 85.34496307373047,
    "ent_coef": 0.08685968816280365,
    "learning_rate": 0.001
  },
  {
    "episode": 5225,
    "reward": 88.400119,
    "length": 69,
    "time": 80654.143692,
    "actor_loss": -60.2266845703125,
    "critic_loss": 16.661624908447266,
    "ent_coef": 0.091629758477211,
    "learning_rate": 0.001
  },
  {
    "episode": 5226,
    "reward": 87.001477,
    "length": 68,
    "time": 80666.909041,
    "actor_loss": -62.53357696533203,
    "critic_loss": 4.098980903625488,
    "ent_coef": 0.09039243310689926,
    "learning_rate": 0.001
  },
  {
    "episode": 5227,
    "reward": 88.268179,
    "length": 66,
    "time": 80678.46812,
    "actor_loss": -58.906471252441406,
    "critic_loss": 59.74681854248047,
    "ent_coef": 0.09209748357534409,
    "learning_rate": 0.001
  },
  {
    "episode": 5228,
    "reward": 81.204194,
    "length": 80,
    "time": 80693.553308,
    "actor_loss": -61.81222152709961,
    "critic_loss": 69.97835540771484,
    "ent_coef": 0.09385153651237488,
    "learning_rate": 0.001
  },
  {
    "episode": 5229,
    "reward": 87.95929,
    "length": 68,
    "time": 80706.983294,
    "actor_loss": -64.0105972290039,
    "critic_loss": 16.65216827392578,
    "ent_coef": 0.09699428826570511,
    "learning_rate": 0.001
  },
  {
    "episode": 5230,
    "reward": 88.906762,
    "length": 65,
    "time": 80719.996967,
    "actor_loss": -62.88402557373047,
    "critic_loss": 2.334810972213745,
    "ent_coef": 0.09826553612947464,
    "learning_rate": 0.001
  },
  {
    "episode": 5231,
    "reward": 86.544505,
    "length": 70,
    "time": 80731.79232,
    "actor_loss": -62.732574462890625,
    "critic_loss": 13.241861343383789,
    "ent_coef": 0.09560026228427887,
    "learning_rate": 0.001
  },
  {
    "episode": 5232,
    "reward": 86.456815,
    "length": 68,
    "time": 80744.141272,
    "actor_loss": -59.15349578857422,
    "critic_loss": 8.651533126831055,
    "ent_coef": 0.09427406638860703,
    "learning_rate": 0.001
  },
  {
    "episode": 5233,
    "reward": 88.351089,
    "length": 66,
    "time": 80758.126443,
    "actor_loss": -60.5535888671875,
    "critic_loss": 5.606950759887695,
    "ent_coef": 0.0871795266866684,
    "learning_rate": 0.001
  },
  {
    "episode": 5234,
    "reward": 88.045208,
    "length": 67,
    "time": 80769.446288,
    "actor_loss": -60.90754699707031,
    "critic_loss": 3.3120570182800293,
    "ent_coef": 0.08439885079860687,
    "learning_rate": 0.001
  },
  {
    "episode": 5235,
    "reward": 88.067045,
    "length": 68,
    "time": 80784.944987,
    "actor_loss": -62.752159118652344,
    "critic_loss": 12.027183532714844,
    "ent_coef": 0.08403605222702026,
    "learning_rate": 0.001
  },
  {
    "episode": 5236,
    "reward": 89.755734,
    "length": 63,
    "time": 80797.434626,
    "actor_loss": -62.831119537353516,
    "critic_loss": 70.21385192871094,
    "ent_coef": 0.0819954127073288,
    "learning_rate": 0.001
  },
  {
    "episode": 5237,
    "reward": 91.195405,
    "length": 61,
    "time": 80811.098409,
    "actor_loss": -69.49668884277344,
    "critic_loss": 74.09078979492188,
    "ent_coef": 0.08305488526821136,
    "learning_rate": 0.001
  },
  {
    "episode": 5238,
    "reward": 85.320508,
    "length": 73,
    "time": 80824.758231,
    "actor_loss": -61.971405029296875,
    "critic_loss": 29.489456176757812,
    "ent_coef": 0.08623301237821579,
    "learning_rate": 0.001
  },
  {
    "episode": 5239,
    "reward": 83.338005,
    "length": 71,
    "time": 80837.430426,
    "actor_loss": -61.777488708496094,
    "critic_loss": 24.108352661132812,
    "ent_coef": 0.08714355528354645,
    "learning_rate": 0.001
  },
  {
    "episode": 5240,
    "reward": 87.467531,
    "length": 69,
    "time": 80851.00488,
    "actor_loss": -68.6416244506836,
    "critic_loss": 8.916585922241211,
    "ent_coef": 0.08677060157060623,
    "learning_rate": 0.001
  },
  {
    "episode": 5241,
    "reward": 87.08211,
    "length": 71,
    "time": 80862.867678,
    "actor_loss": -60.513668060302734,
    "critic_loss": 132.44403076171875,
    "ent_coef": 0.08724864572286606,
    "learning_rate": 0.001
  },
  {
    "episode": 5242,
    "reward": 78.535074,
    "length": 83,
    "time": 80878.111259,
    "actor_loss": -62.72303771972656,
    "critic_loss": 26.55303382873535,
    "ent_coef": 0.09048490971326828,
    "learning_rate": 0.001
  },
  {
    "episode": 5243,
    "reward": 87.602611,
    "length": 72,
    "time": 80891.160529,
    "actor_loss": -58.25746536254883,
    "critic_loss": 11.895097732543945,
    "ent_coef": 0.09001528471708298,
    "learning_rate": 0.001
  },
  {
    "episode": 5244,
    "reward": 83.782809,
    "length": 70,
    "time": 80905.547212,
    "actor_loss": -57.50800323486328,
    "critic_loss": 3.0883326530456543,
    "ent_coef": 0.0891527459025383,
    "learning_rate": 0.001
  },
  {
    "episode": 5245,
    "reward": 87.717574,
    "length": 70,
    "time": 80918.089637,
    "actor_loss": -61.296051025390625,
    "critic_loss": 9.255741119384766,
    "ent_coef": 0.09126080572605133,
    "learning_rate": 0.001
  },
  {
    "episode": 5246,
    "reward": 84.962826,
    "length": 77,
    "time": 80930.622323,
    "actor_loss": -67.01451110839844,
    "critic_loss": 12.188926696777344,
    "ent_coef": 0.08905168622732162,
    "learning_rate": 0.001
  },
  {
    "episode": 5247,
    "reward": 86.225534,
    "length": 73,
    "time": 80942.680707,
    "actor_loss": -61.437713623046875,
    "critic_loss": 4.883853912353516,
    "ent_coef": 0.08898597955703735,
    "learning_rate": 0.001
  },
  {
    "episode": 5248,
    "reward": 89.266522,
    "length": 66,
    "time": 80958.060118,
    "actor_loss": -62.25812530517578,
    "critic_loss": 12.018524169921875,
    "ent_coef": 0.08844584971666336,
    "learning_rate": 0.001
  },
  {
    "episode": 5249,
    "reward": 88.121922,
    "length": 68,
    "time": 80969.49518,
    "actor_loss": -65.81227111816406,
    "critic_loss": 10.600820541381836,
    "ent_coef": 0.09006758034229279,
    "learning_rate": 0.001
  },
  {
    "episode": 5250,
    "reward": 90.228282,
    "length": 64,
    "time": 80985.703518,
    "actor_loss": -57.877838134765625,
    "critic_loss": 37.83802032470703,
    "ent_coef": 0.09408186376094818,
    "learning_rate": 0.001
  },
  {
    "episode": 5251,
    "reward": 87.172602,
    "length": 68,
    "time": 80999.600964,
    "actor_loss": -57.634178161621094,
    "critic_loss": 27.643787384033203,
    "ent_coef": 0.09514673799276352,
    "learning_rate": 0.001
  },
  {
    "episode": 5252,
    "reward": 86.629897,
    "length": 69,
    "time": 81011.819045,
    "actor_loss": -62.20878601074219,
    "critic_loss": 15.824100494384766,
    "ent_coef": 0.09423332661390305,
    "learning_rate": 0.001
  },
  {
    "episode": 5253,
    "reward": 89.892347,
    "length": 63,
    "time": 81024.537698,
    "actor_loss": -56.55015563964844,
    "critic_loss": 52.134735107421875,
    "ent_coef": 0.09288022667169571,
    "learning_rate": 0.001
  },
  {
    "episode": 5254,
    "reward": 89.139361,
    "length": 67,
    "time": 81038.229972,
    "actor_loss": -64.56396484375,
    "critic_loss": 17.689910888671875,
    "ent_coef": 0.09592792391777039,
    "learning_rate": 0.001
  },
  {
    "episode": 5255,
    "reward": 87.425034,
    "length": 68,
    "time": 81049.641229,
    "actor_loss": -68.77647399902344,
    "critic_loss": 16.417530059814453,
    "ent_coef": 0.09345009177923203,
    "learning_rate": 0.001
  },
  {
    "episode": 5256,
    "reward": 85.664701,
    "length": 71,
    "time": 81063.95871,
    "actor_loss": -60.95116424560547,
    "critic_loss": 9.489381790161133,
    "ent_coef": 0.09060615301132202,
    "learning_rate": 0.001
  },
  {
    "episode": 5257,
    "reward": 87.582232,
    "length": 68,
    "time": 81077.21423,
    "actor_loss": -61.21086883544922,
    "critic_loss": 22.373929977416992,
    "ent_coef": 0.09086080640554428,
    "learning_rate": 0.001
  },
  {
    "episode": 5258,
    "reward": 86.446918,
    "length": 71,
    "time": 81089.353926,
    "actor_loss": -62.14608383178711,
    "critic_loss": 12.930517196655273,
    "ent_coef": 0.09299076348543167,
    "learning_rate": 0.001
  },
  {
    "episode": 5259,
    "reward": 84.359493,
    "length": 75,
    "time": 81102.612933,
    "actor_loss": -65.07464599609375,
    "critic_loss": 8.738203048706055,
    "ent_coef": 0.08894077688455582,
    "learning_rate": 0.001
  },
  {
    "episode": 5260,
    "reward": 89.792511,
    "length": 63,
    "time": 81116.226497,
    "actor_loss": -55.70164489746094,
    "critic_loss": 6.748162269592285,
    "ent_coef": 0.08748560398817062,
    "learning_rate": 0.001
  },
  {
    "episode": 5261,
    "reward": 87.567854,
    "length": 66,
    "time": 81129.75062,
    "actor_loss": -63.04957580566406,
    "critic_loss": 12.149023056030273,
    "ent_coef": 0.0879746824502945,
    "learning_rate": 0.001
  },
  {
    "episode": 5262,
    "reward": 89.40046,
    "length": 65,
    "time": 81141.584468,
    "actor_loss": -58.37224578857422,
    "critic_loss": 4.614309310913086,
    "ent_coef": 0.08740464597940445,
    "learning_rate": 0.001
  },
  {
    "episode": 5263,
    "reward": 85.893328,
    "length": 73,
    "time": 81155.122854,
    "actor_loss": -60.795631408691406,
    "critic_loss": 60.110816955566406,
    "ent_coef": 0.08643574267625809,
    "learning_rate": 0.001
  },
  {
    "episode": 5264,
    "reward": 89.58553,
    "length": 65,
    "time": 81168.557005,
    "actor_loss": -65.236083984375,
    "critic_loss": 20.168262481689453,
    "ent_coef": 0.08580803126096725,
    "learning_rate": 0.001
  },
  {
    "episode": 5265,
    "reward": 86.826636,
    "length": 69,
    "time": 81182.413946,
    "actor_loss": -65.93834686279297,
    "critic_loss": 43.708900451660156,
    "ent_coef": 0.08219145238399506,
    "learning_rate": 0.001
  },
  {
    "episode": 5266,
    "reward": 87.023285,
    "length": 68,
    "time": 81193.988312,
    "actor_loss": -68.30621337890625,
    "critic_loss": 228.08477783203125,
    "ent_coef": 0.07854840904474258,
    "learning_rate": 0.001
  },
  {
    "episode": 5267,
    "reward": 87.859337,
    "length": 67,
    "time": 81207.974846,
    "actor_loss": -67.0810775756836,
    "critic_loss": 5.834814071655273,
    "ent_coef": 0.07843217998743057,
    "learning_rate": 0.001
  },
  {
    "episode": 5268,
    "reward": 90.139088,
    "length": 62,
    "time": 81219.480591,
    "actor_loss": -62.924503326416016,
    "critic_loss": 13.410604476928711,
    "ent_coef": 0.08146502822637558,
    "learning_rate": 0.001
  },
  {
    "episode": 5269,
    "reward": 85.422108,
    "length": 73,
    "time": 81233.711174,
    "actor_loss": -63.74797058105469,
    "critic_loss": 2.9189987182617188,
    "ent_coef": 0.08137569576501846,
    "learning_rate": 0.001
  },
  {
    "episode": 5270,
    "reward": 88.774654,
    "length": 65,
    "time": 81244.942743,
    "actor_loss": -62.6269645690918,
    "critic_loss": 39.01453399658203,
    "ent_coef": 0.07982522994279861,
    "learning_rate": 0.001
  },
  {
    "episode": 5271,
    "reward": 83.740303,
    "length": 75,
    "time": 81258.097736,
    "actor_loss": -60.36450958251953,
    "critic_loss": 9.812146186828613,
    "ent_coef": 0.07549142092466354,
    "learning_rate": 0.001
  },
  {
    "episode": 5272,
    "reward": 89.444659,
    "length": 63,
    "time": 81269.912982,
    "actor_loss": -67.31094360351562,
    "critic_loss": 9.57478141784668,
    "ent_coef": 0.07849255949258804,
    "learning_rate": 0.001
  },
  {
    "episode": 5273,
    "reward": 91.178453,
    "length": 60,
    "time": 81283.199464,
    "actor_loss": -64.23930358886719,
    "critic_loss": 10.799165725708008,
    "ent_coef": 0.08191543817520142,
    "learning_rate": 0.001
  },
  {
    "episode": 5274,
    "reward": 86.940839,
    "length": 67,
    "time": 81294.676081,
    "actor_loss": -63.10379409790039,
    "critic_loss": 7.374611854553223,
    "ent_coef": 0.08606742322444916,
    "learning_rate": 0.001
  },
  {
    "episode": 5275,
    "reward": 89.60487,
    "length": 64,
    "time": 81305.92647,
    "actor_loss": -60.57004165649414,
    "critic_loss": 13.156511306762695,
    "ent_coef": 0.08723949640989304,
    "learning_rate": 0.001
  },
  {
    "episode": 5276,
    "reward": 87.153326,
    "length": 67,
    "time": 81320.307324,
    "actor_loss": -67.44599914550781,
    "critic_loss": 36.11369705200195,
    "ent_coef": 0.08779700845479965,
    "learning_rate": 0.001
  },
  {
    "episode": 5277,
    "reward": 85.35938,
    "length": 72,
    "time": 81332.699495,
    "actor_loss": -68.7059555053711,
    "critic_loss": 32.650238037109375,
    "ent_coef": 0.08965037018060684,
    "learning_rate": 0.001
  },
  {
    "episode": 5278,
    "reward": 89.873197,
    "length": 63,
    "time": 81343.560596,
    "actor_loss": -56.76240921020508,
    "critic_loss": 11.583003044128418,
    "ent_coef": 0.0910235270857811,
    "learning_rate": 0.001
  },
  {
    "episode": 5279,
    "reward": 84.704341,
    "length": 73,
    "time": 81356.085701,
    "actor_loss": -66.77464294433594,
    "critic_loss": 12.430122375488281,
    "ent_coef": 0.0843905359506607,
    "learning_rate": 0.001
  },
  {
    "episode": 5280,
    "reward": 87.556959,
    "length": 69,
    "time": 81370.129457,
    "actor_loss": -65.05708312988281,
    "critic_loss": 27.809175491333008,
    "ent_coef": 0.08082911372184753,
    "learning_rate": 0.001
  },
  {
    "episode": 5281,
    "reward": 89.263908,
    "length": 65,
    "time": 81381.527908,
    "actor_loss": -67.22554016113281,
    "critic_loss": 67.05838012695312,
    "ent_coef": 0.07885156571865082,
    "learning_rate": 0.001
  },
  {
    "episode": 5282,
    "reward": 89.18387,
    "length": 65,
    "time": 81396.765916,
    "actor_loss": -64.90837860107422,
    "critic_loss": 4.267626762390137,
    "ent_coef": 0.07956231385469437,
    "learning_rate": 0.001
  },
  {
    "episode": 5283,
    "reward": 88.845392,
    "length": 66,
    "time": 81410.127176,
    "actor_loss": -62.06956481933594,
    "critic_loss": 16.276084899902344,
    "ent_coef": 0.07778061181306839,
    "learning_rate": 0.001
  },
  {
    "episode": 5284,
    "reward": 88.322886,
    "length": 66,
    "time": 81421.507392,
    "actor_loss": -64.56291198730469,
    "critic_loss": 39.78828430175781,
    "ent_coef": 0.07797466218471527,
    "learning_rate": 0.001
  },
  {
    "episode": 5285,
    "reward": 88.483399,
    "length": 66,
    "time": 81435.899037,
    "actor_loss": -63.316261291503906,
    "critic_loss": 15.488859176635742,
    "ent_coef": 0.07827045768499374,
    "learning_rate": 0.001
  },
  {
    "episode": 5286,
    "reward": 87.314644,
    "length": 68,
    "time": 81448.229835,
    "actor_loss": -69.41754150390625,
    "critic_loss": 11.274295806884766,
    "ent_coef": 0.07753778994083405,
    "learning_rate": 0.001
  },
  {
    "episode": 5287,
    "reward": 90.041289,
    "length": 63,
    "time": 81460.562569,
    "actor_loss": -69.64852142333984,
    "critic_loss": 53.64667510986328,
    "ent_coef": 0.07831034809350967,
    "learning_rate": 0.001
  },
  {
    "episode": 5288,
    "reward": 86.846426,
    "length": 70,
    "time": 81473.514321,
    "actor_loss": -64.75509643554688,
    "critic_loss": 20.995319366455078,
    "ent_coef": 0.07925137877464294,
    "learning_rate": 0.001
  },
  {
    "episode": 5289,
    "reward": 87.078659,
    "length": 69,
    "time": 81485.014596,
    "actor_loss": -56.6883544921875,
    "critic_loss": 45.79326629638672,
    "ent_coef": 0.07739086449146271,
    "learning_rate": 0.001
  },
  {
    "episode": 5290,
    "reward": 83.042133,
    "length": 74,
    "time": 81499.333443,
    "actor_loss": -62.89438247680664,
    "critic_loss": 11.901517868041992,
    "ent_coef": 0.07654095441102982,
    "learning_rate": 0.001
  },
  {
    "episode": 5291,
    "reward": 87.53438,
    "length": 66,
    "time": 81511.579151,
    "actor_loss": -67.98589324951172,
    "critic_loss": 42.0611572265625,
    "ent_coef": 0.07648474723100662,
    "learning_rate": 0.001
  },
  {
    "episode": 5292,
    "reward": 88.276242,
    "length": 67,
    "time": 81525.036717,
    "actor_loss": -63.9327392578125,
    "critic_loss": 9.528526306152344,
    "ent_coef": 0.07849138230085373,
    "learning_rate": 0.001
  },
  {
    "episode": 5293,
    "reward": 35.212317,
    "length": 159,
    "time": 81548.689388,
    "actor_loss": -62.28329849243164,
    "critic_loss": 631.5365600585938,
    "ent_coef": 0.08097966760396957,
    "learning_rate": 0.001
  },
  {
    "episode": 5294,
    "reward": 85.1213,
    "length": 71,
    "time": 81562.531952,
    "actor_loss": -67.29493713378906,
    "critic_loss": 5.258133411407471,
    "ent_coef": 0.08430850505828857,
    "learning_rate": 0.001
  },
  {
    "episode": 5295,
    "reward": 86.688218,
    "length": 69,
    "time": 81576.412704,
    "actor_loss": -66.309814453125,
    "critic_loss": 53.681068420410156,
    "ent_coef": 0.08089783042669296,
    "learning_rate": 0.001
  },
  {
    "episode": 5296,
    "reward": 82.354688,
    "length": 81,
    "time": 81590.923455,
    "actor_loss": -59.78084945678711,
    "critic_loss": 74.49018859863281,
    "ent_coef": 0.07552914321422577,
    "learning_rate": 0.001
  },
  {
    "episode": 5297,
    "reward": 33.624108,
    "length": 145,
    "time": 81615.245648,
    "actor_loss": -69.33358764648438,
    "critic_loss": 47.36192321777344,
    "ent_coef": 0.06502440571784973,
    "learning_rate": 0.001
  },
  {
    "episode": 5298,
    "reward": 38.728121,
    "length": 143,
    "time": 81636.521993,
    "actor_loss": -58.28211975097656,
    "critic_loss": 8.578560829162598,
    "ent_coef": 0.06412959843873978,
    "learning_rate": 0.001
  },
  {
    "episode": 5299,
    "reward": 90.298379,
    "length": 63,
    "time": 81648.667916,
    "actor_loss": -60.737464904785156,
    "critic_loss": 5.70042085647583,
    "ent_coef": 0.06807861477136612,
    "learning_rate": 0.001
  },
  {
    "episode": 5300,
    "reward": 88.261274,
    "length": 69,
    "time": 81662.580447,
    "actor_loss": -65.93128967285156,
    "critic_loss": 24.83559226989746,
    "ent_coef": 0.0705806165933609,
    "learning_rate": 0.001
  },
  {
    "episode": 5301,
    "reward": 87.034854,
    "length": 68,
    "time": 81674.683314,
    "actor_loss": -66.70349884033203,
    "critic_loss": 76.13059997558594,
    "ent_coef": 0.0725095346570015,
    "learning_rate": 0.001
  },
  {
    "episode": 5302,
    "reward": 80.151076,
    "length": 83,
    "time": 81690.730124,
    "actor_loss": -66.25385284423828,
    "critic_loss": 7.499965667724609,
    "ent_coef": 0.07252100110054016,
    "learning_rate": 0.001
  },
  {
    "episode": 5303,
    "reward": 87.119625,
    "length": 67,
    "time": 81705.168993,
    "actor_loss": -63.20466613769531,
    "critic_loss": 91.49839782714844,
    "ent_coef": 0.075105682015419,
    "learning_rate": 0.001
  },
  {
    "episode": 5304,
    "reward": 90.337675,
    "length": 62,
    "time": 81717.330821,
    "actor_loss": -66.46257019042969,
    "critic_loss": 25.161266326904297,
    "ent_coef": 0.07813848555088043,
    "learning_rate": 0.001
  },
  {
    "episode": 5305,
    "reward": 91.354687,
    "length": 60,
    "time": 81728.04267,
    "actor_loss": -61.10615539550781,
    "critic_loss": 8.662714004516602,
    "ent_coef": 0.08351707458496094,
    "learning_rate": 0.001
  },
  {
    "episode": 5306,
    "reward": 90.019926,
    "length": 63,
    "time": 81738.962562,
    "actor_loss": -59.70267868041992,
    "critic_loss": 73.5817642211914,
    "ent_coef": 0.08730732649564743,
    "learning_rate": 0.001
  },
  {
    "episode": 5307,
    "reward": 88.095206,
    "length": 68,
    "time": 81750.327301,
    "actor_loss": -67.61278533935547,
    "critic_loss": 34.456764221191406,
    "ent_coef": 0.09195856750011444,
    "learning_rate": 0.001
  },
  {
    "episode": 5308,
    "reward": 86.823068,
    "length": 67,
    "time": 81762.018793,
    "actor_loss": -68.33045959472656,
    "critic_loss": 28.828937530517578,
    "ent_coef": 0.09086371213197708,
    "learning_rate": 0.001
  },
  {
    "episode": 5309,
    "reward": 81.187246,
    "length": 77,
    "time": 81774.686837,
    "actor_loss": -67.02894592285156,
    "critic_loss": 11.564447402954102,
    "ent_coef": 0.08587662875652313,
    "learning_rate": 0.001
  },
  {
    "episode": 5310,
    "reward": 82.880704,
    "length": 74,
    "time": 81787.828592,
    "actor_loss": -60.795101165771484,
    "critic_loss": 44.78700637817383,
    "ent_coef": 0.08488823473453522,
    "learning_rate": 0.001
  },
  {
    "episode": 5311,
    "reward": 86.379344,
    "length": 69,
    "time": 81802.423558,
    "actor_loss": -60.78715896606445,
    "critic_loss": 31.516250610351562,
    "ent_coef": 0.08322817087173462,
    "learning_rate": 0.001
  },
  {
    "episode": 5312,
    "reward": 84.325308,
    "length": 74,
    "time": 81814.867832,
    "actor_loss": -62.403934478759766,
    "critic_loss": 13.554252624511719,
    "ent_coef": 0.08423032611608505,
    "learning_rate": 0.001
  },
  {
    "episode": 5313,
    "reward": 90.312322,
    "length": 63,
    "time": 81829.052678,
    "actor_loss": -69.6319580078125,
    "critic_loss": 76.33045959472656,
    "ent_coef": 0.08627278357744217,
    "learning_rate": 0.001
  },
  {
    "episode": 5314,
    "reward": 87.366075,
    "length": 69,
    "time": 81840.607164,
    "actor_loss": -67.30667114257812,
    "critic_loss": 5.804867744445801,
    "ent_coef": 0.08773589134216309,
    "learning_rate": 0.001
  },
  {
    "episode": 5315,
    "reward": 86.305183,
    "length": 70,
    "time": 81854.870249,
    "actor_loss": -61.9970703125,
    "critic_loss": 10.838876724243164,
    "ent_coef": 0.08445079624652863,
    "learning_rate": 0.001
  },
  {
    "episode": 5316,
    "reward": 80.02129,
    "length": 88,
    "time": 81868.819056,
    "actor_loss": -66.36373901367188,
    "critic_loss": 6.00941801071167,
    "ent_coef": 0.08124195039272308,
    "learning_rate": 0.001
  },
  {
    "episode": 5317,
    "reward": 84.97276,
    "length": 77,
    "time": 81883.382279,
    "actor_loss": -65.80757904052734,
    "critic_loss": 107.9476318359375,
    "ent_coef": 0.08123081177473068,
    "learning_rate": 0.001
  },
  {
    "episode": 5318,
    "reward": 89.819628,
    "length": 62,
    "time": 81897.292017,
    "actor_loss": -62.55198287963867,
    "critic_loss": 23.558683395385742,
    "ent_coef": 0.0853879526257515,
    "learning_rate": 0.001
  },
  {
    "episode": 5319,
    "reward": 88.82553,
    "length": 67,
    "time": 81910.504031,
    "actor_loss": -67.76981353759766,
    "critic_loss": 56.11497497558594,
    "ent_coef": 0.08514318615198135,
    "learning_rate": 0.001
  },
  {
    "episode": 5320,
    "reward": 88.226804,
    "length": 70,
    "time": 81922.570668,
    "actor_loss": -66.31108856201172,
    "critic_loss": 20.902542114257812,
    "ent_coef": 0.09369397908449173,
    "learning_rate": 0.001
  },
  {
    "episode": 5321,
    "reward": 86.757106,
    "length": 71,
    "time": 81937.310178,
    "actor_loss": -63.92026901245117,
    "critic_loss": 8.894405364990234,
    "ent_coef": 0.09486757963895798,
    "learning_rate": 0.001
  },
  {
    "episode": 5322,
    "reward": 87.828212,
    "length": 69,
    "time": 81951.520151,
    "actor_loss": -70.92817687988281,
    "critic_loss": 10.058595657348633,
    "ent_coef": 0.0933789387345314,
    "learning_rate": 0.001
  },
  {
    "episode": 5323,
    "reward": 87.958308,
    "length": 69,
    "time": 81963.105266,
    "actor_loss": -64.9646987915039,
    "critic_loss": 9.771684646606445,
    "ent_coef": 0.09238258004188538,
    "learning_rate": 0.001
  },
  {
    "episode": 5324,
    "reward": 82.394368,
    "length": 78,
    "time": 81977.569085,
    "actor_loss": -69.29761505126953,
    "critic_loss": 51.885719299316406,
    "ent_coef": 0.0915374681353569,
    "learning_rate": 0.001
  },
  {
    "episode": 5325,
    "reward": 89.175177,
    "length": 66,
    "time": 81990.951066,
    "actor_loss": -71.56575012207031,
    "critic_loss": 70.55931854248047,
    "ent_coef": 0.09378865361213684,
    "learning_rate": 0.001
  },
  {
    "episode": 5326,
    "reward": 91.351411,
    "length": 60,
    "time": 82003.527846,
    "actor_loss": -68.25743103027344,
    "critic_loss": 916.1705322265625,
    "ent_coef": 0.09552527964115143,
    "learning_rate": 0.001
  },
  {
    "episode": 5327,
    "reward": 87.267219,
    "length": 67,
    "time": 82018.241122,
    "actor_loss": -68.25556945800781,
    "critic_loss": 17.139007568359375,
    "ent_coef": 0.09276483207941055,
    "learning_rate": 0.001
  },
  {
    "episode": 5328,
    "reward": 90.499053,
    "length": 62,
    "time": 82031.053752,
    "actor_loss": -66.84272766113281,
    "critic_loss": 14.163570404052734,
    "ent_coef": 0.09235282987356186,
    "learning_rate": 0.001
  },
  {
    "episode": 5329,
    "reward": 89.472508,
    "length": 63,
    "time": 82042.693206,
    "actor_loss": -64.78215026855469,
    "critic_loss": 31.849233627319336,
    "ent_coef": 0.09231828898191452,
    "learning_rate": 0.001
  },
  {
    "episode": 5330,
    "reward": 90.823261,
    "length": 62,
    "time": 82054.371253,
    "actor_loss": -71.13697814941406,
    "critic_loss": 11.572877883911133,
    "ent_coef": 0.09366530179977417,
    "learning_rate": 0.001
  },
  {
    "episode": 5331,
    "reward": 86.223934,
    "length": 71,
    "time": 82066.919337,
    "actor_loss": -65.8906478881836,
    "critic_loss": 3.37619948387146,
    "ent_coef": 0.0904998630285263,
    "learning_rate": 0.001
  },
  {
    "episode": 5332,
    "reward": 88.250494,
    "length": 69,
    "time": 82081.624009,
    "actor_loss": -71.54165649414062,
    "critic_loss": 22.904827117919922,
    "ent_coef": 0.09253955632448196,
    "learning_rate": 0.001
  },
  {
    "episode": 5333,
    "reward": 87.864004,
    "length": 69,
    "time": 82099.613843,
    "actor_loss": -72.78184509277344,
    "critic_loss": 15.708831787109375,
    "ent_coef": 0.09159203618764877,
    "learning_rate": 0.001
  },
  {
    "episode": 5334,
    "reward": 89.911377,
    "length": 64,
    "time": 82112.675184,
    "actor_loss": -62.78245544433594,
    "critic_loss": 6.093650817871094,
    "ent_coef": 0.0884837731719017,
    "learning_rate": 0.001
  },
  {
    "episode": 5335,
    "reward": 83.674064,
    "length": 74,
    "time": 82125.09679,
    "actor_loss": -58.40973663330078,
    "critic_loss": 29.67949676513672,
    "ent_coef": 0.0840885266661644,
    "learning_rate": 0.001
  },
  {
    "episode": 5336,
    "reward": 80.618642,
    "length": 114,
    "time": 82146.187885,
    "actor_loss": -63.1446418762207,
    "critic_loss": 8.653763771057129,
    "ent_coef": 0.08742530643939972,
    "learning_rate": 0.001
  },
  {
    "episode": 5337,
    "reward": 88.853851,
    "length": 62,
    "time": 82156.981927,
    "actor_loss": -65.20148468017578,
    "critic_loss": 18.766616821289062,
    "ent_coef": 0.08924365788698196,
    "learning_rate": 0.001
  },
  {
    "episode": 5338,
    "reward": 87.452458,
    "length": 71,
    "time": 82169.946136,
    "actor_loss": -72.99024963378906,
    "critic_loss": 20.129383087158203,
    "ent_coef": 0.0906844437122345,
    "learning_rate": 0.001
  },
  {
    "episode": 5339,
    "reward": 89.266485,
    "length": 65,
    "time": 82181.812592,
    "actor_loss": -67.26192474365234,
    "critic_loss": 20.56144905090332,
    "ent_coef": 0.09033456444740295,
    "learning_rate": 0.001
  },
  {
    "episode": 5340,
    "reward": 87.639447,
    "length": 72,
    "time": 82194.831706,
    "actor_loss": -65.20924377441406,
    "critic_loss": 16.552656173706055,
    "ent_coef": 0.09052152931690216,
    "learning_rate": 0.001
  },
  {
    "episode": 5341,
    "reward": 87.035281,
    "length": 69,
    "time": 82207.428238,
    "actor_loss": -67.81686401367188,
    "critic_loss": 20.529869079589844,
    "ent_coef": 0.08804113417863846,
    "learning_rate": 0.001
  },
  {
    "episode": 5342,
    "reward": 84.565219,
    "length": 75,
    "time": 82221.11085,
    "actor_loss": -64.87914276123047,
    "critic_loss": 111.97743225097656,
    "ent_coef": 0.0833294540643692,
    "learning_rate": 0.001
  },
  {
    "episode": 5343,
    "reward": 87.275678,
    "length": 71,
    "time": 82233.026103,
    "actor_loss": -75.87673950195312,
    "critic_loss": 34.52900695800781,
    "ent_coef": 0.08214592188596725,
    "learning_rate": 0.001
  },
  {
    "episode": 5344,
    "reward": 89.54589,
    "length": 64,
    "time": 82245.083038,
    "actor_loss": -64.50883483886719,
    "critic_loss": 156.48260498046875,
    "ent_coef": 0.08539951592683792,
    "learning_rate": 0.001
  },
  {
    "episode": 5345,
    "reward": 89.29467,
    "length": 67,
    "time": 82259.305475,
    "actor_loss": -66.98982238769531,
    "critic_loss": 68.92308044433594,
    "ent_coef": 0.08942599594593048,
    "learning_rate": 0.001
  },
  {
    "episode": 5346,
    "reward": 90.410861,
    "length": 63,
    "time": 82270.265065,
    "actor_loss": -72.86954498291016,
    "critic_loss": 19.98223876953125,
    "ent_coef": 0.08897032588720322,
    "learning_rate": 0.001
  },
  {
    "episode": 5347,
    "reward": 79.279503,
    "length": 115,
    "time": 82291.304222,
    "actor_loss": -73.6076431274414,
    "critic_loss": 677.21728515625,
    "ent_coef": 0.0901307538151741,
    "learning_rate": 0.001
  },
  {
    "episode": 5348,
    "reward": 81.97306,
    "length": 79,
    "time": 82305.66036,
    "actor_loss": -68.89997863769531,
    "critic_loss": 24.68885040283203,
    "ent_coef": 0.08839123696088791,
    "learning_rate": 0.001
  },
  {
    "episode": 5349,
    "reward": 88.603618,
    "length": 67,
    "time": 82319.347782,
    "actor_loss": -67.36135864257812,
    "critic_loss": 6.026128768920898,
    "ent_coef": 0.08644285053014755,
    "learning_rate": 0.001
  },
  {
    "episode": 5350,
    "reward": 88.355905,
    "length": 66,
    "time": 82332.104513,
    "actor_loss": -75.66239929199219,
    "critic_loss": 67.5982894897461,
    "ent_coef": 0.08412957936525345,
    "learning_rate": 0.001
  },
  {
    "episode": 5351,
    "reward": 90.309665,
    "length": 63,
    "time": 82347.087672,
    "actor_loss": -71.4512939453125,
    "critic_loss": 48.87708282470703,
    "ent_coef": 0.08449093252420425,
    "learning_rate": 0.001
  },
  {
    "episode": 5352,
    "reward": 89.005987,
    "length": 67,
    "time": 82358.89745,
    "actor_loss": -65.40029907226562,
    "critic_loss": 20.83155059814453,
    "ent_coef": 0.08810984343290329,
    "learning_rate": 0.001
  },
  {
    "episode": 5353,
    "reward": 79.854409,
    "length": 83,
    "time": 82375.267069,
    "actor_loss": -70.90106201171875,
    "critic_loss": 19.836441040039062,
    "ent_coef": 0.0917147845029831,
    "learning_rate": 0.001
  },
  {
    "episode": 5354,
    "reward": 88.745448,
    "length": 67,
    "time": 82387.113324,
    "actor_loss": -57.5731201171875,
    "critic_loss": 8.38471794128418,
    "ent_coef": 0.09657236933708191,
    "learning_rate": 0.001
  },
  {
    "episode": 5355,
    "reward": 80.4193,
    "length": 81,
    "time": 82401.098435,
    "actor_loss": -66.77105712890625,
    "critic_loss": 23.461807250976562,
    "ent_coef": 0.09877230226993561,
    "learning_rate": 0.001
  },
  {
    "episode": 5356,
    "reward": 84.75244,
    "length": 73,
    "time": 82413.309415,
    "actor_loss": -71.7502670288086,
    "critic_loss": 14.950637817382812,
    "ent_coef": 0.09406308829784393,
    "learning_rate": 0.001
  },
  {
    "episode": 5357,
    "reward": 81.253295,
    "length": 74,
    "time": 82425.611981,
    "actor_loss": -67.53059387207031,
    "critic_loss": 11.877193450927734,
    "ent_coef": 0.09446661174297333,
    "learning_rate": 0.001
  },
  {
    "episode": 5358,
    "reward": 85.246021,
    "length": 76,
    "time": 82441.446269,
    "actor_loss": -66.8397216796875,
    "critic_loss": 5.066280841827393,
    "ent_coef": 0.09427222609519958,
    "learning_rate": 0.001
  },
  {
    "episode": 5359,
    "reward": 90.424878,
    "length": 62,
    "time": 82453.956543,
    "actor_loss": -64.9556884765625,
    "critic_loss": 8.240659713745117,
    "ent_coef": 0.09460683166980743,
    "learning_rate": 0.001
  },
  {
    "episode": 5360,
    "reward": 81.667346,
    "length": 82,
    "time": 82469.955126,
    "actor_loss": -66.85289001464844,
    "critic_loss": 61.323978424072266,
    "ent_coef": 0.09519366174936295,
    "learning_rate": 0.001
  },
  {
    "episode": 5361,
    "reward": 77.940019,
    "length": 93,
    "time": 82485.829902,
    "actor_loss": -66.32215881347656,
    "critic_loss": 17.768274307250977,
    "ent_coef": 0.10275585204362869,
    "learning_rate": 0.001
  },
  {
    "episode": 5362,
    "reward": 85.863407,
    "length": 82,
    "time": 82500.028269,
    "actor_loss": -63.97920608520508,
    "critic_loss": 78.1964340209961,
    "ent_coef": 0.10526012629270554,
    "learning_rate": 0.001
  },
  {
    "episode": 5363,
    "reward": 89.758092,
    "length": 63,
    "time": 82512.87207,
    "actor_loss": -62.90205383300781,
    "critic_loss": 33.841835021972656,
    "ent_coef": 0.1060909777879715,
    "learning_rate": 0.001
  },
  {
    "episode": 5364,
    "reward": 80.948562,
    "length": 81,
    "time": 82528.430944,
    "actor_loss": -65.76165771484375,
    "critic_loss": 21.357633590698242,
    "ent_coef": 0.09580083936452866,
    "learning_rate": 0.001
  },
  {
    "episode": 5365,
    "reward": 83.705428,
    "length": 73,
    "time": 82541.988411,
    "actor_loss": -78.54948425292969,
    "critic_loss": 173.56552124023438,
    "ent_coef": 0.09002500027418137,
    "learning_rate": 0.001
  },
  {
    "episode": 5366,
    "reward": 80.976514,
    "length": 81,
    "time": 82554.998783,
    "actor_loss": -72.2028579711914,
    "critic_loss": 28.907514572143555,
    "ent_coef": 0.08509282022714615,
    "learning_rate": 0.001
  },
  {
    "episode": 5367,
    "reward": 84.399835,
    "length": 72,
    "time": 82568.031488,
    "actor_loss": -72.95409393310547,
    "critic_loss": 112.24662017822266,
    "ent_coef": 0.08050136268138885,
    "learning_rate": 0.001
  },
  {
    "episode": 5368,
    "reward": 84.667057,
    "length": 85,
    "time": 82584.605178,
    "actor_loss": -70.98626708984375,
    "critic_loss": 2478.880126953125,
    "ent_coef": 0.07977210730314255,
    "learning_rate": 0.001
  },
  {
    "episode": 5369,
    "reward": 81.976436,
    "length": 75,
    "time": 82601.434797,
    "actor_loss": -62.174312591552734,
    "critic_loss": 12.60440731048584,
    "ent_coef": 0.08002346009016037,
    "learning_rate": 0.001
  },
  {
    "episode": 5370,
    "reward": 89.426689,
    "length": 63,
    "time": 82612.302487,
    "actor_loss": -73.84639739990234,
    "critic_loss": 76.82139587402344,
    "ent_coef": 0.08634696900844574,
    "learning_rate": 0.001
  },
  {
    "episode": 5371,
    "reward": 87.412005,
    "length": 66,
    "time": 82624.414093,
    "actor_loss": -69.164794921875,
    "critic_loss": 47.51535415649414,
    "ent_coef": 0.08781716972589493,
    "learning_rate": 0.001
  },
  {
    "episode": 5372,
    "reward": 81.296633,
    "length": 83,
    "time": 82638.83725,
    "actor_loss": -67.64776611328125,
    "critic_loss": 19.381877899169922,
    "ent_coef": 0.08543077111244202,
    "learning_rate": 0.001
  },
  {
    "episode": 5373,
    "reward": -176.842607,
    "length": 172,
    "time": 82664.677523,
    "actor_loss": -78.41832733154297,
    "critic_loss": 80.98336791992188,
    "ent_coef": 0.07731650769710541,
    "learning_rate": 0.001
  },
  {
    "episode": 5374,
    "reward": 87.852352,
    "length": 74,
    "time": 82679.113523,
    "actor_loss": -69.7824935913086,
    "critic_loss": 12.790218353271484,
    "ent_coef": 0.08749192953109741,
    "learning_rate": 0.001
  },
  {
    "episode": 5375,
    "reward": 90.714008,
    "length": 61,
    "time": 82689.854099,
    "actor_loss": -65.14649200439453,
    "critic_loss": 5.3221330642700195,
    "ent_coef": 0.09257389605045319,
    "learning_rate": 0.001
  },
  {
    "episode": 5376,
    "reward": 45.045813,
    "length": 134,
    "time": 82710.211975,
    "actor_loss": -69.12955474853516,
    "critic_loss": 67.48097229003906,
    "ent_coef": 0.08595795184373856,
    "learning_rate": 0.001
  },
  {
    "episode": 5377,
    "reward": 88.452965,
    "length": 66,
    "time": 82725.970456,
    "actor_loss": -68.27005767822266,
    "critic_loss": 88.46534729003906,
    "ent_coef": 0.08648403733968735,
    "learning_rate": 0.001
  },
  {
    "episode": 5378,
    "reward": 86.042361,
    "length": 76,
    "time": 82740.421181,
    "actor_loss": -63.784523010253906,
    "critic_loss": 4.096657752990723,
    "ent_coef": 0.08702518790960312,
    "learning_rate": 0.001
  },
  {
    "episode": 5379,
    "reward": 89.23043,
    "length": 64,
    "time": 82751.808827,
    "actor_loss": -82.10028076171875,
    "critic_loss": 34.17131805419922,
    "ent_coef": 0.08966845273971558,
    "learning_rate": 0.001
  },
  {
    "episode": 5380,
    "reward": 53.733485,
    "length": 182,
    "time": 82778.76245,
    "actor_loss": -61.432350158691406,
    "critic_loss": 11.93846321105957,
    "ent_coef": 0.08712521195411682,
    "learning_rate": 0.001
  },
  {
    "episode": 5381,
    "reward": 81.93761,
    "length": 87,
    "time": 82794.926484,
    "actor_loss": -60.936092376708984,
    "critic_loss": 12.920980453491211,
    "ent_coef": 0.08986423164606094,
    "learning_rate": 0.001
  },
  {
    "episode": 5382,
    "reward": 82.461068,
    "length": 66,
    "time": 82808.36494,
    "actor_loss": -66.82177734375,
    "critic_loss": 27.231733322143555,
    "ent_coef": 0.09364895522594452,
    "learning_rate": 0.001
  },
  {
    "episode": 5383,
    "reward": 54.771712,
    "length": 117,
    "time": 82827.320604,
    "actor_loss": -63.898033142089844,
    "critic_loss": 14.882942199707031,
    "ent_coef": 0.08943171054124832,
    "learning_rate": 0.001
  },
  {
    "episode": 5384,
    "reward": 35.16875,
    "length": 143,
    "time": 82851.469191,
    "actor_loss": -65.5088882446289,
    "critic_loss": 46.642398834228516,
    "ent_coef": 0.08518806099891663,
    "learning_rate": 0.001
  },
  {
    "episode": 5385,
    "reward": 66.458282,
    "length": 108,
    "time": 82870.853755,
    "actor_loss": -61.13897705078125,
    "critic_loss": 68.84793090820312,
    "ent_coef": 0.10180210322141647,
    "learning_rate": 0.001
  },
  {
    "episode": 5386,
    "reward": 50.747931,
    "length": 172,
    "time": 82896.628058,
    "actor_loss": -69.3009033203125,
    "critic_loss": 62.7091064453125,
    "ent_coef": 0.11861275881528854,
    "learning_rate": 0.001
  },
  {
    "episode": 5387,
    "reward": -62.940372,
    "length": 291,
    "time": 82939.809229,
    "actor_loss": -71.39240264892578,
    "critic_loss": 44.485137939453125,
    "ent_coef": 0.1070103794336319,
    "learning_rate": 0.001
  },
  {
    "episode": 5388,
    "reward": 90.249312,
    "length": 65,
    "time": 82952.834336,
    "actor_loss": -79.78203582763672,
    "critic_loss": 30.198862075805664,
    "ent_coef": 0.1143874078989029,
    "learning_rate": 0.001
  },
  {
    "episode": 5389,
    "reward": 77.786637,
    "length": 75,
    "time": 82966.473195,
    "actor_loss": -66.85226440429688,
    "critic_loss": 106.79287719726562,
    "ent_coef": 0.12300042062997818,
    "learning_rate": 0.001
  },
  {
    "episode": 5390,
    "reward": 84.585306,
    "length": 74,
    "time": 82980.446649,
    "actor_loss": -73.03081512451172,
    "critic_loss": 38.42565155029297,
    "ent_coef": 0.12570786476135254,
    "learning_rate": 0.001
  },
  {
    "episode": 5391,
    "reward": 88.245102,
    "length": 70,
    "time": 82994.070414,
    "actor_loss": -74.87910461425781,
    "critic_loss": 714.8336181640625,
    "ent_coef": 0.1275387853384018,
    "learning_rate": 0.001
  },
  {
    "episode": 5392,
    "reward": 83.997162,
    "length": 73,
    "time": 83007.351355,
    "actor_loss": -89.39139556884766,
    "critic_loss": 27.97857093811035,
    "ent_coef": 0.12528693675994873,
    "learning_rate": 0.001
  },
  {
    "episode": 5393,
    "reward": 76.56594,
    "length": 83,
    "time": 83020.849107,
    "actor_loss": -58.58552932739258,
    "critic_loss": 21.349748611450195,
    "ent_coef": 0.12308042496442795,
    "learning_rate": 0.001
  },
  {
    "episode": 5394,
    "reward": 75.389365,
    "length": 80,
    "time": 83035.225491,
    "actor_loss": -62.160343170166016,
    "critic_loss": 25.534648895263672,
    "ent_coef": 0.1193859651684761,
    "learning_rate": 0.001
  },
  {
    "episode": 5395,
    "reward": 85.598133,
    "length": 70,
    "time": 83048.937334,
    "actor_loss": -72.44882202148438,
    "critic_loss": 31.25438690185547,
    "ent_coef": 0.1172015592455864,
    "learning_rate": 0.001
  },
  {
    "episode": 5396,
    "reward": 76.349032,
    "length": 80,
    "time": 83061.897327,
    "actor_loss": -72.0683822631836,
    "critic_loss": 18.863338470458984,
    "ent_coef": 0.11490341275930405,
    "learning_rate": 0.001
  },
  {
    "episode": 5397,
    "reward": 82.107438,
    "length": 79,
    "time": 83074.957694,
    "actor_loss": -63.214412689208984,
    "critic_loss": 4.668745040893555,
    "ent_coef": 0.11220240592956543,
    "learning_rate": 0.001
  },
  {
    "episode": 5398,
    "reward": 88.576442,
    "length": 64,
    "time": 83086.061495,
    "actor_loss": -70.89028930664062,
    "critic_loss": 103.52572631835938,
    "ent_coef": 0.11104029417037964,
    "learning_rate": 0.001
  },
  {
    "episode": 5399,
    "reward": 68.738065,
    "length": 93,
    "time": 83101.682291,
    "actor_loss": -59.62239456176758,
    "critic_loss": 20.557083129882812,
    "ent_coef": 0.10183599591255188,
    "learning_rate": 0.001
  },
  {
    "episode": 5400,
    "reward": 85.645737,
    "length": 76,
    "time": 83116.054832,
    "actor_loss": -72.99642944335938,
    "critic_loss": 75.15022277832031,
    "ent_coef": 0.10449573397636414,
    "learning_rate": 0.001
  },
  {
    "episode": 5401,
    "reward": 82.708547,
    "length": 66,
    "time": 83130.675682,
    "actor_loss": -76.34182739257812,
    "critic_loss": 179.71717834472656,
    "ent_coef": 0.10894017666578293,
    "learning_rate": 0.001
  },
  {
    "episode": 5402,
    "reward": 74.734538,
    "length": 94,
    "time": 83146.73849,
    "actor_loss": -74.25521850585938,
    "critic_loss": 40.71904373168945,
    "ent_coef": 0.10617369413375854,
    "learning_rate": 0.001
  },
  {
    "episode": 5403,
    "reward": 44.575719,
    "length": 128,
    "time": 83169.000393,
    "actor_loss": -63.9863166809082,
    "critic_loss": 9.684272766113281,
    "ent_coef": 0.09512099623680115,
    "learning_rate": 0.001
  },
  {
    "episode": 5404,
    "reward": 86.363008,
    "length": 68,
    "time": 83183.529754,
    "actor_loss": -74.08328247070312,
    "critic_loss": 44.83451461791992,
    "ent_coef": 0.09407602995634079,
    "learning_rate": 0.001
  },
  {
    "episode": 5405,
    "reward": 88.86337,
    "length": 66,
    "time": 83195.284603,
    "actor_loss": -97.26424407958984,
    "critic_loss": 97.15353393554688,
    "ent_coef": 0.09880480915307999,
    "learning_rate": 0.001
  },
  {
    "episode": 5406,
    "reward": 91.109194,
    "length": 61,
    "time": 83207.148301,
    "actor_loss": -67.86099243164062,
    "critic_loss": 215.16915893554688,
    "ent_coef": 0.10709591209888458,
    "learning_rate": 0.001
  },
  {
    "episode": 5407,
    "reward": 86.592778,
    "length": 68,
    "time": 83219.633364,
    "actor_loss": -79.63406372070312,
    "critic_loss": 56.68296813964844,
    "ent_coef": 0.11653628945350647,
    "learning_rate": 0.001
  },
  {
    "episode": 5408,
    "reward": 87.343337,
    "length": 67,
    "time": 83233.342353,
    "actor_loss": -76.47419738769531,
    "critic_loss": 60.10999298095703,
    "ent_coef": 0.11565252393484116,
    "learning_rate": 0.001
  },
  {
    "episode": 5409,
    "reward": 85.1945,
    "length": 71,
    "time": 83245.836589,
    "actor_loss": -85.595703125,
    "critic_loss": 50.85059356689453,
    "ent_coef": 0.10943523794412613,
    "learning_rate": 0.001
  },
  {
    "episode": 5410,
    "reward": 84.44208,
    "length": 71,
    "time": 83257.910074,
    "actor_loss": -70.33961486816406,
    "critic_loss": 120.1960678100586,
    "ent_coef": 0.10972860455513,
    "learning_rate": 0.001
  },
  {
    "episode": 5411,
    "reward": 74.097671,
    "length": 83,
    "time": 83274.120744,
    "actor_loss": -78.63502502441406,
    "critic_loss": 63.08192443847656,
    "ent_coef": 0.11551219969987869,
    "learning_rate": 0.001
  },
  {
    "episode": 5412,
    "reward": 81.905902,
    "length": 86,
    "time": 83287.932686,
    "actor_loss": -76.68721008300781,
    "critic_loss": 24.68716049194336,
    "ent_coef": 0.1179470643401146,
    "learning_rate": 0.001
  },
  {
    "episode": 5413,
    "reward": 87.883424,
    "length": 72,
    "time": 83301.080142,
    "actor_loss": -99.33392333984375,
    "critic_loss": 93.91018676757812,
    "ent_coef": 0.12400269508361816,
    "learning_rate": 0.001
  },
  {
    "episode": 5414,
    "reward": 77.323141,
    "length": 80,
    "time": 83316.133985,
    "actor_loss": -66.21014404296875,
    "critic_loss": 17.40496826171875,
    "ent_coef": 0.12762998044490814,
    "learning_rate": 0.001
  },
  {
    "episode": 5415,
    "reward": 88.859068,
    "length": 64,
    "time": 83329.245423,
    "actor_loss": -79.88404846191406,
    "critic_loss": 143.3378448486328,
    "ent_coef": 0.12819457054138184,
    "learning_rate": 0.001
  },
  {
    "episode": 5416,
    "reward": 87.869204,
    "length": 67,
    "time": 83342.865947,
    "actor_loss": -63.9267578125,
    "critic_loss": 9.947547912597656,
    "ent_coef": 0.13048554956912994,
    "learning_rate": 0.001
  },
  {
    "episode": 5417,
    "reward": 89.795933,
    "length": 63,
    "time": 83355.082584,
    "actor_loss": -80.75921630859375,
    "critic_loss": 38.710968017578125,
    "ent_coef": 0.12910735607147217,
    "learning_rate": 0.001
  },
  {
    "episode": 5418,
    "reward": 82.649389,
    "length": 82,
    "time": 83369.633568,
    "actor_loss": -66.86620330810547,
    "critic_loss": 50.936038970947266,
    "ent_coef": 0.1240202933549881,
    "learning_rate": 0.001
  },
  {
    "episode": 5419,
    "reward": 76.94808,
    "length": 83,
    "time": 83383.264725,
    "actor_loss": -75.6837158203125,
    "critic_loss": 4647.728515625,
    "ent_coef": 0.1172347292304039,
    "learning_rate": 0.001
  },
  {
    "episode": 5420,
    "reward": 78.879971,
    "length": 87,
    "time": 83398.090569,
    "actor_loss": -88.45101165771484,
    "critic_loss": 68.0517578125,
    "ent_coef": 0.11716087907552719,
    "learning_rate": 0.001
  },
  {
    "episode": 5421,
    "reward": 81.960358,
    "length": 82,
    "time": 83415.387526,
    "actor_loss": -65.6113052368164,
    "critic_loss": 55.37691879272461,
    "ent_coef": 0.11562004685401917,
    "learning_rate": 0.001
  },
  {
    "episode": 5422,
    "reward": 51.381675,
    "length": 123,
    "time": 83436.727124,
    "actor_loss": -75.30499267578125,
    "critic_loss": 43.59442138671875,
    "ent_coef": 0.11334231495857239,
    "learning_rate": 0.001
  },
  {
    "episode": 5423,
    "reward": -164.251667,
    "length": 145,
    "time": 83459.336645,
    "actor_loss": -75.90821838378906,
    "critic_loss": 75.19052124023438,
    "ent_coef": 0.11265451461076736,
    "learning_rate": 0.001
  },
  {
    "episode": 5424,
    "reward": 84.134686,
    "length": 74,
    "time": 83472.396546,
    "actor_loss": -76.19312286376953,
    "critic_loss": 9.358997344970703,
    "ent_coef": 0.11158939450979233,
    "learning_rate": 0.001
  },
  {
    "episode": 5425,
    "reward": 86.047288,
    "length": 69,
    "time": 83484.978842,
    "actor_loss": -69.13154602050781,
    "critic_loss": 12.710826873779297,
    "ent_coef": 0.10756250470876694,
    "learning_rate": 0.001
  },
  {
    "episode": 5426,
    "reward": 37.681688,
    "length": 180,
    "time": 83514.532024,
    "actor_loss": -86.50885009765625,
    "critic_loss": 507.9035339355469,
    "ent_coef": 0.10920701920986176,
    "learning_rate": 0.001
  },
  {
    "episode": 5427,
    "reward": 88.299327,
    "length": 66,
    "time": 83526.945678,
    "actor_loss": -87.39630126953125,
    "critic_loss": 63.51205825805664,
    "ent_coef": 0.1136038601398468,
    "learning_rate": 0.001
  },
  {
    "episode": 5428,
    "reward": 83.0803,
    "length": 84,
    "time": 83542.020658,
    "actor_loss": -81.76800537109375,
    "critic_loss": 68.47467803955078,
    "ent_coef": 0.13234661519527435,
    "learning_rate": 0.001
  },
  {
    "episode": 5429,
    "reward": 84.05692,
    "length": 72,
    "time": 83556.76788,
    "actor_loss": -120.42558288574219,
    "critic_loss": 370.17474365234375,
    "ent_coef": 0.1378510594367981,
    "learning_rate": 0.001
  },
  {
    "episode": 5430,
    "reward": 86.504292,
    "length": 67,
    "time": 83570.619188,
    "actor_loss": -77.30732727050781,
    "critic_loss": 36.366127014160156,
    "ent_coef": 0.1417136788368225,
    "learning_rate": 0.001
  },
  {
    "episode": 5431,
    "reward": 28.156001,
    "length": 260,
    "time": 83615.411949,
    "actor_loss": -104.14617156982422,
    "critic_loss": 84.30319213867188,
    "ent_coef": 0.12212394177913666,
    "learning_rate": 0.001
  },
  {
    "episode": 5432,
    "reward": 77.516189,
    "length": 88,
    "time": 83630.970176,
    "actor_loss": -80.35052490234375,
    "critic_loss": 91.08830261230469,
    "ent_coef": 0.11679362505674362,
    "learning_rate": 0.001
  },
  {
    "episode": 5433,
    "reward": 89.43079,
    "length": 61,
    "time": 83643.28467,
    "actor_loss": -77.50267028808594,
    "critic_loss": 30.29867172241211,
    "ent_coef": 0.12124419957399368,
    "learning_rate": 0.001
  },
  {
    "episode": 5434,
    "reward": 85.038927,
    "length": 71,
    "time": 83656.376958,
    "actor_loss": -76.3017349243164,
    "critic_loss": 40.446510314941406,
    "ent_coef": 0.1236519068479538,
    "learning_rate": 0.001
  },
  {
    "episode": 5435,
    "reward": 83.788711,
    "length": 74,
    "time": 83670.377576,
    "actor_loss": -90.06648254394531,
    "critic_loss": 130.28648376464844,
    "ent_coef": 0.1343875229358673,
    "learning_rate": 0.001
  },
  {
    "episode": 5436,
    "reward": 86.103373,
    "length": 70,
    "time": 83682.494768,
    "actor_loss": -74.71975708007812,
    "critic_loss": 230.80987548828125,
    "ent_coef": 0.1423155665397644,
    "learning_rate": 0.001
  },
  {
    "episode": 5437,
    "reward": 85.805561,
    "length": 70,
    "time": 83694.465685,
    "actor_loss": -85.43832397460938,
    "critic_loss": 389.721435546875,
    "ent_coef": 0.1495627909898758,
    "learning_rate": 0.001
  },
  {
    "episode": 5438,
    "reward": -161.678414,
    "length": 140,
    "time": 83718.706125,
    "actor_loss": -66.71519470214844,
    "critic_loss": 71.66566467285156,
    "ent_coef": 0.14510604739189148,
    "learning_rate": 0.001
  },
  {
    "episode": 5439,
    "reward": 85.73513,
    "length": 77,
    "time": 83731.456307,
    "actor_loss": -89.51564025878906,
    "critic_loss": 85.30298614501953,
    "ent_coef": 0.14078758656978607,
    "learning_rate": 0.001
  },
  {
    "episode": 5440,
    "reward": 85.281449,
    "length": 72,
    "time": 83744.432525,
    "actor_loss": -90.40219116210938,
    "critic_loss": 154.5254669189453,
    "ent_coef": 0.14677128195762634,
    "learning_rate": 0.001
  },
  {
    "episode": 5441,
    "reward": -157.059815,
    "length": 126,
    "time": 83766.373869,
    "actor_loss": -102.3957290649414,
    "critic_loss": 149.20828247070312,
    "ent_coef": 0.1761838048696518,
    "learning_rate": 0.001
  },
  {
    "episode": 5442,
    "reward": 75.873576,
    "length": 86,
    "time": 83781.271657,
    "actor_loss": -92.38401794433594,
    "critic_loss": 6965.50927734375,
    "ent_coef": 0.18680588901042938,
    "learning_rate": 0.001
  },
  {
    "episode": 5443,
    "reward": -196.631636,
    "length": 203,
    "time": 83810.023309,
    "actor_loss": -89.060302734375,
    "critic_loss": 89.82965087890625,
    "ent_coef": 0.16338014602661133,
    "learning_rate": 0.001
  },
  {
    "episode": 5444,
    "reward": 77.387629,
    "length": 100,
    "time": 83827.620192,
    "actor_loss": -96.38617706298828,
    "critic_loss": 95.108154296875,
    "ent_coef": 0.15666234493255615,
    "learning_rate": 0.001
  },
  {
    "episode": 5445,
    "reward": -159.810992,
    "length": 138,
    "time": 83849.616965,
    "actor_loss": -60.6904296875,
    "critic_loss": 33.48944091796875,
    "ent_coef": 0.15648414194583893,
    "learning_rate": 0.001
  },
  {
    "episode": 5446,
    "reward": 82.314211,
    "length": 85,
    "time": 83865.704402,
    "actor_loss": -75.36283874511719,
    "critic_loss": 15.078311920166016,
    "ent_coef": 0.15151436626911163,
    "learning_rate": 0.001
  },
  {
    "episode": 5447,
    "reward": 83.74478,
    "length": 76,
    "time": 83880.137676,
    "actor_loss": -78.86151123046875,
    "critic_loss": 129.71726989746094,
    "ent_coef": 0.15764249861240387,
    "learning_rate": 0.001
  },
  {
    "episode": 5448,
    "reward": 53.436355,
    "length": 122,
    "time": 83899.042639,
    "actor_loss": -83.106689453125,
    "critic_loss": 96.11935424804688,
    "ent_coef": 0.15697191655635834,
    "learning_rate": 0.001
  },
  {
    "episode": 5449,
    "reward": 85.584504,
    "length": 71,
    "time": 83913.058408,
    "actor_loss": -73.29888153076172,
    "critic_loss": 24.86993408203125,
    "ent_coef": 0.17562399804592133,
    "learning_rate": 0.001
  },
  {
    "episode": 5450,
    "reward": 83.040151,
    "length": 74,
    "time": 83930.147906,
    "actor_loss": -68.10668182373047,
    "critic_loss": 34.857643127441406,
    "ent_coef": 0.19039826095104218,
    "learning_rate": 0.001
  },
  {
    "episode": 5451,
    "reward": 65.647668,
    "length": 109,
    "time": 83948.532775,
    "actor_loss": -88.40503692626953,
    "critic_loss": 219.32223510742188,
    "ent_coef": 0.17684753239154816,
    "learning_rate": 0.001
  },
  {
    "episode": 5452,
    "reward": 55.15745,
    "length": 118,
    "time": 83968.058963,
    "actor_loss": -103.96605682373047,
    "critic_loss": 10618.5048828125,
    "ent_coef": 0.1606326699256897,
    "learning_rate": 0.001
  },
  {
    "episode": 5453,
    "reward": 81.46459,
    "length": 85,
    "time": 83983.712513,
    "actor_loss": -93.00013732910156,
    "critic_loss": 96.63865661621094,
    "ent_coef": 0.16561877727508545,
    "learning_rate": 0.001
  },
  {
    "episode": 5454,
    "reward": 69.294939,
    "length": 99,
    "time": 84002.27867,
    "actor_loss": -85.55107116699219,
    "critic_loss": 47.275753021240234,
    "ent_coef": 0.1581544131040573,
    "learning_rate": 0.001
  },
  {
    "episode": 5455,
    "reward": 75.575996,
    "length": 89,
    "time": 84016.517738,
    "actor_loss": -68.0036392211914,
    "critic_loss": 23.979991912841797,
    "ent_coef": 0.1651000678539276,
    "learning_rate": 0.001
  },
  {
    "episode": 5456,
    "reward": 75.52536,
    "length": 86,
    "time": 84030.678845,
    "actor_loss": -84.07072448730469,
    "critic_loss": 28.842449188232422,
    "ent_coef": 0.16464540362358093,
    "learning_rate": 0.001
  },
  {
    "episode": 5457,
    "reward": 77.330271,
    "length": 83,
    "time": 84048.37063,
    "actor_loss": -68.55169677734375,
    "critic_loss": 21.738550186157227,
    "ent_coef": 0.16880397498607635,
    "learning_rate": 0.001
  },
  {
    "episode": 5458,
    "reward": 83.823352,
    "length": 75,
    "time": 84065.36697,
    "actor_loss": -78.6587905883789,
    "critic_loss": 16.955799102783203,
    "ent_coef": 0.18715853989124298,
    "learning_rate": 0.001
  },
  {
    "episode": 5459,
    "reward": 84.300285,
    "length": 74,
    "time": 84079.990577,
    "actor_loss": -71.94621276855469,
    "critic_loss": 26.405019760131836,
    "ent_coef": 0.19102969765663147,
    "learning_rate": 0.001
  },
  {
    "episode": 5460,
    "reward": 69.952827,
    "length": 94,
    "time": 84095.670498,
    "actor_loss": -79.71087646484375,
    "critic_loss": 11.510770797729492,
    "ent_coef": 0.18366718292236328,
    "learning_rate": 0.001
  },
  {
    "episode": 5461,
    "reward": 72.454931,
    "length": 91,
    "time": 84112.471026,
    "actor_loss": -91.860107421875,
    "critic_loss": 83.72346496582031,
    "ent_coef": 0.17938588559627533,
    "learning_rate": 0.001
  },
  {
    "episode": 5462,
    "reward": 70.746709,
    "length": 96,
    "time": 84127.728985,
    "actor_loss": -82.43912506103516,
    "critic_loss": 173.6841278076172,
    "ent_coef": 0.16941827535629272,
    "learning_rate": 0.001
  },
  {
    "episode": 5463,
    "reward": 73.272193,
    "length": 97,
    "time": 84143.879275,
    "actor_loss": -87.589111328125,
    "critic_loss": 184.7186737060547,
    "ent_coef": 0.1598282754421234,
    "learning_rate": 0.001
  },
  {
    "episode": 5464,
    "reward": 55.041886,
    "length": 124,
    "time": 84163.742914,
    "actor_loss": -89.19342041015625,
    "critic_loss": 86.10699462890625,
    "ent_coef": 0.15690840780735016,
    "learning_rate": 0.001
  },
  {
    "episode": 5465,
    "reward": 77.083634,
    "length": 88,
    "time": 84179.148505,
    "actor_loss": -83.1737060546875,
    "critic_loss": 21.167598724365234,
    "ent_coef": 0.15274614095687866,
    "learning_rate": 0.001
  },
  {
    "episode": 5466,
    "reward": 72.527436,
    "length": 95,
    "time": 84196.791628,
    "actor_loss": -84.76957702636719,
    "critic_loss": 46.449317932128906,
    "ent_coef": 0.15519391000270844,
    "learning_rate": 0.001
  },
  {
    "episode": 5467,
    "reward": 69.235844,
    "length": 103,
    "time": 84213.776424,
    "actor_loss": -72.74801635742188,
    "critic_loss": 73.49151611328125,
    "ent_coef": 0.16386455297470093,
    "learning_rate": 0.001
  },
  {
    "episode": 5468,
    "reward": 83.869229,
    "length": 70,
    "time": 84227.915716,
    "actor_loss": -93.1922378540039,
    "critic_loss": 124.6395263671875,
    "ent_coef": 0.16670355200767517,
    "learning_rate": 0.001
  },
  {
    "episode": 5469,
    "reward": 78.286596,
    "length": 88,
    "time": 84246.793992,
    "actor_loss": -80.08477783203125,
    "critic_loss": 135.37088012695312,
    "ent_coef": 0.1680932641029358,
    "learning_rate": 0.001
  },
  {
    "episode": 5470,
    "reward": -71.486687,
    "length": 317,
    "time": 84291.281801,
    "actor_loss": -115.47738647460938,
    "critic_loss": 143.88864135742188,
    "ent_coef": 0.14586566388607025,
    "learning_rate": 0.001
  },
  {
    "episode": 5471,
    "reward": 87.583216,
    "length": 68,
    "time": 84305.988441,
    "actor_loss": -72.0309829711914,
    "critic_loss": 29.493453979492188,
    "ent_coef": 0.1601526141166687,
    "learning_rate": 0.001
  },
  {
    "episode": 5472,
    "reward": 75.244439,
    "length": 117,
    "time": 84323.841562,
    "actor_loss": -83.2259292602539,
    "critic_loss": 84.13960266113281,
    "ent_coef": 0.16597802937030792,
    "learning_rate": 0.001
  },
  {
    "episode": 5473,
    "reward": 85.511481,
    "length": 72,
    "time": 84336.984703,
    "actor_loss": -74.26565551757812,
    "critic_loss": 50.429100036621094,
    "ent_coef": 0.1714104562997818,
    "learning_rate": 0.001
  },
  {
    "episode": 5474,
    "reward": 76.915921,
    "length": 86,
    "time": 84350.699845,
    "actor_loss": -86.33145904541016,
    "critic_loss": 30.48521614074707,
    "ent_coef": 0.17829380929470062,
    "learning_rate": 0.001
  },
  {
    "episode": 5475,
    "reward": 82.44116,
    "length": 80,
    "time": 84364.685071,
    "actor_loss": -89.69119262695312,
    "critic_loss": 15221.392578125,
    "ent_coef": 0.17213082313537598,
    "learning_rate": 0.001
  },
  {
    "episode": 5476,
    "reward": 80.192162,
    "length": 84,
    "time": 84378.608281,
    "actor_loss": -72.50447082519531,
    "critic_loss": 20.025774002075195,
    "ent_coef": 0.1653292328119278,
    "learning_rate": 0.001
  },
  {
    "episode": 5477,
    "reward": 81.733429,
    "length": 79,
    "time": 84392.64033,
    "actor_loss": -74.51773071289062,
    "critic_loss": 27.12305450439453,
    "ent_coef": 0.1612091064453125,
    "learning_rate": 0.001
  },
  {
    "episode": 5478,
    "reward": 78.300525,
    "length": 86,
    "time": 84407.329839,
    "actor_loss": -99.43250274658203,
    "critic_loss": 110.91127014160156,
    "ent_coef": 0.15592220425605774,
    "learning_rate": 0.001
  },
  {
    "episode": 5479,
    "reward": 71.806054,
    "length": 98,
    "time": 84422.737367,
    "actor_loss": -72.58805084228516,
    "critic_loss": 20.503265380859375,
    "ent_coef": 0.15322251617908478,
    "learning_rate": 0.001
  },
  {
    "episode": 5480,
    "reward": 85.665475,
    "length": 73,
    "time": 84436.983749,
    "actor_loss": -72.23460388183594,
    "critic_loss": 23.803699493408203,
    "ent_coef": 0.153967022895813,
    "learning_rate": 0.001
  },
  {
    "episode": 5481,
    "reward": 80.758782,
    "length": 79,
    "time": 84457.232527,
    "actor_loss": -106.7007064819336,
    "critic_loss": 83.13605499267578,
    "ent_coef": 0.1521347463130951,
    "learning_rate": 0.001
  },
  {
    "episode": 5482,
    "reward": 77.277199,
    "length": 88,
    "time": 84473.26951,
    "actor_loss": -109.51526641845703,
    "critic_loss": 104.01410675048828,
    "ent_coef": 0.1424940824508667,
    "learning_rate": 0.001
  },
  {
    "episode": 5483,
    "reward": 47.015786,
    "length": 128,
    "time": 84494.936079,
    "actor_loss": -90.89427185058594,
    "critic_loss": 43.454185485839844,
    "ent_coef": 0.1310320496559143,
    "learning_rate": 0.001
  },
  {
    "episode": 5484,
    "reward": 58.824764,
    "length": 121,
    "time": 84514.562907,
    "actor_loss": -86.09649658203125,
    "critic_loss": 95.72647094726562,
    "ent_coef": 0.11451896280050278,
    "learning_rate": 0.001
  },
  {
    "episode": 5485,
    "reward": -28.083943,
    "length": 240,
    "time": 84547.908015,
    "actor_loss": -104.4418716430664,
    "critic_loss": 105.23981475830078,
    "ent_coef": 0.09309391677379608,
    "learning_rate": 0.001
  },
  {
    "episode": 5486,
    "reward": 76.381486,
    "length": 91,
    "time": 84562.681311,
    "actor_loss": -85.69303894042969,
    "critic_loss": 117.53366088867188,
    "ent_coef": 0.09300114214420319,
    "learning_rate": 0.001
  },
  {
    "episode": 5487,
    "reward": 79.581331,
    "length": 85,
    "time": 84577.640807,
    "actor_loss": -88.45337677001953,
    "critic_loss": 57.81662368774414,
    "ent_coef": 0.09518253803253174,
    "learning_rate": 0.001
  },
  {
    "episode": 5488,
    "reward": 48.212589,
    "length": 131,
    "time": 84598.158889,
    "actor_loss": -82.14106750488281,
    "critic_loss": 58.6585693359375,
    "ent_coef": 0.10574072599411011,
    "learning_rate": 0.001
  },
  {
    "episode": 5489,
    "reward": 77.321573,
    "length": 90,
    "time": 84614.46908,
    "actor_loss": -101.75959014892578,
    "critic_loss": 84.74324798583984,
    "ent_coef": 0.11731346696615219,
    "learning_rate": 0.001
  },
  {
    "episode": 5490,
    "reward": 55.825532,
    "length": 131,
    "time": 84634.773201,
    "actor_loss": -96.20417785644531,
    "critic_loss": 40.91016387939453,
    "ent_coef": 0.11117027699947357,
    "learning_rate": 0.001
  },
  {
    "episode": 5491,
    "reward": -178.318982,
    "length": 192,
    "time": 84662.443969,
    "actor_loss": -110.8566665649414,
    "critic_loss": 83.8834228515625,
    "ent_coef": 0.1220889464020729,
    "learning_rate": 0.001
  },
  {
    "episode": 5492,
    "reward": -2.466306,
    "length": 196,
    "time": 84692.570218,
    "actor_loss": -105.45565032958984,
    "critic_loss": 994.5482788085938,
    "ent_coef": 0.12356829643249512,
    "learning_rate": 0.001
  },
  {
    "episode": 5493,
    "reward": 86.492423,
    "length": 69,
    "time": 84704.683768,
    "actor_loss": -87.647705078125,
    "critic_loss": 24.361576080322266,
    "ent_coef": 0.14347970485687256,
    "learning_rate": 0.001
  },
  {
    "episode": 5494,
    "reward": 86.630915,
    "length": 71,
    "time": 84716.652298,
    "actor_loss": -72.29898071289062,
    "critic_loss": 37.32404327392578,
    "ent_coef": 0.1556292176246643,
    "learning_rate": 0.001
  },
  {
    "episode": 5495,
    "reward": 86.217172,
    "length": 70,
    "time": 84730.547398,
    "actor_loss": -91.62725830078125,
    "critic_loss": 178.9697723388672,
    "ent_coef": 0.16708679497241974,
    "learning_rate": 0.001
  },
  {
    "episode": 5496,
    "reward": 70.726076,
    "length": 101,
    "time": 84749.623437,
    "actor_loss": -76.22552490234375,
    "critic_loss": 10.067090034484863,
    "ent_coef": 0.17864379286766052,
    "learning_rate": 0.001
  },
  {
    "episode": 5497,
    "reward": -192.086811,
    "length": 200,
    "time": 84778.948443,
    "actor_loss": -73.8245620727539,
    "critic_loss": 72.6722183227539,
    "ent_coef": 0.17514140903949738,
    "learning_rate": 0.001
  },
  {
    "episode": 5498,
    "reward": -56.882593,
    "length": 292,
    "time": 84820.172637,
    "actor_loss": -96.90435791015625,
    "critic_loss": 296.15673828125,
    "ent_coef": 0.1454249918460846,
    "learning_rate": 0.001
  },
  {
    "episode": 5499,
    "reward": 4.306978,
    "length": 231,
    "time": 84854.137535,
    "actor_loss": -74.34510803222656,
    "critic_loss": 67.94313049316406,
    "ent_coef": 0.16488848626613617,
    "learning_rate": 0.001
  },
  {
    "episode": 5500,
    "reward": 75.85387,
    "length": 91,
    "time": 84868.720473,
    "actor_loss": -103.68157196044922,
    "critic_loss": 167.4735107421875,
    "ent_coef": 0.16983097791671753,
    "learning_rate": 0.001
  },
  {
    "episode": 5501,
    "reward": 79.523034,
    "length": 84,
    "time": 84885.607218,
    "actor_loss": -109.50713348388672,
    "critic_loss": 222.5850067138672,
    "ent_coef": 0.16816866397857666,
    "learning_rate": 0.001
  },
  {
    "episode": 5502,
    "reward": 82.972927,
    "length": 77,
    "time": 84899.174438,
    "actor_loss": -163.35252380371094,
    "critic_loss": 82.22549438476562,
    "ent_coef": 0.17252227663993835,
    "learning_rate": 0.001
  },
  {
    "episode": 5503,
    "reward": 63.687519,
    "length": 110,
    "time": 84916.141572,
    "actor_loss": -90.5230712890625,
    "critic_loss": 124.82266235351562,
    "ent_coef": 0.16987204551696777,
    "learning_rate": 0.001
  },
  {
    "episode": 5504,
    "reward": 76.165792,
    "length": 85,
    "time": 84933.53297,
    "actor_loss": -91.9045639038086,
    "critic_loss": 96.13400268554688,
    "ent_coef": 0.16720370948314667,
    "learning_rate": 0.001
  },
  {
    "episode": 5505,
    "reward": 81.304186,
    "length": 79,
    "time": 84946.547246,
    "actor_loss": -122.06005096435547,
    "critic_loss": 11942.45703125,
    "ent_coef": 0.1665501743555069,
    "learning_rate": 0.001
  },
  {
    "episode": 5506,
    "reward": 86.513979,
    "length": 73,
    "time": 84958.781417,
    "actor_loss": -84.69261169433594,
    "critic_loss": 7535.9296875,
    "ent_coef": 0.17003831267356873,
    "learning_rate": 0.001
  },
  {
    "episode": 5507,
    "reward": 48.453797,
    "length": 134,
    "time": 84978.558002,
    "actor_loss": -71.28077697753906,
    "critic_loss": 54.783145904541016,
    "ent_coef": 0.16588851809501648,
    "learning_rate": 0.001
  },
  {
    "episode": 5508,
    "reward": 76.526261,
    "length": 88,
    "time": 84994.051757,
    "actor_loss": -73.88809204101562,
    "critic_loss": 42.000213623046875,
    "ent_coef": 0.16463099420070648,
    "learning_rate": 0.001
  },
  {
    "episode": 5509,
    "reward": 33.911712,
    "length": 175,
    "time": 85019.916595,
    "actor_loss": -94.36177825927734,
    "critic_loss": 36.48323059082031,
    "ent_coef": 0.15298360586166382,
    "learning_rate": 0.001
  },
  {
    "episode": 5510,
    "reward": 72.331486,
    "length": 102,
    "time": 85035.9698,
    "actor_loss": -100.57342529296875,
    "critic_loss": 154.5257568359375,
    "ent_coef": 0.146450012922287,
    "learning_rate": 0.001
  },
  {
    "episode": 5511,
    "reward": 84.49563,
    "length": 75,
    "time": 85048.817089,
    "actor_loss": -103.97505187988281,
    "critic_loss": 24.555644989013672,
    "ent_coef": 0.1511204093694687,
    "learning_rate": 0.001
  },
  {
    "episode": 5512,
    "reward": 77.489545,
    "length": 98,
    "time": 85065.429765,
    "actor_loss": -75.59259033203125,
    "critic_loss": 51.56675720214844,
    "ent_coef": 0.15176647901535034,
    "learning_rate": 0.001
  },
  {
    "episode": 5513,
    "reward": 74.564891,
    "length": 94,
    "time": 85084.737866,
    "actor_loss": -91.60884094238281,
    "critic_loss": 259.993896484375,
    "ent_coef": 0.15980911254882812,
    "learning_rate": 0.001
  },
  {
    "episode": 5514,
    "reward": 81.837322,
    "length": 81,
    "time": 85099.518722,
    "actor_loss": -92.038330078125,
    "critic_loss": 221.72293090820312,
    "ent_coef": 0.1732296496629715,
    "learning_rate": 0.001
  },
  {
    "episode": 5515,
    "reward": 82.85664,
    "length": 81,
    "time": 85112.942633,
    "actor_loss": -101.31268310546875,
    "critic_loss": 125.42878723144531,
    "ent_coef": 0.17524346709251404,
    "learning_rate": 0.001
  },
  {
    "episode": 5516,
    "reward": 86.000443,
    "length": 74,
    "time": 85129.407086,
    "actor_loss": -76.58155822753906,
    "critic_loss": 37.19414520263672,
    "ent_coef": 0.18268829584121704,
    "learning_rate": 0.001
  },
  {
    "episode": 5517,
    "reward": 78.342368,
    "length": 101,
    "time": 85146.664084,
    "actor_loss": -100.71968078613281,
    "critic_loss": 33.328895568847656,
    "ent_coef": 0.1842690259218216,
    "learning_rate": 0.001
  },
  {
    "episode": 5518,
    "reward": 64.619317,
    "length": 112,
    "time": 85165.448298,
    "actor_loss": -82.22050476074219,
    "critic_loss": 110.21083068847656,
    "ent_coef": 0.18359911441802979,
    "learning_rate": 0.001
  },
  {
    "episode": 5519,
    "reward": 80.905413,
    "length": 91,
    "time": 85181.005094,
    "actor_loss": -93.60736083984375,
    "critic_loss": 23.88195037841797,
    "ent_coef": 0.1857125461101532,
    "learning_rate": 0.001
  },
  {
    "episode": 5520,
    "reward": 79.675435,
    "length": 92,
    "time": 85195.548567,
    "actor_loss": -101.44195556640625,
    "critic_loss": 102.7614517211914,
    "ent_coef": 0.17832344770431519,
    "learning_rate": 0.001
  },
  {
    "episode": 5521,
    "reward": 60.146867,
    "length": 125,
    "time": 85215.608829,
    "actor_loss": -93.39910888671875,
    "critic_loss": 103.62181854248047,
    "ent_coef": 0.16975189745426178,
    "learning_rate": 0.001
  },
  {
    "episode": 5522,
    "reward": 81.29294,
    "length": 90,
    "time": 85229.880658,
    "actor_loss": -97.07778930664062,
    "critic_loss": 100.50711822509766,
    "ent_coef": 0.16596007347106934,
    "learning_rate": 0.001
  },
  {
    "episode": 5523,
    "reward": 67.551158,
    "length": 98,
    "time": 85245.316174,
    "actor_loss": -78.7303695678711,
    "critic_loss": 28.190486907958984,
    "ent_coef": 0.15794417262077332,
    "learning_rate": 0.001
  },
  {
    "episode": 5524,
    "reward": 75.936029,
    "length": 87,
    "time": 85260.786856,
    "actor_loss": -119.92770385742188,
    "critic_loss": 299.13775634765625,
    "ent_coef": 0.14999578893184662,
    "learning_rate": 0.001
  },
  {
    "episode": 5525,
    "reward": 81.035982,
    "length": 82,
    "time": 85276.128981,
    "actor_loss": -101.64659881591797,
    "critic_loss": 87.44142150878906,
    "ent_coef": 0.14504407346248627,
    "learning_rate": 0.001
  },
  {
    "episode": 5526,
    "reward": 76.792048,
    "length": 105,
    "time": 85292.430524,
    "actor_loss": -99.15718078613281,
    "critic_loss": 37.63211441040039,
    "ent_coef": 0.1435801386833191,
    "learning_rate": 0.001
  },
  {
    "episode": 5527,
    "reward": 85.165352,
    "length": 73,
    "time": 85304.371815,
    "actor_loss": -69.25393676757812,
    "critic_loss": 7.004118919372559,
    "ent_coef": 0.14780893921852112,
    "learning_rate": 0.001
  },
  {
    "episode": 5528,
    "reward": 85.379775,
    "length": 78,
    "time": 85317.938833,
    "actor_loss": -87.87909698486328,
    "critic_loss": 1928.476806640625,
    "ent_coef": 0.14631810784339905,
    "learning_rate": 0.001
  },
  {
    "episode": 5529,
    "reward": 78.26593,
    "length": 98,
    "time": 85336.192042,
    "actor_loss": -83.4130859375,
    "critic_loss": 53.94121551513672,
    "ent_coef": 0.15165172517299652,
    "learning_rate": 0.001
  },
  {
    "episode": 5530,
    "reward": 80.679865,
    "length": 85,
    "time": 85351.827001,
    "actor_loss": -96.45744323730469,
    "critic_loss": 96.01705932617188,
    "ent_coef": 0.14408093690872192,
    "learning_rate": 0.001
  },
  {
    "episode": 5531,
    "reward": 89.19634,
    "length": 68,
    "time": 85364.082015,
    "actor_loss": -116.79667663574219,
    "critic_loss": 47.93507385253906,
    "ent_coef": 0.15008436143398285,
    "learning_rate": 0.001
  },
  {
    "episode": 5532,
    "reward": 85.912047,
    "length": 75,
    "time": 85378.301976,
    "actor_loss": -102.19205474853516,
    "critic_loss": 288.1932678222656,
    "ent_coef": 0.1499626785516739,
    "learning_rate": 0.001
  },
  {
    "episode": 5533,
    "reward": 82.18868,
    "length": 78,
    "time": 85391.445427,
    "actor_loss": -99.04124450683594,
    "critic_loss": 45.232879638671875,
    "ent_coef": 0.15196605026721954,
    "learning_rate": 0.001
  },
  {
    "episode": 5534,
    "reward": -199.414817,
    "length": 598,
    "time": 85471.505705,
    "actor_loss": -100.30374145507812,
    "critic_loss": 2417.294921875,
    "ent_coef": 0.1313408464193344,
    "learning_rate": 0.001
  },
  {
    "episode": 5535,
    "reward": 71.500185,
    "length": 105,
    "time": 85488.737578,
    "actor_loss": -74.79240417480469,
    "critic_loss": 57.51411437988281,
    "ent_coef": 0.13319899141788483,
    "learning_rate": 0.001
  },
  {
    "episode": 5536,
    "reward": 85.895868,
    "length": 75,
    "time": 85502.177285,
    "actor_loss": -99.64250183105469,
    "critic_loss": 9571.62109375,
    "ent_coef": 0.1359201818704605,
    "learning_rate": 0.001
  },
  {
    "episode": 5537,
    "reward": 83.216587,
    "length": 78,
    "time": 85515.362592,
    "actor_loss": -73.80780029296875,
    "critic_loss": 13.992452621459961,
    "ent_coef": 0.13988031446933746,
    "learning_rate": 0.001
  },
  {
    "episode": 5538,
    "reward": 84.030174,
    "length": 82,
    "time": 85528.614058,
    "actor_loss": -78.04051208496094,
    "critic_loss": 6.533881187438965,
    "ent_coef": 0.14457917213439941,
    "learning_rate": 0.001
  },
  {
    "episode": 5539,
    "reward": 21.870524,
    "length": 256,
    "time": 85566.203768,
    "actor_loss": -83.52145385742188,
    "critic_loss": 56.584564208984375,
    "ent_coef": 0.13887427747249603,
    "learning_rate": 0.001
  },
  {
    "episode": 5540,
    "reward": 78.294686,
    "length": 97,
    "time": 85586.017826,
    "actor_loss": -81.72624969482422,
    "critic_loss": 52.15910720825195,
    "ent_coef": 0.14613287150859833,
    "learning_rate": 0.001
  },
  {
    "episode": 5541,
    "reward": -202.466907,
    "length": 235,
    "time": 85637.73329,
    "actor_loss": -70.82473754882812,
    "critic_loss": 68.69451141357422,
    "ent_coef": 0.15767039358615875,
    "learning_rate": 0.001
  },
  {
    "episode": 5542,
    "reward": -181.850628,
    "length": 217,
    "time": 85671.400989,
    "actor_loss": -73.91255187988281,
    "critic_loss": 6.883013725280762,
    "ent_coef": 0.1508011668920517,
    "learning_rate": 0.001
  },
  {
    "episode": 5543,
    "reward": 87.502435,
    "length": 72,
    "time": 85688.314063,
    "actor_loss": -83.58139038085938,
    "critic_loss": 84.19425964355469,
    "ent_coef": 0.1533724069595337,
    "learning_rate": 0.001
  },
  {
    "episode": 5544,
    "reward": -183.179761,
    "length": 221,
    "time": 85722.812648,
    "actor_loss": -92.59126281738281,
    "critic_loss": 3851.9453125,
    "ent_coef": 0.14536574482917786,
    "learning_rate": 0.001
  },
  {
    "episode": 5545,
    "reward": 83.157871,
    "length": 83,
    "time": 85739.917667,
    "actor_loss": -84.24000549316406,
    "critic_loss": 308.3095703125,
    "ent_coef": 0.1481766551733017,
    "learning_rate": 0.001
  },
  {
    "episode": 5546,
    "reward": 76.649458,
    "length": 100,
    "time": 85757.460054,
    "actor_loss": -99.56116485595703,
    "critic_loss": 20.000812530517578,
    "ent_coef": 0.1528763622045517,
    "learning_rate": 0.001
  },
  {
    "episode": 5547,
    "reward": 81.419746,
    "length": 80,
    "time": 85770.970858,
    "actor_loss": -70.77457427978516,
    "critic_loss": 40.150535583496094,
    "ent_coef": 0.15395677089691162,
    "learning_rate": 0.001
  },
  {
    "episode": 5548,
    "reward": 83.711234,
    "length": 80,
    "time": 85785.219983,
    "actor_loss": -82.88626861572266,
    "critic_loss": 50.772911071777344,
    "ent_coef": 0.15334093570709229,
    "learning_rate": 0.001
  },
  {
    "episode": 5549,
    "reward": 79.119507,
    "length": 81,
    "time": 85798.969575,
    "actor_loss": -69.57398986816406,
    "critic_loss": 14.182002067565918,
    "ent_coef": 0.1550443172454834,
    "learning_rate": 0.001
  },
  {
    "episode": 5550,
    "reward": 72.611789,
    "length": 99,
    "time": 85814.454923,
    "actor_loss": -88.35643768310547,
    "critic_loss": 180.10946655273438,
    "ent_coef": 0.1541469246149063,
    "learning_rate": 0.001
  },
  {
    "episode": 5551,
    "reward": 81.037562,
    "length": 92,
    "time": 85830.047891,
    "actor_loss": -69.11600494384766,
    "critic_loss": 61.424007415771484,
    "ent_coef": 0.16419491171836853,
    "learning_rate": 0.001
  },
  {
    "episode": 5552,
    "reward": 81.820621,
    "length": 84,
    "time": 85847.160769,
    "actor_loss": -78.99552917480469,
    "critic_loss": 38.20801544189453,
    "ent_coef": 0.16972611844539642,
    "learning_rate": 0.001
  },
  {
    "episode": 5553,
    "reward": 58.355157,
    "length": 156,
    "time": 85873.620669,
    "actor_loss": -78.48484802246094,
    "critic_loss": 30.33804702758789,
    "ent_coef": 0.15688085556030273,
    "learning_rate": 0.001
  },
  {
    "episode": 5554,
    "reward": 82.015215,
    "length": 83,
    "time": 85890.644095,
    "actor_loss": -82.30722045898438,
    "critic_loss": 62.21454620361328,
    "ent_coef": 0.1527639776468277,
    "learning_rate": 0.001
  },
  {
    "episode": 5555,
    "reward": 76.321361,
    "length": 103,
    "time": 85909.938528,
    "actor_loss": -81.00019073486328,
    "critic_loss": 62.881282806396484,
    "ent_coef": 0.14356796443462372,
    "learning_rate": 0.001
  },
  {
    "episode": 5556,
    "reward": 76.642047,
    "length": 96,
    "time": 85927.144952,
    "actor_loss": -95.86738586425781,
    "critic_loss": 87.77589416503906,
    "ent_coef": 0.1402493268251419,
    "learning_rate": 0.001
  },
  {
    "episode": 5557,
    "reward": 79.109778,
    "length": 88,
    "time": 85941.638901,
    "actor_loss": -94.74620056152344,
    "critic_loss": 571.8938598632812,
    "ent_coef": 0.13926434516906738,
    "learning_rate": 0.001
  },
  {
    "episode": 5558,
    "reward": 83.657056,
    "length": 83,
    "time": 85956.532875,
    "actor_loss": -72.37196350097656,
    "critic_loss": 22.398618698120117,
    "ent_coef": 0.131812185049057,
    "learning_rate": 0.001
  },
  {
    "episode": 5559,
    "reward": 78.417112,
    "length": 90,
    "time": 85972.367032,
    "actor_loss": -82.95767211914062,
    "critic_loss": 43.01669692993164,
    "ent_coef": 0.13148923218250275,
    "learning_rate": 0.001
  },
  {
    "episode": 5560,
    "reward": 74.135043,
    "length": 105,
    "time": 85989.405737,
    "actor_loss": -97.39913177490234,
    "critic_loss": 235.96310424804688,
    "ent_coef": 0.12657640874385834,
    "learning_rate": 0.001
  },
  {
    "episode": 5561,
    "reward": 82.560657,
    "length": 83,
    "time": 86004.373152,
    "actor_loss": -78.76200866699219,
    "critic_loss": 44.667503356933594,
    "ent_coef": 0.12249363958835602,
    "learning_rate": 0.001
  },
  {
    "episode": 5562,
    "reward": 77.747346,
    "length": 95,
    "time": 86019.535399,
    "actor_loss": -76.4781265258789,
    "critic_loss": 217.00338745117188,
    "ent_coef": 0.12131546437740326,
    "learning_rate": 0.001
  },
  {
    "episode": 5563,
    "reward": 85.575436,
    "length": 74,
    "time": 86033.161278,
    "actor_loss": -69.45272064208984,
    "critic_loss": 201.53018188476562,
    "ent_coef": 0.12345266342163086,
    "learning_rate": 0.001
  },
  {
    "episode": 5564,
    "reward": 84.414932,
    "length": 80,
    "time": 86046.479008,
    "actor_loss": -85.28351593017578,
    "critic_loss": 26.21401596069336,
    "ent_coef": 0.1286981850862503,
    "learning_rate": 0.001
  },
  {
    "episode": 5565,
    "reward": 82.217983,
    "length": 82,
    "time": 86060.948527,
    "actor_loss": -91.85823822021484,
    "critic_loss": 97.14265441894531,
    "ent_coef": 0.13436923921108246,
    "learning_rate": 0.001
  },
  {
    "episode": 5566,
    "reward": 76.522696,
    "length": 94,
    "time": 86077.719742,
    "actor_loss": -77.37519836425781,
    "critic_loss": 26.09325408935547,
    "ent_coef": 0.13568320870399475,
    "learning_rate": 0.001
  },
  {
    "episode": 5567,
    "reward": 68.22487,
    "length": 115,
    "time": 86097.890455,
    "actor_loss": -77.144775390625,
    "critic_loss": 113.23393249511719,
    "ent_coef": 0.1454053819179535,
    "learning_rate": 0.001
  },
  {
    "episode": 5568,
    "reward": -159.429171,
    "length": 146,
    "time": 86120.456832,
    "actor_loss": -66.5228271484375,
    "critic_loss": 66.08450317382812,
    "ent_coef": 0.14266200363636017,
    "learning_rate": 0.001
  },
  {
    "episode": 5569,
    "reward": 83.065415,
    "length": 76,
    "time": 86138.961619,
    "actor_loss": -81.54658508300781,
    "critic_loss": 70.31531524658203,
    "ent_coef": 0.1465565711259842,
    "learning_rate": 0.001
  },
  {
    "episode": 5570,
    "reward": -159.589025,
    "length": 146,
    "time": 86161.224591,
    "actor_loss": -69.77452087402344,
    "critic_loss": 71.60740661621094,
    "ent_coef": 0.1523013710975647,
    "learning_rate": 0.001
  },
  {
    "episode": 5571,
    "reward": 74.406514,
    "length": 90,
    "time": 86178.99568,
    "actor_loss": -73.56941223144531,
    "critic_loss": 38.124290466308594,
    "ent_coef": 0.15174473822116852,
    "learning_rate": 0.001
  },
  {
    "episode": 5572,
    "reward": -164.339682,
    "length": 150,
    "time": 86203.827117,
    "actor_loss": -91.33876037597656,
    "critic_loss": 145.1978302001953,
    "ent_coef": 0.15732890367507935,
    "learning_rate": 0.001
  },
  {
    "episode": 5573,
    "reward": 81.516466,
    "length": 82,
    "time": 86219.941742,
    "actor_loss": -82.07330322265625,
    "critic_loss": 28.828874588012695,
    "ent_coef": 0.17804649472236633,
    "learning_rate": 0.001
  },
  {
    "episode": 5574,
    "reward": 79.759705,
    "length": 84,
    "time": 86234.780287,
    "actor_loss": -88.10466003417969,
    "critic_loss": 4930.7109375,
    "ent_coef": 0.18543660640716553,
    "learning_rate": 0.001
  },
  {
    "episode": 5575,
    "reward": 84.159777,
    "length": 76,
    "time": 86251.5065,
    "actor_loss": -67.83323669433594,
    "critic_loss": 47.93067169189453,
    "ent_coef": 0.19216322898864746,
    "learning_rate": 0.001
  },
  {
    "episode": 5576,
    "reward": -157.554235,
    "length": 143,
    "time": 86273.255142,
    "actor_loss": -94.13595581054688,
    "critic_loss": 55.91859436035156,
    "ent_coef": 0.1856628805398941,
    "learning_rate": 0.001
  },
  {
    "episode": 5577,
    "reward": 81.530482,
    "length": 83,
    "time": 86287.606782,
    "actor_loss": -73.87367248535156,
    "critic_loss": 31.79876708984375,
    "ent_coef": 0.180686816573143,
    "learning_rate": 0.001
  },
  {
    "episode": 5578,
    "reward": 84.647046,
    "length": 74,
    "time": 86301.330521,
    "actor_loss": -77.56907653808594,
    "critic_loss": 38.184600830078125,
    "ent_coef": 0.17200544476509094,
    "learning_rate": 0.001
  },
  {
    "episode": 5579,
    "reward": 82.460408,
    "length": 79,
    "time": 86318.316124,
    "actor_loss": -75.33256530761719,
    "critic_loss": 33.42059326171875,
    "ent_coef": 0.16551336646080017,
    "learning_rate": 0.001
  },
  {
    "episode": 5580,
    "reward": 80.090703,
    "length": 81,
    "time": 86333.201102,
    "actor_loss": -75.43419647216797,
    "critic_loss": 43.653221130371094,
    "ent_coef": 0.16251228749752045,
    "learning_rate": 0.001
  },
  {
    "episode": 5581,
    "reward": 80.9864,
    "length": 81,
    "time": 86347.819585,
    "actor_loss": -78.77403259277344,
    "critic_loss": 93.7007827758789,
    "ent_coef": 0.161680668592453,
    "learning_rate": 0.001
  },
  {
    "episode": 5582,
    "reward": 77.451135,
    "length": 96,
    "time": 86370.986035,
    "actor_loss": -74.75276184082031,
    "critic_loss": 9.221564292907715,
    "ent_coef": 0.15510708093643188,
    "learning_rate": 0.001
  },
  {
    "episode": 5583,
    "reward": 76.531746,
    "length": 93,
    "time": 86387.690664,
    "actor_loss": -70.99781036376953,
    "critic_loss": 4090.39892578125,
    "ent_coef": 0.1444627344608307,
    "learning_rate": 0.001
  },
  {
    "episode": 5584,
    "reward": 79.903876,
    "length": 85,
    "time": 86401.533314,
    "actor_loss": -66.25885009765625,
    "critic_loss": 8.222362518310547,
    "ent_coef": 0.14192309975624084,
    "learning_rate": 0.001
  },
  {
    "episode": 5585,
    "reward": 84.116181,
    "length": 81,
    "time": 86415.173866,
    "actor_loss": -77.85348510742188,
    "critic_loss": 25.846649169921875,
    "ent_coef": 0.14278703927993774,
    "learning_rate": 0.001
  },
  {
    "episode": 5586,
    "reward": 78.776104,
    "length": 84,
    "time": 86431.914275,
    "actor_loss": -74.22319030761719,
    "critic_loss": 28.174575805664062,
    "ent_coef": 0.14456221461296082,
    "learning_rate": 0.001
  },
  {
    "episode": 5587,
    "reward": 78.951576,
    "length": 92,
    "time": 86449.392152,
    "actor_loss": -76.5282974243164,
    "critic_loss": 123.45060729980469,
    "ent_coef": 0.14346304535865784,
    "learning_rate": 0.001
  },
  {
    "episode": 5588,
    "reward": -161.85652,
    "length": 155,
    "time": 86472.709668,
    "actor_loss": -76.96514129638672,
    "critic_loss": 56.008277893066406,
    "ent_coef": 0.14901810884475708,
    "learning_rate": 0.001
  },
  {
    "episode": 5589,
    "reward": 83.207645,
    "length": 76,
    "time": 86489.562015,
    "actor_loss": -74.25418853759766,
    "critic_loss": 390.13958740234375,
    "ent_coef": 0.15333929657936096,
    "learning_rate": 0.001
  },
  {
    "episode": 5590,
    "reward": -159.489778,
    "length": 147,
    "time": 86513.601558,
    "actor_loss": -85.46086120605469,
    "critic_loss": 70.18702697753906,
    "ent_coef": 0.1624550223350525,
    "learning_rate": 0.001
  },
  {
    "episode": 5591,
    "reward": 83.88717,
    "length": 83,
    "time": 86527.90784,
    "actor_loss": -64.81292724609375,
    "critic_loss": 50.78887176513672,
    "ent_coef": 0.16245654225349426,
    "learning_rate": 0.001
  },
  {
    "episode": 5592,
    "reward": 81.55965,
    "length": 82,
    "time": 86542.790477,
    "actor_loss": -79.69781494140625,
    "critic_loss": 26.868087768554688,
    "ent_coef": 0.15972493588924408,
    "learning_rate": 0.001
  },
  {
    "episode": 5593,
    "reward": 83.080539,
    "length": 79,
    "time": 86556.659592,
    "actor_loss": -66.24925994873047,
    "critic_loss": 51.99378204345703,
    "ent_coef": 0.15422280132770538,
    "learning_rate": 0.001
  },
  {
    "episode": 5594,
    "reward": 83.73977,
    "length": 76,
    "time": 86569.53843,
    "actor_loss": -63.80630874633789,
    "critic_loss": 16.761505126953125,
    "ent_coef": 0.15657956898212433,
    "learning_rate": 0.001
  },
  {
    "episode": 5595,
    "reward": -156.879935,
    "length": 139,
    "time": 86590.792874,
    "actor_loss": -62.74723815917969,
    "critic_loss": 33.78131103515625,
    "ent_coef": 0.17365717887878418,
    "learning_rate": 0.001
  },
  {
    "episode": 5596,
    "reward": -160.288842,
    "length": 150,
    "time": 86615.800956,
    "actor_loss": -71.3231201171875,
    "critic_loss": 35.27381134033203,
    "ent_coef": 0.1612795740365982,
    "learning_rate": 0.001
  },
  {
    "episode": 5597,
    "reward": -166.002399,
    "length": 146,
    "time": 86637.548398,
    "actor_loss": -65.06912231445312,
    "critic_loss": 15.822874069213867,
    "ent_coef": 0.1737366020679474,
    "learning_rate": 0.001
  },
  {
    "episode": 5598,
    "reward": 77.217164,
    "length": 89,
    "time": 86657.716118,
    "actor_loss": -72.864013671875,
    "critic_loss": 36.397579193115234,
    "ent_coef": 0.16397614777088165,
    "learning_rate": 0.001
  },
  {
    "episode": 5599,
    "reward": 75.617702,
    "length": 98,
    "time": 86673.213827,
    "actor_loss": -78.5307388305664,
    "critic_loss": 29.511756896972656,
    "ent_coef": 0.15206654369831085,
    "learning_rate": 0.001
  },
  {
    "episode": 5600,
    "reward": 80.240412,
    "length": 88,
    "time": 86689.177858,
    "actor_loss": -78.1646728515625,
    "critic_loss": 35.4376220703125,
    "ent_coef": 0.14119943976402283,
    "learning_rate": 0.001
  },
  {
    "episode": 5601,
    "reward": 65.868294,
    "length": 129,
    "time": 86710.480992,
    "actor_loss": -64.38784790039062,
    "critic_loss": 9.069051742553711,
    "ent_coef": 0.12990351021289825,
    "learning_rate": 0.001
  },
  {
    "episode": 5602,
    "reward": -163.186298,
    "length": 157,
    "time": 86736.812043,
    "actor_loss": -68.19078826904297,
    "critic_loss": 760.6511840820312,
    "ent_coef": 0.12348295003175735,
    "learning_rate": 0.001
  },
  {
    "episode": 5603,
    "reward": 88.405406,
    "length": 67,
    "time": 86748.396524,
    "actor_loss": -82.64401245117188,
    "critic_loss": 46.383949279785156,
    "ent_coef": 0.12893536686897278,
    "learning_rate": 0.001
  },
  {
    "episode": 5604,
    "reward": 82.310615,
    "length": 81,
    "time": 86763.296704,
    "actor_loss": -70.464111328125,
    "critic_loss": 53.65677261352539,
    "ent_coef": 0.12435697764158249,
    "learning_rate": 0.001
  },
  {
    "episode": 5605,
    "reward": 77.908921,
    "length": 90,
    "time": 86779.258265,
    "actor_loss": -66.72335815429688,
    "critic_loss": 737.53857421875,
    "ent_coef": 0.12187954783439636,
    "learning_rate": 0.001
  },
  {
    "episode": 5606,
    "reward": 81.215473,
    "length": 77,
    "time": 86793.773181,
    "actor_loss": -69.6597671508789,
    "critic_loss": 63.89121627807617,
    "ent_coef": 0.12311692535877228,
    "learning_rate": 0.001
  },
  {
    "episode": 5607,
    "reward": 73.049351,
    "length": 94,
    "time": 86811.272136,
    "actor_loss": -63.25149154663086,
    "critic_loss": 3738.4375,
    "ent_coef": 0.12613236904144287,
    "learning_rate": 0.001
  },
  {
    "episode": 5608,
    "reward": 77.7351,
    "length": 83,
    "time": 86827.68934,
    "actor_loss": -77.8677978515625,
    "critic_loss": 19.948274612426758,
    "ent_coef": 0.123111292719841,
    "learning_rate": 0.001
  },
  {
    "episode": 5609,
    "reward": 83.069237,
    "length": 82,
    "time": 86841.468668,
    "actor_loss": -84.25381469726562,
    "critic_loss": 9.8787841796875,
    "ent_coef": 0.12555058300495148,
    "learning_rate": 0.001
  },
  {
    "episode": 5610,
    "reward": -158.56072,
    "length": 146,
    "time": 86865.581794,
    "actor_loss": -75.75035095214844,
    "critic_loss": 87.1651382446289,
    "ent_coef": 0.13391147553920746,
    "learning_rate": 0.001
  },
  {
    "episode": 5611,
    "reward": 78.463988,
    "length": 86,
    "time": 86882.334474,
    "actor_loss": -68.07365417480469,
    "critic_loss": 4239.2470703125,
    "ent_coef": 0.1250169277191162,
    "learning_rate": 0.001
  },
  {
    "episode": 5612,
    "reward": 76.331859,
    "length": 90,
    "time": 86897.746497,
    "actor_loss": -86.42327880859375,
    "critic_loss": 45.65448760986328,
    "ent_coef": 0.12351634353399277,
    "learning_rate": 0.001
  },
  {
    "episode": 5613,
    "reward": 81.399817,
    "length": 83,
    "time": 86911.464146,
    "actor_loss": -71.2466812133789,
    "critic_loss": 29.722068786621094,
    "ent_coef": 0.12028070539236069,
    "learning_rate": 0.001
  },
  {
    "episode": 5614,
    "reward": 79.847843,
    "length": 83,
    "time": 86927.181173,
    "actor_loss": -74.89266967773438,
    "critic_loss": 38.10082244873047,
    "ent_coef": 0.12322449684143066,
    "learning_rate": 0.001
  },
  {
    "episode": 5615,
    "reward": 87.009998,
    "length": 72,
    "time": 86940.347904,
    "actor_loss": -66.59315490722656,
    "critic_loss": 76.10699462890625,
    "ent_coef": 0.12442340701818466,
    "learning_rate": 0.001
  },
  {
    "episode": 5616,
    "reward": 84.365954,
    "length": 78,
    "time": 86955.968069,
    "actor_loss": -81.48026275634766,
    "critic_loss": 28.823312759399414,
    "ent_coef": 0.11786020547151566,
    "learning_rate": 0.001
  },
  {
    "episode": 5617,
    "reward": 81.399535,
    "length": 84,
    "time": 86969.638163,
    "actor_loss": -75.39273834228516,
    "critic_loss": 28.89028549194336,
    "ent_coef": 0.12058664858341217,
    "learning_rate": 0.001
  },
  {
    "episode": 5618,
    "reward": 77.044741,
    "length": 83,
    "time": 86985.864264,
    "actor_loss": -67.09877014160156,
    "critic_loss": 22.740264892578125,
    "ent_coef": 0.11828341335058212,
    "learning_rate": 0.001
  },
  {
    "episode": 5619,
    "reward": 84.22479,
    "length": 95,
    "time": 87001.957226,
    "actor_loss": -73.86863708496094,
    "critic_loss": 48.0477294921875,
    "ent_coef": 0.10891426354646683,
    "learning_rate": 0.001
  },
  {
    "episode": 5620,
    "reward": -162.780584,
    "length": 153,
    "time": 87027.49551,
    "actor_loss": -71.61832427978516,
    "critic_loss": 665.5758056640625,
    "ent_coef": 0.09930997341871262,
    "learning_rate": 0.001
  },
  {
    "episode": 5621,
    "reward": 88.748419,
    "length": 67,
    "time": 87039.535556,
    "actor_loss": -67.98075866699219,
    "critic_loss": 41.66395950317383,
    "ent_coef": 0.09870744496583939,
    "learning_rate": 0.001
  },
  {
    "episode": 5622,
    "reward": 82.178013,
    "length": 84,
    "time": 87054.550704,
    "actor_loss": -78.71762084960938,
    "critic_loss": 26.484411239624023,
    "ent_coef": 0.0937754213809967,
    "learning_rate": 0.001
  },
  {
    "episode": 5623,
    "reward": 79.218877,
    "length": 83,
    "time": 87071.030433,
    "actor_loss": -72.51690673828125,
    "critic_loss": 98.64521789550781,
    "ent_coef": 0.09339434653520584,
    "learning_rate": 0.001
  },
  {
    "episode": 5624,
    "reward": 86.096624,
    "length": 73,
    "time": 87084.218213,
    "actor_loss": -66.90324401855469,
    "critic_loss": 912.0121459960938,
    "ent_coef": 0.0956534743309021,
    "learning_rate": 0.001
  },
  {
    "episode": 5625,
    "reward": 81.394576,
    "length": 78,
    "time": 87099.454608,
    "actor_loss": -67.15652465820312,
    "critic_loss": 13.532267570495605,
    "ent_coef": 0.10091672092676163,
    "learning_rate": 0.001
  },
  {
    "episode": 5626,
    "reward": 82.101896,
    "length": 79,
    "time": 87112.458533,
    "actor_loss": -71.4184799194336,
    "critic_loss": 17.447399139404297,
    "ent_coef": 0.09928205609321594,
    "learning_rate": 0.001
  },
  {
    "episode": 5627,
    "reward": 79.813339,
    "length": 116,
    "time": 87131.24248,
    "actor_loss": -82.78392791748047,
    "critic_loss": 568.63037109375,
    "ent_coef": 0.09880579262971878,
    "learning_rate": 0.001
  },
  {
    "episode": 5628,
    "reward": 59.588368,
    "length": 116,
    "time": 87149.545914,
    "actor_loss": -73.18577575683594,
    "critic_loss": 21.60260772705078,
    "ent_coef": 0.10686487704515457,
    "learning_rate": 0.001
  },
  {
    "episode": 5629,
    "reward": 80.934235,
    "length": 82,
    "time": 87164.325087,
    "actor_loss": -78.78062438964844,
    "critic_loss": 35.677833557128906,
    "ent_coef": 0.10986156761646271,
    "learning_rate": 0.001
  },
  {
    "episode": 5630,
    "reward": 85.836662,
    "length": 75,
    "time": 87176.945189,
    "actor_loss": -60.3250846862793,
    "critic_loss": 30.448707580566406,
    "ent_coef": 0.10878497362136841,
    "learning_rate": 0.001
  },
  {
    "episode": 5631,
    "reward": 81.975142,
    "length": 81,
    "time": 87190.689779,
    "actor_loss": -74.33667755126953,
    "critic_loss": 48.58296585083008,
    "ent_coef": 0.10577844828367233,
    "learning_rate": 0.001
  },
  {
    "episode": 5632,
    "reward": 69.969861,
    "length": 100,
    "time": 87207.40208,
    "actor_loss": -73.30149841308594,
    "critic_loss": 268.80169677734375,
    "ent_coef": 0.10611412674188614,
    "learning_rate": 0.001
  },
  {
    "episode": 5633,
    "reward": 83.239022,
    "length": 77,
    "time": 87221.210109,
    "actor_loss": -73.5323257446289,
    "critic_loss": 35.65385437011719,
    "ent_coef": 0.11028539389371872,
    "learning_rate": 0.001
  },
  {
    "episode": 5634,
    "reward": 75.936221,
    "length": 105,
    "time": 87240.548837,
    "actor_loss": -61.505577087402344,
    "critic_loss": 37.72244644165039,
    "ent_coef": 0.10284744948148727,
    "learning_rate": 0.001
  },
  {
    "episode": 5635,
    "reward": 78.893092,
    "length": 81,
    "time": 87255.355706,
    "actor_loss": -75.97785949707031,
    "critic_loss": 594.1454467773438,
    "ent_coef": 0.1059001237154007,
    "learning_rate": 0.001
  },
  {
    "episode": 5636,
    "reward": -161.717223,
    "length": 139,
    "time": 87275.768906,
    "actor_loss": -64.82691192626953,
    "critic_loss": 28.028114318847656,
    "ent_coef": 0.12404350191354752,
    "learning_rate": 0.001
  },
  {
    "episode": 5637,
    "reward": 87.002501,
    "length": 71,
    "time": 87290.345267,
    "actor_loss": -74.68665313720703,
    "critic_loss": 109.50633239746094,
    "ent_coef": 0.12332351505756378,
    "learning_rate": 0.001
  },
  {
    "episode": 5638,
    "reward": -187.241334,
    "length": 181,
    "time": 87319.079921,
    "actor_loss": -63.75102996826172,
    "critic_loss": 6.436763763427734,
    "ent_coef": 0.10434658080339432,
    "learning_rate": 0.001
  },
  {
    "episode": 5639,
    "reward": -161.684563,
    "length": 152,
    "time": 87341.666157,
    "actor_loss": -71.35731506347656,
    "critic_loss": 3427.5361328125,
    "ent_coef": 0.09937944263219833,
    "learning_rate": 0.001
  },
  {
    "episode": 5640,
    "reward": 82.057979,
    "length": 79,
    "time": 87354.624362,
    "actor_loss": -70.26832580566406,
    "critic_loss": 108.81269836425781,
    "ent_coef": 0.09730874747037888,
    "learning_rate": 0.001
  },
  {
    "episode": 5641,
    "reward": 72.092665,
    "length": 98,
    "time": 87371.687264,
    "actor_loss": -67.29010009765625,
    "critic_loss": 55.39788818359375,
    "ent_coef": 0.09878009557723999,
    "learning_rate": 0.001
  },
  {
    "episode": 5642,
    "reward": 63.167963,
    "length": 107,
    "time": 87390.52381,
    "actor_loss": -72.97645568847656,
    "critic_loss": 14.715361595153809,
    "ent_coef": 0.09776191413402557,
    "learning_rate": 0.001
  },
  {
    "episode": 5643,
    "reward": 63.06524,
    "length": 115,
    "time": 87411.844149,
    "actor_loss": -74.7041015625,
    "critic_loss": 5.2733235359191895,
    "ent_coef": 0.10467643290758133,
    "learning_rate": 0.001
  },
  {
    "episode": 5644,
    "reward": 74.645897,
    "length": 99,
    "time": 87429.899966,
    "actor_loss": -69.81483459472656,
    "critic_loss": 11.756522178649902,
    "ent_coef": 0.10356516391038895,
    "learning_rate": 0.001
  },
  {
    "episode": 5645,
    "reward": 81.871649,
    "length": 78,
    "time": 87443.844906,
    "actor_loss": -67.34732818603516,
    "critic_loss": 15.334914207458496,
    "ent_coef": 0.1066947653889656,
    "learning_rate": 0.001
  },
  {
    "episode": 5646,
    "reward": 81.029227,
    "length": 80,
    "time": 87457.934587,
    "actor_loss": -63.63454818725586,
    "critic_loss": 69.12632751464844,
    "ent_coef": 0.10772690922021866,
    "learning_rate": 0.001
  },
  {
    "episode": 5647,
    "reward": 54.85324,
    "length": 114,
    "time": 87478.686369,
    "actor_loss": -68.49066162109375,
    "critic_loss": 8.082624435424805,
    "ent_coef": 0.10587389767169952,
    "learning_rate": 0.001
  },
  {
    "episode": 5648,
    "reward": 82.704397,
    "length": 79,
    "time": 87491.7029,
    "actor_loss": -63.719871520996094,
    "critic_loss": 37.84761047363281,
    "ent_coef": 0.10161565244197845,
    "learning_rate": 0.001
  },
  {
    "episode": 5649,
    "reward": 83.137683,
    "length": 77,
    "time": 87506.049571,
    "actor_loss": -66.35554504394531,
    "critic_loss": 114.360107421875,
    "ent_coef": 0.10548590123653412,
    "learning_rate": 0.001
  },
  {
    "episode": 5650,
    "reward": 76.777945,
    "length": 96,
    "time": 87521.536896,
    "actor_loss": -64.74249267578125,
    "critic_loss": 94.53958892822266,
    "ent_coef": 0.11520493030548096,
    "learning_rate": 0.001
  },
  {
    "episode": 5651,
    "reward": 74.315552,
    "length": 101,
    "time": 87539.228621,
    "actor_loss": -58.181453704833984,
    "critic_loss": 66.48542785644531,
    "ent_coef": 0.1207895576953888,
    "learning_rate": 0.001
  },
  {
    "episode": 5652,
    "reward": 72.291029,
    "length": 102,
    "time": 87556.102681,
    "actor_loss": -65.71266174316406,
    "critic_loss": 38.322120666503906,
    "ent_coef": 0.12416445463895798,
    "learning_rate": 0.001
  },
  {
    "episode": 5653,
    "reward": 83.187083,
    "length": 76,
    "time": 87568.840323,
    "actor_loss": -69.19713592529297,
    "critic_loss": 35.50122833251953,
    "ent_coef": 0.12941806018352509,
    "learning_rate": 0.001
  },
  {
    "episode": 5654,
    "reward": 80.441491,
    "length": 80,
    "time": 87582.04267,
    "actor_loss": -67.90641784667969,
    "critic_loss": 763.3612060546875,
    "ent_coef": 0.12776997685432434,
    "learning_rate": 0.001
  },
  {
    "episode": 5655,
    "reward": 22.242133,
    "length": 180,
    "time": 87608.215194,
    "actor_loss": -58.79457473754883,
    "critic_loss": 14.692224502563477,
    "ent_coef": 0.1345590502023697,
    "learning_rate": 0.001
  },
  {
    "episode": 5656,
    "reward": 70.287205,
    "length": 99,
    "time": 87626.4196,
    "actor_loss": -61.19567108154297,
    "critic_loss": 82.4705810546875,
    "ent_coef": 0.13246594369411469,
    "learning_rate": 0.001
  },
  {
    "episode": 5657,
    "reward": 70.451739,
    "length": 101,
    "time": 87642.60517,
    "actor_loss": -78.01286315917969,
    "critic_loss": 31.09170150756836,
    "ent_coef": 0.13539235293865204,
    "learning_rate": 0.001
  },
  {
    "episode": 5658,
    "reward": 73.17428,
    "length": 98,
    "time": 87660.765754,
    "actor_loss": -69.25003051757812,
    "critic_loss": 72.62733459472656,
    "ent_coef": 0.139943465590477,
    "learning_rate": 0.001
  },
  {
    "episode": 5659,
    "reward": 79.183481,
    "length": 86,
    "time": 87677.254066,
    "actor_loss": -70.17073059082031,
    "critic_loss": 47.90326690673828,
    "ent_coef": 0.1416211724281311,
    "learning_rate": 0.001
  },
  {
    "episode": 5660,
    "reward": 82.994828,
    "length": 82,
    "time": 87691.563124,
    "actor_loss": -62.23889923095703,
    "critic_loss": 12.629266738891602,
    "ent_coef": 0.14355412125587463,
    "learning_rate": 0.001
  },
  {
    "episode": 5661,
    "reward": 82.94466,
    "length": 76,
    "time": 87704.682204,
    "actor_loss": -67.45759582519531,
    "critic_loss": 19.531421661376953,
    "ent_coef": 0.14111070334911346,
    "learning_rate": 0.001
  },
  {
    "episode": 5662,
    "reward": 79.235722,
    "length": 86,
    "time": 87719.095897,
    "actor_loss": -67.95346069335938,
    "critic_loss": 26.12179946899414,
    "ent_coef": 0.13604143261909485,
    "learning_rate": 0.001
  },
  {
    "episode": 5663,
    "reward": 77.059821,
    "length": 86,
    "time": 87736.320943,
    "actor_loss": -71.00506591796875,
    "critic_loss": 1734.015869140625,
    "ent_coef": 0.1337202489376068,
    "learning_rate": 0.001
  },
  {
    "episode": 5664,
    "reward": 84.013704,
    "length": 76,
    "time": 87750.450285,
    "actor_loss": -69.86331939697266,
    "critic_loss": 39.20909118652344,
    "ent_coef": 0.1295272409915924,
    "learning_rate": 0.001
  },
  {
    "episode": 5665,
    "reward": 80.65454,
    "length": 83,
    "time": 87764.045243,
    "actor_loss": -65.29183959960938,
    "critic_loss": 15.561853408813477,
    "ent_coef": 0.1248214840888977,
    "learning_rate": 0.001
  },
  {
    "episode": 5666,
    "reward": 66.487733,
    "length": 106,
    "time": 87781.48481,
    "actor_loss": -60.713890075683594,
    "critic_loss": 101.47300720214844,
    "ent_coef": 0.1258588284254074,
    "learning_rate": 0.001
  },
  {
    "episode": 5667,
    "reward": 79.94058,
    "length": 86,
    "time": 87795.513055,
    "actor_loss": -69.90684509277344,
    "critic_loss": 1109.53515625,
    "ent_coef": 0.12916956841945648,
    "learning_rate": 0.001
  },
  {
    "episode": 5668,
    "reward": 88.87961,
    "length": 66,
    "time": 87809.189176,
    "actor_loss": -60.5364990234375,
    "critic_loss": 43.613365173339844,
    "ent_coef": 0.13062302768230438,
    "learning_rate": 0.001
  },
  {
    "episode": 5669,
    "reward": 83.337858,
    "length": 79,
    "time": 87823.330798,
    "actor_loss": -65.91024780273438,
    "critic_loss": 27.385540008544922,
    "ent_coef": 0.12593741714954376,
    "learning_rate": 0.001
  },
  {
    "episode": 5670,
    "reward": 80.019193,
    "length": 83,
    "time": 87840.571327,
    "actor_loss": -59.26905059814453,
    "critic_loss": 36.94293212890625,
    "ent_coef": 0.13370731472969055,
    "learning_rate": 0.001
  },
  {
    "episode": 5671,
    "reward": 84.04939,
    "length": 74,
    "time": 87857.79674,
    "actor_loss": -62.70829772949219,
    "critic_loss": 18.984699249267578,
    "ent_coef": 0.13365401327610016,
    "learning_rate": 0.001
  },
  {
    "episode": 5672,
    "reward": 77.931771,
    "length": 85,
    "time": 87872.845546,
    "actor_loss": -55.81113052368164,
    "critic_loss": 74.05674743652344,
    "ent_coef": 0.1370074599981308,
    "learning_rate": 0.001
  },
  {
    "episode": 5673,
    "reward": 79.119168,
    "length": 88,
    "time": 87887.960043,
    "actor_loss": -63.290191650390625,
    "critic_loss": 26.75027847290039,
    "ent_coef": 0.13245226442813873,
    "learning_rate": 0.001
  },
  {
    "episode": 5674,
    "reward": 80.914715,
    "length": 93,
    "time": 87902.929332,
    "actor_loss": -66.53266143798828,
    "critic_loss": 18.5976505279541,
    "ent_coef": 0.13665448129177094,
    "learning_rate": 0.001
  },
  {
    "episode": 5675,
    "reward": 79.370586,
    "length": 84,
    "time": 87916.967999,
    "actor_loss": -62.09980392456055,
    "critic_loss": 1859.06689453125,
    "ent_coef": 0.1366162747144699,
    "learning_rate": 0.001
  },
  {
    "episode": 5676,
    "reward": 78.158407,
    "length": 83,
    "time": 87933.421262,
    "actor_loss": -60.396297454833984,
    "critic_loss": 5.113492012023926,
    "ent_coef": 0.13864022493362427,
    "learning_rate": 0.001
  },
  {
    "episode": 5677,
    "reward": 78.646328,
    "length": 96,
    "time": 87951.329675,
    "actor_loss": -68.14954376220703,
    "critic_loss": 23.429920196533203,
    "ent_coef": 0.1360507607460022,
    "learning_rate": 0.001
  },
  {
    "episode": 5678,
    "reward": 85.236291,
    "length": 72,
    "time": 87966.253525,
    "actor_loss": -61.402198791503906,
    "critic_loss": 2.8632755279541016,
    "ent_coef": 0.13856002688407898,
    "learning_rate": 0.001
  },
  {
    "episode": 5679,
    "reward": 76.974336,
    "length": 110,
    "time": 87983.238033,
    "actor_loss": -61.45322036743164,
    "critic_loss": 3.9076318740844727,
    "ent_coef": 0.1396782547235489,
    "learning_rate": 0.001
  },
  {
    "episode": 5680,
    "reward": 75.570144,
    "length": 91,
    "time": 88000.564104,
    "actor_loss": -58.82798767089844,
    "critic_loss": 10.777177810668945,
    "ent_coef": 0.13249894976615906,
    "learning_rate": 0.001
  },
  {
    "episode": 5681,
    "reward": -52.315111,
    "length": 244,
    "time": 88036.631883,
    "actor_loss": -67.55603790283203,
    "critic_loss": 23.3227596282959,
    "ent_coef": 0.11418188363313675,
    "learning_rate": 0.001
  },
  {
    "episode": 5682,
    "reward": 82.682804,
    "length": 76,
    "time": 88052.996114,
    "actor_loss": -63.354278564453125,
    "critic_loss": 49.24341583251953,
    "ent_coef": 0.1114923283457756,
    "learning_rate": 0.001
  },
  {
    "episode": 5683,
    "reward": 75.857819,
    "length": 87,
    "time": 88069.10937,
    "actor_loss": -66.57665252685547,
    "critic_loss": 2021.9359130859375,
    "ent_coef": 0.11082859337329865,
    "learning_rate": 0.001
  },
  {
    "episode": 5684,
    "reward": 71.036484,
    "length": 99,
    "time": 88085.947713,
    "actor_loss": -71.25346374511719,
    "critic_loss": 14.472627639770508,
    "ent_coef": 0.115044005215168,
    "learning_rate": 0.001
  },
  {
    "episode": 5685,
    "reward": 78.731323,
    "length": 82,
    "time": 88105.020058,
    "actor_loss": -65.31131744384766,
    "critic_loss": 29.265995025634766,
    "ent_coef": 0.11471959948539734,
    "learning_rate": 0.001
  },
  {
    "episode": 5686,
    "reward": 21.334732,
    "length": 166,
    "time": 88132.993509,
    "actor_loss": -66.65724182128906,
    "critic_loss": 32.99269104003906,
    "ent_coef": 0.10879912972450256,
    "learning_rate": 0.001
  },
  {
    "episode": 5687,
    "reward": 83.855212,
    "length": 73,
    "time": 88147.072111,
    "actor_loss": -50.6832275390625,
    "critic_loss": 50.96208190917969,
    "ent_coef": 0.11552920192480087,
    "learning_rate": 0.001
  },
  {
    "episode": 5688,
    "reward": 82.201433,
    "length": 76,
    "time": 88160.96215,
    "actor_loss": -64.5367660522461,
    "critic_loss": 851.099365234375,
    "ent_coef": 0.11543183773756027,
    "learning_rate": 0.001
  },
  {
    "episode": 5689,
    "reward": 90.419311,
    "length": 62,
    "time": 88175.713514,
    "actor_loss": -61.73181915283203,
    "critic_loss": 35.06648254394531,
    "ent_coef": 0.11947478353977203,
    "learning_rate": 0.001
  },
  {
    "episode": 5690,
    "reward": 89.209217,
    "length": 66,
    "time": 88189.080961,
    "actor_loss": -59.88775634765625,
    "critic_loss": 28.305984497070312,
    "ent_coef": 0.12175089120864868,
    "learning_rate": 0.001
  },
  {
    "episode": 5691,
    "reward": 83.156643,
    "length": 77,
    "time": 88205.332605,
    "actor_loss": -66.85967254638672,
    "critic_loss": 86.41163635253906,
    "ent_coef": 0.12524470686912537,
    "learning_rate": 0.001
  },
  {
    "episode": 5692,
    "reward": 78.451969,
    "length": 83,
    "time": 88220.582547,
    "actor_loss": -64.25194549560547,
    "critic_loss": 53.756072998046875,
    "ent_coef": 0.12677940726280212,
    "learning_rate": 0.001
  },
  {
    "episode": 5693,
    "reward": 66.398427,
    "length": 99,
    "time": 88238.29424,
    "actor_loss": -61.73460006713867,
    "critic_loss": 39.06867218017578,
    "ent_coef": 0.1258848011493683,
    "learning_rate": 0.001
  },
  {
    "episode": 5694,
    "reward": 79.010139,
    "length": 86,
    "time": 88255.477708,
    "actor_loss": -58.80198287963867,
    "critic_loss": 6.427968978881836,
    "ent_coef": 0.12695804238319397,
    "learning_rate": 0.001
  },
  {
    "episode": 5695,
    "reward": 82.939535,
    "length": 80,
    "time": 88270.062337,
    "actor_loss": -67.21588134765625,
    "critic_loss": 9.826756477355957,
    "ent_coef": 0.13097406923770905,
    "learning_rate": 0.001
  },
  {
    "episode": 5696,
    "reward": 83.581775,
    "length": 74,
    "time": 88285.542157,
    "actor_loss": -61.699283599853516,
    "critic_loss": 71.01705932617188,
    "ent_coef": 0.13272324204444885,
    "learning_rate": 0.001
  },
  {
    "episode": 5697,
    "reward": 76.545855,
    "length": 86,
    "time": 88301.500484,
    "actor_loss": -65.47076416015625,
    "critic_loss": 55.84785461425781,
    "ent_coef": 0.12579670548439026,
    "learning_rate": 0.001
  },
  {
    "episode": 5698,
    "reward": 72.77391,
    "length": 97,
    "time": 88318.634727,
    "actor_loss": -71.9124526977539,
    "critic_loss": 40.232704162597656,
    "ent_coef": 0.1282256543636322,
    "learning_rate": 0.001
  },
  {
    "episode": 5699,
    "reward": 83.145541,
    "length": 82,
    "time": 88333.227253,
    "actor_loss": -59.71318054199219,
    "critic_loss": 12.439212799072266,
    "ent_coef": 0.13227014243602753,
    "learning_rate": 0.001
  },
  {
    "episode": 5700,
    "reward": 84.62965,
    "length": 73,
    "time": 88349.225248,
    "actor_loss": -55.90032958984375,
    "critic_loss": 41.93098449707031,
    "ent_coef": 0.12878866493701935,
    "learning_rate": 0.001
  },
  {
    "episode": 5701,
    "reward": 65.712746,
    "length": 102,
    "time": 88367.150155,
    "actor_loss": -60.95378112792969,
    "critic_loss": 41.00519561767578,
    "ent_coef": 0.12142256647348404,
    "learning_rate": 0.001
  },
  {
    "episode": 5702,
    "reward": 76.464015,
    "length": 88,
    "time": 88384.668811,
    "actor_loss": -68.25078582763672,
    "critic_loss": 15.483745574951172,
    "ent_coef": 0.11541244387626648,
    "learning_rate": 0.001
  },
  {
    "episode": 5703,
    "reward": 43.566872,
    "length": 136,
    "time": 88405.909074,
    "actor_loss": -66.73614501953125,
    "critic_loss": 20.696571350097656,
    "ent_coef": 0.10665696859359741,
    "learning_rate": 0.001
  },
  {
    "episode": 5704,
    "reward": 51.328708,
    "length": 123,
    "time": 88425.843354,
    "actor_loss": -57.63041305541992,
    "critic_loss": 55.90302276611328,
    "ent_coef": 0.10250461101531982,
    "learning_rate": 0.001
  },
  {
    "episode": 5705,
    "reward": 77.959782,
    "length": 89,
    "time": 88441.391199,
    "actor_loss": -58.40024185180664,
    "critic_loss": 14.968219757080078,
    "ent_coef": 0.1013265997171402,
    "learning_rate": 0.001
  },
  {
    "episode": 5706,
    "reward": 78.293542,
    "length": 90,
    "time": 88457.371179,
    "actor_loss": -60.16367721557617,
    "critic_loss": 12.674516677856445,
    "ent_coef": 0.1040339320898056,
    "learning_rate": 0.001
  },
  {
    "episode": 5707,
    "reward": 86.070221,
    "length": 76,
    "time": 88470.23705,
    "actor_loss": -69.069580078125,
    "critic_loss": 21.80908203125,
    "ent_coef": 0.10753706842660904,
    "learning_rate": 0.001
  },
  {
    "episode": 5708,
    "reward": 83.66262,
    "length": 74,
    "time": 88482.676597,
    "actor_loss": -63.204429626464844,
    "critic_loss": 100.72186279296875,
    "ent_coef": 0.10726989060640335,
    "learning_rate": 0.001
  },
  {
    "episode": 5709,
    "reward": 88.097693,
    "length": 66,
    "time": 88498.255981,
    "actor_loss": -58.011802673339844,
    "critic_loss": 23.7772159576416,
    "ent_coef": 0.112233467400074,
    "learning_rate": 0.001
  },
  {
    "episode": 5710,
    "reward": 82.04139,
    "length": 80,
    "time": 88512.624753,
    "actor_loss": -60.255638122558594,
    "critic_loss": 23.096744537353516,
    "ent_coef": 0.11766086518764496,
    "learning_rate": 0.001
  },
  {
    "episode": 5711,
    "reward": 82.54918,
    "length": 82,
    "time": 88529.515173,
    "actor_loss": -67.62448120117188,
    "critic_loss": 33.529754638671875,
    "ent_coef": 0.11587710678577423,
    "learning_rate": 0.001
  },
  {
    "episode": 5712,
    "reward": 83.026037,
    "length": 81,
    "time": 88545.215382,
    "actor_loss": -61.71676254272461,
    "critic_loss": 119.62142181396484,
    "ent_coef": 0.1199905276298523,
    "learning_rate": 0.001
  },
  {
    "episode": 5713,
    "reward": 73.129509,
    "length": 94,
    "time": 88561.391902,
    "actor_loss": -64.52049255371094,
    "critic_loss": 12.58737850189209,
    "ent_coef": 0.11522997915744781,
    "learning_rate": 0.001
  },
  {
    "episode": 5714,
    "reward": 79.068849,
    "length": 93,
    "time": 88577.946278,
    "actor_loss": -62.5947151184082,
    "critic_loss": 17.585067749023438,
    "ent_coef": 0.11653392016887665,
    "learning_rate": 0.001
  },
  {
    "episode": 5715,
    "reward": 72.633801,
    "length": 95,
    "time": 88593.496602,
    "actor_loss": -66.7356185913086,
    "critic_loss": 56.98828125,
    "ent_coef": 0.12049965560436249,
    "learning_rate": 0.001
  },
  {
    "episode": 5716,
    "reward": 69.901085,
    "length": 105,
    "time": 88610.646858,
    "actor_loss": -64.69320678710938,
    "critic_loss": 107.13108825683594,
    "ent_coef": 0.11179116368293762,
    "learning_rate": 0.001
  },
  {
    "episode": 5717,
    "reward": 13.752012,
    "length": 182,
    "time": 88637.91368,
    "actor_loss": -60.682762145996094,
    "critic_loss": 36.028724670410156,
    "ent_coef": 0.11053928732872009,
    "learning_rate": 0.001
  },
  {
    "episode": 5718,
    "reward": 83.136245,
    "length": 82,
    "time": 88652.150196,
    "actor_loss": -60.65605163574219,
    "critic_loss": 20.373592376708984,
    "ent_coef": 0.11720681935548782,
    "learning_rate": 0.001
  },
  {
    "episode": 5719,
    "reward": 70.93412,
    "length": 101,
    "time": 88668.273809,
    "actor_loss": -64.58273315429688,
    "critic_loss": 12.683265686035156,
    "ent_coef": 0.11807426810264587,
    "learning_rate": 0.001
  },
  {
    "episode": 5720,
    "reward": 80.938158,
    "length": 82,
    "time": 88682.811485,
    "actor_loss": -67.636962890625,
    "critic_loss": 124.23060607910156,
    "ent_coef": 0.1158326119184494,
    "learning_rate": 0.001
  },
  {
    "episode": 5721,
    "reward": 73.508644,
    "length": 97,
    "time": 88706.727142,
    "actor_loss": -69.46304321289062,
    "critic_loss": 12.849193572998047,
    "ent_coef": 0.11221002787351608,
    "learning_rate": 0.001
  },
  {
    "episode": 5722,
    "reward": 66.475897,
    "length": 104,
    "time": 88725.096107,
    "actor_loss": -51.30183410644531,
    "critic_loss": 36.91572189331055,
    "ent_coef": 0.10844873636960983,
    "learning_rate": 0.001
  },
  {
    "episode": 5723,
    "reward": 76.586608,
    "length": 86,
    "time": 88741.154566,
    "actor_loss": -61.63969421386719,
    "critic_loss": 27.438617706298828,
    "ent_coef": 0.10898245126008987,
    "learning_rate": 0.001
  },
  {
    "episode": 5724,
    "reward": 81.932704,
    "length": 77,
    "time": 88754.027831,
    "actor_loss": -60.67311477661133,
    "critic_loss": 54.153045654296875,
    "ent_coef": 0.11259748786687851,
    "learning_rate": 0.001
  },
  {
    "episode": 5725,
    "reward": 56.032056,
    "length": 121,
    "time": 88772.40837,
    "actor_loss": -62.79432678222656,
    "critic_loss": 49.907081604003906,
    "ent_coef": 0.10949406027793884,
    "learning_rate": 0.001
  },
  {
    "episode": 5726,
    "reward": 83.500448,
    "length": 74,
    "time": 88786.141257,
    "actor_loss": -61.70648956298828,
    "critic_loss": 117.13605499267578,
    "ent_coef": 0.10899260640144348,
    "learning_rate": 0.001
  },
  {
    "episode": 5727,
    "reward": 80.723749,
    "length": 82,
    "time": 88802.39694,
    "actor_loss": -60.478782653808594,
    "critic_loss": 11.092050552368164,
    "ent_coef": 0.11042118072509766,
    "learning_rate": 0.001
  },
  {
    "episode": 5728,
    "reward": 26.169394,
    "length": 155,
    "time": 88827.599324,
    "actor_loss": -69.2485580444336,
    "critic_loss": 11.241580963134766,
    "ent_coef": 0.11087048053741455,
    "learning_rate": 0.001
  },
  {
    "episode": 5729,
    "reward": -47.324945,
    "length": 259,
    "time": 88867.857578,
    "actor_loss": -60.73112106323242,
    "critic_loss": 12.260432243347168,
    "ent_coef": 0.10757020115852356,
    "learning_rate": 0.001
  },
  {
    "episode": 5730,
    "reward": 64.276906,
    "length": 118,
    "time": 88889.133666,
    "actor_loss": -67.94849395751953,
    "critic_loss": 28.545040130615234,
    "ent_coef": 0.11342958360910416,
    "learning_rate": 0.001
  },
  {
    "episode": 5731,
    "reward": 74.5307,
    "length": 114,
    "time": 88908.260424,
    "actor_loss": -65.42503356933594,
    "critic_loss": 18.97045135498047,
    "ent_coef": 0.11428272724151611,
    "learning_rate": 0.001
  },
  {
    "episode": 5732,
    "reward": 78.930947,
    "length": 83,
    "time": 88923.45777,
    "actor_loss": -57.37002182006836,
    "critic_loss": 9.326326370239258,
    "ent_coef": 0.1186857670545578,
    "learning_rate": 0.001
  },
  {
    "episode": 5733,
    "reward": 84.751811,
    "length": 74,
    "time": 88936.778859,
    "actor_loss": -61.95283508300781,
    "critic_loss": 12.50026798248291,
    "ent_coef": 0.11727381497621536,
    "learning_rate": 0.001
  },
  {
    "episode": 5734,
    "reward": 81.162978,
    "length": 82,
    "time": 88950.382409,
    "actor_loss": -56.78590774536133,
    "critic_loss": 10.773765563964844,
    "ent_coef": 0.11705569922924042,
    "learning_rate": 0.001
  },
  {
    "episode": 5735,
    "reward": 80.683289,
    "length": 81,
    "time": 88969.603328,
    "actor_loss": -60.27991485595703,
    "critic_loss": 14.84469223022461,
    "ent_coef": 0.11912881582975388,
    "learning_rate": 0.001
  },
  {
    "episode": 5736,
    "reward": 84.43384,
    "length": 76,
    "time": 88983.424651,
    "actor_loss": -65.83604431152344,
    "critic_loss": 10.60692024230957,
    "ent_coef": 0.11760182678699493,
    "learning_rate": 0.001
  },
  {
    "episode": 5737,
    "reward": 88.869654,
    "length": 68,
    "time": 88996.416091,
    "actor_loss": -62.93605422973633,
    "critic_loss": 14.232320785522461,
    "ent_coef": 0.12321330606937408,
    "learning_rate": 0.001
  },
  {
    "episode": 5738,
    "reward": 79.0105,
    "length": 84,
    "time": 89010.195554,
    "actor_loss": -66.28424072265625,
    "critic_loss": 15.092153549194336,
    "ent_coef": 0.125385582447052,
    "learning_rate": 0.001
  },
  {
    "episode": 5739,
    "reward": 84.563945,
    "length": 75,
    "time": 89024.409277,
    "actor_loss": -65.35914611816406,
    "critic_loss": 50.84471130371094,
    "ent_coef": 0.12183497846126556,
    "learning_rate": 0.001
  },
  {
    "episode": 5740,
    "reward": 75.427038,
    "length": 115,
    "time": 89044.239927,
    "actor_loss": -57.96128845214844,
    "critic_loss": 35.79629898071289,
    "ent_coef": 0.11886442452669144,
    "learning_rate": 0.001
  },
  {
    "episode": 5741,
    "reward": 72.0481,
    "length": 107,
    "time": 89063.383027,
    "actor_loss": -61.08909606933594,
    "critic_loss": 24.61792755126953,
    "ent_coef": 0.11475127935409546,
    "learning_rate": 0.001
  },
  {
    "episode": 5742,
    "reward": 63.346991,
    "length": 111,
    "time": 89083.206851,
    "actor_loss": -61.15615463256836,
    "critic_loss": 167.81924438476562,
    "ent_coef": 0.11319735646247864,
    "learning_rate": 0.001
  },
  {
    "episode": 5743,
    "reward": 54.010741,
    "length": 124,
    "time": 89102.097123,
    "actor_loss": -57.23230743408203,
    "critic_loss": 14.799040794372559,
    "ent_coef": 0.11657383292913437,
    "learning_rate": 0.001
  },
  {
    "episode": 5744,
    "reward": 82.788338,
    "length": 77,
    "time": 89117.755874,
    "actor_loss": -57.55073165893555,
    "critic_loss": 34.669090270996094,
    "ent_coef": 0.12035691738128662,
    "learning_rate": 0.001
  },
  {
    "episode": 5745,
    "reward": 79.221716,
    "length": 82,
    "time": 89133.342628,
    "actor_loss": -59.25624465942383,
    "critic_loss": 10.176223754882812,
    "ent_coef": 0.12162195146083832,
    "learning_rate": 0.001
  },
  {
    "episode": 5746,
    "reward": 76.398576,
    "length": 89,
    "time": 89147.822088,
    "actor_loss": -62.162689208984375,
    "critic_loss": 11.40317440032959,
    "ent_coef": 0.12372005730867386,
    "learning_rate": 0.001
  },
  {
    "episode": 5747,
    "reward": 66.538123,
    "length": 128,
    "time": 89167.511457,
    "actor_loss": -57.62089157104492,
    "critic_loss": 25.866291046142578,
    "ent_coef": 0.11364682018756866,
    "learning_rate": 0.001
  },
  {
    "episode": 5748,
    "reward": 37.383783,
    "length": 146,
    "time": 89189.548124,
    "actor_loss": -60.49162292480469,
    "critic_loss": 179.45574951171875,
    "ent_coef": 0.10207784175872803,
    "learning_rate": 0.001
  },
  {
    "episode": 5749,
    "reward": 85.130989,
    "length": 75,
    "time": 89204.632952,
    "actor_loss": -63.701171875,
    "critic_loss": 23.362133026123047,
    "ent_coef": 0.10310052335262299,
    "learning_rate": 0.001
  },
  {
    "episode": 5750,
    "reward": 79.495213,
    "length": 107,
    "time": 89223.744974,
    "actor_loss": -55.6690559387207,
    "critic_loss": 7.29369592666626,
    "ent_coef": 0.10030494630336761,
    "learning_rate": 0.001
  },
  {
    "episode": 5751,
    "reward": 68.099755,
    "length": 107,
    "time": 89243.209511,
    "actor_loss": -61.78880310058594,
    "critic_loss": 39.63428497314453,
    "ent_coef": 0.09855692088603973,
    "learning_rate": 0.001
  },
  {
    "episode": 5752,
    "reward": 76.850692,
    "length": 90,
    "time": 89258.751734,
    "actor_loss": -61.90145492553711,
    "critic_loss": 58.83427429199219,
    "ent_coef": 0.09631156921386719,
    "learning_rate": 0.001
  },
  {
    "episode": 5753,
    "reward": 68.658083,
    "length": 100,
    "time": 89274.606554,
    "actor_loss": -60.38313293457031,
    "critic_loss": 7.011364936828613,
    "ent_coef": 0.09406903386116028,
    "learning_rate": 0.001
  },
  {
    "episode": 5754,
    "reward": 0.293677,
    "length": 196,
    "time": 89302.832321,
    "actor_loss": -52.55504608154297,
    "critic_loss": 44.51844024658203,
    "ent_coef": 0.08554603159427643,
    "learning_rate": 0.001
  },
  {
    "episode": 5755,
    "reward": 6.255859,
    "length": 184,
    "time": 89330.056573,
    "actor_loss": -62.196815490722656,
    "critic_loss": 13.675772666931152,
    "ent_coef": 0.08872402459383011,
    "learning_rate": 0.001
  },
  {
    "episode": 5756,
    "reward": 82.109538,
    "length": 83,
    "time": 89343.701126,
    "actor_loss": -64.1319580078125,
    "critic_loss": 20.12514305114746,
    "ent_coef": 0.09125079959630966,
    "learning_rate": 0.001
  },
  {
    "episode": 5757,
    "reward": 76.455295,
    "length": 99,
    "time": 89360.666523,
    "actor_loss": -56.13724899291992,
    "critic_loss": 6.596322536468506,
    "ent_coef": 0.09692380577325821,
    "learning_rate": 0.001
  },
  {
    "episode": 5758,
    "reward": 63.431403,
    "length": 106,
    "time": 89377.910937,
    "actor_loss": -56.25459289550781,
    "critic_loss": 57.3026123046875,
    "ent_coef": 0.09892711788415909,
    "learning_rate": 0.001
  },
  {
    "episode": 5759,
    "reward": 9.108774,
    "length": 181,
    "time": 89405.464947,
    "actor_loss": -54.996864318847656,
    "critic_loss": 52.5028076171875,
    "ent_coef": 0.09214527159929276,
    "learning_rate": 0.001
  },
  {
    "episode": 5760,
    "reward": 47.44339,
    "length": 147,
    "time": 89428.955794,
    "actor_loss": -60.514060974121094,
    "critic_loss": 10.135031700134277,
    "ent_coef": 0.0966491773724556,
    "learning_rate": 0.001
  },
  {
    "episode": 5761,
    "reward": 67.357016,
    "length": 99,
    "time": 89446.211157,
    "actor_loss": -59.49091339111328,
    "critic_loss": 15.065497398376465,
    "ent_coef": 0.10699249804019928,
    "learning_rate": 0.001
  },
  {
    "episode": 5762,
    "reward": 80.018703,
    "length": 81,
    "time": 89461.675735,
    "actor_loss": -65.64632415771484,
    "critic_loss": 14.92713737487793,
    "ent_coef": 0.11833655834197998,
    "learning_rate": 0.001
  },
  {
    "episode": 5763,
    "reward": 82.068665,
    "length": 80,
    "time": 89476.726334,
    "actor_loss": -59.67876052856445,
    "critic_loss": 82.90431213378906,
    "ent_coef": 0.11558675020933151,
    "learning_rate": 0.001
  },
  {
    "episode": 5764,
    "reward": 67.80542,
    "length": 108,
    "time": 89495.688504,
    "actor_loss": -65.87272644042969,
    "critic_loss": 511.32867431640625,
    "ent_coef": 0.10321623086929321,
    "learning_rate": 0.001
  },
  {
    "episode": 5765,
    "reward": 80.408999,
    "length": 82,
    "time": 89511.761098,
    "actor_loss": -63.71868133544922,
    "critic_loss": 4.248359203338623,
    "ent_coef": 0.09648661315441132,
    "learning_rate": 0.001
  },
  {
    "episode": 5766,
    "reward": 83.980667,
    "length": 78,
    "time": 89527.74623,
    "actor_loss": -61.789512634277344,
    "critic_loss": 76.5953598022461,
    "ent_coef": 0.09163638204336166,
    "learning_rate": 0.001
  },
  {
    "episode": 5767,
    "reward": 86.472861,
    "length": 70,
    "time": 89539.744785,
    "actor_loss": -59.003326416015625,
    "critic_loss": 6.55490779876709,
    "ent_coef": 0.08934693038463593,
    "learning_rate": 0.001
  },
  {
    "episode": 5768,
    "reward": 87.374838,
    "length": 70,
    "time": 89551.678449,
    "actor_loss": -60.371036529541016,
    "critic_loss": 23.246644973754883,
    "ent_coef": 0.09050790965557098,
    "learning_rate": 0.001
  },
  {
    "episode": 5769,
    "reward": 72.134243,
    "length": 98,
    "time": 89568.337092,
    "actor_loss": -57.889854431152344,
    "critic_loss": 13.189117431640625,
    "ent_coef": 0.08587132394313812,
    "learning_rate": 0.001
  },
  {
    "episode": 5770,
    "reward": 81.688445,
    "length": 80,
    "time": 89586.041141,
    "actor_loss": -65.51708984375,
    "critic_loss": 9.844213485717773,
    "ent_coef": 0.0837482139468193,
    "learning_rate": 0.001
  },
  {
    "episode": 5771,
    "reward": 69.373144,
    "length": 166,
    "time": 89612.48221,
    "actor_loss": -61.69697570800781,
    "critic_loss": 32.89870071411133,
    "ent_coef": 0.0786173865199089,
    "learning_rate": 0.001
  },
  {
    "episode": 5772,
    "reward": 85.482518,
    "length": 73,
    "time": 89627.061726,
    "actor_loss": -63.383270263671875,
    "critic_loss": 61.371238708496094,
    "ent_coef": 0.07761025428771973,
    "learning_rate": 0.001
  },
  {
    "episode": 5773,
    "reward": 83.411979,
    "length": 78,
    "time": 89640.007401,
    "actor_loss": -58.63439178466797,
    "critic_loss": 13.429605484008789,
    "ent_coef": 0.0748647078871727,
    "learning_rate": 0.001
  },
  {
    "episode": 5774,
    "reward": 77.570771,
    "length": 88,
    "time": 89654.286947,
    "actor_loss": -65.45446014404297,
    "critic_loss": 34.135215759277344,
    "ent_coef": 0.06982512772083282,
    "learning_rate": 0.001
  },
  {
    "episode": 5775,
    "reward": 85.558254,
    "length": 74,
    "time": 89667.476372,
    "actor_loss": -58.811119079589844,
    "critic_loss": 69.43435668945312,
    "ent_coef": 0.07028544694185257,
    "learning_rate": 0.001
  },
  {
    "episode": 5776,
    "reward": 86.381487,
    "length": 73,
    "time": 89683.215076,
    "actor_loss": -65.35354614257812,
    "critic_loss": 19.515060424804688,
    "ent_coef": 0.07063443213701248,
    "learning_rate": 0.001
  },
  {
    "episode": 5777,
    "reward": 87.459197,
    "length": 71,
    "time": 89698.854076,
    "actor_loss": -62.10690689086914,
    "critic_loss": 9.873785018920898,
    "ent_coef": 0.07089969515800476,
    "learning_rate": 0.001
  },
  {
    "episode": 5778,
    "reward": 81.262188,
    "length": 80,
    "time": 89712.041057,
    "actor_loss": -60.107582092285156,
    "critic_loss": 78.06266784667969,
    "ent_coef": 0.07151414453983307,
    "learning_rate": 0.001
  },
  {
    "episode": 5779,
    "reward": 87.684434,
    "length": 70,
    "time": 89725.966891,
    "actor_loss": -61.7050666809082,
    "critic_loss": 23.82634735107422,
    "ent_coef": 0.070944644510746,
    "learning_rate": 0.001
  },
  {
    "episode": 5780,
    "reward": 80.910776,
    "length": 84,
    "time": 89740.761406,
    "actor_loss": -54.25235366821289,
    "critic_loss": 9.766294479370117,
    "ent_coef": 0.069860078394413,
    "learning_rate": 0.001
  },
  {
    "episode": 5781,
    "reward": 86.683815,
    "length": 71,
    "time": 89754.6318,
    "actor_loss": -57.68551254272461,
    "critic_loss": 5.56238317489624,
    "ent_coef": 0.06898985058069229,
    "learning_rate": 0.001
  },
  {
    "episode": 5782,
    "reward": 88.398792,
    "length": 69,
    "time": 89769.083571,
    "actor_loss": -60.049835205078125,
    "critic_loss": 7.868659496307373,
    "ent_coef": 0.06871677935123444,
    "learning_rate": 0.001
  },
  {
    "episode": 5783,
    "reward": 86.714334,
    "length": 70,
    "time": 89784.088984,
    "actor_loss": -58.73714828491211,
    "critic_loss": 16.623292922973633,
    "ent_coef": 0.07186681032180786,
    "learning_rate": 0.001
  },
  {
    "episode": 5784,
    "reward": 88.976082,
    "length": 67,
    "time": 89797.440954,
    "actor_loss": -59.60844802856445,
    "critic_loss": 58.23035430908203,
    "ent_coef": 0.07606466859579086,
    "learning_rate": 0.001
  },
  {
    "episode": 5785,
    "reward": 85.274878,
    "length": 71,
    "time": 89809.14059,
    "actor_loss": -64.0345458984375,
    "critic_loss": 9.94803237915039,
    "ent_coef": 0.0772770494222641,
    "learning_rate": 0.001
  },
  {
    "episode": 5786,
    "reward": 82.907496,
    "length": 78,
    "time": 89823.06203,
    "actor_loss": -61.52688980102539,
    "critic_loss": 91.00399780273438,
    "ent_coef": 0.0763600692152977,
    "learning_rate": 0.001
  },
  {
    "episode": 5787,
    "reward": 78.672944,
    "length": 83,
    "time": 89836.651376,
    "actor_loss": -60.82429122924805,
    "critic_loss": 43.24689483642578,
    "ent_coef": 0.07309150695800781,
    "learning_rate": 0.001
  },
  {
    "episode": 5788,
    "reward": 84.658124,
    "length": 74,
    "time": 89850.541508,
    "actor_loss": -55.279151916503906,
    "critic_loss": 6.812407493591309,
    "ent_coef": 0.0714784786105156,
    "learning_rate": 0.001
  },
  {
    "episode": 5789,
    "reward": 81.254183,
    "length": 80,
    "time": 89863.680477,
    "actor_loss": -58.60574722290039,
    "critic_loss": 29.198335647583008,
    "ent_coef": 0.0695997029542923,
    "learning_rate": 0.001
  },
  {
    "episode": 5790,
    "reward": 89.707295,
    "length": 65,
    "time": 89875.816615,
    "actor_loss": -59.51976776123047,
    "critic_loss": 20.256237030029297,
    "ent_coef": 0.07210975140333176,
    "learning_rate": 0.001
  },
  {
    "episode": 5791,
    "reward": 87.878795,
    "length": 66,
    "time": 89890.676533,
    "actor_loss": -55.11128616333008,
    "critic_loss": 15.102506637573242,
    "ent_coef": 0.07589715719223022,
    "learning_rate": 0.001
  },
  {
    "episode": 5792,
    "reward": 84.311183,
    "length": 73,
    "time": 89902.934927,
    "actor_loss": -59.908897399902344,
    "critic_loss": 9.19246768951416,
    "ent_coef": 0.07826732099056244,
    "learning_rate": 0.001
  },
  {
    "episode": 5793,
    "reward": 88.740896,
    "length": 67,
    "time": 89915.528384,
    "actor_loss": -55.4742317199707,
    "critic_loss": 27.451744079589844,
    "ent_coef": 0.08136249333620071,
    "learning_rate": 0.001
  },
  {
    "episode": 5794,
    "reward": 80.776659,
    "length": 81,
    "time": 89930.56159,
    "actor_loss": -58.36249542236328,
    "critic_loss": 20.13492202758789,
    "ent_coef": 0.07979830354452133,
    "learning_rate": 0.001
  },
  {
    "episode": 5795,
    "reward": 84.603831,
    "length": 74,
    "time": 89943.106739,
    "actor_loss": -58.22603988647461,
    "critic_loss": 67.83285522460938,
    "ent_coef": 0.0847831442952156,
    "learning_rate": 0.001
  },
  {
    "episode": 5796,
    "reward": 85.290048,
    "length": 73,
    "time": 89956.453947,
    "actor_loss": -59.73857116699219,
    "critic_loss": 53.8826904296875,
    "ent_coef": 0.08556536585092545,
    "learning_rate": 0.001
  },
  {
    "episode": 5797,
    "reward": 83.20996,
    "length": 76,
    "time": 89969.408029,
    "actor_loss": -60.6962890625,
    "critic_loss": 50.32390213012695,
    "ent_coef": 0.08581715822219849,
    "learning_rate": 0.001
  },
  {
    "episode": 5798,
    "reward": 84.861657,
    "length": 77,
    "time": 89984.641025,
    "actor_loss": -61.68109130859375,
    "critic_loss": 8.406088829040527,
    "ent_coef": 0.08592250943183899,
    "learning_rate": 0.001
  },
  {
    "episode": 5799,
    "reward": 85.482989,
    "length": 73,
    "time": 89999.00193,
    "actor_loss": -61.540225982666016,
    "critic_loss": 43.91471862792969,
    "ent_coef": 0.08482914417982101,
    "learning_rate": 0.001
  },
  {
    "episode": 5800,
    "reward": 86.008505,
    "length": 72,
    "time": 90011.319598,
    "actor_loss": -58.746437072753906,
    "critic_loss": 12.463895797729492,
    "ent_coef": 0.08100316673517227,
    "learning_rate": 0.001
  },
  {
    "episode": 5801,
    "reward": 78.796495,
    "length": 80,
    "time": 90025.011061,
    "actor_loss": -58.6873779296875,
    "critic_loss": 7.82783317565918,
    "ent_coef": 0.07500126957893372,
    "learning_rate": 0.001
  },
  {
    "episode": 5802,
    "reward": 85.760903,
    "length": 75,
    "time": 90038.292121,
    "actor_loss": -65.20442962646484,
    "critic_loss": 480.33294677734375,
    "ent_coef": 0.06953170150518417,
    "learning_rate": 0.001
  },
  {
    "episode": 5803,
    "reward": 88.449903,
    "length": 69,
    "time": 90055.294433,
    "actor_loss": -57.78776550292969,
    "critic_loss": 523.0399169921875,
    "ent_coef": 0.07304470241069794,
    "learning_rate": 0.001
  },
  {
    "episode": 5804,
    "reward": 89.427351,
    "length": 67,
    "time": 90066.67218,
    "actor_loss": -62.558406829833984,
    "critic_loss": 77.02470397949219,
    "ent_coef": 0.07696986198425293,
    "learning_rate": 0.001
  },
  {
    "episode": 5805,
    "reward": 86.168959,
    "length": 72,
    "time": 90080.119386,
    "actor_loss": -63.377464294433594,
    "critic_loss": 18.766054153442383,
    "ent_coef": 0.07683496922254562,
    "learning_rate": 0.001
  },
  {
    "episode": 5806,
    "reward": 85.048022,
    "length": 74,
    "time": 90093.133791,
    "actor_loss": -57.327701568603516,
    "critic_loss": 13.629400253295898,
    "ent_coef": 0.07690650224685669,
    "learning_rate": 0.001
  },
  {
    "episode": 5807,
    "reward": 88.762747,
    "length": 66,
    "time": 90105.403537,
    "actor_loss": -58.08617401123047,
    "critic_loss": 14.149225234985352,
    "ent_coef": 0.07814887911081314,
    "learning_rate": 0.001
  },
  {
    "episode": 5808,
    "reward": 89.652555,
    "length": 65,
    "time": 90118.080072,
    "actor_loss": -55.985931396484375,
    "critic_loss": 99.52151489257812,
    "ent_coef": 0.08167330920696259,
    "learning_rate": 0.001
  },
  {
    "episode": 5809,
    "reward": 86.487945,
    "length": 72,
    "time": 90130.200449,
    "actor_loss": -60.01409912109375,
    "critic_loss": 14.114086151123047,
    "ent_coef": 0.08013484627008438,
    "learning_rate": 0.001
  },
  {
    "episode": 5810,
    "reward": 87.901689,
    "length": 67,
    "time": 90141.566248,
    "actor_loss": -60.3571891784668,
    "critic_loss": 8.96225357055664,
    "ent_coef": 0.08132510632276535,
    "learning_rate": 0.001
  },
  {
    "episode": 5811,
    "reward": 90.098689,
    "length": 64,
    "time": 90153.399638,
    "actor_loss": -65.01815032958984,
    "critic_loss": 13.959846496582031,
    "ent_coef": 0.09120015799999237,
    "learning_rate": 0.001
  },
  {
    "episode": 5812,
    "reward": 88.253659,
    "length": 68,
    "time": 90166.621195,
    "actor_loss": -59.45225524902344,
    "critic_loss": 38.62217712402344,
    "ent_coef": 0.09546446800231934,
    "learning_rate": 0.001
  },
  {
    "episode": 5813,
    "reward": 81.576015,
    "length": 77,
    "time": 90179.170038,
    "actor_loss": -60.265892028808594,
    "critic_loss": 11.192808151245117,
    "ent_coef": 0.09821400791406631,
    "learning_rate": 0.001
  },
  {
    "episode": 5814,
    "reward": 88.143351,
    "length": 67,
    "time": 90191.406127,
    "actor_loss": -58.21967697143555,
    "critic_loss": 62.48467254638672,
    "ent_coef": 0.10216135531663895,
    "learning_rate": 0.001
  },
  {
    "episode": 5815,
    "reward": 87.970769,
    "length": 69,
    "time": 90203.960096,
    "actor_loss": -59.06376266479492,
    "critic_loss": 22.280261993408203,
    "ent_coef": 0.10171142220497131,
    "learning_rate": 0.001
  },
  {
    "episode": 5816,
    "reward": 87.499722,
    "length": 69,
    "time": 90217.980092,
    "actor_loss": -66.9655532836914,
    "critic_loss": 31.9573917388916,
    "ent_coef": 0.09945017099380493,
    "learning_rate": 0.001
  },
  {
    "episode": 5817,
    "reward": 85.851489,
    "length": 74,
    "time": 90230.186981,
    "actor_loss": -60.97502899169922,
    "critic_loss": 41.89883041381836,
    "ent_coef": 0.09587929397821426,
    "learning_rate": 0.001
  },
  {
    "episode": 5818,
    "reward": 84.894544,
    "length": 75,
    "time": 90242.465118,
    "actor_loss": -60.95250701904297,
    "critic_loss": 5.105496406555176,
    "ent_coef": 0.08987051248550415,
    "learning_rate": 0.001
  },
  {
    "episode": 5819,
    "reward": 87.855373,
    "length": 72,
    "time": 90254.578475,
    "actor_loss": -58.203800201416016,
    "critic_loss": 36.45704650878906,
    "ent_coef": 0.08852395415306091,
    "learning_rate": 0.001
  },
  {
    "episode": 5820,
    "reward": 90.201151,
    "length": 64,
    "time": 90265.705544,
    "actor_loss": -59.2386589050293,
    "critic_loss": 24.55484390258789,
    "ent_coef": 0.08919671177864075,
    "learning_rate": 0.001
  },
  {
    "episode": 5821,
    "reward": 80.876008,
    "length": 85,
    "time": 90280.827933,
    "actor_loss": -61.08582305908203,
    "critic_loss": 118.31070709228516,
    "ent_coef": 0.09201674908399582,
    "learning_rate": 0.001
  },
  {
    "episode": 5822,
    "reward": 83.383417,
    "length": 78,
    "time": 90295.986162,
    "actor_loss": -63.39826202392578,
    "critic_loss": 32.199989318847656,
    "ent_coef": 0.08869744092226028,
    "learning_rate": 0.001
  },
  {
    "episode": 5823,
    "reward": 86.121193,
    "length": 72,
    "time": 90311.004769,
    "actor_loss": -59.055686950683594,
    "critic_loss": 26.725831985473633,
    "ent_coef": 0.08909114450216293,
    "learning_rate": 0.001
  },
  {
    "episode": 5824,
    "reward": 81.045234,
    "length": 79,
    "time": 90324.046737,
    "actor_loss": -54.07666015625,
    "critic_loss": 37.80998229980469,
    "ent_coef": 0.08506342768669128,
    "learning_rate": 0.001
  },
  {
    "episode": 5825,
    "reward": 88.117475,
    "length": 69,
    "time": 90335.853957,
    "actor_loss": -59.48530578613281,
    "critic_loss": 25.11847686767578,
    "ent_coef": 0.08405912667512894,
    "learning_rate": 0.001
  },
  {
    "episode": 5826,
    "reward": 81.969841,
    "length": 79,
    "time": 90349.983713,
    "actor_loss": -59.40506362915039,
    "critic_loss": 16.862873077392578,
    "ent_coef": 0.08136938512325287,
    "learning_rate": 0.001
  },
  {
    "episode": 5827,
    "reward": 82.762022,
    "length": 75,
    "time": 90363.518268,
    "actor_loss": -53.43897247314453,
    "critic_loss": 38.46009826660156,
    "ent_coef": 0.08914526551961899,
    "learning_rate": 0.001
  },
  {
    "episode": 5828,
    "reward": 89.011459,
    "length": 70,
    "time": 90376.66664,
    "actor_loss": -63.76359176635742,
    "critic_loss": 20.677825927734375,
    "ent_coef": 0.09465958178043365,
    "learning_rate": 0.001
  },
  {
    "episode": 5829,
    "reward": 78.53438,
    "length": 84,
    "time": 90391.41921,
    "actor_loss": -69.70706176757812,
    "critic_loss": 8.987619400024414,
    "ent_coef": 0.08949139714241028,
    "learning_rate": 0.001
  },
  {
    "episode": 5830,
    "reward": 87.210286,
    "length": 70,
    "time": 90404.191677,
    "actor_loss": -58.87382888793945,
    "critic_loss": 31.121158599853516,
    "ent_coef": 0.0855320394039154,
    "learning_rate": 0.001
  },
  {
    "episode": 5831,
    "reward": 87.511914,
    "length": 68,
    "time": 90416.09705,
    "actor_loss": -63.70873260498047,
    "critic_loss": 8.716133117675781,
    "ent_coef": 0.08330782502889633,
    "learning_rate": 0.001
  },
  {
    "episode": 5832,
    "reward": 87.365699,
    "length": 68,
    "time": 90430.547941,
    "actor_loss": -54.379112243652344,
    "critic_loss": 13.097451210021973,
    "ent_coef": 0.08027040213346481,
    "learning_rate": 0.001
  },
  {
    "episode": 5833,
    "reward": 88.318875,
    "length": 68,
    "time": 90442.45514,
    "actor_loss": -54.964942932128906,
    "critic_loss": 29.82769012451172,
    "ent_coef": 0.07746021449565887,
    "learning_rate": 0.001
  },
  {
    "episode": 5834,
    "reward": 85.280336,
    "length": 75,
    "time": 90458.620806,
    "actor_loss": -63.7767333984375,
    "critic_loss": 6.107499122619629,
    "ent_coef": 0.0739666298031807,
    "learning_rate": 0.001
  },
  {
    "episode": 5835,
    "reward": 87.499457,
    "length": 68,
    "time": 90470.191059,
    "actor_loss": -61.20103454589844,
    "critic_loss": 13.517363548278809,
    "ent_coef": 0.0728718489408493,
    "learning_rate": 0.001
  },
  {
    "episode": 5836,
    "reward": 89.331979,
    "length": 66,
    "time": 90484.40574,
    "actor_loss": -56.83306121826172,
    "critic_loss": 5.705550193786621,
    "ent_coef": 0.07298865914344788,
    "learning_rate": 0.001
  },
  {
    "episode": 5837,
    "reward": 85.062701,
    "length": 73,
    "time": 90496.481534,
    "actor_loss": -61.97181701660156,
    "critic_loss": 27.7994384765625,
    "ent_coef": 0.07426409423351288,
    "learning_rate": 0.001
  },
  {
    "episode": 5838,
    "reward": 87.358876,
    "length": 72,
    "time": 90508.607348,
    "actor_loss": -64.190185546875,
    "critic_loss": 7.813127040863037,
    "ent_coef": 0.0735238566994667,
    "learning_rate": 0.001
  },
  {
    "episode": 5839,
    "reward": 85.615508,
    "length": 73,
    "time": 90524.154398,
    "actor_loss": -67.03755187988281,
    "critic_loss": 73.15617370605469,
    "ent_coef": 0.07234685122966766,
    "learning_rate": 0.001
  },
  {
    "episode": 5840,
    "reward": 85.879417,
    "length": 74,
    "time": 90536.520716,
    "actor_loss": -53.55611801147461,
    "critic_loss": 12.228402137756348,
    "ent_coef": 0.07361511886119843,
    "learning_rate": 0.001
  },
  {
    "episode": 5841,
    "reward": 85.340045,
    "length": 71,
    "time": 90551.512817,
    "actor_loss": -52.4265022277832,
    "critic_loss": 17.048389434814453,
    "ent_coef": 0.07409035414457321,
    "learning_rate": 0.001
  },
  {
    "episode": 5842,
    "reward": 87.567499,
    "length": 68,
    "time": 90564.141577,
    "actor_loss": -59.610923767089844,
    "critic_loss": 14.139764785766602,
    "ent_coef": 0.07548535615205765,
    "learning_rate": 0.001
  },
  {
    "episode": 5843,
    "reward": 88.368754,
    "length": 68,
    "time": 90577.709187,
    "actor_loss": -63.05919647216797,
    "critic_loss": 8.574958801269531,
    "ent_coef": 0.07776110619306564,
    "learning_rate": 0.001
  },
  {
    "episode": 5844,
    "reward": 88.490426,
    "length": 67,
    "time": 90591.916531,
    "actor_loss": -59.08167266845703,
    "critic_loss": 11.460830688476562,
    "ent_coef": 0.08042192459106445,
    "learning_rate": 0.001
  },
  {
    "episode": 5845,
    "reward": 90.257445,
    "length": 64,
    "time": 90604.326193,
    "actor_loss": -63.18198013305664,
    "critic_loss": 12.247121810913086,
    "ent_coef": 0.08252505958080292,
    "learning_rate": 0.001
  },
  {
    "episode": 5846,
    "reward": 89.392819,
    "length": 65,
    "time": 90619.131623,
    "actor_loss": -57.90057373046875,
    "critic_loss": 49.81147003173828,
    "ent_coef": 0.08382190763950348,
    "learning_rate": 0.001
  },
  {
    "episode": 5847,
    "reward": 89.409261,
    "length": 66,
    "time": 90634.273617,
    "actor_loss": -65.3006591796875,
    "critic_loss": 72.499755859375,
    "ent_coef": 0.08325572311878204,
    "learning_rate": 0.001
  },
  {
    "episode": 5848,
    "reward": 89.277846,
    "length": 65,
    "time": 90648.391281,
    "actor_loss": -59.689491271972656,
    "critic_loss": 4.487838268280029,
    "ent_coef": 0.08369100838899612,
    "learning_rate": 0.001
  },
  {
    "episode": 5849,
    "reward": 88.870252,
    "length": 67,
    "time": 90661.054834,
    "actor_loss": -61.21706771850586,
    "critic_loss": 16.53414535522461,
    "ent_coef": 0.08122319728136063,
    "learning_rate": 0.001
  },
  {
    "episode": 5850,
    "reward": 88.677988,
    "length": 66,
    "time": 90672.430642,
    "actor_loss": -59.168243408203125,
    "critic_loss": 24.851293563842773,
    "ent_coef": 0.08460655808448792,
    "learning_rate": 0.001
  },
  {
    "episode": 5851,
    "reward": 86.741135,
    "length": 68,
    "time": 90684.537017,
    "actor_loss": -62.34691619873047,
    "critic_loss": 33.19685745239258,
    "ent_coef": 0.08778783679008484,
    "learning_rate": 0.001
  },
  {
    "episode": 5852,
    "reward": 83.575211,
    "length": 75,
    "time": 90699.722947,
    "actor_loss": -63.2908821105957,
    "critic_loss": 19.7509765625,
    "ent_coef": 0.08646538108587265,
    "learning_rate": 0.001
  },
  {
    "episode": 5853,
    "reward": 87.815661,
    "length": 68,
    "time": 90712.724755,
    "actor_loss": -64.90200805664062,
    "critic_loss": 5.184496879577637,
    "ent_coef": 0.08839915692806244,
    "learning_rate": 0.001
  },
  {
    "episode": 5854,
    "reward": 87.924216,
    "length": 68,
    "time": 90726.188309,
    "actor_loss": -60.62928009033203,
    "critic_loss": 4.644457817077637,
    "ent_coef": 0.08793023973703384,
    "learning_rate": 0.001
  },
  {
    "episode": 5855,
    "reward": 88.381271,
    "length": 67,
    "time": 90737.767816,
    "actor_loss": -60.134422302246094,
    "critic_loss": 14.142394065856934,
    "ent_coef": 0.08956832438707352,
    "learning_rate": 0.001
  },
  {
    "episode": 5856,
    "reward": 86.403019,
    "length": 72,
    "time": 90750.370799,
    "actor_loss": -61.768795013427734,
    "critic_loss": 6.7320942878723145,
    "ent_coef": 0.0875653624534607,
    "learning_rate": 0.001
  },
  {
    "episode": 5857,
    "reward": 89.31926,
    "length": 65,
    "time": 90761.756562,
    "actor_loss": -57.704200744628906,
    "critic_loss": 9.60138988494873,
    "ent_coef": 0.08934281766414642,
    "learning_rate": 0.001
  },
  {
    "episode": 5858,
    "reward": 82.064864,
    "length": 79,
    "time": 90775.880363,
    "actor_loss": -68.80108642578125,
    "critic_loss": 47.12474060058594,
    "ent_coef": 0.08148825913667679,
    "learning_rate": 0.001
  },
  {
    "episode": 5859,
    "reward": 82.321778,
    "length": 83,
    "time": 90789.516278,
    "actor_loss": -62.82598876953125,
    "critic_loss": 36.73249816894531,
    "ent_coef": 0.07564592361450195,
    "learning_rate": 0.001
  },
  {
    "episode": 5860,
    "reward": 86.288174,
    "length": 71,
    "time": 90803.329679,
    "actor_loss": -60.84987258911133,
    "critic_loss": 82.62159729003906,
    "ent_coef": 0.07618238776922226,
    "learning_rate": 0.001
  },
  {
    "episode": 5861,
    "reward": 87.879376,
    "length": 69,
    "time": 90818.094694,
    "actor_loss": -69.04887390136719,
    "critic_loss": 4.287841796875,
    "ent_coef": 0.07459033280611038,
    "learning_rate": 0.001
  },
  {
    "episode": 5862,
    "reward": 87.421213,
    "length": 69,
    "time": 90829.979237,
    "actor_loss": -67.62960815429688,
    "critic_loss": 79.2982406616211,
    "ent_coef": 0.07328250259160995,
    "learning_rate": 0.001
  },
  {
    "episode": 5863,
    "reward": 88.183827,
    "length": 68,
    "time": 90843.521276,
    "actor_loss": -60.93656921386719,
    "critic_loss": 33.33159255981445,
    "ent_coef": 0.07373064011335373,
    "learning_rate": 0.001
  },
  {
    "episode": 5864,
    "reward": 88.997838,
    "length": 66,
    "time": 90857.636615,
    "actor_loss": -64.31794738769531,
    "critic_loss": 18.849224090576172,
    "ent_coef": 0.07444076240062714,
    "learning_rate": 0.001
  },
  {
    "episode": 5865,
    "reward": 88.18465,
    "length": 67,
    "time": 90869.775863,
    "actor_loss": -64.09638977050781,
    "critic_loss": 18.501689910888672,
    "ent_coef": 0.07607206702232361,
    "learning_rate": 0.001
  },
  {
    "episode": 5866,
    "reward": 85.572635,
    "length": 72,
    "time": 90883.951367,
    "actor_loss": -60.5118522644043,
    "critic_loss": 17.348533630371094,
    "ent_coef": 0.07512679696083069,
    "learning_rate": 0.001
  },
  {
    "episode": 5867,
    "reward": 87.896067,
    "length": 69,
    "time": 90897.180892,
    "actor_loss": -61.451133728027344,
    "critic_loss": 10.246353149414062,
    "ent_coef": 0.0762704536318779,
    "learning_rate": 0.001
  },
  {
    "episode": 5868,
    "reward": 88.455717,
    "length": 68,
    "time": 90910.506474,
    "actor_loss": -61.441062927246094,
    "critic_loss": 14.606709480285645,
    "ent_coef": 0.07502789795398712,
    "learning_rate": 0.001
  },
  {
    "episode": 5869,
    "reward": 88.615494,
    "length": 67,
    "time": 90922.047159,
    "actor_loss": -61.68140411376953,
    "critic_loss": 12.799182891845703,
    "ent_coef": 0.07198359072208405,
    "learning_rate": 0.001
  },
  {
    "episode": 5870,
    "reward": 86.927061,
    "length": 72,
    "time": 90934.128153,
    "actor_loss": -62.50907516479492,
    "critic_loss": 42.868553161621094,
    "ent_coef": 0.07057943195104599,
    "learning_rate": 0.001
  },
  {
    "episode": 5871,
    "reward": 85.714818,
    "length": 71,
    "time": 90946.722212,
    "actor_loss": -64.84857940673828,
    "critic_loss": 7.290996551513672,
    "ent_coef": 0.07335786521434784,
    "learning_rate": 0.001
  },
  {
    "episode": 5872,
    "reward": 86.65864,
    "length": 70,
    "time": 90961.444272,
    "actor_loss": -66.9525146484375,
    "critic_loss": 13.906686782836914,
    "ent_coef": 0.07654298096895218,
    "learning_rate": 0.001
  },
  {
    "episode": 5873,
    "reward": 86.612333,
    "length": 70,
    "time": 90976.848922,
    "actor_loss": -56.422035217285156,
    "critic_loss": 8.780967712402344,
    "ent_coef": 0.07810921221971512,
    "learning_rate": 0.001
  },
  {
    "episode": 5874,
    "reward": 85.427105,
    "length": 76,
    "time": 90989.354592,
    "actor_loss": -69.843505859375,
    "critic_loss": 9.313880920410156,
    "ent_coef": 0.07858729362487793,
    "learning_rate": 0.001
  },
  {
    "episode": 5875,
    "reward": 88.481309,
    "length": 67,
    "time": 91000.877237,
    "actor_loss": -56.90436935424805,
    "critic_loss": 11.062606811523438,
    "ent_coef": 0.08227939158678055,
    "learning_rate": 0.001
  },
  {
    "episode": 5876,
    "reward": 76.256274,
    "length": 91,
    "time": 91015.630233,
    "actor_loss": -58.57278823852539,
    "critic_loss": 6.070812225341797,
    "ent_coef": 0.07996635884046555,
    "learning_rate": 0.001
  },
  {
    "episode": 5877,
    "reward": 87.539418,
    "length": 70,
    "time": 91030.754318,
    "actor_loss": -62.6755485534668,
    "critic_loss": 6.102361679077148,
    "ent_coef": 0.07901903986930847,
    "learning_rate": 0.001
  },
  {
    "episode": 5878,
    "reward": 83.696497,
    "length": 80,
    "time": 91044.091155,
    "actor_loss": -60.22829818725586,
    "critic_loss": 199.12542724609375,
    "ent_coef": 0.07757177948951721,
    "learning_rate": 0.001
  },
  {
    "episode": 5879,
    "reward": 86.466741,
    "length": 70,
    "time": 91055.978821,
    "actor_loss": -58.95442199707031,
    "critic_loss": 16.876811981201172,
    "ent_coef": 0.07781027257442474,
    "learning_rate": 0.001
  },
  {
    "episode": 5880,
    "reward": 83.672835,
    "length": 80,
    "time": 91070.299904,
    "actor_loss": -58.22918701171875,
    "critic_loss": 8.45041275024414,
    "ent_coef": 0.07539638131856918,
    "learning_rate": 0.001
  },
  {
    "episode": 5881,
    "reward": 76.311873,
    "length": 93,
    "time": 91086.633157,
    "actor_loss": -67.16838073730469,
    "critic_loss": 22.020339965820312,
    "ent_coef": 0.07450233399868011,
    "learning_rate": 0.001
  },
  {
    "episode": 5882,
    "reward": 86.937943,
    "length": 72,
    "time": 91100.147817,
    "actor_loss": -63.562992095947266,
    "critic_loss": 14.830995559692383,
    "ent_coef": 0.07840479165315628,
    "learning_rate": 0.001
  },
  {
    "episode": 5883,
    "reward": 78.636431,
    "length": 91,
    "time": 91115.5718,
    "actor_loss": -68.4715576171875,
    "critic_loss": 11.710386276245117,
    "ent_coef": 0.07759340107440948,
    "learning_rate": 0.001
  },
  {
    "episode": 5884,
    "reward": 86.864302,
    "length": 72,
    "time": 91127.686621,
    "actor_loss": -64.78691101074219,
    "critic_loss": 6.341160774230957,
    "ent_coef": 0.07993115484714508,
    "learning_rate": 0.001
  },
  {
    "episode": 5885,
    "reward": 79.346222,
    "length": 86,
    "time": 91141.581732,
    "actor_loss": -66.87469482421875,
    "critic_loss": 6.5007829666137695,
    "ent_coef": 0.07603117823600769,
    "learning_rate": 0.001
  },
  {
    "episode": 5886,
    "reward": 87.801333,
    "length": 70,
    "time": 91155.498774,
    "actor_loss": -63.547462463378906,
    "critic_loss": 5.797607421875,
    "ent_coef": 0.07469609379768372,
    "learning_rate": 0.001
  },
  {
    "episode": 5887,
    "reward": 82.17074,
    "length": 79,
    "time": 91168.603958,
    "actor_loss": -60.043190002441406,
    "critic_loss": 10.874482154846191,
    "ent_coef": 0.07479450106620789,
    "learning_rate": 0.001
  },
  {
    "episode": 5888,
    "reward": 88.815127,
    "length": 67,
    "time": 91182.001925,
    "actor_loss": -57.2436408996582,
    "critic_loss": 118.27881622314453,
    "ent_coef": 0.07971218228340149,
    "learning_rate": 0.001
  },
  {
    "episode": 5889,
    "reward": 89.441308,
    "length": 64,
    "time": 91193.068425,
    "actor_loss": -66.3147964477539,
    "critic_loss": 11.872650146484375,
    "ent_coef": 0.08349668979644775,
    "learning_rate": 0.001
  },
  {
    "episode": 5890,
    "reward": 89.29743,
    "length": 67,
    "time": 91207.604895,
    "actor_loss": -63.76971435546875,
    "critic_loss": 24.779438018798828,
    "ent_coef": 0.08953791856765747,
    "learning_rate": 0.001
  },
  {
    "episode": 5891,
    "reward": 88.460141,
    "length": 68,
    "time": 91220.021064,
    "actor_loss": -65.22787475585938,
    "critic_loss": 20.816383361816406,
    "ent_coef": 0.09310629963874817,
    "learning_rate": 0.001
  },
  {
    "episode": 5892,
    "reward": 89.538131,
    "length": 64,
    "time": 91234.245462,
    "actor_loss": -66.42642974853516,
    "critic_loss": 27.248245239257812,
    "ent_coef": 0.09465814381837845,
    "learning_rate": 0.001
  },
  {
    "episode": 5893,
    "reward": 86.57877,
    "length": 72,
    "time": 91246.350855,
    "actor_loss": -63.12398147583008,
    "critic_loss": 15.791702270507812,
    "ent_coef": 0.0968923345208168,
    "learning_rate": 0.001
  },
  {
    "episode": 5894,
    "reward": 90.617765,
    "length": 65,
    "time": 91258.642497,
    "actor_loss": -60.14336395263672,
    "critic_loss": 17.982685089111328,
    "ent_coef": 0.09919621795415878,
    "learning_rate": 0.001
  },
  {
    "episode": 5895,
    "reward": 87.334279,
    "length": 68,
    "time": 91271.448792,
    "actor_loss": -57.08372497558594,
    "critic_loss": 17.112401962280273,
    "ent_coef": 0.10322022438049316,
    "learning_rate": 0.001
  },
  {
    "episode": 5896,
    "reward": 82.789756,
    "length": 78,
    "time": 91284.290886,
    "actor_loss": -64.29158020019531,
    "critic_loss": 403.323486328125,
    "ent_coef": 0.10094889998435974,
    "learning_rate": 0.001
  },
  {
    "episode": 5897,
    "reward": 87.769137,
    "length": 68,
    "time": 91300.760018,
    "actor_loss": -58.57741165161133,
    "critic_loss": 6.0597453117370605,
    "ent_coef": 0.10445898771286011,
    "learning_rate": 0.001
  },
  {
    "episode": 5898,
    "reward": 89.599329,
    "length": 66,
    "time": 91312.301217,
    "actor_loss": -67.7386245727539,
    "critic_loss": 15.750261306762695,
    "ent_coef": 0.10487000644207001,
    "learning_rate": 0.001
  },
  {
    "episode": 5899,
    "reward": 85.796188,
    "length": 71,
    "time": 91327.389923,
    "actor_loss": -69.74932098388672,
    "critic_loss": 3.8837575912475586,
    "ent_coef": 0.10118269920349121,
    "learning_rate": 0.001
  },
  {
    "episode": 5900,
    "reward": 85.378997,
    "length": 73,
    "time": 91343.336872,
    "actor_loss": -66.9045639038086,
    "critic_loss": 120.03764343261719,
    "ent_coef": 0.10225991904735565,
    "learning_rate": 0.001
  },
  {
    "episode": 5901,
    "reward": 82.112447,
    "length": 75,
    "time": 91357.175242,
    "actor_loss": -63.21394348144531,
    "critic_loss": 6.821183204650879,
    "ent_coef": 0.10370998084545135,
    "learning_rate": 0.001
  },
  {
    "episode": 5902,
    "reward": 75.419867,
    "length": 89,
    "time": 91372.391955,
    "actor_loss": -63.6146240234375,
    "critic_loss": 7.740771293640137,
    "ent_coef": 0.09776204079389572,
    "learning_rate": 0.001
  },
  {
    "episode": 5903,
    "reward": 80.834096,
    "length": 79,
    "time": 91386.168008,
    "actor_loss": -60.18950653076172,
    "critic_loss": 14.72565746307373,
    "ent_coef": 0.09459609538316727,
    "learning_rate": 0.001
  },
  {
    "episode": 5904,
    "reward": 86.304686,
    "length": 71,
    "time": 91398.211188,
    "actor_loss": -60.54181671142578,
    "critic_loss": 9.800029754638672,
    "ent_coef": 0.09240078926086426,
    "learning_rate": 0.001
  },
  {
    "episode": 5905,
    "reward": 89.333153,
    "length": 66,
    "time": 91410.804861,
    "actor_loss": -64.02508544921875,
    "critic_loss": 21.16982650756836,
    "ent_coef": 0.09535329788923264,
    "learning_rate": 0.001
  },
  {
    "episode": 5906,
    "reward": 86.324808,
    "length": 74,
    "time": 91425.821351,
    "actor_loss": -64.26673889160156,
    "critic_loss": 10.204058647155762,
    "ent_coef": 0.09366324543952942,
    "learning_rate": 0.001
  },
  {
    "episode": 5907,
    "reward": 82.974072,
    "length": 78,
    "time": 91441.019716,
    "actor_loss": -57.022674560546875,
    "critic_loss": 25.128400802612305,
    "ent_coef": 0.0871717780828476,
    "learning_rate": 0.001
  },
  {
    "episode": 5908,
    "reward": 76.319263,
    "length": 94,
    "time": 91458.4137,
    "actor_loss": -69.13505554199219,
    "critic_loss": 37.00040817260742,
    "ent_coef": 0.08409841358661652,
    "learning_rate": 0.001
  },
  {
    "episode": 5909,
    "reward": 77.814291,
    "length": 92,
    "time": 91477.567875,
    "actor_loss": -64.98470306396484,
    "critic_loss": 18.132736206054688,
    "ent_coef": 0.08440764248371124,
    "learning_rate": 0.001
  },
  {
    "episode": 5910,
    "reward": 73.187618,
    "length": 93,
    "time": 91494.370234,
    "actor_loss": -62.551910400390625,
    "critic_loss": 7.648426532745361,
    "ent_coef": 0.08310937881469727,
    "learning_rate": 0.001
  },
  {
    "episode": 5911,
    "reward": 77.423128,
    "length": 90,
    "time": 91510.246175,
    "actor_loss": -58.87315368652344,
    "critic_loss": 12.740656852722168,
    "ent_coef": 0.08805908262729645,
    "learning_rate": 0.001
  },
  {
    "episode": 5912,
    "reward": 84.403689,
    "length": 74,
    "time": 91523.390754,
    "actor_loss": -61.48494338989258,
    "critic_loss": 35.61848449707031,
    "ent_coef": 0.08812708407640457,
    "learning_rate": 0.001
  },
  {
    "episode": 5913,
    "reward": 88.658911,
    "length": 68,
    "time": 91536.342822,
    "actor_loss": -63.98633575439453,
    "critic_loss": 9.894102096557617,
    "ent_coef": 0.09162017703056335,
    "learning_rate": 0.001
  },
  {
    "episode": 5914,
    "reward": 84.478042,
    "length": 74,
    "time": 91549.240772,
    "actor_loss": -59.18034362792969,
    "critic_loss": 48.22178268432617,
    "ent_coef": 0.09177104383707047,
    "learning_rate": 0.001
  },
  {
    "episode": 5915,
    "reward": 83.767139,
    "length": 76,
    "time": 91562.099319,
    "actor_loss": -63.32868194580078,
    "critic_loss": 18.20402717590332,
    "ent_coef": 0.08675852417945862,
    "learning_rate": 0.001
  },
  {
    "episode": 5916,
    "reward": 86.897004,
    "length": 71,
    "time": 91574.511426,
    "actor_loss": -66.87632751464844,
    "critic_loss": 11.017871856689453,
    "ent_coef": 0.08492259681224823,
    "learning_rate": 0.001
  },
  {
    "episode": 5917,
    "reward": 88.138433,
    "length": 70,
    "time": 91588.78209,
    "actor_loss": -68.83817291259766,
    "critic_loss": 54.69828796386719,
    "ent_coef": 0.08641233295202255,
    "learning_rate": 0.001
  },
  {
    "episode": 5918,
    "reward": 82.450564,
    "length": 80,
    "time": 91601.879736,
    "actor_loss": -65.4330825805664,
    "critic_loss": 36.71595001220703,
    "ent_coef": 0.09029429405927658,
    "learning_rate": 0.001
  },
  {
    "episode": 5919,
    "reward": 88.464799,
    "length": 68,
    "time": 91614.84047,
    "actor_loss": -61.438148498535156,
    "critic_loss": 8.892404556274414,
    "ent_coef": 0.09283574670553207,
    "learning_rate": 0.001
  },
  {
    "episode": 5920,
    "reward": 77.435542,
    "length": 87,
    "time": 91631.335593,
    "actor_loss": -59.610984802246094,
    "critic_loss": 194.9803009033203,
    "ent_coef": 0.08974368870258331,
    "learning_rate": 0.001
  },
  {
    "episode": 5921,
    "reward": 78.802557,
    "length": 82,
    "time": 91646.150627,
    "actor_loss": -69.43041229248047,
    "critic_loss": 10.22677230834961,
    "ent_coef": 0.09055222570896149,
    "learning_rate": 0.001
  },
  {
    "episode": 5922,
    "reward": 89.259139,
    "length": 64,
    "time": 91659.051708,
    "actor_loss": -57.31499099731445,
    "critic_loss": 30.731117248535156,
    "ent_coef": 0.09386108815670013,
    "learning_rate": 0.001
  },
  {
    "episode": 5923,
    "reward": 87.04583,
    "length": 71,
    "time": 91671.12604,
    "actor_loss": -67.63172912597656,
    "critic_loss": 13.346245765686035,
    "ent_coef": 0.09824405610561371,
    "learning_rate": 0.001
  },
  {
    "episode": 5924,
    "reward": 83.11397,
    "length": 75,
    "time": 91684.734318,
    "actor_loss": -65.83564758300781,
    "critic_loss": 15.238872528076172,
    "ent_coef": 0.09648559987545013,
    "learning_rate": 0.001
  },
  {
    "episode": 5925,
    "reward": 87.584908,
    "length": 69,
    "time": 91697.474944,
    "actor_loss": -65.30978393554688,
    "critic_loss": 26.90921974182129,
    "ent_coef": 0.10188385844230652,
    "learning_rate": 0.001
  },
  {
    "episode": 5926,
    "reward": 88.204622,
    "length": 68,
    "time": 91709.895997,
    "actor_loss": -60.33386993408203,
    "critic_loss": 43.970458984375,
    "ent_coef": 0.105923131108284,
    "learning_rate": 0.001
  },
  {
    "episode": 5927,
    "reward": 89.01939,
    "length": 65,
    "time": 91721.540987,
    "actor_loss": -66.2509536743164,
    "critic_loss": 84.7495346069336,
    "ent_coef": 0.10435827076435089,
    "learning_rate": 0.001
  },
  {
    "episode": 5928,
    "reward": 87.567179,
    "length": 69,
    "time": 91734.378786,
    "actor_loss": -60.97300720214844,
    "critic_loss": 8.32076644897461,
    "ent_coef": 0.10115312784910202,
    "learning_rate": 0.001
  },
  {
    "episode": 5929,
    "reward": 88.984197,
    "length": 66,
    "time": 91750.59576,
    "actor_loss": -62.384552001953125,
    "critic_loss": 7.711776256561279,
    "ent_coef": 0.1055581346154213,
    "learning_rate": 0.001
  },
  {
    "episode": 5930,
    "reward": 82.3178,
    "length": 77,
    "time": 91764.284222,
    "actor_loss": -71.65921020507812,
    "critic_loss": 64.02483367919922,
    "ent_coef": 0.09731624275445938,
    "learning_rate": 0.001
  },
  {
    "episode": 5931,
    "reward": 86.338659,
    "length": 68,
    "time": 91779.260271,
    "actor_loss": -68.78616333007812,
    "critic_loss": 6.5889482498168945,
    "ent_coef": 0.09561838209629059,
    "learning_rate": 0.001
  },
  {
    "episode": 5932,
    "reward": 86.302405,
    "length": 70,
    "time": 91791.262558,
    "actor_loss": -65.62056732177734,
    "critic_loss": 15.168224334716797,
    "ent_coef": 0.0951278880238533,
    "learning_rate": 0.001
  },
  {
    "episode": 5933,
    "reward": 85.039965,
    "length": 72,
    "time": 91803.625109,
    "actor_loss": -68.18643188476562,
    "critic_loss": 141.00469970703125,
    "ent_coef": 0.09311309456825256,
    "learning_rate": 0.001
  },
  {
    "episode": 5934,
    "reward": 73.509289,
    "length": 87,
    "time": 91819.844879,
    "actor_loss": -58.01509094238281,
    "critic_loss": 12.115750312805176,
    "ent_coef": 0.09250547736883163,
    "learning_rate": 0.001
  },
  {
    "episode": 5935,
    "reward": 89.598799,
    "length": 66,
    "time": 91834.531115,
    "actor_loss": -63.858734130859375,
    "critic_loss": 12.525890350341797,
    "ent_coef": 0.09621339291334152,
    "learning_rate": 0.001
  },
  {
    "episode": 5936,
    "reward": 89.440402,
    "length": 64,
    "time": 91849.064317,
    "actor_loss": -65.57492065429688,
    "critic_loss": 43.22758865356445,
    "ent_coef": 0.09700345247983932,
    "learning_rate": 0.001
  },
  {
    "episode": 5937,
    "reward": 88.420228,
    "length": 67,
    "time": 91864.732709,
    "actor_loss": -64.46444702148438,
    "critic_loss": 16.14006805419922,
    "ent_coef": 0.09784521162509918,
    "learning_rate": 0.001
  },
  {
    "episode": 5938,
    "reward": 87.385729,
    "length": 70,
    "time": 91879.79627,
    "actor_loss": -65.17822265625,
    "critic_loss": 15.545524597167969,
    "ent_coef": 0.09645847976207733,
    "learning_rate": 0.001
  },
  {
    "episode": 5939,
    "reward": 86.950204,
    "length": 69,
    "time": 91891.794575,
    "actor_loss": -65.77287292480469,
    "critic_loss": 49.26355743408203,
    "ent_coef": 0.09399431198835373,
    "learning_rate": 0.001
  },
  {
    "episode": 5940,
    "reward": 88.786441,
    "length": 68,
    "time": 91905.808952,
    "actor_loss": -64.28244018554688,
    "critic_loss": 61.163387298583984,
    "ent_coef": 0.09322642534971237,
    "learning_rate": 0.001
  },
  {
    "episode": 5941,
    "reward": 87.360538,
    "length": 70,
    "time": 91919.466807,
    "actor_loss": -69.76742553710938,
    "critic_loss": 36.548004150390625,
    "ent_coef": 0.0905032530426979,
    "learning_rate": 0.001
  },
  {
    "episode": 5942,
    "reward": 85.479168,
    "length": 74,
    "time": 91931.949104,
    "actor_loss": -60.6634635925293,
    "critic_loss": 10.737237930297852,
    "ent_coef": 0.0852905660867691,
    "learning_rate": 0.001
  },
  {
    "episode": 5943,
    "reward": 89.500274,
    "length": 63,
    "time": 91944.26742,
    "actor_loss": -65.23863983154297,
    "critic_loss": 22.80984115600586,
    "ent_coef": 0.08310844749212265,
    "learning_rate": 0.001
  },
  {
    "episode": 5944,
    "reward": -161.887213,
    "length": 175,
    "time": 91970.682201,
    "actor_loss": -68.94387817382812,
    "critic_loss": 31.267024993896484,
    "ent_coef": 0.08936875313520432,
    "learning_rate": 0.001
  },
  {
    "episode": 5945,
    "reward": 88.692114,
    "length": 65,
    "time": 91981.990142,
    "actor_loss": -63.04557418823242,
    "critic_loss": 32.55522918701172,
    "ent_coef": 0.09438717365264893,
    "learning_rate": 0.001
  },
  {
    "episode": 5946,
    "reward": 90.826939,
    "length": 62,
    "time": 91995.99242,
    "actor_loss": -59.8994140625,
    "critic_loss": 85.9264144897461,
    "ent_coef": 0.0968162938952446,
    "learning_rate": 0.001
  },
  {
    "episode": 5947,
    "reward": 89.599647,
    "length": 65,
    "time": 92008.228848,
    "actor_loss": -64.06324768066406,
    "critic_loss": 13.828398704528809,
    "ent_coef": 0.0982828214764595,
    "learning_rate": 0.001
  },
  {
    "episode": 5948,
    "reward": 90.166398,
    "length": 65,
    "time": 92019.59282,
    "actor_loss": -65.12259674072266,
    "critic_loss": 10.703651428222656,
    "ent_coef": 0.09941297769546509,
    "learning_rate": 0.001
  },
  {
    "episode": 5949,
    "reward": 86.398389,
    "length": 69,
    "time": 92033.473312,
    "actor_loss": -62.754966735839844,
    "critic_loss": 6.115234851837158,
    "ent_coef": 0.09674165397882462,
    "learning_rate": 0.001
  },
  {
    "episode": 5950,
    "reward": 83.663131,
    "length": 78,
    "time": 92049.217474,
    "actor_loss": -61.031471252441406,
    "critic_loss": 7.3642988204956055,
    "ent_coef": 0.09476795047521591,
    "learning_rate": 0.001
  },
  {
    "episode": 5951,
    "reward": 80.268705,
    "length": 76,
    "time": 92064.16841,
    "actor_loss": -66.96703338623047,
    "critic_loss": 16.00591278076172,
    "ent_coef": 0.09148954600095749,
    "learning_rate": 0.001
  },
  {
    "episode": 5952,
    "reward": 87.910087,
    "length": 68,
    "time": 92075.945325,
    "actor_loss": -66.53416442871094,
    "critic_loss": 7.047820091247559,
    "ent_coef": 0.09262590855360031,
    "learning_rate": 0.001
  },
  {
    "episode": 5953,
    "reward": 85.541331,
    "length": 71,
    "time": 92089.976082,
    "actor_loss": -65.84619140625,
    "critic_loss": 12.87664794921875,
    "ent_coef": 0.09116194397211075,
    "learning_rate": 0.001
  },
  {
    "episode": 5954,
    "reward": 87.525051,
    "length": 70,
    "time": 92104.832261,
    "actor_loss": -65.36958312988281,
    "critic_loss": 11.503823280334473,
    "ent_coef": 0.09190859645605087,
    "learning_rate": 0.001
  },
  {
    "episode": 5955,
    "reward": 89.821819,
    "length": 64,
    "time": 92116.260016,
    "actor_loss": -64.04417419433594,
    "critic_loss": 62.757911682128906,
    "ent_coef": 0.08934096992015839,
    "learning_rate": 0.001
  },
  {
    "episode": 5956,
    "reward": 83.705107,
    "length": 78,
    "time": 92131.285653,
    "actor_loss": -68.54451751708984,
    "critic_loss": 6.639327049255371,
    "ent_coef": 0.08710093796253204,
    "learning_rate": 0.001
  },
  {
    "episode": 5957,
    "reward": 87.018556,
    "length": 73,
    "time": 92144.570015,
    "actor_loss": -65.18920135498047,
    "critic_loss": 8.56023120880127,
    "ent_coef": 0.08466693013906479,
    "learning_rate": 0.001
  },
  {
    "episode": 5958,
    "reward": 89.462879,
    "length": 65,
    "time": 92156.842489,
    "actor_loss": -72.955078125,
    "critic_loss": 10.356695175170898,
    "ent_coef": 0.08103420585393906,
    "learning_rate": 0.001
  },
  {
    "episode": 5959,
    "reward": 88.919448,
    "length": 67,
    "time": 92170.462837,
    "actor_loss": -65.15803527832031,
    "critic_loss": 37.79796600341797,
    "ent_coef": 0.07949686050415039,
    "learning_rate": 0.001
  },
  {
    "episode": 5960,
    "reward": 88.854009,
    "length": 66,
    "time": 92182.962001,
    "actor_loss": -64.2193603515625,
    "critic_loss": 3.0885825157165527,
    "ent_coef": 0.0787375196814537,
    "learning_rate": 0.001
  },
  {
    "episode": 5961,
    "reward": 88.306877,
    "length": 64,
    "time": 92194.496981,
    "actor_loss": -68.27011108398438,
    "critic_loss": 13.567680358886719,
    "ent_coef": 0.07681751251220703,
    "learning_rate": 0.001
  },
  {
    "episode": 5962,
    "reward": 89.139027,
    "length": 67,
    "time": 92206.873375,
    "actor_loss": -64.3310775756836,
    "critic_loss": 12.656888961791992,
    "ent_coef": 0.07673774659633636,
    "learning_rate": 0.001
  },
  {
    "episode": 5963,
    "reward": 90.274344,
    "length": 62,
    "time": 92219.066815,
    "actor_loss": -62.01482391357422,
    "critic_loss": 17.24527931213379,
    "ent_coef": 0.07951488345861435,
    "learning_rate": 0.001
  },
  {
    "episode": 5964,
    "reward": 75.49566,
    "length": 91,
    "time": 92236.724124,
    "actor_loss": -68.91368103027344,
    "critic_loss": 17.237333297729492,
    "ent_coef": 0.07725290209054947,
    "learning_rate": 0.001
  },
  {
    "episode": 5965,
    "reward": 79.844073,
    "length": 79,
    "time": 92253.028711,
    "actor_loss": -67.0865478515625,
    "critic_loss": 5.794853687286377,
    "ent_coef": 0.0776759460568428,
    "learning_rate": 0.001
  },
  {
    "episode": 5966,
    "reward": 88.317938,
    "length": 68,
    "time": 92264.737579,
    "actor_loss": -60.358211517333984,
    "critic_loss": 10.75322151184082,
    "ent_coef": 0.07994891703128815,
    "learning_rate": 0.001
  },
  {
    "episode": 5967,
    "reward": 71.399677,
    "length": 90,
    "time": 92280.356025,
    "actor_loss": -64.36967468261719,
    "critic_loss": 7.037998199462891,
    "ent_coef": 0.07887882739305496,
    "learning_rate": 0.001
  },
  {
    "episode": 5968,
    "reward": 89.634068,
    "length": 65,
    "time": 92294.648328,
    "actor_loss": -61.285804748535156,
    "critic_loss": 48.49130630493164,
    "ent_coef": 0.07999082654714584,
    "learning_rate": 0.001
  },
  {
    "episode": 5969,
    "reward": 88.723357,
    "length": 65,
    "time": 92305.833796,
    "actor_loss": -60.13200378417969,
    "critic_loss": 20.39386749267578,
    "ent_coef": 0.0808863490819931,
    "learning_rate": 0.001
  },
  {
    "episode": 5970,
    "reward": 87.593369,
    "length": 69,
    "time": 92320.958076,
    "actor_loss": -64.47650909423828,
    "critic_loss": 4.750174045562744,
    "ent_coef": 0.0835360512137413,
    "learning_rate": 0.001
  },
  {
    "episode": 5971,
    "reward": -183.544475,
    "length": 195,
    "time": 92350.031368,
    "actor_loss": -67.43319702148438,
    "critic_loss": 14.46614933013916,
    "ent_coef": 0.08368980884552002,
    "learning_rate": 0.001
  },
  {
    "episode": 5972,
    "reward": 85.848216,
    "length": 81,
    "time": 92369.53257,
    "actor_loss": -69.67961120605469,
    "critic_loss": 6.9667649269104,
    "ent_coef": 0.08290331810712814,
    "learning_rate": 0.001
  },
  {
    "episode": 5973,
    "reward": 88.298104,
    "length": 67,
    "time": 92381.063909,
    "actor_loss": -63.62561798095703,
    "critic_loss": 53.31880187988281,
    "ent_coef": 0.07814353704452515,
    "learning_rate": 0.001
  },
  {
    "episode": 5974,
    "reward": 88.837491,
    "length": 64,
    "time": 92394.705743,
    "actor_loss": -59.968605041503906,
    "critic_loss": 87.73601531982422,
    "ent_coef": 0.07860672473907471,
    "learning_rate": 0.001
  },
  {
    "episode": 5975,
    "reward": 87.69723,
    "length": 68,
    "time": 92407.646017,
    "actor_loss": -62.094730377197266,
    "critic_loss": 518.3589477539062,
    "ent_coef": 0.08123373985290527,
    "learning_rate": 0.001
  },
  {
    "episode": 5976,
    "reward": 90.11307,
    "length": 63,
    "time": 92418.855455,
    "actor_loss": -62.12385177612305,
    "critic_loss": 21.09418487548828,
    "ent_coef": 0.0837179645895958,
    "learning_rate": 0.001
  },
  {
    "episode": 5977,
    "reward": 88.415791,
    "length": 68,
    "time": 92432.980733,
    "actor_loss": -58.56660079956055,
    "critic_loss": 53.391273498535156,
    "ent_coef": 0.0855507031083107,
    "learning_rate": 0.001
  },
  {
    "episode": 5978,
    "reward": 78.310141,
    "length": 85,
    "time": 92448.128233,
    "actor_loss": -65.09329986572266,
    "critic_loss": 104.15547180175781,
    "ent_coef": 0.07673483341932297,
    "learning_rate": 0.001
  },
  {
    "episode": 5979,
    "reward": 90.962421,
    "length": 61,
    "time": 92459.068564,
    "actor_loss": -61.92636489868164,
    "critic_loss": 14.653704643249512,
    "ent_coef": 0.08030056208372116,
    "learning_rate": 0.001
  },
  {
    "episode": 5980,
    "reward": 89.133314,
    "length": 66,
    "time": 92470.531127,
    "actor_loss": -68.97236633300781,
    "critic_loss": 5.306622505187988,
    "ent_coef": 0.07792873680591583,
    "learning_rate": 0.001
  },
  {
    "episode": 5981,
    "reward": 88.638193,
    "length": 66,
    "time": 92484.204828,
    "actor_loss": -67.22471618652344,
    "critic_loss": 8.555015563964844,
    "ent_coef": 0.07484948635101318,
    "learning_rate": 0.001
  },
  {
    "episode": 5982,
    "reward": 86.173945,
    "length": 71,
    "time": 92497.201864,
    "actor_loss": -59.34776306152344,
    "critic_loss": 14.764026641845703,
    "ent_coef": 0.07262615859508514,
    "learning_rate": 0.001
  },
  {
    "episode": 5983,
    "reward": 89.797489,
    "length": 65,
    "time": 92509.341808,
    "actor_loss": -63.3122444152832,
    "critic_loss": 17.705883026123047,
    "ent_coef": 0.07463665306568146,
    "learning_rate": 0.001
  },
  {
    "episode": 5984,
    "reward": 88.367518,
    "length": 65,
    "time": 92521.786279,
    "actor_loss": -64.96183013916016,
    "critic_loss": 6.336437225341797,
    "ent_coef": 0.07775285840034485,
    "learning_rate": 0.001
  },
  {
    "episode": 5985,
    "reward": 89.48372,
    "length": 64,
    "time": 92533.052605,
    "actor_loss": -70.38238525390625,
    "critic_loss": 8.545652389526367,
    "ent_coef": 0.07908494025468826,
    "learning_rate": 0.001
  },
  {
    "episode": 5986,
    "reward": 87.873136,
    "length": 68,
    "time": 92546.933355,
    "actor_loss": -65.69319152832031,
    "critic_loss": 15.824825286865234,
    "ent_coef": 0.08027905225753784,
    "learning_rate": 0.001
  },
  {
    "episode": 5987,
    "reward": 86.960425,
    "length": 70,
    "time": 92559.069396,
    "actor_loss": -64.64813232421875,
    "critic_loss": 56.804054260253906,
    "ent_coef": 0.07882128655910492,
    "learning_rate": 0.001
  },
  {
    "episode": 5988,
    "reward": 89.490979,
    "length": 64,
    "time": 92572.069077,
    "actor_loss": -60.332313537597656,
    "critic_loss": 16.212657928466797,
    "ent_coef": 0.08084152638912201,
    "learning_rate": 0.001
  },
  {
    "episode": 5989,
    "reward": 88.415272,
    "length": 67,
    "time": 92584.043679,
    "actor_loss": -66.3581314086914,
    "critic_loss": 68.94401550292969,
    "ent_coef": 0.0812578946352005,
    "learning_rate": 0.001
  },
  {
    "episode": 5990,
    "reward": 88.751325,
    "length": 66,
    "time": 92596.561374,
    "actor_loss": -61.51966094970703,
    "critic_loss": 16.8760986328125,
    "ent_coef": 0.08263339102268219,
    "learning_rate": 0.001
  },
  {
    "episode": 5991,
    "reward": 88.254482,
    "length": 67,
    "time": 92609.541354,
    "actor_loss": -72.13880920410156,
    "critic_loss": 41.73759078979492,
    "ent_coef": 0.08320599049329758,
    "learning_rate": 0.001
  },
  {
    "episode": 5992,
    "reward": 87.639236,
    "length": 68,
    "time": 92621.175085,
    "actor_loss": -70.57028198242188,
    "critic_loss": 59.15955352783203,
    "ent_coef": 0.08171207457780838,
    "learning_rate": 0.001
  },
  {
    "episode": 5993,
    "reward": 89.236258,
    "length": 64,
    "time": 92633.40811,
    "actor_loss": -58.48044967651367,
    "critic_loss": 11.097118377685547,
    "ent_coef": 0.08538717031478882,
    "learning_rate": 0.001
  },
  {
    "episode": 5994,
    "reward": 88.97209,
    "length": 65,
    "time": 92645.245656,
    "actor_loss": -70.05924987792969,
    "critic_loss": 19.78466033935547,
    "ent_coef": 0.08844686299562454,
    "learning_rate": 0.001
  },
  {
    "episode": 5995,
    "reward": 88.596583,
    "length": 66,
    "time": 92657.490979,
    "actor_loss": -58.317604064941406,
    "critic_loss": 11.510374069213867,
    "ent_coef": 0.08673616498708725,
    "learning_rate": 0.001
  },
  {
    "episode": 5996,
    "reward": 90.055719,
    "length": 63,
    "time": 92671.19654,
    "actor_loss": -70.80805969238281,
    "critic_loss": 31.695995330810547,
    "ent_coef": 0.08759955316781998,
    "learning_rate": 0.001
  },
  {
    "episode": 5997,
    "reward": 86.776906,
    "length": 69,
    "time": 92684.86057,
    "actor_loss": -68.47273254394531,
    "critic_loss": 12.787944793701172,
    "ent_coef": 0.08803896605968475,
    "learning_rate": 0.001
  },
  {
    "episode": 5998,
    "reward": 89.129523,
    "length": 65,
    "time": 92697.28372,
    "actor_loss": -63.54131317138672,
    "critic_loss": 6.7568159103393555,
    "ent_coef": 0.09004243463277817,
    "learning_rate": 0.001
  },
  {
    "episode": 5999,
    "reward": 90.784359,
    "length": 62,
    "time": 92708.393474,
    "actor_loss": -59.2498664855957,
    "critic_loss": 20.765552520751953,
    "ent_coef": 0.09310592710971832,
    "learning_rate": 0.001
  },
  {
    "episode": 6000,
    "reward": 85.219483,
    "length": 74,
    "time": 92721.838673,
    "actor_loss": -61.866905212402344,
    "critic_loss": 23.10281753540039,
    "ent_coef": 0.08662149310112,
    "learning_rate": 0.001
  },
  {
    "episode": 6001,
    "reward": 85.328092,
    "length": 71,
    "time": 92735.252654,
    "actor_loss": -67.76520538330078,
    "critic_loss": 33.90037536621094,
    "ent_coef": 0.08434946089982986,
    "learning_rate": 0.001
  },
  {
    "episode": 6002,
    "reward": 86.187215,
    "length": 74,
    "time": 92748.092819,
    "actor_loss": -70.64208984375,
    "critic_loss": 34.661468505859375,
    "ent_coef": 0.08012213557958603,
    "learning_rate": 0.001
  },
  {
    "episode": 6003,
    "reward": 85.62413,
    "length": 71,
    "time": 92762.207957,
    "actor_loss": -62.86594009399414,
    "critic_loss": 17.320709228515625,
    "ent_coef": 0.07619632035493851,
    "learning_rate": 0.001
  },
  {
    "episode": 6004,
    "reward": 89.018586,
    "length": 65,
    "time": 92773.596934,
    "actor_loss": -60.38575744628906,
    "critic_loss": 17.791547775268555,
    "ent_coef": 0.07463133335113525,
    "learning_rate": 0.001
  },
  {
    "episode": 6005,
    "reward": 86.817938,
    "length": 69,
    "time": 92785.762006,
    "actor_loss": -66.68836212158203,
    "critic_loss": 38.30457305908203,
    "ent_coef": 0.07328568398952484,
    "learning_rate": 0.001
  },
  {
    "episode": 6006,
    "reward": 86.594894,
    "length": 72,
    "time": 92798.194409,
    "actor_loss": -60.56005096435547,
    "critic_loss": 21.931432723999023,
    "ent_coef": 0.07230318337678909,
    "learning_rate": 0.001
  },
  {
    "episode": 6007,
    "reward": 87.777909,
    "length": 69,
    "time": 92810.638523,
    "actor_loss": -68.53290557861328,
    "critic_loss": 6.527316093444824,
    "ent_coef": 0.0712578222155571,
    "learning_rate": 0.001
  },
  {
    "episode": 6008,
    "reward": 83.805936,
    "length": 73,
    "time": 92824.020829,
    "actor_loss": -66.61419677734375,
    "critic_loss": 5.726206302642822,
    "ent_coef": 0.07008037716150284,
    "learning_rate": 0.001
  },
  {
    "episode": 6009,
    "reward": 88.577549,
    "length": 67,
    "time": 92835.669214,
    "actor_loss": -66.42044067382812,
    "critic_loss": 10.989849090576172,
    "ent_coef": 0.06894687563180923,
    "learning_rate": 0.001
  },
  {
    "episode": 6010,
    "reward": 81.380537,
    "length": 70,
    "time": 92850.373873,
    "actor_loss": -63.82881164550781,
    "critic_loss": 6.7000041007995605,
    "ent_coef": 0.07156742364168167,
    "learning_rate": 0.001
  },
  {
    "episode": 6011,
    "reward": 88.799401,
    "length": 66,
    "time": 92863.594607,
    "actor_loss": -65.14763641357422,
    "critic_loss": 39.04510498046875,
    "ent_coef": 0.07184625416994095,
    "learning_rate": 0.001
  },
  {
    "episode": 6012,
    "reward": 91.324492,
    "length": 61,
    "time": 92875.593775,
    "actor_loss": -66.04232788085938,
    "critic_loss": 78.20909881591797,
    "ent_coef": 0.07472406327724457,
    "learning_rate": 0.001
  },
  {
    "episode": 6013,
    "reward": 90.100718,
    "length": 65,
    "time": 92887.218496,
    "actor_loss": -63.20252990722656,
    "critic_loss": 94.494873046875,
    "ent_coef": 0.0792640969157219,
    "learning_rate": 0.001
  },
  {
    "episode": 6014,
    "reward": 87.190721,
    "length": 68,
    "time": 92902.721519,
    "actor_loss": -63.99571228027344,
    "critic_loss": 12.772133827209473,
    "ent_coef": 0.08018206804990768,
    "learning_rate": 0.001
  },
  {
    "episode": 6015,
    "reward": 88.189935,
    "length": 67,
    "time": 92914.219634,
    "actor_loss": -67.05724334716797,
    "critic_loss": 165.95994567871094,
    "ent_coef": 0.08116071671247482,
    "learning_rate": 0.001
  },
  {
    "episode": 6016,
    "reward": 86.252199,
    "length": 71,
    "time": 92927.344085,
    "actor_loss": -66.64797973632812,
    "critic_loss": 38.837467193603516,
    "ent_coef": 0.07829416543245316,
    "learning_rate": 0.001
  },
  {
    "episode": 6017,
    "reward": 89.144026,
    "length": 64,
    "time": 92939.616566,
    "actor_loss": -67.69222259521484,
    "critic_loss": 5.244491100311279,
    "ent_coef": 0.07723457366228104,
    "learning_rate": 0.001
  },
  {
    "episode": 6018,
    "reward": 90.244097,
    "length": 63,
    "time": 92950.886548,
    "actor_loss": -69.30165100097656,
    "critic_loss": 22.93564224243164,
    "ent_coef": 0.07467226684093475,
    "learning_rate": 0.001
  },
  {
    "episode": 6019,
    "reward": 83.104915,
    "length": 76,
    "time": 92964.650198,
    "actor_loss": -69.90629577636719,
    "critic_loss": 7.566864490509033,
    "ent_coef": 0.07457553595304489,
    "learning_rate": 0.001
  },
  {
    "episode": 6020,
    "reward": 86.955505,
    "length": 70,
    "time": 92976.934667,
    "actor_loss": -69.32434844970703,
    "critic_loss": 6.067051887512207,
    "ent_coef": 0.07426871359348297,
    "learning_rate": 0.001
  },
  {
    "episode": 6021,
    "reward": 87.452605,
    "length": 70,
    "time": 92990.593059,
    "actor_loss": -65.39720153808594,
    "critic_loss": 4.935724258422852,
    "ent_coef": 0.07509662210941315,
    "learning_rate": 0.001
  },
  {
    "episode": 6022,
    "reward": 86.481511,
    "length": 70,
    "time": 93003.449031,
    "actor_loss": -67.17498779296875,
    "critic_loss": 22.413955688476562,
    "ent_coef": 0.07692038267850876,
    "learning_rate": 0.001
  },
  {
    "episode": 6023,
    "reward": 86.865143,
    "length": 69,
    "time": 93015.445911,
    "actor_loss": -69.00212097167969,
    "critic_loss": 5.968383312225342,
    "ent_coef": 0.07527598738670349,
    "learning_rate": 0.001
  },
  {
    "episode": 6024,
    "reward": 88.290051,
    "length": 66,
    "time": 93028.338707,
    "actor_loss": -67.36785888671875,
    "critic_loss": 26.686870574951172,
    "ent_coef": 0.07471422851085663,
    "learning_rate": 0.001
  },
  {
    "episode": 6025,
    "reward": 88.377335,
    "length": 66,
    "time": 93041.338452,
    "actor_loss": -68.93838500976562,
    "critic_loss": 58.478939056396484,
    "ent_coef": 0.07529199868440628,
    "learning_rate": 0.001
  },
  {
    "episode": 6026,
    "reward": 91.415167,
    "length": 61,
    "time": 93052.955009,
    "actor_loss": -60.6567497253418,
    "critic_loss": 8.571739196777344,
    "ent_coef": 0.07539688795804977,
    "learning_rate": 0.001
  },
  {
    "episode": 6027,
    "reward": 88.775599,
    "length": 65,
    "time": 93065.113254,
    "actor_loss": -66.01716613769531,
    "critic_loss": 15.163239479064941,
    "ent_coef": 0.07827102392911911,
    "learning_rate": 0.001
  },
  {
    "episode": 6028,
    "reward": 82.051212,
    "length": 77,
    "time": 93080.134779,
    "actor_loss": -66.5069808959961,
    "critic_loss": 17.203632354736328,
    "ent_coef": 0.07326336205005646,
    "learning_rate": 0.001
  },
  {
    "episode": 6029,
    "reward": 86.811422,
    "length": 70,
    "time": 93095.019562,
    "actor_loss": -65.15998840332031,
    "critic_loss": 46.86098098754883,
    "ent_coef": 0.07293079048395157,
    "learning_rate": 0.001
  },
  {
    "episode": 6030,
    "reward": 80.917023,
    "length": 77,
    "time": 93109.887297,
    "actor_loss": -61.74969482421875,
    "critic_loss": 19.08151626586914,
    "ent_coef": 0.0741528645157814,
    "learning_rate": 0.001
  },
  {
    "episode": 6031,
    "reward": 79.971996,
    "length": 78,
    "time": 93125.81681,
    "actor_loss": -60.26064682006836,
    "critic_loss": 10.493282318115234,
    "ent_coef": 0.07704399526119232,
    "learning_rate": 0.001
  },
  {
    "episode": 6032,
    "reward": 88.273152,
    "length": 66,
    "time": 93137.746061,
    "actor_loss": -60.8475341796875,
    "critic_loss": 48.57642364501953,
    "ent_coef": 0.07590745389461517,
    "learning_rate": 0.001
  },
  {
    "episode": 6033,
    "reward": 83.2212,
    "length": 78,
    "time": 93150.756529,
    "actor_loss": -65.50257873535156,
    "critic_loss": 8.867046356201172,
    "ent_coef": 0.07511869817972183,
    "learning_rate": 0.001
  },
  {
    "episode": 6034,
    "reward": 65.143866,
    "length": 108,
    "time": 93168.499439,
    "actor_loss": -64.55046844482422,
    "critic_loss": 9.617330551147461,
    "ent_coef": 0.06780730932950974,
    "learning_rate": 0.001
  },
  {
    "episode": 6035,
    "reward": 60.127957,
    "length": 118,
    "time": 93186.612736,
    "actor_loss": -65.78367614746094,
    "critic_loss": 17.435707092285156,
    "ent_coef": 0.06483540683984756,
    "learning_rate": 0.001
  },
  {
    "episode": 6036,
    "reward": 71.950882,
    "length": 101,
    "time": 93206.092506,
    "actor_loss": -66.29974365234375,
    "critic_loss": 33.44758605957031,
    "ent_coef": 0.06693068146705627,
    "learning_rate": 0.001
  },
  {
    "episode": 6037,
    "reward": 61.132784,
    "length": 115,
    "time": 93226.186957,
    "actor_loss": -65.16419982910156,
    "critic_loss": 8.644899368286133,
    "ent_coef": 0.06713714450597763,
    "learning_rate": 0.001
  },
  {
    "episode": 6038,
    "reward": 88.440823,
    "length": 66,
    "time": 93239.5642,
    "actor_loss": -66.61203002929688,
    "critic_loss": 27.429508209228516,
    "ent_coef": 0.06731415539979935,
    "learning_rate": 0.001
  },
  {
    "episode": 6039,
    "reward": 87.745032,
    "length": 67,
    "time": 93251.242527,
    "actor_loss": -60.431854248046875,
    "critic_loss": 80.63760375976562,
    "ent_coef": 0.06570935994386673,
    "learning_rate": 0.001
  },
  {
    "episode": 6040,
    "reward": 83.240079,
    "length": 75,
    "time": 93264.734926,
    "actor_loss": -71.12569427490234,
    "critic_loss": 6.467829704284668,
    "ent_coef": 0.06799673289060593,
    "learning_rate": 0.001
  },
  {
    "episode": 6041,
    "reward": 84.181801,
    "length": 63,
    "time": 93277.587226,
    "actor_loss": -63.4891242980957,
    "critic_loss": 52.021270751953125,
    "ent_coef": 0.07334329932928085,
    "learning_rate": 0.001
  },
  {
    "episode": 6042,
    "reward": 88.443144,
    "length": 67,
    "time": 93292.095773,
    "actor_loss": -65.86479187011719,
    "critic_loss": 19.666397094726562,
    "ent_coef": 0.07666673511266708,
    "learning_rate": 0.001
  },
  {
    "episode": 6043,
    "reward": 88.94123,
    "length": 66,
    "time": 93304.556369,
    "actor_loss": -63.854522705078125,
    "critic_loss": 11.16845703125,
    "ent_coef": 0.07716838270425797,
    "learning_rate": 0.001
  },
  {
    "episode": 6044,
    "reward": 81.605513,
    "length": 67,
    "time": 93317.94186,
    "actor_loss": -67.12957763671875,
    "critic_loss": 52.81925582885742,
    "ent_coef": 0.08005882054567337,
    "learning_rate": 0.001
  },
  {
    "episode": 6045,
    "reward": 63.110056,
    "length": 93,
    "time": 93332.583295,
    "actor_loss": -66.89420318603516,
    "critic_loss": 6.498298645019531,
    "ent_coef": 0.07742033898830414,
    "learning_rate": 0.001
  },
  {
    "episode": 6046,
    "reward": 80.369916,
    "length": 82,
    "time": 93346.935494,
    "actor_loss": -73.07377624511719,
    "critic_loss": 30.283361434936523,
    "ent_coef": 0.07659902423620224,
    "learning_rate": 0.001
  },
  {
    "episode": 6047,
    "reward": 88.19812,
    "length": 67,
    "time": 93359.439132,
    "actor_loss": -65.44512939453125,
    "critic_loss": 9.053377151489258,
    "ent_coef": 0.07694252580404282,
    "learning_rate": 0.001
  },
  {
    "episode": 6048,
    "reward": 90.181844,
    "length": 63,
    "time": 93372.79268,
    "actor_loss": -64.65635681152344,
    "critic_loss": 87.88094329833984,
    "ent_coef": 0.076107919216156,
    "learning_rate": 0.001
  },
  {
    "episode": 6049,
    "reward": 88.188364,
    "length": 68,
    "time": 93388.568876,
    "actor_loss": -68.02207946777344,
    "critic_loss": 10.521125793457031,
    "ent_coef": 0.07619279623031616,
    "learning_rate": 0.001
  },
  {
    "episode": 6050,
    "reward": 88.212439,
    "length": 68,
    "time": 93400.351709,
    "actor_loss": -68.4406509399414,
    "critic_loss": 9.338052749633789,
    "ent_coef": 0.07470790296792984,
    "learning_rate": 0.001
  },
  {
    "episode": 6051,
    "reward": 81.936666,
    "length": 69,
    "time": 93413.342862,
    "actor_loss": -65.2858657836914,
    "critic_loss": 45.36968994140625,
    "ent_coef": 0.07610131055116653,
    "learning_rate": 0.001
  },
  {
    "episode": 6052,
    "reward": 87.975689,
    "length": 67,
    "time": 93425.572632,
    "actor_loss": -68.1266098022461,
    "critic_loss": 8.70820426940918,
    "ent_coef": 0.07434616982936859,
    "learning_rate": 0.001
  },
  {
    "episode": 6053,
    "reward": 85.057393,
    "length": 75,
    "time": 93439.496207,
    "actor_loss": -69.62155151367188,
    "critic_loss": 4.0105061531066895,
    "ent_coef": 0.07430504262447357,
    "learning_rate": 0.001
  },
  {
    "episode": 6054,
    "reward": 85.252239,
    "length": 73,
    "time": 93451.776499,
    "actor_loss": -66.43049621582031,
    "critic_loss": 9.755731582641602,
    "ent_coef": 0.07311902940273285,
    "learning_rate": 0.001
  },
  {
    "episode": 6055,
    "reward": 81.609143,
    "length": 76,
    "time": 93464.582556,
    "actor_loss": -63.65549087524414,
    "critic_loss": 8.798446655273438,
    "ent_coef": 0.07169724255800247,
    "learning_rate": 0.001
  },
  {
    "episode": 6056,
    "reward": 90.575614,
    "length": 62,
    "time": 93476.789823,
    "actor_loss": -65.57148742675781,
    "critic_loss": 4.761521816253662,
    "ent_coef": 0.07288540154695511,
    "learning_rate": 0.001
  },
  {
    "episode": 6057,
    "reward": 80.587522,
    "length": 75,
    "time": 93490.904937,
    "actor_loss": -64.61497497558594,
    "critic_loss": 8.360725402832031,
    "ent_coef": 0.07407943904399872,
    "learning_rate": 0.001
  },
  {
    "episode": 6058,
    "reward": 70.973457,
    "length": 86,
    "time": 93507.964981,
    "actor_loss": -71.36912536621094,
    "critic_loss": 36.744632720947266,
    "ent_coef": 0.07106436043977737,
    "learning_rate": 0.001
  },
  {
    "episode": 6059,
    "reward": 81.918473,
    "length": 74,
    "time": 93521.412018,
    "actor_loss": -68.99317169189453,
    "critic_loss": 17.56414794921875,
    "ent_coef": 0.06935980916023254,
    "learning_rate": 0.001
  },
  {
    "episode": 6060,
    "reward": 88.59302,
    "length": 67,
    "time": 93533.695096,
    "actor_loss": -65.83306121826172,
    "critic_loss": 8.180707931518555,
    "ent_coef": 0.06825176626443863,
    "learning_rate": 0.001
  },
  {
    "episode": 6061,
    "reward": 81.281664,
    "length": 69,
    "time": 93547.903089,
    "actor_loss": -55.95197296142578,
    "critic_loss": 19.22201156616211,
    "ent_coef": 0.06887882202863693,
    "learning_rate": 0.001
  },
  {
    "episode": 6062,
    "reward": 84.505428,
    "length": 71,
    "time": 93560.04561,
    "actor_loss": -67.02873992919922,
    "critic_loss": 15.841283798217773,
    "ent_coef": 0.07064785063266754,
    "learning_rate": 0.001
  },
  {
    "episode": 6063,
    "reward": 82.26752,
    "length": 72,
    "time": 93572.362525,
    "actor_loss": -61.52464294433594,
    "critic_loss": 17.910755157470703,
    "ent_coef": 0.07305138558149338,
    "learning_rate": 0.001
  },
  {
    "episode": 6064,
    "reward": 80.518159,
    "length": 77,
    "time": 93586.158565,
    "actor_loss": -61.438804626464844,
    "critic_loss": 7.204071044921875,
    "ent_coef": 0.07264505326747894,
    "learning_rate": 0.001
  },
  {
    "episode": 6065,
    "reward": 83.015884,
    "length": 79,
    "time": 93601.339224,
    "actor_loss": -62.147804260253906,
    "critic_loss": 11.379758834838867,
    "ent_coef": 0.0746820792555809,
    "learning_rate": 0.001
  },
  {
    "episode": 6066,
    "reward": 71.579958,
    "length": 96,
    "time": 93617.668082,
    "actor_loss": -68.88626098632812,
    "critic_loss": 45.93666076660156,
    "ent_coef": 0.0700114369392395,
    "learning_rate": 0.001
  },
  {
    "episode": 6067,
    "reward": 85.788047,
    "length": 72,
    "time": 93631.037446,
    "actor_loss": -64.33335876464844,
    "critic_loss": 86.36188507080078,
    "ent_coef": 0.06989414989948273,
    "learning_rate": 0.001
  },
  {
    "episode": 6068,
    "reward": 88.91247,
    "length": 66,
    "time": 93643.671952,
    "actor_loss": -65.04910278320312,
    "critic_loss": 6.296078681945801,
    "ent_coef": 0.07355917245149612,
    "learning_rate": 0.001
  },
  {
    "episode": 6069,
    "reward": 61.990161,
    "length": 103,
    "time": 93663.264336,
    "actor_loss": -67.54234313964844,
    "critic_loss": 77.87113952636719,
    "ent_coef": 0.07246974855661392,
    "learning_rate": 0.001
  },
  {
    "episode": 6070,
    "reward": 91.649602,
    "length": 61,
    "time": 93675.920598,
    "actor_loss": -64.2176742553711,
    "critic_loss": 80.20320129394531,
    "ent_coef": 0.07608269900083542,
    "learning_rate": 0.001
  },
  {
    "episode": 6071,
    "reward": 82.199403,
    "length": 72,
    "time": 93689.047187,
    "actor_loss": -62.868553161621094,
    "critic_loss": 9.38947868347168,
    "ent_coef": 0.07654161006212234,
    "learning_rate": 0.001
  },
  {
    "episode": 6072,
    "reward": 64.010439,
    "length": 90,
    "time": 93704.742738,
    "actor_loss": -69.83256530761719,
    "critic_loss": 4.550199508666992,
    "ent_coef": 0.07540019601583481,
    "learning_rate": 0.001
  },
  {
    "episode": 6073,
    "reward": 88.157171,
    "length": 68,
    "time": 93716.419543,
    "actor_loss": -61.67123031616211,
    "critic_loss": 10.459601402282715,
    "ent_coef": 0.07345382869243622,
    "learning_rate": 0.001
  },
  {
    "episode": 6074,
    "reward": 76.570521,
    "length": 87,
    "time": 93732.278226,
    "actor_loss": -67.6812744140625,
    "critic_loss": 127.67872619628906,
    "ent_coef": 0.07492200285196304,
    "learning_rate": 0.001
  },
  {
    "episode": 6075,
    "reward": 78.90903,
    "length": 76,
    "time": 93744.910785,
    "actor_loss": -67.89794158935547,
    "critic_loss": 17.927330017089844,
    "ent_coef": 0.06964482367038727,
    "learning_rate": 0.001
  },
  {
    "episode": 6076,
    "reward": 79.12841,
    "length": 74,
    "time": 93758.303041,
    "actor_loss": -64.31758117675781,
    "critic_loss": 9.074850082397461,
    "ent_coef": 0.07033203542232513,
    "learning_rate": 0.001
  },
  {
    "episode": 6077,
    "reward": 77.897655,
    "length": 75,
    "time": 93776.595286,
    "actor_loss": -68.79167938232422,
    "critic_loss": 5.763608455657959,
    "ent_coef": 0.07288500666618347,
    "learning_rate": 0.001
  },
  {
    "episode": 6078,
    "reward": 90.847242,
    "length": 62,
    "time": 93790.048231,
    "actor_loss": -64.20023345947266,
    "critic_loss": 19.973398208618164,
    "ent_coef": 0.07732096314430237,
    "learning_rate": 0.001
  },
  {
    "episode": 6079,
    "reward": 78.382767,
    "length": 73,
    "time": 93802.822893,
    "actor_loss": -66.28608703613281,
    "critic_loss": 16.344865798950195,
    "ent_coef": 0.08882037550210953,
    "learning_rate": 0.001
  },
  {
    "episode": 6080,
    "reward": 76.787879,
    "length": 80,
    "time": 93816.192142,
    "actor_loss": -63.98127746582031,
    "critic_loss": 9.484416961669922,
    "ent_coef": 0.09232055395841599,
    "learning_rate": 0.001
  },
  {
    "episode": 6081,
    "reward": 86.164381,
    "length": 71,
    "time": 93828.90938,
    "actor_loss": -65.47308349609375,
    "critic_loss": 22.62267303466797,
    "ent_coef": 0.09543642401695251,
    "learning_rate": 0.001
  },
  {
    "episode": 6082,
    "reward": 80.517917,
    "length": 77,
    "time": 93842.690862,
    "actor_loss": -62.80672073364258,
    "critic_loss": 31.414775848388672,
    "ent_coef": 0.09675521403551102,
    "learning_rate": 0.001
  },
  {
    "episode": 6083,
    "reward": 81.497554,
    "length": 81,
    "time": 93858.310805,
    "actor_loss": -68.77328491210938,
    "critic_loss": 60.70329666137695,
    "ent_coef": 0.09803227335214615,
    "learning_rate": 0.001
  },
  {
    "episode": 6084,
    "reward": 78.150666,
    "length": 82,
    "time": 93876.555937,
    "actor_loss": -60.14783477783203,
    "critic_loss": 35.74230194091797,
    "ent_coef": 0.09910183399915695,
    "learning_rate": 0.001
  },
  {
    "episode": 6085,
    "reward": 82.461177,
    "length": 80,
    "time": 93889.755673,
    "actor_loss": -63.238197326660156,
    "critic_loss": 29.81957244873047,
    "ent_coef": 0.09643327444791794,
    "learning_rate": 0.001
  },
  {
    "episode": 6086,
    "reward": 78.854995,
    "length": 71,
    "time": 93902.951639,
    "actor_loss": -66.07907104492188,
    "critic_loss": 92.11956024169922,
    "ent_coef": 0.09507029503583908,
    "learning_rate": 0.001
  },
  {
    "episode": 6087,
    "reward": 76.916777,
    "length": 73,
    "time": 93915.335014,
    "actor_loss": -68.03092956542969,
    "critic_loss": 6.539292335510254,
    "ent_coef": 0.09236053377389908,
    "learning_rate": 0.001
  },
  {
    "episode": 6088,
    "reward": 77.172557,
    "length": 74,
    "time": 93929.462367,
    "actor_loss": -60.539268493652344,
    "critic_loss": 9.864583015441895,
    "ent_coef": 0.0900840014219284,
    "learning_rate": 0.001
  },
  {
    "episode": 6089,
    "reward": 86.775203,
    "length": 71,
    "time": 93942.658176,
    "actor_loss": -60.06215286254883,
    "critic_loss": 6.595246315002441,
    "ent_coef": 0.08764959871768951,
    "learning_rate": 0.001
  },
  {
    "episode": 6090,
    "reward": 76.38023,
    "length": 76,
    "time": 93956.896705,
    "actor_loss": -67.1368408203125,
    "critic_loss": 18.36762046813965,
    "ent_coef": 0.08937984704971313,
    "learning_rate": 0.001
  },
  {
    "episode": 6091,
    "reward": 77.397427,
    "length": 72,
    "time": 93969.635611,
    "actor_loss": -60.713436126708984,
    "critic_loss": 32.26995849609375,
    "ent_coef": 0.0952458307147026,
    "learning_rate": 0.001
  },
  {
    "episode": 6092,
    "reward": 77.971377,
    "length": 74,
    "time": 93986.493471,
    "actor_loss": -64.38595581054688,
    "critic_loss": 339.89593505859375,
    "ent_coef": 0.09173435717821121,
    "learning_rate": 0.001
  },
  {
    "episode": 6093,
    "reward": 74.496584,
    "length": 83,
    "time": 94001.130163,
    "actor_loss": -63.450408935546875,
    "critic_loss": 27.359189987182617,
    "ent_coef": 0.08797761052846909,
    "learning_rate": 0.001
  },
  {
    "episode": 6094,
    "reward": 51.621903,
    "length": 111,
    "time": 94021.292066,
    "actor_loss": -71.82540893554688,
    "critic_loss": 22.11763572692871,
    "ent_coef": 0.08562052249908447,
    "learning_rate": 0.001
  },
  {
    "episode": 6095,
    "reward": 68.252563,
    "length": 83,
    "time": 94035.625179,
    "actor_loss": -69.74266052246094,
    "critic_loss": 33.55901336669922,
    "ent_coef": 0.0857468992471695,
    "learning_rate": 0.001
  },
  {
    "episode": 6096,
    "reward": 87.464774,
    "length": 68,
    "time": 94047.23191,
    "actor_loss": -67.28743743896484,
    "critic_loss": 26.035354614257812,
    "ent_coef": 0.08726050704717636,
    "learning_rate": 0.001
  },
  {
    "episode": 6097,
    "reward": 76.408843,
    "length": 76,
    "time": 94061.813576,
    "actor_loss": -62.456607818603516,
    "critic_loss": 6.857216835021973,
    "ent_coef": 0.0864843875169754,
    "learning_rate": 0.001
  },
  {
    "episode": 6098,
    "reward": 80.612662,
    "length": 77,
    "time": 94075.199025,
    "actor_loss": -66.09260559082031,
    "critic_loss": 25.8579158782959,
    "ent_coef": 0.0888657197356224,
    "learning_rate": 0.001
  },
  {
    "episode": 6099,
    "reward": 78.321407,
    "length": 76,
    "time": 94089.872772,
    "actor_loss": -60.54066467285156,
    "critic_loss": 8.588323593139648,
    "ent_coef": 0.09255076944828033,
    "learning_rate": 0.001
  },
  {
    "episode": 6100,
    "reward": 68.796069,
    "length": 100,
    "time": 94106.752697,
    "actor_loss": -63.199520111083984,
    "critic_loss": 10.689783096313477,
    "ent_coef": 0.08896230161190033,
    "learning_rate": 0.001
  },
  {
    "episode": 6101,
    "reward": 56.047059,
    "length": 128,
    "time": 94128.155118,
    "actor_loss": -60.579715728759766,
    "critic_loss": 4.215943813323975,
    "ent_coef": 0.08531424403190613,
    "learning_rate": 0.001
  },
  {
    "episode": 6102,
    "reward": 64.745411,
    "length": 107,
    "time": 94145.050209,
    "actor_loss": -62.57231903076172,
    "critic_loss": 17.055967330932617,
    "ent_coef": 0.08641843497753143,
    "learning_rate": 0.001
  },
  {
    "episode": 6103,
    "reward": 78.307709,
    "length": 80,
    "time": 94161.76233,
    "actor_loss": -56.90934753417969,
    "critic_loss": 7.5055623054504395,
    "ent_coef": 0.08835316449403763,
    "learning_rate": 0.001
  },
  {
    "episode": 6104,
    "reward": 71.378596,
    "length": 93,
    "time": 94178.044433,
    "actor_loss": -64.06765747070312,
    "critic_loss": 28.784908294677734,
    "ent_coef": 0.08781272917985916,
    "learning_rate": 0.001
  },
  {
    "episode": 6105,
    "reward": 72.305369,
    "length": 97,
    "time": 94195.444539,
    "actor_loss": -60.46373748779297,
    "critic_loss": 33.55501174926758,
    "ent_coef": 0.08845329284667969,
    "learning_rate": 0.001
  },
  {
    "episode": 6106,
    "reward": 69.920382,
    "length": 102,
    "time": 94212.147213,
    "actor_loss": -60.077735900878906,
    "critic_loss": 8.536537170410156,
    "ent_coef": 0.09294848889112473,
    "learning_rate": 0.001
  },
  {
    "episode": 6107,
    "reward": 79.123764,
    "length": 84,
    "time": 94226.125943,
    "actor_loss": -67.85911560058594,
    "critic_loss": 66.01261901855469,
    "ent_coef": 0.09289299696683884,
    "learning_rate": 0.001
  },
  {
    "episode": 6108,
    "reward": 75.069405,
    "length": 94,
    "time": 94244.111421,
    "actor_loss": -68.76508331298828,
    "critic_loss": 24.107574462890625,
    "ent_coef": 0.09793784469366074,
    "learning_rate": 0.001
  },
  {
    "episode": 6109,
    "reward": 71.193944,
    "length": 93,
    "time": 94259.122645,
    "actor_loss": -64.99554443359375,
    "critic_loss": 3.8445401191711426,
    "ent_coef": 0.0956248790025711,
    "learning_rate": 0.001
  },
  {
    "episode": 6110,
    "reward": 88.708347,
    "length": 66,
    "time": 94271.788085,
    "actor_loss": -64.58350372314453,
    "critic_loss": 8.678326606750488,
    "ent_coef": 0.09521472454071045,
    "learning_rate": 0.001
  },
  {
    "episode": 6111,
    "reward": 86.871393,
    "length": 70,
    "time": 94284.589692,
    "actor_loss": -61.754798889160156,
    "critic_loss": 29.950841903686523,
    "ent_coef": 0.09419184178113937,
    "learning_rate": 0.001
  },
  {
    "episode": 6112,
    "reward": 88.73786,
    "length": 68,
    "time": 94296.392514,
    "actor_loss": -62.49134063720703,
    "critic_loss": 20.19628143310547,
    "ent_coef": 0.09352246671915054,
    "learning_rate": 0.001
  },
  {
    "episode": 6113,
    "reward": 79.556296,
    "length": 85,
    "time": 94313.392027,
    "actor_loss": -58.409568786621094,
    "critic_loss": 17.259910583496094,
    "ent_coef": 0.08901528269052505,
    "learning_rate": 0.001
  },
  {
    "episode": 6114,
    "reward": 80.964044,
    "length": 83,
    "time": 94326.986839,
    "actor_loss": -68.47624206542969,
    "critic_loss": 18.748592376708984,
    "ent_coef": 0.09031623601913452,
    "learning_rate": 0.001
  },
  {
    "episode": 6115,
    "reward": 87.601151,
    "length": 69,
    "time": 94339.878885,
    "actor_loss": -65.9531478881836,
    "critic_loss": 8.443052291870117,
    "ent_coef": 0.08992508053779602,
    "learning_rate": 0.001
  },
  {
    "episode": 6116,
    "reward": 90.306804,
    "length": 64,
    "time": 94352.191651,
    "actor_loss": -64.18230438232422,
    "critic_loss": 8.519399642944336,
    "ent_coef": 0.08760232478380203,
    "learning_rate": 0.001
  },
  {
    "episode": 6117,
    "reward": 77.346587,
    "length": 85,
    "time": 94366.05657,
    "actor_loss": -63.16734313964844,
    "critic_loss": 12.016175270080566,
    "ent_coef": 0.08920664340257645,
    "learning_rate": 0.001
  },
  {
    "episode": 6118,
    "reward": 75.942423,
    "length": 98,
    "time": 94381.82636,
    "actor_loss": -65.16459655761719,
    "critic_loss": 9.493385314941406,
    "ent_coef": 0.08621763437986374,
    "learning_rate": 0.001
  },
  {
    "episode": 6119,
    "reward": 74.565452,
    "length": 78,
    "time": 94398.187098,
    "actor_loss": -67.6943359375,
    "critic_loss": 108.20942687988281,
    "ent_coef": 0.07849046587944031,
    "learning_rate": 0.001
  },
  {
    "episode": 6120,
    "reward": 64.017315,
    "length": 97,
    "time": 94414.65814,
    "actor_loss": -66.19772338867188,
    "critic_loss": 605.89892578125,
    "ent_coef": 0.06969583034515381,
    "learning_rate": 0.001
  },
  {
    "episode": 6121,
    "reward": 79.174627,
    "length": 86,
    "time": 94429.625988,
    "actor_loss": -67.1910400390625,
    "critic_loss": 4.949977874755859,
    "ent_coef": 0.06749153882265091,
    "learning_rate": 0.001
  },
  {
    "episode": 6122,
    "reward": 81.377187,
    "length": 75,
    "time": 94443.982762,
    "actor_loss": -68.58056640625,
    "critic_loss": 35.724143981933594,
    "ent_coef": 0.07238227128982544,
    "learning_rate": 0.001
  },
  {
    "episode": 6123,
    "reward": 82.301048,
    "length": 75,
    "time": 94457.725189,
    "actor_loss": -59.84432601928711,
    "critic_loss": 93.07982635498047,
    "ent_coef": 0.07636556029319763,
    "learning_rate": 0.001
  },
  {
    "episode": 6124,
    "reward": 87.1378,
    "length": 72,
    "time": 94470.470632,
    "actor_loss": -63.694129943847656,
    "critic_loss": 12.451775550842285,
    "ent_coef": 0.07676959782838821,
    "learning_rate": 0.001
  },
  {
    "episode": 6125,
    "reward": 82.651837,
    "length": 79,
    "time": 94486.686329,
    "actor_loss": -59.56291198730469,
    "critic_loss": 17.466724395751953,
    "ent_coef": 0.08080366253852844,
    "learning_rate": 0.001
  },
  {
    "episode": 6126,
    "reward": 79.585028,
    "length": 85,
    "time": 94501.558596,
    "actor_loss": -66.96207427978516,
    "critic_loss": 6.16762638092041,
    "ent_coef": 0.0786968320608139,
    "learning_rate": 0.001
  },
  {
    "episode": 6127,
    "reward": 81.869471,
    "length": 82,
    "time": 94517.247981,
    "actor_loss": -64.12727355957031,
    "critic_loss": 27.21133804321289,
    "ent_coef": 0.07734030485153198,
    "learning_rate": 0.001
  },
  {
    "episode": 6128,
    "reward": 23.486906,
    "length": 173,
    "time": 94545.390848,
    "actor_loss": -65.60122680664062,
    "critic_loss": 64.21382141113281,
    "ent_coef": 0.07464327663183212,
    "learning_rate": 0.001
  },
  {
    "episode": 6129,
    "reward": 82.796924,
    "length": 74,
    "time": 94562.653355,
    "actor_loss": -63.06589126586914,
    "critic_loss": 41.16769027709961,
    "ent_coef": 0.0794033408164978,
    "learning_rate": 0.001
  },
  {
    "episode": 6130,
    "reward": 61.384427,
    "length": 112,
    "time": 94582.587111,
    "actor_loss": -66.00196838378906,
    "critic_loss": 5.806189060211182,
    "ent_coef": 0.07958301156759262,
    "learning_rate": 0.001
  },
  {
    "episode": 6131,
    "reward": 84.972188,
    "length": 70,
    "time": 94595.288613,
    "actor_loss": -68.8472900390625,
    "critic_loss": 19.102046966552734,
    "ent_coef": 0.07849185168743134,
    "learning_rate": 0.001
  },
  {
    "episode": 6132,
    "reward": 87.23545,
    "length": 70,
    "time": 94610.348137,
    "actor_loss": -67.3333740234375,
    "critic_loss": 4.499361038208008,
    "ent_coef": 0.07986640185117722,
    "learning_rate": 0.001
  },
  {
    "episode": 6133,
    "reward": 75.544829,
    "length": 87,
    "time": 94626.202692,
    "actor_loss": -64.98624420166016,
    "critic_loss": 55.403236389160156,
    "ent_coef": 0.08102205395698547,
    "learning_rate": 0.001
  },
  {
    "episode": 6134,
    "reward": 74.138026,
    "length": 86,
    "time": 94640.207314,
    "actor_loss": -61.487491607666016,
    "critic_loss": 11.32870864868164,
    "ent_coef": 0.08353597670793533,
    "learning_rate": 0.001
  },
  {
    "episode": 6135,
    "reward": 49.936812,
    "length": 129,
    "time": 94661.025298,
    "actor_loss": -64.93659973144531,
    "critic_loss": 4.3291120529174805,
    "ent_coef": 0.07524169236421585,
    "learning_rate": 0.001
  },
  {
    "episode": 6136,
    "reward": 60.366141,
    "length": 118,
    "time": 94679.484013,
    "actor_loss": -66.28823852539062,
    "critic_loss": 11.394351959228516,
    "ent_coef": 0.06883489340543747,
    "learning_rate": 0.001
  },
  {
    "episode": 6137,
    "reward": 78.879333,
    "length": 82,
    "time": 94693.355296,
    "actor_loss": -68.01722717285156,
    "critic_loss": 2.6841492652893066,
    "ent_coef": 0.06903740018606186,
    "learning_rate": 0.001
  },
  {
    "episode": 6138,
    "reward": 90.352838,
    "length": 63,
    "time": 94704.706535,
    "actor_loss": -67.24940490722656,
    "critic_loss": 83.92056274414062,
    "ent_coef": 0.07001101970672607,
    "learning_rate": 0.001
  },
  {
    "episode": 6139,
    "reward": 71.059192,
    "length": 99,
    "time": 94722.042546,
    "actor_loss": -61.66516876220703,
    "critic_loss": 12.506263732910156,
    "ent_coef": 0.0691220760345459,
    "learning_rate": 0.001
  },
  {
    "episode": 6140,
    "reward": 89.577212,
    "length": 64,
    "time": 94734.391284,
    "actor_loss": -67.11294555664062,
    "critic_loss": 10.896245956420898,
    "ent_coef": 0.06845807284116745,
    "learning_rate": 0.001
  },
  {
    "episode": 6141,
    "reward": 73.068005,
    "length": 87,
    "time": 94752.397829,
    "actor_loss": -66.62959289550781,
    "critic_loss": 8.947380065917969,
    "ent_coef": 0.07402500510215759,
    "learning_rate": 0.001
  },
  {
    "episode": 6142,
    "reward": 89.812322,
    "length": 65,
    "time": 94764.434616,
    "actor_loss": -61.95305252075195,
    "critic_loss": 12.375191688537598,
    "ent_coef": 0.079938143491745,
    "learning_rate": 0.001
  },
  {
    "episode": 6143,
    "reward": 90.123901,
    "length": 62,
    "time": 94775.69184,
    "actor_loss": -69.97003936767578,
    "critic_loss": 101.00401306152344,
    "ent_coef": 0.08107997477054596,
    "learning_rate": 0.001
  },
  {
    "episode": 6144,
    "reward": 91.371046,
    "length": 60,
    "time": 94787.25505,
    "actor_loss": -65.77925109863281,
    "critic_loss": 23.739669799804688,
    "ent_coef": 0.0812624841928482,
    "learning_rate": 0.001
  },
  {
    "episode": 6145,
    "reward": 86.666551,
    "length": 70,
    "time": 94800.391739,
    "actor_loss": -63.456077575683594,
    "critic_loss": 24.767864227294922,
    "ent_coef": 0.07809535413980484,
    "learning_rate": 0.001
  },
  {
    "episode": 6146,
    "reward": 83.371044,
    "length": 75,
    "time": 94816.67732,
    "actor_loss": -62.023529052734375,
    "critic_loss": 26.850276947021484,
    "ent_coef": 0.07759175449609756,
    "learning_rate": 0.001
  },
  {
    "episode": 6147,
    "reward": 82.107608,
    "length": 75,
    "time": 94830.318261,
    "actor_loss": -61.83078384399414,
    "critic_loss": 7.5524091720581055,
    "ent_coef": 0.07917819172143936,
    "learning_rate": 0.001
  },
  {
    "episode": 6148,
    "reward": 77.98691,
    "length": 76,
    "time": 94843.369001,
    "actor_loss": -61.48841857910156,
    "critic_loss": 5.03971004486084,
    "ent_coef": 0.08174556493759155,
    "learning_rate": 0.001
  },
  {
    "episode": 6149,
    "reward": 65.039621,
    "length": 103,
    "time": 94862.02636,
    "actor_loss": -63.27069854736328,
    "critic_loss": 6.581135272979736,
    "ent_coef": 0.07909759134054184,
    "learning_rate": 0.001
  },
  {
    "episode": 6150,
    "reward": 78.174023,
    "length": 74,
    "time": 94878.366849,
    "actor_loss": -63.649635314941406,
    "critic_loss": 25.76365852355957,
    "ent_coef": 0.07706744223833084,
    "learning_rate": 0.001
  },
  {
    "episode": 6151,
    "reward": 75.496135,
    "length": 112,
    "time": 94898.585156,
    "actor_loss": -70.76731872558594,
    "critic_loss": 4.132472991943359,
    "ent_coef": 0.07873823493719101,
    "learning_rate": 0.001
  },
  {
    "episode": 6152,
    "reward": 90.215518,
    "length": 63,
    "time": 94911.886384,
    "actor_loss": -64.0838623046875,
    "critic_loss": 6.141976833343506,
    "ent_coef": 0.08276642113924026,
    "learning_rate": 0.001
  },
  {
    "episode": 6153,
    "reward": 75.860602,
    "length": 82,
    "time": 94929.695198,
    "actor_loss": -66.70059967041016,
    "critic_loss": 50.39417266845703,
    "ent_coef": 0.0838467925786972,
    "learning_rate": 0.001
  },
  {
    "episode": 6154,
    "reward": 73.26242,
    "length": 84,
    "time": 94946.249363,
    "actor_loss": -65.77432250976562,
    "critic_loss": 4.1362714767456055,
    "ent_coef": 0.08436159044504166,
    "learning_rate": 0.001
  },
  {
    "episode": 6155,
    "reward": 83.306953,
    "length": 129,
    "time": 94969.684564,
    "actor_loss": -69.98873138427734,
    "critic_loss": 5.372241973876953,
    "ent_coef": 0.08209738880395889,
    "learning_rate": 0.001
  },
  {
    "episode": 6156,
    "reward": 74.828625,
    "length": 79,
    "time": 94987.917755,
    "actor_loss": -59.68248748779297,
    "critic_loss": 8.04824447631836,
    "ent_coef": 0.0889890119433403,
    "learning_rate": 0.001
  },
  {
    "episode": 6157,
    "reward": 78.660726,
    "length": 75,
    "time": 95002.370931,
    "actor_loss": -68.33324432373047,
    "critic_loss": 120.16424560546875,
    "ent_coef": 0.08809830248355865,
    "learning_rate": 0.001
  },
  {
    "episode": 6158,
    "reward": 85.501044,
    "length": 72,
    "time": 95016.343644,
    "actor_loss": -61.636863708496094,
    "critic_loss": 10.646642684936523,
    "ent_coef": 0.08803950995206833,
    "learning_rate": 0.001
  },
  {
    "episode": 6159,
    "reward": 89.221668,
    "length": 67,
    "time": 95029.969527,
    "actor_loss": -68.58627319335938,
    "critic_loss": 108.34138488769531,
    "ent_coef": 0.08863510191440582,
    "learning_rate": 0.001
  },
  {
    "episode": 6160,
    "reward": 91.424463,
    "length": 60,
    "time": 95044.58907,
    "actor_loss": -58.359413146972656,
    "critic_loss": 15.072478294372559,
    "ent_coef": 0.08676185458898544,
    "learning_rate": 0.001
  },
  {
    "episode": 6161,
    "reward": 83.627821,
    "length": 77,
    "time": 95062.498459,
    "actor_loss": -70.145751953125,
    "critic_loss": 37.819393157958984,
    "ent_coef": 0.08219975978136063,
    "learning_rate": 0.001
  },
  {
    "episode": 6162,
    "reward": 65.364999,
    "length": 107,
    "time": 95082.780544,
    "actor_loss": -63.61664962768555,
    "critic_loss": 13.387547492980957,
    "ent_coef": 0.08449117839336395,
    "learning_rate": 0.001
  },
  {
    "episode": 6163,
    "reward": 80.843572,
    "length": 81,
    "time": 95097.442909,
    "actor_loss": -63.411991119384766,
    "critic_loss": 5.184286117553711,
    "ent_coef": 0.0824296697974205,
    "learning_rate": 0.001
  },
  {
    "episode": 6164,
    "reward": 83.136872,
    "length": 76,
    "time": 95112.435044,
    "actor_loss": -66.16316223144531,
    "critic_loss": 15.224248886108398,
    "ent_coef": 0.07747828215360641,
    "learning_rate": 0.001
  },
  {
    "episode": 6165,
    "reward": 89.011264,
    "length": 65,
    "time": 95126.022718,
    "actor_loss": -60.187255859375,
    "critic_loss": 32.58834457397461,
    "ent_coef": 0.0767037570476532,
    "learning_rate": 0.001
  },
  {
    "episode": 6166,
    "reward": 77.844751,
    "length": 84,
    "time": 95142.272871,
    "actor_loss": -64.87691497802734,
    "critic_loss": 6.076889991760254,
    "ent_coef": 0.0708739385008812,
    "learning_rate": 0.001
  },
  {
    "episode": 6167,
    "reward": 90.233674,
    "length": 64,
    "time": 95156.013339,
    "actor_loss": -59.45551300048828,
    "critic_loss": 17.64417839050293,
    "ent_coef": 0.07090706378221512,
    "learning_rate": 0.001
  },
  {
    "episode": 6168,
    "reward": 88.069224,
    "length": 67,
    "time": 95168.781619,
    "actor_loss": -67.93888854980469,
    "critic_loss": 9.782405853271484,
    "ent_coef": 0.07198942452669144,
    "learning_rate": 0.001
  },
  {
    "episode": 6169,
    "reward": 77.335978,
    "length": 78,
    "time": 95183.965492,
    "actor_loss": -61.483428955078125,
    "critic_loss": 9.46924877166748,
    "ent_coef": 0.07149692624807358,
    "learning_rate": 0.001
  },
  {
    "episode": 6170,
    "reward": 69.354983,
    "length": 103,
    "time": 95203.128693,
    "actor_loss": -61.556640625,
    "critic_loss": 13.056078910827637,
    "ent_coef": 0.07030615210533142,
    "learning_rate": 0.001
  },
  {
    "episode": 6171,
    "reward": 52.983556,
    "length": 111,
    "time": 95225.383928,
    "actor_loss": -62.920413970947266,
    "critic_loss": 5.730401039123535,
    "ent_coef": 0.07761088013648987,
    "learning_rate": 0.001
  },
  {
    "episode": 6172,
    "reward": 88.172188,
    "length": 65,
    "time": 95243.94583,
    "actor_loss": -59.92115020751953,
    "critic_loss": 19.98529052734375,
    "ent_coef": 0.08020935207605362,
    "learning_rate": 0.001
  },
  {
    "episode": 6173,
    "reward": 69.446717,
    "length": 94,
    "time": 95262.859308,
    "actor_loss": -63.974327087402344,
    "critic_loss": 23.861900329589844,
    "ent_coef": 0.07753138989210129,
    "learning_rate": 0.001
  },
  {
    "episode": 6174,
    "reward": 74.729889,
    "length": 80,
    "time": 95280.646392,
    "actor_loss": -62.99475860595703,
    "critic_loss": 4.176804542541504,
    "ent_coef": 0.07707089185714722,
    "learning_rate": 0.001
  },
  {
    "episode": 6175,
    "reward": 2.635934,
    "length": 175,
    "time": 95310.126959,
    "actor_loss": -67.1116943359375,
    "critic_loss": 10.797484397888184,
    "ent_coef": 0.08013969659805298,
    "learning_rate": 0.001
  },
  {
    "episode": 6176,
    "reward": 78.357985,
    "length": 83,
    "time": 95326.249141,
    "actor_loss": -59.05318832397461,
    "critic_loss": 55.01880645751953,
    "ent_coef": 0.077564537525177,
    "learning_rate": 0.001
  },
  {
    "episode": 6177,
    "reward": 79.043789,
    "length": 76,
    "time": 95342.505118,
    "actor_loss": -55.02021789550781,
    "critic_loss": 19.107685089111328,
    "ent_coef": 0.08433646708726883,
    "learning_rate": 0.001
  },
  {
    "episode": 6178,
    "reward": -159.680977,
    "length": 153,
    "time": 95366.798486,
    "actor_loss": -57.830528259277344,
    "critic_loss": 9.601984977722168,
    "ent_coef": 0.08130190521478653,
    "learning_rate": 0.001
  },
  {
    "episode": 6179,
    "reward": 50.685328,
    "length": 104,
    "time": 95384.399703,
    "actor_loss": -59.76676559448242,
    "critic_loss": 40.436859130859375,
    "ent_coef": 0.08361414074897766,
    "learning_rate": 0.001
  },
  {
    "episode": 6180,
    "reward": 77.607917,
    "length": 85,
    "time": 95398.81866,
    "actor_loss": -60.92692565917969,
    "critic_loss": 8.520450592041016,
    "ent_coef": 0.08424746245145798,
    "learning_rate": 0.001
  },
  {
    "episode": 6181,
    "reward": -162.629225,
    "length": 144,
    "time": 95424.960416,
    "actor_loss": -67.29450988769531,
    "critic_loss": 13.786443710327148,
    "ent_coef": 0.0821978822350502,
    "learning_rate": 0.001
  },
  {
    "episode": 6182,
    "reward": 58.710077,
    "length": 110,
    "time": 95444.089948,
    "actor_loss": -65.13859558105469,
    "critic_loss": 8.866039276123047,
    "ent_coef": 0.08023654669523239,
    "learning_rate": 0.001
  },
  {
    "episode": 6183,
    "reward": 90.564821,
    "length": 61,
    "time": 95456.433921,
    "actor_loss": -61.619415283203125,
    "critic_loss": 10.26711654663086,
    "ent_coef": 0.0812951922416687,
    "learning_rate": 0.001
  },
  {
    "episode": 6184,
    "reward": 88.501026,
    "length": 71,
    "time": 95469.986035,
    "actor_loss": -61.695499420166016,
    "critic_loss": 14.01347541809082,
    "ent_coef": 0.0822383239865303,
    "learning_rate": 0.001
  },
  {
    "episode": 6185,
    "reward": 87.80794,
    "length": 66,
    "time": 95486.619944,
    "actor_loss": -69.43484497070312,
    "critic_loss": 32.296905517578125,
    "ent_coef": 0.08171544224023819,
    "learning_rate": 0.001
  },
  {
    "episode": 6186,
    "reward": 91.869645,
    "length": 61,
    "time": 95499.050989,
    "actor_loss": -67.89141845703125,
    "critic_loss": 7.561359882354736,
    "ent_coef": 0.08536379039287567,
    "learning_rate": 0.001
  },
  {
    "episode": 6187,
    "reward": 89.927883,
    "length": 64,
    "time": 95510.923929,
    "actor_loss": -65.56453704833984,
    "critic_loss": 7.457032680511475,
    "ent_coef": 0.08697781711816788,
    "learning_rate": 0.001
  },
  {
    "episode": 6188,
    "reward": 78.314068,
    "length": 83,
    "time": 95525.889083,
    "actor_loss": -63.75184631347656,
    "critic_loss": 7.579033851623535,
    "ent_coef": 0.08188847452402115,
    "learning_rate": 0.001
  },
  {
    "episode": 6189,
    "reward": 83.93873,
    "length": 87,
    "time": 95545.295707,
    "actor_loss": -63.5164909362793,
    "critic_loss": 22.92262840270996,
    "ent_coef": 0.07622916996479034,
    "learning_rate": 0.001
  },
  {
    "episode": 6190,
    "reward": 54.73687,
    "length": 112,
    "time": 95567.666334,
    "actor_loss": -62.984806060791016,
    "critic_loss": 9.83889389038086,
    "ent_coef": 0.07607197761535645,
    "learning_rate": 0.001
  },
  {
    "episode": 6191,
    "reward": 84.919449,
    "length": 68,
    "time": 95580.848673,
    "actor_loss": -60.59168243408203,
    "critic_loss": 22.458608627319336,
    "ent_coef": 0.07482217997312546,
    "learning_rate": 0.001
  },
  {
    "episode": 6192,
    "reward": -155.147593,
    "length": 139,
    "time": 95604.027099,
    "actor_loss": -66.08961486816406,
    "critic_loss": 15.021405220031738,
    "ent_coef": 0.07437562197446823,
    "learning_rate": 0.001
  },
  {
    "episode": 6193,
    "reward": 90.037661,
    "length": 63,
    "time": 95616.205828,
    "actor_loss": -70.71045684814453,
    "critic_loss": 27.609718322753906,
    "ent_coef": 0.07150423526763916,
    "learning_rate": 0.001
  },
  {
    "episode": 6194,
    "reward": 87.566712,
    "length": 79,
    "time": 95632.251166,
    "actor_loss": -64.11616516113281,
    "critic_loss": 24.861621856689453,
    "ent_coef": 0.06980054825544357,
    "learning_rate": 0.001
  },
  {
    "episode": 6195,
    "reward": 85.831442,
    "length": 65,
    "time": 95646.681981,
    "actor_loss": -60.73211669921875,
    "critic_loss": 8.351144790649414,
    "ent_coef": 0.07069272547960281,
    "learning_rate": 0.001
  },
  {
    "episode": 6196,
    "reward": 83.679904,
    "length": 64,
    "time": 95662.74124,
    "actor_loss": -63.64567184448242,
    "critic_loss": 22.810068130493164,
    "ent_coef": 0.07282865792512894,
    "learning_rate": 0.001
  },
  {
    "episode": 6197,
    "reward": 92.954276,
    "length": 56,
    "time": 95674.023299,
    "actor_loss": -59.71873474121094,
    "critic_loss": 10.843399047851562,
    "ent_coef": 0.07530278712511063,
    "learning_rate": 0.001
  },
  {
    "episode": 6198,
    "reward": 89.306694,
    "length": 67,
    "time": 95686.702202,
    "actor_loss": -61.6456413269043,
    "critic_loss": 10.979122161865234,
    "ent_coef": 0.07396731525659561,
    "learning_rate": 0.001
  },
  {
    "episode": 6199,
    "reward": 80.831724,
    "length": 82,
    "time": 95704.979764,
    "actor_loss": -64.30863952636719,
    "critic_loss": 30.305091857910156,
    "ent_coef": 0.07714871317148209,
    "learning_rate": 0.001
  },
  {
    "episode": 6200,
    "reward": 83.718775,
    "length": 70,
    "time": 95720.316079,
    "actor_loss": -59.75471115112305,
    "critic_loss": 5.101232051849365,
    "ent_coef": 0.07854308933019638,
    "learning_rate": 0.001
  },
  {
    "episode": 6201,
    "reward": 80.828566,
    "length": 87,
    "time": 95737.185458,
    "actor_loss": -58.362098693847656,
    "critic_loss": 16.333637237548828,
    "ent_coef": 0.07230422645807266,
    "learning_rate": 0.001
  },
  {
    "episode": 6202,
    "reward": 90.862076,
    "length": 61,
    "time": 95748.981646,
    "actor_loss": -59.06398010253906,
    "critic_loss": 15.561867713928223,
    "ent_coef": 0.06938786059617996,
    "learning_rate": 0.001
  },
  {
    "episode": 6203,
    "reward": 92.245845,
    "length": 57,
    "time": 95761.454225,
    "actor_loss": -60.75848388671875,
    "critic_loss": 9.340435028076172,
    "ent_coef": 0.0695321336388588,
    "learning_rate": 0.001
  },
  {
    "episode": 6204,
    "reward": 91.553647,
    "length": 59,
    "time": 95773.310369,
    "actor_loss": -64.20919799804688,
    "critic_loss": 25.234149932861328,
    "ent_coef": 0.06964124739170074,
    "learning_rate": 0.001
  },
  {
    "episode": 6205,
    "reward": 83.843292,
    "length": 95,
    "time": 95791.628302,
    "actor_loss": -57.31312942504883,
    "critic_loss": 19.237468719482422,
    "ent_coef": 0.07088731974363327,
    "learning_rate": 0.001
  },
  {
    "episode": 6206,
    "reward": 80.945698,
    "length": 91,
    "time": 95807.925794,
    "actor_loss": -64.30130004882812,
    "critic_loss": 13.569564819335938,
    "ent_coef": 0.06739393621683121,
    "learning_rate": 0.001
  },
  {
    "episode": 6207,
    "reward": 82.827662,
    "length": 91,
    "time": 95824.413313,
    "actor_loss": -60.26063537597656,
    "critic_loss": 41.76112365722656,
    "ent_coef": 0.06728760898113251,
    "learning_rate": 0.001
  },
  {
    "episode": 6208,
    "reward": 86.08817,
    "length": 69,
    "time": 95839.187309,
    "actor_loss": -60.858367919921875,
    "critic_loss": 6.511837959289551,
    "ent_coef": 0.06945954263210297,
    "learning_rate": 0.001
  },
  {
    "episode": 6209,
    "reward": 84.527916,
    "length": 80,
    "time": 95853.814747,
    "actor_loss": -69.01747131347656,
    "critic_loss": 8.464184761047363,
    "ent_coef": 0.0747847631573677,
    "learning_rate": 0.001
  },
  {
    "episode": 6210,
    "reward": 73.831912,
    "length": 79,
    "time": 95871.002508,
    "actor_loss": -60.452510833740234,
    "critic_loss": 22.121530532836914,
    "ent_coef": 0.08025309443473816,
    "learning_rate": 0.001
  },
  {
    "episode": 6211,
    "reward": 78.701647,
    "length": 82,
    "time": 95886.2673,
    "actor_loss": -61.04606628417969,
    "critic_loss": 19.290449142456055,
    "ent_coef": 0.08224200457334518,
    "learning_rate": 0.001
  },
  {
    "episode": 6212,
    "reward": 89.476761,
    "length": 64,
    "time": 95900.324237,
    "actor_loss": -62.498191833496094,
    "critic_loss": 66.05889129638672,
    "ent_coef": 0.0808899775147438,
    "learning_rate": 0.001
  },
  {
    "episode": 6213,
    "reward": 90.434073,
    "length": 60,
    "time": 95913.702164,
    "actor_loss": -54.9442138671875,
    "critic_loss": 7.575826644897461,
    "ent_coef": 0.07945223152637482,
    "learning_rate": 0.001
  },
  {
    "episode": 6214,
    "reward": 90.211483,
    "length": 63,
    "time": 95925.990889,
    "actor_loss": -69.08497619628906,
    "critic_loss": 64.47953796386719,
    "ent_coef": 0.07942789793014526,
    "learning_rate": 0.001
  },
  {
    "episode": 6215,
    "reward": 90.121316,
    "length": 63,
    "time": 95938.555734,
    "actor_loss": -62.700584411621094,
    "critic_loss": 13.226905822753906,
    "ent_coef": 0.07598543912172318,
    "learning_rate": 0.001
  },
  {
    "episode": 6216,
    "reward": 88.752429,
    "length": 65,
    "time": 95951.901089,
    "actor_loss": -60.89699172973633,
    "critic_loss": 32.36593246459961,
    "ent_coef": 0.07256172597408295,
    "learning_rate": 0.001
  },
  {
    "episode": 6217,
    "reward": 88.367733,
    "length": 65,
    "time": 95964.679596,
    "actor_loss": -59.885650634765625,
    "critic_loss": 9.918210983276367,
    "ent_coef": 0.07116653770208359,
    "learning_rate": 0.001
  },
  {
    "episode": 6218,
    "reward": 88.859224,
    "length": 71,
    "time": 95979.63377,
    "actor_loss": -62.926795959472656,
    "critic_loss": 81.45572662353516,
    "ent_coef": 0.07507377862930298,
    "learning_rate": 0.001
  },
  {
    "episode": 6219,
    "reward": 89.400894,
    "length": 63,
    "time": 95993.585334,
    "actor_loss": -65.50473022460938,
    "critic_loss": 12.964700698852539,
    "ent_coef": 0.0776529461145401,
    "learning_rate": 0.001
  },
  {
    "episode": 6220,
    "reward": 89.534055,
    "length": 63,
    "time": 96007.458132,
    "actor_loss": -63.599857330322266,
    "critic_loss": 19.716411590576172,
    "ent_coef": 0.08013614267110825,
    "learning_rate": 0.001
  },
  {
    "episode": 6221,
    "reward": 51.37944,
    "length": 114,
    "time": 96028.827339,
    "actor_loss": -53.82728576660156,
    "critic_loss": 14.197949409484863,
    "ent_coef": 0.08170028775930405,
    "learning_rate": 0.001
  },
  {
    "episode": 6222,
    "reward": 90.034481,
    "length": 62,
    "time": 96043.640256,
    "actor_loss": -62.296913146972656,
    "critic_loss": 4.051461219787598,
    "ent_coef": 0.08109530061483383,
    "learning_rate": 0.001
  },
  {
    "episode": 6223,
    "reward": 66.940633,
    "length": 93,
    "time": 96068.797784,
    "actor_loss": -60.043235778808594,
    "critic_loss": 27.65393829345703,
    "ent_coef": 0.07631318271160126,
    "learning_rate": 0.001
  },
  {
    "episode": 6224,
    "reward": 87.257945,
    "length": 64,
    "time": 96082.372358,
    "actor_loss": -61.762062072753906,
    "critic_loss": 9.013450622558594,
    "ent_coef": 0.07821153104305267,
    "learning_rate": 0.001
  },
  {
    "episode": 6225,
    "reward": 83.847957,
    "length": 84,
    "time": 96096.954861,
    "actor_loss": -54.332733154296875,
    "critic_loss": 14.731712341308594,
    "ent_coef": 0.07360752671957016,
    "learning_rate": 0.001
  },
  {
    "episode": 6226,
    "reward": 74.409821,
    "length": 83,
    "time": 96112.677387,
    "actor_loss": -66.0447769165039,
    "critic_loss": 15.540691375732422,
    "ent_coef": 0.07240933179855347,
    "learning_rate": 0.001
  },
  {
    "episode": 6227,
    "reward": 86.511714,
    "length": 78,
    "time": 96130.557757,
    "actor_loss": -65.21664428710938,
    "critic_loss": 18.85953140258789,
    "ent_coef": 0.07411924749612808,
    "learning_rate": 0.001
  },
  {
    "episode": 6228,
    "reward": 91.121822,
    "length": 62,
    "time": 96145.191358,
    "actor_loss": -65.56549072265625,
    "critic_loss": 10.526326179504395,
    "ent_coef": 0.07632634043693542,
    "learning_rate": 0.001
  },
  {
    "episode": 6229,
    "reward": 87.837667,
    "length": 72,
    "time": 96158.80479,
    "actor_loss": -64.7795181274414,
    "critic_loss": 24.991165161132812,
    "ent_coef": 0.07427483052015305,
    "learning_rate": 0.001
  },
  {
    "episode": 6230,
    "reward": 90.128089,
    "length": 63,
    "time": 96170.946841,
    "actor_loss": -63.646018981933594,
    "critic_loss": 14.857869148254395,
    "ent_coef": 0.0720207691192627,
    "learning_rate": 0.001
  },
  {
    "episode": 6231,
    "reward": 91.891411,
    "length": 59,
    "time": 96184.420824,
    "actor_loss": -67.23399353027344,
    "critic_loss": 109.57273864746094,
    "ent_coef": 0.06880826503038406,
    "learning_rate": 0.001
  },
  {
    "episode": 6232,
    "reward": 83.564272,
    "length": 74,
    "time": 96204.159353,
    "actor_loss": -61.226932525634766,
    "critic_loss": 12.693778991699219,
    "ent_coef": 0.06800975650548935,
    "learning_rate": 0.001
  },
  {
    "episode": 6233,
    "reward": 86.368739,
    "length": 75,
    "time": 96217.72604,
    "actor_loss": -56.26252365112305,
    "critic_loss": 144.04156494140625,
    "ent_coef": 0.0686468780040741,
    "learning_rate": 0.001
  },
  {
    "episode": 6234,
    "reward": 89.961304,
    "length": 63,
    "time": 96232.825182,
    "actor_loss": -67.88385009765625,
    "critic_loss": 11.430814743041992,
    "ent_coef": 0.07029671221971512,
    "learning_rate": 0.001
  },
  {
    "episode": 6235,
    "reward": 88.12407,
    "length": 65,
    "time": 96245.971158,
    "actor_loss": -60.98451232910156,
    "critic_loss": 16.685020446777344,
    "ent_coef": 0.067966990172863,
    "learning_rate": 0.001
  },
  {
    "episode": 6236,
    "reward": 79.968815,
    "length": 99,
    "time": 96264.375806,
    "actor_loss": -60.98868179321289,
    "critic_loss": 78.89669036865234,
    "ent_coef": 0.06412363052368164,
    "learning_rate": 0.001
  },
  {
    "episode": 6237,
    "reward": 87.732665,
    "length": 71,
    "time": 96278.811948,
    "actor_loss": -68.5268783569336,
    "critic_loss": 6.3782958984375,
    "ent_coef": 0.06471946090459824,
    "learning_rate": 0.001
  },
  {
    "episode": 6238,
    "reward": 88.757852,
    "length": 65,
    "time": 96293.206442,
    "actor_loss": -65.28807067871094,
    "critic_loss": 9.778847694396973,
    "ent_coef": 0.06134527549147606,
    "learning_rate": 0.001
  },
  {
    "episode": 6239,
    "reward": 90.691928,
    "length": 61,
    "time": 96304.74702,
    "actor_loss": -67.5645751953125,
    "critic_loss": 64.24028778076172,
    "ent_coef": 0.06245271861553192,
    "learning_rate": 0.001
  },
  {
    "episode": 6240,
    "reward": 84.90196,
    "length": 72,
    "time": 96320.466887,
    "actor_loss": -60.094120025634766,
    "critic_loss": 23.31326675415039,
    "ent_coef": 0.061053674668073654,
    "learning_rate": 0.001
  },
  {
    "episode": 6241,
    "reward": 87.691534,
    "length": 67,
    "time": 96335.363598,
    "actor_loss": -62.451332092285156,
    "critic_loss": 15.572226524353027,
    "ent_coef": 0.060337282717227936,
    "learning_rate": 0.001
  },
  {
    "episode": 6242,
    "reward": 88.59255,
    "length": 64,
    "time": 96352.83709,
    "actor_loss": -58.868202209472656,
    "critic_loss": 11.541515350341797,
    "ent_coef": 0.05950727313756943,
    "learning_rate": 0.001
  },
  {
    "episode": 6243,
    "reward": 85.62621,
    "length": 72,
    "time": 96365.314174,
    "actor_loss": -57.09900665283203,
    "critic_loss": 9.999701499938965,
    "ent_coef": 0.05641340836882591,
    "learning_rate": 0.001
  },
  {
    "episode": 6244,
    "reward": 89.712612,
    "length": 63,
    "time": 96379.2372,
    "actor_loss": -59.789146423339844,
    "critic_loss": 30.346647262573242,
    "ent_coef": 0.05611269176006317,
    "learning_rate": 0.001
  },
  {
    "episode": 6245,
    "reward": 87.81105,
    "length": 67,
    "time": 96391.237043,
    "actor_loss": -54.26808547973633,
    "critic_loss": 705.715087890625,
    "ent_coef": 0.05728834867477417,
    "learning_rate": 0.001
  },
  {
    "episode": 6246,
    "reward": 86.754774,
    "length": 68,
    "time": 96403.152603,
    "actor_loss": -69.67822265625,
    "critic_loss": 8.944267272949219,
    "ent_coef": 0.06003159284591675,
    "learning_rate": 0.001
  },
  {
    "episode": 6247,
    "reward": 81.711853,
    "length": 76,
    "time": 96419.37466,
    "actor_loss": -61.75381088256836,
    "critic_loss": 22.487064361572266,
    "ent_coef": 0.06297840923070908,
    "learning_rate": 0.001
  },
  {
    "episode": 6248,
    "reward": 89.423659,
    "length": 65,
    "time": 96433.880989,
    "actor_loss": -55.618194580078125,
    "critic_loss": 11.25743293762207,
    "ent_coef": 0.06325861066579819,
    "learning_rate": 0.001
  },
  {
    "episode": 6249,
    "reward": 86.345014,
    "length": 77,
    "time": 96447.268057,
    "actor_loss": -59.480262756347656,
    "critic_loss": 53.3451042175293,
    "ent_coef": 0.06280602514743805,
    "learning_rate": 0.001
  },
  {
    "episode": 6250,
    "reward": 89.186891,
    "length": 66,
    "time": 96464.620625,
    "actor_loss": -66.33277893066406,
    "critic_loss": 15.28010368347168,
    "ent_coef": 0.06356661021709442,
    "learning_rate": 0.001
  },
  {
    "episode": 6251,
    "reward": 90.970456,
    "length": 60,
    "time": 96477.260592,
    "actor_loss": -59.772335052490234,
    "critic_loss": 8.816227912902832,
    "ent_coef": 0.06524286419153214,
    "learning_rate": 0.001
  },
  {
    "episode": 6252,
    "reward": 91.232046,
    "length": 61,
    "time": 96489.337448,
    "actor_loss": -60.6414794921875,
    "critic_loss": 26.67046546936035,
    "ent_coef": 0.06599905341863632,
    "learning_rate": 0.001
  },
  {
    "episode": 6253,
    "reward": 86.62416,
    "length": 71,
    "time": 96502.867177,
    "actor_loss": -64.14089965820312,
    "critic_loss": 16.291797637939453,
    "ent_coef": 0.06345193833112717,
    "learning_rate": 0.001
  },
  {
    "episode": 6254,
    "reward": 84.687083,
    "length": 81,
    "time": 96519.354174,
    "actor_loss": -62.050148010253906,
    "critic_loss": 11.050317764282227,
    "ent_coef": 0.06297238916158676,
    "learning_rate": 0.001
  },
  {
    "episode": 6255,
    "reward": 85.583874,
    "length": 73,
    "time": 96532.101218,
    "actor_loss": -62.15475082397461,
    "critic_loss": 36.926795959472656,
    "ent_coef": 0.06533993780612946,
    "learning_rate": 0.001
  },
  {
    "episode": 6256,
    "reward": 91.952904,
    "length": 61,
    "time": 96545.771796,
    "actor_loss": -56.3331184387207,
    "critic_loss": 71.24308013916016,
    "ent_coef": 0.06785689294338226,
    "learning_rate": 0.001
  },
  {
    "episode": 6257,
    "reward": 89.645021,
    "length": 63,
    "time": 96557.98312,
    "actor_loss": -54.406410217285156,
    "critic_loss": 6.817318439483643,
    "ent_coef": 0.06607979536056519,
    "learning_rate": 0.001
  },
  {
    "episode": 6258,
    "reward": 89.494649,
    "length": 64,
    "time": 96571.168742,
    "actor_loss": -56.54509735107422,
    "critic_loss": 9.87498950958252,
    "ent_coef": 0.06457570195198059,
    "learning_rate": 0.001
  },
  {
    "episode": 6259,
    "reward": 88.218894,
    "length": 68,
    "time": 96585.696163,
    "actor_loss": -67.02313995361328,
    "critic_loss": 67.95829772949219,
    "ent_coef": 0.06254102289676666,
    "learning_rate": 0.001
  },
  {
    "episode": 6260,
    "reward": 89.732073,
    "length": 64,
    "time": 96597.922384,
    "actor_loss": -59.17849349975586,
    "critic_loss": 7.761824607849121,
    "ent_coef": 0.060296155512332916,
    "learning_rate": 0.001
  },
  {
    "episode": 6261,
    "reward": 88.753659,
    "length": 67,
    "time": 96611.219254,
    "actor_loss": -60.423301696777344,
    "critic_loss": 15.42324161529541,
    "ent_coef": 0.06062936782836914,
    "learning_rate": 0.001
  },
  {
    "episode": 6262,
    "reward": 88.796059,
    "length": 65,
    "time": 96622.990162,
    "actor_loss": -57.96186065673828,
    "critic_loss": 98.94613647460938,
    "ent_coef": 0.06324170529842377,
    "learning_rate": 0.001
  },
  {
    "episode": 6263,
    "reward": 89.920518,
    "length": 63,
    "time": 96634.711799,
    "actor_loss": -60.94927978515625,
    "critic_loss": 28.33208465576172,
    "ent_coef": 0.06559262424707413,
    "learning_rate": 0.001
  },
  {
    "episode": 6264,
    "reward": 91.283567,
    "length": 61,
    "time": 96647.509382,
    "actor_loss": -63.79877471923828,
    "critic_loss": 64.25325012207031,
    "ent_coef": 0.06549789011478424,
    "learning_rate": 0.001
  },
  {
    "episode": 6265,
    "reward": 91.670039,
    "length": 62,
    "time": 96658.809838,
    "actor_loss": -61.522239685058594,
    "critic_loss": 10.136335372924805,
    "ent_coef": 0.06718194484710693,
    "learning_rate": 0.001
  },
  {
    "episode": 6266,
    "reward": 87.522917,
    "length": 67,
    "time": 96672.658852,
    "actor_loss": -63.100669860839844,
    "critic_loss": 120.61129760742188,
    "ent_coef": 0.06786930561065674,
    "learning_rate": 0.001
  },
  {
    "episode": 6267,
    "reward": 88.550762,
    "length": 65,
    "time": 96685.935565,
    "actor_loss": -59.34786605834961,
    "critic_loss": 127.6834487915039,
    "ent_coef": 0.06969011574983597,
    "learning_rate": 0.001
  },
  {
    "episode": 6268,
    "reward": 88.524053,
    "length": 66,
    "time": 96697.912595,
    "actor_loss": -61.29309844970703,
    "critic_loss": 21.26681900024414,
    "ent_coef": 0.06726620346307755,
    "learning_rate": 0.001
  },
  {
    "episode": 6269,
    "reward": 88.07832,
    "length": 68,
    "time": 96710.565454,
    "actor_loss": -53.5525016784668,
    "critic_loss": 17.668479919433594,
    "ent_coef": 0.06344674527645111,
    "learning_rate": 0.001
  },
  {
    "episode": 6270,
    "reward": 90.312034,
    "length": 63,
    "time": 96724.533522,
    "actor_loss": -61.693687438964844,
    "critic_loss": 179.91732788085938,
    "ent_coef": 0.06409596651792526,
    "learning_rate": 0.001
  },
  {
    "episode": 6271,
    "reward": 89.1031,
    "length": 69,
    "time": 96739.042132,
    "actor_loss": -57.208396911621094,
    "critic_loss": 38.8642578125,
    "ent_coef": 0.07037504762411118,
    "learning_rate": 0.001
  },
  {
    "episode": 6272,
    "reward": 83.671415,
    "length": 74,
    "time": 96752.935997,
    "actor_loss": -65.29247283935547,
    "critic_loss": 7.842020034790039,
    "ent_coef": 0.0717998743057251,
    "learning_rate": 0.001
  },
  {
    "episode": 6273,
    "reward": 86.205293,
    "length": 76,
    "time": 96768.353221,
    "actor_loss": -66.14183044433594,
    "critic_loss": 12.993607521057129,
    "ent_coef": 0.07273717224597931,
    "learning_rate": 0.001
  },
  {
    "episode": 6274,
    "reward": 85.143641,
    "length": 86,
    "time": 96783.53725,
    "actor_loss": -59.885108947753906,
    "critic_loss": 11.255863189697266,
    "ent_coef": 0.07513263076543808,
    "learning_rate": 0.001
  },
  {
    "episode": 6275,
    "reward": 90.533669,
    "length": 62,
    "time": 96797.638443,
    "actor_loss": -64.1092300415039,
    "critic_loss": 11.675493240356445,
    "ent_coef": 0.07422540336847305,
    "learning_rate": 0.001
  },
  {
    "episode": 6276,
    "reward": 80.15624,
    "length": 76,
    "time": 96812.318473,
    "actor_loss": -61.7307014465332,
    "critic_loss": 72.93504333496094,
    "ent_coef": 0.07273631542921066,
    "learning_rate": 0.001
  },
  {
    "episode": 6277,
    "reward": 89.243298,
    "length": 70,
    "time": 96826.191231,
    "actor_loss": -60.70986557006836,
    "critic_loss": 28.18701171875,
    "ent_coef": 0.0744250938296318,
    "learning_rate": 0.001
  },
  {
    "episode": 6278,
    "reward": 90.387029,
    "length": 62,
    "time": 96838.934869,
    "actor_loss": -59.71856689453125,
    "critic_loss": 6.175354480743408,
    "ent_coef": 0.0768454372882843,
    "learning_rate": 0.001
  },
  {
    "episode": 6279,
    "reward": 89.038767,
    "length": 68,
    "time": 96853.99142,
    "actor_loss": -58.018951416015625,
    "critic_loss": 288.29974365234375,
    "ent_coef": 0.07449156045913696,
    "learning_rate": 0.001
  },
  {
    "episode": 6280,
    "reward": 89.414124,
    "length": 63,
    "time": 96865.390908,
    "actor_loss": -59.118743896484375,
    "critic_loss": 11.88749885559082,
    "ent_coef": 0.07429905980825424,
    "learning_rate": 0.001
  },
  {
    "episode": 6281,
    "reward": 86.676953,
    "length": 69,
    "time": 96878.47317,
    "actor_loss": -59.66995620727539,
    "critic_loss": 11.247669219970703,
    "ent_coef": 0.07357248663902283,
    "learning_rate": 0.001
  },
  {
    "episode": 6282,
    "reward": 88.412566,
    "length": 67,
    "time": 96891.483098,
    "actor_loss": -66.9334487915039,
    "critic_loss": 5.666349411010742,
    "ent_coef": 0.07081049680709839,
    "learning_rate": 0.001
  },
  {
    "episode": 6283,
    "reward": 89.489255,
    "length": 63,
    "time": 96903.326266,
    "actor_loss": -61.71967315673828,
    "critic_loss": 48.526546478271484,
    "ent_coef": 0.06964028626680374,
    "learning_rate": 0.001
  },
  {
    "episode": 6284,
    "reward": 84.631737,
    "length": 75,
    "time": 96917.552263,
    "actor_loss": -58.95268249511719,
    "critic_loss": 16.486648559570312,
    "ent_coef": 0.06894970685243607,
    "learning_rate": 0.001
  },
  {
    "episode": 6285,
    "reward": 87.740194,
    "length": 67,
    "time": 96929.456414,
    "actor_loss": -61.104881286621094,
    "critic_loss": 8.913190841674805,
    "ent_coef": 0.07079312205314636,
    "learning_rate": 0.001
  },
  {
    "episode": 6286,
    "reward": 90.319383,
    "length": 64,
    "time": 96942.882916,
    "actor_loss": -58.336082458496094,
    "critic_loss": 8.387808799743652,
    "ent_coef": 0.07173231244087219,
    "learning_rate": 0.001
  },
  {
    "episode": 6287,
    "reward": 91.539379,
    "length": 61,
    "time": 96954.27108,
    "actor_loss": -63.09965896606445,
    "critic_loss": 28.156085968017578,
    "ent_coef": 0.07238736003637314,
    "learning_rate": 0.001
  },
  {
    "episode": 6288,
    "reward": 89.249731,
    "length": 66,
    "time": 96966.406269,
    "actor_loss": -62.65306091308594,
    "critic_loss": 35.99095916748047,
    "ent_coef": 0.07213671505451202,
    "learning_rate": 0.001
  },
  {
    "episode": 6289,
    "reward": 89.575236,
    "length": 65,
    "time": 96982.520561,
    "actor_loss": -67.99860382080078,
    "critic_loss": 10.506390571594238,
    "ent_coef": 0.06954007595777512,
    "learning_rate": 0.001
  },
  {
    "episode": 6290,
    "reward": 90.043354,
    "length": 63,
    "time": 96996.132068,
    "actor_loss": -59.58610534667969,
    "critic_loss": 21.978042602539062,
    "ent_coef": 0.06740739941596985,
    "learning_rate": 0.001
  },
  {
    "episode": 6291,
    "reward": 88.313238,
    "length": 64,
    "time": 97009.733498,
    "actor_loss": -62.5360221862793,
    "critic_loss": 37.247222900390625,
    "ent_coef": 0.06823697686195374,
    "learning_rate": 0.001
  },
  {
    "episode": 6292,
    "reward": 79.443129,
    "length": 82,
    "time": 97023.678803,
    "actor_loss": -57.34239196777344,
    "critic_loss": 28.144481658935547,
    "ent_coef": 0.06218128651380539,
    "learning_rate": 0.001
  },
  {
    "episode": 6293,
    "reward": 88.229122,
    "length": 69,
    "time": 97037.251692,
    "actor_loss": -67.35314178466797,
    "critic_loss": 145.3538818359375,
    "ent_coef": 0.06307533383369446,
    "learning_rate": 0.001
  },
  {
    "episode": 6294,
    "reward": 91.418711,
    "length": 62,
    "time": 97049.39469,
    "actor_loss": -62.69033432006836,
    "critic_loss": 9.865972518920898,
    "ent_coef": 0.06437431275844574,
    "learning_rate": 0.001
  },
  {
    "episode": 6295,
    "reward": 90.578523,
    "length": 62,
    "time": 97061.720014,
    "actor_loss": -65.45177459716797,
    "critic_loss": 77.23863220214844,
    "ent_coef": 0.06668231636285782,
    "learning_rate": 0.001
  },
  {
    "episode": 6296,
    "reward": 90.492126,
    "length": 64,
    "time": 97073.417065,
    "actor_loss": -62.243629455566406,
    "critic_loss": 13.07366943359375,
    "ent_coef": 0.07062791287899017,
    "learning_rate": 0.001
  },
  {
    "episode": 6297,
    "reward": 88.349216,
    "length": 67,
    "time": 97086.438635,
    "actor_loss": -59.32630157470703,
    "critic_loss": 9.13637924194336,
    "ent_coef": 0.07098792493343353,
    "learning_rate": 0.001
  },
  {
    "episode": 6298,
    "reward": 91.257298,
    "length": 60,
    "time": 97097.486976,
    "actor_loss": -62.94892883300781,
    "critic_loss": 8.606342315673828,
    "ent_coef": 0.07489848136901855,
    "learning_rate": 0.001
  },
  {
    "episode": 6299,
    "reward": 89.951984,
    "length": 64,
    "time": 97109.303571,
    "actor_loss": -63.23328399658203,
    "critic_loss": 11.339651107788086,
    "ent_coef": 0.07679572701454163,
    "learning_rate": 0.001
  },
  {
    "episode": 6300,
    "reward": 91.026758,
    "length": 61,
    "time": 97123.450431,
    "actor_loss": -62.93224334716797,
    "critic_loss": 18.523311614990234,
    "ent_coef": 0.07713107764720917,
    "learning_rate": 0.001
  },
  {
    "episode": 6301,
    "reward": 82.7135,
    "length": 65,
    "time": 97137.713974,
    "actor_loss": -65.58174896240234,
    "critic_loss": 35.58726501464844,
    "ent_coef": 0.07972702383995056,
    "learning_rate": 0.001
  },
  {
    "episode": 6302,
    "reward": 86.089695,
    "length": 71,
    "time": 97151.03819,
    "actor_loss": -63.36449432373047,
    "critic_loss": 4.860077857971191,
    "ent_coef": 0.07625453174114227,
    "learning_rate": 0.001
  },
  {
    "episode": 6303,
    "reward": 90.419135,
    "length": 62,
    "time": 97165.366784,
    "actor_loss": -56.79261779785156,
    "critic_loss": 36.17295837402344,
    "ent_coef": 0.0773593932390213,
    "learning_rate": 0.001
  },
  {
    "episode": 6304,
    "reward": 90.732405,
    "length": 62,
    "time": 97177.933719,
    "actor_loss": -61.510475158691406,
    "critic_loss": 11.981610298156738,
    "ent_coef": 0.0813445970416069,
    "learning_rate": 0.001
  },
  {
    "episode": 6305,
    "reward": 89.838336,
    "length": 65,
    "time": 97189.737602,
    "actor_loss": -68.24697875976562,
    "critic_loss": 4.557652950286865,
    "ent_coef": 0.08444187790155411,
    "learning_rate": 0.001
  },
  {
    "episode": 6306,
    "reward": 90.713287,
    "length": 63,
    "time": 97202.894385,
    "actor_loss": -58.869468688964844,
    "critic_loss": 55.452674865722656,
    "ent_coef": 0.08075718581676483,
    "learning_rate": 0.001
  },
  {
    "episode": 6307,
    "reward": 87.204377,
    "length": 70,
    "time": 97215.173295,
    "actor_loss": -64.55912780761719,
    "critic_loss": 9.463199615478516,
    "ent_coef": 0.07637269794940948,
    "learning_rate": 0.001
  },
  {
    "episode": 6308,
    "reward": 90.896305,
    "length": 62,
    "time": 97227.281636,
    "actor_loss": -61.65784454345703,
    "critic_loss": 14.386570930480957,
    "ent_coef": 0.07405314594507217,
    "learning_rate": 0.001
  },
  {
    "episode": 6309,
    "reward": 89.700347,
    "length": 65,
    "time": 97238.867919,
    "actor_loss": -68.13833618164062,
    "critic_loss": 18.105575561523438,
    "ent_coef": 0.0723014622926712,
    "learning_rate": 0.001
  },
  {
    "episode": 6310,
    "reward": 91.763665,
    "length": 60,
    "time": 97249.896077,
    "actor_loss": -55.76067352294922,
    "critic_loss": 67.68034362792969,
    "ent_coef": 0.07452230155467987,
    "learning_rate": 0.001
  },
  {
    "episode": 6311,
    "reward": 90.32855,
    "length": 64,
    "time": 97264.791207,
    "actor_loss": -58.62171173095703,
    "critic_loss": 33.731712341308594,
    "ent_coef": 0.07239007204771042,
    "learning_rate": 0.001
  },
  {
    "episode": 6312,
    "reward": 89.265474,
    "length": 65,
    "time": 97276.537637,
    "actor_loss": -68.1804428100586,
    "critic_loss": 102.85047149658203,
    "ent_coef": 0.07165107131004333,
    "learning_rate": 0.001
  },
  {
    "episode": 6313,
    "reward": 79.067217,
    "length": 80,
    "time": 97290.595054,
    "actor_loss": -62.9567756652832,
    "critic_loss": 5.034152030944824,
    "ent_coef": 0.06654137372970581,
    "learning_rate": 0.001
  },
  {
    "episode": 6314,
    "reward": 90.862392,
    "length": 62,
    "time": 97303.442813,
    "actor_loss": -59.21723556518555,
    "critic_loss": 31.717945098876953,
    "ent_coef": 0.0662289708852768,
    "learning_rate": 0.001
  },
  {
    "episode": 6315,
    "reward": 91.807138,
    "length": 60,
    "time": 97314.827745,
    "actor_loss": -61.97063446044922,
    "critic_loss": 7.731709003448486,
    "ent_coef": 0.06650670617818832,
    "learning_rate": 0.001
  },
  {
    "episode": 6316,
    "reward": 92.764428,
    "length": 58,
    "time": 97330.296022,
    "actor_loss": -57.849422454833984,
    "critic_loss": 24.70284080505371,
    "ent_coef": 0.0678146481513977,
    "learning_rate": 0.001
  },
  {
    "episode": 6317,
    "reward": 79.758269,
    "length": 80,
    "time": 97344.789807,
    "actor_loss": -61.85038375854492,
    "critic_loss": 12.142186164855957,
    "ent_coef": 0.06692451238632202,
    "learning_rate": 0.001
  },
  {
    "episode": 6318,
    "reward": 93.383829,
    "length": 58,
    "time": 97357.856906,
    "actor_loss": -60.98419189453125,
    "critic_loss": 67.2207260131836,
    "ent_coef": 0.07065226882696152,
    "learning_rate": 0.001
  },
  {
    "episode": 6319,
    "reward": 90.957741,
    "length": 61,
    "time": 97372.392168,
    "actor_loss": -65.11288452148438,
    "critic_loss": 26.450927734375,
    "ent_coef": 0.07687543332576752,
    "learning_rate": 0.001
  },
  {
    "episode": 6320,
    "reward": 91.553354,
    "length": 60,
    "time": 97384.039505,
    "actor_loss": -58.726356506347656,
    "critic_loss": 46.91960144042969,
    "ent_coef": 0.08245208114385605,
    "learning_rate": 0.001
  },
  {
    "episode": 6321,
    "reward": 90.549392,
    "length": 61,
    "time": 97398.164015,
    "actor_loss": -63.22703552246094,
    "critic_loss": 28.71880340576172,
    "ent_coef": 0.07905834913253784,
    "learning_rate": 0.001
  },
  {
    "episode": 6322,
    "reward": 90.841506,
    "length": 62,
    "time": 97411.662255,
    "actor_loss": -54.441619873046875,
    "critic_loss": 6.498128890991211,
    "ent_coef": 0.07720489054918289,
    "learning_rate": 0.001
  },
  {
    "episode": 6323,
    "reward": 91.291414,
    "length": 62,
    "time": 97426.774853,
    "actor_loss": -57.843788146972656,
    "critic_loss": 50.601295471191406,
    "ent_coef": 0.07464899122714996,
    "learning_rate": 0.001
  },
  {
    "episode": 6324,
    "reward": 90.632045,
    "length": 62,
    "time": 97439.60245,
    "actor_loss": -60.1287841796875,
    "critic_loss": 37.04522705078125,
    "ent_coef": 0.07462507486343384,
    "learning_rate": 0.001
  },
  {
    "episode": 6325,
    "reward": 88.967432,
    "length": 72,
    "time": 97454.666141,
    "actor_loss": -66.80555725097656,
    "critic_loss": 14.025315284729004,
    "ent_coef": 0.0760558694601059,
    "learning_rate": 0.001
  },
  {
    "episode": 6326,
    "reward": 89.074673,
    "length": 62,
    "time": 97468.375849,
    "actor_loss": -64.63690185546875,
    "critic_loss": 11.02335262298584,
    "ent_coef": 0.07366558164358139,
    "learning_rate": 0.001
  },
  {
    "episode": 6327,
    "reward": 91.77808,
    "length": 61,
    "time": 97480.89899,
    "actor_loss": -62.10633087158203,
    "critic_loss": 37.938697814941406,
    "ent_coef": 0.07506904751062393,
    "learning_rate": 0.001
  },
  {
    "episode": 6328,
    "reward": 91.077166,
    "length": 62,
    "time": 97494.004462,
    "actor_loss": -60.923606872558594,
    "critic_loss": 16.085790634155273,
    "ent_coef": 0.07775242626667023,
    "learning_rate": 0.001
  },
  {
    "episode": 6329,
    "reward": 70.539657,
    "length": 104,
    "time": 97513.108527,
    "actor_loss": -60.93501281738281,
    "critic_loss": 102.58103942871094,
    "ent_coef": 0.07428647577762604,
    "learning_rate": 0.001
  },
  {
    "episode": 6330,
    "reward": 89.419503,
    "length": 66,
    "time": 97526.496677,
    "actor_loss": -59.631900787353516,
    "critic_loss": 7.084567070007324,
    "ent_coef": 0.0740671157836914,
    "learning_rate": 0.001
  },
  {
    "episode": 6331,
    "reward": 92.465343,
    "length": 58,
    "time": 97539.088755,
    "actor_loss": -60.92674255371094,
    "critic_loss": 4.097367286682129,
    "ent_coef": 0.07639752328395844,
    "learning_rate": 0.001
  },
  {
    "episode": 6332,
    "reward": 90.655995,
    "length": 62,
    "time": 97552.808628,
    "actor_loss": -64.82785034179688,
    "critic_loss": 36.22380828857422,
    "ent_coef": 0.07647313177585602,
    "learning_rate": 0.001
  },
  {
    "episode": 6333,
    "reward": 91.004702,
    "length": 61,
    "time": 97565.853655,
    "actor_loss": -63.371009826660156,
    "critic_loss": 58.967308044433594,
    "ent_coef": 0.07280895113945007,
    "learning_rate": 0.001
  },
  {
    "episode": 6334,
    "reward": 88.213042,
    "length": 65,
    "time": 97579.395749,
    "actor_loss": -59.367652893066406,
    "critic_loss": 12.508069038391113,
    "ent_coef": 0.06796339899301529,
    "learning_rate": 0.001
  },
  {
    "episode": 6335,
    "reward": 89.501773,
    "length": 64,
    "time": 97592.414621,
    "actor_loss": -60.27625274658203,
    "critic_loss": 6.343733787536621,
    "ent_coef": 0.06419623643159866,
    "learning_rate": 0.001
  },
  {
    "episode": 6336,
    "reward": 88.719395,
    "length": 66,
    "time": 97607.432365,
    "actor_loss": -62.73783874511719,
    "critic_loss": 32.619537353515625,
    "ent_coef": 0.06231812387704849,
    "learning_rate": 0.001
  },
  {
    "episode": 6337,
    "reward": 92.254551,
    "length": 59,
    "time": 97619.431238,
    "actor_loss": -61.35491943359375,
    "critic_loss": 19.08944320678711,
    "ent_coef": 0.06286854296922684,
    "learning_rate": 0.001
  },
  {
    "episode": 6338,
    "reward": 91.106785,
    "length": 63,
    "time": 97633.002857,
    "actor_loss": -64.41683959960938,
    "critic_loss": 6.689729690551758,
    "ent_coef": 0.062435392290353775,
    "learning_rate": 0.001
  },
  {
    "episode": 6339,
    "reward": 91.668555,
    "length": 60,
    "time": 97645.312444,
    "actor_loss": -58.30207061767578,
    "critic_loss": 13.393951416015625,
    "ent_coef": 0.06359465420246124,
    "learning_rate": 0.001
  },
  {
    "episode": 6340,
    "reward": 91.3458,
    "length": 63,
    "time": 97657.647511,
    "actor_loss": -59.359840393066406,
    "critic_loss": 4.149021148681641,
    "ent_coef": 0.06423185765743256,
    "learning_rate": 0.001
  },
  {
    "episode": 6341,
    "reward": 89.73646,
    "length": 66,
    "time": 97670.675701,
    "actor_loss": -64.33399200439453,
    "critic_loss": 4.4652419090271,
    "ent_coef": 0.06664226949214935,
    "learning_rate": 0.001
  },
  {
    "episode": 6342,
    "reward": 90.457179,
    "length": 64,
    "time": 97683.08598,
    "actor_loss": -59.80804443359375,
    "critic_loss": 40.68943786621094,
    "ent_coef": 0.06635195016860962,
    "learning_rate": 0.001
  },
  {
    "episode": 6343,
    "reward": 89.395586,
    "length": 65,
    "time": 97695.620629,
    "actor_loss": -64.43748474121094,
    "critic_loss": 18.046466827392578,
    "ent_coef": 0.06424624472856522,
    "learning_rate": 0.001
  },
  {
    "episode": 6344,
    "reward": 91.354625,
    "length": 62,
    "time": 97708.286386,
    "actor_loss": -57.879188537597656,
    "critic_loss": 4.916175842285156,
    "ent_coef": 0.06450490653514862,
    "learning_rate": 0.001
  },
  {
    "episode": 6345,
    "reward": 89.856336,
    "length": 66,
    "time": 97723.891917,
    "actor_loss": -58.359825134277344,
    "critic_loss": 35.07701110839844,
    "ent_coef": 0.06395182758569717,
    "learning_rate": 0.001
  },
  {
    "episode": 6346,
    "reward": 90.197558,
    "length": 64,
    "time": 97736.480016,
    "actor_loss": -63.42204284667969,
    "critic_loss": 9.943277359008789,
    "ent_coef": 0.059652477502822876,
    "learning_rate": 0.001
  },
  {
    "episode": 6347,
    "reward": 89.853711,
    "length": 63,
    "time": 97749.147593,
    "actor_loss": -65.74795532226562,
    "critic_loss": 14.08144760131836,
    "ent_coef": 0.058359622955322266,
    "learning_rate": 0.001
  },
  {
    "episode": 6348,
    "reward": 90.046369,
    "length": 64,
    "time": 97761.486129,
    "actor_loss": -63.208858489990234,
    "critic_loss": 5.624648094177246,
    "ent_coef": 0.059753984212875366,
    "learning_rate": 0.001
  },
  {
    "episode": 6349,
    "reward": 91.5294,
    "length": 60,
    "time": 97772.528655,
    "actor_loss": -59.70357894897461,
    "critic_loss": 14.59478759765625,
    "ent_coef": 0.0631367638707161,
    "learning_rate": 0.001
  },
  {
    "episode": 6350,
    "reward": 91.906065,
    "length": 60,
    "time": 97786.036856,
    "actor_loss": -61.34044647216797,
    "critic_loss": 44.35368347167969,
    "ent_coef": 0.06698695570230484,
    "learning_rate": 0.001
  },
  {
    "episode": 6351,
    "reward": 91.903343,
    "length": 60,
    "time": 97801.362921,
    "actor_loss": -56.077049255371094,
    "critic_loss": 11.096380233764648,
    "ent_coef": 0.0695454329252243,
    "learning_rate": 0.001
  },
  {
    "episode": 6352,
    "reward": 88.570946,
    "length": 66,
    "time": 97816.756914,
    "actor_loss": -62.91786193847656,
    "critic_loss": 20.85488510131836,
    "ent_coef": 0.06929586827754974,
    "learning_rate": 0.001
  },
  {
    "episode": 6353,
    "reward": 88.393064,
    "length": 68,
    "time": 97832.293583,
    "actor_loss": -57.634178161621094,
    "critic_loss": 7.793745040893555,
    "ent_coef": 0.06622225791215897,
    "learning_rate": 0.001
  },
  {
    "episode": 6354,
    "reward": 87.343757,
    "length": 69,
    "time": 97847.189494,
    "actor_loss": -60.40141677856445,
    "critic_loss": 13.533498764038086,
    "ent_coef": 0.06410013884305954,
    "learning_rate": 0.001
  },
  {
    "episode": 6355,
    "reward": 91.001933,
    "length": 62,
    "time": 97858.482107,
    "actor_loss": -60.830467224121094,
    "critic_loss": 21.461151123046875,
    "ent_coef": 0.0655975490808487,
    "learning_rate": 0.001
  },
  {
    "episode": 6356,
    "reward": 91.020851,
    "length": 63,
    "time": 97869.664856,
    "actor_loss": -66.59466552734375,
    "critic_loss": 43.93809509277344,
    "ent_coef": 0.06621856987476349,
    "learning_rate": 0.001
  },
  {
    "episode": 6357,
    "reward": 89.425907,
    "length": 68,
    "time": 97883.056178,
    "actor_loss": -61.663597106933594,
    "critic_loss": 34.16010284423828,
    "ent_coef": 0.06593504548072815,
    "learning_rate": 0.001
  },
  {
    "episode": 6358,
    "reward": 89.434676,
    "length": 66,
    "time": 97896.382172,
    "actor_loss": -63.22023391723633,
    "critic_loss": 7.487514972686768,
    "ent_coef": 0.06439749151468277,
    "learning_rate": 0.001
  },
  {
    "episode": 6359,
    "reward": 91.872354,
    "length": 60,
    "time": 97908.296694,
    "actor_loss": -60.15715789794922,
    "critic_loss": 12.397254943847656,
    "ent_coef": 0.06521283835172653,
    "learning_rate": 0.001
  },
  {
    "episode": 6360,
    "reward": 90.741899,
    "length": 64,
    "time": 97921.452652,
    "actor_loss": -61.56171417236328,
    "critic_loss": 25.433631896972656,
    "ent_coef": 0.06686728447675705,
    "learning_rate": 0.001
  },
  {
    "episode": 6361,
    "reward": 88.426935,
    "length": 68,
    "time": 97934.166547,
    "actor_loss": -58.403114318847656,
    "critic_loss": 248.90101623535156,
    "ent_coef": 0.06165844947099686,
    "learning_rate": 0.001
  },
  {
    "episode": 6362,
    "reward": 91.564852,
    "length": 62,
    "time": 97946.469275,
    "actor_loss": -54.0126953125,
    "critic_loss": 10.051794052124023,
    "ent_coef": 0.06295036524534225,
    "learning_rate": 0.001
  },
  {
    "episode": 6363,
    "reward": 92.027239,
    "length": 58,
    "time": 97959.783026,
    "actor_loss": -60.03266906738281,
    "critic_loss": 18.013999938964844,
    "ent_coef": 0.06654159724712372,
    "learning_rate": 0.001
  },
  {
    "episode": 6364,
    "reward": 90.743379,
    "length": 63,
    "time": 97972.005667,
    "actor_loss": -64.65293884277344,
    "critic_loss": 103.7136001586914,
    "ent_coef": 0.06724996864795685,
    "learning_rate": 0.001
  },
  {
    "episode": 6365,
    "reward": 90.693245,
    "length": 63,
    "time": 97983.378164,
    "actor_loss": -61.30602264404297,
    "critic_loss": 11.203401565551758,
    "ent_coef": 0.06679905205965042,
    "learning_rate": 0.001
  },
  {
    "episode": 6366,
    "reward": 90.300523,
    "length": 64,
    "time": 97996.778718,
    "actor_loss": -62.29145812988281,
    "critic_loss": 28.388216018676758,
    "ent_coef": 0.06793305277824402,
    "learning_rate": 0.001
  },
  {
    "episode": 6367,
    "reward": 90.450381,
    "length": 63,
    "time": 98009.736658,
    "actor_loss": -58.705318450927734,
    "critic_loss": 20.572673797607422,
    "ent_coef": 0.06986594945192337,
    "learning_rate": 0.001
  },
  {
    "episode": 6368,
    "reward": 92.265837,
    "length": 59,
    "time": 98022.487555,
    "actor_loss": -65.93404388427734,
    "critic_loss": 11.428215026855469,
    "ent_coef": 0.07120116055011749,
    "learning_rate": 0.001
  },
  {
    "episode": 6369,
    "reward": 90.531263,
    "length": 61,
    "time": 98033.413028,
    "actor_loss": -65.93824768066406,
    "critic_loss": 11.863996505737305,
    "ent_coef": 0.073605976998806,
    "learning_rate": 0.001
  },
  {
    "episode": 6370,
    "reward": 90.206285,
    "length": 64,
    "time": 98044.834972,
    "actor_loss": -63.643707275390625,
    "critic_loss": 22.571149826049805,
    "ent_coef": 0.07190565019845963,
    "learning_rate": 0.001
  },
  {
    "episode": 6371,
    "reward": 90.5246,
    "length": 63,
    "time": 98056.373567,
    "actor_loss": -62.1214599609375,
    "critic_loss": 6.842932224273682,
    "ent_coef": 0.07486320286989212,
    "learning_rate": 0.001
  },
  {
    "episode": 6372,
    "reward": 88.937159,
    "length": 66,
    "time": 98068.833204,
    "actor_loss": -60.82450485229492,
    "critic_loss": 8.192447662353516,
    "ent_coef": 0.0740356296300888,
    "learning_rate": 0.001
  },
  {
    "episode": 6373,
    "reward": 90.27975,
    "length": 63,
    "time": 98081.032075,
    "actor_loss": -60.95588684082031,
    "critic_loss": 12.354896545410156,
    "ent_coef": 0.0710999146103859,
    "learning_rate": 0.001
  },
  {
    "episode": 6374,
    "reward": 87.266468,
    "length": 70,
    "time": 98093.395844,
    "actor_loss": -62.39417266845703,
    "critic_loss": 12.132598876953125,
    "ent_coef": 0.06945767253637314,
    "learning_rate": 0.001
  },
  {
    "episode": 6375,
    "reward": 88.753797,
    "length": 66,
    "time": 98105.070621,
    "actor_loss": -64.98583984375,
    "critic_loss": 8.062105178833008,
    "ent_coef": 0.06550618261098862,
    "learning_rate": 0.001
  },
  {
    "episode": 6376,
    "reward": 86.574866,
    "length": 71,
    "time": 98120.377133,
    "actor_loss": -59.51921844482422,
    "critic_loss": 15.674053192138672,
    "ent_coef": 0.06432384997606277,
    "learning_rate": 0.001
  },
  {
    "episode": 6377,
    "reward": 86.57819,
    "length": 70,
    "time": 98132.26494,
    "actor_loss": -58.22651290893555,
    "critic_loss": 22.06832504272461,
    "ent_coef": 0.06138506904244423,
    "learning_rate": 0.001
  },
  {
    "episode": 6378,
    "reward": 90.134529,
    "length": 63,
    "time": 98146.446162,
    "actor_loss": -60.495018005371094,
    "critic_loss": 20.139400482177734,
    "ent_coef": 0.060095060616731644,
    "learning_rate": 0.001
  },
  {
    "episode": 6379,
    "reward": 89.246868,
    "length": 65,
    "time": 98161.660476,
    "actor_loss": -65.15125274658203,
    "critic_loss": 22.396141052246094,
    "ent_coef": 0.061166588217020035,
    "learning_rate": 0.001
  },
  {
    "episode": 6380,
    "reward": 90.348984,
    "length": 64,
    "time": 98176.503947,
    "actor_loss": -69.87010192871094,
    "critic_loss": 155.67941284179688,
    "ent_coef": 0.061662934720516205,
    "learning_rate": 0.001
  },
  {
    "episode": 6381,
    "reward": 85.880224,
    "length": 74,
    "time": 98191.283496,
    "actor_loss": -61.06915283203125,
    "critic_loss": 18.328857421875,
    "ent_coef": 0.06290925294160843,
    "learning_rate": 0.001
  },
  {
    "episode": 6382,
    "reward": 86.690755,
    "length": 71,
    "time": 98207.404241,
    "actor_loss": -65.4349136352539,
    "critic_loss": 7.988490581512451,
    "ent_coef": 0.06055048108100891,
    "learning_rate": 0.001
  },
  {
    "episode": 6383,
    "reward": 88.204024,
    "length": 67,
    "time": 98218.947916,
    "actor_loss": -57.30154037475586,
    "critic_loss": 11.245401382446289,
    "ent_coef": 0.05787675827741623,
    "learning_rate": 0.001
  },
  {
    "episode": 6384,
    "reward": 89.525091,
    "length": 66,
    "time": 98232.240132,
    "actor_loss": -68.47845458984375,
    "critic_loss": 27.50351333618164,
    "ent_coef": 0.05627956613898277,
    "learning_rate": 0.001
  },
  {
    "episode": 6385,
    "reward": 87.673081,
    "length": 68,
    "time": 98245.944422,
    "actor_loss": -60.399818420410156,
    "critic_loss": 76.4066162109375,
    "ent_coef": 0.05443133786320686,
    "learning_rate": 0.001
  },
  {
    "episode": 6386,
    "reward": 86.497514,
    "length": 72,
    "time": 98258.456689,
    "actor_loss": -59.19623565673828,
    "critic_loss": 11.909635543823242,
    "ent_coef": 0.05340147763490677,
    "learning_rate": 0.001
  },
  {
    "episode": 6387,
    "reward": 87.705138,
    "length": 68,
    "time": 98271.62829,
    "actor_loss": -57.82583236694336,
    "critic_loss": 327.9302062988281,
    "ent_coef": 0.052197299897670746,
    "learning_rate": 0.001
  },
  {
    "episode": 6388,
    "reward": 88.252891,
    "length": 68,
    "time": 98285.229144,
    "actor_loss": -57.92168045043945,
    "critic_loss": 15.152297019958496,
    "ent_coef": 0.05304840952157974,
    "learning_rate": 0.001
  },
  {
    "episode": 6389,
    "reward": 90.546323,
    "length": 63,
    "time": 98296.951589,
    "actor_loss": -67.24647521972656,
    "critic_loss": 60.81245422363281,
    "ent_coef": 0.05314116179943085,
    "learning_rate": 0.001
  },
  {
    "episode": 6390,
    "reward": 85.056651,
    "length": 89,
    "time": 98314.926198,
    "actor_loss": -62.213714599609375,
    "critic_loss": 26.522075653076172,
    "ent_coef": 0.05692649632692337,
    "learning_rate": 0.001
  },
  {
    "episode": 6391,
    "reward": 88.607879,
    "length": 65,
    "time": 98329.905893,
    "actor_loss": -61.67644500732422,
    "critic_loss": 21.809799194335938,
    "ent_coef": 0.05847565829753876,
    "learning_rate": 0.001
  },
  {
    "episode": 6392,
    "reward": 91.07981,
    "length": 62,
    "time": 98344.384814,
    "actor_loss": -58.638328552246094,
    "critic_loss": 26.6324462890625,
    "ent_coef": 0.059983450919389725,
    "learning_rate": 0.001
  },
  {
    "episode": 6393,
    "reward": 90.781556,
    "length": 63,
    "time": 98356.496602,
    "actor_loss": -63.763694763183594,
    "critic_loss": 14.862714767456055,
    "ent_coef": 0.06263105571269989,
    "learning_rate": 0.001
  },
  {
    "episode": 6394,
    "reward": 89.155317,
    "length": 66,
    "time": 98368.924966,
    "actor_loss": -57.507137298583984,
    "critic_loss": 38.936370849609375,
    "ent_coef": 0.06349359452724457,
    "learning_rate": 0.001
  },
  {
    "episode": 6395,
    "reward": 90.044835,
    "length": 65,
    "time": 98381.362905,
    "actor_loss": -62.52165985107422,
    "critic_loss": 7.242076396942139,
    "ent_coef": 0.06521781533956528,
    "learning_rate": 0.001
  },
  {
    "episode": 6396,
    "reward": 90.107237,
    "length": 63,
    "time": 98394.214913,
    "actor_loss": -60.69093322753906,
    "critic_loss": 5.862382888793945,
    "ent_coef": 0.06540556252002716,
    "learning_rate": 0.001
  },
  {
    "episode": 6397,
    "reward": 87.491889,
    "length": 75,
    "time": 98408.886698,
    "actor_loss": -60.16581726074219,
    "critic_loss": 8.989330291748047,
    "ent_coef": 0.06732062250375748,
    "learning_rate": 0.001
  },
  {
    "episode": 6398,
    "reward": 88.248142,
    "length": 66,
    "time": 98422.977562,
    "actor_loss": -57.79981994628906,
    "critic_loss": 13.369162559509277,
    "ent_coef": 0.06939004361629486,
    "learning_rate": 0.001
  },
  {
    "episode": 6399,
    "reward": 84.80202,
    "length": 73,
    "time": 98436.995971,
    "actor_loss": -62.015281677246094,
    "critic_loss": 39.07207489013672,
    "ent_coef": 0.06755011528730392,
    "learning_rate": 0.001
  },
  {
    "episode": 6400,
    "reward": 87.620952,
    "length": 67,
    "time": 98452.898389,
    "actor_loss": -62.55763626098633,
    "critic_loss": 7.9939727783203125,
    "ent_coef": 0.06410624831914902,
    "learning_rate": 0.001
  },
  {
    "episode": 6401,
    "reward": 91.044498,
    "length": 63,
    "time": 98466.822746,
    "actor_loss": -64.928955078125,
    "critic_loss": 7.1309661865234375,
    "ent_coef": 0.06297620385885239,
    "learning_rate": 0.001
  },
  {
    "episode": 6402,
    "reward": 89.928006,
    "length": 63,
    "time": 98478.959423,
    "actor_loss": -53.06202697753906,
    "critic_loss": 29.729228973388672,
    "ent_coef": 0.06359738111495972,
    "learning_rate": 0.001
  },
  {
    "episode": 6403,
    "reward": 89.443491,
    "length": 64,
    "time": 98493.084153,
    "actor_loss": -68.76310729980469,
    "critic_loss": 9.800423622131348,
    "ent_coef": 0.06365038454532623,
    "learning_rate": 0.001
  },
  {
    "episode": 6404,
    "reward": 91.18175,
    "length": 62,
    "time": 98506.333979,
    "actor_loss": -61.71561050415039,
    "critic_loss": 4.241606712341309,
    "ent_coef": 0.0635804757475853,
    "learning_rate": 0.001
  },
  {
    "episode": 6405,
    "reward": 90.045085,
    "length": 63,
    "time": 98518.149022,
    "actor_loss": -66.82781982421875,
    "critic_loss": 40.38289260864258,
    "ent_coef": 0.0604904405772686,
    "learning_rate": 0.001
  },
  {
    "episode": 6406,
    "reward": 90.294335,
    "length": 63,
    "time": 98530.257231,
    "actor_loss": -63.243019104003906,
    "critic_loss": 8.087119102478027,
    "ent_coef": 0.058171242475509644,
    "learning_rate": 0.001
  },
  {
    "episode": 6407,
    "reward": 90.478747,
    "length": 63,
    "time": 98542.560289,
    "actor_loss": -60.408058166503906,
    "critic_loss": 29.164875030517578,
    "ent_coef": 0.05705917999148369,
    "learning_rate": 0.001
  },
  {
    "episode": 6408,
    "reward": 91.414803,
    "length": 61,
    "time": 98553.581426,
    "actor_loss": -63.95536804199219,
    "critic_loss": 46.256134033203125,
    "ent_coef": 0.05824223905801773,
    "learning_rate": 0.001
  },
  {
    "episode": 6409,
    "reward": 84.505124,
    "length": 77,
    "time": 98567.498454,
    "actor_loss": -62.88164520263672,
    "critic_loss": 4.630943298339844,
    "ent_coef": 0.053550854325294495,
    "learning_rate": 0.001
  },
  {
    "episode": 6410,
    "reward": 87.766318,
    "length": 70,
    "time": 98587.057821,
    "actor_loss": -55.66342544555664,
    "critic_loss": 6.111137390136719,
    "ent_coef": 0.0509590245783329,
    "learning_rate": 0.001
  },
  {
    "episode": 6411,
    "reward": 85.752437,
    "length": 82,
    "time": 98603.307052,
    "actor_loss": -60.210548400878906,
    "critic_loss": 23.947593688964844,
    "ent_coef": 0.05367060750722885,
    "learning_rate": 0.001
  },
  {
    "episode": 6412,
    "reward": 89.678228,
    "length": 65,
    "time": 98617.709797,
    "actor_loss": -56.79004669189453,
    "critic_loss": 12.41502571105957,
    "ent_coef": 0.05376508831977844,
    "learning_rate": 0.001
  },
  {
    "episode": 6413,
    "reward": 90.650175,
    "length": 63,
    "time": 98629.295821,
    "actor_loss": -61.67295837402344,
    "critic_loss": 55.86482238769531,
    "ent_coef": 0.055372972041368484,
    "learning_rate": 0.001
  },
  {
    "episode": 6414,
    "reward": 88.704736,
    "length": 67,
    "time": 98641.391598,
    "actor_loss": -64.34101104736328,
    "critic_loss": 15.830987930297852,
    "ent_coef": 0.05418311804533005,
    "learning_rate": 0.001
  },
  {
    "episode": 6415,
    "reward": 90.148607,
    "length": 63,
    "time": 98652.994458,
    "actor_loss": -62.76049041748047,
    "critic_loss": 3.9176273345947266,
    "ent_coef": 0.05860435590147972,
    "learning_rate": 0.001
  },
  {
    "episode": 6416,
    "reward": 84.904242,
    "length": 73,
    "time": 98666.70816,
    "actor_loss": -60.712928771972656,
    "critic_loss": 10.74186897277832,
    "ent_coef": 0.06321586668491364,
    "learning_rate": 0.001
  },
  {
    "episode": 6417,
    "reward": 89.76692,
    "length": 66,
    "time": 98678.196674,
    "actor_loss": -59.117942810058594,
    "critic_loss": 10.438907623291016,
    "ent_coef": 0.06176766753196716,
    "learning_rate": 0.001
  },
  {
    "episode": 6418,
    "reward": 90.524595,
    "length": 63,
    "time": 98692.337975,
    "actor_loss": -61.34964370727539,
    "critic_loss": 10.452130317687988,
    "ent_coef": 0.06093638762831688,
    "learning_rate": 0.001
  },
  {
    "episode": 6419,
    "reward": 91.523012,
    "length": 60,
    "time": 98704.183724,
    "actor_loss": -67.83287048339844,
    "critic_loss": 51.5131721496582,
    "ent_coef": 0.06214725598692894,
    "learning_rate": 0.001
  },
  {
    "episode": 6420,
    "reward": 90.829715,
    "length": 62,
    "time": 98716.065065,
    "actor_loss": -66.47976684570312,
    "critic_loss": 17.234508514404297,
    "ent_coef": 0.06311558187007904,
    "learning_rate": 0.001
  },
  {
    "episode": 6421,
    "reward": 86.242739,
    "length": 70,
    "time": 98729.706555,
    "actor_loss": -66.14581298828125,
    "critic_loss": 33.83414077758789,
    "ent_coef": 0.06206950172781944,
    "learning_rate": 0.001
  },
  {
    "episode": 6422,
    "reward": 91.452715,
    "length": 61,
    "time": 98743.220643,
    "actor_loss": -57.58192443847656,
    "critic_loss": 23.325605392456055,
    "ent_coef": 0.0661887377500534,
    "learning_rate": 0.001
  },
  {
    "episode": 6423,
    "reward": 90.252523,
    "length": 63,
    "time": 98756.628973,
    "actor_loss": -63.843994140625,
    "critic_loss": 31.356287002563477,
    "ent_coef": 0.0689789280295372,
    "learning_rate": 0.001
  },
  {
    "episode": 6424,
    "reward": 84.621567,
    "length": 67,
    "time": 98769.346093,
    "actor_loss": -59.799964904785156,
    "critic_loss": 19.59050941467285,
    "ent_coef": 0.07792305201292038,
    "learning_rate": 0.001
  },
  {
    "episode": 6425,
    "reward": 89.788233,
    "length": 64,
    "time": 98780.841908,
    "actor_loss": -58.84322738647461,
    "critic_loss": 8.905142784118652,
    "ent_coef": 0.07692324370145798,
    "learning_rate": 0.001
  },
  {
    "episode": 6426,
    "reward": 89.772402,
    "length": 66,
    "time": 98794.821377,
    "actor_loss": -57.66447830200195,
    "critic_loss": 27.789531707763672,
    "ent_coef": 0.07367897778749466,
    "learning_rate": 0.001
  },
  {
    "episode": 6427,
    "reward": 90.208843,
    "length": 65,
    "time": 98808.150229,
    "actor_loss": -62.16539001464844,
    "critic_loss": 36.87586212158203,
    "ent_coef": 0.07202571630477905,
    "learning_rate": 0.001
  },
  {
    "episode": 6428,
    "reward": 90.339025,
    "length": 64,
    "time": 98820.561661,
    "actor_loss": -64.32337951660156,
    "critic_loss": 7.917266845703125,
    "ent_coef": 0.07065103203058243,
    "learning_rate": 0.001
  },
  {
    "episode": 6429,
    "reward": 89.451746,
    "length": 67,
    "time": 98833.907311,
    "actor_loss": -59.90492630004883,
    "critic_loss": 53.758216857910156,
    "ent_coef": 0.06876136362552643,
    "learning_rate": 0.001
  },
  {
    "episode": 6430,
    "reward": 88.970701,
    "length": 68,
    "time": 98847.756708,
    "actor_loss": -63.916534423828125,
    "critic_loss": 11.690135955810547,
    "ent_coef": 0.06468077003955841,
    "learning_rate": 0.001
  },
  {
    "episode": 6431,
    "reward": 90.960526,
    "length": 63,
    "time": 98862.093397,
    "actor_loss": -59.29901885986328,
    "critic_loss": 18.264629364013672,
    "ent_coef": 0.06539236754179001,
    "learning_rate": 0.001
  },
  {
    "episode": 6432,
    "reward": 88.611576,
    "length": 70,
    "time": 98875.101872,
    "actor_loss": -58.29399490356445,
    "critic_loss": 14.123891830444336,
    "ent_coef": 0.07012088596820831,
    "learning_rate": 0.001
  },
  {
    "episode": 6433,
    "reward": 89.664863,
    "length": 66,
    "time": 98888.593364,
    "actor_loss": -58.58055114746094,
    "critic_loss": 5.567902565002441,
    "ent_coef": 0.06711422652006149,
    "learning_rate": 0.001
  },
  {
    "episode": 6434,
    "reward": 89.824717,
    "length": 64,
    "time": 98900.265669,
    "actor_loss": -67.06527709960938,
    "critic_loss": 37.75429916381836,
    "ent_coef": 0.06654905527830124,
    "learning_rate": 0.001
  },
  {
    "episode": 6435,
    "reward": 90.666923,
    "length": 62,
    "time": 98911.612238,
    "actor_loss": -61.55572509765625,
    "critic_loss": 24.554718017578125,
    "ent_coef": 0.06704611331224442,
    "learning_rate": 0.001
  },
  {
    "episode": 6436,
    "reward": 92.18417,
    "length": 61,
    "time": 98923.7674,
    "actor_loss": -65.64395141601562,
    "critic_loss": 16.05583381652832,
    "ent_coef": 0.06876152008771896,
    "learning_rate": 0.001
  },
  {
    "episode": 6437,
    "reward": 91.310644,
    "length": 60,
    "time": 98938.226052,
    "actor_loss": -59.30017852783203,
    "critic_loss": 18.749256134033203,
    "ent_coef": 0.07051672786474228,
    "learning_rate": 0.001
  },
  {
    "episode": 6438,
    "reward": 90.666822,
    "length": 63,
    "time": 98949.405336,
    "actor_loss": -61.361141204833984,
    "critic_loss": 16.48897361755371,
    "ent_coef": 0.06909812986850739,
    "learning_rate": 0.001
  },
  {
    "episode": 6439,
    "reward": 90.769831,
    "length": 62,
    "time": 98960.315304,
    "actor_loss": -63.38333511352539,
    "critic_loss": 108.42774963378906,
    "ent_coef": 0.06696123629808426,
    "learning_rate": 0.001
  },
  {
    "episode": 6440,
    "reward": 92.355635,
    "length": 61,
    "time": 98974.323004,
    "actor_loss": -61.67570495605469,
    "critic_loss": 51.72233581542969,
    "ent_coef": 0.06708285957574844,
    "learning_rate": 0.001
  },
  {
    "episode": 6441,
    "reward": 91.0135,
    "length": 63,
    "time": 98985.783731,
    "actor_loss": -62.353546142578125,
    "critic_loss": 69.38154602050781,
    "ent_coef": 0.06908077001571655,
    "learning_rate": 0.001
  },
  {
    "episode": 6442,
    "reward": 91.11382,
    "length": 62,
    "time": 98999.466833,
    "actor_loss": -68.44401550292969,
    "critic_loss": 7.327181339263916,
    "ent_coef": 0.06930316239595413,
    "learning_rate": 0.001
  },
  {
    "episode": 6443,
    "reward": 91.287697,
    "length": 62,
    "time": 99011.804313,
    "actor_loss": -68.9739761352539,
    "critic_loss": 15.645942687988281,
    "ent_coef": 0.06836270540952682,
    "learning_rate": 0.001
  },
  {
    "episode": 6444,
    "reward": 91.200597,
    "length": 63,
    "time": 99023.58386,
    "actor_loss": -56.04936218261719,
    "critic_loss": 7.036064147949219,
    "ent_coef": 0.06750360876321793,
    "learning_rate": 0.001
  },
  {
    "episode": 6445,
    "reward": 90.941648,
    "length": 62,
    "time": 99035.042722,
    "actor_loss": -61.57889938354492,
    "critic_loss": 57.19548034667969,
    "ent_coef": 0.06581161916255951,
    "learning_rate": 0.001
  },
  {
    "episode": 6446,
    "reward": 90.152773,
    "length": 64,
    "time": 99047.348011,
    "actor_loss": -60.7957878112793,
    "critic_loss": 19.451946258544922,
    "ent_coef": 0.06443928182125092,
    "learning_rate": 0.001
  },
  {
    "episode": 6447,
    "reward": 91.731447,
    "length": 61,
    "time": 99058.601664,
    "actor_loss": -56.585182189941406,
    "critic_loss": 9.263025283813477,
    "ent_coef": 0.06481742858886719,
    "learning_rate": 0.001
  },
  {
    "episode": 6448,
    "reward": 92.345984,
    "length": 60,
    "time": 99070.688105,
    "actor_loss": -58.9609375,
    "critic_loss": 23.050336837768555,
    "ent_coef": 0.06375469267368317,
    "learning_rate": 0.001
  },
  {
    "episode": 6449,
    "reward": 89.977708,
    "length": 64,
    "time": 99084.127877,
    "actor_loss": -57.77391052246094,
    "critic_loss": 366.82684326171875,
    "ent_coef": 0.062234118580818176,
    "learning_rate": 0.001
  },
  {
    "episode": 6450,
    "reward": 87.600753,
    "length": 69,
    "time": 99097.309437,
    "actor_loss": -59.680816650390625,
    "critic_loss": 14.161836624145508,
    "ent_coef": 0.05914633348584175,
    "learning_rate": 0.001
  },
  {
    "episode": 6451,
    "reward": 91.781097,
    "length": 61,
    "time": 99112.403042,
    "actor_loss": -58.03785705566406,
    "critic_loss": 22.351356506347656,
    "ent_coef": 0.05929729714989662,
    "learning_rate": 0.001
  },
  {
    "episode": 6452,
    "reward": 90.001639,
    "length": 64,
    "time": 99124.5655,
    "actor_loss": -66.24005889892578,
    "critic_loss": 31.085018157958984,
    "ent_coef": 0.058398209512233734,
    "learning_rate": 0.001
  },
  {
    "episode": 6453,
    "reward": 91.824417,
    "length": 60,
    "time": 99139.026902,
    "actor_loss": -60.98430633544922,
    "critic_loss": 13.50825309753418,
    "ent_coef": 0.06245376169681549,
    "learning_rate": 0.001
  },
  {
    "episode": 6454,
    "reward": 88.602381,
    "length": 68,
    "time": 99152.038124,
    "actor_loss": -55.36984634399414,
    "critic_loss": 15.076886177062988,
    "ent_coef": 0.06039202958345413,
    "learning_rate": 0.001
  },
  {
    "episode": 6455,
    "reward": 88.771047,
    "length": 67,
    "time": 99166.900853,
    "actor_loss": -57.04949951171875,
    "critic_loss": 5.308823585510254,
    "ent_coef": 0.060414254665374756,
    "learning_rate": 0.001
  },
  {
    "episode": 6456,
    "reward": 82.084973,
    "length": 71,
    "time": 99182.616844,
    "actor_loss": -69.83872985839844,
    "critic_loss": 10.287616729736328,
    "ent_coef": 0.060937490314245224,
    "learning_rate": 0.001
  },
  {
    "episode": 6457,
    "reward": 88.48223,
    "length": 71,
    "time": 99197.43263,
    "actor_loss": -62.72728729248047,
    "critic_loss": 16.721492767333984,
    "ent_coef": 0.058487869799137115,
    "learning_rate": 0.001
  },
  {
    "episode": 6458,
    "reward": 85.926046,
    "length": 72,
    "time": 99209.880191,
    "actor_loss": -61.39229202270508,
    "critic_loss": 21.4216365814209,
    "ent_coef": 0.05583244934678078,
    "learning_rate": 0.001
  },
  {
    "episode": 6459,
    "reward": 79.4944,
    "length": 72,
    "time": 99224.524698,
    "actor_loss": -61.83878707885742,
    "critic_loss": 75.88154602050781,
    "ent_coef": 0.06167415529489517,
    "learning_rate": 0.001
  },
  {
    "episode": 6460,
    "reward": 92.404176,
    "length": 60,
    "time": 99238.208149,
    "actor_loss": -60.245826721191406,
    "critic_loss": 57.24755096435547,
    "ent_coef": 0.06298387050628662,
    "learning_rate": 0.001
  },
  {
    "episode": 6461,
    "reward": 89.933142,
    "length": 64,
    "time": 99250.004974,
    "actor_loss": -60.14341735839844,
    "critic_loss": 7.836151123046875,
    "ent_coef": 0.06307334452867508,
    "learning_rate": 0.001
  },
  {
    "episode": 6462,
    "reward": 91.251891,
    "length": 63,
    "time": 99263.227667,
    "actor_loss": -59.900638580322266,
    "critic_loss": 18.63677406311035,
    "ent_coef": 0.06917210668325424,
    "learning_rate": 0.001
  },
  {
    "episode": 6463,
    "reward": 90.503629,
    "length": 64,
    "time": 99274.566879,
    "actor_loss": -57.762664794921875,
    "critic_loss": 282.7754211425781,
    "ent_coef": 0.07035922259092331,
    "learning_rate": 0.001
  },
  {
    "episode": 6464,
    "reward": 89.906284,
    "length": 64,
    "time": 99286.810566,
    "actor_loss": -59.58483123779297,
    "critic_loss": 14.476301193237305,
    "ent_coef": 0.06861574202775955,
    "learning_rate": 0.001
  },
  {
    "episode": 6465,
    "reward": 92.401815,
    "length": 60,
    "time": 99298.575122,
    "actor_loss": -56.753578186035156,
    "critic_loss": 15.564665794372559,
    "ent_coef": 0.07084720581769943,
    "learning_rate": 0.001
  },
  {
    "episode": 6466,
    "reward": 87.226474,
    "length": 76,
    "time": 99313.507111,
    "actor_loss": -61.3283576965332,
    "critic_loss": 35.94265365600586,
    "ent_coef": 0.07327740639448166,
    "learning_rate": 0.001
  },
  {
    "episode": 6467,
    "reward": 91.684009,
    "length": 60,
    "time": 99324.248516,
    "actor_loss": -63.95663833618164,
    "critic_loss": 16.278440475463867,
    "ent_coef": 0.0715547502040863,
    "learning_rate": 0.001
  },
  {
    "episode": 6468,
    "reward": 88.146775,
    "length": 74,
    "time": 99336.925876,
    "actor_loss": -61.24781799316406,
    "critic_loss": 10.935659408569336,
    "ent_coef": 0.0717347264289856,
    "learning_rate": 0.001
  },
  {
    "episode": 6469,
    "reward": 90.850192,
    "length": 63,
    "time": 99349.272066,
    "actor_loss": -61.990692138671875,
    "critic_loss": 7.110954284667969,
    "ent_coef": 0.0683165118098259,
    "learning_rate": 0.001
  },
  {
    "episode": 6470,
    "reward": 89.229323,
    "length": 71,
    "time": 99364.150728,
    "actor_loss": -59.64906692504883,
    "critic_loss": 28.756370544433594,
    "ent_coef": 0.06828878074884415,
    "learning_rate": 0.001
  },
  {
    "episode": 6471,
    "reward": 91.323104,
    "length": 62,
    "time": 99377.723041,
    "actor_loss": -60.42746353149414,
    "critic_loss": 6.149896621704102,
    "ent_coef": 0.06610841304063797,
    "learning_rate": 0.001
  },
  {
    "episode": 6472,
    "reward": 88.073332,
    "length": 76,
    "time": 99390.580449,
    "actor_loss": -64.46754455566406,
    "critic_loss": 96.46238708496094,
    "ent_coef": 0.06942126899957657,
    "learning_rate": 0.001
  },
  {
    "episode": 6473,
    "reward": 91.619128,
    "length": 61,
    "time": 99404.492597,
    "actor_loss": -60.57306671142578,
    "critic_loss": 8.544873237609863,
    "ent_coef": 0.069709911942482,
    "learning_rate": 0.001
  },
  {
    "episode": 6474,
    "reward": 91.591176,
    "length": 61,
    "time": 99418.390006,
    "actor_loss": -60.86821365356445,
    "critic_loss": 5.06387996673584,
    "ent_coef": 0.07310084253549576,
    "learning_rate": 0.001
  },
  {
    "episode": 6475,
    "reward": 91.317597,
    "length": 63,
    "time": 99430.741243,
    "actor_loss": -61.81133270263672,
    "critic_loss": 18.463157653808594,
    "ent_coef": 0.07268791645765305,
    "learning_rate": 0.001
  },
  {
    "episode": 6476,
    "reward": 90.867777,
    "length": 63,
    "time": 99442.814131,
    "actor_loss": -61.87145233154297,
    "critic_loss": 10.99399185180664,
    "ent_coef": 0.07023650407791138,
    "learning_rate": 0.001
  },
  {
    "episode": 6477,
    "reward": 91.0973,
    "length": 64,
    "time": 99454.608576,
    "actor_loss": -68.28006744384766,
    "critic_loss": 66.90269470214844,
    "ent_coef": 0.06734033674001694,
    "learning_rate": 0.001
  },
  {
    "episode": 6478,
    "reward": 90.588099,
    "length": 64,
    "time": 99466.679967,
    "actor_loss": -63.268898010253906,
    "critic_loss": 9.55327320098877,
    "ent_coef": 0.06267687678337097,
    "learning_rate": 0.001
  },
  {
    "episode": 6479,
    "reward": 91.738561,
    "length": 61,
    "time": 99478.763844,
    "actor_loss": -62.96796798706055,
    "critic_loss": 58.541866302490234,
    "ent_coef": 0.06253593415021896,
    "learning_rate": 0.001
  },
  {
    "episode": 6480,
    "reward": 84.709069,
    "length": 74,
    "time": 99492.025998,
    "actor_loss": -63.920867919921875,
    "critic_loss": 24.137409210205078,
    "ent_coef": 0.06263954192399979,
    "learning_rate": 0.001
  },
  {
    "episode": 6481,
    "reward": 91.221643,
    "length": 63,
    "time": 99509.260987,
    "actor_loss": -66.54216766357422,
    "critic_loss": 96.9061279296875,
    "ent_coef": 0.06225145235657692,
    "learning_rate": 0.001
  },
  {
    "episode": 6482,
    "reward": 91.877608,
    "length": 60,
    "time": 99522.992226,
    "actor_loss": -61.6010627746582,
    "critic_loss": 6.575479507446289,
    "ent_coef": 0.06188048794865608,
    "learning_rate": 0.001
  },
  {
    "episode": 6483,
    "reward": 92.733202,
    "length": 60,
    "time": 99534.065364,
    "actor_loss": -64.71318054199219,
    "critic_loss": 6.187282562255859,
    "ent_coef": 0.06402850896120071,
    "learning_rate": 0.001
  },
  {
    "episode": 6484,
    "reward": 92.583077,
    "length": 60,
    "time": 99547.402208,
    "actor_loss": -61.183956146240234,
    "critic_loss": 41.14529800415039,
    "ent_coef": 0.06489963084459305,
    "learning_rate": 0.001
  },
  {
    "episode": 6485,
    "reward": 90.935951,
    "length": 62,
    "time": 99558.634903,
    "actor_loss": -64.03668975830078,
    "critic_loss": 30.395938873291016,
    "ent_coef": 0.0657140463590622,
    "learning_rate": 0.001
  },
  {
    "episode": 6486,
    "reward": 92.071376,
    "length": 60,
    "time": 99571.225617,
    "actor_loss": -66.91085052490234,
    "critic_loss": 12.749302864074707,
    "ent_coef": 0.06916613131761551,
    "learning_rate": 0.001
  },
  {
    "episode": 6487,
    "reward": 91.646835,
    "length": 62,
    "time": 99586.486541,
    "actor_loss": -64.02779388427734,
    "critic_loss": 9.886335372924805,
    "ent_coef": 0.06931132078170776,
    "learning_rate": 0.001
  },
  {
    "episode": 6488,
    "reward": 91.175871,
    "length": 62,
    "time": 99597.483947,
    "actor_loss": -57.965087890625,
    "critic_loss": 22.885644912719727,
    "ent_coef": 0.06809227168560028,
    "learning_rate": 0.001
  },
  {
    "episode": 6489,
    "reward": 91.672686,
    "length": 63,
    "time": 99608.849469,
    "actor_loss": -64.21189880371094,
    "critic_loss": 15.559834480285645,
    "ent_coef": 0.06944839656352997,
    "learning_rate": 0.001
  },
  {
    "episode": 6490,
    "reward": 90.701696,
    "length": 63,
    "time": 99622.381909,
    "actor_loss": -65.28490447998047,
    "critic_loss": 11.16584587097168,
    "ent_coef": 0.06943654268980026,
    "learning_rate": 0.001
  },
  {
    "episode": 6491,
    "reward": 92.288076,
    "length": 61,
    "time": 99633.449842,
    "actor_loss": -60.518646240234375,
    "critic_loss": 13.384061813354492,
    "ent_coef": 0.07175851613283157,
    "learning_rate": 0.001
  },
  {
    "episode": 6492,
    "reward": 91.574973,
    "length": 62,
    "time": 99644.560173,
    "actor_loss": -63.76573944091797,
    "critic_loss": 11.442858695983887,
    "ent_coef": 0.07365314662456512,
    "learning_rate": 0.001
  },
  {
    "episode": 6493,
    "reward": 90.652429,
    "length": 63,
    "time": 99657.81169,
    "actor_loss": -63.17961883544922,
    "critic_loss": 12.125112533569336,
    "ent_coef": 0.07464005053043365,
    "learning_rate": 0.001
  },
  {
    "episode": 6494,
    "reward": 90.132425,
    "length": 64,
    "time": 99670.253876,
    "actor_loss": -62.890769958496094,
    "critic_loss": 13.67729377746582,
    "ent_coef": 0.0741305723786354,
    "learning_rate": 0.001
  },
  {
    "episode": 6495,
    "reward": 86.280889,
    "length": 75,
    "time": 99684.608721,
    "actor_loss": -67.29032897949219,
    "critic_loss": 9.239839553833008,
    "ent_coef": 0.07152101397514343,
    "learning_rate": 0.001
  },
  {
    "episode": 6496,
    "reward": 89.383411,
    "length": 66,
    "time": 99697.759815,
    "actor_loss": -56.178855895996094,
    "critic_loss": 8.729255676269531,
    "ent_coef": 0.06763188540935516,
    "learning_rate": 0.001
  },
  {
    "episode": 6497,
    "reward": 88.374794,
    "length": 75,
    "time": 99712.257876,
    "actor_loss": -65.03382110595703,
    "critic_loss": 13.64232063293457,
    "ent_coef": 0.06731238961219788,
    "learning_rate": 0.001
  },
  {
    "episode": 6498,
    "reward": 90.456377,
    "length": 64,
    "time": 99724.999431,
    "actor_loss": -61.04165267944336,
    "critic_loss": 10.1892728805542,
    "ent_coef": 0.06704174727201462,
    "learning_rate": 0.001
  },
  {
    "episode": 6499,
    "reward": 90.987229,
    "length": 62,
    "time": 99737.116586,
    "actor_loss": -56.964542388916016,
    "critic_loss": 29.25326919555664,
    "ent_coef": 0.06953379511833191,
    "learning_rate": 0.001
  },
  {
    "episode": 6500,
    "reward": 91.082471,
    "length": 63,
    "time": 99751.401202,
    "actor_loss": -60.66753387451172,
    "critic_loss": 5.919788360595703,
    "ent_coef": 0.06755761057138443,
    "learning_rate": 0.001
  },
  {
    "episode": 6501,
    "reward": 89.549222,
    "length": 66,
    "time": 99764.05906,
    "actor_loss": -60.36091613769531,
    "critic_loss": 574.1913452148438,
    "ent_coef": 0.06496196985244751,
    "learning_rate": 0.001
  },
  {
    "episode": 6502,
    "reward": 90.533859,
    "length": 65,
    "time": 99775.991044,
    "actor_loss": -62.60830307006836,
    "critic_loss": 12.098234176635742,
    "ent_coef": 0.06309033930301666,
    "learning_rate": 0.001
  },
  {
    "episode": 6503,
    "reward": 89.654656,
    "length": 66,
    "time": 99787.94584,
    "actor_loss": -64.92556762695312,
    "critic_loss": 10.515700340270996,
    "ent_coef": 0.062209971249103546,
    "learning_rate": 0.001
  },
  {
    "episode": 6504,
    "reward": 87.887475,
    "length": 69,
    "time": 99800.295803,
    "actor_loss": -58.53485107421875,
    "critic_loss": 10.726987838745117,
    "ent_coef": 0.05972930043935776,
    "learning_rate": 0.001
  },
  {
    "episode": 6505,
    "reward": 90.558906,
    "length": 64,
    "time": 99814.648673,
    "actor_loss": -65.66781616210938,
    "critic_loss": 24.803653717041016,
    "ent_coef": 0.060649678111076355,
    "learning_rate": 0.001
  },
  {
    "episode": 6506,
    "reward": 88.744029,
    "length": 70,
    "time": 99827.61602,
    "actor_loss": -59.83291244506836,
    "critic_loss": 7.929830551147461,
    "ent_coef": 0.06182008981704712,
    "learning_rate": 0.001
  },
  {
    "episode": 6507,
    "reward": 89.081111,
    "length": 69,
    "time": 99842.167059,
    "actor_loss": -60.33638381958008,
    "critic_loss": 6.96466064453125,
    "ent_coef": 0.0581970177590847,
    "learning_rate": 0.001
  },
  {
    "episode": 6508,
    "reward": 89.528538,
    "length": 67,
    "time": 99853.9905,
    "actor_loss": -62.259544372558594,
    "critic_loss": 19.231067657470703,
    "ent_coef": 0.06115536391735077,
    "learning_rate": 0.001
  },
  {
    "episode": 6509,
    "reward": 89.576504,
    "length": 67,
    "time": 99867.305609,
    "actor_loss": -61.440025329589844,
    "critic_loss": 39.87162780761719,
    "ent_coef": 0.06087551265954971,
    "learning_rate": 0.001
  },
  {
    "episode": 6510,
    "reward": 89.06435,
    "length": 68,
    "time": 99880.167406,
    "actor_loss": -65.27003479003906,
    "critic_loss": 8.484105110168457,
    "ent_coef": 0.05738415941596031,
    "learning_rate": 0.001
  },
  {
    "episode": 6511,
    "reward": 90.489564,
    "length": 65,
    "time": 99892.933251,
    "actor_loss": -59.36253356933594,
    "critic_loss": 121.07756042480469,
    "ent_coef": 0.058353837579488754,
    "learning_rate": 0.001
  },
  {
    "episode": 6512,
    "reward": 84.393093,
    "length": 75,
    "time": 99907.335654,
    "actor_loss": -64.33430480957031,
    "critic_loss": 10.224738121032715,
    "ent_coef": 0.05721788480877876,
    "learning_rate": 0.001
  },
  {
    "episode": 6513,
    "reward": 90.967332,
    "length": 64,
    "time": 99919.696402,
    "actor_loss": -61.358360290527344,
    "critic_loss": 42.440773010253906,
    "ent_coef": 0.059469036757946014,
    "learning_rate": 0.001
  },
  {
    "episode": 6514,
    "reward": 89.554995,
    "length": 64,
    "time": 99934.602885,
    "actor_loss": -72.64881896972656,
    "critic_loss": 6.44342041015625,
    "ent_coef": 0.06133488938212395,
    "learning_rate": 0.001
  },
  {
    "episode": 6515,
    "reward": 91.087619,
    "length": 65,
    "time": 99946.753975,
    "actor_loss": -60.34605407714844,
    "critic_loss": 8.010991096496582,
    "ent_coef": 0.06597678363323212,
    "learning_rate": 0.001
  },
  {
    "episode": 6516,
    "reward": 91.621889,
    "length": 62,
    "time": 99958.484683,
    "actor_loss": -58.172760009765625,
    "critic_loss": 6.762423515319824,
    "ent_coef": 0.06905391067266464,
    "learning_rate": 0.001
  },
  {
    "episode": 6517,
    "reward": 91.356567,
    "length": 63,
    "time": 99969.894154,
    "actor_loss": -59.22722625732422,
    "critic_loss": 10.89291000366211,
    "ent_coef": 0.07059959322214127,
    "learning_rate": 0.001
  },
  {
    "episode": 6518,
    "reward": 91.441455,
    "length": 62,
    "time": 99982.394482,
    "actor_loss": -67.24443817138672,
    "critic_loss": 140.7312774658203,
    "ent_coef": 0.0760883018374443,
    "learning_rate": 0.001
  },
  {
    "episode": 6519,
    "reward": 88.636765,
    "length": 66,
    "time": 99997.831048,
    "actor_loss": -54.875736236572266,
    "critic_loss": 72.4043197631836,
    "ent_coef": 0.07455011457204819,
    "learning_rate": 0.001
  },
  {
    "episode": 6520,
    "reward": 88.915108,
    "length": 67,
    "time": 100011.358908,
    "actor_loss": -66.62844848632812,
    "critic_loss": 33.77234649658203,
    "ent_coef": 0.07236773520708084,
    "learning_rate": 0.001
  },
  {
    "episode": 6521,
    "reward": 84.408062,
    "length": 72,
    "time": 100024.918078,
    "actor_loss": -63.9793701171875,
    "critic_loss": 37.61265182495117,
    "ent_coef": 0.07021711766719818,
    "learning_rate": 0.001
  },
  {
    "episode": 6522,
    "reward": 89.665766,
    "length": 64,
    "time": 100037.299585,
    "actor_loss": -63.711761474609375,
    "critic_loss": 14.005306243896484,
    "ent_coef": 0.06887921690940857,
    "learning_rate": 0.001
  },
  {
    "episode": 6523,
    "reward": 91.844527,
    "length": 59,
    "time": 100050.246996,
    "actor_loss": -57.69624328613281,
    "critic_loss": 269.60858154296875,
    "ent_coef": 0.07483110576868057,
    "learning_rate": 0.001
  },
  {
    "episode": 6524,
    "reward": 90.463981,
    "length": 64,
    "time": 100062.908665,
    "actor_loss": -57.95524597167969,
    "critic_loss": 58.45909881591797,
    "ent_coef": 0.07377901673316956,
    "learning_rate": 0.001
  },
  {
    "episode": 6525,
    "reward": 91.456127,
    "length": 62,
    "time": 100074.254704,
    "actor_loss": -66.31675720214844,
    "critic_loss": 4.909948348999023,
    "ent_coef": 0.0736091136932373,
    "learning_rate": 0.001
  },
  {
    "episode": 6526,
    "reward": 89.523909,
    "length": 66,
    "time": 100087.95183,
    "actor_loss": -64.93475341796875,
    "critic_loss": 13.09786605834961,
    "ent_coef": 0.07506465166807175,
    "learning_rate": 0.001
  },
  {
    "episode": 6527,
    "reward": 87.618855,
    "length": 77,
    "time": 100101.836699,
    "actor_loss": -60.03200912475586,
    "critic_loss": 4.671738624572754,
    "ent_coef": 0.07193922251462936,
    "learning_rate": 0.001
  },
  {
    "episode": 6528,
    "reward": 87.699075,
    "length": 76,
    "time": 100116.142399,
    "actor_loss": -63.857547760009766,
    "critic_loss": 11.714603424072266,
    "ent_coef": 0.07114256173372269,
    "learning_rate": 0.001
  },
  {
    "episode": 6529,
    "reward": 92.109688,
    "length": 62,
    "time": 100127.519156,
    "actor_loss": -63.03022384643555,
    "critic_loss": 11.525894165039062,
    "ent_coef": 0.07242100685834885,
    "learning_rate": 0.001
  },
  {
    "episode": 6530,
    "reward": 90.490498,
    "length": 65,
    "time": 100139.235127,
    "actor_loss": -65.08221435546875,
    "critic_loss": 7.599526405334473,
    "ent_coef": 0.07024936378002167,
    "learning_rate": 0.001
  },
  {
    "episode": 6531,
    "reward": 89.524571,
    "length": 67,
    "time": 100154.274856,
    "actor_loss": -59.771522521972656,
    "critic_loss": 18.896106719970703,
    "ent_coef": 0.0685657262802124,
    "learning_rate": 0.001
  },
  {
    "episode": 6532,
    "reward": 91.705892,
    "length": 63,
    "time": 100168.487111,
    "actor_loss": -59.381683349609375,
    "critic_loss": 8.227640151977539,
    "ent_coef": 0.0693202018737793,
    "learning_rate": 0.001
  },
  {
    "episode": 6533,
    "reward": 91.487112,
    "length": 63,
    "time": 100182.428672,
    "actor_loss": -61.18206787109375,
    "critic_loss": 24.44412612915039,
    "ent_coef": 0.06907720863819122,
    "learning_rate": 0.001
  },
  {
    "episode": 6534,
    "reward": 91.134637,
    "length": 62,
    "time": 100195.495533,
    "actor_loss": -69.02923583984375,
    "critic_loss": 8.111288070678711,
    "ent_coef": 0.06899088621139526,
    "learning_rate": 0.001
  },
  {
    "episode": 6535,
    "reward": 90.388693,
    "length": 64,
    "time": 100208.016182,
    "actor_loss": -57.29139709472656,
    "critic_loss": 13.72503662109375,
    "ent_coef": 0.06652434170246124,
    "learning_rate": 0.001
  },
  {
    "episode": 6536,
    "reward": 89.599495,
    "length": 64,
    "time": 100219.650642,
    "actor_loss": -63.94886016845703,
    "critic_loss": 27.636356353759766,
    "ent_coef": 0.06520787626504898,
    "learning_rate": 0.001
  },
  {
    "episode": 6537,
    "reward": 88.072218,
    "length": 69,
    "time": 100231.47472,
    "actor_loss": -63.18682098388672,
    "critic_loss": 66.95231628417969,
    "ent_coef": 0.06473977118730545,
    "learning_rate": 0.001
  },
  {
    "episode": 6538,
    "reward": 86.357949,
    "length": 72,
    "time": 100243.891578,
    "actor_loss": -62.52634811401367,
    "critic_loss": 14.718908309936523,
    "ent_coef": 0.06141582876443863,
    "learning_rate": 0.001
  },
  {
    "episode": 6539,
    "reward": 89.433013,
    "length": 67,
    "time": 100257.292696,
    "actor_loss": -55.17045593261719,
    "critic_loss": 72.39710998535156,
    "ent_coef": 0.058969639241695404,
    "learning_rate": 0.001
  },
  {
    "episode": 6540,
    "reward": 90.205783,
    "length": 65,
    "time": 100268.893907,
    "actor_loss": -65.64622497558594,
    "critic_loss": 8.461746215820312,
    "ent_coef": 0.059716884046792984,
    "learning_rate": 0.001
  },
  {
    "episode": 6541,
    "reward": 90.400626,
    "length": 66,
    "time": 100283.112402,
    "actor_loss": -60.32801055908203,
    "critic_loss": 11.116079330444336,
    "ent_coef": 0.06026259809732437,
    "learning_rate": 0.001
  },
  {
    "episode": 6542,
    "reward": 90.002362,
    "length": 65,
    "time": 100296.008726,
    "actor_loss": -66.87562561035156,
    "critic_loss": 19.482608795166016,
    "ent_coef": 0.06166909262537956,
    "learning_rate": 0.001
  },
  {
    "episode": 6543,
    "reward": 90.730235,
    "length": 63,
    "time": 100308.234728,
    "actor_loss": -58.9105110168457,
    "critic_loss": 6.294989109039307,
    "ent_coef": 0.06134197115898132,
    "learning_rate": 0.001
  },
  {
    "episode": 6544,
    "reward": 88.608656,
    "length": 70,
    "time": 100320.694409,
    "actor_loss": -58.572120666503906,
    "critic_loss": 29.87186622619629,
    "ent_coef": 0.05815505608916283,
    "learning_rate": 0.001
  },
  {
    "episode": 6545,
    "reward": 89.853399,
    "length": 65,
    "time": 100335.295641,
    "actor_loss": -66.15324401855469,
    "critic_loss": 32.954559326171875,
    "ent_coef": 0.05552920326590538,
    "learning_rate": 0.001
  },
  {
    "episode": 6546,
    "reward": 87.017691,
    "length": 69,
    "time": 100347.547076,
    "actor_loss": -62.16558074951172,
    "critic_loss": 8.246139526367188,
    "ent_coef": 0.055315177887678146,
    "learning_rate": 0.001
  },
  {
    "episode": 6547,
    "reward": 90.21969,
    "length": 66,
    "time": 100360.956964,
    "actor_loss": -60.47282409667969,
    "critic_loss": 12.570785522460938,
    "ent_coef": 0.05797535181045532,
    "learning_rate": 0.001
  },
  {
    "episode": 6548,
    "reward": 89.759492,
    "length": 65,
    "time": 100374.72183,
    "actor_loss": -67.02435302734375,
    "critic_loss": 12.193180084228516,
    "ent_coef": 0.05899694561958313,
    "learning_rate": 0.001
  },
  {
    "episode": 6549,
    "reward": 90.605081,
    "length": 62,
    "time": 100388.466372,
    "actor_loss": -63.491600036621094,
    "critic_loss": 12.190950393676758,
    "ent_coef": 0.062283650040626526,
    "learning_rate": 0.001
  },
  {
    "episode": 6550,
    "reward": 90.54918,
    "length": 65,
    "time": 100401.060884,
    "actor_loss": -61.4001350402832,
    "critic_loss": 20.531185150146484,
    "ent_coef": 0.063395656645298,
    "learning_rate": 0.001
  },
  {
    "episode": 6551,
    "reward": 91.347955,
    "length": 63,
    "time": 100414.803832,
    "actor_loss": -60.39033508300781,
    "critic_loss": 20.736011505126953,
    "ent_coef": 0.06632667779922485,
    "learning_rate": 0.001
  },
  {
    "episode": 6552,
    "reward": 91.456893,
    "length": 62,
    "time": 100427.759219,
    "actor_loss": -64.48483276367188,
    "critic_loss": 10.890331268310547,
    "ent_coef": 0.0670357495546341,
    "learning_rate": 0.001
  },
  {
    "episode": 6553,
    "reward": 91.964385,
    "length": 60,
    "time": 100439.599608,
    "actor_loss": -56.491127014160156,
    "critic_loss": 6.682301044464111,
    "ent_coef": 0.06801280379295349,
    "learning_rate": 0.001
  },
  {
    "episode": 6554,
    "reward": 91.241324,
    "length": 63,
    "time": 100453.468527,
    "actor_loss": -69.26870727539062,
    "critic_loss": 28.142044067382812,
    "ent_coef": 0.07192795723676682,
    "learning_rate": 0.001
  },
  {
    "episode": 6555,
    "reward": 90.387871,
    "length": 65,
    "time": 100468.192214,
    "actor_loss": -65.94047546386719,
    "critic_loss": 3.6327099800109863,
    "ent_coef": 0.06959019601345062,
    "learning_rate": 0.001
  },
  {
    "episode": 6556,
    "reward": 85.672761,
    "length": 73,
    "time": 100480.806269,
    "actor_loss": -60.09333038330078,
    "critic_loss": 107.42809295654297,
    "ent_coef": 0.06266460567712784,
    "learning_rate": 0.001
  },
  {
    "episode": 6557,
    "reward": 83.90739,
    "length": 91,
    "time": 100495.723634,
    "actor_loss": -62.343963623046875,
    "critic_loss": 7.165022850036621,
    "ent_coef": 0.06327605992555618,
    "learning_rate": 0.001
  },
  {
    "episode": 6558,
    "reward": 90.391513,
    "length": 64,
    "time": 100510.543848,
    "actor_loss": -62.12104034423828,
    "critic_loss": 7.593693256378174,
    "ent_coef": 0.06311006098985672,
    "learning_rate": 0.001
  },
  {
    "episode": 6559,
    "reward": 89.306905,
    "length": 67,
    "time": 100524.339592,
    "actor_loss": -62.67495346069336,
    "critic_loss": 7.945132255554199,
    "ent_coef": 0.0615701787173748,
    "learning_rate": 0.001
  },
  {
    "episode": 6560,
    "reward": 90.710763,
    "length": 65,
    "time": 100535.811392,
    "actor_loss": -64.57322692871094,
    "critic_loss": 29.29122543334961,
    "ent_coef": 0.0626813992857933,
    "learning_rate": 0.001
  },
  {
    "episode": 6561,
    "reward": 88.377375,
    "length": 70,
    "time": 100550.240991,
    "actor_loss": -62.34384536743164,
    "critic_loss": 14.221475601196289,
    "ent_coef": 0.06364975869655609,
    "learning_rate": 0.001
  },
  {
    "episode": 6562,
    "reward": 89.087447,
    "length": 67,
    "time": 100563.976286,
    "actor_loss": -65.52200317382812,
    "critic_loss": 74.90167236328125,
    "ent_coef": 0.06320291757583618,
    "learning_rate": 0.001
  },
  {
    "episode": 6563,
    "reward": 89.546256,
    "length": 65,
    "time": 100575.928391,
    "actor_loss": -62.888248443603516,
    "critic_loss": 6.8509063720703125,
    "ent_coef": 0.06270669400691986,
    "learning_rate": 0.001
  },
  {
    "episode": 6564,
    "reward": 90.59751,
    "length": 65,
    "time": 100588.803649,
    "actor_loss": -65.86618041992188,
    "critic_loss": 50.67578887939453,
    "ent_coef": 0.06667546927928925,
    "learning_rate": 0.001
  },
  {
    "episode": 6565,
    "reward": 87.329216,
    "length": 73,
    "time": 100601.886965,
    "actor_loss": -61.544864654541016,
    "critic_loss": 19.26612663269043,
    "ent_coef": 0.06590535491704941,
    "learning_rate": 0.001
  },
  {
    "episode": 6566,
    "reward": 74.322702,
    "length": 91,
    "time": 100616.862936,
    "actor_loss": -66.87594604492188,
    "critic_loss": 5.7695817947387695,
    "ent_coef": 0.06314228475093842,
    "learning_rate": 0.001
  },
  {
    "episode": 6567,
    "reward": 85.942426,
    "length": 74,
    "time": 100630.397704,
    "actor_loss": -62.496376037597656,
    "critic_loss": 52.217315673828125,
    "ent_coef": 0.06065364554524422,
    "learning_rate": 0.001
  },
  {
    "episode": 6568,
    "reward": 90.1839,
    "length": 66,
    "time": 100642.85206,
    "actor_loss": -63.52143096923828,
    "critic_loss": 12.864984512329102,
    "ent_coef": 0.06453748792409897,
    "learning_rate": 0.001
  },
  {
    "episode": 6569,
    "reward": 89.905644,
    "length": 67,
    "time": 100657.332304,
    "actor_loss": -61.44187927246094,
    "critic_loss": 12.08314037322998,
    "ent_coef": 0.06451890617609024,
    "learning_rate": 0.001
  },
  {
    "episode": 6570,
    "reward": 90.864619,
    "length": 62,
    "time": 100668.513629,
    "actor_loss": -72.45230102539062,
    "critic_loss": 3.8156614303588867,
    "ent_coef": 0.06385206431150436,
    "learning_rate": 0.001
  },
  {
    "episode": 6571,
    "reward": 89.277234,
    "length": 66,
    "time": 100682.222395,
    "actor_loss": -66.90757751464844,
    "critic_loss": 5.489053726196289,
    "ent_coef": 0.06306865066289902,
    "learning_rate": 0.001
  },
  {
    "episode": 6572,
    "reward": 89.204881,
    "length": 66,
    "time": 100695.302968,
    "actor_loss": -63.91070556640625,
    "critic_loss": 16.23914337158203,
    "ent_coef": 0.060411255806684494,
    "learning_rate": 0.001
  },
  {
    "episode": 6573,
    "reward": 89.724224,
    "length": 66,
    "time": 100708.146396,
    "actor_loss": -66.5237808227539,
    "critic_loss": 7.799253463745117,
    "ent_coef": 0.05874144658446312,
    "learning_rate": 0.001
  },
  {
    "episode": 6574,
    "reward": 89.007204,
    "length": 69,
    "time": 100720.524149,
    "actor_loss": -66.65118408203125,
    "critic_loss": 49.53610610961914,
    "ent_coef": 0.059711359441280365,
    "learning_rate": 0.001
  },
  {
    "episode": 6575,
    "reward": 90.421091,
    "length": 65,
    "time": 100732.725301,
    "actor_loss": -60.55216598510742,
    "critic_loss": 13.259241104125977,
    "ent_coef": 0.06116131320595741,
    "learning_rate": 0.001
  },
  {
    "episode": 6576,
    "reward": 87.488751,
    "length": 70,
    "time": 100747.548908,
    "actor_loss": -61.31318664550781,
    "critic_loss": 29.542383193969727,
    "ent_coef": 0.0635886937379837,
    "learning_rate": 0.001
  },
  {
    "episode": 6577,
    "reward": 88.80081,
    "length": 69,
    "time": 100760.342409,
    "actor_loss": -66.36279296875,
    "critic_loss": 67.77632141113281,
    "ent_coef": 0.06575090438127518,
    "learning_rate": 0.001
  },
  {
    "episode": 6578,
    "reward": 87.679808,
    "length": 72,
    "time": 100773.059071,
    "actor_loss": -66.99640655517578,
    "critic_loss": 18.425796508789062,
    "ent_coef": 0.06278550624847412,
    "learning_rate": 0.001
  },
  {
    "episode": 6579,
    "reward": 84.873965,
    "length": 76,
    "time": 100786.01581,
    "actor_loss": -63.685325622558594,
    "critic_loss": 6.590631484985352,
    "ent_coef": 0.05754146724939346,
    "learning_rate": 0.001
  },
  {
    "episode": 6580,
    "reward": 78.260483,
    "length": 93,
    "time": 100805.252969,
    "actor_loss": -60.45960998535156,
    "critic_loss": 8.046793937683105,
    "ent_coef": 0.053487155586481094,
    "learning_rate": 0.001
  },
  {
    "episode": 6581,
    "reward": 89.632274,
    "length": 67,
    "time": 100818.52844,
    "actor_loss": -65.41055297851562,
    "critic_loss": 55.971397399902344,
    "ent_coef": 0.057008352130651474,
    "learning_rate": 0.001
  },
  {
    "episode": 6582,
    "reward": 85.292867,
    "length": 83,
    "time": 100834.335767,
    "actor_loss": -64.00961303710938,
    "critic_loss": 19.46805763244629,
    "ent_coef": 0.05475880578160286,
    "learning_rate": 0.001
  },
  {
    "episode": 6583,
    "reward": 83.183596,
    "length": 78,
    "time": 100847.931144,
    "actor_loss": -68.3302001953125,
    "critic_loss": 12.878074645996094,
    "ent_coef": 0.05587030574679375,
    "learning_rate": 0.001
  },
  {
    "episode": 6584,
    "reward": 89.0019,
    "length": 69,
    "time": 100860.765352,
    "actor_loss": -55.99629592895508,
    "critic_loss": 25.260517120361328,
    "ent_coef": 0.05770112946629524,
    "learning_rate": 0.001
  },
  {
    "episode": 6585,
    "reward": 89.737117,
    "length": 67,
    "time": 100874.105311,
    "actor_loss": -58.01483917236328,
    "critic_loss": 14.583172798156738,
    "ent_coef": 0.06242257356643677,
    "learning_rate": 0.001
  },
  {
    "episode": 6586,
    "reward": 88.410487,
    "length": 71,
    "time": 100887.931692,
    "actor_loss": -62.173545837402344,
    "critic_loss": 12.590863227844238,
    "ent_coef": 0.06405241042375565,
    "learning_rate": 0.001
  },
  {
    "episode": 6587,
    "reward": 87.264188,
    "length": 72,
    "time": 100901.245475,
    "actor_loss": -61.023040771484375,
    "critic_loss": 14.811851501464844,
    "ent_coef": 0.06483367085456848,
    "learning_rate": 0.001
  },
  {
    "episode": 6588,
    "reward": 86.644417,
    "length": 74,
    "time": 100913.899811,
    "actor_loss": -65.07406616210938,
    "critic_loss": 44.92149353027344,
    "ent_coef": 0.06603040546178818,
    "learning_rate": 0.001
  },
  {
    "episode": 6589,
    "reward": 89.611131,
    "length": 68,
    "time": 100926.377494,
    "actor_loss": -63.15146255493164,
    "critic_loss": 19.471595764160156,
    "ent_coef": 0.06953485310077667,
    "learning_rate": 0.001
  },
  {
    "episode": 6590,
    "reward": 87.939763,
    "length": 72,
    "time": 100940.640745,
    "actor_loss": -60.57379913330078,
    "critic_loss": 11.064943313598633,
    "ent_coef": 0.06736952811479568,
    "learning_rate": 0.001
  },
  {
    "episode": 6591,
    "reward": 89.518939,
    "length": 66,
    "time": 100952.461265,
    "actor_loss": -62.76172637939453,
    "critic_loss": 25.481666564941406,
    "ent_coef": 0.0670694038271904,
    "learning_rate": 0.001
  },
  {
    "episode": 6592,
    "reward": 86.766447,
    "length": 73,
    "time": 100967.771787,
    "actor_loss": -56.24005126953125,
    "critic_loss": 7.80746603012085,
    "ent_coef": 0.06753171235322952,
    "learning_rate": 0.001
  },
  {
    "episode": 6593,
    "reward": 90.084055,
    "length": 66,
    "time": 100981.981867,
    "actor_loss": -63.683074951171875,
    "critic_loss": 15.736010551452637,
    "ent_coef": 0.06868264824151993,
    "learning_rate": 0.001
  },
  {
    "episode": 6594,
    "reward": 90.137371,
    "length": 65,
    "time": 100996.616302,
    "actor_loss": -58.28392791748047,
    "critic_loss": 7.973120212554932,
    "ent_coef": 0.07145925611257553,
    "learning_rate": 0.001
  },
  {
    "episode": 6595,
    "reward": 89.308309,
    "length": 68,
    "time": 101009.25754,
    "actor_loss": -66.22787475585938,
    "critic_loss": 9.748886108398438,
    "ent_coef": 0.07114069908857346,
    "learning_rate": 0.001
  },
  {
    "episode": 6596,
    "reward": 89.86985,
    "length": 65,
    "time": 101020.86923,
    "actor_loss": -63.49817657470703,
    "critic_loss": 24.907119750976562,
    "ent_coef": 0.07306206226348877,
    "learning_rate": 0.001
  },
  {
    "episode": 6597,
    "reward": 91.804344,
    "length": 61,
    "time": 101032.273451,
    "actor_loss": -63.29396057128906,
    "critic_loss": 5.931206703186035,
    "ent_coef": 0.07600698620080948,
    "learning_rate": 0.001
  },
  {
    "episode": 6598,
    "reward": 91.872292,
    "length": 61,
    "time": 101045.613302,
    "actor_loss": -66.5965347290039,
    "critic_loss": 8.613059043884277,
    "ent_coef": 0.07901652157306671,
    "learning_rate": 0.001
  },
  {
    "episode": 6599,
    "reward": 90.955056,
    "length": 64,
    "time": 101058.12412,
    "actor_loss": -57.09341812133789,
    "critic_loss": 11.749066352844238,
    "ent_coef": 0.07887003570795059,
    "learning_rate": 0.001
  },
  {
    "episode": 6600,
    "reward": 88.79411,
    "length": 67,
    "time": 101070.547826,
    "actor_loss": -66.9233627319336,
    "critic_loss": 6.952670574188232,
    "ent_coef": 0.07567604631185532,
    "learning_rate": 0.001
  },
  {
    "episode": 6601,
    "reward": 89.955725,
    "length": 65,
    "time": 101082.432102,
    "actor_loss": -67.27804565429688,
    "critic_loss": 15.392403602600098,
    "ent_coef": 0.07457032799720764,
    "learning_rate": 0.001
  },
  {
    "episode": 6602,
    "reward": 89.776103,
    "length": 66,
    "time": 101094.220196,
    "actor_loss": -61.72629928588867,
    "critic_loss": 8.877270698547363,
    "ent_coef": 0.07647683471441269,
    "learning_rate": 0.001
  },
  {
    "episode": 6603,
    "reward": 88.218101,
    "length": 73,
    "time": 101108.714609,
    "actor_loss": -63.41764831542969,
    "critic_loss": 12.514110565185547,
    "ent_coef": 0.07730294018983841,
    "learning_rate": 0.001
  },
  {
    "episode": 6604,
    "reward": 88.612725,
    "length": 71,
    "time": 101120.982921,
    "actor_loss": -72.94283294677734,
    "critic_loss": 17.409896850585938,
    "ent_coef": 0.07732483744621277,
    "learning_rate": 0.001
  },
  {
    "episode": 6605,
    "reward": 89.622902,
    "length": 67,
    "time": 101135.043364,
    "actor_loss": -68.43302917480469,
    "critic_loss": 19.550474166870117,
    "ent_coef": 0.0744868814945221,
    "learning_rate": 0.001
  },
  {
    "episode": 6606,
    "reward": 89.782179,
    "length": 65,
    "time": 101147.971217,
    "actor_loss": -67.99351501464844,
    "critic_loss": 6.70853328704834,
    "ent_coef": 0.07223082333803177,
    "learning_rate": 0.001
  },
  {
    "episode": 6607,
    "reward": 89.43163,
    "length": 66,
    "time": 101160.215897,
    "actor_loss": -62.71984100341797,
    "critic_loss": 25.481441497802734,
    "ent_coef": 0.07447740435600281,
    "learning_rate": 0.001
  },
  {
    "episode": 6608,
    "reward": 90.426677,
    "length": 64,
    "time": 101173.75806,
    "actor_loss": -70.28703308105469,
    "critic_loss": 13.674985885620117,
    "ent_coef": 0.07507245242595673,
    "learning_rate": 0.001
  },
  {
    "episode": 6609,
    "reward": 88.717484,
    "length": 67,
    "time": 101185.622887,
    "actor_loss": -64.12138366699219,
    "critic_loss": 7.963184833526611,
    "ent_coef": 0.07313365489244461,
    "learning_rate": 0.001
  },
  {
    "episode": 6610,
    "reward": 88.174913,
    "length": 69,
    "time": 101199.611039,
    "actor_loss": -57.79552459716797,
    "critic_loss": 4.871157646179199,
    "ent_coef": 0.07021772116422653,
    "learning_rate": 0.001
  },
  {
    "episode": 6611,
    "reward": 89.009433,
    "length": 70,
    "time": 101214.924165,
    "actor_loss": -65.90177917480469,
    "critic_loss": 8.7802734375,
    "ent_coef": 0.06778135150671005,
    "learning_rate": 0.001
  },
  {
    "episode": 6612,
    "reward": 90.35786,
    "length": 64,
    "time": 101228.827329,
    "actor_loss": -64.89659118652344,
    "critic_loss": 4.646000862121582,
    "ent_coef": 0.07183955609798431,
    "learning_rate": 0.001
  },
  {
    "episode": 6613,
    "reward": 90.768161,
    "length": 63,
    "time": 101242.586675,
    "actor_loss": -62.767181396484375,
    "critic_loss": 4.254273414611816,
    "ent_coef": 0.07383669167757034,
    "learning_rate": 0.001
  },
  {
    "episode": 6614,
    "reward": 89.56257,
    "length": 67,
    "time": 101254.999613,
    "actor_loss": -65.28453063964844,
    "critic_loss": 21.531513214111328,
    "ent_coef": 0.07247239351272583,
    "learning_rate": 0.001
  },
  {
    "episode": 6615,
    "reward": 90.389268,
    "length": 65,
    "time": 101268.371495,
    "actor_loss": -66.28137969970703,
    "critic_loss": 13.580877304077148,
    "ent_coef": 0.07373704761266708,
    "learning_rate": 0.001
  },
  {
    "episode": 6616,
    "reward": 90.326707,
    "length": 64,
    "time": 101281.493014,
    "actor_loss": -67.91500091552734,
    "critic_loss": 126.35530090332031,
    "ent_coef": 0.07402602583169937,
    "learning_rate": 0.001
  },
  {
    "episode": 6617,
    "reward": 90.102439,
    "length": 66,
    "time": 101294.079559,
    "actor_loss": -58.57280349731445,
    "critic_loss": 7.602962493896484,
    "ent_coef": 0.07533986866474152,
    "learning_rate": 0.001
  },
  {
    "episode": 6618,
    "reward": 88.924868,
    "length": 67,
    "time": 101306.805975,
    "actor_loss": -62.909061431884766,
    "critic_loss": 4.920629501342773,
    "ent_coef": 0.0727403461933136,
    "learning_rate": 0.001
  },
  {
    "episode": 6619,
    "reward": 88.964654,
    "length": 69,
    "time": 101318.850159,
    "actor_loss": -66.49239349365234,
    "critic_loss": 68.2701644897461,
    "ent_coef": 0.07151598483324051,
    "learning_rate": 0.001
  },
  {
    "episode": 6620,
    "reward": 87.868088,
    "length": 69,
    "time": 101333.380961,
    "actor_loss": -63.42396545410156,
    "critic_loss": 12.20925521850586,
    "ent_coef": 0.06920905411243439,
    "learning_rate": 0.001
  },
  {
    "episode": 6621,
    "reward": 88.040298,
    "length": 71,
    "time": 101345.926897,
    "actor_loss": -70.04305267333984,
    "critic_loss": 30.534399032592773,
    "ent_coef": 0.06925322860479355,
    "learning_rate": 0.001
  },
  {
    "episode": 6622,
    "reward": 71.664831,
    "length": 105,
    "time": 101363.405549,
    "actor_loss": -64.02247619628906,
    "critic_loss": 8.051902770996094,
    "ent_coef": 0.06690391898155212,
    "learning_rate": 0.001
  },
  {
    "episode": 6623,
    "reward": 84.331901,
    "length": 78,
    "time": 101379.606704,
    "actor_loss": -70.72866821289062,
    "critic_loss": 36.835304260253906,
    "ent_coef": 0.06610731035470963,
    "learning_rate": 0.001
  },
  {
    "episode": 6624,
    "reward": 88.775085,
    "length": 69,
    "time": 101392.096657,
    "actor_loss": -64.11785125732422,
    "critic_loss": 52.075965881347656,
    "ent_coef": 0.0667324811220169,
    "learning_rate": 0.001
  },
  {
    "episode": 6625,
    "reward": 88.292322,
    "length": 68,
    "time": 101406.508867,
    "actor_loss": -58.187835693359375,
    "critic_loss": 57.00135803222656,
    "ent_coef": 0.0639907494187355,
    "learning_rate": 0.001
  },
  {
    "episode": 6626,
    "reward": 85.949835,
    "length": 76,
    "time": 101420.298436,
    "actor_loss": -64.87476348876953,
    "critic_loss": 22.851158142089844,
    "ent_coef": 0.0626613050699234,
    "learning_rate": 0.001
  },
  {
    "episode": 6627,
    "reward": 88.215417,
    "length": 69,
    "time": 101435.340509,
    "actor_loss": -64.7318115234375,
    "critic_loss": 37.60211181640625,
    "ent_coef": 0.06064620614051819,
    "learning_rate": 0.001
  },
  {
    "episode": 6628,
    "reward": 89.650018,
    "length": 68,
    "time": 101448.467366,
    "actor_loss": -66.45802307128906,
    "critic_loss": 9.05795669555664,
    "ent_coef": 0.06053279712796211,
    "learning_rate": 0.001
  },
  {
    "episode": 6629,
    "reward": 81.087524,
    "length": 81,
    "time": 101462.212024,
    "actor_loss": -69.378173828125,
    "critic_loss": 16.335189819335938,
    "ent_coef": 0.061341263353824615,
    "learning_rate": 0.001
  },
  {
    "episode": 6630,
    "reward": 89.73394,
    "length": 66,
    "time": 101474.704868,
    "actor_loss": -68.22308349609375,
    "critic_loss": 24.65999984741211,
    "ent_coef": 0.06508669257164001,
    "learning_rate": 0.001
  },
  {
    "episode": 6631,
    "reward": 85.409915,
    "length": 77,
    "time": 101488.105553,
    "actor_loss": -65.58807373046875,
    "critic_loss": 17.213973999023438,
    "ent_coef": 0.06519309431314468,
    "learning_rate": 0.001
  },
  {
    "episode": 6632,
    "reward": 88.938042,
    "length": 68,
    "time": 101501.087572,
    "actor_loss": -67.03106689453125,
    "critic_loss": 17.45067596435547,
    "ent_coef": 0.06731158494949341,
    "learning_rate": 0.001
  },
  {
    "episode": 6633,
    "reward": 90.949591,
    "length": 64,
    "time": 101515.760184,
    "actor_loss": -62.042884826660156,
    "critic_loss": 13.829753875732422,
    "ent_coef": 0.0703609511256218,
    "learning_rate": 0.001
  },
  {
    "episode": 6634,
    "reward": 88.81845,
    "length": 69,
    "time": 101527.751473,
    "actor_loss": -62.108795166015625,
    "critic_loss": 13.43776798248291,
    "ent_coef": 0.07030946761369705,
    "learning_rate": 0.001
  },
  {
    "episode": 6635,
    "reward": 82.105351,
    "length": 82,
    "time": 101541.33976,
    "actor_loss": -69.19303894042969,
    "critic_loss": 71.14057159423828,
    "ent_coef": 0.07074008136987686,
    "learning_rate": 0.001
  },
  {
    "episode": 6636,
    "reward": 90.852889,
    "length": 64,
    "time": 101553.47825,
    "actor_loss": -63.3553581237793,
    "critic_loss": 64.7856216430664,
    "ent_coef": 0.07382208108901978,
    "learning_rate": 0.001
  },
  {
    "episode": 6637,
    "reward": 89.613689,
    "length": 65,
    "time": 101566.234854,
    "actor_loss": -60.216064453125,
    "critic_loss": 6.207388401031494,
    "ent_coef": 0.07344235479831696,
    "learning_rate": 0.001
  },
  {
    "episode": 6638,
    "reward": 90.481841,
    "length": 64,
    "time": 101580.182186,
    "actor_loss": -63.30301284790039,
    "critic_loss": 66.26046752929688,
    "ent_coef": 0.07506536692380905,
    "learning_rate": 0.001
  },
  {
    "episode": 6639,
    "reward": 84.571998,
    "length": 79,
    "time": 101595.25632,
    "actor_loss": -68.42778015136719,
    "critic_loss": 13.48238754272461,
    "ent_coef": 0.07141758501529694,
    "learning_rate": 0.001
  },
  {
    "episode": 6640,
    "reward": 80.651381,
    "length": 86,
    "time": 101611.749788,
    "actor_loss": -65.45246124267578,
    "critic_loss": 58.28820037841797,
    "ent_coef": 0.07165919989347458,
    "learning_rate": 0.001
  },
  {
    "episode": 6641,
    "reward": 87.332145,
    "length": 73,
    "time": 101625.149421,
    "actor_loss": -62.750423431396484,
    "critic_loss": 340.0351257324219,
    "ent_coef": 0.07113516330718994,
    "learning_rate": 0.001
  },
  {
    "episode": 6642,
    "reward": 90.918839,
    "length": 62,
    "time": 101636.233121,
    "actor_loss": -62.76508712768555,
    "critic_loss": 4.984971046447754,
    "ent_coef": 0.07330349087715149,
    "learning_rate": 0.001
  },
  {
    "episode": 6643,
    "reward": 88.79946,
    "length": 68,
    "time": 101648.200752,
    "actor_loss": -65.79354095458984,
    "critic_loss": 19.02936553955078,
    "ent_coef": 0.07810255885124207,
    "learning_rate": 0.001
  },
  {
    "episode": 6644,
    "reward": 85.657982,
    "length": 75,
    "time": 101661.717323,
    "actor_loss": -62.335025787353516,
    "critic_loss": 6.94293737411499,
    "ent_coef": 0.07455886155366898,
    "learning_rate": 0.001
  },
  {
    "episode": 6645,
    "reward": 87.270463,
    "length": 72,
    "time": 101674.222533,
    "actor_loss": -63.58633804321289,
    "critic_loss": 5.457651615142822,
    "ent_coef": 0.07417722791433334,
    "learning_rate": 0.001
  },
  {
    "episode": 6646,
    "reward": 85.075679,
    "length": 76,
    "time": 101687.136201,
    "actor_loss": -59.959136962890625,
    "critic_loss": 12.0371732711792,
    "ent_coef": 0.07233305275440216,
    "learning_rate": 0.001
  },
  {
    "episode": 6647,
    "reward": 80.020144,
    "length": 88,
    "time": 101704.701902,
    "actor_loss": -70.63906860351562,
    "critic_loss": 10.842103958129883,
    "ent_coef": 0.06925582140684128,
    "learning_rate": 0.001
  },
  {
    "episode": 6648,
    "reward": 84.422018,
    "length": 78,
    "time": 101717.827017,
    "actor_loss": -68.46212768554688,
    "critic_loss": 7.749711036682129,
    "ent_coef": 0.06607981771230698,
    "learning_rate": 0.001
  },
  {
    "episode": 6649,
    "reward": 75.403237,
    "length": 96,
    "time": 101733.563143,
    "actor_loss": -64.249755859375,
    "critic_loss": 30.91489601135254,
    "ent_coef": 0.06419450044631958,
    "learning_rate": 0.001
  },
  {
    "episode": 6650,
    "reward": 81.101745,
    "length": 87,
    "time": 101747.944227,
    "actor_loss": -59.79389190673828,
    "critic_loss": 39.935791015625,
    "ent_coef": 0.0639750212430954,
    "learning_rate": 0.001
  },
  {
    "episode": 6651,
    "reward": 87.198966,
    "length": 73,
    "time": 101762.074095,
    "actor_loss": -65.23246765136719,
    "critic_loss": 36.64530563354492,
    "ent_coef": 0.05957445129752159,
    "learning_rate": 0.001
  },
  {
    "episode": 6652,
    "reward": 89.2199,
    "length": 67,
    "time": 101773.815737,
    "actor_loss": -69.92059326171875,
    "critic_loss": 6.234189987182617,
    "ent_coef": 0.06191125512123108,
    "learning_rate": 0.001
  },
  {
    "episode": 6653,
    "reward": 90.588708,
    "length": 64,
    "time": 101785.312877,
    "actor_loss": -63.14159393310547,
    "critic_loss": 6.358162879943848,
    "ent_coef": 0.06689136475324631,
    "learning_rate": 0.001
  },
  {
    "episode": 6654,
    "reward": 88.368237,
    "length": 70,
    "time": 101801.659544,
    "actor_loss": -64.34331512451172,
    "critic_loss": 17.96526336669922,
    "ent_coef": 0.06934522092342377,
    "learning_rate": 0.001
  },
  {
    "episode": 6655,
    "reward": 88.060279,
    "length": 71,
    "time": 101816.727697,
    "actor_loss": -66.53540802001953,
    "critic_loss": 69.38359069824219,
    "ent_coef": 0.06887561827898026,
    "learning_rate": 0.001
  },
  {
    "episode": 6656,
    "reward": 79.388532,
    "length": 138,
    "time": 101837.732472,
    "actor_loss": -64.62854766845703,
    "critic_loss": 14.543801307678223,
    "ent_coef": 0.07190512865781784,
    "learning_rate": 0.001
  },
  {
    "episode": 6657,
    "reward": 86.979388,
    "length": 74,
    "time": 101851.338623,
    "actor_loss": -61.08876037597656,
    "critic_loss": 14.83743667602539,
    "ent_coef": 0.07366394251585007,
    "learning_rate": 0.001
  },
  {
    "episode": 6658,
    "reward": 90.213534,
    "length": 64,
    "time": 101864.822546,
    "actor_loss": -71.16475677490234,
    "critic_loss": 26.824176788330078,
    "ent_coef": 0.07582513242959976,
    "learning_rate": 0.001
  },
  {
    "episode": 6659,
    "reward": 90.696613,
    "length": 66,
    "time": 101877.455992,
    "actor_loss": -62.8997802734375,
    "critic_loss": 13.029525756835938,
    "ent_coef": 0.07568112015724182,
    "learning_rate": 0.001
  },
  {
    "episode": 6660,
    "reward": 90.058703,
    "length": 65,
    "time": 101889.152383,
    "actor_loss": -69.96444702148438,
    "critic_loss": 312.3919982910156,
    "ent_coef": 0.07231266796588898,
    "learning_rate": 0.001
  },
  {
    "episode": 6661,
    "reward": 90.483575,
    "length": 64,
    "time": 101901.522434,
    "actor_loss": -63.556095123291016,
    "critic_loss": 25.693065643310547,
    "ent_coef": 0.07002627104520798,
    "learning_rate": 0.001
  },
  {
    "episode": 6662,
    "reward": 90.499564,
    "length": 64,
    "time": 101914.818355,
    "actor_loss": -64.65852355957031,
    "critic_loss": 56.1544303894043,
    "ent_coef": 0.06878600269556046,
    "learning_rate": 0.001
  },
  {
    "episode": 6663,
    "reward": 89.76533,
    "length": 67,
    "time": 101928.651954,
    "actor_loss": -68.30479431152344,
    "critic_loss": 15.870384216308594,
    "ent_coef": 0.06768012046813965,
    "learning_rate": 0.001
  },
  {
    "episode": 6664,
    "reward": 86.650408,
    "length": 75,
    "time": 101944.539132,
    "actor_loss": -63.46684265136719,
    "critic_loss": 103.05958557128906,
    "ent_coef": 0.06350104510784149,
    "learning_rate": 0.001
  },
  {
    "episode": 6665,
    "reward": 85.524231,
    "length": 75,
    "time": 101958.342697,
    "actor_loss": -63.47994613647461,
    "critic_loss": 5.625618934631348,
    "ent_coef": 0.06434766203165054,
    "learning_rate": 0.001
  },
  {
    "episode": 6666,
    "reward": 87.611017,
    "length": 71,
    "time": 101972.594364,
    "actor_loss": -63.5634880065918,
    "critic_loss": 57.22132110595703,
    "ent_coef": 0.06883890181779861,
    "learning_rate": 0.001
  },
  {
    "episode": 6667,
    "reward": 86.262958,
    "length": 74,
    "time": 101987.178627,
    "actor_loss": -65.24411010742188,
    "critic_loss": 6.67179536819458,
    "ent_coef": 0.0668736919760704,
    "learning_rate": 0.001
  },
  {
    "episode": 6668,
    "reward": 86.999111,
    "length": 72,
    "time": 102000.921593,
    "actor_loss": -70.24407958984375,
    "critic_loss": 91.44178009033203,
    "ent_coef": 0.06569651514291763,
    "learning_rate": 0.001
  },
  {
    "episode": 6669,
    "reward": 85.524889,
    "length": 76,
    "time": 102013.836221,
    "actor_loss": -60.411582946777344,
    "critic_loss": 6.669133186340332,
    "ent_coef": 0.06551197916269302,
    "learning_rate": 0.001
  },
  {
    "episode": 6670,
    "reward": 90.083403,
    "length": 65,
    "time": 102026.191281,
    "actor_loss": -67.29580688476562,
    "critic_loss": 68.94408416748047,
    "ent_coef": 0.06729444861412048,
    "learning_rate": 0.001
  },
  {
    "episode": 6671,
    "reward": 89.352821,
    "length": 68,
    "time": 102041.635327,
    "actor_loss": -60.44767379760742,
    "critic_loss": 2.926486015319824,
    "ent_coef": 0.0663021057844162,
    "learning_rate": 0.001
  },
  {
    "episode": 6672,
    "reward": 89.896869,
    "length": 66,
    "time": 102056.191782,
    "actor_loss": -61.741249084472656,
    "critic_loss": 51.20329284667969,
    "ent_coef": 0.06527591496706009,
    "learning_rate": 0.001
  },
  {
    "episode": 6673,
    "reward": 91.12945,
    "length": 63,
    "time": 102067.517192,
    "actor_loss": -65.63412475585938,
    "critic_loss": 15.648582458496094,
    "ent_coef": 0.06888807564973831,
    "learning_rate": 0.001
  },
  {
    "episode": 6674,
    "reward": 91.997982,
    "length": 61,
    "time": 102079.452796,
    "actor_loss": -71.79829406738281,
    "critic_loss": 117.10687255859375,
    "ent_coef": 0.06987299025058746,
    "learning_rate": 0.001
  },
  {
    "episode": 6675,
    "reward": 87.943709,
    "length": 71,
    "time": 102094.147449,
    "actor_loss": -63.180641174316406,
    "critic_loss": 44.308982849121094,
    "ent_coef": 0.06598753482103348,
    "learning_rate": 0.001
  },
  {
    "episode": 6676,
    "reward": 91.015273,
    "length": 64,
    "time": 102106.978589,
    "actor_loss": -67.88369750976562,
    "critic_loss": 35.60829544067383,
    "ent_coef": 0.06838151067495346,
    "learning_rate": 0.001
  },
  {
    "episode": 6677,
    "reward": 88.46157,
    "length": 70,
    "time": 102119.432843,
    "actor_loss": -64.36903381347656,
    "critic_loss": 5.144018173217773,
    "ent_coef": 0.06943176686763763,
    "learning_rate": 0.001
  },
  {
    "episode": 6678,
    "reward": 89.590978,
    "length": 67,
    "time": 102133.179743,
    "actor_loss": -65.59935760498047,
    "critic_loss": 19.957984924316406,
    "ent_coef": 0.07282926142215729,
    "learning_rate": 0.001
  },
  {
    "episode": 6679,
    "reward": 90.664264,
    "length": 64,
    "time": 102145.772846,
    "actor_loss": -71.16248321533203,
    "critic_loss": 12.795833587646484,
    "ent_coef": 0.07151129096746445,
    "learning_rate": 0.001
  },
  {
    "episode": 6680,
    "reward": 90.636384,
    "length": 65,
    "time": 102157.239683,
    "actor_loss": -64.978759765625,
    "critic_loss": 8.970386505126953,
    "ent_coef": 0.07190407067537308,
    "learning_rate": 0.001
  },
  {
    "episode": 6681,
    "reward": 85.336089,
    "length": 78,
    "time": 102171.872161,
    "actor_loss": -62.00699234008789,
    "critic_loss": 3.1049208641052246,
    "ent_coef": 0.06886157393455505,
    "learning_rate": 0.001
  },
  {
    "episode": 6682,
    "reward": 85.086676,
    "length": 77,
    "time": 102186.493247,
    "actor_loss": -57.2850341796875,
    "critic_loss": 7.5413126945495605,
    "ent_coef": 0.06765692681074142,
    "learning_rate": 0.001
  },
  {
    "episode": 6683,
    "reward": 89.880225,
    "length": 67,
    "time": 102198.264969,
    "actor_loss": -65.35741424560547,
    "critic_loss": 10.28318977355957,
    "ent_coef": 0.06969273835420609,
    "learning_rate": 0.001
  },
  {
    "episode": 6684,
    "reward": 88.418284,
    "length": 69,
    "time": 102212.450916,
    "actor_loss": -64.81396484375,
    "critic_loss": 20.351730346679688,
    "ent_coef": 0.06950515508651733,
    "learning_rate": 0.001
  },
  {
    "episode": 6685,
    "reward": 87.025055,
    "length": 71,
    "time": 102227.907962,
    "actor_loss": -65.85723876953125,
    "critic_loss": 7.289252758026123,
    "ent_coef": 0.07032344490289688,
    "learning_rate": 0.001
  },
  {
    "episode": 6686,
    "reward": 88.089172,
    "length": 69,
    "time": 102242.35031,
    "actor_loss": -67.71704864501953,
    "critic_loss": 21.02532958984375,
    "ent_coef": 0.07172835618257523,
    "learning_rate": 0.001
  },
  {
    "episode": 6687,
    "reward": 85.967721,
    "length": 77,
    "time": 102256.88477,
    "actor_loss": -67.91073608398438,
    "critic_loss": 39.11156463623047,
    "ent_coef": 0.07144007831811905,
    "learning_rate": 0.001
  },
  {
    "episode": 6688,
    "reward": 91.168268,
    "length": 63,
    "time": 102274.889713,
    "actor_loss": -69.53178405761719,
    "critic_loss": 6.0264573097229,
    "ent_coef": 0.07625161856412888,
    "learning_rate": 0.001
  },
  {
    "episode": 6689,
    "reward": 89.651467,
    "length": 68,
    "time": 102286.801276,
    "actor_loss": -64.69146728515625,
    "critic_loss": 8.01899528503418,
    "ent_coef": 0.07606340199708939,
    "learning_rate": 0.001
  },
  {
    "episode": 6690,
    "reward": 88.977033,
    "length": 69,
    "time": 102298.959789,
    "actor_loss": -64.94027709960938,
    "critic_loss": 38.01803207397461,
    "ent_coef": 0.07373762130737305,
    "learning_rate": 0.001
  },
  {
    "episode": 6691,
    "reward": 91.297061,
    "length": 63,
    "time": 102311.297886,
    "actor_loss": -66.46095275878906,
    "critic_loss": 16.287450790405273,
    "ent_coef": 0.07938242703676224,
    "learning_rate": 0.001
  },
  {
    "episode": 6692,
    "reward": 91.088115,
    "length": 65,
    "time": 102322.957953,
    "actor_loss": -67.52186584472656,
    "critic_loss": 3.699281930923462,
    "ent_coef": 0.08237051963806152,
    "learning_rate": 0.001
  },
  {
    "episode": 6693,
    "reward": 88.540387,
    "length": 69,
    "time": 102335.831911,
    "actor_loss": -65.51234436035156,
    "critic_loss": 12.90438461303711,
    "ent_coef": 0.0811653584241867,
    "learning_rate": 0.001
  },
  {
    "episode": 6694,
    "reward": 89.200627,
    "length": 67,
    "time": 102350.047277,
    "actor_loss": -65.42597961425781,
    "critic_loss": 8.969024658203125,
    "ent_coef": 0.07926708459854126,
    "learning_rate": 0.001
  },
  {
    "episode": 6695,
    "reward": 90.333163,
    "length": 64,
    "time": 102361.254711,
    "actor_loss": -62.47132873535156,
    "critic_loss": 84.04531860351562,
    "ent_coef": 0.07821457833051682,
    "learning_rate": 0.001
  },
  {
    "episode": 6696,
    "reward": 88.601271,
    "length": 68,
    "time": 102373.549337,
    "actor_loss": -65.58978271484375,
    "critic_loss": 52.203895568847656,
    "ent_coef": 0.0758715569972992,
    "learning_rate": 0.001
  },
  {
    "episode": 6697,
    "reward": 88.152545,
    "length": 69,
    "time": 102386.86714,
    "actor_loss": -66.54649353027344,
    "critic_loss": 6.823249816894531,
    "ent_coef": 0.0734388530254364,
    "learning_rate": 0.001
  },
  {
    "episode": 6698,
    "reward": 89.471737,
    "length": 67,
    "time": 102400.59268,
    "actor_loss": -65.80457305908203,
    "critic_loss": 30.122413635253906,
    "ent_coef": 0.07407622784376144,
    "learning_rate": 0.001
  },
  {
    "episode": 6699,
    "reward": 91.067846,
    "length": 63,
    "time": 102412.803504,
    "actor_loss": -54.95677185058594,
    "critic_loss": 15.091629028320312,
    "ent_coef": 0.07655343413352966,
    "learning_rate": 0.001
  },
  {
    "episode": 6700,
    "reward": 91.196886,
    "length": 63,
    "time": 102423.95358,
    "actor_loss": -64.53875732421875,
    "critic_loss": 13.937810897827148,
    "ent_coef": 0.08323245495557785,
    "learning_rate": 0.001
  },
  {
    "episode": 6701,
    "reward": 91.530336,
    "length": 62,
    "time": 102435.150214,
    "actor_loss": -59.943424224853516,
    "critic_loss": 6.533233642578125,
    "ent_coef": 0.0864308550953865,
    "learning_rate": 0.001
  },
  {
    "episode": 6702,
    "reward": 91.30304,
    "length": 63,
    "time": 102446.979751,
    "actor_loss": -63.371337890625,
    "critic_loss": 23.143112182617188,
    "ent_coef": 0.08631674945354462,
    "learning_rate": 0.001
  },
  {
    "episode": 6703,
    "reward": 89.646722,
    "length": 65,
    "time": 102459.513665,
    "actor_loss": -71.95616149902344,
    "critic_loss": 24.679176330566406,
    "ent_coef": 0.08351701498031616,
    "learning_rate": 0.001
  },
  {
    "episode": 6704,
    "reward": 90.873187,
    "length": 63,
    "time": 102472.661578,
    "actor_loss": -67.44747924804688,
    "critic_loss": 24.63345718383789,
    "ent_coef": 0.08279667794704437,
    "learning_rate": 0.001
  },
  {
    "episode": 6705,
    "reward": 88.791941,
    "length": 67,
    "time": 102485.230842,
    "actor_loss": -60.67104721069336,
    "critic_loss": 4.950925350189209,
    "ent_coef": 0.07943892478942871,
    "learning_rate": 0.001
  },
  {
    "episode": 6706,
    "reward": 90.452801,
    "length": 64,
    "time": 102496.642642,
    "actor_loss": -64.79408264160156,
    "critic_loss": 5.588373184204102,
    "ent_coef": 0.07717692106962204,
    "learning_rate": 0.001
  },
  {
    "episode": 6707,
    "reward": 91.2877,
    "length": 62,
    "time": 102507.740016,
    "actor_loss": -60.93275833129883,
    "critic_loss": 11.400035858154297,
    "ent_coef": 0.07643324881792068,
    "learning_rate": 0.001
  },
  {
    "episode": 6708,
    "reward": 89.410453,
    "length": 67,
    "time": 102519.626091,
    "actor_loss": -64.84188842773438,
    "critic_loss": 8.977460861206055,
    "ent_coef": 0.07233529537916183,
    "learning_rate": 0.001
  },
  {
    "episode": 6709,
    "reward": 90.749849,
    "length": 64,
    "time": 102532.786023,
    "actor_loss": -64.86376190185547,
    "critic_loss": 7.970297813415527,
    "ent_coef": 0.07101576775312424,
    "learning_rate": 0.001
  },
  {
    "episode": 6710,
    "reward": 89.889755,
    "length": 65,
    "time": 102545.223248,
    "actor_loss": -59.86651611328125,
    "critic_loss": 21.88336944580078,
    "ent_coef": 0.07036769390106201,
    "learning_rate": 0.001
  },
  {
    "episode": 6711,
    "reward": 88.497706,
    "length": 71,
    "time": 102557.851683,
    "actor_loss": -63.554718017578125,
    "critic_loss": 66.46377563476562,
    "ent_coef": 0.06574775278568268,
    "learning_rate": 0.001
  },
  {
    "episode": 6712,
    "reward": 86.368086,
    "length": 75,
    "time": 102571.507954,
    "actor_loss": -64.02897644042969,
    "critic_loss": 15.834959030151367,
    "ent_coef": 0.06379096955060959,
    "learning_rate": 0.001
  },
  {
    "episode": 6713,
    "reward": 89.930013,
    "length": 64,
    "time": 102585.906646,
    "actor_loss": -65.56861877441406,
    "critic_loss": 27.391101837158203,
    "ent_coef": 0.06238714978098869,
    "learning_rate": 0.001
  },
  {
    "episode": 6714,
    "reward": 91.907897,
    "length": 61,
    "time": 102598.769999,
    "actor_loss": -64.10450744628906,
    "critic_loss": 4.419272422790527,
    "ent_coef": 0.06544455140829086,
    "learning_rate": 0.001
  },
  {
    "episode": 6715,
    "reward": 91.488366,
    "length": 62,
    "time": 102617.452257,
    "actor_loss": -71.09059143066406,
    "critic_loss": 7.288708686828613,
    "ent_coef": 0.06651581823825836,
    "learning_rate": 0.001
  },
  {
    "episode": 6716,
    "reward": 87.72776,
    "length": 72,
    "time": 102631.069286,
    "actor_loss": -62.58684539794922,
    "critic_loss": 17.97507667541504,
    "ent_coef": 0.06211024522781372,
    "learning_rate": 0.001
  },
  {
    "episode": 6717,
    "reward": 89.438072,
    "length": 66,
    "time": 102642.665981,
    "actor_loss": -65.16155242919922,
    "critic_loss": 67.15099334716797,
    "ent_coef": 0.059908054769039154,
    "learning_rate": 0.001
  },
  {
    "episode": 6718,
    "reward": 87.179835,
    "length": 75,
    "time": 102656.430709,
    "actor_loss": -69.82354736328125,
    "critic_loss": 9.295228958129883,
    "ent_coef": 0.06209820508956909,
    "learning_rate": 0.001
  },
  {
    "episode": 6719,
    "reward": 87.88558,
    "length": 71,
    "time": 102668.676628,
    "actor_loss": -66.08769226074219,
    "critic_loss": 12.596402168273926,
    "ent_coef": 0.06104175001382828,
    "learning_rate": 0.001
  },
  {
    "episode": 6720,
    "reward": 89.043728,
    "length": 66,
    "time": 102681.29583,
    "actor_loss": -62.86479568481445,
    "critic_loss": 12.450613021850586,
    "ent_coef": 0.0608634278178215,
    "learning_rate": 0.001
  },
  {
    "episode": 6721,
    "reward": 90.693475,
    "length": 62,
    "time": 102693.063781,
    "actor_loss": -66.88084411621094,
    "critic_loss": 13.276698112487793,
    "ent_coef": 0.0657535046339035,
    "learning_rate": 0.001
  },
  {
    "episode": 6722,
    "reward": 91.058412,
    "length": 63,
    "time": 102706.723415,
    "actor_loss": -68.22550964355469,
    "critic_loss": 3.3058018684387207,
    "ent_coef": 0.06768433004617691,
    "learning_rate": 0.001
  },
  {
    "episode": 6723,
    "reward": 89.493284,
    "length": 65,
    "time": 102720.941928,
    "actor_loss": -66.28961181640625,
    "critic_loss": 4.179463863372803,
    "ent_coef": 0.0678982064127922,
    "learning_rate": 0.001
  },
  {
    "episode": 6724,
    "reward": 89.239321,
    "length": 66,
    "time": 102733.997158,
    "actor_loss": -68.60619354248047,
    "critic_loss": 11.013124465942383,
    "ent_coef": 0.06659898906946182,
    "learning_rate": 0.001
  },
  {
    "episode": 6725,
    "reward": 90.581797,
    "length": 63,
    "time": 102748.854762,
    "actor_loss": -66.34769439697266,
    "critic_loss": 6.744009494781494,
    "ent_coef": 0.07029519230127335,
    "learning_rate": 0.001
  },
  {
    "episode": 6726,
    "reward": 90.402997,
    "length": 64,
    "time": 102763.620103,
    "actor_loss": -66.53999328613281,
    "critic_loss": 16.351909637451172,
    "ent_coef": 0.07067295163869858,
    "learning_rate": 0.001
  },
  {
    "episode": 6727,
    "reward": 87.635098,
    "length": 76,
    "time": 102776.337317,
    "actor_loss": -67.90098571777344,
    "critic_loss": 11.025382995605469,
    "ent_coef": 0.07207687199115753,
    "learning_rate": 0.001
  },
  {
    "episode": 6728,
    "reward": 89.454935,
    "length": 65,
    "time": 102790.827282,
    "actor_loss": -67.95056915283203,
    "critic_loss": 7.060521125793457,
    "ent_coef": 0.07172032445669174,
    "learning_rate": 0.001
  },
  {
    "episode": 6729,
    "reward": 86.924225,
    "length": 70,
    "time": 102803.38142,
    "actor_loss": -64.28558349609375,
    "critic_loss": 100.26610565185547,
    "ent_coef": 0.0674513652920723,
    "learning_rate": 0.001
  },
  {
    "episode": 6730,
    "reward": 84.739773,
    "length": 77,
    "time": 102816.461103,
    "actor_loss": -64.31787872314453,
    "critic_loss": 8.959771156311035,
    "ent_coef": 0.06470799446105957,
    "learning_rate": 0.001
  },
  {
    "episode": 6731,
    "reward": 90.502761,
    "length": 65,
    "time": 102828.744733,
    "actor_loss": -62.153587341308594,
    "critic_loss": 13.747817993164062,
    "ent_coef": 0.06453153491020203,
    "learning_rate": 0.001
  },
  {
    "episode": 6732,
    "reward": 90.430694,
    "length": 65,
    "time": 102841.076897,
    "actor_loss": -66.36155700683594,
    "critic_loss": 36.50856018066406,
    "ent_coef": 0.06649374961853027,
    "learning_rate": 0.001
  },
  {
    "episode": 6733,
    "reward": 85.947667,
    "length": 74,
    "time": 102855.219173,
    "actor_loss": -65.1950454711914,
    "critic_loss": 7.220113754272461,
    "ent_coef": 0.06311147660017014,
    "learning_rate": 0.001
  },
  {
    "episode": 6734,
    "reward": 83.729693,
    "length": 77,
    "time": 102868.84481,
    "actor_loss": -66.35493469238281,
    "critic_loss": 21.022045135498047,
    "ent_coef": 0.059521619230508804,
    "learning_rate": 0.001
  },
  {
    "episode": 6735,
    "reward": 87.974464,
    "length": 71,
    "time": 102884.64357,
    "actor_loss": -66.35143280029297,
    "critic_loss": 148.18899536132812,
    "ent_coef": 0.06057053431868553,
    "learning_rate": 0.001
  },
  {
    "episode": 6736,
    "reward": 86.883267,
    "length": 75,
    "time": 102900.157758,
    "actor_loss": -67.70448303222656,
    "critic_loss": 3.8227767944335938,
    "ent_coef": 0.06133594363927841,
    "learning_rate": 0.001
  },
  {
    "episode": 6737,
    "reward": 90.398811,
    "length": 65,
    "time": 102911.615999,
    "actor_loss": -70.45591735839844,
    "critic_loss": 24.495014190673828,
    "ent_coef": 0.06311047077178955,
    "learning_rate": 0.001
  },
  {
    "episode": 6738,
    "reward": 88.573059,
    "length": 70,
    "time": 102925.767229,
    "actor_loss": -69.0556411743164,
    "critic_loss": 460.69891357421875,
    "ent_coef": 0.06443116068840027,
    "learning_rate": 0.001
  },
  {
    "episode": 6739,
    "reward": 82.552407,
    "length": 85,
    "time": 102940.41135,
    "actor_loss": -70.90705871582031,
    "critic_loss": 55.377716064453125,
    "ent_coef": 0.06207728758454323,
    "learning_rate": 0.001
  },
  {
    "episode": 6740,
    "reward": 90.284828,
    "length": 65,
    "time": 102952.895957,
    "actor_loss": -70.16729736328125,
    "critic_loss": 11.177167892456055,
    "ent_coef": 0.06389546394348145,
    "learning_rate": 0.001
  },
  {
    "episode": 6741,
    "reward": 87.993796,
    "length": 75,
    "time": 102966.054172,
    "actor_loss": -66.16468811035156,
    "critic_loss": 9.610639572143555,
    "ent_coef": 0.065403513610363,
    "learning_rate": 0.001
  },
  {
    "episode": 6742,
    "reward": 88.790123,
    "length": 68,
    "time": 102984.487857,
    "actor_loss": -75.1111831665039,
    "critic_loss": 5.301702499389648,
    "ent_coef": 0.06648046523332596,
    "learning_rate": 0.001
  },
  {
    "episode": 6743,
    "reward": 90.587776,
    "length": 65,
    "time": 102996.514592,
    "actor_loss": -71.34553527832031,
    "critic_loss": 239.83460998535156,
    "ent_coef": 0.06776745617389679,
    "learning_rate": 0.001
  },
  {
    "episode": 6744,
    "reward": 86.871573,
    "length": 77,
    "time": 103009.617536,
    "actor_loss": -72.134033203125,
    "critic_loss": 17.225177764892578,
    "ent_coef": 0.06723189353942871,
    "learning_rate": 0.001
  },
  {
    "episode": 6745,
    "reward": 85.297803,
    "length": 78,
    "time": 103023.548896,
    "actor_loss": -58.415184020996094,
    "critic_loss": 31.471416473388672,
    "ent_coef": 0.06909976154565811,
    "learning_rate": 0.001
  },
  {
    "episode": 6746,
    "reward": 88.34724,
    "length": 68,
    "time": 103037.225359,
    "actor_loss": -65.57591247558594,
    "critic_loss": 11.139208793640137,
    "ent_coef": 0.07204601913690567,
    "learning_rate": 0.001
  },
  {
    "episode": 6747,
    "reward": 87.779868,
    "length": 70,
    "time": 103050.504612,
    "actor_loss": -69.22221374511719,
    "critic_loss": 5.3565168380737305,
    "ent_coef": 0.07300124317407608,
    "learning_rate": 0.001
  },
  {
    "episode": 6748,
    "reward": 89.319839,
    "length": 68,
    "time": 103064.364443,
    "actor_loss": -65.30904388427734,
    "critic_loss": 3.874122381210327,
    "ent_coef": 0.07835578918457031,
    "learning_rate": 0.001
  },
  {
    "episode": 6749,
    "reward": 89.505327,
    "length": 69,
    "time": 103079.534512,
    "actor_loss": -71.01402282714844,
    "critic_loss": 5.837881088256836,
    "ent_coef": 0.08262103796005249,
    "learning_rate": 0.001
  },
  {
    "episode": 6750,
    "reward": 86.643553,
    "length": 72,
    "time": 103092.916202,
    "actor_loss": -68.24285125732422,
    "critic_loss": 16.127635955810547,
    "ent_coef": 0.07912435382604599,
    "learning_rate": 0.001
  },
  {
    "episode": 6751,
    "reward": 76.742997,
    "length": 95,
    "time": 103110.125071,
    "actor_loss": -65.52902221679688,
    "critic_loss": 32.273719787597656,
    "ent_coef": 0.07615906745195389,
    "learning_rate": 0.001
  },
  {
    "episode": 6752,
    "reward": 88.267209,
    "length": 71,
    "time": 103123.523691,
    "actor_loss": -70.32168579101562,
    "critic_loss": 4.900291442871094,
    "ent_coef": 0.07760479301214218,
    "learning_rate": 0.001
  },
  {
    "episode": 6753,
    "reward": 87.23149,
    "length": 71,
    "time": 103135.871743,
    "actor_loss": -67.66429138183594,
    "critic_loss": 11.562969207763672,
    "ent_coef": 0.07778461277484894,
    "learning_rate": 0.001
  },
  {
    "episode": 6754,
    "reward": 86.607664,
    "length": 75,
    "time": 103148.617331,
    "actor_loss": -60.33477783203125,
    "critic_loss": 4.732240200042725,
    "ent_coef": 0.07999259233474731,
    "learning_rate": 0.001
  },
  {
    "episode": 6755,
    "reward": 88.999763,
    "length": 69,
    "time": 103163.622946,
    "actor_loss": -66.73503112792969,
    "critic_loss": 17.56244659423828,
    "ent_coef": 0.0762653648853302,
    "learning_rate": 0.001
  },
  {
    "episode": 6756,
    "reward": 88.60005,
    "length": 69,
    "time": 103177.410634,
    "actor_loss": -68.21711730957031,
    "critic_loss": 15.482030868530273,
    "ent_coef": 0.07829102873802185,
    "learning_rate": 0.001
  },
  {
    "episode": 6757,
    "reward": 91.284996,
    "length": 62,
    "time": 103192.500927,
    "actor_loss": -71.3448486328125,
    "critic_loss": 11.04277515411377,
    "ent_coef": 0.07903645932674408,
    "learning_rate": 0.001
  },
  {
    "episode": 6758,
    "reward": 90.943863,
    "length": 64,
    "time": 103204.704994,
    "actor_loss": -62.98357391357422,
    "critic_loss": 15.610532760620117,
    "ent_coef": 0.07701169699430466,
    "learning_rate": 0.001
  },
  {
    "episode": 6759,
    "reward": 86.98906,
    "length": 73,
    "time": 103219.537271,
    "actor_loss": -71.0284194946289,
    "critic_loss": 12.514571189880371,
    "ent_coef": 0.07759411633014679,
    "learning_rate": 0.001
  },
  {
    "episode": 6760,
    "reward": 90.984821,
    "length": 63,
    "time": 103230.921661,
    "actor_loss": -63.869834899902344,
    "critic_loss": 18.16313362121582,
    "ent_coef": 0.07545337080955505,
    "learning_rate": 0.001
  },
  {
    "episode": 6761,
    "reward": 91.158699,
    "length": 63,
    "time": 103244.489772,
    "actor_loss": -59.579124450683594,
    "critic_loss": 51.561622619628906,
    "ent_coef": 0.0745091587305069,
    "learning_rate": 0.001
  },
  {
    "episode": 6762,
    "reward": 89.532573,
    "length": 65,
    "time": 103255.850995,
    "actor_loss": -65.587158203125,
    "critic_loss": 74.019775390625,
    "ent_coef": 0.07430300861597061,
    "learning_rate": 0.001
  },
  {
    "episode": 6763,
    "reward": 90.946997,
    "length": 64,
    "time": 103270.825302,
    "actor_loss": -67.241455078125,
    "critic_loss": 8.034832000732422,
    "ent_coef": 0.07487496733665466,
    "learning_rate": 0.001
  },
  {
    "episode": 6764,
    "reward": 87.310303,
    "length": 75,
    "time": 103285.436106,
    "actor_loss": -58.50157928466797,
    "critic_loss": 7.189504146575928,
    "ent_coef": 0.07335272431373596,
    "learning_rate": 0.001
  },
  {
    "episode": 6765,
    "reward": 88.695149,
    "length": 68,
    "time": 103301.679429,
    "actor_loss": -67.11253356933594,
    "critic_loss": 28.921287536621094,
    "ent_coef": 0.07407509535551071,
    "learning_rate": 0.001
  },
  {
    "episode": 6766,
    "reward": 87.774682,
    "length": 70,
    "time": 103316.754414,
    "actor_loss": -68.22705841064453,
    "critic_loss": 11.582953453063965,
    "ent_coef": 0.07560843229293823,
    "learning_rate": 0.001
  },
  {
    "episode": 6767,
    "reward": 89.486714,
    "length": 66,
    "time": 103329.636169,
    "actor_loss": -66.81598663330078,
    "critic_loss": 11.913883209228516,
    "ent_coef": 0.07578324526548386,
    "learning_rate": 0.001
  },
  {
    "episode": 6768,
    "reward": 88.593722,
    "length": 70,
    "time": 103343.593972,
    "actor_loss": -61.78429412841797,
    "critic_loss": 34.825462341308594,
    "ent_coef": 0.07504431903362274,
    "learning_rate": 0.001
  },
  {
    "episode": 6769,
    "reward": 87.911934,
    "length": 70,
    "time": 103357.188675,
    "actor_loss": -65.1251220703125,
    "critic_loss": 27.22127914428711,
    "ent_coef": 0.07716794312000275,
    "learning_rate": 0.001
  },
  {
    "episode": 6770,
    "reward": 88.662606,
    "length": 68,
    "time": 103370.311158,
    "actor_loss": -64.6837158203125,
    "critic_loss": 34.815574645996094,
    "ent_coef": 0.07845506817102432,
    "learning_rate": 0.001
  },
  {
    "episode": 6771,
    "reward": 90.511846,
    "length": 64,
    "time": 103384.597986,
    "actor_loss": -66.91761779785156,
    "critic_loss": 70.64921569824219,
    "ent_coef": 0.07875597476959229,
    "learning_rate": 0.001
  },
  {
    "episode": 6772,
    "reward": 87.814701,
    "length": 69,
    "time": 103400.600891,
    "actor_loss": -65.39757537841797,
    "critic_loss": 48.71978759765625,
    "ent_coef": 0.07928156107664108,
    "learning_rate": 0.001
  },
  {
    "episode": 6773,
    "reward": 90.673475,
    "length": 64,
    "time": 103412.830081,
    "actor_loss": -69.5924072265625,
    "critic_loss": 4.432737350463867,
    "ent_coef": 0.07803439348936081,
    "learning_rate": 0.001
  },
  {
    "episode": 6774,
    "reward": 89.372801,
    "length": 70,
    "time": 103425.241451,
    "actor_loss": -66.2351303100586,
    "critic_loss": 3.4648406505584717,
    "ent_coef": 0.08003509789705276,
    "learning_rate": 0.001
  },
  {
    "episode": 6775,
    "reward": 87.945749,
    "length": 71,
    "time": 103439.667053,
    "actor_loss": -62.63892364501953,
    "critic_loss": 17.626312255859375,
    "ent_coef": 0.0791381299495697,
    "learning_rate": 0.001
  },
  {
    "episode": 6776,
    "reward": 90.939792,
    "length": 63,
    "time": 103452.941727,
    "actor_loss": -68.07164001464844,
    "critic_loss": 13.359365463256836,
    "ent_coef": 0.07741203159093857,
    "learning_rate": 0.001
  },
  {
    "episode": 6777,
    "reward": 89.481793,
    "length": 68,
    "time": 103464.770881,
    "actor_loss": -62.39634323120117,
    "critic_loss": 10.78692626953125,
    "ent_coef": 0.07670368254184723,
    "learning_rate": 0.001
  },
  {
    "episode": 6778,
    "reward": 89.034379,
    "length": 67,
    "time": 103478.235874,
    "actor_loss": -62.600196838378906,
    "critic_loss": 10.016742706298828,
    "ent_coef": 0.07618951797485352,
    "learning_rate": 0.001
  },
  {
    "episode": 6779,
    "reward": 87.640508,
    "length": 71,
    "time": 103492.124544,
    "actor_loss": -65.71226501464844,
    "critic_loss": 2.4948601722717285,
    "ent_coef": 0.07336734235286713,
    "learning_rate": 0.001
  },
  {
    "episode": 6780,
    "reward": 88.097597,
    "length": 68,
    "time": 103508.335323,
    "actor_loss": -68.30841064453125,
    "critic_loss": 23.004812240600586,
    "ent_coef": 0.07432933896780014,
    "learning_rate": 0.001
  },
  {
    "episode": 6781,
    "reward": 90.369597,
    "length": 64,
    "time": 103521.154532,
    "actor_loss": -63.71846389770508,
    "critic_loss": 21.143062591552734,
    "ent_coef": 0.07515893876552582,
    "learning_rate": 0.001
  },
  {
    "episode": 6782,
    "reward": 89.863866,
    "length": 66,
    "time": 103535.091794,
    "actor_loss": -65.24810791015625,
    "critic_loss": 16.669435501098633,
    "ent_coef": 0.07723788917064667,
    "learning_rate": 0.001
  },
  {
    "episode": 6783,
    "reward": 88.463712,
    "length": 71,
    "time": 103549.132412,
    "actor_loss": -59.01525115966797,
    "critic_loss": 13.720121383666992,
    "ent_coef": 0.07512127608060837,
    "learning_rate": 0.001
  },
  {
    "episode": 6784,
    "reward": 91.034647,
    "length": 65,
    "time": 103561.772894,
    "actor_loss": -60.07857131958008,
    "critic_loss": 8.950810432434082,
    "ent_coef": 0.08063207566738129,
    "learning_rate": 0.001
  },
  {
    "episode": 6785,
    "reward": 91.01694,
    "length": 63,
    "time": 103574.318059,
    "actor_loss": -64.54092407226562,
    "critic_loss": 63.76377868652344,
    "ent_coef": 0.08236826211214066,
    "learning_rate": 0.001
  },
  {
    "episode": 6786,
    "reward": -154.42427,
    "length": 91,
    "time": 103591.662156,
    "actor_loss": -65.98609924316406,
    "critic_loss": 27.946483612060547,
    "ent_coef": 0.08024546504020691,
    "learning_rate": 0.001
  },
  {
    "episode": 6787,
    "reward": 94.459315,
    "length": 78,
    "time": 103607.07739,
    "actor_loss": -60.51264190673828,
    "critic_loss": 5.5383734703063965,
    "ent_coef": 0.0831519365310669,
    "learning_rate": 0.001
  },
  {
    "episode": 6788,
    "reward": 89.683124,
    "length": 69,
    "time": 103618.899159,
    "actor_loss": -67.00796508789062,
    "critic_loss": 12.50770378112793,
    "ent_coef": 0.08372684568166733,
    "learning_rate": 0.001
  },
  {
    "episode": 6789,
    "reward": 89.915223,
    "length": 65,
    "time": 103631.426846,
    "actor_loss": -70.05278015136719,
    "critic_loss": 9.819429397583008,
    "ent_coef": 0.08141829073429108,
    "learning_rate": 0.001
  },
  {
    "episode": 6790,
    "reward": 88.787694,
    "length": 68,
    "time": 103643.440812,
    "actor_loss": -69.87100219726562,
    "critic_loss": 3.7785069942474365,
    "ent_coef": 0.08263246715068817,
    "learning_rate": 0.001
  },
  {
    "episode": 6791,
    "reward": 90.668207,
    "length": 65,
    "time": 103658.296658,
    "actor_loss": -61.40620422363281,
    "critic_loss": 10.8265962600708,
    "ent_coef": 0.08622735738754272,
    "learning_rate": 0.001
  },
  {
    "episode": 6792,
    "reward": 90.224996,
    "length": 63,
    "time": 103669.803831,
    "actor_loss": -63.87910461425781,
    "critic_loss": 24.66567611694336,
    "ent_coef": 0.08932162821292877,
    "learning_rate": 0.001
  },
  {
    "episode": 6793,
    "reward": 84.105889,
    "length": 80,
    "time": 103684.080886,
    "actor_loss": -64.86775207519531,
    "critic_loss": 32.88745880126953,
    "ent_coef": 0.08749610185623169,
    "learning_rate": 0.001
  },
  {
    "episode": 6794,
    "reward": 90.150264,
    "length": 64,
    "time": 103696.651672,
    "actor_loss": -65.67469787597656,
    "critic_loss": 7.706318378448486,
    "ent_coef": 0.08535139262676239,
    "learning_rate": 0.001
  },
  {
    "episode": 6795,
    "reward": 85.180232,
    "length": 78,
    "time": 103710.781078,
    "actor_loss": -63.494232177734375,
    "critic_loss": 12.351308822631836,
    "ent_coef": 0.07994720339775085,
    "learning_rate": 0.001
  },
  {
    "episode": 6796,
    "reward": 82.31067,
    "length": 82,
    "time": 103726.329137,
    "actor_loss": -68.52591705322266,
    "critic_loss": 38.51430130004883,
    "ent_coef": 0.07467273622751236,
    "learning_rate": 0.001
  },
  {
    "episode": 6797,
    "reward": 85.597215,
    "length": 75,
    "time": 103743.111004,
    "actor_loss": -66.55984497070312,
    "critic_loss": 11.466856956481934,
    "ent_coef": 0.07053936272859573,
    "learning_rate": 0.001
  },
  {
    "episode": 6798,
    "reward": 82.61185,
    "length": 83,
    "time": 103756.673537,
    "actor_loss": -63.06507110595703,
    "critic_loss": 9.137571334838867,
    "ent_coef": 0.0696711391210556,
    "learning_rate": 0.001
  },
  {
    "episode": 6799,
    "reward": 90.197301,
    "length": 66,
    "time": 103771.358845,
    "actor_loss": -61.701961517333984,
    "critic_loss": 28.037193298339844,
    "ent_coef": 0.0715264230966568,
    "learning_rate": 0.001
  },
  {
    "episode": 6800,
    "reward": 79.511976,
    "length": 88,
    "time": 103787.317788,
    "actor_loss": -65.85769653320312,
    "critic_loss": 9.381025314331055,
    "ent_coef": 0.07013716548681259,
    "learning_rate": 0.001
  },
  {
    "episode": 6801,
    "reward": 89.608404,
    "length": 65,
    "time": 103799.336953,
    "actor_loss": -61.269737243652344,
    "critic_loss": 22.68583106994629,
    "ent_coef": 0.06980156153440475,
    "learning_rate": 0.001
  },
  {
    "episode": 6802,
    "reward": 86.63721,
    "length": 75,
    "time": 103813.802167,
    "actor_loss": -67.55976867675781,
    "critic_loss": 9.730157852172852,
    "ent_coef": 0.07438994944095612,
    "learning_rate": 0.001
  },
  {
    "episode": 6803,
    "reward": 86.587772,
    "length": 73,
    "time": 103827.148634,
    "actor_loss": -68.931396484375,
    "critic_loss": 107.8485336303711,
    "ent_coef": 0.07325904071331024,
    "learning_rate": 0.001
  },
  {
    "episode": 6804,
    "reward": 85.26036,
    "length": 76,
    "time": 103840.110763,
    "actor_loss": -60.830421447753906,
    "critic_loss": 52.54269027709961,
    "ent_coef": 0.06984592974185944,
    "learning_rate": 0.001
  },
  {
    "episode": 6805,
    "reward": 68.890294,
    "length": 112,
    "time": 103860.287871,
    "actor_loss": -61.18860626220703,
    "critic_loss": 4.250126838684082,
    "ent_coef": 0.06358344852924347,
    "learning_rate": 0.001
  },
  {
    "episode": 6806,
    "reward": 87.473814,
    "length": 72,
    "time": 103872.710116,
    "actor_loss": -63.08356857299805,
    "critic_loss": 6.953848361968994,
    "ent_coef": 0.06618139892816544,
    "learning_rate": 0.001
  },
  {
    "episode": 6807,
    "reward": 86.249616,
    "length": 79,
    "time": 103886.260417,
    "actor_loss": -61.126102447509766,
    "critic_loss": 5.502837181091309,
    "ent_coef": 0.07375344634056091,
    "learning_rate": 0.001
  },
  {
    "episode": 6808,
    "reward": 89.447834,
    "length": 67,
    "time": 103897.972843,
    "actor_loss": -64.45135498046875,
    "critic_loss": 33.033355712890625,
    "ent_coef": 0.07768737524747849,
    "learning_rate": 0.001
  },
  {
    "episode": 6809,
    "reward": 85.846759,
    "length": 75,
    "time": 103911.393784,
    "actor_loss": -66.33406066894531,
    "critic_loss": 12.59521484375,
    "ent_coef": 0.07562318444252014,
    "learning_rate": 0.001
  },
  {
    "episode": 6810,
    "reward": 81.575574,
    "length": 83,
    "time": 103926.169992,
    "actor_loss": -66.25021362304688,
    "critic_loss": 12.614432334899902,
    "ent_coef": 0.07754586637020111,
    "learning_rate": 0.001
  },
  {
    "episode": 6811,
    "reward": 86.616878,
    "length": 73,
    "time": 103939.453141,
    "actor_loss": -66.90017700195312,
    "critic_loss": 15.174837112426758,
    "ent_coef": 0.08077196031808853,
    "learning_rate": 0.001
  },
  {
    "episode": 6812,
    "reward": 88.323821,
    "length": 68,
    "time": 103952.846686,
    "actor_loss": -60.74272155761719,
    "critic_loss": 3.448192834854126,
    "ent_coef": 0.08051535487174988,
    "learning_rate": 0.001
  },
  {
    "episode": 6813,
    "reward": 85.218757,
    "length": 75,
    "time": 103966.412742,
    "actor_loss": -71.52696228027344,
    "critic_loss": 15.616695404052734,
    "ent_coef": 0.0788077637553215,
    "learning_rate": 0.001
  },
  {
    "episode": 6814,
    "reward": 82.291018,
    "length": 84,
    "time": 103981.477604,
    "actor_loss": -70.03033447265625,
    "critic_loss": 20.922977447509766,
    "ent_coef": 0.07975791394710541,
    "learning_rate": 0.001
  },
  {
    "episode": 6815,
    "reward": 89.20618,
    "length": 67,
    "time": 104000.260693,
    "actor_loss": -66.59983825683594,
    "critic_loss": 6.686987400054932,
    "ent_coef": 0.07824394851922989,
    "learning_rate": 0.001
  },
  {
    "episode": 6816,
    "reward": 87.485776,
    "length": 72,
    "time": 104012.64747,
    "actor_loss": -67.19361114501953,
    "critic_loss": 12.317039489746094,
    "ent_coef": 0.08118591457605362,
    "learning_rate": 0.001
  },
  {
    "episode": 6817,
    "reward": 88.200208,
    "length": 70,
    "time": 104033.597009,
    "actor_loss": -62.68204116821289,
    "critic_loss": 29.088130950927734,
    "ent_coef": 0.07898657023906708,
    "learning_rate": 0.001
  },
  {
    "episode": 6818,
    "reward": 87.100948,
    "length": 71,
    "time": 104047.349755,
    "actor_loss": -63.761390686035156,
    "critic_loss": 20.68242073059082,
    "ent_coef": 0.07634160667657852,
    "learning_rate": 0.001
  },
  {
    "episode": 6819,
    "reward": 83.308241,
    "length": 80,
    "time": 104061.832497,
    "actor_loss": -66.82666015625,
    "critic_loss": 4.915205001831055,
    "ent_coef": 0.07813749462366104,
    "learning_rate": 0.001
  },
  {
    "episode": 6820,
    "reward": 89.456818,
    "length": 67,
    "time": 104078.227628,
    "actor_loss": -65.91522216796875,
    "critic_loss": 10.814695358276367,
    "ent_coef": 0.07880616188049316,
    "learning_rate": 0.001
  },
  {
    "episode": 6821,
    "reward": 78.320316,
    "length": 76,
    "time": 104091.88952,
    "actor_loss": -61.771949768066406,
    "critic_loss": 14.375205993652344,
    "ent_coef": 0.08364325761795044,
    "learning_rate": 0.001
  },
  {
    "episode": 6822,
    "reward": 89.337353,
    "length": 67,
    "time": 104103.658877,
    "actor_loss": -70.34255981445312,
    "critic_loss": 18.723617553710938,
    "ent_coef": 0.07973120361566544,
    "learning_rate": 0.001
  },
  {
    "episode": 6823,
    "reward": 85.377333,
    "length": 76,
    "time": 104117.586464,
    "actor_loss": -65.67206573486328,
    "critic_loss": 161.23214721679688,
    "ent_coef": 0.07393736392259598,
    "learning_rate": 0.001
  },
  {
    "episode": 6824,
    "reward": -163.795755,
    "length": 171,
    "time": 104145.653708,
    "actor_loss": -63.498191833496094,
    "critic_loss": 21.722993850708008,
    "ent_coef": 0.07803612947463989,
    "learning_rate": 0.001
  },
  {
    "episode": 6825,
    "reward": 82.976618,
    "length": 79,
    "time": 104160.17367,
    "actor_loss": -64.16262817382812,
    "critic_loss": 6.062553405761719,
    "ent_coef": 0.07860618084669113,
    "learning_rate": 0.001
  },
  {
    "episode": 6826,
    "reward": 91.099628,
    "length": 62,
    "time": 104172.330296,
    "actor_loss": -65.72697448730469,
    "critic_loss": 13.271602630615234,
    "ent_coef": 0.07823462039232254,
    "learning_rate": 0.001
  },
  {
    "episode": 6827,
    "reward": 86.371726,
    "length": 75,
    "time": 104186.164321,
    "actor_loss": -63.930084228515625,
    "critic_loss": 394.32476806640625,
    "ent_coef": 0.07911927998065948,
    "learning_rate": 0.001
  },
  {
    "episode": 6828,
    "reward": 89.114322,
    "length": 68,
    "time": 104198.187007,
    "actor_loss": -65.07720947265625,
    "critic_loss": 20.256624221801758,
    "ent_coef": 0.08281219750642776,
    "learning_rate": 0.001
  },
  {
    "episode": 6829,
    "reward": 90.013218,
    "length": 65,
    "time": 104211.99379,
    "actor_loss": -64.1182861328125,
    "critic_loss": 10.619928359985352,
    "ent_coef": 0.08440016955137253,
    "learning_rate": 0.001
  },
  {
    "episode": 6830,
    "reward": 87.347275,
    "length": 73,
    "time": 104225.392827,
    "actor_loss": -67.89170837402344,
    "critic_loss": 3.337491989135742,
    "ent_coef": 0.08341909199953079,
    "learning_rate": 0.001
  },
  {
    "episode": 6831,
    "reward": 88.340848,
    "length": 68,
    "time": 104238.522688,
    "actor_loss": -72.73878479003906,
    "critic_loss": 70.59644317626953,
    "ent_coef": 0.08052036911249161,
    "learning_rate": 0.001
  },
  {
    "episode": 6832,
    "reward": 87.787262,
    "length": 71,
    "time": 104251.945257,
    "actor_loss": -73.9658203125,
    "critic_loss": 66.78657531738281,
    "ent_coef": 0.07917600870132446,
    "learning_rate": 0.001
  },
  {
    "episode": 6833,
    "reward": 86.848042,
    "length": 74,
    "time": 104268.219929,
    "actor_loss": -67.63397216796875,
    "critic_loss": 43.005882263183594,
    "ent_coef": 0.07940735667943954,
    "learning_rate": 0.001
  },
  {
    "episode": 6834,
    "reward": 90.798941,
    "length": 64,
    "time": 104280.700365,
    "actor_loss": -64.4483871459961,
    "critic_loss": 11.664145469665527,
    "ent_coef": 0.07786183804273605,
    "learning_rate": 0.001
  },
  {
    "episode": 6835,
    "reward": 87.002532,
    "length": 72,
    "time": 104293.386272,
    "actor_loss": -61.80842971801758,
    "critic_loss": 10.08224105834961,
    "ent_coef": 0.07383473217487335,
    "learning_rate": 0.001
  },
  {
    "episode": 6836,
    "reward": 90.889257,
    "length": 64,
    "time": 104308.833827,
    "actor_loss": -61.54824447631836,
    "critic_loss": 20.02157211303711,
    "ent_coef": 0.07515542954206467,
    "learning_rate": 0.001
  },
  {
    "episode": 6837,
    "reward": 91.279811,
    "length": 62,
    "time": 104321.057271,
    "actor_loss": -59.372161865234375,
    "critic_loss": 4.3312201499938965,
    "ent_coef": 0.07295221090316772,
    "learning_rate": 0.001
  },
  {
    "episode": 6838,
    "reward": 89.893032,
    "length": 67,
    "time": 104333.220656,
    "actor_loss": -67.94690704345703,
    "critic_loss": 10.679378509521484,
    "ent_coef": 0.07856620103120804,
    "learning_rate": 0.001
  },
  {
    "episode": 6839,
    "reward": 87.444513,
    "length": 73,
    "time": 104346.288867,
    "actor_loss": -65.28767395019531,
    "critic_loss": 10.498549461364746,
    "ent_coef": 0.07717014849185944,
    "learning_rate": 0.001
  },
  {
    "episode": 6840,
    "reward": 89.351433,
    "length": 67,
    "time": 104358.045736,
    "actor_loss": -65.62010955810547,
    "critic_loss": 8.767301559448242,
    "ent_coef": 0.07592523097991943,
    "learning_rate": 0.001
  },
  {
    "episode": 6841,
    "reward": 91.885706,
    "length": 61,
    "time": 104371.678739,
    "actor_loss": -63.313140869140625,
    "critic_loss": 6.375814437866211,
    "ent_coef": 0.07926509529352188,
    "learning_rate": 0.001
  },
  {
    "episode": 6842,
    "reward": 85.0774,
    "length": 77,
    "time": 104385.595007,
    "actor_loss": -62.69877624511719,
    "critic_loss": 86.19606018066406,
    "ent_coef": 0.08117228746414185,
    "learning_rate": 0.001
  },
  {
    "episode": 6843,
    "reward": 91.54687,
    "length": 61,
    "time": 104398.595612,
    "actor_loss": -58.782508850097656,
    "critic_loss": 7.926395416259766,
    "ent_coef": 0.08761032670736313,
    "learning_rate": 0.001
  },
  {
    "episode": 6844,
    "reward": 92.614543,
    "length": 59,
    "time": 104411.819351,
    "actor_loss": -61.286582946777344,
    "critic_loss": 8.205545425415039,
    "ent_coef": 0.09458542615175247,
    "learning_rate": 0.001
  },
  {
    "episode": 6845,
    "reward": 92.46936,
    "length": 60,
    "time": 104424.052304,
    "actor_loss": -60.95281219482422,
    "critic_loss": 6.763236045837402,
    "ent_coef": 0.09687863290309906,
    "learning_rate": 0.001
  },
  {
    "episode": 6846,
    "reward": 90.072119,
    "length": 66,
    "time": 104438.006253,
    "actor_loss": -67.89945983886719,
    "critic_loss": 18.15359878540039,
    "ent_coef": 0.09148424863815308,
    "learning_rate": 0.001
  },
  {
    "episode": 6847,
    "reward": 86.085176,
    "length": 77,
    "time": 104452.849554,
    "actor_loss": -67.58277893066406,
    "critic_loss": 57.80289840698242,
    "ent_coef": 0.08293592184782028,
    "learning_rate": 0.001
  },
  {
    "episode": 6848,
    "reward": 85.340776,
    "length": 78,
    "time": 104467.025303,
    "actor_loss": -58.861602783203125,
    "critic_loss": 9.115489959716797,
    "ent_coef": 0.07649219036102295,
    "learning_rate": 0.001
  },
  {
    "episode": 6849,
    "reward": 89.664995,
    "length": 66,
    "time": 104478.659033,
    "actor_loss": -62.77785873413086,
    "critic_loss": 24.129058837890625,
    "ent_coef": 0.07602252811193466,
    "learning_rate": 0.001
  },
  {
    "episode": 6850,
    "reward": 90.313155,
    "length": 66,
    "time": 104492.341453,
    "actor_loss": -64.62535858154297,
    "critic_loss": 15.45254135131836,
    "ent_coef": 0.07447553426027298,
    "learning_rate": 0.001
  },
  {
    "episode": 6851,
    "reward": 89.796329,
    "length": 65,
    "time": 104504.802763,
    "actor_loss": -70.65442657470703,
    "critic_loss": 94.52655029296875,
    "ent_coef": 0.07286818325519562,
    "learning_rate": 0.001
  },
  {
    "episode": 6852,
    "reward": 91.473654,
    "length": 63,
    "time": 104518.752019,
    "actor_loss": -69.72502899169922,
    "critic_loss": 1135.120361328125,
    "ent_coef": 0.07397075742483139,
    "learning_rate": 0.001
  },
  {
    "episode": 6853,
    "reward": 91.19873,
    "length": 65,
    "time": 104530.389744,
    "actor_loss": -72.12603759765625,
    "critic_loss": 21.447189331054688,
    "ent_coef": 0.07594812661409378,
    "learning_rate": 0.001
  },
  {
    "episode": 6854,
    "reward": 91.486067,
    "length": 62,
    "time": 104541.582112,
    "actor_loss": -63.048072814941406,
    "critic_loss": 3.9966909885406494,
    "ent_coef": 0.07694033533334732,
    "learning_rate": 0.001
  },
  {
    "episode": 6855,
    "reward": 92.243774,
    "length": 61,
    "time": 104553.780837,
    "actor_loss": -73.46490478515625,
    "critic_loss": 59.59986114501953,
    "ent_coef": 0.07991605997085571,
    "learning_rate": 0.001
  },
  {
    "episode": 6856,
    "reward": 91.548536,
    "length": 62,
    "time": 104565.855024,
    "actor_loss": -71.23016357421875,
    "critic_loss": 5.806396484375,
    "ent_coef": 0.08265307545661926,
    "learning_rate": 0.001
  },
  {
    "episode": 6857,
    "reward": 90.4757,
    "length": 63,
    "time": 104577.923331,
    "actor_loss": -59.548160552978516,
    "critic_loss": 20.10325813293457,
    "ent_coef": 0.08406655490398407,
    "learning_rate": 0.001
  },
  {
    "episode": 6858,
    "reward": 92.120362,
    "length": 60,
    "time": 104588.959116,
    "actor_loss": -70.03263854980469,
    "critic_loss": 17.136558532714844,
    "ent_coef": 0.08607602119445801,
    "learning_rate": 0.001
  },
  {
    "episode": 6859,
    "reward": 91.842605,
    "length": 61,
    "time": 104601.139955,
    "actor_loss": -70.33119201660156,
    "critic_loss": 15.359012603759766,
    "ent_coef": 0.0885157659649849,
    "learning_rate": 0.001
  },
  {
    "episode": 6860,
    "reward": 85.805782,
    "length": 78,
    "time": 104616.145292,
    "actor_loss": -61.49263000488281,
    "critic_loss": 6.505398750305176,
    "ent_coef": 0.09046677500009537,
    "learning_rate": 0.001
  },
  {
    "episode": 6861,
    "reward": 86.559888,
    "length": 81,
    "time": 104631.348482,
    "actor_loss": -63.90496063232422,
    "critic_loss": 4.295681953430176,
    "ent_coef": 0.09357396513223648,
    "learning_rate": 0.001
  },
  {
    "episode": 6862,
    "reward": 90.258853,
    "length": 64,
    "time": 104642.678428,
    "actor_loss": -65.27693176269531,
    "critic_loss": 7.098433017730713,
    "ent_coef": 0.09534610062837601,
    "learning_rate": 0.001
  },
  {
    "episode": 6863,
    "reward": 85.269768,
    "length": 76,
    "time": 104655.496927,
    "actor_loss": -68.44988250732422,
    "critic_loss": 21.760555267333984,
    "ent_coef": 0.08973600715398788,
    "learning_rate": 0.001
  },
  {
    "episode": 6864,
    "reward": -163.886696,
    "length": 170,
    "time": 104680.4801,
    "actor_loss": -63.01372146606445,
    "critic_loss": 30.34819221496582,
    "ent_coef": 0.0824744775891304,
    "learning_rate": 0.001
  },
  {
    "episode": 6865,
    "reward": 86.235586,
    "length": 74,
    "time": 104692.957287,
    "actor_loss": -68.01268005371094,
    "critic_loss": 20.578935623168945,
    "ent_coef": 0.0764225423336029,
    "learning_rate": 0.001
  },
  {
    "episode": 6866,
    "reward": 87.817621,
    "length": 75,
    "time": 104706.837924,
    "actor_loss": -64.12007904052734,
    "critic_loss": 27.21219825744629,
    "ent_coef": 0.07583216577768326,
    "learning_rate": 0.001
  },
  {
    "episode": 6867,
    "reward": 86.173993,
    "length": 80,
    "time": 104722.408299,
    "actor_loss": -60.234153747558594,
    "critic_loss": 9.805007934570312,
    "ent_coef": 0.07236501574516296,
    "learning_rate": 0.001
  },
  {
    "episode": 6868,
    "reward": 87.571585,
    "length": 75,
    "time": 104736.504364,
    "actor_loss": -63.67001724243164,
    "critic_loss": 2.4545366764068604,
    "ent_coef": 0.07234305143356323,
    "learning_rate": 0.001
  },
  {
    "episode": 6869,
    "reward": 90.339925,
    "length": 65,
    "time": 104750.019282,
    "actor_loss": -66.77330780029297,
    "critic_loss": 20.153608322143555,
    "ent_coef": 0.07622142881155014,
    "learning_rate": 0.001
  },
  {
    "episode": 6870,
    "reward": 90.065715,
    "length": 69,
    "time": 104762.87913,
    "actor_loss": -62.70521926879883,
    "critic_loss": 74.93556213378906,
    "ent_coef": 0.0797349140048027,
    "learning_rate": 0.001
  },
  {
    "episode": 6871,
    "reward": 91.17642,
    "length": 65,
    "time": 104777.325509,
    "actor_loss": -65.12406158447266,
    "critic_loss": 9.008001327514648,
    "ent_coef": 0.08311807364225388,
    "learning_rate": 0.001
  },
  {
    "episode": 6872,
    "reward": 89.643447,
    "length": 68,
    "time": 104789.20617,
    "actor_loss": -62.51041793823242,
    "critic_loss": 11.613265991210938,
    "ent_coef": 0.077654629945755,
    "learning_rate": 0.001
  },
  {
    "episode": 6873,
    "reward": 89.671408,
    "length": 66,
    "time": 104801.812808,
    "actor_loss": -62.549625396728516,
    "critic_loss": 12.60039234161377,
    "ent_coef": 0.07461126893758774,
    "learning_rate": 0.001
  },
  {
    "episode": 6874,
    "reward": 89.985223,
    "length": 65,
    "time": 104813.686826,
    "actor_loss": -59.36663818359375,
    "critic_loss": 30.21303939819336,
    "ent_coef": 0.07457912713289261,
    "learning_rate": 0.001
  },
  {
    "episode": 6875,
    "reward": 89.627764,
    "length": 67,
    "time": 104827.00322,
    "actor_loss": -64.00140380859375,
    "critic_loss": 4.881389141082764,
    "ent_coef": 0.07641548663377762,
    "learning_rate": 0.001
  },
  {
    "episode": 6876,
    "reward": 89.550866,
    "length": 66,
    "time": 104838.545974,
    "actor_loss": -62.192501068115234,
    "critic_loss": 9.659995079040527,
    "ent_coef": 0.07863079011440277,
    "learning_rate": 0.001
  },
  {
    "episode": 6877,
    "reward": 90.48509,
    "length": 63,
    "time": 104851.717707,
    "actor_loss": -70.20804595947266,
    "critic_loss": 14.344077110290527,
    "ent_coef": 0.08054311573505402,
    "learning_rate": 0.001
  },
  {
    "episode": 6878,
    "reward": 87.156377,
    "length": 78,
    "time": 104864.856305,
    "actor_loss": -58.171287536621094,
    "critic_loss": 3.087395191192627,
    "ent_coef": 0.08701801300048828,
    "learning_rate": 0.001
  },
  {
    "episode": 6879,
    "reward": 89.561832,
    "length": 66,
    "time": 104877.434669,
    "actor_loss": -66.24241638183594,
    "critic_loss": 73.84039306640625,
    "ent_coef": 0.08986691385507584,
    "learning_rate": 0.001
  },
  {
    "episode": 6880,
    "reward": 90.989026,
    "length": 64,
    "time": 104889.320148,
    "actor_loss": -57.44293975830078,
    "critic_loss": 5.826638221740723,
    "ent_coef": 0.08762177079916,
    "learning_rate": 0.001
  },
  {
    "episode": 6881,
    "reward": 90.309396,
    "length": 66,
    "time": 104901.130147,
    "actor_loss": -62.208194732666016,
    "critic_loss": 7.750831604003906,
    "ent_coef": 0.09079575538635254,
    "learning_rate": 0.001
  },
  {
    "episode": 6882,
    "reward": 90.576529,
    "length": 63,
    "time": 104914.101026,
    "actor_loss": -63.383209228515625,
    "critic_loss": 10.045612335205078,
    "ent_coef": 0.10065619647502899,
    "learning_rate": 0.001
  },
  {
    "episode": 6883,
    "reward": 89.33908,
    "length": 66,
    "time": 104927.473007,
    "actor_loss": -63.990509033203125,
    "critic_loss": 10.353589057922363,
    "ent_coef": 0.1015150174498558,
    "learning_rate": 0.001
  },
  {
    "episode": 6884,
    "reward": 89.002102,
    "length": 67,
    "time": 104940.661864,
    "actor_loss": -65.005859375,
    "critic_loss": 10.584787368774414,
    "ent_coef": 0.10201497375965118,
    "learning_rate": 0.001
  },
  {
    "episode": 6885,
    "reward": 91.709513,
    "length": 61,
    "time": 104952.803327,
    "actor_loss": -65.4920654296875,
    "critic_loss": 120.49278259277344,
    "ent_coef": 0.10476407408714294,
    "learning_rate": 0.001
  },
  {
    "episode": 6886,
    "reward": 89.542516,
    "length": 65,
    "time": 104965.349594,
    "actor_loss": -61.524410247802734,
    "critic_loss": 4.847387313842773,
    "ent_coef": 0.10529403388500214,
    "learning_rate": 0.001
  },
  {
    "episode": 6887,
    "reward": 86.015081,
    "length": 76,
    "time": 104978.759756,
    "actor_loss": -65.8589096069336,
    "critic_loss": 33.690406799316406,
    "ent_coef": 0.1010991707444191,
    "learning_rate": 0.001
  },
  {
    "episode": 6888,
    "reward": 88.846868,
    "length": 67,
    "time": 104991.497421,
    "actor_loss": -63.88481903076172,
    "critic_loss": 50.626502990722656,
    "ent_coef": 0.09637991338968277,
    "learning_rate": 0.001
  },
  {
    "episode": 6889,
    "reward": 87.623281,
    "length": 69,
    "time": 105004.483132,
    "actor_loss": -61.21458435058594,
    "critic_loss": 7.28945779800415,
    "ent_coef": 0.09299854934215546,
    "learning_rate": 0.001
  },
  {
    "episode": 6890,
    "reward": 88.445217,
    "length": 70,
    "time": 105019.923572,
    "actor_loss": -61.63231658935547,
    "critic_loss": 5.568811416625977,
    "ent_coef": 0.09215709567070007,
    "learning_rate": 0.001
  },
  {
    "episode": 6891,
    "reward": 92.621245,
    "length": 59,
    "time": 105030.812638,
    "actor_loss": -72.68113708496094,
    "critic_loss": 1961.814697265625,
    "ent_coef": 0.0927186831831932,
    "learning_rate": 0.001
  },
  {
    "episode": 6892,
    "reward": 90.856428,
    "length": 63,
    "time": 105043.78893,
    "actor_loss": -67.70451354980469,
    "critic_loss": 5.494429588317871,
    "ent_coef": 0.09098593145608902,
    "learning_rate": 0.001
  },
  {
    "episode": 6893,
    "reward": 86.751405,
    "length": 69,
    "time": 105056.477237,
    "actor_loss": -60.860591888427734,
    "critic_loss": 9.290156364440918,
    "ent_coef": 0.08674389868974686,
    "learning_rate": 0.001
  },
  {
    "episode": 6894,
    "reward": 87.539383,
    "length": 75,
    "time": 105070.290091,
    "actor_loss": -61.677513122558594,
    "critic_loss": 10.689823150634766,
    "ent_coef": 0.08645123988389969,
    "learning_rate": 0.001
  },
  {
    "episode": 6895,
    "reward": 91.23668,
    "length": 63,
    "time": 105082.646065,
    "actor_loss": -59.17655944824219,
    "critic_loss": 8.396810531616211,
    "ent_coef": 0.08551846444606781,
    "learning_rate": 0.001
  },
  {
    "episode": 6896,
    "reward": 89.750313,
    "length": 65,
    "time": 105095.127425,
    "actor_loss": -64.79862213134766,
    "critic_loss": 5.759984970092773,
    "ent_coef": 0.08687751740217209,
    "learning_rate": 0.001
  },
  {
    "episode": 6897,
    "reward": 89.935793,
    "length": 64,
    "time": 105106.818374,
    "actor_loss": -64.64604949951172,
    "critic_loss": 4.375227451324463,
    "ent_coef": 0.0895717591047287,
    "learning_rate": 0.001
  },
  {
    "episode": 6898,
    "reward": 89.529568,
    "length": 65,
    "time": 105120.594551,
    "actor_loss": -70.82229614257812,
    "critic_loss": 5.685563564300537,
    "ent_coef": 0.09079103916883469,
    "learning_rate": 0.001
  },
  {
    "episode": 6899,
    "reward": 87.954389,
    "length": 72,
    "time": 105133.184321,
    "actor_loss": -70.20013427734375,
    "critic_loss": 8.54460334777832,
    "ent_coef": 0.08587003499269485,
    "learning_rate": 0.001
  },
  {
    "episode": 6900,
    "reward": 88.246074,
    "length": 68,
    "time": 105149.125399,
    "actor_loss": -61.984947204589844,
    "critic_loss": 5.639032363891602,
    "ent_coef": 0.08484602719545364,
    "learning_rate": 0.001
  },
  {
    "episode": 6901,
    "reward": 90.763708,
    "length": 62,
    "time": 105161.772304,
    "actor_loss": -65.73307800292969,
    "critic_loss": 4.665581703186035,
    "ent_coef": 0.08740604668855667,
    "learning_rate": 0.001
  },
  {
    "episode": 6902,
    "reward": 90.400226,
    "length": 62,
    "time": 105178.870942,
    "actor_loss": -66.21922302246094,
    "critic_loss": 11.538269996643066,
    "ent_coef": 0.08874084800481796,
    "learning_rate": 0.001
  },
  {
    "episode": 6903,
    "reward": 91.511444,
    "length": 62,
    "time": 105189.866302,
    "actor_loss": -64.54945373535156,
    "critic_loss": 3.9740748405456543,
    "ent_coef": 0.0877872183918953,
    "learning_rate": 0.001
  },
  {
    "episode": 6904,
    "reward": 89.228532,
    "length": 67,
    "time": 105203.255501,
    "actor_loss": -60.61328887939453,
    "critic_loss": 21.711837768554688,
    "ent_coef": 0.08821243047714233,
    "learning_rate": 0.001
  },
  {
    "episode": 6905,
    "reward": 86.83289,
    "length": 73,
    "time": 105216.703521,
    "actor_loss": -69.45927429199219,
    "critic_loss": 57.226654052734375,
    "ent_coef": 0.08559119701385498,
    "learning_rate": 0.001
  },
  {
    "episode": 6906,
    "reward": 90.100464,
    "length": 64,
    "time": 105230.1442,
    "actor_loss": -62.540767669677734,
    "critic_loss": 8.824584007263184,
    "ent_coef": 0.083590567111969,
    "learning_rate": 0.001
  },
  {
    "episode": 6907,
    "reward": 89.692003,
    "length": 65,
    "time": 105242.550779,
    "actor_loss": -63.23303985595703,
    "critic_loss": 5.352799415588379,
    "ent_coef": 0.07993677258491516,
    "learning_rate": 0.001
  },
  {
    "episode": 6908,
    "reward": 89.688871,
    "length": 64,
    "time": 105255.823907,
    "actor_loss": -60.68988037109375,
    "critic_loss": 3.2067363262176514,
    "ent_coef": 0.07902418822050095,
    "learning_rate": 0.001
  },
  {
    "episode": 6909,
    "reward": 89.386733,
    "length": 64,
    "time": 105267.465947,
    "actor_loss": -66.57501220703125,
    "critic_loss": 6.738688945770264,
    "ent_coef": 0.07701128721237183,
    "learning_rate": 0.001
  },
  {
    "episode": 6910,
    "reward": 90.885955,
    "length": 63,
    "time": 105284.196917,
    "actor_loss": -64.79854583740234,
    "critic_loss": 856.261962890625,
    "ent_coef": 0.07668428868055344,
    "learning_rate": 0.001
  },
  {
    "episode": 6911,
    "reward": 89.820511,
    "length": 65,
    "time": 105296.246521,
    "actor_loss": -67.84040832519531,
    "critic_loss": 31.677309036254883,
    "ent_coef": 0.07907386869192123,
    "learning_rate": 0.001
  },
  {
    "episode": 6912,
    "reward": 90.427857,
    "length": 63,
    "time": 105310.786466,
    "actor_loss": -62.63579559326172,
    "critic_loss": 84.84324645996094,
    "ent_coef": 0.07841676473617554,
    "learning_rate": 0.001
  },
  {
    "episode": 6913,
    "reward": 89.268245,
    "length": 66,
    "time": 105326.079298,
    "actor_loss": -62.76286315917969,
    "critic_loss": 8.45633316040039,
    "ent_coef": 0.07666351646184921,
    "learning_rate": 0.001
  },
  {
    "episode": 6914,
    "reward": 89.241534,
    "length": 65,
    "time": 105340.358541,
    "actor_loss": -62.66530227661133,
    "critic_loss": 829.014892578125,
    "ent_coef": 0.07630687206983566,
    "learning_rate": 0.001
  },
  {
    "episode": 6915,
    "reward": 88.09262,
    "length": 72,
    "time": 105353.822662,
    "actor_loss": -60.896366119384766,
    "critic_loss": 26.017446517944336,
    "ent_coef": 0.0789087563753128,
    "learning_rate": 0.001
  },
  {
    "episode": 6916,
    "reward": 90.230877,
    "length": 63,
    "time": 105367.770954,
    "actor_loss": -58.440826416015625,
    "critic_loss": 83.23760986328125,
    "ent_coef": 0.08157575130462646,
    "learning_rate": 0.001
  },
  {
    "episode": 6917,
    "reward": 88.380235,
    "length": 65,
    "time": 105381.241127,
    "actor_loss": -61.900306701660156,
    "critic_loss": 76.06588745117188,
    "ent_coef": 0.0801694393157959,
    "learning_rate": 0.001
  },
  {
    "episode": 6918,
    "reward": 89.301746,
    "length": 68,
    "time": 105395.329673,
    "actor_loss": -56.880130767822266,
    "critic_loss": 10.641874313354492,
    "ent_coef": 0.08167582005262375,
    "learning_rate": 0.001
  },
  {
    "episode": 6919,
    "reward": 90.365488,
    "length": 63,
    "time": 105409.711782,
    "actor_loss": -63.46295166015625,
    "critic_loss": 8.796459197998047,
    "ent_coef": 0.08103761076927185,
    "learning_rate": 0.001
  },
  {
    "episode": 6920,
    "reward": 87.536817,
    "length": 69,
    "time": 105421.942749,
    "actor_loss": -66.07755279541016,
    "critic_loss": 4.472253799438477,
    "ent_coef": 0.08166978508234024,
    "learning_rate": 0.001
  },
  {
    "episode": 6921,
    "reward": 89.527798,
    "length": 68,
    "time": 105433.997488,
    "actor_loss": -64.49270629882812,
    "critic_loss": 4.448960304260254,
    "ent_coef": 0.08473959565162659,
    "learning_rate": 0.001
  },
  {
    "episode": 6922,
    "reward": 90.145042,
    "length": 62,
    "time": 105445.147442,
    "actor_loss": -60.04359436035156,
    "critic_loss": 8.554088592529297,
    "ent_coef": 0.08912467211484909,
    "learning_rate": 0.001
  },
  {
    "episode": 6923,
    "reward": 89.712207,
    "length": 66,
    "time": 105461.299559,
    "actor_loss": -70.37476348876953,
    "critic_loss": 109.52360534667969,
    "ent_coef": 0.09096973389387131,
    "learning_rate": 0.001
  },
  {
    "episode": 6924,
    "reward": 87.839964,
    "length": 71,
    "time": 105474.620673,
    "actor_loss": -65.30155944824219,
    "critic_loss": 27.44188690185547,
    "ent_coef": 0.0896008089184761,
    "learning_rate": 0.001
  },
  {
    "episode": 6925,
    "reward": 91.728577,
    "length": 61,
    "time": 105485.764246,
    "actor_loss": -66.15685272216797,
    "critic_loss": 6.760235786437988,
    "ent_coef": 0.09437787532806396,
    "learning_rate": 0.001
  },
  {
    "episode": 6926,
    "reward": 87.966981,
    "length": 72,
    "time": 105497.999506,
    "actor_loss": -70.63299560546875,
    "critic_loss": 55.539466857910156,
    "ent_coef": 0.09378127753734589,
    "learning_rate": 0.001
  },
  {
    "episode": 6927,
    "reward": 91.29977,
    "length": 60,
    "time": 105508.971086,
    "actor_loss": -63.407508850097656,
    "critic_loss": 4.078155517578125,
    "ent_coef": 0.09593730419874191,
    "learning_rate": 0.001
  },
  {
    "episode": 6928,
    "reward": 87.750897,
    "length": 68,
    "time": 105522.133366,
    "actor_loss": -66.47065734863281,
    "critic_loss": 4.45671272277832,
    "ent_coef": 0.09503687173128128,
    "learning_rate": 0.001
  },
  {
    "episode": 6929,
    "reward": 87.287213,
    "length": 72,
    "time": 105536.02331,
    "actor_loss": -64.6747817993164,
    "critic_loss": 3.4548091888427734,
    "ent_coef": 0.09162705391645432,
    "learning_rate": 0.001
  },
  {
    "episode": 6930,
    "reward": 85.784121,
    "length": 72,
    "time": 105548.682055,
    "actor_loss": -65.7523193359375,
    "critic_loss": 10.584465026855469,
    "ent_coef": 0.08789490908384323,
    "learning_rate": 0.001
  },
  {
    "episode": 6931,
    "reward": 90.021757,
    "length": 64,
    "time": 105560.108157,
    "actor_loss": -70.26081085205078,
    "critic_loss": 15.201517105102539,
    "ent_coef": 0.08358641713857651,
    "learning_rate": 0.001
  },
  {
    "episode": 6932,
    "reward": 88.996873,
    "length": 67,
    "time": 105573.550718,
    "actor_loss": -63.065673828125,
    "critic_loss": 16.478660583496094,
    "ent_coef": 0.08394914865493774,
    "learning_rate": 0.001
  },
  {
    "episode": 6933,
    "reward": 84.961608,
    "length": 78,
    "time": 105587.934007,
    "actor_loss": -65.37626647949219,
    "critic_loss": 13.001226425170898,
    "ent_coef": 0.08241863548755646,
    "learning_rate": 0.001
  },
  {
    "episode": 6934,
    "reward": 91.112215,
    "length": 62,
    "time": 105601.711469,
    "actor_loss": -64.3419189453125,
    "critic_loss": 4.618348121643066,
    "ent_coef": 0.08416998386383057,
    "learning_rate": 0.001
  },
  {
    "episode": 6935,
    "reward": 80.80867,
    "length": 91,
    "time": 105619.500464,
    "actor_loss": -66.34693908691406,
    "critic_loss": 12.2551908493042,
    "ent_coef": 0.08743399381637573,
    "learning_rate": 0.001
  },
  {
    "episode": 6936,
    "reward": 90.003871,
    "length": 65,
    "time": 105631.042632,
    "actor_loss": -63.92903518676758,
    "critic_loss": 6.731316566467285,
    "ent_coef": 0.09100955724716187,
    "learning_rate": 0.001
  },
  {
    "episode": 6937,
    "reward": 87.339183,
    "length": 70,
    "time": 105644.227509,
    "actor_loss": -62.428619384765625,
    "critic_loss": 13.522787094116211,
    "ent_coef": 0.09097868204116821,
    "learning_rate": 0.001
  },
  {
    "episode": 6938,
    "reward": 90.16241,
    "length": 64,
    "time": 105656.818897,
    "actor_loss": -66.34242248535156,
    "critic_loss": 3.8614869117736816,
    "ent_coef": 0.08851198852062225,
    "learning_rate": 0.001
  },
  {
    "episode": 6939,
    "reward": 83.500006,
    "length": 77,
    "time": 105671.069369,
    "actor_loss": -65.20770263671875,
    "critic_loss": 639.357421875,
    "ent_coef": 0.08671538531780243,
    "learning_rate": 0.001
  },
  {
    "episode": 6940,
    "reward": 88.629612,
    "length": 68,
    "time": 105684.365034,
    "actor_loss": -62.114402770996094,
    "critic_loss": 11.720369338989258,
    "ent_coef": 0.08655097335577011,
    "learning_rate": 0.001
  },
  {
    "episode": 6941,
    "reward": 90.076172,
    "length": 65,
    "time": 105698.191617,
    "actor_loss": -60.456668853759766,
    "critic_loss": 5.3071184158325195,
    "ent_coef": 0.08938878029584885,
    "learning_rate": 0.001
  },
  {
    "episode": 6942,
    "reward": 87.329367,
    "length": 74,
    "time": 105711.880854,
    "actor_loss": -60.80850601196289,
    "critic_loss": 8.27867317199707,
    "ent_coef": 0.08692057430744171,
    "learning_rate": 0.001
  },
  {
    "episode": 6943,
    "reward": 88.673912,
    "length": 69,
    "time": 105723.994934,
    "actor_loss": -64.30211639404297,
    "critic_loss": 2.9940247535705566,
    "ent_coef": 0.08575943112373352,
    "learning_rate": 0.001
  },
  {
    "episode": 6944,
    "reward": 85.698194,
    "length": 75,
    "time": 105736.481658,
    "actor_loss": -68.93162536621094,
    "critic_loss": 7.6055006980896,
    "ent_coef": 0.08120691776275635,
    "learning_rate": 0.001
  },
  {
    "episode": 6945,
    "reward": 83.022141,
    "length": 82,
    "time": 105750.377138,
    "actor_loss": -59.61180877685547,
    "critic_loss": 22.565845489501953,
    "ent_coef": 0.07277397811412811,
    "learning_rate": 0.001
  },
  {
    "episode": 6946,
    "reward": 85.143722,
    "length": 79,
    "time": 105764.08924,
    "actor_loss": -64.71031188964844,
    "critic_loss": 11.847806930541992,
    "ent_coef": 0.07099929451942444,
    "learning_rate": 0.001
  },
  {
    "episode": 6947,
    "reward": 86.81543,
    "length": 74,
    "time": 105777.602556,
    "actor_loss": -68.91825866699219,
    "critic_loss": 10.358146667480469,
    "ent_coef": 0.07347482442855835,
    "learning_rate": 0.001
  },
  {
    "episode": 6948,
    "reward": 90.404917,
    "length": 63,
    "time": 105790.890483,
    "actor_loss": -61.77081298828125,
    "critic_loss": 72.24629211425781,
    "ent_coef": 0.07686468958854675,
    "learning_rate": 0.001
  },
  {
    "episode": 6949,
    "reward": 87.222531,
    "length": 69,
    "time": 105803.132503,
    "actor_loss": -65.0583724975586,
    "critic_loss": 6.757616996765137,
    "ent_coef": 0.07912193983793259,
    "learning_rate": 0.001
  },
  {
    "episode": 6950,
    "reward": 87.71167,
    "length": 72,
    "time": 105818.863903,
    "actor_loss": -71.58963012695312,
    "critic_loss": 11.105188369750977,
    "ent_coef": 0.08290760964155197,
    "learning_rate": 0.001
  },
  {
    "episode": 6951,
    "reward": 86.706104,
    "length": 75,
    "time": 105833.807524,
    "actor_loss": -61.367225646972656,
    "critic_loss": 38.925865173339844,
    "ent_coef": 0.08427998423576355,
    "learning_rate": 0.001
  },
  {
    "episode": 6952,
    "reward": 89.767597,
    "length": 68,
    "time": 105847.728059,
    "actor_loss": -60.80666732788086,
    "critic_loss": 21.397249221801758,
    "ent_coef": 0.08501032739877701,
    "learning_rate": 0.001
  },
  {
    "episode": 6953,
    "reward": 86.043365,
    "length": 77,
    "time": 105860.643595,
    "actor_loss": -61.54789733886719,
    "critic_loss": 68.04112243652344,
    "ent_coef": 0.08473458141088486,
    "learning_rate": 0.001
  },
  {
    "episode": 6954,
    "reward": 87.130544,
    "length": 75,
    "time": 105874.638864,
    "actor_loss": -59.743873596191406,
    "critic_loss": 4.49744987487793,
    "ent_coef": 0.08563175797462463,
    "learning_rate": 0.001
  },
  {
    "episode": 6955,
    "reward": 88.060117,
    "length": 71,
    "time": 105887.86292,
    "actor_loss": -67.4183578491211,
    "critic_loss": 5.2916765213012695,
    "ent_coef": 0.08554937690496445,
    "learning_rate": 0.001
  },
  {
    "episode": 6956,
    "reward": 90.47075,
    "length": 64,
    "time": 105899.261117,
    "actor_loss": -59.0961799621582,
    "critic_loss": 4.58718204498291,
    "ent_coef": 0.08397383242845535,
    "learning_rate": 0.001
  },
  {
    "episode": 6957,
    "reward": 91.731338,
    "length": 60,
    "time": 105910.357364,
    "actor_loss": -61.923831939697266,
    "critic_loss": 5.4552459716796875,
    "ent_coef": 0.08512266725301743,
    "learning_rate": 0.001
  },
  {
    "episode": 6958,
    "reward": 89.964501,
    "length": 66,
    "time": 105923.101194,
    "actor_loss": -67.73361206054688,
    "critic_loss": 4.790625095367432,
    "ent_coef": 0.08375059068202972,
    "learning_rate": 0.001
  },
  {
    "episode": 6959,
    "reward": 89.76647,
    "length": 66,
    "time": 105934.723641,
    "actor_loss": -67.9187240600586,
    "critic_loss": 5.676433563232422,
    "ent_coef": 0.08282990753650665,
    "learning_rate": 0.001
  },
  {
    "episode": 6960,
    "reward": 88.987704,
    "length": 71,
    "time": 105948.018204,
    "actor_loss": -59.149635314941406,
    "critic_loss": 14.313892364501953,
    "ent_coef": 0.08554848283529282,
    "learning_rate": 0.001
  },
  {
    "episode": 6961,
    "reward": 88.701594,
    "length": 71,
    "time": 105960.885026,
    "actor_loss": -63.69968032836914,
    "critic_loss": 4.507861137390137,
    "ent_coef": 0.08708666265010834,
    "learning_rate": 0.001
  },
  {
    "episode": 6962,
    "reward": 86.923063,
    "length": 69,
    "time": 105973.997783,
    "actor_loss": -63.551048278808594,
    "critic_loss": 50.93116760253906,
    "ent_coef": 0.08840345591306686,
    "learning_rate": 0.001
  },
  {
    "episode": 6963,
    "reward": 85.908155,
    "length": 75,
    "time": 105990.362857,
    "actor_loss": -64.55242919921875,
    "critic_loss": 3.8576395511627197,
    "ent_coef": 0.08746936172246933,
    "learning_rate": 0.001
  },
  {
    "episode": 6964,
    "reward": 87.975329,
    "length": 73,
    "time": 106003.919639,
    "actor_loss": -73.0173110961914,
    "critic_loss": 11.20388412475586,
    "ent_coef": 0.08745578676462173,
    "learning_rate": 0.001
  },
  {
    "episode": 6965,
    "reward": 85.416383,
    "length": 82,
    "time": 106021.350903,
    "actor_loss": -67.36597442626953,
    "critic_loss": 12.99755573272705,
    "ent_coef": 0.08679229021072388,
    "learning_rate": 0.001
  },
  {
    "episode": 6966,
    "reward": 91.087033,
    "length": 63,
    "time": 106035.337612,
    "actor_loss": -70.11404418945312,
    "critic_loss": 8.136405944824219,
    "ent_coef": 0.0856490507721901,
    "learning_rate": 0.001
  },
  {
    "episode": 6967,
    "reward": 87.722951,
    "length": 75,
    "time": 106048.103701,
    "actor_loss": -71.8366470336914,
    "critic_loss": 642.929443359375,
    "ent_coef": 0.08335922658443451,
    "learning_rate": 0.001
  },
  {
    "episode": 6968,
    "reward": 86.254949,
    "length": 69,
    "time": 106060.072694,
    "actor_loss": -61.50646209716797,
    "critic_loss": 8.599193572998047,
    "ent_coef": 0.08555880188941956,
    "learning_rate": 0.001
  },
  {
    "episode": 6969,
    "reward": 91.885701,
    "length": 60,
    "time": 106073.620835,
    "actor_loss": -63.1439094543457,
    "critic_loss": 204.3857879638672,
    "ent_coef": 0.08660633862018585,
    "learning_rate": 0.001
  },
  {
    "episode": 6970,
    "reward": 89.374655,
    "length": 66,
    "time": 106085.151894,
    "actor_loss": -67.841552734375,
    "critic_loss": 14.902579307556152,
    "ent_coef": 0.0809168666601181,
    "learning_rate": 0.001
  },
  {
    "episode": 6971,
    "reward": -165.504568,
    "length": 171,
    "time": 106112.228036,
    "actor_loss": -60.21059036254883,
    "critic_loss": 4.329903602600098,
    "ent_coef": 0.08113053441047668,
    "learning_rate": 0.001
  },
  {
    "episode": 6972,
    "reward": 86.513892,
    "length": 74,
    "time": 106125.257226,
    "actor_loss": -61.92006301879883,
    "critic_loss": 14.988629341125488,
    "ent_coef": 0.08043522387742996,
    "learning_rate": 0.001
  },
  {
    "episode": 6973,
    "reward": 82.368037,
    "length": 83,
    "time": 106139.673547,
    "actor_loss": -66.49867248535156,
    "critic_loss": 22.44011688232422,
    "ent_coef": 0.08407247066497803,
    "learning_rate": 0.001
  },
  {
    "episode": 6974,
    "reward": 92.412542,
    "length": 60,
    "time": 106151.370382,
    "actor_loss": -64.04688262939453,
    "critic_loss": 49.10669708251953,
    "ent_coef": 0.08633169531822205,
    "learning_rate": 0.001
  },
  {
    "episode": 6975,
    "reward": 91.141947,
    "length": 62,
    "time": 106162.680805,
    "actor_loss": -65.0753173828125,
    "critic_loss": 11.848085403442383,
    "ent_coef": 0.08732510358095169,
    "learning_rate": 0.001
  },
  {
    "episode": 6976,
    "reward": 91.728074,
    "length": 60,
    "time": 106173.65977,
    "actor_loss": -68.2275390625,
    "critic_loss": 7.24509859085083,
    "ent_coef": 0.08801044523715973,
    "learning_rate": 0.001
  },
  {
    "episode": 6977,
    "reward": 91.265441,
    "length": 60,
    "time": 106192.411814,
    "actor_loss": -59.069637298583984,
    "critic_loss": 28.03688621520996,
    "ent_coef": 0.08717219531536102,
    "learning_rate": 0.001
  },
  {
    "episode": 6978,
    "reward": 91.168087,
    "length": 62,
    "time": 106204.610887,
    "actor_loss": -62.47990798950195,
    "critic_loss": 5.343470096588135,
    "ent_coef": 0.08514830470085144,
    "learning_rate": 0.001
  },
  {
    "episode": 6979,
    "reward": 88.999639,
    "length": 69,
    "time": 106218.858862,
    "actor_loss": -67.47732543945312,
    "critic_loss": 4.74394416809082,
    "ent_coef": 0.08615417778491974,
    "learning_rate": 0.001
  },
  {
    "episode": 6980,
    "reward": 91.024997,
    "length": 63,
    "time": 106229.839959,
    "actor_loss": -70.37789916992188,
    "critic_loss": 24.978729248046875,
    "ent_coef": 0.08661548048257828,
    "learning_rate": 0.001
  },
  {
    "episode": 6981,
    "reward": 83.470848,
    "length": 79,
    "time": 106244.301969,
    "actor_loss": -67.66317749023438,
    "critic_loss": 9.163597106933594,
    "ent_coef": 0.08672133833169937,
    "learning_rate": 0.001
  },
  {
    "episode": 6982,
    "reward": 88.92607,
    "length": 71,
    "time": 106256.473666,
    "actor_loss": -67.26779174804688,
    "critic_loss": 12.374044418334961,
    "ent_coef": 0.09323587268590927,
    "learning_rate": 0.001
  },
  {
    "episode": 6983,
    "reward": 89.404417,
    "length": 68,
    "time": 106268.366237,
    "actor_loss": -65.687744140625,
    "critic_loss": 7.051695823669434,
    "ent_coef": 0.09462682157754898,
    "learning_rate": 0.001
  },
  {
    "episode": 6984,
    "reward": 88.088047,
    "length": 73,
    "time": 106282.01815,
    "actor_loss": -66.01254272460938,
    "critic_loss": 4.703768730163574,
    "ent_coef": 0.09002837538719177,
    "learning_rate": 0.001
  },
  {
    "episode": 6985,
    "reward": 85.18787,
    "length": 81,
    "time": 106297.106927,
    "actor_loss": -64.9715347290039,
    "critic_loss": 13.831319808959961,
    "ent_coef": 0.08932680636644363,
    "learning_rate": 0.001
  },
  {
    "episode": 6986,
    "reward": 91.156312,
    "length": 61,
    "time": 106309.540648,
    "actor_loss": -63.36772155761719,
    "critic_loss": 32.35523986816406,
    "ent_coef": 0.08976125717163086,
    "learning_rate": 0.001
  },
  {
    "episode": 6987,
    "reward": 83.206783,
    "length": 80,
    "time": 106324.05297,
    "actor_loss": -66.18670654296875,
    "critic_loss": 9.181720733642578,
    "ent_coef": 0.08783277124166489,
    "learning_rate": 0.001
  },
  {
    "episode": 6988,
    "reward": 81.348955,
    "length": 84,
    "time": 106338.87962,
    "actor_loss": -68.06501770019531,
    "critic_loss": 3.1487059593200684,
    "ent_coef": 0.0813426598906517,
    "learning_rate": 0.001
  },
  {
    "episode": 6989,
    "reward": 81.466306,
    "length": 79,
    "time": 106352.111214,
    "actor_loss": -64.03067016601562,
    "critic_loss": 7.402741432189941,
    "ent_coef": 0.07587354630231857,
    "learning_rate": 0.001
  },
  {
    "episode": 6990,
    "reward": 88.420169,
    "length": 75,
    "time": 106368.337891,
    "actor_loss": -66.582275390625,
    "critic_loss": 30.457565307617188,
    "ent_coef": 0.07898154854774475,
    "learning_rate": 0.001
  },
  {
    "episode": 6991,
    "reward": 89.070709,
    "length": 68,
    "time": 106381.528553,
    "actor_loss": -67.67264556884766,
    "critic_loss": 12.894760131835938,
    "ent_coef": 0.0804009661078453,
    "learning_rate": 0.001
  },
  {
    "episode": 6992,
    "reward": 68.279795,
    "length": 131,
    "time": 106403.819073,
    "actor_loss": -69.41773986816406,
    "critic_loss": 13.880589485168457,
    "ent_coef": 0.07976305484771729,
    "learning_rate": 0.001
  },
  {
    "episode": 6993,
    "reward": 88.647809,
    "length": 73,
    "time": 106417.015373,
    "actor_loss": -66.93289947509766,
    "critic_loss": 5.673935413360596,
    "ent_coef": 0.0861201137304306,
    "learning_rate": 0.001
  },
  {
    "episode": 6994,
    "reward": 90.693321,
    "length": 64,
    "time": 106428.840013,
    "actor_loss": -62.2637939453125,
    "critic_loss": 2.5165963172912598,
    "ent_coef": 0.0867358148097992,
    "learning_rate": 0.001
  },
  {
    "episode": 6995,
    "reward": 91.163732,
    "length": 62,
    "time": 106440.016027,
    "actor_loss": -61.82720947265625,
    "critic_loss": 7.963128089904785,
    "ent_coef": 0.08989029377698898,
    "learning_rate": 0.001
  },
  {
    "episode": 6996,
    "reward": 90.89896,
    "length": 63,
    "time": 106451.25477,
    "actor_loss": -64.29611206054688,
    "critic_loss": 7.2439961433410645,
    "ent_coef": 0.09354592114686966,
    "learning_rate": 0.001
  },
  {
    "episode": 6997,
    "reward": 83.371839,
    "length": 81,
    "time": 106465.051756,
    "actor_loss": -65.60295867919922,
    "critic_loss": 13.884380340576172,
    "ent_coef": 0.09453485906124115,
    "learning_rate": 0.001
  },
  {
    "episode": 6998,
    "reward": 89.487389,
    "length": 66,
    "time": 106479.769495,
    "actor_loss": -66.12393188476562,
    "critic_loss": 21.900110244750977,
    "ent_coef": 0.09046832472085953,
    "learning_rate": 0.001
  },
  {
    "episode": 6999,
    "reward": 91.292775,
    "length": 61,
    "time": 106492.581693,
    "actor_loss": -70.19204711914062,
    "critic_loss": 8.393596649169922,
    "ent_coef": 0.09579203277826309,
    "learning_rate": 0.001
  },
  {
    "episode": 7000,
    "reward": 91.437077,
    "length": 60,
    "time": 106503.676967,
    "actor_loss": -67.80655670166016,
    "critic_loss": 9.010049819946289,
    "ent_coef": 0.10102877765893936,
    "learning_rate": 0.001
  },
  {
    "episode": 7001,
    "reward": 91.946935,
    "length": 60,
    "time": 106514.837338,
    "actor_loss": -63.904537200927734,
    "critic_loss": 9.177934646606445,
    "ent_coef": 0.10505361109972,
    "learning_rate": 0.001
  },
  {
    "episode": 7002,
    "reward": 90.447039,
    "length": 63,
    "time": 106526.030704,
    "actor_loss": -52.254173278808594,
    "critic_loss": 9.504401206970215,
    "ent_coef": 0.10613279789686203,
    "learning_rate": 0.001
  },
  {
    "episode": 7003,
    "reward": 90.549207,
    "length": 63,
    "time": 106537.712395,
    "actor_loss": -64.24807739257812,
    "critic_loss": 11.397050857543945,
    "ent_coef": 0.10431531071662903,
    "learning_rate": 0.001
  },
  {
    "episode": 7004,
    "reward": 87.595775,
    "length": 68,
    "time": 106550.792818,
    "actor_loss": -62.814903259277344,
    "critic_loss": 18.654373168945312,
    "ent_coef": 0.10673888027667999,
    "learning_rate": 0.001
  },
  {
    "episode": 7005,
    "reward": 90.275364,
    "length": 63,
    "time": 106564.8237,
    "actor_loss": -62.18761444091797,
    "critic_loss": 23.692981719970703,
    "ent_coef": 0.10713797062635422,
    "learning_rate": 0.001
  },
  {
    "episode": 7006,
    "reward": 90.549598,
    "length": 63,
    "time": 106579.714631,
    "actor_loss": -63.59983825683594,
    "critic_loss": 9.013118743896484,
    "ent_coef": 0.10676104575395584,
    "learning_rate": 0.001
  },
  {
    "episode": 7007,
    "reward": 90.088043,
    "length": 64,
    "time": 106591.965793,
    "actor_loss": -68.97537231445312,
    "critic_loss": 25.78658676147461,
    "ent_coef": 0.10332383215427399,
    "learning_rate": 0.001
  },
  {
    "episode": 7008,
    "reward": 90.59929,
    "length": 63,
    "time": 106603.271845,
    "actor_loss": -58.87279510498047,
    "critic_loss": 5.158363342285156,
    "ent_coef": 0.10203306376934052,
    "learning_rate": 0.001
  },
  {
    "episode": 7009,
    "reward": 91.302604,
    "length": 61,
    "time": 106615.024807,
    "actor_loss": -64.90068054199219,
    "critic_loss": 51.6911506652832,
    "ent_coef": 0.10339374095201492,
    "learning_rate": 0.001
  },
  {
    "episode": 7010,
    "reward": 91.888824,
    "length": 61,
    "time": 106627.693083,
    "actor_loss": -68.55581665039062,
    "critic_loss": 23.16394805908203,
    "ent_coef": 0.10663464665412903,
    "learning_rate": 0.001
  },
  {
    "episode": 7011,
    "reward": 91.615964,
    "length": 61,
    "time": 106639.021424,
    "actor_loss": -62.4078254699707,
    "critic_loss": 5.322877407073975,
    "ent_coef": 0.10741399228572845,
    "learning_rate": 0.001
  },
  {
    "episode": 7012,
    "reward": 83.809615,
    "length": 80,
    "time": 106654.079598,
    "actor_loss": -65.30032348632812,
    "critic_loss": 6.611293792724609,
    "ent_coef": 0.10461598634719849,
    "learning_rate": 0.001
  },
  {
    "episode": 7013,
    "reward": 89.515314,
    "length": 65,
    "time": 106665.879465,
    "actor_loss": -68.75009155273438,
    "critic_loss": 38.79819107055664,
    "ent_coef": 0.1017792746424675,
    "learning_rate": 0.001
  },
  {
    "episode": 7014,
    "reward": 90.440215,
    "length": 62,
    "time": 106678.398966,
    "actor_loss": -59.4136962890625,
    "critic_loss": 5.190454006195068,
    "ent_coef": 0.10076124221086502,
    "learning_rate": 0.001
  },
  {
    "episode": 7015,
    "reward": 89.508914,
    "length": 67,
    "time": 106691.248022,
    "actor_loss": -72.38678741455078,
    "critic_loss": 8.755853652954102,
    "ent_coef": 0.10418564826250076,
    "learning_rate": 0.001
  },
  {
    "episode": 7016,
    "reward": 89.529889,
    "length": 64,
    "time": 106706.075484,
    "actor_loss": -66.99842834472656,
    "critic_loss": 3.969773769378662,
    "ent_coef": 0.10096557438373566,
    "learning_rate": 0.001
  },
  {
    "episode": 7017,
    "reward": 88.671397,
    "length": 67,
    "time": 106718.031002,
    "actor_loss": -64.28121948242188,
    "critic_loss": 65.19197845458984,
    "ent_coef": 0.09210797399282455,
    "learning_rate": 0.001
  },
  {
    "episode": 7018,
    "reward": 76.308487,
    "length": 134,
    "time": 106741.58414,
    "actor_loss": -67.31245422363281,
    "critic_loss": 6.465423583984375,
    "ent_coef": 0.08523286134004593,
    "learning_rate": 0.001
  },
  {
    "episode": 7019,
    "reward": 91.226145,
    "length": 62,
    "time": 106755.038834,
    "actor_loss": -67.02903747558594,
    "critic_loss": 38.59394836425781,
    "ent_coef": 0.08420506864786148,
    "learning_rate": 0.001
  },
  {
    "episode": 7020,
    "reward": 90.611012,
    "length": 64,
    "time": 106767.645447,
    "actor_loss": -62.15637969970703,
    "critic_loss": 66.6546859741211,
    "ent_coef": 0.08249831199645996,
    "learning_rate": 0.001
  },
  {
    "episode": 7021,
    "reward": 91.158502,
    "length": 61,
    "time": 106779.017674,
    "actor_loss": -69.5997314453125,
    "critic_loss": 5.763308048248291,
    "ent_coef": 0.08389518409967422,
    "learning_rate": 0.001
  },
  {
    "episode": 7022,
    "reward": 85.258361,
    "length": 79,
    "time": 106793.246666,
    "actor_loss": -67.8121337890625,
    "critic_loss": 18.436954498291016,
    "ent_coef": 0.08445105701684952,
    "learning_rate": 0.001
  },
  {
    "episode": 7023,
    "reward": -155.961701,
    "length": 143,
    "time": 106815.716282,
    "actor_loss": -64.12986755371094,
    "critic_loss": 9.656953811645508,
    "ent_coef": 0.07892640680074692,
    "learning_rate": 0.001
  },
  {
    "episode": 7024,
    "reward": 84.972836,
    "length": 78,
    "time": 106829.028884,
    "actor_loss": -65.69332885742188,
    "critic_loss": 5.141196250915527,
    "ent_coef": 0.07604224234819412,
    "learning_rate": 0.001
  },
  {
    "episode": 7025,
    "reward": 90.198816,
    "length": 65,
    "time": 106843.359485,
    "actor_loss": -63.1002082824707,
    "critic_loss": 6.443201065063477,
    "ent_coef": 0.07636720687150955,
    "learning_rate": 0.001
  },
  {
    "episode": 7026,
    "reward": 89.692541,
    "length": 65,
    "time": 106857.792309,
    "actor_loss": -64.00187683105469,
    "critic_loss": 4.380986213684082,
    "ent_coef": 0.07526155561208725,
    "learning_rate": 0.001
  },
  {
    "episode": 7027,
    "reward": 87.522881,
    "length": 74,
    "time": 106872.175406,
    "actor_loss": -60.35722732543945,
    "critic_loss": 161.80587768554688,
    "ent_coef": 0.07600977271795273,
    "learning_rate": 0.001
  },
  {
    "episode": 7028,
    "reward": 91.137813,
    "length": 62,
    "time": 106884.393402,
    "actor_loss": -55.970890045166016,
    "critic_loss": 5.793271064758301,
    "ent_coef": 0.07729741185903549,
    "learning_rate": 0.001
  },
  {
    "episode": 7029,
    "reward": 91.206198,
    "length": 62,
    "time": 106897.737137,
    "actor_loss": -66.76083374023438,
    "critic_loss": 40.55926513671875,
    "ent_coef": 0.0752890333533287,
    "learning_rate": 0.001
  },
  {
    "episode": 7030,
    "reward": 88.033537,
    "length": 67,
    "time": 106909.321759,
    "actor_loss": -63.56653594970703,
    "critic_loss": 13.33210563659668,
    "ent_coef": 0.0742054432630539,
    "learning_rate": 0.001
  },
  {
    "episode": 7031,
    "reward": 92.746767,
    "length": 58,
    "time": 106926.18538,
    "actor_loss": -62.836883544921875,
    "critic_loss": 2.359198808670044,
    "ent_coef": 0.07854127138853073,
    "learning_rate": 0.001
  },
  {
    "episode": 7032,
    "reward": 86.583686,
    "length": 75,
    "time": 106939.327021,
    "actor_loss": -64.96792602539062,
    "critic_loss": 9.757745742797852,
    "ent_coef": 0.0778641402721405,
    "learning_rate": 0.001
  },
  {
    "episode": 7033,
    "reward": 86.961147,
    "length": 68,
    "time": 106955.396132,
    "actor_loss": -57.297115325927734,
    "critic_loss": 4.1162519454956055,
    "ent_coef": 0.07797295600175858,
    "learning_rate": 0.001
  },
  {
    "episode": 7034,
    "reward": 85.313868,
    "length": 82,
    "time": 106969.284291,
    "actor_loss": -69.53419494628906,
    "critic_loss": 15.814470291137695,
    "ent_coef": 0.08070210367441177,
    "learning_rate": 0.001
  },
  {
    "episode": 7035,
    "reward": 91.202333,
    "length": 61,
    "time": 106980.37096,
    "actor_loss": -64.85612487792969,
    "critic_loss": 12.10427474975586,
    "ent_coef": 0.08133687824010849,
    "learning_rate": 0.001
  },
  {
    "episode": 7036,
    "reward": 86.540693,
    "length": 76,
    "time": 106994.340933,
    "actor_loss": -65.13751220703125,
    "critic_loss": 5.750255584716797,
    "ent_coef": 0.08191004395484924,
    "learning_rate": 0.001
  },
  {
    "episode": 7037,
    "reward": 90.114948,
    "length": 66,
    "time": 107007.456598,
    "actor_loss": -64.80974578857422,
    "critic_loss": 6.517011642456055,
    "ent_coef": 0.08244840800762177,
    "learning_rate": 0.001
  },
  {
    "episode": 7038,
    "reward": 89.651404,
    "length": 67,
    "time": 107019.678522,
    "actor_loss": -63.4281005859375,
    "critic_loss": 40.87706756591797,
    "ent_coef": 0.08025633543729782,
    "learning_rate": 0.001
  },
  {
    "episode": 7039,
    "reward": 87.013092,
    "length": 75,
    "time": 107034.268625,
    "actor_loss": -66.56184387207031,
    "critic_loss": 5.619842052459717,
    "ent_coef": 0.07866764068603516,
    "learning_rate": 0.001
  },
  {
    "episode": 7040,
    "reward": -161.109934,
    "length": 173,
    "time": 107059.921782,
    "actor_loss": -69.4215316772461,
    "critic_loss": 10.242514610290527,
    "ent_coef": 0.08310426771640778,
    "learning_rate": 0.001
  },
  {
    "episode": 7041,
    "reward": 81.842731,
    "length": 80,
    "time": 107077.11652,
    "actor_loss": -62.74739074707031,
    "critic_loss": 61.89277648925781,
    "ent_coef": 0.08446653932332993,
    "learning_rate": 0.001
  },
  {
    "episode": 7042,
    "reward": 91.781223,
    "length": 61,
    "time": 107093.576854,
    "actor_loss": -66.37454223632812,
    "critic_loss": 22.705358505249023,
    "ent_coef": 0.08844408392906189,
    "learning_rate": 0.001
  },
  {
    "episode": 7043,
    "reward": 91.576574,
    "length": 61,
    "time": 107104.901609,
    "actor_loss": -62.248069763183594,
    "critic_loss": 15.729138374328613,
    "ent_coef": 0.09245282411575317,
    "learning_rate": 0.001
  },
  {
    "episode": 7044,
    "reward": 90.490803,
    "length": 63,
    "time": 107115.943386,
    "actor_loss": -67.21095275878906,
    "critic_loss": 86.62638854980469,
    "ent_coef": 0.09170524775981903,
    "learning_rate": 0.001
  },
  {
    "episode": 7045,
    "reward": 91.447967,
    "length": 62,
    "time": 107128.055353,
    "actor_loss": -61.23786163330078,
    "critic_loss": 35.27197265625,
    "ent_coef": 0.09330563247203827,
    "learning_rate": 0.001
  },
  {
    "episode": 7046,
    "reward": 88.932606,
    "length": 67,
    "time": 107139.907068,
    "actor_loss": -66.35403442382812,
    "critic_loss": 14.528106689453125,
    "ent_coef": 0.08924403786659241,
    "learning_rate": 0.001
  },
  {
    "episode": 7047,
    "reward": 88.439043,
    "length": 72,
    "time": 107156.94328,
    "actor_loss": -62.68315124511719,
    "critic_loss": 2.980597972869873,
    "ent_coef": 0.09163101017475128,
    "learning_rate": 0.001
  },
  {
    "episode": 7048,
    "reward": 91.504537,
    "length": 61,
    "time": 107167.816894,
    "actor_loss": -61.82064437866211,
    "critic_loss": 42.70473098754883,
    "ent_coef": 0.09487751126289368,
    "learning_rate": 0.001
  },
  {
    "episode": 7049,
    "reward": 89.286939,
    "length": 66,
    "time": 107179.605478,
    "actor_loss": -61.73612976074219,
    "critic_loss": 6.02928352355957,
    "ent_coef": 0.09681379795074463,
    "learning_rate": 0.001
  },
  {
    "episode": 7050,
    "reward": 90.733456,
    "length": 62,
    "time": 107194.792733,
    "actor_loss": -68.06498718261719,
    "critic_loss": 12.923095703125,
    "ent_coef": 0.09784805774688721,
    "learning_rate": 0.001
  },
  {
    "episode": 7051,
    "reward": 90.225795,
    "length": 64,
    "time": 107206.12673,
    "actor_loss": -62.3798828125,
    "critic_loss": 57.50926208496094,
    "ent_coef": 0.09628251194953918,
    "learning_rate": 0.001
  },
  {
    "episode": 7052,
    "reward": 91.474369,
    "length": 60,
    "time": 107218.484171,
    "actor_loss": -65.40779876708984,
    "critic_loss": 7.822198390960693,
    "ent_coef": 0.09347779303789139,
    "learning_rate": 0.001
  },
  {
    "episode": 7053,
    "reward": 90.814032,
    "length": 61,
    "time": 107230.396862,
    "actor_loss": -62.788902282714844,
    "critic_loss": 4.657022476196289,
    "ent_coef": 0.09427518397569656,
    "learning_rate": 0.001
  },
  {
    "episode": 7054,
    "reward": 91.88617,
    "length": 61,
    "time": 107243.968387,
    "actor_loss": -68.3488540649414,
    "critic_loss": 35.092369079589844,
    "ent_coef": 0.09557555615901947,
    "learning_rate": 0.001
  },
  {
    "episode": 7055,
    "reward": 90.74229,
    "length": 63,
    "time": 107256.181275,
    "actor_loss": -70.18812561035156,
    "critic_loss": 15.073158264160156,
    "ent_coef": 0.09542744606733322,
    "learning_rate": 0.001
  },
  {
    "episode": 7056,
    "reward": 89.657725,
    "length": 65,
    "time": 107267.641304,
    "actor_loss": -66.43264770507812,
    "critic_loss": 3.70035719871521,
    "ent_coef": 0.09324181079864502,
    "learning_rate": 0.001
  },
  {
    "episode": 7057,
    "reward": 90.517366,
    "length": 63,
    "time": 107281.90824,
    "actor_loss": -65.97246551513672,
    "critic_loss": 9.589456558227539,
    "ent_coef": 0.09030771255493164,
    "learning_rate": 0.001
  },
  {
    "episode": 7058,
    "reward": 90.993852,
    "length": 62,
    "time": 107293.95941,
    "actor_loss": -65.53103637695312,
    "critic_loss": 24.322969436645508,
    "ent_coef": 0.09246351569890976,
    "learning_rate": 0.001
  },
  {
    "episode": 7059,
    "reward": 90.769416,
    "length": 63,
    "time": 107305.12468,
    "actor_loss": -71.33279418945312,
    "critic_loss": 6.335332870483398,
    "ent_coef": 0.0933733731508255,
    "learning_rate": 0.001
  },
  {
    "episode": 7060,
    "reward": 89.553625,
    "length": 65,
    "time": 107321.427453,
    "actor_loss": -66.88528442382812,
    "critic_loss": 4.549367427825928,
    "ent_coef": 0.09106015413999557,
    "learning_rate": 0.001
  },
  {
    "episode": 7061,
    "reward": 90.385711,
    "length": 63,
    "time": 107336.345972,
    "actor_loss": -62.46524429321289,
    "critic_loss": 59.936378479003906,
    "ent_coef": 0.09227444976568222,
    "learning_rate": 0.001
  },
  {
    "episode": 7062,
    "reward": 89.279457,
    "length": 66,
    "time": 107348.029863,
    "actor_loss": -62.551849365234375,
    "critic_loss": 6.105037689208984,
    "ent_coef": 0.08884888142347336,
    "learning_rate": 0.001
  },
  {
    "episode": 7063,
    "reward": 89.81374,
    "length": 65,
    "time": 107361.700524,
    "actor_loss": -68.94622039794922,
    "critic_loss": 4.068730354309082,
    "ent_coef": 0.08539088070392609,
    "learning_rate": 0.001
  },
  {
    "episode": 7064,
    "reward": 90.149795,
    "length": 63,
    "time": 107372.921122,
    "actor_loss": -62.864627838134766,
    "critic_loss": 58.32107162475586,
    "ent_coef": 0.08357400447130203,
    "learning_rate": 0.001
  },
  {
    "episode": 7065,
    "reward": 91.653589,
    "length": 61,
    "time": 107384.85951,
    "actor_loss": -64.17141723632812,
    "critic_loss": 6.48362398147583,
    "ent_coef": 0.08518456667661667,
    "learning_rate": 0.001
  },
  {
    "episode": 7066,
    "reward": 90.428102,
    "length": 62,
    "time": 107397.789274,
    "actor_loss": -61.81508255004883,
    "critic_loss": 108.99613189697266,
    "ent_coef": 0.08267614990472794,
    "learning_rate": 0.001
  },
  {
    "episode": 7067,
    "reward": 91.131179,
    "length": 62,
    "time": 107409.364045,
    "actor_loss": -67.4886703491211,
    "critic_loss": 83.00454711914062,
    "ent_coef": 0.08743827044963837,
    "learning_rate": 0.001
  },
  {
    "episode": 7068,
    "reward": 91.701322,
    "length": 61,
    "time": 107422.923357,
    "actor_loss": -70.11808776855469,
    "critic_loss": 51.25483703613281,
    "ent_coef": 0.09017909318208694,
    "learning_rate": 0.001
  },
  {
    "episode": 7069,
    "reward": 84.057059,
    "length": 78,
    "time": 107436.383457,
    "actor_loss": -62.73750305175781,
    "critic_loss": 5.881107807159424,
    "ent_coef": 0.08981422334909439,
    "learning_rate": 0.001
  },
  {
    "episode": 7070,
    "reward": 86.779623,
    "length": 74,
    "time": 107449.635331,
    "actor_loss": -62.21828842163086,
    "critic_loss": 4.288370132446289,
    "ent_coef": 0.08966280519962311,
    "learning_rate": 0.001
  },
  {
    "episode": 7071,
    "reward": 86.389472,
    "length": 75,
    "time": 107463.726737,
    "actor_loss": -60.79014587402344,
    "critic_loss": 30.065319061279297,
    "ent_coef": 0.08711428940296173,
    "learning_rate": 0.001
  },
  {
    "episode": 7072,
    "reward": 90.848922,
    "length": 63,
    "time": 107476.760159,
    "actor_loss": -62.32086944580078,
    "critic_loss": 6.735115051269531,
    "ent_coef": 0.08846268057823181,
    "learning_rate": 0.001
  },
  {
    "episode": 7073,
    "reward": 91.381362,
    "length": 62,
    "time": 107488.633849,
    "actor_loss": -72.31401062011719,
    "critic_loss": 12.511356353759766,
    "ent_coef": 0.0924205407500267,
    "learning_rate": 0.001
  },
  {
    "episode": 7074,
    "reward": 90.71038,
    "length": 64,
    "time": 107502.205468,
    "actor_loss": -64.79695129394531,
    "critic_loss": 15.226107597351074,
    "ent_coef": 0.09280586987733841,
    "learning_rate": 0.001
  },
  {
    "episode": 7075,
    "reward": 89.872357,
    "length": 63,
    "time": 107515.790291,
    "actor_loss": -66.80508422851562,
    "critic_loss": 5.14375114440918,
    "ent_coef": 0.09146788716316223,
    "learning_rate": 0.001
  },
  {
    "episode": 7076,
    "reward": 91.233839,
    "length": 62,
    "time": 107526.741629,
    "actor_loss": -65.75051879882812,
    "critic_loss": 20.010154724121094,
    "ent_coef": 0.09221258014440536,
    "learning_rate": 0.001
  },
  {
    "episode": 7077,
    "reward": 90.234286,
    "length": 64,
    "time": 107538.599417,
    "actor_loss": -60.05113220214844,
    "critic_loss": 3.8791744709014893,
    "ent_coef": 0.09016814827919006,
    "learning_rate": 0.001
  },
  {
    "episode": 7078,
    "reward": 90.965757,
    "length": 62,
    "time": 107549.834499,
    "actor_loss": -65.44547271728516,
    "critic_loss": 8.577640533447266,
    "ent_coef": 0.08988960087299347,
    "learning_rate": 0.001
  },
  {
    "episode": 7079,
    "reward": 85.221547,
    "length": 73,
    "time": 107563.306247,
    "actor_loss": -59.81599426269531,
    "critic_loss": 36.37073516845703,
    "ent_coef": 0.08588603138923645,
    "learning_rate": 0.001
  },
  {
    "episode": 7080,
    "reward": 89.775243,
    "length": 64,
    "time": 107575.973013,
    "actor_loss": -69.91332244873047,
    "critic_loss": 23.878395080566406,
    "ent_coef": 0.08666861802339554,
    "learning_rate": 0.001
  },
  {
    "episode": 7081,
    "reward": 90.530422,
    "length": 63,
    "time": 107589.34332,
    "actor_loss": -61.135223388671875,
    "critic_loss": 8.610932350158691,
    "ent_coef": 0.08725160360336304,
    "learning_rate": 0.001
  },
  {
    "episode": 7082,
    "reward": 90.470188,
    "length": 64,
    "time": 107602.53454,
    "actor_loss": -70.67473602294922,
    "critic_loss": 96.12863159179688,
    "ent_coef": 0.0848882794380188,
    "learning_rate": 0.001
  },
  {
    "episode": 7083,
    "reward": 90.805781,
    "length": 64,
    "time": 107614.937033,
    "actor_loss": -67.36366271972656,
    "critic_loss": 12.08655071258545,
    "ent_coef": 0.08755974471569061,
    "learning_rate": 0.001
  },
  {
    "episode": 7084,
    "reward": 91.738004,
    "length": 61,
    "time": 107625.882267,
    "actor_loss": -69.51094818115234,
    "critic_loss": 4.538544654846191,
    "ent_coef": 0.08985365182161331,
    "learning_rate": 0.001
  },
  {
    "episode": 7085,
    "reward": 91.447894,
    "length": 61,
    "time": 107638.540621,
    "actor_loss": -66.3834228515625,
    "critic_loss": 5.96125602722168,
    "ent_coef": 0.0917414203286171,
    "learning_rate": 0.001
  },
  {
    "episode": 7086,
    "reward": 91.379669,
    "length": 62,
    "time": 107650.818434,
    "actor_loss": -59.33984375,
    "critic_loss": 93.84040069580078,
    "ent_coef": 0.09160042554140091,
    "learning_rate": 0.001
  },
  {
    "episode": 7087,
    "reward": 90.549491,
    "length": 64,
    "time": 107663.154702,
    "actor_loss": -63.98393630981445,
    "critic_loss": 13.595463752746582,
    "ent_coef": 0.090541772544384,
    "learning_rate": 0.001
  },
  {
    "episode": 7088,
    "reward": 88.458198,
    "length": 72,
    "time": 107675.93654,
    "actor_loss": -61.044898986816406,
    "critic_loss": 7.050768852233887,
    "ent_coef": 0.08847187459468842,
    "learning_rate": 0.001
  },
  {
    "episode": 7089,
    "reward": 87.828131,
    "length": 74,
    "time": 107690.137665,
    "actor_loss": -68.56976318359375,
    "critic_loss": 28.791160583496094,
    "ent_coef": 0.08954043686389923,
    "learning_rate": 0.001
  },
  {
    "episode": 7090,
    "reward": 90.053403,
    "length": 64,
    "time": 107704.161136,
    "actor_loss": -62.379432678222656,
    "critic_loss": 15.56907844543457,
    "ent_coef": 0.09066466242074966,
    "learning_rate": 0.001
  },
  {
    "episode": 7091,
    "reward": 84.525476,
    "length": 81,
    "time": 107717.901636,
    "actor_loss": -64.71043395996094,
    "critic_loss": 7.145663261413574,
    "ent_coef": 0.08556204289197922,
    "learning_rate": 0.001
  },
  {
    "episode": 7092,
    "reward": 90.815833,
    "length": 62,
    "time": 107730.258219,
    "actor_loss": -64.15349578857422,
    "critic_loss": 10.701133728027344,
    "ent_coef": 0.08469653129577637,
    "learning_rate": 0.001
  },
  {
    "episode": 7093,
    "reward": 89.247197,
    "length": 65,
    "time": 107741.86591,
    "actor_loss": -58.72962188720703,
    "critic_loss": 11.36014175415039,
    "ent_coef": 0.08762279152870178,
    "learning_rate": 0.001
  },
  {
    "episode": 7094,
    "reward": 89.512942,
    "length": 66,
    "time": 107754.437483,
    "actor_loss": -63.95737838745117,
    "critic_loss": 4.250495910644531,
    "ent_coef": 0.08888689428567886,
    "learning_rate": 0.001
  },
  {
    "episode": 7095,
    "reward": 90.378467,
    "length": 63,
    "time": 107767.926038,
    "actor_loss": -63.850372314453125,
    "critic_loss": 3.4264626502990723,
    "ent_coef": 0.0884479433298111,
    "learning_rate": 0.001
  },
  {
    "episode": 7096,
    "reward": 89.389418,
    "length": 67,
    "time": 107783.368468,
    "actor_loss": -68.9533462524414,
    "critic_loss": 28.30452537536621,
    "ent_coef": 0.08676830679178238,
    "learning_rate": 0.001
  },
  {
    "episode": 7097,
    "reward": 88.491098,
    "length": 66,
    "time": 107796.855265,
    "actor_loss": -69.41047668457031,
    "critic_loss": 8.326656341552734,
    "ent_coef": 0.08583301305770874,
    "learning_rate": 0.001
  },
  {
    "episode": 7098,
    "reward": 88.861047,
    "length": 68,
    "time": 107809.919581,
    "actor_loss": -58.80965805053711,
    "critic_loss": 23.839698791503906,
    "ent_coef": 0.07995983958244324,
    "learning_rate": 0.001
  },
  {
    "episode": 7099,
    "reward": 87.786431,
    "length": 70,
    "time": 107822.589802,
    "actor_loss": -55.872169494628906,
    "critic_loss": 35.74455642700195,
    "ent_coef": 0.07459395378828049,
    "learning_rate": 0.001
  },
  {
    "episode": 7100,
    "reward": 85.835324,
    "length": 74,
    "time": 107836.720632,
    "actor_loss": -58.79011917114258,
    "critic_loss": 6.6136474609375,
    "ent_coef": 0.07069066911935806,
    "learning_rate": 0.001
  },
  {
    "episode": 7101,
    "reward": 89.660892,
    "length": 66,
    "time": 107848.877841,
    "actor_loss": -62.85540008544922,
    "critic_loss": 40.434722900390625,
    "ent_coef": 0.07014111429452896,
    "learning_rate": 0.001
  },
  {
    "episode": 7102,
    "reward": 86.141087,
    "length": 79,
    "time": 107862.877767,
    "actor_loss": -69.32513427734375,
    "critic_loss": 28.337085723876953,
    "ent_coef": 0.06721431761980057,
    "learning_rate": 0.001
  },
  {
    "episode": 7103,
    "reward": 92.392554,
    "length": 59,
    "time": 107874.662697,
    "actor_loss": -64.247802734375,
    "critic_loss": 24.87574577331543,
    "ent_coef": 0.06830932945013046,
    "learning_rate": 0.001
  },
  {
    "episode": 7104,
    "reward": 89.666582,
    "length": 66,
    "time": 107887.440717,
    "actor_loss": -60.633079528808594,
    "critic_loss": 25.639686584472656,
    "ent_coef": 0.0697709321975708,
    "learning_rate": 0.001
  },
  {
    "episode": 7105,
    "reward": 88.535283,
    "length": 68,
    "time": 107899.238637,
    "actor_loss": -64.99076080322266,
    "critic_loss": 15.431453704833984,
    "ent_coef": 0.06836280226707458,
    "learning_rate": 0.001
  },
  {
    "episode": 7106,
    "reward": 91.083669,
    "length": 62,
    "time": 107911.785925,
    "actor_loss": -63.99127197265625,
    "critic_loss": 39.760162353515625,
    "ent_coef": 0.07378310710191727,
    "learning_rate": 0.001
  },
  {
    "episode": 7107,
    "reward": 91.09291,
    "length": 63,
    "time": 107923.085721,
    "actor_loss": -61.78108215332031,
    "critic_loss": 19.420351028442383,
    "ent_coef": 0.07508137077093124,
    "learning_rate": 0.001
  },
  {
    "episode": 7108,
    "reward": 90.539887,
    "length": 63,
    "time": 107938.815076,
    "actor_loss": -59.15983581542969,
    "critic_loss": 33.32582473754883,
    "ent_coef": 0.0730462595820427,
    "learning_rate": 0.001
  },
  {
    "episode": 7109,
    "reward": 92.390489,
    "length": 59,
    "time": 107950.384443,
    "actor_loss": -65.60015869140625,
    "critic_loss": 25.420852661132812,
    "ent_coef": 0.07683167606592178,
    "learning_rate": 0.001
  },
  {
    "episode": 7110,
    "reward": 91.236504,
    "length": 63,
    "time": 107962.577707,
    "actor_loss": -67.04367065429688,
    "critic_loss": 5.761619567871094,
    "ent_coef": 0.08020243048667908,
    "learning_rate": 0.001
  },
  {
    "episode": 7111,
    "reward": 92.006228,
    "length": 61,
    "time": 107974.253675,
    "actor_loss": -64.00957489013672,
    "critic_loss": 3.4493632316589355,
    "ent_coef": 0.08220040798187256,
    "learning_rate": 0.001
  },
  {
    "episode": 7112,
    "reward": 90.984496,
    "length": 62,
    "time": 107985.186428,
    "actor_loss": -64.88507080078125,
    "critic_loss": 5.873505115509033,
    "ent_coef": 0.08443237841129303,
    "learning_rate": 0.001
  },
  {
    "episode": 7113,
    "reward": 87.074767,
    "length": 72,
    "time": 107997.563051,
    "actor_loss": -64.96223449707031,
    "critic_loss": 37.939781188964844,
    "ent_coef": 0.08301641792058945,
    "learning_rate": 0.001
  },
  {
    "episode": 7114,
    "reward": 88.296949,
    "length": 72,
    "time": 108012.16692,
    "actor_loss": -65.84546661376953,
    "critic_loss": 22.962200164794922,
    "ent_coef": 0.08192053437232971,
    "learning_rate": 0.001
  },
  {
    "episode": 7115,
    "reward": 85.488556,
    "length": 87,
    "time": 108027.396461,
    "actor_loss": -64.92131042480469,
    "critic_loss": 168.9689483642578,
    "ent_coef": 0.0802500769495964,
    "learning_rate": 0.001
  },
  {
    "episode": 7116,
    "reward": 89.546956,
    "length": 65,
    "time": 108040.988536,
    "actor_loss": -65.30500030517578,
    "critic_loss": 21.224227905273438,
    "ent_coef": 0.07940410077571869,
    "learning_rate": 0.001
  },
  {
    "episode": 7117,
    "reward": 88.307059,
    "length": 69,
    "time": 108055.279634,
    "actor_loss": -63.991455078125,
    "critic_loss": 49.34259796142578,
    "ent_coef": 0.07788164913654327,
    "learning_rate": 0.001
  },
  {
    "episode": 7118,
    "reward": 90.54628,
    "length": 64,
    "time": 108067.991795,
    "actor_loss": -69.1844482421875,
    "critic_loss": 4.964982986450195,
    "ent_coef": 0.0785689502954483,
    "learning_rate": 0.001
  },
  {
    "episode": 7119,
    "reward": 89.115349,
    "length": 68,
    "time": 108083.319566,
    "actor_loss": -65.44767761230469,
    "critic_loss": 4.30655574798584,
    "ent_coef": 0.07954002916812897,
    "learning_rate": 0.001
  },
  {
    "episode": 7120,
    "reward": 89.997876,
    "length": 65,
    "time": 108095.123365,
    "actor_loss": -62.968849182128906,
    "critic_loss": 5.951066017150879,
    "ent_coef": 0.07856829464435577,
    "learning_rate": 0.001
  },
  {
    "episode": 7121,
    "reward": 87.828439,
    "length": 69,
    "time": 108109.364294,
    "actor_loss": -65.88317108154297,
    "critic_loss": 69.9100341796875,
    "ent_coef": 0.07756657898426056,
    "learning_rate": 0.001
  },
  {
    "episode": 7122,
    "reward": 89.983579,
    "length": 64,
    "time": 108123.515136,
    "actor_loss": -68.34313201904297,
    "critic_loss": 106.57328033447266,
    "ent_coef": 0.0781618133187294,
    "learning_rate": 0.001
  },
  {
    "episode": 7123,
    "reward": 87.229286,
    "length": 72,
    "time": 108137.955196,
    "actor_loss": -62.93901824951172,
    "critic_loss": 9.90812873840332,
    "ent_coef": 0.07510575652122498,
    "learning_rate": 0.001
  },
  {
    "episode": 7124,
    "reward": 90.246559,
    "length": 64,
    "time": 108150.316329,
    "actor_loss": -69.41483306884766,
    "critic_loss": 18.950851440429688,
    "ent_coef": 0.07617804408073425,
    "learning_rate": 0.001
  },
  {
    "episode": 7125,
    "reward": 91.788616,
    "length": 61,
    "time": 108161.965365,
    "actor_loss": -70.41092681884766,
    "critic_loss": 20.919002532958984,
    "ent_coef": 0.07804924994707108,
    "learning_rate": 0.001
  },
  {
    "episode": 7126,
    "reward": 89.709225,
    "length": 66,
    "time": 108176.308591,
    "actor_loss": -67.49821472167969,
    "critic_loss": 9.176101684570312,
    "ent_coef": 0.07721032947301865,
    "learning_rate": 0.001
  },
  {
    "episode": 7127,
    "reward": 86.898502,
    "length": 71,
    "time": 108189.12016,
    "actor_loss": -66.42788696289062,
    "critic_loss": 29.888126373291016,
    "ent_coef": 0.07248692214488983,
    "learning_rate": 0.001
  },
  {
    "episode": 7128,
    "reward": 89.376249,
    "length": 65,
    "time": 108200.523994,
    "actor_loss": -65.47926330566406,
    "critic_loss": 28.99659538269043,
    "ent_coef": 0.0704098716378212,
    "learning_rate": 0.001
  },
  {
    "episode": 7129,
    "reward": 90.59066,
    "length": 63,
    "time": 108212.705059,
    "actor_loss": -56.52470779418945,
    "critic_loss": 32.558982849121094,
    "ent_coef": 0.07080941647291183,
    "learning_rate": 0.001
  },
  {
    "episode": 7130,
    "reward": 90.663032,
    "length": 64,
    "time": 108225.277559,
    "actor_loss": -63.85357666015625,
    "critic_loss": 19.007152557373047,
    "ent_coef": 0.0731029361486435,
    "learning_rate": 0.001
  },
  {
    "episode": 7131,
    "reward": 91.555135,
    "length": 61,
    "time": 108237.492883,
    "actor_loss": -63.148921966552734,
    "critic_loss": 3.415771484375,
    "ent_coef": 0.07413224875926971,
    "learning_rate": 0.001
  },
  {
    "episode": 7132,
    "reward": 90.879762,
    "length": 62,
    "time": 108248.928053,
    "actor_loss": -65.83383178710938,
    "critic_loss": 62.338356018066406,
    "ent_coef": 0.07522626966238022,
    "learning_rate": 0.001
  },
  {
    "episode": 7133,
    "reward": 90.093311,
    "length": 66,
    "time": 108263.367975,
    "actor_loss": -64.44151306152344,
    "critic_loss": 7.288829326629639,
    "ent_coef": 0.07433070242404938,
    "learning_rate": 0.001
  },
  {
    "episode": 7134,
    "reward": 89.599689,
    "length": 66,
    "time": 108278.647851,
    "actor_loss": -64.78544616699219,
    "critic_loss": 25.83436393737793,
    "ent_coef": 0.07398414611816406,
    "learning_rate": 0.001
  },
  {
    "episode": 7135,
    "reward": 89.525851,
    "length": 66,
    "time": 108291.536041,
    "actor_loss": -63.96758270263672,
    "critic_loss": 21.50679588317871,
    "ent_coef": 0.0739249512553215,
    "learning_rate": 0.001
  },
  {
    "episode": 7136,
    "reward": 86.501152,
    "length": 72,
    "time": 108304.236843,
    "actor_loss": -63.27539825439453,
    "critic_loss": 56.89012145996094,
    "ent_coef": 0.07177925854921341,
    "learning_rate": 0.001
  },
  {
    "episode": 7137,
    "reward": 91.073916,
    "length": 62,
    "time": 108315.582122,
    "actor_loss": -63.415000915527344,
    "critic_loss": 56.37016296386719,
    "ent_coef": 0.07038301229476929,
    "learning_rate": 0.001
  },
  {
    "episode": 7138,
    "reward": 88.955667,
    "length": 66,
    "time": 108328.758962,
    "actor_loss": -60.85929870605469,
    "critic_loss": 3.7434892654418945,
    "ent_coef": 0.06841204315423965,
    "learning_rate": 0.001
  },
  {
    "episode": 7139,
    "reward": 91.333547,
    "length": 62,
    "time": 108342.065829,
    "actor_loss": -59.56559371948242,
    "critic_loss": 3.6369969844818115,
    "ent_coef": 0.06895761936903,
    "learning_rate": 0.001
  },
  {
    "episode": 7140,
    "reward": 90.604719,
    "length": 63,
    "time": 108355.946229,
    "actor_loss": -68.87191772460938,
    "critic_loss": 54.76074981689453,
    "ent_coef": 0.07251326739788055,
    "learning_rate": 0.001
  },
  {
    "episode": 7141,
    "reward": 87.854497,
    "length": 69,
    "time": 108370.179996,
    "actor_loss": -68.1676254272461,
    "critic_loss": 58.20214080810547,
    "ent_coef": 0.07102014869451523,
    "learning_rate": 0.001
  },
  {
    "episode": 7142,
    "reward": 90.468419,
    "length": 65,
    "time": 108383.677169,
    "actor_loss": -62.76325225830078,
    "critic_loss": 17.347793579101562,
    "ent_coef": 0.07317520678043365,
    "learning_rate": 0.001
  },
  {
    "episode": 7143,
    "reward": 90.367467,
    "length": 64,
    "time": 108395.241496,
    "actor_loss": -59.31982421875,
    "critic_loss": 21.25843048095703,
    "ent_coef": 0.07298856973648071,
    "learning_rate": 0.001
  },
  {
    "episode": 7144,
    "reward": 89.291667,
    "length": 66,
    "time": 108407.299407,
    "actor_loss": -59.27513885498047,
    "critic_loss": 3.5957560539245605,
    "ent_coef": 0.07392138987779617,
    "learning_rate": 0.001
  },
  {
    "episode": 7145,
    "reward": 89.83873,
    "length": 63,
    "time": 108425.86576,
    "actor_loss": -68.23367309570312,
    "critic_loss": 4.387308120727539,
    "ent_coef": 0.07634735852479935,
    "learning_rate": 0.001
  },
  {
    "episode": 7146,
    "reward": 89.665187,
    "length": 65,
    "time": 108438.27296,
    "actor_loss": -67.59602355957031,
    "critic_loss": 106.73825073242188,
    "ent_coef": 0.0768592357635498,
    "learning_rate": 0.001
  },
  {
    "episode": 7147,
    "reward": 89.351251,
    "length": 66,
    "time": 108449.992651,
    "actor_loss": -68.95120239257812,
    "critic_loss": 4.194753646850586,
    "ent_coef": 0.07798228412866592,
    "learning_rate": 0.001
  },
  {
    "episode": 7148,
    "reward": 89.603071,
    "length": 65,
    "time": 108462.371958,
    "actor_loss": -65.6953125,
    "critic_loss": 5.711289405822754,
    "ent_coef": 0.07596652954816818,
    "learning_rate": 0.001
  },
  {
    "episode": 7149,
    "reward": 90.9671,
    "length": 62,
    "time": 108474.255733,
    "actor_loss": -67.89965057373047,
    "critic_loss": 130.85220336914062,
    "ent_coef": 0.07749634981155396,
    "learning_rate": 0.001
  },
  {
    "episode": 7150,
    "reward": 90.516275,
    "length": 63,
    "time": 108486.363581,
    "actor_loss": -62.7845458984375,
    "critic_loss": 12.049454689025879,
    "ent_coef": 0.08006551861763,
    "learning_rate": 0.001
  },
  {
    "episode": 7151,
    "reward": 87.514711,
    "length": 69,
    "time": 108499.213524,
    "actor_loss": -69.58747863769531,
    "critic_loss": 13.785137176513672,
    "ent_coef": 0.07716242223978043,
    "learning_rate": 0.001
  },
  {
    "episode": 7152,
    "reward": 85.154217,
    "length": 73,
    "time": 108512.785686,
    "actor_loss": -72.62395477294922,
    "critic_loss": 3.186586380004883,
    "ent_coef": 0.07331056892871857,
    "learning_rate": 0.001
  },
  {
    "episode": 7153,
    "reward": 89.798999,
    "length": 63,
    "time": 108527.103636,
    "actor_loss": -60.80908203125,
    "critic_loss": 23.726926803588867,
    "ent_coef": 0.07415894418954849,
    "learning_rate": 0.001
  },
  {
    "episode": 7154,
    "reward": 91.372963,
    "length": 61,
    "time": 108537.917261,
    "actor_loss": -66.73770141601562,
    "critic_loss": 18.69283676147461,
    "ent_coef": 0.07499243319034576,
    "learning_rate": 0.001
  },
  {
    "episode": 7155,
    "reward": 90.436649,
    "length": 63,
    "time": 108554.292882,
    "actor_loss": -66.21610260009766,
    "critic_loss": 21.88813018798828,
    "ent_coef": 0.07717013359069824,
    "learning_rate": 0.001
  },
  {
    "episode": 7156,
    "reward": 89.880215,
    "length": 64,
    "time": 108567.511882,
    "actor_loss": -66.01151275634766,
    "critic_loss": 4.195598602294922,
    "ent_coef": 0.07417537271976471,
    "learning_rate": 0.001
  },
  {
    "episode": 7157,
    "reward": 87.094646,
    "length": 68,
    "time": 108579.917414,
    "actor_loss": -68.97177124023438,
    "critic_loss": 37.74479675292969,
    "ent_coef": 0.0737440213561058,
    "learning_rate": 0.001
  },
  {
    "episode": 7158,
    "reward": 90.673375,
    "length": 63,
    "time": 108591.021539,
    "actor_loss": -62.02277374267578,
    "critic_loss": 18.308391571044922,
    "ent_coef": 0.07463375478982925,
    "learning_rate": 0.001
  },
  {
    "episode": 7159,
    "reward": 88.765353,
    "length": 67,
    "time": 108604.763149,
    "actor_loss": -67.00039672851562,
    "critic_loss": 58.339969635009766,
    "ent_coef": 0.07228521257638931,
    "learning_rate": 0.001
  },
  {
    "episode": 7160,
    "reward": 81.448417,
    "length": 86,
    "time": 108621.280623,
    "actor_loss": -67.75750732421875,
    "critic_loss": 3.6161856651306152,
    "ent_coef": 0.0679149329662323,
    "learning_rate": 0.001
  },
  {
    "episode": 7161,
    "reward": 85.178286,
    "length": 73,
    "time": 108635.116825,
    "actor_loss": -63.757713317871094,
    "critic_loss": 21.082393646240234,
    "ent_coef": 0.06706846505403519,
    "learning_rate": 0.001
  },
  {
    "episode": 7162,
    "reward": 89.479307,
    "length": 67,
    "time": 108647.55152,
    "actor_loss": -62.57227325439453,
    "critic_loss": 37.19656753540039,
    "ent_coef": 0.06953942775726318,
    "learning_rate": 0.001
  },
  {
    "episode": 7163,
    "reward": 85.214596,
    "length": 86,
    "time": 108664.889592,
    "actor_loss": -62.19200897216797,
    "critic_loss": 4.5367350578308105,
    "ent_coef": 0.0714634358882904,
    "learning_rate": 0.001
  },
  {
    "episode": 7164,
    "reward": 81.703816,
    "length": 94,
    "time": 108682.307671,
    "actor_loss": -62.27581024169922,
    "critic_loss": 5.475224018096924,
    "ent_coef": 0.07599308341741562,
    "learning_rate": 0.001
  },
  {
    "episode": 7165,
    "reward": 91.723441,
    "length": 61,
    "time": 108696.909702,
    "actor_loss": -70.58447265625,
    "critic_loss": 68.3406753540039,
    "ent_coef": 0.07868825644254684,
    "learning_rate": 0.001
  },
  {
    "episode": 7166,
    "reward": 86.851646,
    "length": 72,
    "time": 108711.009454,
    "actor_loss": -62.985511779785156,
    "critic_loss": 24.480018615722656,
    "ent_coef": 0.07720829546451569,
    "learning_rate": 0.001
  },
  {
    "episode": 7167,
    "reward": 89.81663,
    "length": 66,
    "time": 108725.185548,
    "actor_loss": -69.80720520019531,
    "critic_loss": 16.21125030517578,
    "ent_coef": 0.07559531182050705,
    "learning_rate": 0.001
  },
  {
    "episode": 7168,
    "reward": 91.292058,
    "length": 63,
    "time": 108737.335746,
    "actor_loss": -65.2964859008789,
    "critic_loss": 6.206363201141357,
    "ent_coef": 0.0777812972664833,
    "learning_rate": 0.001
  },
  {
    "episode": 7169,
    "reward": 89.287292,
    "length": 66,
    "time": 108749.720715,
    "actor_loss": -65.31892395019531,
    "critic_loss": 157.4140625,
    "ent_coef": 0.08021239191293716,
    "learning_rate": 0.001
  },
  {
    "episode": 7170,
    "reward": 91.420907,
    "length": 62,
    "time": 108763.77174,
    "actor_loss": -69.68917846679688,
    "critic_loss": 41.323787689208984,
    "ent_coef": 0.08242016285657883,
    "learning_rate": 0.001
  },
  {
    "episode": 7171,
    "reward": 91.286235,
    "length": 62,
    "time": 108775.142108,
    "actor_loss": -70.22969818115234,
    "critic_loss": 38.73554992675781,
    "ent_coef": 0.08369854837656021,
    "learning_rate": 0.001
  },
  {
    "episode": 7172,
    "reward": 89.697436,
    "length": 66,
    "time": 108787.598103,
    "actor_loss": -67.4757080078125,
    "critic_loss": 8.699783325195312,
    "ent_coef": 0.08549866825342178,
    "learning_rate": 0.001
  },
  {
    "episode": 7173,
    "reward": 90.157521,
    "length": 66,
    "time": 108799.294814,
    "actor_loss": -61.16713333129883,
    "critic_loss": 12.342948913574219,
    "ent_coef": 0.08300561457872391,
    "learning_rate": 0.001
  },
  {
    "episode": 7174,
    "reward": 89.506744,
    "length": 66,
    "time": 108812.202828,
    "actor_loss": -68.85431671142578,
    "critic_loss": 58.353790283203125,
    "ent_coef": 0.08212205767631531,
    "learning_rate": 0.001
  },
  {
    "episode": 7175,
    "reward": 90.196826,
    "length": 64,
    "time": 108825.366895,
    "actor_loss": -59.495967864990234,
    "critic_loss": 16.777366638183594,
    "ent_coef": 0.08338262140750885,
    "learning_rate": 0.001
  },
  {
    "episode": 7176,
    "reward": 89.653467,
    "length": 68,
    "time": 108839.100909,
    "actor_loss": -72.71676635742188,
    "critic_loss": 6.358400344848633,
    "ent_coef": 0.0804734006524086,
    "learning_rate": 0.001
  },
  {
    "episode": 7177,
    "reward": 89.507006,
    "length": 66,
    "time": 108852.883787,
    "actor_loss": -67.31071472167969,
    "critic_loss": 40.08063888549805,
    "ent_coef": 0.07685443013906479,
    "learning_rate": 0.001
  },
  {
    "episode": 7178,
    "reward": 89.913005,
    "length": 65,
    "time": 108864.437713,
    "actor_loss": -61.334449768066406,
    "critic_loss": 7.967221260070801,
    "ent_coef": 0.07639358937740326,
    "learning_rate": 0.001
  },
  {
    "episode": 7179,
    "reward": 89.232623,
    "length": 67,
    "time": 108876.988354,
    "actor_loss": -69.0439453125,
    "critic_loss": 16.21811294555664,
    "ent_coef": 0.07294394820928574,
    "learning_rate": 0.001
  },
  {
    "episode": 7180,
    "reward": 90.002192,
    "length": 66,
    "time": 108888.620272,
    "actor_loss": -66.53382873535156,
    "critic_loss": 19.487825393676758,
    "ent_coef": 0.07268188148736954,
    "learning_rate": 0.001
  },
  {
    "episode": 7181,
    "reward": 89.805653,
    "length": 65,
    "time": 108900.72116,
    "actor_loss": -61.0609016418457,
    "critic_loss": 9.027403831481934,
    "ent_coef": 0.07104045897722244,
    "learning_rate": 0.001
  },
  {
    "episode": 7182,
    "reward": 86.84851,
    "length": 72,
    "time": 108914.960604,
    "actor_loss": -66.18050384521484,
    "critic_loss": 139.38816833496094,
    "ent_coef": 0.06645973771810532,
    "learning_rate": 0.001
  },
  {
    "episode": 7183,
    "reward": 89.804709,
    "length": 66,
    "time": 108927.731774,
    "actor_loss": -68.38427734375,
    "critic_loss": 6.583020210266113,
    "ent_coef": 0.06405466049909592,
    "learning_rate": 0.001
  },
  {
    "episode": 7184,
    "reward": 88.038241,
    "length": 70,
    "time": 108941.206314,
    "actor_loss": -63.44139862060547,
    "critic_loss": 3.7302188873291016,
    "ent_coef": 0.06621171534061432,
    "learning_rate": 0.001
  },
  {
    "episode": 7185,
    "reward": 91.490482,
    "length": 62,
    "time": 108952.8432,
    "actor_loss": -58.442161560058594,
    "critic_loss": 20.082216262817383,
    "ent_coef": 0.06899986416101456,
    "learning_rate": 0.001
  },
  {
    "episode": 7186,
    "reward": 88.042312,
    "length": 67,
    "time": 108964.525962,
    "actor_loss": -65.35543823242188,
    "critic_loss": 6.0719404220581055,
    "ent_coef": 0.06766196340322495,
    "learning_rate": 0.001
  },
  {
    "episode": 7187,
    "reward": 92.13819,
    "length": 60,
    "time": 108975.398058,
    "actor_loss": -64.22460174560547,
    "critic_loss": 24.812482833862305,
    "ent_coef": 0.06998611986637115,
    "learning_rate": 0.001
  },
  {
    "episode": 7188,
    "reward": 91.425534,
    "length": 62,
    "time": 108987.793224,
    "actor_loss": -59.80493927001953,
    "critic_loss": 95.8465576171875,
    "ent_coef": 0.07216346263885498,
    "learning_rate": 0.001
  },
  {
    "episode": 7189,
    "reward": 90.925134,
    "length": 62,
    "time": 108999.163166,
    "actor_loss": -64.65776062011719,
    "critic_loss": 79.57969665527344,
    "ent_coef": 0.07257264107465744,
    "learning_rate": 0.001
  },
  {
    "episode": 7190,
    "reward": 92.146756,
    "length": 60,
    "time": 109010.140165,
    "actor_loss": -63.811126708984375,
    "critic_loss": 3.4347453117370605,
    "ent_coef": 0.07336785644292831,
    "learning_rate": 0.001
  },
  {
    "episode": 7191,
    "reward": 92.370502,
    "length": 60,
    "time": 109021.137668,
    "actor_loss": -66.55860900878906,
    "critic_loss": 20.799781799316406,
    "ent_coef": 0.08085384219884872,
    "learning_rate": 0.001
  },
  {
    "episode": 7192,
    "reward": 92.382948,
    "length": 59,
    "time": 109031.874456,
    "actor_loss": -65.582275390625,
    "critic_loss": 6.332262992858887,
    "ent_coef": 0.08661158382892609,
    "learning_rate": 0.001
  },
  {
    "episode": 7193,
    "reward": 91.37253,
    "length": 61,
    "time": 109042.937895,
    "actor_loss": -62.50159454345703,
    "critic_loss": 21.783618927001953,
    "ent_coef": 0.08794040977954865,
    "learning_rate": 0.001
  },
  {
    "episode": 7194,
    "reward": 91.414032,
    "length": 61,
    "time": 109057.673065,
    "actor_loss": -62.965885162353516,
    "critic_loss": 19.269123077392578,
    "ent_coef": 0.08582580834627151,
    "learning_rate": 0.001
  },
  {
    "episode": 7195,
    "reward": 91.305555,
    "length": 61,
    "time": 109070.905601,
    "actor_loss": -64.51483154296875,
    "critic_loss": 3.343507766723633,
    "ent_coef": 0.08539792895317078,
    "learning_rate": 0.001
  },
  {
    "episode": 7196,
    "reward": 89.605928,
    "length": 65,
    "time": 109085.330123,
    "actor_loss": -63.18732452392578,
    "critic_loss": 6.689178466796875,
    "ent_coef": 0.08321214467287064,
    "learning_rate": 0.001
  },
  {
    "episode": 7197,
    "reward": 87.676665,
    "length": 74,
    "time": 109099.115588,
    "actor_loss": -65.94798278808594,
    "critic_loss": 3.735337734222412,
    "ent_coef": 0.08234112709760666,
    "learning_rate": 0.001
  },
  {
    "episode": 7198,
    "reward": 84.588863,
    "length": 87,
    "time": 109113.41883,
    "actor_loss": -66.48683166503906,
    "critic_loss": 9.472522735595703,
    "ent_coef": 0.08181458711624146,
    "learning_rate": 0.001
  },
  {
    "episode": 7199,
    "reward": 89.411281,
    "length": 65,
    "time": 109126.122124,
    "actor_loss": -67.59396362304688,
    "critic_loss": 8.556538581848145,
    "ent_coef": 0.08101877570152283,
    "learning_rate": 0.001
  },
  {
    "episode": 7200,
    "reward": 90.278436,
    "length": 62,
    "time": 109138.235466,
    "actor_loss": -64.6097640991211,
    "critic_loss": 4.362140655517578,
    "ent_coef": 0.07952872663736343,
    "learning_rate": 0.001
  },
  {
    "episode": 7201,
    "reward": 88.03704,
    "length": 67,
    "time": 109151.785619,
    "actor_loss": -66.33626556396484,
    "critic_loss": 2.4839327335357666,
    "ent_coef": 0.07770407944917679,
    "learning_rate": 0.001
  },
  {
    "episode": 7202,
    "reward": 87.691076,
    "length": 67,
    "time": 109164.610988,
    "actor_loss": -61.536258697509766,
    "critic_loss": 20.242198944091797,
    "ent_coef": 0.077640600502491,
    "learning_rate": 0.001
  },
  {
    "episode": 7203,
    "reward": 86.756465,
    "length": 70,
    "time": 109177.128,
    "actor_loss": -64.1422348022461,
    "critic_loss": 10.600738525390625,
    "ent_coef": 0.07521533221006393,
    "learning_rate": 0.001
  },
  {
    "episode": 7204,
    "reward": 88.516519,
    "length": 66,
    "time": 109190.258292,
    "actor_loss": -60.106624603271484,
    "critic_loss": 7.778627395629883,
    "ent_coef": 0.07530763000249863,
    "learning_rate": 0.001
  },
  {
    "episode": 7205,
    "reward": 88.362659,
    "length": 72,
    "time": 109205.176058,
    "actor_loss": -66.24577331542969,
    "critic_loss": 3.2761025428771973,
    "ent_coef": 0.07648051530122757,
    "learning_rate": 0.001
  },
  {
    "episode": 7206,
    "reward": 83.275238,
    "length": 85,
    "time": 109222.816496,
    "actor_loss": -67.59952545166016,
    "critic_loss": 39.519264221191406,
    "ent_coef": 0.0732099637389183,
    "learning_rate": 0.001
  },
  {
    "episode": 7207,
    "reward": 81.921763,
    "length": 92,
    "time": 109238.453286,
    "actor_loss": -62.617149353027344,
    "critic_loss": 12.38345718383789,
    "ent_coef": 0.07489648461341858,
    "learning_rate": 0.001
  },
  {
    "episode": 7208,
    "reward": 90.089022,
    "length": 63,
    "time": 109250.11366,
    "actor_loss": -66.14872741699219,
    "critic_loss": 6.0594024658203125,
    "ent_coef": 0.07676498591899872,
    "learning_rate": 0.001
  },
  {
    "episode": 7209,
    "reward": 87.110295,
    "length": 71,
    "time": 109263.014745,
    "actor_loss": -67.69852447509766,
    "critic_loss": 5.31611442565918,
    "ent_coef": 0.07811296731233597,
    "learning_rate": 0.001
  },
  {
    "episode": 7210,
    "reward": 88.273406,
    "length": 67,
    "time": 109274.73879,
    "actor_loss": -66.01530456542969,
    "critic_loss": 10.872856140136719,
    "ent_coef": 0.07689613103866577,
    "learning_rate": 0.001
  },
  {
    "episode": 7211,
    "reward": 88.216148,
    "length": 66,
    "time": 109286.756729,
    "actor_loss": -61.053958892822266,
    "critic_loss": 38.871150970458984,
    "ent_coef": 0.0769299566745758,
    "learning_rate": 0.001
  },
  {
    "episode": 7212,
    "reward": 87.639053,
    "length": 67,
    "time": 109298.452241,
    "actor_loss": -68.39894104003906,
    "critic_loss": 21.18126678466797,
    "ent_coef": 0.07813261449337006,
    "learning_rate": 0.001
  },
  {
    "episode": 7213,
    "reward": 86.290475,
    "length": 71,
    "time": 109311.522224,
    "actor_loss": -70.9704360961914,
    "critic_loss": 35.31856155395508,
    "ent_coef": 0.077663853764534,
    "learning_rate": 0.001
  },
  {
    "episode": 7214,
    "reward": 87.182555,
    "length": 68,
    "time": 109324.366177,
    "actor_loss": -64.20626831054688,
    "critic_loss": 6.920534133911133,
    "ent_coef": 0.07555867731571198,
    "learning_rate": 0.001
  },
  {
    "episode": 7215,
    "reward": 81.862774,
    "length": 93,
    "time": 109343.807273,
    "actor_loss": -68.36288452148438,
    "critic_loss": 1239.1434326171875,
    "ent_coef": 0.07462155073881149,
    "learning_rate": 0.001
  },
  {
    "episode": 7216,
    "reward": 79.381467,
    "length": 96,
    "time": 109360.497231,
    "actor_loss": -66.72409057617188,
    "critic_loss": 5.029170036315918,
    "ent_coef": 0.07847242802381516,
    "learning_rate": 0.001
  },
  {
    "episode": 7217,
    "reward": 87.721063,
    "length": 67,
    "time": 109374.923391,
    "actor_loss": -74.3701171875,
    "critic_loss": 23.203868865966797,
    "ent_coef": 0.07926906645298004,
    "learning_rate": 0.001
  },
  {
    "episode": 7218,
    "reward": 82.131178,
    "length": 81,
    "time": 109389.54962,
    "actor_loss": -62.22832107543945,
    "critic_loss": 5.6152849197387695,
    "ent_coef": 0.07374237477779388,
    "learning_rate": 0.001
  },
  {
    "episode": 7219,
    "reward": 54.562389,
    "length": 134,
    "time": 109409.97905,
    "actor_loss": -60.144500732421875,
    "critic_loss": 4.502649784088135,
    "ent_coef": 0.06605889648199081,
    "learning_rate": 0.001
  },
  {
    "episode": 7220,
    "reward": 87.07359,
    "length": 68,
    "time": 109422.909492,
    "actor_loss": -62.28754425048828,
    "critic_loss": 3.2847206592559814,
    "ent_coef": 0.06607409566640854,
    "learning_rate": 0.001
  },
  {
    "episode": 7221,
    "reward": 80.441781,
    "length": 89,
    "time": 109439.723391,
    "actor_loss": -67.48916625976562,
    "critic_loss": 9.322722434997559,
    "ent_coef": 0.06424855440855026,
    "learning_rate": 0.001
  },
  {
    "episode": 7222,
    "reward": 79.334696,
    "length": 88,
    "time": 109454.130934,
    "actor_loss": -64.12157440185547,
    "critic_loss": 18.51105308532715,
    "ent_coef": 0.0632615014910698,
    "learning_rate": 0.001
  },
  {
    "episode": 7223,
    "reward": 83.370094,
    "length": 78,
    "time": 109467.338145,
    "actor_loss": -70.32061767578125,
    "critic_loss": 13.406594276428223,
    "ent_coef": 0.06054975837469101,
    "learning_rate": 0.001
  },
  {
    "episode": 7224,
    "reward": 89.314309,
    "length": 66,
    "time": 109480.835736,
    "actor_loss": -62.94574737548828,
    "critic_loss": 24.987136840820312,
    "ent_coef": 0.060392577201128006,
    "learning_rate": 0.001
  },
  {
    "episode": 7225,
    "reward": 83.552544,
    "length": 77,
    "time": 109495.029449,
    "actor_loss": -70.50997924804688,
    "critic_loss": 31.51848793029785,
    "ent_coef": 0.058739081025123596,
    "learning_rate": 0.001
  },
  {
    "episode": 7226,
    "reward": 88.893372,
    "length": 66,
    "time": 109508.736851,
    "actor_loss": -71.250732421875,
    "critic_loss": 31.280677795410156,
    "ent_coef": 0.05814184993505478,
    "learning_rate": 0.001
  },
  {
    "episode": 7227,
    "reward": 85.249269,
    "length": 81,
    "time": 109524.514906,
    "actor_loss": -64.58285522460938,
    "critic_loss": 6.334212303161621,
    "ent_coef": 0.059043705463409424,
    "learning_rate": 0.001
  },
  {
    "episode": 7228,
    "reward": 78.651262,
    "length": 86,
    "time": 109539.73893,
    "actor_loss": -68.90813446044922,
    "critic_loss": 3.0297443866729736,
    "ent_coef": 0.057819053530693054,
    "learning_rate": 0.001
  },
  {
    "episode": 7229,
    "reward": 87.439217,
    "length": 70,
    "time": 109552.197869,
    "actor_loss": -70.3107681274414,
    "critic_loss": 14.850677490234375,
    "ent_coef": 0.06289020925760269,
    "learning_rate": 0.001
  },
  {
    "episode": 7230,
    "reward": 84.008057,
    "length": 88,
    "time": 109567.879007,
    "actor_loss": -63.68136215209961,
    "critic_loss": 55.49097442626953,
    "ent_coef": 0.067451111972332,
    "learning_rate": 0.001
  },
  {
    "episode": 7231,
    "reward": 87.016484,
    "length": 72,
    "time": 109581.304983,
    "actor_loss": -68.95442199707031,
    "critic_loss": 8.201443672180176,
    "ent_coef": 0.06585675477981567,
    "learning_rate": 0.001
  },
  {
    "episode": 7232,
    "reward": 90.436484,
    "length": 62,
    "time": 109592.649597,
    "actor_loss": -73.62156677246094,
    "critic_loss": 35.487220764160156,
    "ent_coef": 0.06622913479804993,
    "learning_rate": 0.001
  },
  {
    "episode": 7233,
    "reward": 90.332861,
    "length": 63,
    "time": 109604.401415,
    "actor_loss": -68.652587890625,
    "critic_loss": 3.401252269744873,
    "ent_coef": 0.06713560968637466,
    "learning_rate": 0.001
  },
  {
    "episode": 7234,
    "reward": 89.964828,
    "length": 62,
    "time": 109618.815729,
    "actor_loss": -65.12358093261719,
    "critic_loss": 27.391063690185547,
    "ent_coef": 0.06722556054592133,
    "learning_rate": 0.001
  },
  {
    "episode": 7235,
    "reward": 87.765056,
    "length": 73,
    "time": 109633.134181,
    "actor_loss": -69.86442565917969,
    "critic_loss": 30.3720703125,
    "ent_coef": 0.06810013204813004,
    "learning_rate": 0.001
  },
  {
    "episode": 7236,
    "reward": 89.321753,
    "length": 65,
    "time": 109644.466805,
    "actor_loss": -60.27421569824219,
    "critic_loss": 2.9988346099853516,
    "ent_coef": 0.07072778791189194,
    "learning_rate": 0.001
  },
  {
    "episode": 7237,
    "reward": 87.105594,
    "length": 71,
    "time": 109656.826689,
    "actor_loss": -64.90838623046875,
    "critic_loss": 4.651585102081299,
    "ent_coef": 0.07072436809539795,
    "learning_rate": 0.001
  },
  {
    "episode": 7238,
    "reward": 88.065068,
    "length": 68,
    "time": 109669.911437,
    "actor_loss": -68.06925964355469,
    "critic_loss": 4.867915153503418,
    "ent_coef": 0.07341886311769485,
    "learning_rate": 0.001
  },
  {
    "episode": 7239,
    "reward": 91.494663,
    "length": 62,
    "time": 109683.372438,
    "actor_loss": -63.16926574707031,
    "critic_loss": 10.791559219360352,
    "ent_coef": 0.0732412114739418,
    "learning_rate": 0.001
  },
  {
    "episode": 7240,
    "reward": 87.782409,
    "length": 66,
    "time": 109696.008888,
    "actor_loss": -65.12232971191406,
    "critic_loss": 6.131022930145264,
    "ent_coef": 0.07185260951519012,
    "learning_rate": 0.001
  },
  {
    "episode": 7241,
    "reward": 89.087223,
    "length": 67,
    "time": 109709.285683,
    "actor_loss": -61.3419303894043,
    "critic_loss": 5.907685279846191,
    "ent_coef": 0.07251141965389252,
    "learning_rate": 0.001
  },
  {
    "episode": 7242,
    "reward": 83.782986,
    "length": 77,
    "time": 109725.778157,
    "actor_loss": -69.47291564941406,
    "critic_loss": 71.01441955566406,
    "ent_coef": 0.07196277379989624,
    "learning_rate": 0.001
  },
  {
    "episode": 7243,
    "reward": 88.21022,
    "length": 68,
    "time": 109739.85052,
    "actor_loss": -64.75300598144531,
    "critic_loss": 113.338623046875,
    "ent_coef": 0.07155860215425491,
    "learning_rate": 0.001
  },
  {
    "episode": 7244,
    "reward": 87.956969,
    "length": 69,
    "time": 109752.815821,
    "actor_loss": -65.65621185302734,
    "critic_loss": 5.831170082092285,
    "ent_coef": 0.07172151654958725,
    "learning_rate": 0.001
  },
  {
    "episode": 7245,
    "reward": 91.499095,
    "length": 61,
    "time": 109764.99748,
    "actor_loss": -68.4548110961914,
    "critic_loss": 5.538308143615723,
    "ent_coef": 0.07392767816781998,
    "learning_rate": 0.001
  },
  {
    "episode": 7246,
    "reward": 89.874384,
    "length": 65,
    "time": 109776.445377,
    "actor_loss": -66.96211242675781,
    "critic_loss": 27.224416732788086,
    "ent_coef": 0.0746784657239914,
    "learning_rate": 0.001
  },
  {
    "episode": 7247,
    "reward": 87.344356,
    "length": 72,
    "time": 109789.522852,
    "actor_loss": -64.42779541015625,
    "critic_loss": 4.391514778137207,
    "ent_coef": 0.073729008436203,
    "learning_rate": 0.001
  },
  {
    "episode": 7248,
    "reward": 86.586216,
    "length": 71,
    "time": 109802.372406,
    "actor_loss": -71.92314910888672,
    "critic_loss": 17.337890625,
    "ent_coef": 0.06992021948099136,
    "learning_rate": 0.001
  },
  {
    "episode": 7249,
    "reward": 79.906486,
    "length": 83,
    "time": 109819.547742,
    "actor_loss": -66.02674865722656,
    "critic_loss": 5.371869087219238,
    "ent_coef": 0.06465370953083038,
    "learning_rate": 0.001
  },
  {
    "episode": 7250,
    "reward": 79.341293,
    "length": 96,
    "time": 109834.878899,
    "actor_loss": -65.07060241699219,
    "critic_loss": 5.925609588623047,
    "ent_coef": 0.06207672506570816,
    "learning_rate": 0.001
  },
  {
    "episode": 7251,
    "reward": 90.879417,
    "length": 62,
    "time": 109848.460142,
    "actor_loss": -61.79022979736328,
    "critic_loss": 4.10792350769043,
    "ent_coef": 0.06371640413999557,
    "learning_rate": 0.001
  },
  {
    "episode": 7252,
    "reward": 88.580582,
    "length": 68,
    "time": 109860.46345,
    "actor_loss": -61.73400115966797,
    "critic_loss": 3.498591899871826,
    "ent_coef": 0.06592679023742676,
    "learning_rate": 0.001
  },
  {
    "episode": 7253,
    "reward": 89.802614,
    "length": 65,
    "time": 109872.700943,
    "actor_loss": -68.31857299804688,
    "critic_loss": 42.80058288574219,
    "ent_coef": 0.06796425580978394,
    "learning_rate": 0.001
  },
  {
    "episode": 7254,
    "reward": 88.663025,
    "length": 67,
    "time": 109885.535946,
    "actor_loss": -68.50050354003906,
    "critic_loss": 41.37200164794922,
    "ent_coef": 0.06955955922603607,
    "learning_rate": 0.001
  },
  {
    "episode": 7255,
    "reward": 83.775415,
    "length": 88,
    "time": 109901.554513,
    "actor_loss": -59.04554748535156,
    "critic_loss": 2.6985530853271484,
    "ent_coef": 0.07202746719121933,
    "learning_rate": 0.001
  },
  {
    "episode": 7256,
    "reward": 90.026889,
    "length": 64,
    "time": 109913.250315,
    "actor_loss": -66.5223159790039,
    "critic_loss": 165.91436767578125,
    "ent_coef": 0.07328717410564423,
    "learning_rate": 0.001
  },
  {
    "episode": 7257,
    "reward": 90.481226,
    "length": 62,
    "time": 109924.816213,
    "actor_loss": -65.81953430175781,
    "critic_loss": 4.597443103790283,
    "ent_coef": 0.07556642591953278,
    "learning_rate": 0.001
  },
  {
    "episode": 7258,
    "reward": 87.127252,
    "length": 74,
    "time": 109938.302556,
    "actor_loss": -68.95787048339844,
    "critic_loss": 3.200366497039795,
    "ent_coef": 0.07348901033401489,
    "learning_rate": 0.001
  },
  {
    "episode": 7259,
    "reward": 89.44839,
    "length": 65,
    "time": 109950.897483,
    "actor_loss": -66.03273010253906,
    "critic_loss": 30.083324432373047,
    "ent_coef": 0.07045280933380127,
    "learning_rate": 0.001
  },
  {
    "episode": 7260,
    "reward": 90.601052,
    "length": 64,
    "time": 109962.415614,
    "actor_loss": -59.60554122924805,
    "critic_loss": 7.235227584838867,
    "ent_coef": 0.06903861463069916,
    "learning_rate": 0.001
  },
  {
    "episode": 7261,
    "reward": 90.529612,
    "length": 63,
    "time": 109973.786788,
    "actor_loss": -56.81597900390625,
    "critic_loss": 4.859457015991211,
    "ent_coef": 0.06834523379802704,
    "learning_rate": 0.001
  },
  {
    "episode": 7262,
    "reward": 86.891157,
    "length": 73,
    "time": 109987.067615,
    "actor_loss": -63.00152587890625,
    "critic_loss": 5.622015953063965,
    "ent_coef": 0.0659472644329071,
    "learning_rate": 0.001
  },
  {
    "episode": 7263,
    "reward": 88.175482,
    "length": 74,
    "time": 110001.815184,
    "actor_loss": -64.8306884765625,
    "critic_loss": 10.100045204162598,
    "ent_coef": 0.0647900179028511,
    "learning_rate": 0.001
  },
  {
    "episode": 7264,
    "reward": 92.146898,
    "length": 61,
    "time": 110013.479658,
    "actor_loss": -65.54507446289062,
    "critic_loss": 35.822845458984375,
    "ent_coef": 0.06682021915912628,
    "learning_rate": 0.001
  },
  {
    "episode": 7265,
    "reward": 90.804045,
    "length": 64,
    "time": 110025.831327,
    "actor_loss": -65.17964172363281,
    "critic_loss": 111.31412506103516,
    "ent_coef": 0.06840680539608002,
    "learning_rate": 0.001
  },
  {
    "episode": 7266,
    "reward": 90.998882,
    "length": 63,
    "time": 110038.377511,
    "actor_loss": -63.22362518310547,
    "critic_loss": 15.114883422851562,
    "ent_coef": 0.07098465412855148,
    "learning_rate": 0.001
  },
  {
    "episode": 7267,
    "reward": 87.501229,
    "length": 68,
    "time": 110050.421773,
    "actor_loss": -67.49850463867188,
    "critic_loss": 49.67314910888672,
    "ent_coef": 0.06694332510232925,
    "learning_rate": 0.001
  },
  {
    "episode": 7268,
    "reward": 88.443991,
    "length": 67,
    "time": 110065.855945,
    "actor_loss": -58.99635696411133,
    "critic_loss": 7.32237434387207,
    "ent_coef": 0.06535159051418304,
    "learning_rate": 0.001
  },
  {
    "episode": 7269,
    "reward": 87.86364,
    "length": 69,
    "time": 110078.374904,
    "actor_loss": -70.13212585449219,
    "critic_loss": 6.911860466003418,
    "ent_coef": 0.06621403992176056,
    "learning_rate": 0.001
  },
  {
    "episode": 7270,
    "reward": 89.786013,
    "length": 64,
    "time": 110089.608846,
    "actor_loss": -70.34796905517578,
    "critic_loss": 26.32452392578125,
    "ent_coef": 0.06770658493041992,
    "learning_rate": 0.001
  },
  {
    "episode": 7271,
    "reward": 89.521904,
    "length": 65,
    "time": 110101.389079,
    "actor_loss": -64.11557006835938,
    "critic_loss": 4.9507036209106445,
    "ent_coef": 0.06995735317468643,
    "learning_rate": 0.001
  },
  {
    "episode": 7272,
    "reward": 89.348155,
    "length": 65,
    "time": 110116.650908,
    "actor_loss": -63.043968200683594,
    "critic_loss": 16.12721824645996,
    "ent_coef": 0.06945474445819855,
    "learning_rate": 0.001
  },
  {
    "episode": 7273,
    "reward": 87.886423,
    "length": 72,
    "time": 110133.144011,
    "actor_loss": -60.77850341796875,
    "critic_loss": 8.080726623535156,
    "ent_coef": 0.06928936392068863,
    "learning_rate": 0.001
  },
  {
    "episode": 7274,
    "reward": 89.806981,
    "length": 64,
    "time": 110145.216939,
    "actor_loss": -67.02507019042969,
    "critic_loss": 3.368565082550049,
    "ent_coef": 0.07056044042110443,
    "learning_rate": 0.001
  },
  {
    "episode": 7275,
    "reward": 90.635269,
    "length": 63,
    "time": 110157.58675,
    "actor_loss": -61.87232208251953,
    "critic_loss": 7.313416004180908,
    "ent_coef": 0.07224763184785843,
    "learning_rate": 0.001
  },
  {
    "episode": 7276,
    "reward": 90.772593,
    "length": 63,
    "time": 110169.507235,
    "actor_loss": -68.61288452148438,
    "critic_loss": 47.26715850830078,
    "ent_coef": 0.0742454007267952,
    "learning_rate": 0.001
  },
  {
    "episode": 7277,
    "reward": 89.610411,
    "length": 67,
    "time": 110181.913365,
    "actor_loss": -64.8252944946289,
    "critic_loss": 7.146026134490967,
    "ent_coef": 0.07672111690044403,
    "learning_rate": 0.001
  },
  {
    "episode": 7278,
    "reward": 87.75896,
    "length": 68,
    "time": 110195.903811,
    "actor_loss": -68.04410552978516,
    "critic_loss": 3.7191264629364014,
    "ent_coef": 0.07547632604837418,
    "learning_rate": 0.001
  },
  {
    "episode": 7279,
    "reward": 91.375858,
    "length": 62,
    "time": 110207.978078,
    "actor_loss": -68.30919647216797,
    "critic_loss": 15.249520301818848,
    "ent_coef": 0.07533582299947739,
    "learning_rate": 0.001
  },
  {
    "episode": 7280,
    "reward": 87.077399,
    "length": 72,
    "time": 110223.210908,
    "actor_loss": -64.46302032470703,
    "critic_loss": 8.280757904052734,
    "ent_coef": 0.07210604101419449,
    "learning_rate": 0.001
  },
  {
    "episode": 7281,
    "reward": 88.04249,
    "length": 68,
    "time": 110235.249254,
    "actor_loss": -63.93247985839844,
    "critic_loss": 6.926192283630371,
    "ent_coef": 0.06909460574388504,
    "learning_rate": 0.001
  },
  {
    "episode": 7282,
    "reward": 90.950314,
    "length": 63,
    "time": 110247.665019,
    "actor_loss": -67.96471405029297,
    "critic_loss": 4.715565204620361,
    "ent_coef": 0.06949333101511002,
    "learning_rate": 0.001
  },
  {
    "episode": 7283,
    "reward": 91.593328,
    "length": 61,
    "time": 110260.629043,
    "actor_loss": -58.521949768066406,
    "critic_loss": 6.307541847229004,
    "ent_coef": 0.0704156756401062,
    "learning_rate": 0.001
  },
  {
    "episode": 7284,
    "reward": 90.536203,
    "length": 63,
    "time": 110273.984996,
    "actor_loss": -68.94220733642578,
    "critic_loss": 68.5054931640625,
    "ent_coef": 0.07132945209741592,
    "learning_rate": 0.001
  },
  {
    "episode": 7285,
    "reward": 79.422596,
    "length": 64,
    "time": 110286.319748,
    "actor_loss": -67.15167236328125,
    "critic_loss": 150.59320068359375,
    "ent_coef": 0.07018435746431351,
    "learning_rate": 0.001
  },
  {
    "episode": 7286,
    "reward": 88.168841,
    "length": 66,
    "time": 110299.028547,
    "actor_loss": -68.57064819335938,
    "critic_loss": 3.539633274078369,
    "ent_coef": 0.07335972040891647,
    "learning_rate": 0.001
  },
  {
    "episode": 7287,
    "reward": 87.894255,
    "length": 74,
    "time": 110311.605717,
    "actor_loss": -65.88510131835938,
    "critic_loss": 77.74655151367188,
    "ent_coef": 0.07423554360866547,
    "learning_rate": 0.001
  },
  {
    "episode": 7288,
    "reward": 89.091275,
    "length": 69,
    "time": 110324.521123,
    "actor_loss": -71.443603515625,
    "critic_loss": 36.517127990722656,
    "ent_coef": 0.0770055279135704,
    "learning_rate": 0.001
  },
  {
    "episode": 7289,
    "reward": 65.856876,
    "length": 99,
    "time": 110341.946254,
    "actor_loss": -63.72521209716797,
    "critic_loss": 3.9385929107666016,
    "ent_coef": 0.07677945494651794,
    "learning_rate": 0.001
  },
  {
    "episode": 7290,
    "reward": 90.000287,
    "length": 64,
    "time": 110356.546629,
    "actor_loss": -66.7269058227539,
    "critic_loss": 49.01423645019531,
    "ent_coef": 0.076851025223732,
    "learning_rate": 0.001
  },
  {
    "episode": 7291,
    "reward": 87.282124,
    "length": 71,
    "time": 110370.417335,
    "actor_loss": -67.22105407714844,
    "critic_loss": 14.852948188781738,
    "ent_coef": 0.0735001266002655,
    "learning_rate": 0.001
  },
  {
    "episode": 7292,
    "reward": 89.98122,
    "length": 64,
    "time": 110381.929399,
    "actor_loss": -65.59190368652344,
    "critic_loss": 12.72014331817627,
    "ent_coef": 0.0694778636097908,
    "learning_rate": 0.001
  },
  {
    "episode": 7293,
    "reward": 90.230907,
    "length": 63,
    "time": 110394.349941,
    "actor_loss": -73.97051239013672,
    "critic_loss": 3.7445168495178223,
    "ent_coef": 0.07015618681907654,
    "learning_rate": 0.001
  },
  {
    "episode": 7294,
    "reward": 89.8114,
    "length": 65,
    "time": 110406.736021,
    "actor_loss": -69.30154418945312,
    "critic_loss": 10.731185913085938,
    "ent_coef": 0.06979605555534363,
    "learning_rate": 0.001
  },
  {
    "episode": 7295,
    "reward": 89.536008,
    "length": 65,
    "time": 110420.124488,
    "actor_loss": -64.0093002319336,
    "critic_loss": 7.561354637145996,
    "ent_coef": 0.06856342405080795,
    "learning_rate": 0.001
  },
  {
    "episode": 7296,
    "reward": 88.637642,
    "length": 67,
    "time": 110432.93817,
    "actor_loss": -68.94456481933594,
    "critic_loss": 8.160222053527832,
    "ent_coef": 0.06677121669054031,
    "learning_rate": 0.001
  },
  {
    "episode": 7297,
    "reward": 91.657433,
    "length": 59,
    "time": 110445.106106,
    "actor_loss": -65.42720031738281,
    "critic_loss": 8.473052978515625,
    "ent_coef": 0.06739174574613571,
    "learning_rate": 0.001
  },
  {
    "episode": 7298,
    "reward": 85.059046,
    "length": 72,
    "time": 110458.666589,
    "actor_loss": -59.430789947509766,
    "critic_loss": 10.016282081604004,
    "ent_coef": 0.06312595307826996,
    "learning_rate": 0.001
  },
  {
    "episode": 7299,
    "reward": 89.625077,
    "length": 65,
    "time": 110472.657667,
    "actor_loss": -64.68872833251953,
    "critic_loss": 3.4565038681030273,
    "ent_coef": 0.06388647854328156,
    "learning_rate": 0.001
  },
  {
    "episode": 7300,
    "reward": 89.709369,
    "length": 63,
    "time": 110484.576823,
    "actor_loss": -63.52796173095703,
    "critic_loss": 10.366704940795898,
    "ent_coef": 0.06291677057743073,
    "learning_rate": 0.001
  },
  {
    "episode": 7301,
    "reward": 86.659173,
    "length": 71,
    "time": 110497.856264,
    "actor_loss": -64.37274169921875,
    "critic_loss": 6.342447280883789,
    "ent_coef": 0.061239808797836304,
    "learning_rate": 0.001
  },
  {
    "episode": 7302,
    "reward": 87.406777,
    "length": 71,
    "time": 110514.173244,
    "actor_loss": -61.72441864013672,
    "critic_loss": 6.0351762771606445,
    "ent_coef": 0.06319817155599594,
    "learning_rate": 0.001
  },
  {
    "episode": 7303,
    "reward": 89.965292,
    "length": 65,
    "time": 110525.695199,
    "actor_loss": -71.51652526855469,
    "critic_loss": 12.598093032836914,
    "ent_coef": 0.0635836124420166,
    "learning_rate": 0.001
  },
  {
    "episode": 7304,
    "reward": 89.74407,
    "length": 65,
    "time": 110538.267323,
    "actor_loss": -70.85246276855469,
    "critic_loss": 13.59110164642334,
    "ent_coef": 0.062117572873830795,
    "learning_rate": 0.001
  },
  {
    "episode": 7305,
    "reward": 91.90744,
    "length": 60,
    "time": 110551.028487,
    "actor_loss": -67.93023681640625,
    "critic_loss": 174.54061889648438,
    "ent_coef": 0.06515979021787643,
    "learning_rate": 0.001
  },
  {
    "episode": 7306,
    "reward": 90.332873,
    "length": 62,
    "time": 110562.932826,
    "actor_loss": -65.58148193359375,
    "critic_loss": 6.350621223449707,
    "ent_coef": 0.06459761410951614,
    "learning_rate": 0.001
  },
  {
    "episode": 7307,
    "reward": 89.721651,
    "length": 65,
    "time": 110574.29905,
    "actor_loss": -62.75394821166992,
    "critic_loss": 5.448910713195801,
    "ent_coef": 0.06651528179645538,
    "learning_rate": 0.001
  },
  {
    "episode": 7308,
    "reward": 92.386532,
    "length": 59,
    "time": 110585.111457,
    "actor_loss": -69.54734802246094,
    "critic_loss": 3.579555034637451,
    "ent_coef": 0.0709148421883583,
    "learning_rate": 0.001
  },
  {
    "episode": 7309,
    "reward": 90.030956,
    "length": 66,
    "time": 110597.825309,
    "actor_loss": -59.256622314453125,
    "critic_loss": 10.92015552520752,
    "ent_coef": 0.07147490233182907,
    "learning_rate": 0.001
  },
  {
    "episode": 7310,
    "reward": 90.478043,
    "length": 63,
    "time": 110609.116357,
    "actor_loss": -61.508544921875,
    "critic_loss": 15.35562801361084,
    "ent_coef": 0.07512762397527695,
    "learning_rate": 0.001
  },
  {
    "episode": 7311,
    "reward": 91.055611,
    "length": 63,
    "time": 110621.042813,
    "actor_loss": -70.18916320800781,
    "critic_loss": 14.811463356018066,
    "ent_coef": 0.07849842309951782,
    "learning_rate": 0.001
  },
  {
    "episode": 7312,
    "reward": 82.132003,
    "length": 79,
    "time": 110635.207465,
    "actor_loss": -62.25811767578125,
    "critic_loss": 4.98361873626709,
    "ent_coef": 0.073638416826725,
    "learning_rate": 0.001
  },
  {
    "episode": 7313,
    "reward": 88.202189,
    "length": 69,
    "time": 110648.348016,
    "actor_loss": -67.56108856201172,
    "critic_loss": 8.830350875854492,
    "ent_coef": 0.07226695865392685,
    "learning_rate": 0.001
  },
  {
    "episode": 7314,
    "reward": 85.20404,
    "length": 73,
    "time": 110662.888729,
    "actor_loss": -65.31375885009766,
    "critic_loss": 15.787225723266602,
    "ent_coef": 0.06648598611354828,
    "learning_rate": 0.001
  },
  {
    "episode": 7315,
    "reward": 87.98375,
    "length": 68,
    "time": 110675.822986,
    "actor_loss": -70.00337219238281,
    "critic_loss": 6.697440147399902,
    "ent_coef": 0.06700863689184189,
    "learning_rate": 0.001
  },
  {
    "episode": 7316,
    "reward": 88.477855,
    "length": 65,
    "time": 110688.894188,
    "actor_loss": -64.7343978881836,
    "critic_loss": 14.418331146240234,
    "ent_coef": 0.06960252672433853,
    "learning_rate": 0.001
  },
  {
    "episode": 7317,
    "reward": 90.673849,
    "length": 63,
    "time": 110700.930146,
    "actor_loss": -68.13286590576172,
    "critic_loss": 607.1460571289062,
    "ent_coef": 0.07037593424320221,
    "learning_rate": 0.001
  },
  {
    "episode": 7318,
    "reward": 88.156656,
    "length": 72,
    "time": 110714.569046,
    "actor_loss": -66.17037963867188,
    "critic_loss": 7.6940717697143555,
    "ent_coef": 0.06735184788703918,
    "learning_rate": 0.001
  },
  {
    "episode": 7319,
    "reward": 86.52628,
    "length": 71,
    "time": 110726.962157,
    "actor_loss": -69.27043151855469,
    "critic_loss": 4.517337322235107,
    "ent_coef": 0.06300587207078934,
    "learning_rate": 0.001
  },
  {
    "episode": 7320,
    "reward": 89.631454,
    "length": 64,
    "time": 110739.770781,
    "actor_loss": -69.32084655761719,
    "critic_loss": 3.9889190196990967,
    "ent_coef": 0.06209499388933182,
    "learning_rate": 0.001
  },
  {
    "episode": 7321,
    "reward": 81.753469,
    "length": 80,
    "time": 110753.205626,
    "actor_loss": -65.95240783691406,
    "critic_loss": 4.389178276062012,
    "ent_coef": 0.05844828486442566,
    "learning_rate": 0.001
  },
  {
    "episode": 7322,
    "reward": 88.847144,
    "length": 67,
    "time": 110765.388613,
    "actor_loss": -64.10602569580078,
    "critic_loss": 22.810375213623047,
    "ent_coef": 0.05808867886662483,
    "learning_rate": 0.001
  },
  {
    "episode": 7323,
    "reward": 87.61886,
    "length": 68,
    "time": 110777.98624,
    "actor_loss": -64.79133605957031,
    "critic_loss": 5.34515380859375,
    "ent_coef": 0.05748513713479042,
    "learning_rate": 0.001
  },
  {
    "episode": 7324,
    "reward": 90.00843,
    "length": 65,
    "time": 110792.349668,
    "actor_loss": -67.06591796875,
    "critic_loss": 85.44152069091797,
    "ent_coef": 0.06235317140817642,
    "learning_rate": 0.001
  },
  {
    "episode": 7325,
    "reward": 91.7966,
    "length": 62,
    "time": 110803.446159,
    "actor_loss": -61.31029510498047,
    "critic_loss": 16.47074317932129,
    "ent_coef": 0.06677055358886719,
    "learning_rate": 0.001
  },
  {
    "episode": 7326,
    "reward": 89.530331,
    "length": 68,
    "time": 110816.206797,
    "actor_loss": -64.69151306152344,
    "critic_loss": 9.770523071289062,
    "ent_coef": 0.06994511187076569,
    "learning_rate": 0.001
  },
  {
    "episode": 7327,
    "reward": 83.961893,
    "length": 76,
    "time": 110829.851735,
    "actor_loss": -65.16197967529297,
    "critic_loss": 10.24492073059082,
    "ent_coef": 0.07112261652946472,
    "learning_rate": 0.001
  },
  {
    "episode": 7328,
    "reward": 84.047924,
    "length": 75,
    "time": 110844.886233,
    "actor_loss": -64.68720245361328,
    "critic_loss": 19.890853881835938,
    "ent_coef": 0.07066107541322708,
    "learning_rate": 0.001
  },
  {
    "episode": 7329,
    "reward": 87.847166,
    "length": 68,
    "time": 110857.514794,
    "actor_loss": -67.10356903076172,
    "critic_loss": 5.929201126098633,
    "ent_coef": 0.06861498951911926,
    "learning_rate": 0.001
  },
  {
    "episode": 7330,
    "reward": 91.449602,
    "length": 63,
    "time": 110871.488375,
    "actor_loss": -64.01129150390625,
    "critic_loss": 12.938748359680176,
    "ent_coef": 0.07050865888595581,
    "learning_rate": 0.001
  },
  {
    "episode": 7331,
    "reward": 91.435408,
    "length": 62,
    "time": 110882.916488,
    "actor_loss": -61.759300231933594,
    "critic_loss": 8.721231460571289,
    "ent_coef": 0.07160048186779022,
    "learning_rate": 0.001
  },
  {
    "episode": 7332,
    "reward": 87.512264,
    "length": 67,
    "time": 110895.464988,
    "actor_loss": -62.84642028808594,
    "critic_loss": 21.474105834960938,
    "ent_coef": 0.06930061429738998,
    "learning_rate": 0.001
  },
  {
    "episode": 7333,
    "reward": 88.077239,
    "length": 73,
    "time": 110908.2485,
    "actor_loss": -64.23077392578125,
    "critic_loss": 9.259496688842773,
    "ent_coef": 0.06928528100252151,
    "learning_rate": 0.001
  },
  {
    "episode": 7334,
    "reward": 90.471207,
    "length": 64,
    "time": 110919.958493,
    "actor_loss": -69.64131927490234,
    "critic_loss": 7.896064758300781,
    "ent_coef": 0.07222135365009308,
    "learning_rate": 0.001
  },
  {
    "episode": 7335,
    "reward": 90.140941,
    "length": 64,
    "time": 110931.442476,
    "actor_loss": -65.79967498779297,
    "critic_loss": 8.280635833740234,
    "ent_coef": 0.07367756217718124,
    "learning_rate": 0.001
  },
  {
    "episode": 7336,
    "reward": 89.623357,
    "length": 65,
    "time": 110944.970483,
    "actor_loss": -63.248619079589844,
    "critic_loss": 6.976066589355469,
    "ent_coef": 0.07528261095285416,
    "learning_rate": 0.001
  },
  {
    "episode": 7337,
    "reward": 89.445818,
    "length": 71,
    "time": 110958.050602,
    "actor_loss": -71.0809326171875,
    "critic_loss": 33.39411544799805,
    "ent_coef": 0.07381371408700943,
    "learning_rate": 0.001
  },
  {
    "episode": 7338,
    "reward": 86.99422,
    "length": 73,
    "time": 110971.756589,
    "actor_loss": -62.47072982788086,
    "critic_loss": 38.631011962890625,
    "ent_coef": 0.07400669157505035,
    "learning_rate": 0.001
  },
  {
    "episode": 7339,
    "reward": 90.811283,
    "length": 63,
    "time": 110987.072566,
    "actor_loss": -62.81380081176758,
    "critic_loss": 4.115727424621582,
    "ent_coef": 0.07704826444387436,
    "learning_rate": 0.001
  },
  {
    "episode": 7340,
    "reward": 88.73052,
    "length": 67,
    "time": 110999.2465,
    "actor_loss": -71.99610137939453,
    "critic_loss": 4.598503112792969,
    "ent_coef": 0.07805158942937851,
    "learning_rate": 0.001
  },
  {
    "episode": 7341,
    "reward": 89.526628,
    "length": 65,
    "time": 111014.707793,
    "actor_loss": -66.80781555175781,
    "critic_loss": 3.3593478202819824,
    "ent_coef": 0.07693313807249069,
    "learning_rate": 0.001
  },
  {
    "episode": 7342,
    "reward": 88.434535,
    "length": 67,
    "time": 111026.290674,
    "actor_loss": -64.38130187988281,
    "critic_loss": 9.201290130615234,
    "ent_coef": 0.07379506528377533,
    "learning_rate": 0.001
  },
  {
    "episode": 7343,
    "reward": 88.64797,
    "length": 66,
    "time": 111038.920619,
    "actor_loss": -67.89241790771484,
    "critic_loss": 9.930204391479492,
    "ent_coef": 0.07224094867706299,
    "learning_rate": 0.001
  },
  {
    "episode": 7344,
    "reward": 90.050096,
    "length": 64,
    "time": 111053.300519,
    "actor_loss": -71.36296081542969,
    "critic_loss": 30.703765869140625,
    "ent_coef": 0.07300879806280136,
    "learning_rate": 0.001
  },
  {
    "episode": 7345,
    "reward": 86.57976,
    "length": 75,
    "time": 111066.200322,
    "actor_loss": -62.018314361572266,
    "critic_loss": 6.626530647277832,
    "ent_coef": 0.07113153487443924,
    "learning_rate": 0.001
  },
  {
    "episode": 7346,
    "reward": 86.438989,
    "length": 75,
    "time": 111081.767919,
    "actor_loss": -64.4297866821289,
    "critic_loss": 39.376285552978516,
    "ent_coef": 0.0695234164595604,
    "learning_rate": 0.001
  },
  {
    "episode": 7347,
    "reward": 90.740461,
    "length": 63,
    "time": 111095.177524,
    "actor_loss": -68.075927734375,
    "critic_loss": 560.86865234375,
    "ent_coef": 0.06700623780488968,
    "learning_rate": 0.001
  },
  {
    "episode": 7348,
    "reward": 91.914558,
    "length": 59,
    "time": 111106.067516,
    "actor_loss": -64.375244140625,
    "critic_loss": 7.592563152313232,
    "ent_coef": 0.06900148093700409,
    "learning_rate": 0.001
  },
  {
    "episode": 7349,
    "reward": 90.656652,
    "length": 65,
    "time": 111117.442561,
    "actor_loss": -64.37689208984375,
    "critic_loss": 14.259258270263672,
    "ent_coef": 0.06917883455753326,
    "learning_rate": 0.001
  },
  {
    "episode": 7350,
    "reward": 92.177408,
    "length": 60,
    "time": 111129.09815,
    "actor_loss": -71.33897399902344,
    "critic_loss": 5.690715312957764,
    "ent_coef": 0.06989330798387527,
    "learning_rate": 0.001
  },
  {
    "episode": 7351,
    "reward": 90.842346,
    "length": 63,
    "time": 111141.451541,
    "actor_loss": -63.861572265625,
    "critic_loss": 4.765260696411133,
    "ent_coef": 0.070432148873806,
    "learning_rate": 0.001
  },
  {
    "episode": 7352,
    "reward": -156.34484,
    "length": 134,
    "time": 111161.799029,
    "actor_loss": -64.18936157226562,
    "critic_loss": 5.344732284545898,
    "ent_coef": 0.07279381901025772,
    "learning_rate": 0.001
  },
  {
    "episode": 7353,
    "reward": 90.433295,
    "length": 66,
    "time": 111174.82314,
    "actor_loss": -67.56517028808594,
    "critic_loss": 6.912501811981201,
    "ent_coef": 0.07448212802410126,
    "learning_rate": 0.001
  },
  {
    "episode": 7354,
    "reward": 88.107622,
    "length": 67,
    "time": 111186.589329,
    "actor_loss": -69.79840087890625,
    "critic_loss": 181.18736267089844,
    "ent_coef": 0.07430194318294525,
    "learning_rate": 0.001
  },
  {
    "episode": 7355,
    "reward": 89.648022,
    "length": 66,
    "time": 111198.240301,
    "actor_loss": -68.9152603149414,
    "critic_loss": 2.3093106746673584,
    "ent_coef": 0.07484908401966095,
    "learning_rate": 0.001
  },
  {
    "episode": 7356,
    "reward": 87.480277,
    "length": 72,
    "time": 111213.333317,
    "actor_loss": -68.51653289794922,
    "critic_loss": 3.7937939167022705,
    "ent_coef": 0.07569888979196548,
    "learning_rate": 0.001
  },
  {
    "episode": 7357,
    "reward": 89.62097,
    "length": 69,
    "time": 111228.189043,
    "actor_loss": -70.31044006347656,
    "critic_loss": 11.444265365600586,
    "ent_coef": 0.08066811412572861,
    "learning_rate": 0.001
  },
  {
    "episode": 7358,
    "reward": 88.789346,
    "length": 69,
    "time": 111241.632323,
    "actor_loss": -64.49411010742188,
    "critic_loss": 7.095094680786133,
    "ent_coef": 0.0800199881196022,
    "learning_rate": 0.001
  },
  {
    "episode": 7359,
    "reward": 88.125595,
    "length": 68,
    "time": 111256.095966,
    "actor_loss": -66.43380737304688,
    "critic_loss": 2.0337300300598145,
    "ent_coef": 0.0817333310842514,
    "learning_rate": 0.001
  },
  {
    "episode": 7360,
    "reward": 89.697045,
    "length": 67,
    "time": 111267.8778,
    "actor_loss": -65.74028778076172,
    "critic_loss": 85.40220642089844,
    "ent_coef": 0.08039449155330658,
    "learning_rate": 0.001
  },
  {
    "episode": 7361,
    "reward": 88.787289,
    "length": 66,
    "time": 111279.820652,
    "actor_loss": -72.79139709472656,
    "critic_loss": 10.965812683105469,
    "ent_coef": 0.08181855082511902,
    "learning_rate": 0.001
  },
  {
    "episode": 7362,
    "reward": 88.620055,
    "length": 66,
    "time": 111291.968499,
    "actor_loss": -71.49922943115234,
    "critic_loss": 148.21896362304688,
    "ent_coef": 0.08200648427009583,
    "learning_rate": 0.001
  },
  {
    "episode": 7363,
    "reward": 86.812518,
    "length": 69,
    "time": 111303.787623,
    "actor_loss": -68.26042938232422,
    "critic_loss": 15.933168411254883,
    "ent_coef": 0.07947570830583572,
    "learning_rate": 0.001
  },
  {
    "episode": 7364,
    "reward": 90.878018,
    "length": 62,
    "time": 111314.808043,
    "actor_loss": -60.44634246826172,
    "critic_loss": 21.025007247924805,
    "ent_coef": 0.07822848111391068,
    "learning_rate": 0.001
  },
  {
    "episode": 7365,
    "reward": 90.581472,
    "length": 65,
    "time": 111326.372522,
    "actor_loss": -67.06996154785156,
    "critic_loss": 4.273385047912598,
    "ent_coef": 0.07829436659812927,
    "learning_rate": 0.001
  },
  {
    "episode": 7366,
    "reward": 89.466922,
    "length": 66,
    "time": 111338.012741,
    "actor_loss": -65.9144058227539,
    "critic_loss": 10.356842041015625,
    "ent_coef": 0.0763404592871666,
    "learning_rate": 0.001
  },
  {
    "episode": 7367,
    "reward": 89.012729,
    "length": 65,
    "time": 111349.679606,
    "actor_loss": -66.5170669555664,
    "critic_loss": 4.256293773651123,
    "ent_coef": 0.07431624084711075,
    "learning_rate": 0.001
  },
  {
    "episode": 7368,
    "reward": 89.304577,
    "length": 66,
    "time": 111364.04804,
    "actor_loss": -67.43447875976562,
    "critic_loss": 9.602354049682617,
    "ent_coef": 0.07676035910844803,
    "learning_rate": 0.001
  },
  {
    "episode": 7369,
    "reward": 88.569576,
    "length": 68,
    "time": 111375.82987,
    "actor_loss": -59.37290954589844,
    "critic_loss": 15.247309684753418,
    "ent_coef": 0.07561399042606354,
    "learning_rate": 0.001
  },
  {
    "episode": 7370,
    "reward": 90.77407,
    "length": 63,
    "time": 111389.438014,
    "actor_loss": -68.39120483398438,
    "critic_loss": 3.066534996032715,
    "ent_coef": 0.07477057725191116,
    "learning_rate": 0.001
  },
  {
    "episode": 7371,
    "reward": 88.581233,
    "length": 69,
    "time": 111405.21375,
    "actor_loss": -66.01283264160156,
    "critic_loss": 2.211168050765991,
    "ent_coef": 0.07358432561159134,
    "learning_rate": 0.001
  },
  {
    "episode": 7372,
    "reward": 88.015101,
    "length": 70,
    "time": 111418.024913,
    "actor_loss": -64.42201232910156,
    "critic_loss": 44.86229705810547,
    "ent_coef": 0.07495410740375519,
    "learning_rate": 0.001
  },
  {
    "episode": 7373,
    "reward": 89.655131,
    "length": 65,
    "time": 111431.457242,
    "actor_loss": -65.26361083984375,
    "critic_loss": 7.031826972961426,
    "ent_coef": 0.07716090977191925,
    "learning_rate": 0.001
  },
  {
    "episode": 7374,
    "reward": 90.059402,
    "length": 68,
    "time": 111443.362709,
    "actor_loss": -64.19189453125,
    "critic_loss": 3.502528667449951,
    "ent_coef": 0.07831371575593948,
    "learning_rate": 0.001
  },
  {
    "episode": 7375,
    "reward": 91.167518,
    "length": 63,
    "time": 111458.51291,
    "actor_loss": -68.89103698730469,
    "critic_loss": 3.993473768234253,
    "ent_coef": 0.08056530356407166,
    "learning_rate": 0.001
  },
  {
    "episode": 7376,
    "reward": 89.053462,
    "length": 68,
    "time": 111471.278048,
    "actor_loss": -65.09672546386719,
    "critic_loss": 4.588543891906738,
    "ent_coef": 0.0787423625588417,
    "learning_rate": 0.001
  },
  {
    "episode": 7377,
    "reward": 89.770448,
    "length": 63,
    "time": 111482.617393,
    "actor_loss": -68.16719055175781,
    "critic_loss": 13.902888298034668,
    "ent_coef": 0.07839345932006836,
    "learning_rate": 0.001
  },
  {
    "episode": 7378,
    "reward": 86.171205,
    "length": 93,
    "time": 111498.622873,
    "actor_loss": -67.78736114501953,
    "critic_loss": 83.84310913085938,
    "ent_coef": 0.08263488858938217,
    "learning_rate": 0.001
  },
  {
    "episode": 7379,
    "reward": 89.704586,
    "length": 65,
    "time": 111512.433877,
    "actor_loss": -68.16017150878906,
    "critic_loss": 21.180349349975586,
    "ent_coef": 0.08121814578771591,
    "learning_rate": 0.001
  },
  {
    "episode": 7380,
    "reward": 91.265188,
    "length": 62,
    "time": 111523.77275,
    "actor_loss": -65.83671569824219,
    "critic_loss": 16.62440299987793,
    "ent_coef": 0.08189358562231064,
    "learning_rate": 0.001
  },
  {
    "episode": 7381,
    "reward": 90.256014,
    "length": 64,
    "time": 111536.283689,
    "actor_loss": -73.34982299804688,
    "critic_loss": 3.244418144226074,
    "ent_coef": 0.08204425871372223,
    "learning_rate": 0.001
  },
  {
    "episode": 7382,
    "reward": 86.644396,
    "length": 75,
    "time": 111552.610375,
    "actor_loss": -68.36695861816406,
    "critic_loss": 61.568660736083984,
    "ent_coef": 0.08487257361412048,
    "learning_rate": 0.001
  },
  {
    "episode": 7383,
    "reward": 90.306743,
    "length": 64,
    "time": 111565.646751,
    "actor_loss": -63.63930892944336,
    "critic_loss": 54.39043426513672,
    "ent_coef": 0.08653624355792999,
    "learning_rate": 0.001
  },
  {
    "episode": 7384,
    "reward": 90.373325,
    "length": 63,
    "time": 111577.627575,
    "actor_loss": -70.25515747070312,
    "critic_loss": 29.1546573638916,
    "ent_coef": 0.0839323177933693,
    "learning_rate": 0.001
  },
  {
    "episode": 7385,
    "reward": 89.359096,
    "length": 67,
    "time": 111589.420395,
    "actor_loss": -68.73174285888672,
    "critic_loss": 8.393786430358887,
    "ent_coef": 0.08021558821201324,
    "learning_rate": 0.001
  },
  {
    "episode": 7386,
    "reward": 88.938132,
    "length": 66,
    "time": 111602.665606,
    "actor_loss": -70.69668579101562,
    "critic_loss": 65.75076293945312,
    "ent_coef": 0.07545020431280136,
    "learning_rate": 0.001
  },
  {
    "episode": 7387,
    "reward": 89.613105,
    "length": 66,
    "time": 111615.307878,
    "actor_loss": -67.16545104980469,
    "critic_loss": 2.4540281295776367,
    "ent_coef": 0.07400692254304886,
    "learning_rate": 0.001
  },
  {
    "episode": 7388,
    "reward": 88.104773,
    "length": 71,
    "time": 111628.524508,
    "actor_loss": -66.89126586914062,
    "critic_loss": 11.690327644348145,
    "ent_coef": 0.07418083399534225,
    "learning_rate": 0.001
  },
  {
    "episode": 7389,
    "reward": 91.551544,
    "length": 63,
    "time": 111644.244029,
    "actor_loss": -64.14591217041016,
    "critic_loss": 6.2085981369018555,
    "ent_coef": 0.0785149484872818,
    "learning_rate": 0.001
  },
  {
    "episode": 7390,
    "reward": 88.752306,
    "length": 69,
    "time": 111659.771326,
    "actor_loss": -70.06990051269531,
    "critic_loss": 6.726921558380127,
    "ent_coef": 0.07935186475515366,
    "learning_rate": 0.001
  },
  {
    "episode": 7391,
    "reward": 89.559246,
    "length": 65,
    "time": 111671.937396,
    "actor_loss": -67.06521606445312,
    "critic_loss": 2.523040294647217,
    "ent_coef": 0.08037875592708588,
    "learning_rate": 0.001
  },
  {
    "episode": 7392,
    "reward": 89.601098,
    "length": 66,
    "time": 111683.431323,
    "actor_loss": -72.84709167480469,
    "critic_loss": 30.739295959472656,
    "ent_coef": 0.08268477022647858,
    "learning_rate": 0.001
  },
  {
    "episode": 7393,
    "reward": 88.758588,
    "length": 68,
    "time": 111696.230825,
    "actor_loss": -70.177001953125,
    "critic_loss": 3.61527156829834,
    "ent_coef": 0.08561026304960251,
    "learning_rate": 0.001
  },
  {
    "episode": 7394,
    "reward": 87.166857,
    "length": 71,
    "time": 111708.84887,
    "actor_loss": -72.08302307128906,
    "critic_loss": 15.40866470336914,
    "ent_coef": 0.08138440549373627,
    "learning_rate": 0.001
  },
  {
    "episode": 7395,
    "reward": 86.433222,
    "length": 71,
    "time": 111722.162473,
    "actor_loss": -66.21564483642578,
    "critic_loss": 3.7379190921783447,
    "ent_coef": 0.07483108341693878,
    "learning_rate": 0.001
  },
  {
    "episode": 7396,
    "reward": 87.211027,
    "length": 74,
    "time": 111738.678004,
    "actor_loss": -68.62979125976562,
    "critic_loss": 75.35139465332031,
    "ent_coef": 0.07009989023208618,
    "learning_rate": 0.001
  },
  {
    "episode": 7397,
    "reward": 89.268992,
    "length": 70,
    "time": 111751.841951,
    "actor_loss": -66.343994140625,
    "critic_loss": 5.056250095367432,
    "ent_coef": 0.07024747133255005,
    "learning_rate": 0.001
  },
  {
    "episode": 7398,
    "reward": 90.685942,
    "length": 63,
    "time": 111763.080574,
    "actor_loss": -63.63536071777344,
    "critic_loss": 9.21853256225586,
    "ent_coef": 0.0693417638540268,
    "learning_rate": 0.001
  },
  {
    "episode": 7399,
    "reward": 90.24795,
    "length": 63,
    "time": 111774.394761,
    "actor_loss": -73.0221176147461,
    "critic_loss": 3.0582265853881836,
    "ent_coef": 0.06808385998010635,
    "learning_rate": 0.001
  },
  {
    "episode": 7400,
    "reward": 90.772842,
    "length": 63,
    "time": 111788.077274,
    "actor_loss": -66.6043701171875,
    "critic_loss": 20.973766326904297,
    "ent_coef": 0.07171750068664551,
    "learning_rate": 0.001
  },
  {
    "episode": 7401,
    "reward": 89.273885,
    "length": 65,
    "time": 111802.292797,
    "actor_loss": -63.413238525390625,
    "critic_loss": 13.032060623168945,
    "ent_coef": 0.07363149523735046,
    "learning_rate": 0.001
  },
  {
    "episode": 7402,
    "reward": 86.222997,
    "length": 78,
    "time": 111817.0466,
    "actor_loss": -70.63243103027344,
    "critic_loss": 8.362284660339355,
    "ent_coef": 0.07373247295618057,
    "learning_rate": 0.001
  },
  {
    "episode": 7403,
    "reward": 87.877711,
    "length": 69,
    "time": 111828.997108,
    "actor_loss": -63.322998046875,
    "critic_loss": 31.816635131835938,
    "ent_coef": 0.07408348470926285,
    "learning_rate": 0.001
  },
  {
    "episode": 7404,
    "reward": 90.014592,
    "length": 65,
    "time": 111840.564603,
    "actor_loss": -68.33013153076172,
    "critic_loss": 10.62620735168457,
    "ent_coef": 0.07508983463048935,
    "learning_rate": 0.001
  },
  {
    "episode": 7405,
    "reward": 90.456573,
    "length": 65,
    "time": 111853.102503,
    "actor_loss": -71.2563247680664,
    "critic_loss": 4.3213958740234375,
    "ent_coef": 0.07626111060380936,
    "learning_rate": 0.001
  },
  {
    "episode": 7406,
    "reward": 88.110316,
    "length": 67,
    "time": 111865.282297,
    "actor_loss": -64.9063720703125,
    "critic_loss": 5.646770477294922,
    "ent_coef": 0.0770692452788353,
    "learning_rate": 0.001
  },
  {
    "episode": 7407,
    "reward": 85.507318,
    "length": 81,
    "time": 111880.538999,
    "actor_loss": -65.79864501953125,
    "critic_loss": 3.524533271789551,
    "ent_coef": 0.07783401757478714,
    "learning_rate": 0.001
  },
  {
    "episode": 7408,
    "reward": 87.378683,
    "length": 71,
    "time": 111894.265837,
    "actor_loss": -69.95536804199219,
    "critic_loss": 26.334991455078125,
    "ent_coef": 0.07613348215818405,
    "learning_rate": 0.001
  },
  {
    "episode": 7409,
    "reward": 89.88781,
    "length": 64,
    "time": 111906.568701,
    "actor_loss": -62.49087142944336,
    "critic_loss": 5.6827712059021,
    "ent_coef": 0.07778322696685791,
    "learning_rate": 0.001
  },
  {
    "episode": 7410,
    "reward": 87.589744,
    "length": 69,
    "time": 111921.235774,
    "actor_loss": -61.20240783691406,
    "critic_loss": 4.104755401611328,
    "ent_coef": 0.07641226053237915,
    "learning_rate": 0.001
  },
  {
    "episode": 7411,
    "reward": 89.228178,
    "length": 66,
    "time": 111935.915769,
    "actor_loss": -68.99505615234375,
    "critic_loss": 7.158729553222656,
    "ent_coef": 0.0753982663154602,
    "learning_rate": 0.001
  },
  {
    "episode": 7412,
    "reward": 88.603539,
    "length": 67,
    "time": 111950.810981,
    "actor_loss": -68.11188507080078,
    "critic_loss": 4.572196006774902,
    "ent_coef": 0.07182630151510239,
    "learning_rate": 0.001
  },
  {
    "episode": 7413,
    "reward": 88.920208,
    "length": 67,
    "time": 111964.071855,
    "actor_loss": -65.24560546875,
    "critic_loss": 41.638267517089844,
    "ent_coef": 0.07085993140935898,
    "learning_rate": 0.001
  },
  {
    "episode": 7414,
    "reward": 90.820912,
    "length": 62,
    "time": 111975.327166,
    "actor_loss": -69.92529296875,
    "critic_loss": 6.94917631149292,
    "ent_coef": 0.07430510222911835,
    "learning_rate": 0.001
  },
  {
    "episode": 7415,
    "reward": 87.987195,
    "length": 69,
    "time": 111989.180841,
    "actor_loss": -63.977577209472656,
    "critic_loss": 10.263129234313965,
    "ent_coef": 0.07393951714038849,
    "learning_rate": 0.001
  },
  {
    "episode": 7416,
    "reward": 89.250709,
    "length": 65,
    "time": 112000.695935,
    "actor_loss": -76.812744140625,
    "critic_loss": 17.82620620727539,
    "ent_coef": 0.07121886312961578,
    "learning_rate": 0.001
  },
  {
    "episode": 7417,
    "reward": 87.235427,
    "length": 71,
    "time": 112014.189933,
    "actor_loss": -70.42727661132812,
    "critic_loss": 24.07280731201172,
    "ent_coef": 0.06888987869024277,
    "learning_rate": 0.001
  },
  {
    "episode": 7418,
    "reward": 90.71008,
    "length": 62,
    "time": 112026.192633,
    "actor_loss": -69.16057586669922,
    "critic_loss": 4.59226131439209,
    "ent_coef": 0.06855393201112747,
    "learning_rate": 0.001
  },
  {
    "episode": 7419,
    "reward": 88.935137,
    "length": 68,
    "time": 112038.29938,
    "actor_loss": -66.65850830078125,
    "critic_loss": 34.05147933959961,
    "ent_coef": 0.0701783075928688,
    "learning_rate": 0.001
  },
  {
    "episode": 7420,
    "reward": 90.151228,
    "length": 64,
    "time": 112051.330058,
    "actor_loss": -68.65757751464844,
    "critic_loss": 3.881282091140747,
    "ent_coef": 0.06949431449174881,
    "learning_rate": 0.001
  },
  {
    "episode": 7421,
    "reward": 90.027904,
    "length": 65,
    "time": 112063.929102,
    "actor_loss": -67.36329650878906,
    "critic_loss": 8.187782287597656,
    "ent_coef": 0.07202688604593277,
    "learning_rate": 0.001
  },
  {
    "episode": 7422,
    "reward": 88.101202,
    "length": 69,
    "time": 112078.468653,
    "actor_loss": -65.83155822753906,
    "critic_loss": 5.9466552734375,
    "ent_coef": 0.07290740311145782,
    "learning_rate": 0.001
  },
  {
    "episode": 7423,
    "reward": 89.90553,
    "length": 64,
    "time": 112093.768023,
    "actor_loss": -64.39883422851562,
    "critic_loss": 108.353759765625,
    "ent_coef": 0.07655787467956543,
    "learning_rate": 0.001
  },
  {
    "episode": 7424,
    "reward": 90.062259,
    "length": 65,
    "time": 112106.423269,
    "actor_loss": -67.82736206054688,
    "critic_loss": 4.7675676345825195,
    "ent_coef": 0.07924733310937881,
    "learning_rate": 0.001
  },
  {
    "episode": 7425,
    "reward": 80.298862,
    "length": 83,
    "time": 112120.946208,
    "actor_loss": -64.2451171875,
    "critic_loss": 139.07630920410156,
    "ent_coef": 0.07448182255029678,
    "learning_rate": 0.001
  },
  {
    "episode": 7426,
    "reward": 86.419107,
    "length": 70,
    "time": 112135.037739,
    "actor_loss": -65.71549987792969,
    "critic_loss": 2.8071508407592773,
    "ent_coef": 0.07018058001995087,
    "learning_rate": 0.001
  },
  {
    "episode": 7427,
    "reward": 84.427328,
    "length": 73,
    "time": 112149.808552,
    "actor_loss": -69.94065856933594,
    "critic_loss": 5.738399505615234,
    "ent_coef": 0.06727459281682968,
    "learning_rate": 0.001
  },
  {
    "episode": 7428,
    "reward": 87.243269,
    "length": 69,
    "time": 112164.248439,
    "actor_loss": -73.72360229492188,
    "critic_loss": 105.9312744140625,
    "ent_coef": 0.06576811522245407,
    "learning_rate": 0.001
  },
  {
    "episode": 7429,
    "reward": 89.356612,
    "length": 65,
    "time": 112175.794788,
    "actor_loss": -70.76051330566406,
    "critic_loss": 14.320108413696289,
    "ent_coef": 0.06273391097784042,
    "learning_rate": 0.001
  },
  {
    "episode": 7430,
    "reward": 89.539253,
    "length": 66,
    "time": 112188.112399,
    "actor_loss": -68.06594848632812,
    "critic_loss": 2.8006749153137207,
    "ent_coef": 0.06290093064308167,
    "learning_rate": 0.001
  },
  {
    "episode": 7431,
    "reward": 89.127726,
    "length": 65,
    "time": 112201.782828,
    "actor_loss": -66.8509292602539,
    "critic_loss": 4.569896221160889,
    "ent_coef": 0.06416439265012741,
    "learning_rate": 0.001
  },
  {
    "episode": 7432,
    "reward": 90.653528,
    "length": 63,
    "time": 112217.532219,
    "actor_loss": -67.80574035644531,
    "critic_loss": 18.785953521728516,
    "ent_coef": 0.06501469761133194,
    "learning_rate": 0.001
  },
  {
    "episode": 7433,
    "reward": 91.170702,
    "length": 62,
    "time": 112230.701732,
    "actor_loss": -68.1501693725586,
    "critic_loss": 16.927331924438477,
    "ent_coef": 0.06845875829458237,
    "learning_rate": 0.001
  },
  {
    "episode": 7434,
    "reward": 89.127774,
    "length": 65,
    "time": 112242.389823,
    "actor_loss": -70.17044067382812,
    "critic_loss": 2.160222291946411,
    "ent_coef": 0.06845566630363464,
    "learning_rate": 0.001
  },
  {
    "episode": 7435,
    "reward": 89.255862,
    "length": 65,
    "time": 112254.803098,
    "actor_loss": -69.53555297851562,
    "critic_loss": 7.0873236656188965,
    "ent_coef": 0.06932535022497177,
    "learning_rate": 0.001
  },
  {
    "episode": 7436,
    "reward": 88.278684,
    "length": 72,
    "time": 112269.191256,
    "actor_loss": -69.61969757080078,
    "critic_loss": 61.55754852294922,
    "ent_coef": 0.06930821388959885,
    "learning_rate": 0.001
  },
  {
    "episode": 7437,
    "reward": 91.14638,
    "length": 61,
    "time": 112280.101557,
    "actor_loss": -62.3186149597168,
    "critic_loss": 24.366941452026367,
    "ent_coef": 0.0699746385216713,
    "learning_rate": 0.001
  },
  {
    "episode": 7438,
    "reward": 89.180153,
    "length": 66,
    "time": 112292.98521,
    "actor_loss": -68.74441528320312,
    "critic_loss": 4.194849967956543,
    "ent_coef": 0.06981266289949417,
    "learning_rate": 0.001
  },
  {
    "episode": 7439,
    "reward": 86.002558,
    "length": 75,
    "time": 112305.764904,
    "actor_loss": -68.3242416381836,
    "critic_loss": 2.9751362800598145,
    "ent_coef": 0.06688150763511658,
    "learning_rate": 0.001
  },
  {
    "episode": 7440,
    "reward": 88.347527,
    "length": 68,
    "time": 112318.734081,
    "actor_loss": -73.70611572265625,
    "critic_loss": 4.443835735321045,
    "ent_coef": 0.06615184992551804,
    "learning_rate": 0.001
  },
  {
    "episode": 7441,
    "reward": 84.526113,
    "length": 76,
    "time": 112336.421713,
    "actor_loss": -65.42987060546875,
    "critic_loss": 3.7820053100585938,
    "ent_coef": 0.06636042147874832,
    "learning_rate": 0.001
  },
  {
    "episode": 7442,
    "reward": 89.84067,
    "length": 65,
    "time": 112349.758677,
    "actor_loss": -65.26019287109375,
    "critic_loss": 7.638872146606445,
    "ent_coef": 0.06972482055425644,
    "learning_rate": 0.001
  },
  {
    "episode": 7443,
    "reward": 86.697043,
    "length": 70,
    "time": 112362.534283,
    "actor_loss": -59.42791748046875,
    "critic_loss": 3.502131700515747,
    "ent_coef": 0.0680176317691803,
    "learning_rate": 0.001
  },
  {
    "episode": 7444,
    "reward": 89.116007,
    "length": 67,
    "time": 112377.177059,
    "actor_loss": -68.91030883789062,
    "critic_loss": 3.8848071098327637,
    "ent_coef": 0.06752096861600876,
    "learning_rate": 0.001
  },
  {
    "episode": 7445,
    "reward": 80.422943,
    "length": 84,
    "time": 112394.316856,
    "actor_loss": -66.55802154541016,
    "critic_loss": 4.915266513824463,
    "ent_coef": 0.06418318301439285,
    "learning_rate": 0.001
  },
  {
    "episode": 7446,
    "reward": 84.663514,
    "length": 75,
    "time": 112408.329561,
    "actor_loss": -74.62110900878906,
    "critic_loss": 5.048289775848389,
    "ent_coef": 0.06364846974611282,
    "learning_rate": 0.001
  },
  {
    "episode": 7447,
    "reward": 88.498611,
    "length": 70,
    "time": 112421.313816,
    "actor_loss": -70.0599365234375,
    "critic_loss": 11.893444061279297,
    "ent_coef": 0.06618548184633255,
    "learning_rate": 0.001
  },
  {
    "episode": 7448,
    "reward": 90.860302,
    "length": 62,
    "time": 112434.633778,
    "actor_loss": -69.37155151367188,
    "critic_loss": 19.591766357421875,
    "ent_coef": 0.06890041381120682,
    "learning_rate": 0.001
  },
  {
    "episode": 7449,
    "reward": 90.870023,
    "length": 63,
    "time": 112446.825355,
    "actor_loss": -66.7829360961914,
    "critic_loss": 30.310260772705078,
    "ent_coef": 0.07257519662380219,
    "learning_rate": 0.001
  },
  {
    "episode": 7450,
    "reward": 87.246172,
    "length": 70,
    "time": 112459.118908,
    "actor_loss": -64.12360382080078,
    "critic_loss": 26.38640594482422,
    "ent_coef": 0.07118503004312515,
    "learning_rate": 0.001
  },
  {
    "episode": 7451,
    "reward": 86.923457,
    "length": 69,
    "time": 112471.856642,
    "actor_loss": -73.4976806640625,
    "critic_loss": 46.24143600463867,
    "ent_coef": 0.06950036436319351,
    "learning_rate": 0.001
  },
  {
    "episode": 7452,
    "reward": 87.288139,
    "length": 70,
    "time": 112485.673847,
    "actor_loss": -70.93501281738281,
    "critic_loss": 9.437128067016602,
    "ent_coef": 0.06726979464292526,
    "learning_rate": 0.001
  },
  {
    "episode": 7453,
    "reward": 89.080215,
    "length": 65,
    "time": 112498.39993,
    "actor_loss": -67.95964050292969,
    "critic_loss": 3.8226473331451416,
    "ent_coef": 0.0674050971865654,
    "learning_rate": 0.001
  },
  {
    "episode": 7454,
    "reward": 87.996011,
    "length": 68,
    "time": 112511.052117,
    "actor_loss": -64.65792846679688,
    "critic_loss": 32.376731872558594,
    "ent_coef": 0.06780137121677399,
    "learning_rate": 0.001
  },
  {
    "episode": 7455,
    "reward": 90.215409,
    "length": 63,
    "time": 112523.35458,
    "actor_loss": -66.91956329345703,
    "critic_loss": 10.907913208007812,
    "ent_coef": 0.0691988468170166,
    "learning_rate": 0.001
  },
  {
    "episode": 7456,
    "reward": 89.709019,
    "length": 64,
    "time": 112535.79434,
    "actor_loss": -64.27825927734375,
    "critic_loss": 10.548282623291016,
    "ent_coef": 0.07099712640047073,
    "learning_rate": 0.001
  },
  {
    "episode": 7457,
    "reward": 88.699609,
    "length": 67,
    "time": 112551.002705,
    "actor_loss": -67.76976013183594,
    "critic_loss": 58.410831451416016,
    "ent_coef": 0.07308033853769302,
    "learning_rate": 0.001
  },
  {
    "episode": 7458,
    "reward": 87.66293,
    "length": 69,
    "time": 112566.492824,
    "actor_loss": -68.32418823242188,
    "critic_loss": 17.03154945373535,
    "ent_coef": 0.07337503880262375,
    "learning_rate": 0.001
  },
  {
    "episode": 7459,
    "reward": 89.352161,
    "length": 65,
    "time": 112580.89431,
    "actor_loss": -64.63179779052734,
    "critic_loss": 9.69739818572998,
    "ent_coef": 0.07262586802244186,
    "learning_rate": 0.001
  },
  {
    "episode": 7460,
    "reward": 85.321202,
    "length": 72,
    "time": 112594.30255,
    "actor_loss": -66.66646575927734,
    "critic_loss": 4.390561103820801,
    "ent_coef": 0.0725758969783783,
    "learning_rate": 0.001
  },
  {
    "episode": 7461,
    "reward": 84.410131,
    "length": 80,
    "time": 112609.215266,
    "actor_loss": -69.51122283935547,
    "critic_loss": 40.28403091430664,
    "ent_coef": 0.07099039107561111,
    "learning_rate": 0.001
  },
  {
    "episode": 7462,
    "reward": 86.843115,
    "length": 68,
    "time": 112623.13399,
    "actor_loss": -66.94282531738281,
    "critic_loss": 5.801509857177734,
    "ent_coef": 0.06917218863964081,
    "learning_rate": 0.001
  },
  {
    "episode": 7463,
    "reward": 87.788663,
    "length": 66,
    "time": 112636.40598,
    "actor_loss": -67.28983306884766,
    "critic_loss": 4.3708720207214355,
    "ent_coef": 0.07065621018409729,
    "learning_rate": 0.001
  },
  {
    "episode": 7464,
    "reward": 90.890837,
    "length": 61,
    "time": 112647.352941,
    "actor_loss": -73.48001098632812,
    "critic_loss": 8.313764572143555,
    "ent_coef": 0.07454314827919006,
    "learning_rate": 0.001
  },
  {
    "episode": 7465,
    "reward": 90.09418,
    "length": 67,
    "time": 112662.050037,
    "actor_loss": -65.33759307861328,
    "critic_loss": 6.169250965118408,
    "ent_coef": 0.07694936543703079,
    "learning_rate": 0.001
  },
  {
    "episode": 7466,
    "reward": 90.240256,
    "length": 64,
    "time": 112674.577737,
    "actor_loss": -72.23099517822266,
    "critic_loss": 2.3067994117736816,
    "ent_coef": 0.07999574393033981,
    "learning_rate": 0.001
  },
  {
    "episode": 7467,
    "reward": 91.022765,
    "length": 61,
    "time": 112685.597958,
    "actor_loss": -68.53070068359375,
    "critic_loss": 70.46859741210938,
    "ent_coef": 0.07998132705688477,
    "learning_rate": 0.001
  },
  {
    "episode": 7468,
    "reward": 90.568525,
    "length": 64,
    "time": 112697.15606,
    "actor_loss": -68.470458984375,
    "critic_loss": 27.058025360107422,
    "ent_coef": 0.07932526618242264,
    "learning_rate": 0.001
  },
  {
    "episode": 7469,
    "reward": 86.930101,
    "length": 74,
    "time": 112714.087743,
    "actor_loss": -69.82949829101562,
    "critic_loss": 10.989608764648438,
    "ent_coef": 0.08070701360702515,
    "learning_rate": 0.001
  },
  {
    "episode": 7470,
    "reward": 91.59966,
    "length": 62,
    "time": 112725.180557,
    "actor_loss": -65.67567443847656,
    "critic_loss": 13.17827320098877,
    "ent_coef": 0.08299190551042557,
    "learning_rate": 0.001
  },
  {
    "episode": 7471,
    "reward": 85.702471,
    "length": 73,
    "time": 112739.379645,
    "actor_loss": -66.10417175292969,
    "critic_loss": 2.303955554962158,
    "ent_coef": 0.07934165000915527,
    "learning_rate": 0.001
  },
  {
    "episode": 7472,
    "reward": 88.237133,
    "length": 68,
    "time": 112752.184967,
    "actor_loss": -68.79637145996094,
    "critic_loss": 16.385732650756836,
    "ent_coef": 0.07549979537725449,
    "learning_rate": 0.001
  },
  {
    "episode": 7473,
    "reward": 90.91565,
    "length": 64,
    "time": 112764.588713,
    "actor_loss": -65.59980773925781,
    "critic_loss": 106.8744125366211,
    "ent_coef": 0.07414045184850693,
    "learning_rate": 0.001
  },
  {
    "episode": 7474,
    "reward": 91.438142,
    "length": 61,
    "time": 112775.575878,
    "actor_loss": -76.02298736572266,
    "critic_loss": 3.293318510055542,
    "ent_coef": 0.07564530521631241,
    "learning_rate": 0.001
  },
  {
    "episode": 7475,
    "reward": 90.456815,
    "length": 63,
    "time": 112786.807465,
    "actor_loss": -65.57270812988281,
    "critic_loss": 2.1160998344421387,
    "ent_coef": 0.07708553969860077,
    "learning_rate": 0.001
  },
  {
    "episode": 7476,
    "reward": 88.943772,
    "length": 66,
    "time": 112800.100994,
    "actor_loss": -71.06111145019531,
    "critic_loss": 16.407657623291016,
    "ent_coef": 0.07618843019008636,
    "learning_rate": 0.001
  },
  {
    "episode": 7477,
    "reward": 83.215063,
    "length": 82,
    "time": 112813.763476,
    "actor_loss": -69.16792297363281,
    "critic_loss": 3.1698145866394043,
    "ent_coef": 0.0722508355975151,
    "learning_rate": 0.001
  },
  {
    "episode": 7478,
    "reward": -158.492952,
    "length": 141,
    "time": 112836.110994,
    "actor_loss": -68.373291015625,
    "critic_loss": 9.470071792602539,
    "ent_coef": 0.07493800669908524,
    "learning_rate": 0.001
  },
  {
    "episode": 7479,
    "reward": 87.108992,
    "length": 67,
    "time": 112848.805011,
    "actor_loss": -64.32158660888672,
    "critic_loss": 28.952138900756836,
    "ent_coef": 0.07970020920038223,
    "learning_rate": 0.001
  },
  {
    "episode": 7480,
    "reward": 85.416847,
    "length": 73,
    "time": 112864.074522,
    "actor_loss": -69.84017944335938,
    "critic_loss": 8.035755157470703,
    "ent_coef": 0.0800599530339241,
    "learning_rate": 0.001
  },
  {
    "episode": 7481,
    "reward": 89.185104,
    "length": 64,
    "time": 112876.577448,
    "actor_loss": -64.52958679199219,
    "critic_loss": 7.385520935058594,
    "ent_coef": 0.07713697850704193,
    "learning_rate": 0.001
  },
  {
    "episode": 7482,
    "reward": 81.887034,
    "length": 82,
    "time": 112891.270031,
    "actor_loss": -71.56234741210938,
    "critic_loss": 7.050825119018555,
    "ent_coef": 0.0699370950460434,
    "learning_rate": 0.001
  },
  {
    "episode": 7483,
    "reward": 82.559979,
    "length": 78,
    "time": 112905.257504,
    "actor_loss": -70.54884338378906,
    "critic_loss": 30.64476776123047,
    "ent_coef": 0.061989229172468185,
    "learning_rate": 0.001
  },
  {
    "episode": 7484,
    "reward": 84.378135,
    "length": 78,
    "time": 112919.424459,
    "actor_loss": -66.94046020507812,
    "critic_loss": 27.36921501159668,
    "ent_coef": 0.05747288838028908,
    "learning_rate": 0.001
  },
  {
    "episode": 7485,
    "reward": -163.193352,
    "length": 141,
    "time": 112944.700933,
    "actor_loss": -68.87057495117188,
    "critic_loss": 5.262729644775391,
    "ent_coef": 0.05980689078569412,
    "learning_rate": 0.001
  },
  {
    "episode": 7486,
    "reward": 89.390371,
    "length": 75,
    "time": 112957.526935,
    "actor_loss": -67.24069213867188,
    "critic_loss": 4.18403434753418,
    "ent_coef": 0.059534862637519836,
    "learning_rate": 0.001
  },
  {
    "episode": 7487,
    "reward": -155.119573,
    "length": 136,
    "time": 112980.194039,
    "actor_loss": -67.81434631347656,
    "critic_loss": 8.289179801940918,
    "ent_coef": 0.06305698305368423,
    "learning_rate": 0.001
  },
  {
    "episode": 7488,
    "reward": 86.763808,
    "length": 74,
    "time": 112996.243321,
    "actor_loss": -68.93877410888672,
    "critic_loss": 3.7632713317871094,
    "ent_coef": 0.0630008652806282,
    "learning_rate": 0.001
  },
  {
    "episode": 7489,
    "reward": 86.677095,
    "length": 86,
    "time": 113011.688314,
    "actor_loss": -67.32249450683594,
    "critic_loss": 40.78017044067383,
    "ent_coef": 0.06601806730031967,
    "learning_rate": 0.001
  },
  {
    "episode": 7490,
    "reward": 84.612913,
    "length": 71,
    "time": 113023.901469,
    "actor_loss": -75.87894439697266,
    "critic_loss": 6.711103439331055,
    "ent_coef": 0.06797564774751663,
    "learning_rate": 0.001
  },
  {
    "episode": 7491,
    "reward": -158.427215,
    "length": 134,
    "time": 113046.303214,
    "actor_loss": -69.67179870605469,
    "critic_loss": 4.081411838531494,
    "ent_coef": 0.07157351821660995,
    "learning_rate": 0.001
  },
  {
    "episode": 7492,
    "reward": 85.58266,
    "length": 71,
    "time": 113061.423088,
    "actor_loss": -67.92861938476562,
    "critic_loss": 57.66341781616211,
    "ent_coef": 0.07076296955347061,
    "learning_rate": 0.001
  },
  {
    "episode": 7493,
    "reward": 87.708538,
    "length": 68,
    "time": 113073.119825,
    "actor_loss": -65.44297790527344,
    "critic_loss": 6.0409722328186035,
    "ent_coef": 0.07142991572618484,
    "learning_rate": 0.001
  },
  {
    "episode": 7494,
    "reward": 84.014543,
    "length": 79,
    "time": 113086.705711,
    "actor_loss": -67.71529388427734,
    "critic_loss": 20.925155639648438,
    "ent_coef": 0.0715315043926239,
    "learning_rate": 0.001
  },
  {
    "episode": 7495,
    "reward": 87.475315,
    "length": 68,
    "time": 113100.447979,
    "actor_loss": -71.79887390136719,
    "critic_loss": 5.545765399932861,
    "ent_coef": 0.06938125938177109,
    "learning_rate": 0.001
  },
  {
    "episode": 7496,
    "reward": 88.55374,
    "length": 67,
    "time": 113112.303638,
    "actor_loss": -64.08940124511719,
    "critic_loss": 9.269221305847168,
    "ent_coef": 0.06827925890684128,
    "learning_rate": 0.001
  },
  {
    "episode": 7497,
    "reward": -156.876038,
    "length": 139,
    "time": 113134.90417,
    "actor_loss": -72.72315216064453,
    "critic_loss": 31.091632843017578,
    "ent_coef": 0.06840331852436066,
    "learning_rate": 0.001
  },
  {
    "episode": 7498,
    "reward": 79.762546,
    "length": 92,
    "time": 113149.780159,
    "actor_loss": -65.47578430175781,
    "critic_loss": 4.374047756195068,
    "ent_coef": 0.062325604259967804,
    "learning_rate": 0.001
  },
  {
    "episode": 7499,
    "reward": 88.701527,
    "length": 71,
    "time": 113162.118114,
    "actor_loss": -68.64385986328125,
    "critic_loss": 67.60641479492188,
    "ent_coef": 0.06288620829582214,
    "learning_rate": 0.001
  },
  {
    "episode": 7500,
    "reward": 87.321525,
    "length": 69,
    "time": 113174.509136,
    "actor_loss": -63.64238739013672,
    "critic_loss": 5.906675815582275,
    "ent_coef": 0.0668768510222435,
    "learning_rate": 0.001
  },
  {
    "episode": 7501,
    "reward": 87.893542,
    "length": 66,
    "time": 113187.32663,
    "actor_loss": -68.69436645507812,
    "critic_loss": 14.33686351776123,
    "ent_coef": 0.06921405345201492,
    "learning_rate": 0.001
  },
  {
    "episode": 7502,
    "reward": 87.417952,
    "length": 68,
    "time": 113201.279008,
    "actor_loss": -66.97683715820312,
    "critic_loss": 9.01102352142334,
    "ent_coef": 0.07038453966379166,
    "learning_rate": 0.001
  },
  {
    "episode": 7503,
    "reward": 87.305231,
    "length": 68,
    "time": 113214.221461,
    "actor_loss": -70.23741149902344,
    "critic_loss": 12.779516220092773,
    "ent_coef": 0.07049436867237091,
    "learning_rate": 0.001
  },
  {
    "episode": 7504,
    "reward": 88.43366,
    "length": 67,
    "time": 113226.116202,
    "actor_loss": -67.10533142089844,
    "critic_loss": 20.880905151367188,
    "ent_coef": 0.07056410610675812,
    "learning_rate": 0.001
  },
  {
    "episode": 7505,
    "reward": 85.176743,
    "length": 76,
    "time": 113239.812557,
    "actor_loss": -68.2400894165039,
    "critic_loss": 4.337654113769531,
    "ent_coef": 0.07085638493299484,
    "learning_rate": 0.001
  },
  {
    "episode": 7506,
    "reward": 89.113561,
    "length": 64,
    "time": 113254.326502,
    "actor_loss": -64.70182037353516,
    "critic_loss": 2.0965628623962402,
    "ent_coef": 0.069965660572052,
    "learning_rate": 0.001
  },
  {
    "episode": 7507,
    "reward": 88.585557,
    "length": 68,
    "time": 113266.384447,
    "actor_loss": -65.7956771850586,
    "critic_loss": 17.467266082763672,
    "ent_coef": 0.0693686231970787,
    "learning_rate": 0.001
  },
  {
    "episode": 7508,
    "reward": 91.333471,
    "length": 62,
    "time": 113278.335872,
    "actor_loss": -69.65448760986328,
    "critic_loss": 39.00614929199219,
    "ent_coef": 0.07076447457075119,
    "learning_rate": 0.001
  },
  {
    "episode": 7509,
    "reward": 86.104492,
    "length": 70,
    "time": 113292.601447,
    "actor_loss": -66.57416534423828,
    "critic_loss": 2.767946243286133,
    "ent_coef": 0.06912574917078018,
    "learning_rate": 0.001
  },
  {
    "episode": 7510,
    "reward": 86.998206,
    "length": 69,
    "time": 113305.779186,
    "actor_loss": -70.5225830078125,
    "critic_loss": 4.981719017028809,
    "ent_coef": 0.0674055814743042,
    "learning_rate": 0.001
  },
  {
    "episode": 7511,
    "reward": 90.700274,
    "length": 63,
    "time": 113321.769637,
    "actor_loss": -70.45294189453125,
    "critic_loss": 4.198177814483643,
    "ent_coef": 0.06859239935874939,
    "learning_rate": 0.001
  },
  {
    "episode": 7512,
    "reward": 89.102059,
    "length": 65,
    "time": 113335.222116,
    "actor_loss": -67.90877532958984,
    "critic_loss": 15.356773376464844,
    "ent_coef": 0.06846737116575241,
    "learning_rate": 0.001
  },
  {
    "episode": 7513,
    "reward": 90.289444,
    "length": 63,
    "time": 113348.829358,
    "actor_loss": -66.63304138183594,
    "critic_loss": 3.772099018096924,
    "ent_coef": 0.06952923536300659,
    "learning_rate": 0.001
  },
  {
    "episode": 7514,
    "reward": 90.373361,
    "length": 63,
    "time": 113362.019916,
    "actor_loss": -66.99916076660156,
    "critic_loss": 24.783761978149414,
    "ent_coef": 0.07161416113376617,
    "learning_rate": 0.001
  },
  {
    "episode": 7515,
    "reward": 80.687843,
    "length": 87,
    "time": 113376.711987,
    "actor_loss": -68.05499267578125,
    "critic_loss": 145.01060485839844,
    "ent_coef": 0.0680953860282898,
    "learning_rate": 0.001
  },
  {
    "episode": 7516,
    "reward": 88.743636,
    "length": 71,
    "time": 113388.909411,
    "actor_loss": -66.70841979980469,
    "critic_loss": 4.376037120819092,
    "ent_coef": 0.07138357311487198,
    "learning_rate": 0.001
  },
  {
    "episode": 7517,
    "reward": -162.565718,
    "length": 151,
    "time": 113411.665064,
    "actor_loss": -68.65479278564453,
    "critic_loss": 33.7967529296875,
    "ent_coef": 0.07114388793706894,
    "learning_rate": 0.001
  },
  {
    "episode": 7518,
    "reward": 86.907537,
    "length": 76,
    "time": 113426.506901,
    "actor_loss": -64.55342102050781,
    "critic_loss": 22.897876739501953,
    "ent_coef": 0.07187649607658386,
    "learning_rate": 0.001
  },
  {
    "episode": 7519,
    "reward": 85.202756,
    "length": 72,
    "time": 113442.862452,
    "actor_loss": -63.0772590637207,
    "critic_loss": 4.908642768859863,
    "ent_coef": 0.0710594654083252,
    "learning_rate": 0.001
  },
  {
    "episode": 7520,
    "reward": 90.978416,
    "length": 63,
    "time": 113454.990435,
    "actor_loss": -69.10260772705078,
    "critic_loss": 9.316761016845703,
    "ent_coef": 0.07185321301221848,
    "learning_rate": 0.001
  },
  {
    "episode": 7521,
    "reward": 91.241875,
    "length": 63,
    "time": 113468.866805,
    "actor_loss": -67.06134033203125,
    "critic_loss": 12.813352584838867,
    "ent_coef": 0.07441098988056183,
    "learning_rate": 0.001
  },
  {
    "episode": 7522,
    "reward": 90.487385,
    "length": 64,
    "time": 113480.654829,
    "actor_loss": -64.70372009277344,
    "critic_loss": 4.269813537597656,
    "ent_coef": 0.07561001926660538,
    "learning_rate": 0.001
  },
  {
    "episode": 7523,
    "reward": 90.192375,
    "length": 63,
    "time": 113492.87017,
    "actor_loss": -69.48101806640625,
    "critic_loss": 58.629486083984375,
    "ent_coef": 0.0765155777335167,
    "learning_rate": 0.001
  },
  {
    "episode": 7524,
    "reward": 89.82952,
    "length": 63,
    "time": 113504.523717,
    "actor_loss": -65.74571990966797,
    "critic_loss": 4.981999397277832,
    "ent_coef": 0.07673046737909317,
    "learning_rate": 0.001
  },
  {
    "episode": 7525,
    "reward": 90.787688,
    "length": 63,
    "time": 113515.97628,
    "actor_loss": -71.34634399414062,
    "critic_loss": 231.03048706054688,
    "ent_coef": 0.077724389731884,
    "learning_rate": 0.001
  },
  {
    "episode": 7526,
    "reward": 91.88088,
    "length": 59,
    "time": 113529.582279,
    "actor_loss": -62.136653900146484,
    "critic_loss": 7.445137023925781,
    "ent_coef": 0.07825326174497604,
    "learning_rate": 0.001
  },
  {
    "episode": 7527,
    "reward": 88.950128,
    "length": 66,
    "time": 113543.986074,
    "actor_loss": -64.7525405883789,
    "critic_loss": 34.084625244140625,
    "ent_coef": 0.07694927603006363,
    "learning_rate": 0.001
  },
  {
    "episode": 7528,
    "reward": 89.645789,
    "length": 64,
    "time": 113557.332844,
    "actor_loss": -69.05406188964844,
    "critic_loss": 26.735797882080078,
    "ent_coef": 0.08014208823442459,
    "learning_rate": 0.001
  },
  {
    "episode": 7529,
    "reward": 87.500783,
    "length": 67,
    "time": 113569.523178,
    "actor_loss": -68.83984375,
    "critic_loss": 15.326240539550781,
    "ent_coef": 0.0811910629272461,
    "learning_rate": 0.001
  },
  {
    "episode": 7530,
    "reward": 89.688682,
    "length": 63,
    "time": 113580.981393,
    "actor_loss": -62.62203598022461,
    "critic_loss": 40.855308532714844,
    "ent_coef": 0.08075612783432007,
    "learning_rate": 0.001
  },
  {
    "episode": 7531,
    "reward": 87.987042,
    "length": 70,
    "time": 113595.813323,
    "actor_loss": -72.36262512207031,
    "critic_loss": 2.91872501373291,
    "ent_coef": 0.0811874195933342,
    "learning_rate": 0.001
  },
  {
    "episode": 7532,
    "reward": 83.588129,
    "length": 79,
    "time": 113609.128775,
    "actor_loss": -69.75630187988281,
    "critic_loss": 91.60039520263672,
    "ent_coef": 0.08269651979207993,
    "learning_rate": 0.001
  },
  {
    "episode": 7533,
    "reward": 89.422296,
    "length": 65,
    "time": 113621.409837,
    "actor_loss": -72.6772232055664,
    "critic_loss": 12.359267234802246,
    "ent_coef": 0.08018835633993149,
    "learning_rate": 0.001
  },
  {
    "episode": 7534,
    "reward": 89.960197,
    "length": 63,
    "time": 113634.677835,
    "actor_loss": -66.39961242675781,
    "critic_loss": 6.061396598815918,
    "ent_coef": 0.08004513382911682,
    "learning_rate": 0.001
  },
  {
    "episode": 7535,
    "reward": 90.172088,
    "length": 65,
    "time": 113647.324003,
    "actor_loss": -67.21620178222656,
    "critic_loss": 8.022522926330566,
    "ent_coef": 0.08258701115846634,
    "learning_rate": 0.001
  },
  {
    "episode": 7536,
    "reward": 87.319083,
    "length": 68,
    "time": 113660.419845,
    "actor_loss": -65.88687133789062,
    "critic_loss": 67.6752700805664,
    "ent_coef": 0.08051249384880066,
    "learning_rate": 0.001
  },
  {
    "episode": 7537,
    "reward": 84.971103,
    "length": 71,
    "time": 113673.701352,
    "actor_loss": -66.97598266601562,
    "critic_loss": 65.9109115600586,
    "ent_coef": 0.07838284224271774,
    "learning_rate": 0.001
  },
  {
    "episode": 7538,
    "reward": 91.47212,
    "length": 62,
    "time": 113685.081545,
    "actor_loss": -65.1186294555664,
    "critic_loss": 7.616335391998291,
    "ent_coef": 0.07974453270435333,
    "learning_rate": 0.001
  },
  {
    "episode": 7539,
    "reward": 88.191182,
    "length": 69,
    "time": 113697.245335,
    "actor_loss": -74.87655639648438,
    "critic_loss": 4.178804397583008,
    "ent_coef": 0.07880189269781113,
    "learning_rate": 0.001
  },
  {
    "episode": 7540,
    "reward": 89.36275,
    "length": 66,
    "time": 113710.376394,
    "actor_loss": -63.11469650268555,
    "critic_loss": 11.760812759399414,
    "ent_coef": 0.08001138269901276,
    "learning_rate": 0.001
  },
  {
    "episode": 7541,
    "reward": 81.901235,
    "length": 79,
    "time": 113725.915122,
    "actor_loss": -66.66162872314453,
    "critic_loss": 14.482343673706055,
    "ent_coef": 0.07248115539550781,
    "learning_rate": 0.001
  },
  {
    "episode": 7542,
    "reward": 83.605215,
    "length": 77,
    "time": 113745.003629,
    "actor_loss": -68.30712890625,
    "critic_loss": 2.0964202880859375,
    "ent_coef": 0.06806313991546631,
    "learning_rate": 0.001
  },
  {
    "episode": 7543,
    "reward": 91.302879,
    "length": 61,
    "time": 113758.767709,
    "actor_loss": -66.81317138671875,
    "critic_loss": 2.126002788543701,
    "ent_coef": 0.0687737911939621,
    "learning_rate": 0.001
  },
  {
    "episode": 7544,
    "reward": 91.243534,
    "length": 60,
    "time": 113774.330005,
    "actor_loss": -69.31703186035156,
    "critic_loss": 6.5422773361206055,
    "ent_coef": 0.07277394831180573,
    "learning_rate": 0.001
  },
  {
    "episode": 7545,
    "reward": 89.686925,
    "length": 68,
    "time": 113787.399682,
    "actor_loss": -66.31944274902344,
    "critic_loss": 11.062997817993164,
    "ent_coef": 0.07437113672494888,
    "learning_rate": 0.001
  },
  {
    "episode": 7546,
    "reward": 90.105608,
    "length": 65,
    "time": 113800.301606,
    "actor_loss": -72.37073516845703,
    "critic_loss": 7.8770036697387695,
    "ent_coef": 0.07417377829551697,
    "learning_rate": 0.001
  },
  {
    "episode": 7547,
    "reward": 85.648192,
    "length": 70,
    "time": 113814.481882,
    "actor_loss": -71.15780639648438,
    "critic_loss": 3.2580785751342773,
    "ent_coef": 0.06985693424940109,
    "learning_rate": 0.001
  },
  {
    "episode": 7548,
    "reward": 89.85527,
    "length": 66,
    "time": 113825.984067,
    "actor_loss": -67.64620971679688,
    "critic_loss": 23.75815200805664,
    "ent_coef": 0.06752274930477142,
    "learning_rate": 0.001
  },
  {
    "episode": 7549,
    "reward": 87.905898,
    "length": 73,
    "time": 113838.377211,
    "actor_loss": -67.92655181884766,
    "critic_loss": 3.2579922676086426,
    "ent_coef": 0.06731219589710236,
    "learning_rate": 0.001
  },
  {
    "episode": 7550,
    "reward": 90.193282,
    "length": 65,
    "time": 113850.079208,
    "actor_loss": -67.82615661621094,
    "critic_loss": 2.613053321838379,
    "ent_coef": 0.06696255505084991,
    "learning_rate": 0.001
  },
  {
    "episode": 7551,
    "reward": 90.303996,
    "length": 63,
    "time": 113861.692501,
    "actor_loss": -66.7409439086914,
    "critic_loss": 12.131728172302246,
    "ent_coef": 0.0661492645740509,
    "learning_rate": 0.001
  },
  {
    "episode": 7552,
    "reward": 50.546434,
    "length": 193,
    "time": 113893.30259,
    "actor_loss": -67.75031280517578,
    "critic_loss": 4.172708511352539,
    "ent_coef": 0.06447022408246994,
    "learning_rate": 0.001
  },
  {
    "episode": 7553,
    "reward": 88.711068,
    "length": 66,
    "time": 113905.729667,
    "actor_loss": -74.16433715820312,
    "critic_loss": 19.511890411376953,
    "ent_coef": 0.06894925236701965,
    "learning_rate": 0.001
  },
  {
    "episode": 7554,
    "reward": 86.068724,
    "length": 72,
    "time": 113919.501705,
    "actor_loss": -66.62115478515625,
    "critic_loss": 12.335031509399414,
    "ent_coef": 0.06905969977378845,
    "learning_rate": 0.001
  },
  {
    "episode": 7555,
    "reward": 90.690663,
    "length": 63,
    "time": 113931.179123,
    "actor_loss": -72.21688079833984,
    "critic_loss": 25.13581085205078,
    "ent_coef": 0.07129129022359848,
    "learning_rate": 0.001
  },
  {
    "episode": 7556,
    "reward": 91.007793,
    "length": 64,
    "time": 113943.876074,
    "actor_loss": -68.08184814453125,
    "critic_loss": 7.978069305419922,
    "ent_coef": 0.07157879322767258,
    "learning_rate": 0.001
  },
  {
    "episode": 7557,
    "reward": 87.271665,
    "length": 72,
    "time": 113957.12675,
    "actor_loss": -66.26818084716797,
    "critic_loss": 4.61155891418457,
    "ent_coef": 0.06910952925682068,
    "learning_rate": 0.001
  },
  {
    "episode": 7558,
    "reward": -165.688307,
    "length": 155,
    "time": 113981.038564,
    "actor_loss": -67.28071594238281,
    "critic_loss": 4.325466632843018,
    "ent_coef": 0.07583994418382645,
    "learning_rate": 0.001
  },
  {
    "episode": 7559,
    "reward": 89.420009,
    "length": 67,
    "time": 113997.311809,
    "actor_loss": -68.09066009521484,
    "critic_loss": 6.685605525970459,
    "ent_coef": 0.07752538472414017,
    "learning_rate": 0.001
  },
  {
    "episode": 7560,
    "reward": 89.231974,
    "length": 65,
    "time": 114009.083211,
    "actor_loss": -68.02015686035156,
    "critic_loss": 31.32920265197754,
    "ent_coef": 0.07693371921777725,
    "learning_rate": 0.001
  },
  {
    "episode": 7561,
    "reward": 90.384603,
    "length": 63,
    "time": 114020.66879,
    "actor_loss": -65.3729248046875,
    "critic_loss": 20.995330810546875,
    "ent_coef": 0.07612349838018417,
    "learning_rate": 0.001
  },
  {
    "episode": 7562,
    "reward": -176.587566,
    "length": 172,
    "time": 114046.766882,
    "actor_loss": -71.74594116210938,
    "critic_loss": 7.152344703674316,
    "ent_coef": 0.07373987138271332,
    "learning_rate": 0.001
  },
  {
    "episode": 7563,
    "reward": -152.908584,
    "length": 129,
    "time": 114067.624414,
    "actor_loss": -72.17929077148438,
    "critic_loss": 14.104024887084961,
    "ent_coef": 0.08127505332231522,
    "learning_rate": 0.001
  },
  {
    "episode": 7564,
    "reward": 91.339049,
    "length": 65,
    "time": 114080.140286,
    "actor_loss": -69.58549499511719,
    "critic_loss": 8.577926635742188,
    "ent_coef": 0.08609968423843384,
    "learning_rate": 0.001
  },
  {
    "episode": 7565,
    "reward": 91.236555,
    "length": 61,
    "time": 114093.909781,
    "actor_loss": -69.91913604736328,
    "critic_loss": 3.8427934646606445,
    "ent_coef": 0.09125387668609619,
    "learning_rate": 0.001
  },
  {
    "episode": 7566,
    "reward": 90.052941,
    "length": 64,
    "time": 114107.868187,
    "actor_loss": -67.7245101928711,
    "critic_loss": 4.48336124420166,
    "ent_coef": 0.09076061099767685,
    "learning_rate": 0.001
  },
  {
    "episode": 7567,
    "reward": 90.340046,
    "length": 63,
    "time": 114119.162672,
    "actor_loss": -68.64936828613281,
    "critic_loss": 12.60841178894043,
    "ent_coef": 0.08739806711673737,
    "learning_rate": 0.001
  },
  {
    "episode": 7568,
    "reward": 90.418506,
    "length": 63,
    "time": 114130.292044,
    "actor_loss": -66.02458190917969,
    "critic_loss": 46.011634826660156,
    "ent_coef": 0.08545063436031342,
    "learning_rate": 0.001
  },
  {
    "episode": 7569,
    "reward": 87.92426,
    "length": 69,
    "time": 114142.609973,
    "actor_loss": -65.85894775390625,
    "critic_loss": 21.61395263671875,
    "ent_coef": 0.08350572735071182,
    "learning_rate": 0.001
  },
  {
    "episode": 7570,
    "reward": 89.815173,
    "length": 64,
    "time": 114156.052399,
    "actor_loss": -64.40792846679688,
    "critic_loss": 122.44625854492188,
    "ent_coef": 0.08466114103794098,
    "learning_rate": 0.001
  },
  {
    "episode": 7571,
    "reward": 89.605016,
    "length": 68,
    "time": 114169.058707,
    "actor_loss": -58.99913024902344,
    "critic_loss": 4.468542098999023,
    "ent_coef": 0.08583243936300278,
    "learning_rate": 0.001
  },
  {
    "episode": 7572,
    "reward": 90.784362,
    "length": 63,
    "time": 114182.487127,
    "actor_loss": -71.32952880859375,
    "critic_loss": 2.2164766788482666,
    "ent_coef": 0.08635711669921875,
    "learning_rate": 0.001
  },
  {
    "episode": 7573,
    "reward": 90.257622,
    "length": 63,
    "time": 114193.761708,
    "actor_loss": -67.33982849121094,
    "critic_loss": 11.072545051574707,
    "ent_coef": 0.08472076803445816,
    "learning_rate": 0.001
  },
  {
    "episode": 7574,
    "reward": -146.689139,
    "length": 82,
    "time": 114210.475759,
    "actor_loss": -65.7961196899414,
    "critic_loss": 33.03058624267578,
    "ent_coef": 0.0816863402724266,
    "learning_rate": 0.001
  },
  {
    "episode": 7575,
    "reward": 94.834107,
    "length": 66,
    "time": 114225.031686,
    "actor_loss": -70.95172119140625,
    "critic_loss": 62.2174072265625,
    "ent_coef": 0.08148952573537827,
    "learning_rate": 0.001
  },
  {
    "episode": 7576,
    "reward": 90.065632,
    "length": 64,
    "time": 114236.694166,
    "actor_loss": -66.85901641845703,
    "critic_loss": 14.71410083770752,
    "ent_coef": 0.07872018963098526,
    "learning_rate": 0.001
  },
  {
    "episode": 7577,
    "reward": 74.88386,
    "length": 87,
    "time": 114251.026006,
    "actor_loss": -68.32520294189453,
    "critic_loss": 4.754574775695801,
    "ent_coef": 0.072467140853405,
    "learning_rate": 0.001
  },
  {
    "episode": 7578,
    "reward": 86.740056,
    "length": 70,
    "time": 114264.897673,
    "actor_loss": -70.70709228515625,
    "critic_loss": 7.953265190124512,
    "ent_coef": 0.07166391611099243,
    "learning_rate": 0.001
  },
  {
    "episode": 7579,
    "reward": 89.063336,
    "length": 66,
    "time": 114278.934971,
    "actor_loss": -67.5705337524414,
    "critic_loss": 760.85888671875,
    "ent_coef": 0.07000110298395157,
    "learning_rate": 0.001
  },
  {
    "episode": 7580,
    "reward": 89.219288,
    "length": 69,
    "time": 114291.421439,
    "actor_loss": -67.96694946289062,
    "critic_loss": 53.85460662841797,
    "ent_coef": 0.06918928772211075,
    "learning_rate": 0.001
  },
  {
    "episode": 7581,
    "reward": 89.286322,
    "length": 64,
    "time": 114306.204277,
    "actor_loss": -71.43114471435547,
    "critic_loss": 2.2405753135681152,
    "ent_coef": 0.06732954829931259,
    "learning_rate": 0.001
  },
  {
    "episode": 7582,
    "reward": 85.472519,
    "length": 72,
    "time": 114319.617085,
    "actor_loss": -66.78192138671875,
    "critic_loss": 1.7712916135787964,
    "ent_coef": 0.06449034810066223,
    "learning_rate": 0.001
  },
  {
    "episode": 7583,
    "reward": 87.345776,
    "length": 69,
    "time": 114333.561246,
    "actor_loss": -66.45793151855469,
    "critic_loss": 34.27155303955078,
    "ent_coef": 0.06248411908745766,
    "learning_rate": 0.001
  },
  {
    "episode": 7584,
    "reward": 87.700884,
    "length": 68,
    "time": 114348.510878,
    "actor_loss": -75.4800796508789,
    "critic_loss": 31.626873016357422,
    "ent_coef": 0.06175127997994423,
    "learning_rate": 0.001
  },
  {
    "episode": 7585,
    "reward": -161.321327,
    "length": 149,
    "time": 114373.874147,
    "actor_loss": -72.04269409179688,
    "critic_loss": 108.51988220214844,
    "ent_coef": 0.05905119329690933,
    "learning_rate": 0.001
  },
  {
    "episode": 7586,
    "reward": 86.103854,
    "length": 73,
    "time": 114387.311461,
    "actor_loss": -69.05119323730469,
    "critic_loss": 52.034080505371094,
    "ent_coef": 0.05693028122186661,
    "learning_rate": 0.001
  },
  {
    "episode": 7587,
    "reward": 87.762573,
    "length": 70,
    "time": 114399.296389,
    "actor_loss": -64.76074981689453,
    "critic_loss": 3.1189463138580322,
    "ent_coef": 0.05878172442317009,
    "learning_rate": 0.001
  },
  {
    "episode": 7588,
    "reward": -168.250201,
    "length": 175,
    "time": 114424.823825,
    "actor_loss": -67.46969604492188,
    "critic_loss": 2.721538782119751,
    "ent_coef": 0.06793271750211716,
    "learning_rate": 0.001
  },
  {
    "episode": 7589,
    "reward": 91.437842,
    "length": 64,
    "time": 114437.765829,
    "actor_loss": -69.7554702758789,
    "critic_loss": 6.901191711425781,
    "ent_coef": 0.07156911492347717,
    "learning_rate": 0.001
  },
  {
    "episode": 7590,
    "reward": 87.289104,
    "length": 68,
    "time": 114450.789464,
    "actor_loss": -71.99571228027344,
    "critic_loss": 80.6871566772461,
    "ent_coef": 0.0714356005191803,
    "learning_rate": 0.001
  },
  {
    "episode": 7591,
    "reward": 86.952696,
    "length": 70,
    "time": 114464.078358,
    "actor_loss": -65.75142669677734,
    "critic_loss": 21.557863235473633,
    "ent_coef": 0.06914255768060684,
    "learning_rate": 0.001
  },
  {
    "episode": 7592,
    "reward": 88.885533,
    "length": 69,
    "time": 114476.741978,
    "actor_loss": -66.05397033691406,
    "critic_loss": 3.843555450439453,
    "ent_coef": 0.07052479684352875,
    "learning_rate": 0.001
  },
  {
    "episode": 7593,
    "reward": -169.903903,
    "length": 190,
    "time": 114504.501213,
    "actor_loss": -68.24029541015625,
    "critic_loss": 5.052153587341309,
    "ent_coef": 0.07554174959659576,
    "learning_rate": 0.001
  },
  {
    "episode": 7594,
    "reward": 90.051634,
    "length": 64,
    "time": 114516.722653,
    "actor_loss": -63.06686019897461,
    "critic_loss": 19.2015380859375,
    "ent_coef": 0.07677759975194931,
    "learning_rate": 0.001
  },
  {
    "episode": 7595,
    "reward": 90.741872,
    "length": 63,
    "time": 114528.951824,
    "actor_loss": -65.03730773925781,
    "critic_loss": 2.4006357192993164,
    "ent_coef": 0.07926258444786072,
    "learning_rate": 0.001
  },
  {
    "episode": 7596,
    "reward": 90.190854,
    "length": 64,
    "time": 114540.971379,
    "actor_loss": -71.76626586914062,
    "critic_loss": 3.281064987182617,
    "ent_coef": 0.08126626163721085,
    "learning_rate": 0.001
  },
  {
    "episode": 7597,
    "reward": -159.211339,
    "length": 149,
    "time": 114564.266684,
    "actor_loss": -68.10546112060547,
    "critic_loss": 5.310093879699707,
    "ent_coef": 0.0784565657377243,
    "learning_rate": 0.001
  },
  {
    "episode": 7598,
    "reward": 90.05355,
    "length": 69,
    "time": 114576.574911,
    "actor_loss": -68.71809387207031,
    "critic_loss": 3.7950387001037598,
    "ent_coef": 0.07835450023412704,
    "learning_rate": 0.001
  },
  {
    "episode": 7599,
    "reward": 89.982825,
    "length": 63,
    "time": 114587.800007,
    "actor_loss": -70.65635681152344,
    "critic_loss": 11.02595329284668,
    "ent_coef": 0.07917564362287521,
    "learning_rate": 0.001
  },
  {
    "episode": 7600,
    "reward": 88.997007,
    "length": 66,
    "time": 114600.176888,
    "actor_loss": -67.96339416503906,
    "critic_loss": 25.632526397705078,
    "ent_coef": 0.07631860673427582,
    "learning_rate": 0.001
  },
  {
    "episode": 7601,
    "reward": 86.582213,
    "length": 71,
    "time": 114612.797195,
    "actor_loss": -71.74697875976562,
    "critic_loss": 12.490460395812988,
    "ent_coef": 0.07218974083662033,
    "learning_rate": 0.001
  },
  {
    "episode": 7602,
    "reward": 88.210313,
    "length": 67,
    "time": 114627.090641,
    "actor_loss": -71.79328918457031,
    "critic_loss": 25.128740310668945,
    "ent_coef": 0.07065121829509735,
    "learning_rate": 0.001
  },
  {
    "episode": 7603,
    "reward": 89.010555,
    "length": 66,
    "time": 114640.598759,
    "actor_loss": -73.64717102050781,
    "critic_loss": 7.2757368087768555,
    "ent_coef": 0.07037099450826645,
    "learning_rate": 0.001
  },
  {
    "episode": 7604,
    "reward": 89.103072,
    "length": 66,
    "time": 114653.469372,
    "actor_loss": -68.61557006835938,
    "critic_loss": 6.716062068939209,
    "ent_coef": 0.07340247929096222,
    "learning_rate": 0.001
  },
  {
    "episode": 7605,
    "reward": 90.446812,
    "length": 65,
    "time": 114665.272662,
    "actor_loss": -66.72358703613281,
    "critic_loss": 41.410369873046875,
    "ent_coef": 0.0786847323179245,
    "learning_rate": 0.001
  },
  {
    "episode": 7606,
    "reward": 90.518826,
    "length": 63,
    "time": 114677.383131,
    "actor_loss": -68.92620086669922,
    "critic_loss": 85.12800598144531,
    "ent_coef": 0.08248484134674072,
    "learning_rate": 0.001
  },
  {
    "episode": 7607,
    "reward": 86.820225,
    "length": 74,
    "time": 114691.117865,
    "actor_loss": -69.17979431152344,
    "critic_loss": 16.337034225463867,
    "ent_coef": 0.07952550053596497,
    "learning_rate": 0.001
  },
  {
    "episode": 7608,
    "reward": 85.300163,
    "length": 74,
    "time": 114706.014976,
    "actor_loss": -66.25643920898438,
    "critic_loss": 4.6852264404296875,
    "ent_coef": 0.07318156957626343,
    "learning_rate": 0.001
  },
  {
    "episode": 7609,
    "reward": 89.612532,
    "length": 65,
    "time": 114717.44505,
    "actor_loss": -70.6022720336914,
    "critic_loss": 50.7249641418457,
    "ent_coef": 0.07051649689674377,
    "learning_rate": 0.001
  },
  {
    "episode": 7610,
    "reward": -154.724348,
    "length": 140,
    "time": 114738.629189,
    "actor_loss": -72.4002914428711,
    "critic_loss": 2.933309555053711,
    "ent_coef": 0.07161319255828857,
    "learning_rate": 0.001
  },
  {
    "episode": 7611,
    "reward": 90.731208,
    "length": 68,
    "time": 114750.683031,
    "actor_loss": -68.95977783203125,
    "critic_loss": 7.246219635009766,
    "ent_coef": 0.07286854833364487,
    "learning_rate": 0.001
  },
  {
    "episode": 7612,
    "reward": 89.372939,
    "length": 66,
    "time": 114762.340074,
    "actor_loss": -66.147216796875,
    "critic_loss": 6.526534080505371,
    "ent_coef": 0.07280942052602768,
    "learning_rate": 0.001
  },
  {
    "episode": 7613,
    "reward": -159.84467,
    "length": 149,
    "time": 114787.824381,
    "actor_loss": -67.98045349121094,
    "critic_loss": 10.862857818603516,
    "ent_coef": 0.0740320011973381,
    "learning_rate": 0.001
  },
  {
    "episode": 7614,
    "reward": -154.607896,
    "length": 141,
    "time": 114813.630167,
    "actor_loss": -64.73201751708984,
    "critic_loss": 32.76377868652344,
    "ent_coef": 0.08056879788637161,
    "learning_rate": 0.001
  },
  {
    "episode": 7615,
    "reward": 90.177743,
    "length": 71,
    "time": 114828.609902,
    "actor_loss": -72.30269622802734,
    "critic_loss": 21.141094207763672,
    "ent_coef": 0.07922171801328659,
    "learning_rate": 0.001
  },
  {
    "episode": 7616,
    "reward": 89.495292,
    "length": 65,
    "time": 114842.451341,
    "actor_loss": -65.94786834716797,
    "critic_loss": 9.820472717285156,
    "ent_coef": 0.078761026263237,
    "learning_rate": 0.001
  },
  {
    "episode": 7617,
    "reward": 88.456821,
    "length": 68,
    "time": 114855.487964,
    "actor_loss": -71.4044189453125,
    "critic_loss": 5.014771938323975,
    "ent_coef": 0.08282792568206787,
    "learning_rate": 0.001
  },
  {
    "episode": 7618,
    "reward": 86.924708,
    "length": 71,
    "time": 114870.540457,
    "actor_loss": -68.46880340576172,
    "critic_loss": 2.467033624649048,
    "ent_coef": 0.08172614127397537,
    "learning_rate": 0.001
  },
  {
    "episode": 7619,
    "reward": 87.639061,
    "length": 70,
    "time": 114884.006043,
    "actor_loss": -71.07048034667969,
    "critic_loss": 102.4059066772461,
    "ent_coef": 0.08249933272600174,
    "learning_rate": 0.001
  },
  {
    "episode": 7620,
    "reward": 85.880607,
    "length": 73,
    "time": 114899.43359,
    "actor_loss": -74.43338012695312,
    "critic_loss": 19.352237701416016,
    "ent_coef": 0.0790473222732544,
    "learning_rate": 0.001
  },
  {
    "episode": 7621,
    "reward": -157.022045,
    "length": 144,
    "time": 114922.712706,
    "actor_loss": -63.721580505371094,
    "critic_loss": 10.950766563415527,
    "ent_coef": 0.08029551059007645,
    "learning_rate": 0.001
  },
  {
    "episode": 7622,
    "reward": 85.851468,
    "length": 70,
    "time": 114936.345401,
    "actor_loss": -73.10140991210938,
    "critic_loss": 2.982954502105713,
    "ent_coef": 0.08522982895374298,
    "learning_rate": 0.001
  },
  {
    "episode": 7623,
    "reward": 90.144356,
    "length": 63,
    "time": 114951.01239,
    "actor_loss": -68.23507690429688,
    "critic_loss": 12.606317520141602,
    "ent_coef": 0.08542877435684204,
    "learning_rate": 0.001
  },
  {
    "episode": 7624,
    "reward": 89.040189,
    "length": 66,
    "time": 114962.683305,
    "actor_loss": -72.01287841796875,
    "critic_loss": 11.958463668823242,
    "ent_coef": 0.08371944725513458,
    "learning_rate": 0.001
  },
  {
    "episode": 7625,
    "reward": 89.032711,
    "length": 66,
    "time": 114975.39981,
    "actor_loss": -63.8631706237793,
    "critic_loss": 93.15067291259766,
    "ent_coef": 0.08257121592760086,
    "learning_rate": 0.001
  },
  {
    "episode": 7626,
    "reward": -156.130476,
    "length": 143,
    "time": 114996.985421,
    "actor_loss": -69.3904800415039,
    "critic_loss": 5.101666450500488,
    "ent_coef": 0.0777890533208847,
    "learning_rate": 0.001
  },
  {
    "episode": 7627,
    "reward": 86.652359,
    "length": 72,
    "time": 115010.240263,
    "actor_loss": -69.73897552490234,
    "critic_loss": 34.48430633544922,
    "ent_coef": 0.07559626549482346,
    "learning_rate": 0.001
  },
  {
    "episode": 7628,
    "reward": 87.199521,
    "length": 69,
    "time": 115023.472274,
    "actor_loss": -67.05860900878906,
    "critic_loss": 26.572265625,
    "ent_coef": 0.07477627694606781,
    "learning_rate": 0.001
  },
  {
    "episode": 7629,
    "reward": 89.333777,
    "length": 65,
    "time": 115035.824957,
    "actor_loss": -70.33934783935547,
    "critic_loss": 10.308087348937988,
    "ent_coef": 0.07902863621711731,
    "learning_rate": 0.001
  },
  {
    "episode": 7630,
    "reward": 90.880166,
    "length": 62,
    "time": 115047.033974,
    "actor_loss": -62.54368591308594,
    "critic_loss": 4.688459396362305,
    "ent_coef": 0.0853862538933754,
    "learning_rate": 0.001
  },
  {
    "episode": 7631,
    "reward": 90.635882,
    "length": 62,
    "time": 115059.185238,
    "actor_loss": -74.08517456054688,
    "critic_loss": 5.973172187805176,
    "ent_coef": 0.09004810452461243,
    "learning_rate": 0.001
  },
  {
    "episode": 7632,
    "reward": 88.255159,
    "length": 70,
    "time": 115072.852684,
    "actor_loss": -71.36027526855469,
    "critic_loss": 26.265525817871094,
    "ent_coef": 0.09321766346693039,
    "learning_rate": 0.001
  },
  {
    "episode": 7633,
    "reward": 86.47261,
    "length": 72,
    "time": 115085.148218,
    "actor_loss": -66.79150390625,
    "critic_loss": 2.5735015869140625,
    "ent_coef": 0.08865495026111603,
    "learning_rate": 0.001
  },
  {
    "episode": 7634,
    "reward": 84.757304,
    "length": 76,
    "time": 115099.371429,
    "actor_loss": -72.45946502685547,
    "critic_loss": 31.87295913696289,
    "ent_coef": 0.08407852798700333,
    "learning_rate": 0.001
  },
  {
    "episode": 7635,
    "reward": 86.487322,
    "length": 74,
    "time": 115113.699992,
    "actor_loss": -67.45658874511719,
    "critic_loss": 4.995265007019043,
    "ent_coef": 0.08226720988750458,
    "learning_rate": 0.001
  },
  {
    "episode": 7636,
    "reward": 87.575176,
    "length": 72,
    "time": 115126.060694,
    "actor_loss": -70.30670166015625,
    "critic_loss": 11.552022933959961,
    "ent_coef": 0.0860373005270958,
    "learning_rate": 0.001
  },
  {
    "episode": 7637,
    "reward": 87.546186,
    "length": 69,
    "time": 115138.72425,
    "actor_loss": -66.35624694824219,
    "critic_loss": 6.516071319580078,
    "ent_coef": 0.08282968401908875,
    "learning_rate": 0.001
  },
  {
    "episode": 7638,
    "reward": 81.297391,
    "length": 80,
    "time": 115153.192881,
    "actor_loss": -67.6099853515625,
    "critic_loss": 2.5049726963043213,
    "ent_coef": 0.0745541900396347,
    "learning_rate": 0.001
  },
  {
    "episode": 7639,
    "reward": 85.116505,
    "length": 75,
    "time": 115166.182846,
    "actor_loss": -73.48561096191406,
    "critic_loss": 7.162197589874268,
    "ent_coef": 0.07114899158477783,
    "learning_rate": 0.001
  },
  {
    "episode": 7640,
    "reward": 90.547504,
    "length": 63,
    "time": 115177.511795,
    "actor_loss": -71.97332763671875,
    "critic_loss": 22.963382720947266,
    "ent_coef": 0.06805099546909332,
    "learning_rate": 0.001
  },
  {
    "episode": 7641,
    "reward": 84.380426,
    "length": 73,
    "time": 115191.582027,
    "actor_loss": -63.90581130981445,
    "critic_loss": 27.605043411254883,
    "ent_coef": 0.06530161201953888,
    "learning_rate": 0.001
  },
  {
    "episode": 7642,
    "reward": 87.630895,
    "length": 68,
    "time": 115203.569655,
    "actor_loss": -68.07878875732422,
    "critic_loss": 17.02197265625,
    "ent_coef": 0.06515931338071823,
    "learning_rate": 0.001
  },
  {
    "episode": 7643,
    "reward": 87.875816,
    "length": 72,
    "time": 115216.030852,
    "actor_loss": -67.91989135742188,
    "critic_loss": 3.179953098297119,
    "ent_coef": 0.06358633190393448,
    "learning_rate": 0.001
  },
  {
    "episode": 7644,
    "reward": 85.422044,
    "length": 75,
    "time": 115229.417594,
    "actor_loss": -68.28069305419922,
    "critic_loss": 17.691852569580078,
    "ent_coef": 0.060800641775131226,
    "learning_rate": 0.001
  },
  {
    "episode": 7645,
    "reward": 84.789417,
    "length": 77,
    "time": 115243.748943,
    "actor_loss": -60.9659423828125,
    "critic_loss": 4.393381118774414,
    "ent_coef": 0.05941936373710632,
    "learning_rate": 0.001
  },
  {
    "episode": 7646,
    "reward": 89.514126,
    "length": 66,
    "time": 115259.538817,
    "actor_loss": -67.90794372558594,
    "critic_loss": 4.620125770568848,
    "ent_coef": 0.06301559507846832,
    "learning_rate": 0.001
  },
  {
    "episode": 7647,
    "reward": 88.270272,
    "length": 69,
    "time": 115272.364151,
    "actor_loss": -67.60513305664062,
    "critic_loss": 7.950010299682617,
    "ent_coef": 0.06664350628852844,
    "learning_rate": 0.001
  },
  {
    "episode": 7648,
    "reward": 87.107744,
    "length": 73,
    "time": 115287.894609,
    "actor_loss": -69.84644317626953,
    "critic_loss": 34.76091766357422,
    "ent_coef": 0.06949391216039658,
    "learning_rate": 0.001
  },
  {
    "episode": 7649,
    "reward": 84.138143,
    "length": 76,
    "time": 115302.126511,
    "actor_loss": -68.44364166259766,
    "critic_loss": 2.733666181564331,
    "ent_coef": 0.07037948817014694,
    "learning_rate": 0.001
  },
  {
    "episode": 7650,
    "reward": 83.251516,
    "length": 77,
    "time": 115315.23633,
    "actor_loss": -67.295166015625,
    "critic_loss": 2.079268455505371,
    "ent_coef": 0.06460642069578171,
    "learning_rate": 0.001
  },
  {
    "episode": 7651,
    "reward": 86.560182,
    "length": 75,
    "time": 115330.513367,
    "actor_loss": -65.92466735839844,
    "critic_loss": 5.409579277038574,
    "ent_coef": 0.06096549332141876,
    "learning_rate": 0.001
  },
  {
    "episode": 7652,
    "reward": 87.449582,
    "length": 75,
    "time": 115343.148415,
    "actor_loss": -66.22049713134766,
    "critic_loss": 4.2769389152526855,
    "ent_coef": 0.06727627664804459,
    "learning_rate": 0.001
  },
  {
    "episode": 7653,
    "reward": 90.778429,
    "length": 63,
    "time": 115355.704957,
    "actor_loss": -65.05377960205078,
    "critic_loss": 5.53861141204834,
    "ent_coef": 0.0697454959154129,
    "learning_rate": 0.001
  },
  {
    "episode": 7654,
    "reward": 86.519978,
    "length": 75,
    "time": 115368.524905,
    "actor_loss": -63.568153381347656,
    "critic_loss": 28.903736114501953,
    "ent_coef": 0.06549408286809921,
    "learning_rate": 0.001
  },
  {
    "episode": 7655,
    "reward": 80.258944,
    "length": 85,
    "time": 115385.269871,
    "actor_loss": -73.6418685913086,
    "critic_loss": 4.658829212188721,
    "ent_coef": 0.06209574639797211,
    "learning_rate": 0.001
  },
  {
    "episode": 7656,
    "reward": 83.570585,
    "length": 77,
    "time": 115399.460769,
    "actor_loss": -64.47451782226562,
    "critic_loss": 4.094346046447754,
    "ent_coef": 0.05834308639168739,
    "learning_rate": 0.001
  },
  {
    "episode": 7657,
    "reward": 82.427428,
    "length": 79,
    "time": 115413.370623,
    "actor_loss": -72.87381744384766,
    "critic_loss": 3.1006789207458496,
    "ent_coef": 0.0567626953125,
    "learning_rate": 0.001
  },
  {
    "episode": 7658,
    "reward": 83.363736,
    "length": 80,
    "time": 115426.675637,
    "actor_loss": -67.0667724609375,
    "critic_loss": 2.901545286178589,
    "ent_coef": 0.05788606032729149,
    "learning_rate": 0.001
  },
  {
    "episode": 7659,
    "reward": 87.244595,
    "length": 73,
    "time": 115440.572786,
    "actor_loss": -67.30741882324219,
    "critic_loss": 6.177491188049316,
    "ent_coef": 0.06208008527755737,
    "learning_rate": 0.001
  },
  {
    "episode": 7660,
    "reward": 86.278603,
    "length": 73,
    "time": 115453.770516,
    "actor_loss": -69.71786499023438,
    "critic_loss": 3.345374584197998,
    "ent_coef": 0.06198021396994591,
    "learning_rate": 0.001
  },
  {
    "episode": 7661,
    "reward": 83.489052,
    "length": 80,
    "time": 115468.176644,
    "actor_loss": -72.99260711669922,
    "critic_loss": 4.326940059661865,
    "ent_coef": 0.06320773810148239,
    "learning_rate": 0.001
  },
  {
    "episode": 7662,
    "reward": 82.323464,
    "length": 87,
    "time": 115484.052875,
    "actor_loss": -67.7557373046875,
    "critic_loss": 17.30886459350586,
    "ent_coef": 0.06473469734191895,
    "learning_rate": 0.001
  },
  {
    "episode": 7663,
    "reward": 87.312972,
    "length": 71,
    "time": 115497.731061,
    "actor_loss": -68.04407501220703,
    "critic_loss": 8.055757522583008,
    "ent_coef": 0.06715942919254303,
    "learning_rate": 0.001
  },
  {
    "episode": 7664,
    "reward": 87.00816,
    "length": 69,
    "time": 115512.428665,
    "actor_loss": -66.86073303222656,
    "critic_loss": 21.64181137084961,
    "ent_coef": 0.06683707982301712,
    "learning_rate": 0.001
  },
  {
    "episode": 7665,
    "reward": 85.044605,
    "length": 73,
    "time": 115524.91532,
    "actor_loss": -69.20399475097656,
    "critic_loss": 8.994012832641602,
    "ent_coef": 0.06814587861299515,
    "learning_rate": 0.001
  },
  {
    "episode": 7666,
    "reward": 78.830609,
    "length": 82,
    "time": 115539.244378,
    "actor_loss": -75.85226440429688,
    "critic_loss": 2.1782429218292236,
    "ent_coef": 0.06634900718927383,
    "learning_rate": 0.001
  },
  {
    "episode": 7667,
    "reward": 79.459468,
    "length": 88,
    "time": 115553.788405,
    "actor_loss": -69.43910217285156,
    "critic_loss": 67.68511962890625,
    "ent_coef": 0.0638456866145134,
    "learning_rate": 0.001
  },
  {
    "episode": 7668,
    "reward": 81.52792,
    "length": 82,
    "time": 115568.085869,
    "actor_loss": -72.41975402832031,
    "critic_loss": 7.033497333526611,
    "ent_coef": 0.06563705205917358,
    "learning_rate": 0.001
  },
  {
    "episode": 7669,
    "reward": 83.346666,
    "length": 78,
    "time": 115586.993693,
    "actor_loss": -75.34699249267578,
    "critic_loss": 46.592689514160156,
    "ent_coef": 0.06470400094985962,
    "learning_rate": 0.001
  },
  {
    "episode": 7670,
    "reward": 85.959965,
    "length": 72,
    "time": 115599.626092,
    "actor_loss": -68.36064147949219,
    "critic_loss": 6.16779899597168,
    "ent_coef": 0.06477710604667664,
    "learning_rate": 0.001
  },
  {
    "episode": 7671,
    "reward": 83.248679,
    "length": 80,
    "time": 115614.482094,
    "actor_loss": -72.54080200195312,
    "critic_loss": 32.57855987548828,
    "ent_coef": 0.06361564993858337,
    "learning_rate": 0.001
  },
  {
    "episode": 7672,
    "reward": 87.792517,
    "length": 68,
    "time": 115627.494244,
    "actor_loss": -65.88888549804688,
    "critic_loss": 5.095691680908203,
    "ent_coef": 0.06560979783535004,
    "learning_rate": 0.001
  },
  {
    "episode": 7673,
    "reward": 85.863938,
    "length": 78,
    "time": 115642.030969,
    "actor_loss": -72.78239440917969,
    "critic_loss": 6.526437759399414,
    "ent_coef": 0.06593155115842819,
    "learning_rate": 0.001
  },
  {
    "episode": 7674,
    "reward": 84.768196,
    "length": 75,
    "time": 115655.995656,
    "actor_loss": -67.87484741210938,
    "critic_loss": 14.924999237060547,
    "ent_coef": 0.06513459980487823,
    "learning_rate": 0.001
  },
  {
    "episode": 7675,
    "reward": 86.01753,
    "length": 70,
    "time": 115672.070411,
    "actor_loss": -68.28079223632812,
    "critic_loss": 28.6873779296875,
    "ent_coef": 0.06385841220617294,
    "learning_rate": 0.001
  },
  {
    "episode": 7676,
    "reward": 87.064779,
    "length": 69,
    "time": 115684.017463,
    "actor_loss": -72.74441528320312,
    "critic_loss": 14.653985977172852,
    "ent_coef": 0.06179232895374298,
    "learning_rate": 0.001
  },
  {
    "episode": 7677,
    "reward": 84.49396,
    "length": 74,
    "time": 115698.968716,
    "actor_loss": -67.71834564208984,
    "critic_loss": 6.977400779724121,
    "ent_coef": 0.05919251590967178,
    "learning_rate": 0.001
  },
  {
    "episode": 7678,
    "reward": 88.018555,
    "length": 68,
    "time": 115713.209003,
    "actor_loss": -67.87593078613281,
    "critic_loss": 31.589061737060547,
    "ent_coef": 0.05743880569934845,
    "learning_rate": 0.001
  },
  {
    "episode": 7679,
    "reward": 84.126853,
    "length": 77,
    "time": 115729.383113,
    "actor_loss": -65.64047241210938,
    "critic_loss": 127.15708923339844,
    "ent_coef": 0.05580926686525345,
    "learning_rate": 0.001
  },
  {
    "episode": 7680,
    "reward": 80.683286,
    "length": 84,
    "time": 115745.449486,
    "actor_loss": -61.68905258178711,
    "critic_loss": 7.490120887756348,
    "ent_coef": 0.05721960589289665,
    "learning_rate": 0.001
  },
  {
    "episode": 7681,
    "reward": 82.965985,
    "length": 81,
    "time": 115759.367507,
    "actor_loss": -66.12998962402344,
    "critic_loss": 20.087759017944336,
    "ent_coef": 0.056906912475824356,
    "learning_rate": 0.001
  },
  {
    "episode": 7682,
    "reward": 72.812917,
    "length": 100,
    "time": 115776.487132,
    "actor_loss": -68.30548095703125,
    "critic_loss": 2.0177817344665527,
    "ent_coef": 0.054398491978645325,
    "learning_rate": 0.001
  },
  {
    "episode": 7683,
    "reward": 83.118193,
    "length": 75,
    "time": 115790.600142,
    "actor_loss": -69.97893524169922,
    "critic_loss": 2.7177038192749023,
    "ent_coef": 0.054486263543367386,
    "learning_rate": 0.001
  },
  {
    "episode": 7684,
    "reward": 83.151277,
    "length": 78,
    "time": 115803.660763,
    "actor_loss": -67.4443359375,
    "critic_loss": 10.518159866333008,
    "ent_coef": 0.0558001808822155,
    "learning_rate": 0.001
  },
  {
    "episode": 7685,
    "reward": 85.526798,
    "length": 73,
    "time": 115817.257963,
    "actor_loss": -66.89695739746094,
    "critic_loss": 3.36187744140625,
    "ent_coef": 0.05941539630293846,
    "learning_rate": 0.001
  },
  {
    "episode": 7686,
    "reward": 86.315418,
    "length": 73,
    "time": 115830.95329,
    "actor_loss": -68.59590148925781,
    "critic_loss": 3.1354565620422363,
    "ent_coef": 0.061578575521707535,
    "learning_rate": 0.001
  },
  {
    "episode": 7687,
    "reward": 88.409721,
    "length": 69,
    "time": 115845.593778,
    "actor_loss": -65.46261596679688,
    "critic_loss": 1.8657406568527222,
    "ent_coef": 0.063307024538517,
    "learning_rate": 0.001
  },
  {
    "episode": 7688,
    "reward": 85.84846,
    "length": 75,
    "time": 115861.2683,
    "actor_loss": -74.03301239013672,
    "critic_loss": 15.123617172241211,
    "ent_coef": 0.06520898640155792,
    "learning_rate": 0.001
  },
  {
    "episode": 7689,
    "reward": 88.74355,
    "length": 66,
    "time": 115875.095023,
    "actor_loss": -66.8331298828125,
    "critic_loss": 3.1763110160827637,
    "ent_coef": 0.06622651219367981,
    "learning_rate": 0.001
  },
  {
    "episode": 7690,
    "reward": 86.072504,
    "length": 73,
    "time": 115889.033101,
    "actor_loss": -70.94772338867188,
    "critic_loss": 13.772510528564453,
    "ent_coef": 0.06505419313907623,
    "learning_rate": 0.001
  },
  {
    "episode": 7691,
    "reward": 84.301763,
    "length": 74,
    "time": 115901.942394,
    "actor_loss": -71.0156478881836,
    "critic_loss": 18.49048614501953,
    "ent_coef": 0.06309133768081665,
    "learning_rate": 0.001
  },
  {
    "episode": 7692,
    "reward": 86.301988,
    "length": 74,
    "time": 115915.031929,
    "actor_loss": -67.2499771118164,
    "critic_loss": 3.0205485820770264,
    "ent_coef": 0.060834065079689026,
    "learning_rate": 0.001
  },
  {
    "episode": 7693,
    "reward": 87.87682,
    "length": 68,
    "time": 115927.642881,
    "actor_loss": -71.61239624023438,
    "critic_loss": 11.369303703308105,
    "ent_coef": 0.057437434792518616,
    "learning_rate": 0.001
  },
  {
    "episode": 7694,
    "reward": 86.499284,
    "length": 72,
    "time": 115940.555779,
    "actor_loss": -70.96322631835938,
    "critic_loss": 12.492337226867676,
    "ent_coef": 0.05272586643695831,
    "learning_rate": 0.001
  },
  {
    "episode": 7695,
    "reward": 89.501386,
    "length": 65,
    "time": 115952.057945,
    "actor_loss": -61.9373779296875,
    "critic_loss": 114.37555694580078,
    "ent_coef": 0.052415840327739716,
    "learning_rate": 0.001
  },
  {
    "episode": 7696,
    "reward": 92.036592,
    "length": 61,
    "time": 115964.60137,
    "actor_loss": -66.52110290527344,
    "critic_loss": 5.826478004455566,
    "ent_coef": 0.05450305715203285,
    "learning_rate": 0.001
  },
  {
    "episode": 7697,
    "reward": 86.751552,
    "length": 74,
    "time": 115979.319045,
    "actor_loss": -63.95044708251953,
    "critic_loss": 3.8795814514160156,
    "ent_coef": 0.058095261454582214,
    "learning_rate": 0.001
  },
  {
    "episode": 7698,
    "reward": 91.089368,
    "length": 64,
    "time": 115991.87113,
    "actor_loss": -69.89263153076172,
    "critic_loss": 5.415670871734619,
    "ent_coef": 0.061677444726228714,
    "learning_rate": 0.001
  },
  {
    "episode": 7699,
    "reward": 88.255996,
    "length": 71,
    "time": 116004.910452,
    "actor_loss": -73.04533386230469,
    "critic_loss": 17.220401763916016,
    "ent_coef": 0.061908572912216187,
    "learning_rate": 0.001
  },
  {
    "episode": 7700,
    "reward": 89.088823,
    "length": 66,
    "time": 116017.3751,
    "actor_loss": -67.63371276855469,
    "critic_loss": 83.62885284423828,
    "ent_coef": 0.0639708861708641,
    "learning_rate": 0.001
  },
  {
    "episode": 7701,
    "reward": 88.496786,
    "length": 68,
    "time": 116029.659782,
    "actor_loss": -68.72167205810547,
    "critic_loss": 10.069852828979492,
    "ent_coef": 0.06303712725639343,
    "learning_rate": 0.001
  },
  {
    "episode": 7702,
    "reward": 88.168596,
    "length": 68,
    "time": 116042.568935,
    "actor_loss": -74.64083099365234,
    "critic_loss": 11.15860366821289,
    "ent_coef": 0.06073464825749397,
    "learning_rate": 0.001
  },
  {
    "episode": 7703,
    "reward": 82.942708,
    "length": 80,
    "time": 116060.000449,
    "actor_loss": -69.46110534667969,
    "critic_loss": 52.20597839355469,
    "ent_coef": 0.060435619205236435,
    "learning_rate": 0.001
  },
  {
    "episode": 7704,
    "reward": 85.053083,
    "length": 74,
    "time": 116072.673546,
    "actor_loss": -70.23057556152344,
    "critic_loss": 3.3565330505371094,
    "ent_coef": 0.06324444711208344,
    "learning_rate": 0.001
  },
  {
    "episode": 7705,
    "reward": 78.665855,
    "length": 85,
    "time": 116088.737144,
    "actor_loss": -67.83721923828125,
    "critic_loss": 57.42716979980469,
    "ent_coef": 0.062386006116867065,
    "learning_rate": 0.001
  },
  {
    "episode": 7706,
    "reward": 71.945043,
    "length": 101,
    "time": 116107.438933,
    "actor_loss": -73.03982543945312,
    "critic_loss": 4.4714765548706055,
    "ent_coef": 0.061159662902355194,
    "learning_rate": 0.001
  },
  {
    "episode": 7707,
    "reward": 84.011304,
    "length": 77,
    "time": 116120.720989,
    "actor_loss": -74.00167846679688,
    "critic_loss": 6.1575188636779785,
    "ent_coef": 0.06388433277606964,
    "learning_rate": 0.001
  },
  {
    "episode": 7708,
    "reward": 83.313685,
    "length": 81,
    "time": 116134.686751,
    "actor_loss": -69.51248931884766,
    "critic_loss": 15.129043579101562,
    "ent_coef": 0.06516383588314056,
    "learning_rate": 0.001
  },
  {
    "episode": 7709,
    "reward": 86.662093,
    "length": 70,
    "time": 116146.984903,
    "actor_loss": -70.37126922607422,
    "critic_loss": 50.119842529296875,
    "ent_coef": 0.06581704318523407,
    "learning_rate": 0.001
  },
  {
    "episode": 7710,
    "reward": 85.860498,
    "length": 72,
    "time": 116162.055998,
    "actor_loss": -71.48235321044922,
    "critic_loss": 5.745903015136719,
    "ent_coef": 0.06811584532260895,
    "learning_rate": 0.001
  },
  {
    "episode": 7711,
    "reward": 85.55599,
    "length": 72,
    "time": 116175.618916,
    "actor_loss": -76.35243225097656,
    "critic_loss": 1.8046684265136719,
    "ent_coef": 0.06954037398099899,
    "learning_rate": 0.001
  },
  {
    "episode": 7712,
    "reward": 89.349469,
    "length": 66,
    "time": 116192.238686,
    "actor_loss": -64.88162231445312,
    "critic_loss": 2.398743152618408,
    "ent_coef": 0.06934729218482971,
    "learning_rate": 0.001
  },
  {
    "episode": 7713,
    "reward": 85.798816,
    "length": 73,
    "time": 116204.734054,
    "actor_loss": -71.54065704345703,
    "critic_loss": 6.318173885345459,
    "ent_coef": 0.06854767352342606,
    "learning_rate": 0.001
  },
  {
    "episode": 7714,
    "reward": 87.412972,
    "length": 69,
    "time": 116216.747473,
    "actor_loss": -66.0453872680664,
    "critic_loss": 4.821887969970703,
    "ent_coef": 0.06531399488449097,
    "learning_rate": 0.001
  },
  {
    "episode": 7715,
    "reward": 89.861974,
    "length": 65,
    "time": 116229.20972,
    "actor_loss": -69.42173767089844,
    "critic_loss": 11.081475257873535,
    "ent_coef": 0.06228304281830788,
    "learning_rate": 0.001
  },
  {
    "episode": 7716,
    "reward": 87.148066,
    "length": 68,
    "time": 116242.927558,
    "actor_loss": -65.91381072998047,
    "critic_loss": 3.1513631343841553,
    "ent_coef": 0.06426967680454254,
    "learning_rate": 0.001
  },
  {
    "episode": 7717,
    "reward": 84.587875,
    "length": 76,
    "time": 116255.969801,
    "actor_loss": -66.08375549316406,
    "critic_loss": 12.493300437927246,
    "ent_coef": 0.06176561117172241,
    "learning_rate": 0.001
  },
  {
    "episode": 7718,
    "reward": 92.032449,
    "length": 59,
    "time": 116266.879627,
    "actor_loss": -59.663475036621094,
    "critic_loss": 8.259766578674316,
    "ent_coef": 0.0646698996424675,
    "learning_rate": 0.001
  },
  {
    "episode": 7719,
    "reward": 79.997147,
    "length": 87,
    "time": 116285.893161,
    "actor_loss": -70.17469787597656,
    "critic_loss": 2.447939395904541,
    "ent_coef": 0.06259974092245102,
    "learning_rate": 0.001
  },
  {
    "episode": 7720,
    "reward": 85.091479,
    "length": 74,
    "time": 116299.211152,
    "actor_loss": -72.85560607910156,
    "critic_loss": 4.168932914733887,
    "ent_coef": 0.06442885100841522,
    "learning_rate": 0.001
  },
  {
    "episode": 7721,
    "reward": 88.644159,
    "length": 68,
    "time": 116311.601852,
    "actor_loss": -66.8248062133789,
    "critic_loss": 4.359969139099121,
    "ent_coef": 0.0687485933303833,
    "learning_rate": 0.001
  },
  {
    "episode": 7722,
    "reward": 87.079581,
    "length": 72,
    "time": 116329.316119,
    "actor_loss": -66.64529418945312,
    "critic_loss": 22.17206573486328,
    "ent_coef": 0.06779589504003525,
    "learning_rate": 0.001
  },
  {
    "episode": 7723,
    "reward": 84.917613,
    "length": 74,
    "time": 116343.937635,
    "actor_loss": -68.14091491699219,
    "critic_loss": 2.821920394897461,
    "ent_coef": 0.06509827077388763,
    "learning_rate": 0.001
  },
  {
    "episode": 7724,
    "reward": 81.964601,
    "length": 78,
    "time": 116359.733374,
    "actor_loss": -68.64385986328125,
    "critic_loss": 4.737494468688965,
    "ent_coef": 0.060630377382040024,
    "learning_rate": 0.001
  },
  {
    "episode": 7725,
    "reward": 75.506742,
    "length": 88,
    "time": 116377.230461,
    "actor_loss": -72.27139282226562,
    "critic_loss": 12.22895622253418,
    "ent_coef": 0.05789082497358322,
    "learning_rate": 0.001
  },
  {
    "episode": 7726,
    "reward": 86.8753,
    "length": 70,
    "time": 116390.442422,
    "actor_loss": -64.99114990234375,
    "critic_loss": 6.05598258972168,
    "ent_coef": 0.055843938142061234,
    "learning_rate": 0.001
  },
  {
    "episode": 7727,
    "reward": 82.888744,
    "length": 74,
    "time": 116405.635433,
    "actor_loss": -70.80180358886719,
    "critic_loss": 5.354585647583008,
    "ent_coef": 0.0543203130364418,
    "learning_rate": 0.001
  },
  {
    "episode": 7728,
    "reward": 89.874094,
    "length": 65,
    "time": 116417.435877,
    "actor_loss": -67.86698913574219,
    "critic_loss": 8.328444480895996,
    "ent_coef": 0.05634957179427147,
    "learning_rate": 0.001
  },
  {
    "episode": 7729,
    "reward": 77.994421,
    "length": 87,
    "time": 116435.790763,
    "actor_loss": -65.2186279296875,
    "critic_loss": 6.3877997398376465,
    "ent_coef": 0.05234210193157196,
    "learning_rate": 0.001
  },
  {
    "episode": 7730,
    "reward": 81.740919,
    "length": 78,
    "time": 116452.62128,
    "actor_loss": -69.46151733398438,
    "critic_loss": 3.7273154258728027,
    "ent_coef": 0.052129559218883514,
    "learning_rate": 0.001
  },
  {
    "episode": 7731,
    "reward": 90.245604,
    "length": 64,
    "time": 116464.378385,
    "actor_loss": -64.91390991210938,
    "critic_loss": 4.990981101989746,
    "ent_coef": 0.054244715720415115,
    "learning_rate": 0.001
  },
  {
    "episode": 7732,
    "reward": 87.924025,
    "length": 69,
    "time": 116476.977094,
    "actor_loss": -70.69486999511719,
    "critic_loss": 25.109344482421875,
    "ent_coef": 0.05248091742396355,
    "learning_rate": 0.001
  },
  {
    "episode": 7733,
    "reward": 88.191476,
    "length": 70,
    "time": 116490.308685,
    "actor_loss": -63.30866241455078,
    "critic_loss": 5.0527024269104,
    "ent_coef": 0.05275547876954079,
    "learning_rate": 0.001
  },
  {
    "episode": 7734,
    "reward": 87.743897,
    "length": 71,
    "time": 116502.823722,
    "actor_loss": -73.25819396972656,
    "critic_loss": 1.748405933380127,
    "ent_coef": 0.05437995865941048,
    "learning_rate": 0.001
  },
  {
    "episode": 7735,
    "reward": 88.839349,
    "length": 69,
    "time": 116514.988062,
    "actor_loss": -67.36336517333984,
    "critic_loss": 42.116416931152344,
    "ent_coef": 0.05348779261112213,
    "learning_rate": 0.001
  },
  {
    "episode": 7736,
    "reward": 85.983614,
    "length": 73,
    "time": 116530.064533,
    "actor_loss": -69.22339630126953,
    "critic_loss": 3.079277992248535,
    "ent_coef": 0.054036062210798264,
    "learning_rate": 0.001
  },
  {
    "episode": 7737,
    "reward": 71.960552,
    "length": 105,
    "time": 116547.415061,
    "actor_loss": -67.27738189697266,
    "critic_loss": 18.828649520874023,
    "ent_coef": 0.05319589748978615,
    "learning_rate": 0.001
  },
  {
    "episode": 7738,
    "reward": 87.459016,
    "length": 72,
    "time": 116559.924515,
    "actor_loss": -72.85282135009766,
    "critic_loss": 6.410435676574707,
    "ent_coef": 0.0560382641851902,
    "learning_rate": 0.001
  },
  {
    "episode": 7739,
    "reward": 90.445065,
    "length": 65,
    "time": 116571.706116,
    "actor_loss": -67.42212677001953,
    "critic_loss": 59.249820709228516,
    "ent_coef": 0.055159129202365875,
    "learning_rate": 0.001
  },
  {
    "episode": 7740,
    "reward": 85.57455,
    "length": 74,
    "time": 116584.585815,
    "actor_loss": -65.52277374267578,
    "critic_loss": 23.308795928955078,
    "ent_coef": 0.05098029971122742,
    "learning_rate": 0.001
  },
  {
    "episode": 7741,
    "reward": 90.745297,
    "length": 63,
    "time": 116597.88892,
    "actor_loss": -66.62185668945312,
    "critic_loss": 7.652411937713623,
    "ent_coef": 0.05078897252678871,
    "learning_rate": 0.001
  },
  {
    "episode": 7742,
    "reward": 89.451173,
    "length": 67,
    "time": 116610.562876,
    "actor_loss": -70.1340560913086,
    "critic_loss": 38.45417022705078,
    "ent_coef": 0.05090135708451271,
    "learning_rate": 0.001
  },
  {
    "episode": 7743,
    "reward": 89.329871,
    "length": 65,
    "time": 116623.854845,
    "actor_loss": -65.1734848022461,
    "critic_loss": 10.2899808883667,
    "ent_coef": 0.05351370945572853,
    "learning_rate": 0.001
  },
  {
    "episode": 7744,
    "reward": 89.46357,
    "length": 66,
    "time": 116635.730199,
    "actor_loss": -71.5020751953125,
    "critic_loss": 24.88137435913086,
    "ent_coef": 0.057848379015922546,
    "learning_rate": 0.001
  },
  {
    "episode": 7745,
    "reward": 89.614678,
    "length": 68,
    "time": 116649.261075,
    "actor_loss": -67.99815368652344,
    "critic_loss": 12.41153335571289,
    "ent_coef": 0.0588340237736702,
    "learning_rate": 0.001
  },
  {
    "episode": 7746,
    "reward": 88.129005,
    "length": 70,
    "time": 116664.03089,
    "actor_loss": -65.46485137939453,
    "critic_loss": 187.56402587890625,
    "ent_coef": 0.060540664941072464,
    "learning_rate": 0.001
  },
  {
    "episode": 7747,
    "reward": 91.255712,
    "length": 61,
    "time": 116678.480065,
    "actor_loss": -67.22848510742188,
    "critic_loss": 15.331905364990234,
    "ent_coef": 0.061829183250665665,
    "learning_rate": 0.001
  },
  {
    "episode": 7748,
    "reward": 90.312418,
    "length": 67,
    "time": 116690.283338,
    "actor_loss": -76.12186431884766,
    "critic_loss": 2.8188462257385254,
    "ent_coef": 0.0653337761759758,
    "learning_rate": 0.001
  },
  {
    "episode": 7749,
    "reward": 90.528902,
    "length": 65,
    "time": 116702.611276,
    "actor_loss": -69.23238372802734,
    "critic_loss": 51.377601623535156,
    "ent_coef": 0.06717574596405029,
    "learning_rate": 0.001
  },
  {
    "episode": 7750,
    "reward": 90.110747,
    "length": 64,
    "time": 116715.091249,
    "actor_loss": -72.67333984375,
    "critic_loss": 2.7364749908447266,
    "ent_coef": 0.06487902253866196,
    "learning_rate": 0.001
  },
  {
    "episode": 7751,
    "reward": 88.250048,
    "length": 68,
    "time": 116730.625835,
    "actor_loss": -69.78863525390625,
    "critic_loss": 3.6929612159729004,
    "ent_coef": 0.06423833966255188,
    "learning_rate": 0.001
  },
  {
    "episode": 7752,
    "reward": 88.001286,
    "length": 71,
    "time": 116742.749102,
    "actor_loss": -70.82418823242188,
    "critic_loss": 2.4500865936279297,
    "ent_coef": 0.05899731069803238,
    "learning_rate": 0.001
  },
  {
    "episode": 7753,
    "reward": 87.681333,
    "length": 71,
    "time": 116755.867642,
    "actor_loss": -62.50609588623047,
    "critic_loss": 3.7287416458129883,
    "ent_coef": 0.05582988262176514,
    "learning_rate": 0.001
  },
  {
    "episode": 7754,
    "reward": 88.976791,
    "length": 67,
    "time": 116772.274732,
    "actor_loss": -68.74393463134766,
    "critic_loss": 5.785275459289551,
    "ent_coef": 0.055799778550863266,
    "learning_rate": 0.001
  },
  {
    "episode": 7755,
    "reward": 77.919366,
    "length": 88,
    "time": 116787.417373,
    "actor_loss": -72.74909973144531,
    "critic_loss": 6.669282913208008,
    "ent_coef": 0.05297638103365898,
    "learning_rate": 0.001
  },
  {
    "episode": 7756,
    "reward": 85.100027,
    "length": 76,
    "time": 116801.793433,
    "actor_loss": -70.10857391357422,
    "critic_loss": 2.9492244720458984,
    "ent_coef": 0.054308515042066574,
    "learning_rate": 0.001
  },
  {
    "episode": 7757,
    "reward": 88.501735,
    "length": 66,
    "time": 116813.393376,
    "actor_loss": -69.507080078125,
    "critic_loss": 2.9831650257110596,
    "ent_coef": 0.05803949758410454,
    "learning_rate": 0.001
  },
  {
    "episode": 7758,
    "reward": 83.483536,
    "length": 87,
    "time": 116829.20114,
    "actor_loss": -64.80821228027344,
    "critic_loss": 227.40972900390625,
    "ent_coef": 0.054267678409814835,
    "learning_rate": 0.001
  },
  {
    "episode": 7759,
    "reward": 86.896199,
    "length": 71,
    "time": 116843.88806,
    "actor_loss": -65.17221069335938,
    "critic_loss": 2.2177670001983643,
    "ent_coef": 0.053954895585775375,
    "learning_rate": 0.001
  },
  {
    "episode": 7760,
    "reward": 90.078327,
    "length": 67,
    "time": 116855.740359,
    "actor_loss": -68.62677001953125,
    "critic_loss": 5.769268035888672,
    "ent_coef": 0.05562452971935272,
    "learning_rate": 0.001
  },
  {
    "episode": 7761,
    "reward": 86.216624,
    "length": 72,
    "time": 116870.39311,
    "actor_loss": -72.87973022460938,
    "critic_loss": 3.3159852027893066,
    "ent_coef": 0.053176697343587875,
    "learning_rate": 0.001
  },
  {
    "episode": 7762,
    "reward": 87.935263,
    "length": 70,
    "time": 116882.717103,
    "actor_loss": -64.72456359863281,
    "critic_loss": 5.272342205047607,
    "ent_coef": 0.055421896278858185,
    "learning_rate": 0.001
  },
  {
    "episode": 7763,
    "reward": 90.100131,
    "length": 67,
    "time": 116894.708659,
    "actor_loss": -73.05006408691406,
    "critic_loss": 67.29779052734375,
    "ent_coef": 0.05670798942446709,
    "learning_rate": 0.001
  },
  {
    "episode": 7764,
    "reward": 89.614749,
    "length": 64,
    "time": 116906.212269,
    "actor_loss": -68.80532836914062,
    "critic_loss": 4.056556701660156,
    "ent_coef": 0.05782092735171318,
    "learning_rate": 0.001
  },
  {
    "episode": 7765,
    "reward": 85.61894,
    "length": 73,
    "time": 116919.680647,
    "actor_loss": -67.74363708496094,
    "critic_loss": 20.888729095458984,
    "ent_coef": 0.057596806436777115,
    "learning_rate": 0.001
  },
  {
    "episode": 7766,
    "reward": 89.861416,
    "length": 66,
    "time": 116932.47636,
    "actor_loss": -68.64446258544922,
    "critic_loss": 13.733494758605957,
    "ent_coef": 0.059142790734767914,
    "learning_rate": 0.001
  },
  {
    "episode": 7767,
    "reward": 90.667587,
    "length": 64,
    "time": 116944.524904,
    "actor_loss": -65.85252380371094,
    "critic_loss": 13.654195785522461,
    "ent_coef": 0.06081225350499153,
    "learning_rate": 0.001
  },
  {
    "episode": 7768,
    "reward": 91.223267,
    "length": 63,
    "time": 116957.754894,
    "actor_loss": -68.15476989746094,
    "critic_loss": 12.66478157043457,
    "ent_coef": 0.06333833187818527,
    "learning_rate": 0.001
  },
  {
    "episode": 7769,
    "reward": 90.582461,
    "length": 65,
    "time": 116972.15639,
    "actor_loss": -68.65814971923828,
    "critic_loss": 3.209589958190918,
    "ent_coef": 0.0650404766201973,
    "learning_rate": 0.001
  },
  {
    "episode": 7770,
    "reward": 91.103415,
    "length": 62,
    "time": 116986.974643,
    "actor_loss": -68.05363464355469,
    "critic_loss": 2.8505330085754395,
    "ent_coef": 0.06502208858728409,
    "learning_rate": 0.001
  },
  {
    "episode": 7771,
    "reward": 91.343485,
    "length": 61,
    "time": 117002.602444,
    "actor_loss": -65.63706970214844,
    "critic_loss": 5.584803581237793,
    "ent_coef": 0.0637001320719719,
    "learning_rate": 0.001
  },
  {
    "episode": 7772,
    "reward": 89.318991,
    "length": 66,
    "time": 117017.971604,
    "actor_loss": -69.89491271972656,
    "critic_loss": 18.220775604248047,
    "ent_coef": 0.061558227986097336,
    "learning_rate": 0.001
  },
  {
    "episode": 7773,
    "reward": 83.851663,
    "length": 85,
    "time": 117032.534079,
    "actor_loss": -66.57933044433594,
    "critic_loss": 7.666232109069824,
    "ent_coef": 0.058497354388237,
    "learning_rate": 0.001
  },
  {
    "episode": 7774,
    "reward": 87.290833,
    "length": 70,
    "time": 117044.695843,
    "actor_loss": -68.52301788330078,
    "critic_loss": 6.549324989318848,
    "ent_coef": 0.05837167426943779,
    "learning_rate": 0.001
  },
  {
    "episode": 7775,
    "reward": 89.874987,
    "length": 64,
    "time": 117056.545815,
    "actor_loss": -66.86953735351562,
    "critic_loss": 3.3411402702331543,
    "ent_coef": 0.06001389026641846,
    "learning_rate": 0.001
  },
  {
    "episode": 7776,
    "reward": 87.167657,
    "length": 71,
    "time": 117068.874893,
    "actor_loss": -74.07447814941406,
    "critic_loss": 489.77374267578125,
    "ent_coef": 0.05770820006728172,
    "learning_rate": 0.001
  },
  {
    "episode": 7777,
    "reward": 87.844123,
    "length": 70,
    "time": 117081.664854,
    "actor_loss": -71.87025451660156,
    "critic_loss": 5.9184160232543945,
    "ent_coef": 0.05744088441133499,
    "learning_rate": 0.001
  },
  {
    "episode": 7778,
    "reward": 77.75584,
    "length": 97,
    "time": 117100.32663,
    "actor_loss": -70.68380737304688,
    "critic_loss": 9.28204345703125,
    "ent_coef": 0.051151104271411896,
    "learning_rate": 0.001
  },
  {
    "episode": 7779,
    "reward": 84.403856,
    "length": 74,
    "time": 117114.275925,
    "actor_loss": -69.97016143798828,
    "critic_loss": 4.864409446716309,
    "ent_coef": 0.04808974638581276,
    "learning_rate": 0.001
  },
  {
    "episode": 7780,
    "reward": 73.052897,
    "length": 103,
    "time": 117132.139246,
    "actor_loss": -69.33702850341797,
    "critic_loss": 5.966192245483398,
    "ent_coef": 0.04664349555969238,
    "learning_rate": 0.001
  },
  {
    "episode": 7781,
    "reward": 87.601194,
    "length": 71,
    "time": 117145.105731,
    "actor_loss": -71.36868286132812,
    "critic_loss": 13.499855995178223,
    "ent_coef": 0.044628724455833435,
    "learning_rate": 0.001
  },
  {
    "episode": 7782,
    "reward": 87.195634,
    "length": 71,
    "time": 117158.214689,
    "actor_loss": -75.0768051147461,
    "critic_loss": 6.062184810638428,
    "ent_coef": 0.04310804605484009,
    "learning_rate": 0.001
  },
  {
    "episode": 7783,
    "reward": 90.43114,
    "length": 63,
    "time": 117170.209496,
    "actor_loss": -65.60884857177734,
    "critic_loss": 12.01507568359375,
    "ent_coef": 0.04286367818713188,
    "learning_rate": 0.001
  },
  {
    "episode": 7784,
    "reward": 91.42057,
    "length": 65,
    "time": 117184.183497,
    "actor_loss": -72.07997131347656,
    "critic_loss": 9.449845314025879,
    "ent_coef": 0.048715975135564804,
    "learning_rate": 0.001
  },
  {
    "episode": 7785,
    "reward": 90.350492,
    "length": 64,
    "time": 117197.166169,
    "actor_loss": -69.88636779785156,
    "critic_loss": 11.24262809753418,
    "ent_coef": 0.05148131772875786,
    "learning_rate": 0.001
  },
  {
    "episode": 7786,
    "reward": 89.954098,
    "length": 64,
    "time": 117209.731939,
    "actor_loss": -67.57467651367188,
    "critic_loss": 22.919050216674805,
    "ent_coef": 0.054035596549510956,
    "learning_rate": 0.001
  },
  {
    "episode": 7787,
    "reward": 89.165477,
    "length": 67,
    "time": 117221.481507,
    "actor_loss": -69.84243774414062,
    "critic_loss": 3.162727117538452,
    "ent_coef": 0.0554390475153923,
    "learning_rate": 0.001
  },
  {
    "episode": 7788,
    "reward": 89.091319,
    "length": 68,
    "time": 117234.399284,
    "actor_loss": -66.4091796875,
    "critic_loss": 2.6245951652526855,
    "ent_coef": 0.05918150022625923,
    "learning_rate": 0.001
  },
  {
    "episode": 7789,
    "reward": 93.238205,
    "length": 58,
    "time": 117246.253731,
    "actor_loss": -69.84954833984375,
    "critic_loss": 53.63489532470703,
    "ent_coef": 0.06554353982210159,
    "learning_rate": 0.001
  },
  {
    "episode": 7790,
    "reward": 91.951058,
    "length": 60,
    "time": 117258.035742,
    "actor_loss": -73.31044006347656,
    "critic_loss": 9.94990348815918,
    "ent_coef": 0.06936686486005783,
    "learning_rate": 0.001
  },
  {
    "episode": 7791,
    "reward": 89.783481,
    "length": 65,
    "time": 117270.49245,
    "actor_loss": -71.6973648071289,
    "critic_loss": 2.3660788536071777,
    "ent_coef": 0.07116901129484177,
    "learning_rate": 0.001
  },
  {
    "episode": 7792,
    "reward": 87.110008,
    "length": 71,
    "time": 117285.853969,
    "actor_loss": -67.23612213134766,
    "critic_loss": 10.177230834960938,
    "ent_coef": 0.06961327791213989,
    "learning_rate": 0.001
  },
  {
    "episode": 7793,
    "reward": -160.814828,
    "length": 94,
    "time": 117301.970544,
    "actor_loss": -70.96742248535156,
    "critic_loss": 12.448678970336914,
    "ent_coef": 0.0698825865983963,
    "learning_rate": 0.001
  },
  {
    "episode": 7794,
    "reward": 81.095723,
    "length": 90,
    "time": 117321.154266,
    "actor_loss": -71.05751037597656,
    "critic_loss": 4.017292499542236,
    "ent_coef": 0.0691496804356575,
    "learning_rate": 0.001
  },
  {
    "episode": 7795,
    "reward": 76.865915,
    "length": 82,
    "time": 117337.422029,
    "actor_loss": -67.70489501953125,
    "critic_loss": 4.3564252853393555,
    "ent_coef": 0.06965810805559158,
    "learning_rate": 0.001
  },
  {
    "episode": 7796,
    "reward": 89.493677,
    "length": 66,
    "time": 117349.417861,
    "actor_loss": -67.49462127685547,
    "critic_loss": 1.8551372289657593,
    "ent_coef": 0.072844959795475,
    "learning_rate": 0.001
  },
  {
    "episode": 7797,
    "reward": 79.418167,
    "length": 82,
    "time": 117363.312016,
    "actor_loss": -71.07632446289062,
    "critic_loss": 6.805408477783203,
    "ent_coef": 0.07019384950399399,
    "learning_rate": 0.001
  },
  {
    "episode": 7798,
    "reward": 89.080857,
    "length": 66,
    "time": 117375.261508,
    "actor_loss": -69.89773559570312,
    "critic_loss": 23.43872833251953,
    "ent_coef": 0.07086765021085739,
    "learning_rate": 0.001
  },
  {
    "episode": 7799,
    "reward": 91.106188,
    "length": 63,
    "time": 117389.709488,
    "actor_loss": -72.85877990722656,
    "critic_loss": 7.715073585510254,
    "ent_coef": 0.07316998392343521,
    "learning_rate": 0.001
  },
  {
    "episode": 7800,
    "reward": 90.117224,
    "length": 66,
    "time": 117401.324185,
    "actor_loss": -69.77116394042969,
    "critic_loss": 75.02105712890625,
    "ent_coef": 0.07326865196228027,
    "learning_rate": 0.001
  },
  {
    "episode": 7801,
    "reward": 88.456956,
    "length": 67,
    "time": 117414.087248,
    "actor_loss": -68.39863586425781,
    "critic_loss": 8.36787223815918,
    "ent_coef": 0.07105985283851624,
    "learning_rate": 0.001
  },
  {
    "episode": 7802,
    "reward": 86.907435,
    "length": 70,
    "time": 117426.278128,
    "actor_loss": -68.62862396240234,
    "critic_loss": 17.46743392944336,
    "ent_coef": 0.06912557780742645,
    "learning_rate": 0.001
  },
  {
    "episode": 7803,
    "reward": 88.913686,
    "length": 69,
    "time": 117439.888777,
    "actor_loss": -65.73500061035156,
    "critic_loss": 2.3056716918945312,
    "ent_coef": 0.07018188387155533,
    "learning_rate": 0.001
  },
  {
    "episode": 7804,
    "reward": 89.323379,
    "length": 68,
    "time": 117451.958321,
    "actor_loss": -71.1091079711914,
    "critic_loss": 8.240480422973633,
    "ent_coef": 0.0689215362071991,
    "learning_rate": 0.001
  },
  {
    "episode": 7805,
    "reward": 85.674147,
    "length": 74,
    "time": 117467.736337,
    "actor_loss": -68.68913269042969,
    "critic_loss": 1.9972033500671387,
    "ent_coef": 0.06593124568462372,
    "learning_rate": 0.001
  },
  {
    "episode": 7806,
    "reward": 87.827978,
    "length": 69,
    "time": 117481.668269,
    "actor_loss": -72.04434204101562,
    "critic_loss": 8.055683135986328,
    "ent_coef": 0.06204983592033386,
    "learning_rate": 0.001
  },
  {
    "episode": 7807,
    "reward": 90.97862,
    "length": 62,
    "time": 117492.844859,
    "actor_loss": -66.53824615478516,
    "critic_loss": 3.799558162689209,
    "ent_coef": 0.06462576985359192,
    "learning_rate": 0.001
  },
  {
    "episode": 7808,
    "reward": 91.913573,
    "length": 61,
    "time": 117504.924254,
    "actor_loss": -67.9639892578125,
    "critic_loss": 8.255630493164062,
    "ent_coef": 0.06656000018119812,
    "learning_rate": 0.001
  },
  {
    "episode": 7809,
    "reward": 86.021763,
    "length": 69,
    "time": 117516.98065,
    "actor_loss": -72.86326599121094,
    "critic_loss": 3.212372303009033,
    "ent_coef": 0.07031295448541641,
    "learning_rate": 0.001
  },
  {
    "episode": 7810,
    "reward": 91.801736,
    "length": 60,
    "time": 117527.749893,
    "actor_loss": -63.21013641357422,
    "critic_loss": 2.1759955883026123,
    "ent_coef": 0.07647038251161575,
    "learning_rate": 0.001
  },
  {
    "episode": 7811,
    "reward": 90.544858,
    "length": 63,
    "time": 117539.329259,
    "actor_loss": -67.98605346679688,
    "critic_loss": 9.262489318847656,
    "ent_coef": 0.07849965989589691,
    "learning_rate": 0.001
  },
  {
    "episode": 7812,
    "reward": 90.070541,
    "length": 65,
    "time": 117557.639536,
    "actor_loss": -72.713134765625,
    "critic_loss": 10.886651992797852,
    "ent_coef": 0.07760828733444214,
    "learning_rate": 0.001
  },
  {
    "episode": 7813,
    "reward": 89.681293,
    "length": 66,
    "time": 117570.59281,
    "actor_loss": -72.09251403808594,
    "critic_loss": 2.9915592670440674,
    "ent_coef": 0.07559347152709961,
    "learning_rate": 0.001
  },
  {
    "episode": 7814,
    "reward": 88.277606,
    "length": 66,
    "time": 117581.976843,
    "actor_loss": -69.32831573486328,
    "critic_loss": 2.1336026191711426,
    "ent_coef": 0.07456636428833008,
    "learning_rate": 0.001
  },
  {
    "episode": 7815,
    "reward": 89.037623,
    "length": 66,
    "time": 117594.463008,
    "actor_loss": -73.90243530273438,
    "critic_loss": 4.203239440917969,
    "ent_coef": 0.07162246108055115,
    "learning_rate": 0.001
  },
  {
    "episode": 7816,
    "reward": 85.492525,
    "length": 73,
    "time": 117607.929106,
    "actor_loss": -66.17879486083984,
    "critic_loss": 25.974912643432617,
    "ent_coef": 0.06667733192443848,
    "learning_rate": 0.001
  },
  {
    "episode": 7817,
    "reward": 87.37382,
    "length": 71,
    "time": 117623.030914,
    "actor_loss": -68.84034729003906,
    "critic_loss": 4.065151214599609,
    "ent_coef": 0.0624375082552433,
    "learning_rate": 0.001
  },
  {
    "episode": 7818,
    "reward": 91.691502,
    "length": 61,
    "time": 117635.210504,
    "actor_loss": -72.55046081542969,
    "critic_loss": 6.268253803253174,
    "ent_coef": 0.061843689531087875,
    "learning_rate": 0.001
  },
  {
    "episode": 7819,
    "reward": 90.990122,
    "length": 62,
    "time": 117646.417734,
    "actor_loss": -70.59000396728516,
    "critic_loss": 6.14369535446167,
    "ent_coef": 0.06327198445796967,
    "learning_rate": 0.001
  },
  {
    "episode": 7820,
    "reward": 91.079103,
    "length": 61,
    "time": 117657.272303,
    "actor_loss": -71.36276245117188,
    "critic_loss": 3.071204662322998,
    "ent_coef": 0.06446754932403564,
    "learning_rate": 0.001
  },
  {
    "episode": 7821,
    "reward": 89.844111,
    "length": 64,
    "time": 117668.800778,
    "actor_loss": -68.5715103149414,
    "critic_loss": 3.5057616233825684,
    "ent_coef": 0.06380783766508102,
    "learning_rate": 0.001
  },
  {
    "episode": 7822,
    "reward": 90.660775,
    "length": 65,
    "time": 117680.293827,
    "actor_loss": -65.53221893310547,
    "critic_loss": 1.8225730657577515,
    "ent_coef": 0.06422258168458939,
    "learning_rate": 0.001
  },
  {
    "episode": 7823,
    "reward": -145.684094,
    "length": 81,
    "time": 117694.698806,
    "actor_loss": -65.35214233398438,
    "critic_loss": 3.8220248222351074,
    "ent_coef": 0.06619599461555481,
    "learning_rate": 0.001
  },
  {
    "episode": 7824,
    "reward": 98.120318,
    "length": 64,
    "time": 117708.026859,
    "actor_loss": -66.87779235839844,
    "critic_loss": 6.910209655761719,
    "ent_coef": 0.0642356425523758,
    "learning_rate": 0.001
  },
  {
    "episode": 7825,
    "reward": 91.341212,
    "length": 64,
    "time": 117722.860611,
    "actor_loss": -72.99839782714844,
    "critic_loss": 5.760907173156738,
    "ent_coef": 0.06269685924053192,
    "learning_rate": 0.001
  },
  {
    "episode": 7826,
    "reward": 89.743943,
    "length": 68,
    "time": 117737.168122,
    "actor_loss": -68.21562957763672,
    "critic_loss": 20.75760841369629,
    "ent_coef": 0.05988766625523567,
    "learning_rate": 0.001
  },
  {
    "episode": 7827,
    "reward": 86.2315,
    "length": 74,
    "time": 117751.266603,
    "actor_loss": -65.31912231445312,
    "critic_loss": 48.083740234375,
    "ent_coef": 0.05429966002702713,
    "learning_rate": 0.001
  },
  {
    "episode": 7828,
    "reward": 90.996553,
    "length": 63,
    "time": 117762.389466,
    "actor_loss": -68.17776489257812,
    "critic_loss": 5.1883416175842285,
    "ent_coef": 0.05319352447986603,
    "learning_rate": 0.001
  },
  {
    "episode": 7829,
    "reward": 90.269993,
    "length": 65,
    "time": 117775.307714,
    "actor_loss": -66.69918823242188,
    "critic_loss": 4.682182312011719,
    "ent_coef": 0.053653616458177567,
    "learning_rate": 0.001
  },
  {
    "episode": 7830,
    "reward": 85.275174,
    "length": 72,
    "time": 117788.232693,
    "actor_loss": -69.14781951904297,
    "critic_loss": 3.8298351764678955,
    "ent_coef": 0.051741376519203186,
    "learning_rate": 0.001
  },
  {
    "episode": 7831,
    "reward": 87.21167,
    "length": 71,
    "time": 117800.89466,
    "actor_loss": -65.59898376464844,
    "critic_loss": 3.397188186645508,
    "ent_coef": 0.051302552223205566,
    "learning_rate": 0.001
  },
  {
    "episode": 7832,
    "reward": 90.48629,
    "length": 63,
    "time": 117814.301149,
    "actor_loss": -68.59205627441406,
    "critic_loss": 14.136922836303711,
    "ent_coef": 0.05160827934741974,
    "learning_rate": 0.001
  },
  {
    "episode": 7833,
    "reward": 88.178459,
    "length": 66,
    "time": 117826.522142,
    "actor_loss": -69.45845031738281,
    "critic_loss": 2.696697235107422,
    "ent_coef": 0.05094939097762108,
    "learning_rate": 0.001
  },
  {
    "episode": 7834,
    "reward": 89.514846,
    "length": 67,
    "time": 117840.322934,
    "actor_loss": -69.77337646484375,
    "critic_loss": 12.151244163513184,
    "ent_coef": 0.0516834631562233,
    "learning_rate": 0.001
  },
  {
    "episode": 7835,
    "reward": 92.038691,
    "length": 60,
    "time": 117854.392391,
    "actor_loss": -64.03305053710938,
    "critic_loss": 3.435638666152954,
    "ent_coef": 0.05572360008955002,
    "learning_rate": 0.001
  },
  {
    "episode": 7836,
    "reward": 90.635986,
    "length": 63,
    "time": 117866.800328,
    "actor_loss": -68.4625244140625,
    "critic_loss": 5.944515228271484,
    "ent_coef": 0.058570217341184616,
    "learning_rate": 0.001
  },
  {
    "episode": 7837,
    "reward": 90.352496,
    "length": 64,
    "time": 117878.198876,
    "actor_loss": -65.97920227050781,
    "critic_loss": 75.04876708984375,
    "ent_coef": 0.05839678645133972,
    "learning_rate": 0.001
  },
  {
    "episode": 7838,
    "reward": 92.073363,
    "length": 60,
    "time": 117889.083438,
    "actor_loss": -62.75684356689453,
    "critic_loss": 1.8029590845108032,
    "ent_coef": 0.06174099072813988,
    "learning_rate": 0.001
  },
  {
    "episode": 7839,
    "reward": 86.988188,
    "length": 79,
    "time": 117902.51005,
    "actor_loss": -67.94593811035156,
    "critic_loss": 58.120216369628906,
    "ent_coef": 0.06543107330799103,
    "learning_rate": 0.001
  },
  {
    "episode": 7840,
    "reward": 91.763065,
    "length": 60,
    "time": 117914.013375,
    "actor_loss": -66.80149841308594,
    "critic_loss": 2.511378288269043,
    "ent_coef": 0.07012436538934708,
    "learning_rate": 0.001
  },
  {
    "episode": 7841,
    "reward": 83.013709,
    "length": 85,
    "time": 117930.018132,
    "actor_loss": -67.5843734741211,
    "critic_loss": 36.16788864135742,
    "ent_coef": 0.06772508472204208,
    "learning_rate": 0.001
  },
  {
    "episode": 7842,
    "reward": 83.349604,
    "length": 79,
    "time": 117944.077638,
    "actor_loss": -59.151573181152344,
    "critic_loss": 24.061988830566406,
    "ent_coef": 0.06763723492622375,
    "learning_rate": 0.001
  },
  {
    "episode": 7843,
    "reward": 90.572445,
    "length": 63,
    "time": 117955.190881,
    "actor_loss": -70.0948715209961,
    "critic_loss": 8.883251190185547,
    "ent_coef": 0.06713583320379257,
    "learning_rate": 0.001
  },
  {
    "episode": 7844,
    "reward": 85.628856,
    "length": 71,
    "time": 117967.454246,
    "actor_loss": -68.00990295410156,
    "critic_loss": 3.0642004013061523,
    "ent_coef": 0.06491956114768982,
    "learning_rate": 0.001
  },
  {
    "episode": 7845,
    "reward": 88.685715,
    "length": 66,
    "time": 117979.137079,
    "actor_loss": -67.8865737915039,
    "critic_loss": 3.437032461166382,
    "ent_coef": 0.06383539736270905,
    "learning_rate": 0.001
  },
  {
    "episode": 7846,
    "reward": 90.832071,
    "length": 62,
    "time": 117991.410546,
    "actor_loss": -62.47138214111328,
    "critic_loss": 2.0658459663391113,
    "ent_coef": 0.06611484289169312,
    "learning_rate": 0.001
  },
  {
    "episode": 7847,
    "reward": 90.101801,
    "length": 66,
    "time": 118005.220498,
    "actor_loss": -65.59306335449219,
    "critic_loss": 22.391387939453125,
    "ent_coef": 0.06785944849252701,
    "learning_rate": 0.001
  },
  {
    "episode": 7848,
    "reward": 89.982572,
    "length": 64,
    "time": 118016.504182,
    "actor_loss": -70.47554779052734,
    "critic_loss": 13.031896591186523,
    "ent_coef": 0.06843298673629761,
    "learning_rate": 0.001
  },
  {
    "episode": 7849,
    "reward": 90.780999,
    "length": 62,
    "time": 118027.870293,
    "actor_loss": -70.15457153320312,
    "critic_loss": 7.785498142242432,
    "ent_coef": 0.0689660981297493,
    "learning_rate": 0.001
  },
  {
    "episode": 7850,
    "reward": 65.101381,
    "length": 102,
    "time": 118045.03005,
    "actor_loss": -67.7378158569336,
    "critic_loss": 3.0342493057250977,
    "ent_coef": 0.06237052008509636,
    "learning_rate": 0.001
  },
  {
    "episode": 7851,
    "reward": 86.235491,
    "length": 72,
    "time": 118060.266837,
    "actor_loss": -62.912750244140625,
    "critic_loss": 4.817101955413818,
    "ent_coef": 0.05695232376456261,
    "learning_rate": 0.001
  },
  {
    "episode": 7852,
    "reward": 83.942616,
    "length": 75,
    "time": 118073.721299,
    "actor_loss": -71.87430572509766,
    "critic_loss": 12.148822784423828,
    "ent_coef": 0.05410553142428398,
    "learning_rate": 0.001
  },
  {
    "episode": 7853,
    "reward": 88.331163,
    "length": 67,
    "time": 118085.580784,
    "actor_loss": -67.94569396972656,
    "critic_loss": 4.663789749145508,
    "ent_coef": 0.05480148643255234,
    "learning_rate": 0.001
  },
  {
    "episode": 7854,
    "reward": 89.490857,
    "length": 67,
    "time": 118099.31372,
    "actor_loss": -66.15943908691406,
    "critic_loss": 18.256412506103516,
    "ent_coef": 0.056877151131629944,
    "learning_rate": 0.001
  },
  {
    "episode": 7855,
    "reward": 87.061511,
    "length": 79,
    "time": 118113.130962,
    "actor_loss": -69.09849548339844,
    "critic_loss": 106.2916259765625,
    "ent_coef": 0.05819655954837799,
    "learning_rate": 0.001
  },
  {
    "episode": 7856,
    "reward": 90.191699,
    "length": 63,
    "time": 118125.582114,
    "actor_loss": -68.81282043457031,
    "critic_loss": 6.5304155349731445,
    "ent_coef": 0.059497784823179245,
    "learning_rate": 0.001
  },
  {
    "episode": 7857,
    "reward": 90.177226,
    "length": 66,
    "time": 118137.003897,
    "actor_loss": -64.17119598388672,
    "critic_loss": 20.48190689086914,
    "ent_coef": 0.06100429967045784,
    "learning_rate": 0.001
  },
  {
    "episode": 7858,
    "reward": 90.415896,
    "length": 66,
    "time": 118150.541409,
    "actor_loss": -62.35747146606445,
    "critic_loss": 2.372518301010132,
    "ent_coef": 0.06083418056368828,
    "learning_rate": 0.001
  },
  {
    "episode": 7859,
    "reward": 85.722099,
    "length": 71,
    "time": 118164.790741,
    "actor_loss": -66.90174865722656,
    "critic_loss": 4.219230651855469,
    "ent_coef": 0.057739194482564926,
    "learning_rate": 0.001
  },
  {
    "episode": 7860,
    "reward": 91.240819,
    "length": 62,
    "time": 118178.085205,
    "actor_loss": -64.44012451171875,
    "critic_loss": 4.854723930358887,
    "ent_coef": 0.05764535814523697,
    "learning_rate": 0.001
  },
  {
    "episode": 7861,
    "reward": 86.895106,
    "length": 74,
    "time": 118192.345488,
    "actor_loss": -65.1496353149414,
    "critic_loss": 6.331363677978516,
    "ent_coef": 0.059066422283649445,
    "learning_rate": 0.001
  },
  {
    "episode": 7862,
    "reward": 89.62636,
    "length": 64,
    "time": 118204.70997,
    "actor_loss": -65.6973876953125,
    "critic_loss": 18.41748046875,
    "ent_coef": 0.05695023387670517,
    "learning_rate": 0.001
  },
  {
    "episode": 7863,
    "reward": 88.559555,
    "length": 67,
    "time": 118216.706218,
    "actor_loss": -71.04084777832031,
    "critic_loss": 21.526905059814453,
    "ent_coef": 0.05402536690235138,
    "learning_rate": 0.001
  },
  {
    "episode": 7864,
    "reward": 85.144775,
    "length": 71,
    "time": 118230.814776,
    "actor_loss": -70.40156555175781,
    "critic_loss": 5.589801788330078,
    "ent_coef": 0.051236946135759354,
    "learning_rate": 0.001
  },
  {
    "episode": 7865,
    "reward": 90.734065,
    "length": 62,
    "time": 118241.982455,
    "actor_loss": -66.96534729003906,
    "critic_loss": 14.5335111618042,
    "ent_coef": 0.05117746815085411,
    "learning_rate": 0.001
  },
  {
    "episode": 7866,
    "reward": 90.722158,
    "length": 62,
    "time": 118255.055711,
    "actor_loss": -68.96239471435547,
    "critic_loss": 4.932032585144043,
    "ent_coef": 0.05217091739177704,
    "learning_rate": 0.001
  },
  {
    "episode": 7867,
    "reward": 84.684375,
    "length": 71,
    "time": 118269.886648,
    "actor_loss": -67.19013977050781,
    "critic_loss": 19.47071075439453,
    "ent_coef": 0.05267186462879181,
    "learning_rate": 0.001
  },
  {
    "episode": 7868,
    "reward": 90.150514,
    "length": 65,
    "time": 118282.314551,
    "actor_loss": -70.17694091796875,
    "critic_loss": 3.2160964012145996,
    "ent_coef": 0.05131397768855095,
    "learning_rate": 0.001
  },
  {
    "episode": 7869,
    "reward": 91.213953,
    "length": 61,
    "time": 118295.763319,
    "actor_loss": -70.73485565185547,
    "critic_loss": 2.5388221740722656,
    "ent_coef": 0.05015409737825394,
    "learning_rate": 0.001
  },
  {
    "episode": 7870,
    "reward": 89.73978,
    "length": 63,
    "time": 118309.152254,
    "actor_loss": -69.49561309814453,
    "critic_loss": 3.51011061668396,
    "ent_coef": 0.050142791122198105,
    "learning_rate": 0.001
  },
  {
    "episode": 7871,
    "reward": 83.038258,
    "length": 77,
    "time": 118324.255065,
    "actor_loss": -64.56788635253906,
    "critic_loss": 6.181669235229492,
    "ent_coef": 0.047997742891311646,
    "learning_rate": 0.001
  },
  {
    "episode": 7872,
    "reward": 89.618625,
    "length": 65,
    "time": 118336.519061,
    "actor_loss": -70.56925964355469,
    "critic_loss": 2.5754635334014893,
    "ent_coef": 0.048328060656785965,
    "learning_rate": 0.001
  },
  {
    "episode": 7873,
    "reward": 85.416154,
    "length": 73,
    "time": 118349.368004,
    "actor_loss": -69.56916809082031,
    "critic_loss": 116.89360046386719,
    "ent_coef": 0.046398818492889404,
    "learning_rate": 0.001
  },
  {
    "episode": 7874,
    "reward": 88.772855,
    "length": 65,
    "time": 118362.142035,
    "actor_loss": -59.774566650390625,
    "critic_loss": 78.64822387695312,
    "ent_coef": 0.046906325966119766,
    "learning_rate": 0.001
  },
  {
    "episode": 7875,
    "reward": 88.643997,
    "length": 67,
    "time": 118373.845963,
    "actor_loss": -64.31285858154297,
    "critic_loss": 3.347038507461548,
    "ent_coef": 0.05254892632365227,
    "learning_rate": 0.001
  },
  {
    "episode": 7876,
    "reward": 90.173199,
    "length": 67,
    "time": 118389.32366,
    "actor_loss": -64.65380859375,
    "critic_loss": 17.46877670288086,
    "ent_coef": 0.05605437979102135,
    "learning_rate": 0.001
  },
  {
    "episode": 7877,
    "reward": 91.299181,
    "length": 62,
    "time": 118400.735584,
    "actor_loss": -67.08770751953125,
    "critic_loss": 16.045143127441406,
    "ent_coef": 0.05647682398557663,
    "learning_rate": 0.001
  },
  {
    "episode": 7878,
    "reward": 88.941434,
    "length": 67,
    "time": 118413.325263,
    "actor_loss": -67.53424072265625,
    "critic_loss": 5.131565093994141,
    "ent_coef": 0.054048895835876465,
    "learning_rate": 0.001
  },
  {
    "episode": 7879,
    "reward": 85.197479,
    "length": 71,
    "time": 118425.886425,
    "actor_loss": -62.71029281616211,
    "critic_loss": 3.4466850757598877,
    "ent_coef": 0.050289858132600784,
    "learning_rate": 0.001
  },
  {
    "episode": 7880,
    "reward": 89.583683,
    "length": 64,
    "time": 118437.198162,
    "actor_loss": -71.87419891357422,
    "critic_loss": 10.773126602172852,
    "ent_coef": 0.04944073408842087,
    "learning_rate": 0.001
  },
  {
    "episode": 7881,
    "reward": 89.845655,
    "length": 64,
    "time": 118449.279312,
    "actor_loss": -71.84031677246094,
    "critic_loss": 2.140073776245117,
    "ent_coef": 0.049554627388715744,
    "learning_rate": 0.001
  },
  {
    "episode": 7882,
    "reward": 92.005922,
    "length": 60,
    "time": 118463.297239,
    "actor_loss": -75.5512924194336,
    "critic_loss": 5.684279441833496,
    "ent_coef": 0.052796561270952225,
    "learning_rate": 0.001
  },
  {
    "episode": 7883,
    "reward": 91.126107,
    "length": 62,
    "time": 118475.306705,
    "actor_loss": -63.1407470703125,
    "critic_loss": 105.21133422851562,
    "ent_coef": 0.05439090356230736,
    "learning_rate": 0.001
  },
  {
    "episode": 7884,
    "reward": 91.112868,
    "length": 61,
    "time": 118488.949614,
    "actor_loss": -74.58270263671875,
    "critic_loss": 2.8399124145507812,
    "ent_coef": 0.0561794638633728,
    "learning_rate": 0.001
  },
  {
    "episode": 7885,
    "reward": 92.119026,
    "length": 59,
    "time": 118501.594611,
    "actor_loss": -62.49882125854492,
    "critic_loss": 5.709895610809326,
    "ent_coef": 0.05820753425359726,
    "learning_rate": 0.001
  },
  {
    "episode": 7886,
    "reward": 91.9323,
    "length": 60,
    "time": 118512.796934,
    "actor_loss": -67.86561584472656,
    "critic_loss": 5.036446571350098,
    "ent_coef": 0.059036560356616974,
    "learning_rate": 0.001
  },
  {
    "episode": 7887,
    "reward": 90.529917,
    "length": 65,
    "time": 118533.026788,
    "actor_loss": -66.95437622070312,
    "critic_loss": 8.916255950927734,
    "ent_coef": 0.060655638575553894,
    "learning_rate": 0.001
  },
  {
    "episode": 7888,
    "reward": 89.235641,
    "length": 65,
    "time": 118544.954184,
    "actor_loss": -62.529781341552734,
    "critic_loss": 10.792814254760742,
    "ent_coef": 0.05895756185054779,
    "learning_rate": 0.001
  },
  {
    "episode": 7889,
    "reward": 89.685672,
    "length": 69,
    "time": 118560.44421,
    "actor_loss": -67.79303741455078,
    "critic_loss": 8.165029525756836,
    "ent_coef": 0.061279214918613434,
    "learning_rate": 0.001
  },
  {
    "episode": 7890,
    "reward": 79.326958,
    "length": 80,
    "time": 118575.653731,
    "actor_loss": -65.37979888916016,
    "critic_loss": 6.299059867858887,
    "ent_coef": 0.058177344501018524,
    "learning_rate": 0.001
  },
  {
    "episode": 7891,
    "reward": 90.276352,
    "length": 63,
    "time": 118588.744806,
    "actor_loss": -65.68797302246094,
    "critic_loss": 2.5761990547180176,
    "ent_coef": 0.05841536447405815,
    "learning_rate": 0.001
  },
  {
    "episode": 7892,
    "reward": 88.437857,
    "length": 71,
    "time": 118600.92317,
    "actor_loss": -67.24198913574219,
    "critic_loss": 2.994992733001709,
    "ent_coef": 0.05662432312965393,
    "learning_rate": 0.001
  },
  {
    "episode": 7893,
    "reward": 90.853944,
    "length": 62,
    "time": 118613.671553,
    "actor_loss": -68.21791076660156,
    "critic_loss": 4.787853240966797,
    "ent_coef": 0.05608773231506348,
    "learning_rate": 0.001
  },
  {
    "episode": 7894,
    "reward": 91.015543,
    "length": 61,
    "time": 118628.742714,
    "actor_loss": -65.83291625976562,
    "critic_loss": 6.077543258666992,
    "ent_coef": 0.05559172481298447,
    "learning_rate": 0.001
  },
  {
    "episode": 7895,
    "reward": 92.500412,
    "length": 58,
    "time": 118643.389863,
    "actor_loss": -67.21467590332031,
    "critic_loss": 15.402193069458008,
    "ent_coef": 0.055754926055669785,
    "learning_rate": 0.001
  },
  {
    "episode": 7896,
    "reward": 92.566647,
    "length": 58,
    "time": 118655.468522,
    "actor_loss": -59.1115837097168,
    "critic_loss": 17.77279281616211,
    "ent_coef": 0.0585312694311142,
    "learning_rate": 0.001
  },
  {
    "episode": 7897,
    "reward": 91.14422,
    "length": 62,
    "time": 118670.968491,
    "actor_loss": -68.20484161376953,
    "critic_loss": 615.60498046875,
    "ent_coef": 0.06111704185605049,
    "learning_rate": 0.001
  },
  {
    "episode": 7898,
    "reward": 89.798571,
    "length": 63,
    "time": 118685.002269,
    "actor_loss": -74.23663330078125,
    "critic_loss": 4.4967942237854,
    "ent_coef": 0.06413499265909195,
    "learning_rate": 0.001
  },
  {
    "episode": 7899,
    "reward": 87.539813,
    "length": 66,
    "time": 118698.049124,
    "actor_loss": -71.5749740600586,
    "critic_loss": 5.1597747802734375,
    "ent_coef": 0.0630456954240799,
    "learning_rate": 0.001
  },
  {
    "episode": 7900,
    "reward": 81.451072,
    "length": 83,
    "time": 118714.301495,
    "actor_loss": -66.61531066894531,
    "critic_loss": 13.790894508361816,
    "ent_coef": 0.05836630240082741,
    "learning_rate": 0.001
  },
  {
    "episode": 7901,
    "reward": 90.464434,
    "length": 62,
    "time": 118726.526948,
    "actor_loss": -64.88676452636719,
    "critic_loss": 13.009101867675781,
    "ent_coef": 0.057261668145656586,
    "learning_rate": 0.001
  },
  {
    "episode": 7902,
    "reward": 47.708147,
    "length": 117,
    "time": 118747.418748,
    "actor_loss": -65.95065307617188,
    "critic_loss": 2.588153839111328,
    "ent_coef": 0.057212524116039276,
    "learning_rate": 0.001
  },
  {
    "episode": 7903,
    "reward": 90.130481,
    "length": 69,
    "time": 118762.003642,
    "actor_loss": -68.89508056640625,
    "critic_loss": 27.945880889892578,
    "ent_coef": 0.05710531771183014,
    "learning_rate": 0.001
  },
  {
    "episode": 7904,
    "reward": 90.503557,
    "length": 62,
    "time": 118773.330991,
    "actor_loss": -68.43017578125,
    "critic_loss": 6.371865749359131,
    "ent_coef": 0.05916301906108856,
    "learning_rate": 0.001
  },
  {
    "episode": 7905,
    "reward": 90.543838,
    "length": 65,
    "time": 118786.508379,
    "actor_loss": -66.01675415039062,
    "critic_loss": 49.901100158691406,
    "ent_coef": 0.06355534493923187,
    "learning_rate": 0.001
  },
  {
    "episode": 7906,
    "reward": 85.075651,
    "length": 81,
    "time": 118800.980976,
    "actor_loss": -70.21562957763672,
    "critic_loss": 36.46434020996094,
    "ent_coef": 0.06459000706672668,
    "learning_rate": 0.001
  },
  {
    "episode": 7907,
    "reward": 87.920239,
    "length": 69,
    "time": 118814.268137,
    "actor_loss": -68.09063720703125,
    "critic_loss": 7.366545677185059,
    "ent_coef": 0.06460673362016678,
    "learning_rate": 0.001
  },
  {
    "episode": 7908,
    "reward": 91.762185,
    "length": 61,
    "time": 118826.327759,
    "actor_loss": -67.72280883789062,
    "critic_loss": 2.7538809776306152,
    "ent_coef": 0.06814661622047424,
    "learning_rate": 0.001
  },
  {
    "episode": 7909,
    "reward": 90.487302,
    "length": 65,
    "time": 118839.090537,
    "actor_loss": -68.05870056152344,
    "critic_loss": 60.10901641845703,
    "ent_coef": 0.07237445563077927,
    "learning_rate": 0.001
  },
  {
    "episode": 7910,
    "reward": 89.445158,
    "length": 67,
    "time": 118851.62213,
    "actor_loss": -72.00657653808594,
    "critic_loss": 7.305896282196045,
    "ent_coef": 0.0722486823797226,
    "learning_rate": 0.001
  },
  {
    "episode": 7911,
    "reward": 89.822086,
    "length": 69,
    "time": 118866.883567,
    "actor_loss": -62.413055419921875,
    "critic_loss": 42.554115295410156,
    "ent_coef": 0.07237757742404938,
    "learning_rate": 0.001
  },
  {
    "episode": 7912,
    "reward": 87.929658,
    "length": 71,
    "time": 118880.965496,
    "actor_loss": -65.77395629882812,
    "critic_loss": 30.33100700378418,
    "ent_coef": 0.06738956272602081,
    "learning_rate": 0.001
  },
  {
    "episode": 7913,
    "reward": 90.85931,
    "length": 64,
    "time": 118894.531693,
    "actor_loss": -72.31787872314453,
    "critic_loss": 76.38964080810547,
    "ent_coef": 0.0673723891377449,
    "learning_rate": 0.001
  },
  {
    "episode": 7914,
    "reward": 90.129106,
    "length": 65,
    "time": 118906.228783,
    "actor_loss": -68.51581573486328,
    "critic_loss": 2.4021177291870117,
    "ent_coef": 0.06835123151540756,
    "learning_rate": 0.001
  },
  {
    "episode": 7915,
    "reward": 89.013494,
    "length": 69,
    "time": 118919.885013,
    "actor_loss": -72.26318359375,
    "critic_loss": 32.091556549072266,
    "ent_coef": 0.06930982321500778,
    "learning_rate": 0.001
  },
  {
    "episode": 7916,
    "reward": 90.25881,
    "length": 67,
    "time": 118933.581188,
    "actor_loss": -70.065185546875,
    "critic_loss": 3.2539734840393066,
    "ent_coef": 0.06978824734687805,
    "learning_rate": 0.001
  },
  {
    "episode": 7917,
    "reward": 89.598154,
    "length": 68,
    "time": 118946.038651,
    "actor_loss": -69.084228515625,
    "critic_loss": 2.951385021209717,
    "ent_coef": 0.0682564228773117,
    "learning_rate": 0.001
  },
  {
    "episode": 7918,
    "reward": 82.646597,
    "length": 74,
    "time": 118958.704031,
    "actor_loss": -75.15475463867188,
    "critic_loss": 6.276036262512207,
    "ent_coef": 0.06568776071071625,
    "learning_rate": 0.001
  },
  {
    "episode": 7919,
    "reward": 90.218374,
    "length": 66,
    "time": 118971.374558,
    "actor_loss": -63.779090881347656,
    "critic_loss": 3.8424649238586426,
    "ent_coef": 0.06804945319890976,
    "learning_rate": 0.001
  },
  {
    "episode": 7920,
    "reward": 88.423214,
    "length": 73,
    "time": 118983.746006,
    "actor_loss": -65.76750183105469,
    "critic_loss": 3.0612893104553223,
    "ent_coef": 0.07024312019348145,
    "learning_rate": 0.001
  },
  {
    "episode": 7921,
    "reward": 91.045541,
    "length": 65,
    "time": 118996.395089,
    "actor_loss": -73.33659362792969,
    "critic_loss": 3.4167895317077637,
    "ent_coef": 0.07830017805099487,
    "learning_rate": 0.001
  },
  {
    "episode": 7922,
    "reward": 89.941378,
    "length": 68,
    "time": 119010.512009,
    "actor_loss": -68.01988983154297,
    "critic_loss": 39.97807693481445,
    "ent_coef": 0.0795525461435318,
    "learning_rate": 0.001
  },
  {
    "episode": 7923,
    "reward": 89.920626,
    "length": 67,
    "time": 119029.005869,
    "actor_loss": -71.87591552734375,
    "critic_loss": 5.680915832519531,
    "ent_coef": 0.08001930266618729,
    "learning_rate": 0.001
  },
  {
    "episode": 7924,
    "reward": 90.070907,
    "length": 67,
    "time": 119040.745728,
    "actor_loss": -65.87274169921875,
    "critic_loss": 8.830270767211914,
    "ent_coef": 0.08181975036859512,
    "learning_rate": 0.001
  },
  {
    "episode": 7925,
    "reward": 88.160042,
    "length": 71,
    "time": 119054.158332,
    "actor_loss": -70.87957000732422,
    "critic_loss": 13.520297050476074,
    "ent_coef": 0.07662240415811539,
    "learning_rate": 0.001
  },
  {
    "episode": 7926,
    "reward": 89.158598,
    "length": 68,
    "time": 119066.334823,
    "actor_loss": -67.03070831298828,
    "critic_loss": 4.786277770996094,
    "ent_coef": 0.0727066844701767,
    "learning_rate": 0.001
  },
  {
    "episode": 7927,
    "reward": 89.908342,
    "length": 66,
    "time": 119079.059937,
    "actor_loss": -72.89987182617188,
    "critic_loss": 1.9382814168930054,
    "ent_coef": 0.07122176885604858,
    "learning_rate": 0.001
  },
  {
    "episode": 7928,
    "reward": 91.048997,
    "length": 62,
    "time": 119091.296369,
    "actor_loss": -63.80003356933594,
    "critic_loss": 24.483352661132812,
    "ent_coef": 0.0704624131321907,
    "learning_rate": 0.001
  },
  {
    "episode": 7929,
    "reward": 87.039376,
    "length": 71,
    "time": 119104.398133,
    "actor_loss": -64.26081848144531,
    "critic_loss": 18.940290451049805,
    "ent_coef": 0.06560970097780228,
    "learning_rate": 0.001
  },
  {
    "episode": 7930,
    "reward": 91.930596,
    "length": 60,
    "time": 119115.731283,
    "actor_loss": -69.02210998535156,
    "critic_loss": 3.679533004760742,
    "ent_coef": 0.06844429671764374,
    "learning_rate": 0.001
  },
  {
    "episode": 7931,
    "reward": 88.625008,
    "length": 69,
    "time": 119128.11819,
    "actor_loss": -69.67601013183594,
    "critic_loss": 8.62386703491211,
    "ent_coef": 0.06899659335613251,
    "learning_rate": 0.001
  },
  {
    "episode": 7932,
    "reward": 87.024358,
    "length": 82,
    "time": 119142.627547,
    "actor_loss": -68.04623413085938,
    "critic_loss": 19.421424865722656,
    "ent_coef": 0.07233242690563202,
    "learning_rate": 0.001
  },
  {
    "episode": 7933,
    "reward": 89.61947,
    "length": 62,
    "time": 119153.898583,
    "actor_loss": -64.78373718261719,
    "critic_loss": 10.000259399414062,
    "ent_coef": 0.0730283260345459,
    "learning_rate": 0.001
  },
  {
    "episode": 7934,
    "reward": 89.991839,
    "length": 68,
    "time": 119169.481045,
    "actor_loss": -73.58304595947266,
    "critic_loss": 19.59258270263672,
    "ent_coef": 0.07442952692508698,
    "learning_rate": 0.001
  },
  {
    "episode": 7935,
    "reward": 81.900687,
    "length": 81,
    "time": 119183.039211,
    "actor_loss": -65.2288589477539,
    "critic_loss": 42.44629669189453,
    "ent_coef": 0.0677657425403595,
    "learning_rate": 0.001
  },
  {
    "episode": 7936,
    "reward": 50.816848,
    "length": 130,
    "time": 119202.833685,
    "actor_loss": -70.49484252929688,
    "critic_loss": 13.409258842468262,
    "ent_coef": 0.05976327136158943,
    "learning_rate": 0.001
  },
  {
    "episode": 7937,
    "reward": 90.761103,
    "length": 63,
    "time": 119215.010226,
    "actor_loss": -71.42088317871094,
    "critic_loss": 8.835841178894043,
    "ent_coef": 0.061518408358097076,
    "learning_rate": 0.001
  },
  {
    "episode": 7938,
    "reward": 90.036962,
    "length": 68,
    "time": 119227.115147,
    "actor_loss": -70.09170532226562,
    "critic_loss": 27.881494522094727,
    "ent_coef": 0.06410742551088333,
    "learning_rate": 0.001
  },
  {
    "episode": 7939,
    "reward": -146.757977,
    "length": 83,
    "time": 119241.620819,
    "actor_loss": -63.21055603027344,
    "critic_loss": 15.888678550720215,
    "ent_coef": 0.06355081498622894,
    "learning_rate": 0.001
  },
  {
    "episode": 7940,
    "reward": 96.890105,
    "length": 65,
    "time": 119256.015853,
    "actor_loss": -70.24929809570312,
    "critic_loss": 4.827606678009033,
    "ent_coef": 0.0653250515460968,
    "learning_rate": 0.001
  },
  {
    "episode": 7941,
    "reward": 89.280557,
    "length": 69,
    "time": 119268.266942,
    "actor_loss": -70.84684753417969,
    "critic_loss": 3.0508525371551514,
    "ent_coef": 0.06605608761310577,
    "learning_rate": 0.001
  },
  {
    "episode": 7942,
    "reward": 91.307452,
    "length": 61,
    "time": 119280.166904,
    "actor_loss": -66.59815979003906,
    "critic_loss": 3.5351691246032715,
    "ent_coef": 0.066218800842762,
    "learning_rate": 0.001
  },
  {
    "episode": 7943,
    "reward": 89.448029,
    "length": 67,
    "time": 119292.858266,
    "actor_loss": -61.5155029296875,
    "critic_loss": 4.560476303100586,
    "ent_coef": 0.06734452396631241,
    "learning_rate": 0.001
  },
  {
    "episode": 7944,
    "reward": 91.23192,
    "length": 63,
    "time": 119304.302575,
    "actor_loss": -69.2831802368164,
    "critic_loss": 2.4674835205078125,
    "ent_coef": 0.0683177039027214,
    "learning_rate": 0.001
  },
  {
    "episode": 7945,
    "reward": 89.729099,
    "length": 64,
    "time": 119315.830439,
    "actor_loss": -73.93551635742188,
    "critic_loss": 8.524906158447266,
    "ent_coef": 0.06859514862298965,
    "learning_rate": 0.001
  },
  {
    "episode": 7946,
    "reward": 88.815561,
    "length": 69,
    "time": 119329.048334,
    "actor_loss": -67.5615463256836,
    "critic_loss": 13.526365280151367,
    "ent_coef": 0.0671280026435852,
    "learning_rate": 0.001
  },
  {
    "episode": 7947,
    "reward": 90.990173,
    "length": 62,
    "time": 119341.19162,
    "actor_loss": -68.53215789794922,
    "critic_loss": 7.232951641082764,
    "ent_coef": 0.06564002484083176,
    "learning_rate": 0.001
  },
  {
    "episode": 7948,
    "reward": 90.649571,
    "length": 62,
    "time": 119354.67926,
    "actor_loss": -67.33299255371094,
    "critic_loss": 11.661493301391602,
    "ent_coef": 0.06491118669509888,
    "learning_rate": 0.001
  },
  {
    "episode": 7949,
    "reward": 89.566636,
    "length": 66,
    "time": 119366.257387,
    "actor_loss": -69.3427963256836,
    "critic_loss": 2.6453447341918945,
    "ent_coef": 0.0627976730465889,
    "learning_rate": 0.001
  },
  {
    "episode": 7950,
    "reward": 89.498802,
    "length": 65,
    "time": 119377.635689,
    "actor_loss": -68.35440826416016,
    "critic_loss": 3.559079647064209,
    "ent_coef": 0.06327972561120987,
    "learning_rate": 0.001
  },
  {
    "episode": 7951,
    "reward": 90.352333,
    "length": 63,
    "time": 119390.042593,
    "actor_loss": -68.63734436035156,
    "critic_loss": 3.962535858154297,
    "ent_coef": 0.06525780260562897,
    "learning_rate": 0.001
  },
  {
    "episode": 7952,
    "reward": -140.182801,
    "length": 77,
    "time": 119403.135993,
    "actor_loss": -73.6911392211914,
    "critic_loss": 3.946442127227783,
    "ent_coef": 0.0675520971417427,
    "learning_rate": 0.001
  },
  {
    "episode": 7953,
    "reward": 95.816691,
    "length": 66,
    "time": 119415.289,
    "actor_loss": -67.31282043457031,
    "critic_loss": 311.54608154296875,
    "ent_coef": 0.0683530867099762,
    "learning_rate": 0.001
  },
  {
    "episode": 7954,
    "reward": 91.419085,
    "length": 62,
    "time": 119427.97436,
    "actor_loss": -68.43988037109375,
    "critic_loss": 6.371705532073975,
    "ent_coef": 0.07412862777709961,
    "learning_rate": 0.001
  },
  {
    "episode": 7955,
    "reward": 90.024089,
    "length": 64,
    "time": 119442.16057,
    "actor_loss": -64.99324035644531,
    "critic_loss": 28.998939514160156,
    "ent_coef": 0.07510305196046829,
    "learning_rate": 0.001
  },
  {
    "episode": 7956,
    "reward": 77.027443,
    "length": 142,
    "time": 119465.470287,
    "actor_loss": -69.58648681640625,
    "critic_loss": 2.655933380126953,
    "ent_coef": 0.07796533405780792,
    "learning_rate": 0.001
  },
  {
    "episode": 7957,
    "reward": 89.546776,
    "length": 64,
    "time": 119477.848377,
    "actor_loss": -72.55284881591797,
    "critic_loss": 563.1143798828125,
    "ent_coef": 0.07689893245697021,
    "learning_rate": 0.001
  },
  {
    "episode": 7958,
    "reward": 90.957027,
    "length": 63,
    "time": 119492.884629,
    "actor_loss": -68.74654388427734,
    "critic_loss": 4.031206130981445,
    "ent_coef": 0.07726896554231644,
    "learning_rate": 0.001
  },
  {
    "episode": 7959,
    "reward": 91.527033,
    "length": 62,
    "time": 119505.945312,
    "actor_loss": -75.24544525146484,
    "critic_loss": 67.59442138671875,
    "ent_coef": 0.07536902278661728,
    "learning_rate": 0.001
  },
  {
    "episode": 7960,
    "reward": 87.802042,
    "length": 73,
    "time": 119518.689448,
    "actor_loss": -65.56874084472656,
    "critic_loss": 20.813310623168945,
    "ent_coef": 0.07202791422605515,
    "learning_rate": 0.001
  },
  {
    "episode": 7961,
    "reward": 91.257949,
    "length": 63,
    "time": 119530.436077,
    "actor_loss": -72.38381958007812,
    "critic_loss": 4.962161064147949,
    "ent_coef": 0.07652516663074493,
    "learning_rate": 0.001
  },
  {
    "episode": 7962,
    "reward": 88.590953,
    "length": 72,
    "time": 119545.089468,
    "actor_loss": -67.95801544189453,
    "critic_loss": 5.733672142028809,
    "ent_coef": 0.07704741507768631,
    "learning_rate": 0.001
  },
  {
    "episode": 7963,
    "reward": 91.118593,
    "length": 62,
    "time": 119556.10246,
    "actor_loss": -64.07967376708984,
    "critic_loss": 17.162349700927734,
    "ent_coef": 0.07471376657485962,
    "learning_rate": 0.001
  },
  {
    "episode": 7964,
    "reward": 86.973562,
    "length": 72,
    "time": 119570.450882,
    "actor_loss": -66.41943359375,
    "critic_loss": 5.208096504211426,
    "ent_coef": 0.06805265694856644,
    "learning_rate": 0.001
  },
  {
    "episode": 7965,
    "reward": 87.909798,
    "length": 72,
    "time": 119583.151025,
    "actor_loss": -67.45828247070312,
    "critic_loss": 4.987926959991455,
    "ent_coef": 0.06661587208509445,
    "learning_rate": 0.001
  },
  {
    "episode": 7966,
    "reward": 89.413005,
    "length": 67,
    "time": 119594.889505,
    "actor_loss": -77.04830932617188,
    "critic_loss": 19.467113494873047,
    "ent_coef": 0.06671428680419922,
    "learning_rate": 0.001
  },
  {
    "episode": 7967,
    "reward": 89.249853,
    "length": 65,
    "time": 119606.709394,
    "actor_loss": -69.23243713378906,
    "critic_loss": 11.832743644714355,
    "ent_coef": 0.06133733317255974,
    "learning_rate": 0.001
  },
  {
    "episode": 7968,
    "reward": 89.182822,
    "length": 66,
    "time": 119619.162414,
    "actor_loss": -66.35111999511719,
    "critic_loss": 24.48391342163086,
    "ent_coef": 0.05870472267270088,
    "learning_rate": 0.001
  },
  {
    "episode": 7969,
    "reward": 90.808311,
    "length": 61,
    "time": 119630.615081,
    "actor_loss": -64.71802520751953,
    "critic_loss": 4.892118453979492,
    "ent_coef": 0.057547103613615036,
    "learning_rate": 0.001
  },
  {
    "episode": 7970,
    "reward": 89.29612,
    "length": 66,
    "time": 119643.6816,
    "actor_loss": -65.25527954101562,
    "critic_loss": 122.86048889160156,
    "ent_coef": 0.05491349846124649,
    "learning_rate": 0.001
  },
  {
    "episode": 7971,
    "reward": 88.018503,
    "length": 66,
    "time": 119658.837804,
    "actor_loss": -69.40902709960938,
    "critic_loss": 2.63810396194458,
    "ent_coef": 0.05391515791416168,
    "learning_rate": 0.001
  },
  {
    "episode": 7972,
    "reward": 90.514617,
    "length": 63,
    "time": 119671.060574,
    "actor_loss": -68.66978454589844,
    "critic_loss": 130.36184692382812,
    "ent_coef": 0.05557027459144592,
    "learning_rate": 0.001
  },
  {
    "episode": 7973,
    "reward": 91.631792,
    "length": 63,
    "time": 119684.792472,
    "actor_loss": -68.20050811767578,
    "critic_loss": 3.205848455429077,
    "ent_coef": 0.060995914041996,
    "learning_rate": 0.001
  },
  {
    "episode": 7974,
    "reward": 89.630225,
    "length": 66,
    "time": 119699.627268,
    "actor_loss": -66.7214126586914,
    "critic_loss": 8.052478790283203,
    "ent_coef": 0.06411424279212952,
    "learning_rate": 0.001
  },
  {
    "episode": 7975,
    "reward": 89.616186,
    "length": 63,
    "time": 119713.277326,
    "actor_loss": -69.06230163574219,
    "critic_loss": 9.800443649291992,
    "ent_coef": 0.06400062143802643,
    "learning_rate": 0.001
  },
  {
    "episode": 7976,
    "reward": 91.821146,
    "length": 60,
    "time": 119724.141916,
    "actor_loss": -71.19173431396484,
    "critic_loss": 61.14366149902344,
    "ent_coef": 0.066965751349926,
    "learning_rate": 0.001
  },
  {
    "episode": 7977,
    "reward": 91.206038,
    "length": 61,
    "time": 119735.516731,
    "actor_loss": -68.08582305908203,
    "critic_loss": 15.366130828857422,
    "ent_coef": 0.07182712107896805,
    "learning_rate": 0.001
  },
  {
    "episode": 7978,
    "reward": 82.141126,
    "length": 83,
    "time": 119751.549268,
    "actor_loss": -70.46980285644531,
    "critic_loss": 10.526391983032227,
    "ent_coef": 0.07769033312797546,
    "learning_rate": 0.001
  },
  {
    "episode": 7979,
    "reward": 91.502601,
    "length": 62,
    "time": 119765.90229,
    "actor_loss": -63.63005828857422,
    "critic_loss": 9.105684280395508,
    "ent_coef": 0.07932853698730469,
    "learning_rate": 0.001
  },
  {
    "episode": 7980,
    "reward": 91.666796,
    "length": 60,
    "time": 119776.769694,
    "actor_loss": -72.45203399658203,
    "critic_loss": 1.5620808601379395,
    "ent_coef": 0.07865787297487259,
    "learning_rate": 0.001
  },
  {
    "episode": 7981,
    "reward": 90.86814,
    "length": 62,
    "time": 119789.217109,
    "actor_loss": -69.04953002929688,
    "critic_loss": 6.48532772064209,
    "ent_coef": 0.07588479667901993,
    "learning_rate": 0.001
  },
  {
    "episode": 7982,
    "reward": 91.799697,
    "length": 61,
    "time": 119801.674042,
    "actor_loss": -70.38581848144531,
    "critic_loss": 4.128807067871094,
    "ent_coef": 0.07537594437599182,
    "learning_rate": 0.001
  },
  {
    "episode": 7983,
    "reward": 88.074882,
    "length": 69,
    "time": 119814.70014,
    "actor_loss": -65.69249725341797,
    "critic_loss": 20.03199005126953,
    "ent_coef": 0.07287278771400452,
    "learning_rate": 0.001
  },
  {
    "episode": 7984,
    "reward": 90.285865,
    "length": 65,
    "time": 119826.134434,
    "actor_loss": -72.84517669677734,
    "critic_loss": 2.7961349487304688,
    "ent_coef": 0.07077794522047043,
    "learning_rate": 0.001
  },
  {
    "episode": 7985,
    "reward": 81.542974,
    "length": 79,
    "time": 119841.241495,
    "actor_loss": -78.54913330078125,
    "critic_loss": 85.14086151123047,
    "ent_coef": 0.06317899376153946,
    "learning_rate": 0.001
  },
  {
    "episode": 7986,
    "reward": 87.556702,
    "length": 68,
    "time": 119853.33236,
    "actor_loss": -66.17835235595703,
    "critic_loss": 34.724281311035156,
    "ent_coef": 0.060375016182661057,
    "learning_rate": 0.001
  },
  {
    "episode": 7987,
    "reward": 81.162391,
    "length": 78,
    "time": 119868.19544,
    "actor_loss": -70.64122009277344,
    "critic_loss": 2.3341288566589355,
    "ent_coef": 0.0555453822016716,
    "learning_rate": 0.001
  },
  {
    "episode": 7988,
    "reward": 86.162646,
    "length": 71,
    "time": 119882.922398,
    "actor_loss": -67.54824829101562,
    "critic_loss": 12.970381736755371,
    "ent_coef": 0.05155603587627411,
    "learning_rate": 0.001
  },
  {
    "episode": 7989,
    "reward": 89.371116,
    "length": 67,
    "time": 119895.58652,
    "actor_loss": -72.86322021484375,
    "critic_loss": 2.7096920013427734,
    "ent_coef": 0.05348876491189003,
    "learning_rate": 0.001
  },
  {
    "episode": 7990,
    "reward": 90.776591,
    "length": 63,
    "time": 119907.134589,
    "actor_loss": -63.42042922973633,
    "critic_loss": 4.185158729553223,
    "ent_coef": 0.05429637432098389,
    "learning_rate": 0.001
  },
  {
    "episode": 7991,
    "reward": 80.437133,
    "length": 81,
    "time": 119924.467555,
    "actor_loss": -68.32723236083984,
    "critic_loss": 25.897544860839844,
    "ent_coef": 0.0510919913649559,
    "learning_rate": 0.001
  },
  {
    "episode": 7992,
    "reward": 88.394892,
    "length": 65,
    "time": 119936.741735,
    "actor_loss": -71.27554321289062,
    "critic_loss": 4.099143028259277,
    "ent_coef": 0.05105757713317871,
    "learning_rate": 0.001
  },
  {
    "episode": 7993,
    "reward": 89.271823,
    "length": 70,
    "time": 119949.693216,
    "actor_loss": -71.35200500488281,
    "critic_loss": 8.877422332763672,
    "ent_coef": 0.05334211513400078,
    "learning_rate": 0.001
  },
  {
    "episode": 7994,
    "reward": 91.055053,
    "length": 63,
    "time": 119962.280417,
    "actor_loss": -67.14524841308594,
    "critic_loss": 42.27373504638672,
    "ent_coef": 0.05696091055870056,
    "learning_rate": 0.001
  },
  {
    "episode": 7995,
    "reward": 91.076715,
    "length": 66,
    "time": 119976.314757,
    "actor_loss": -73.87299346923828,
    "critic_loss": 14.614720344543457,
    "ent_coef": 0.06475915759801865,
    "learning_rate": 0.001
  },
  {
    "episode": 7996,
    "reward": 92.12661,
    "length": 61,
    "time": 119988.357674,
    "actor_loss": -73.31381225585938,
    "critic_loss": 1.449508547782898,
    "ent_coef": 0.06941522657871246,
    "learning_rate": 0.001
  },
  {
    "episode": 7997,
    "reward": 89.465485,
    "length": 68,
    "time": 120000.507484,
    "actor_loss": -65.41236877441406,
    "critic_loss": 2.535508394241333,
    "ent_coef": 0.07220685482025146,
    "learning_rate": 0.001
  },
  {
    "episode": 7998,
    "reward": 87.881684,
    "length": 69,
    "time": 120013.750691,
    "actor_loss": -68.08656311035156,
    "critic_loss": 49.29973220825195,
    "ent_coef": 0.07021801918745041,
    "learning_rate": 0.001
  },
  {
    "episode": 7999,
    "reward": -38.608342,
    "length": 238,
    "time": 120047.751191,
    "actor_loss": -71.2755126953125,
    "critic_loss": 2.742628574371338,
    "ent_coef": 0.057997554540634155,
    "learning_rate": 0.001
  },
  {
    "episode": 8000,
    "reward": 87.851852,
    "length": 67,
    "time": 120060.545823,
    "actor_loss": -70.25535583496094,
    "critic_loss": 3.3455333709716797,
    "ent_coef": 0.05760541930794716,
    "learning_rate": 0.001
  },
  {
    "episode": 8001,
    "reward": 90.339745,
    "length": 65,
    "time": 120072.52033,
    "actor_loss": -68.27530670166016,
    "critic_loss": 2.6185686588287354,
    "ent_coef": 0.061463613063097,
    "learning_rate": 0.001
  },
  {
    "episode": 8002,
    "reward": 91.681814,
    "length": 59,
    "time": 120084.588939,
    "actor_loss": -68.67548370361328,
    "critic_loss": 5.699597358703613,
    "ent_coef": 0.06575939804315567,
    "learning_rate": 0.001
  },
  {
    "episode": 8003,
    "reward": 90.035271,
    "length": 67,
    "time": 120096.327264,
    "actor_loss": -66.7879409790039,
    "critic_loss": 4.106605529785156,
    "ent_coef": 0.06711329519748688,
    "learning_rate": 0.001
  },
  {
    "episode": 8004,
    "reward": 89.672651,
    "length": 68,
    "time": 120108.417791,
    "actor_loss": -63.68129348754883,
    "critic_loss": 2.854531764984131,
    "ent_coef": 0.06660699099302292,
    "learning_rate": 0.001
  },
  {
    "episode": 8005,
    "reward": 89.508216,
    "length": 66,
    "time": 120120.842025,
    "actor_loss": -69.32054138183594,
    "critic_loss": 2.7898647785186768,
    "ent_coef": 0.06455547362565994,
    "learning_rate": 0.001
  },
  {
    "episode": 8006,
    "reward": 92.285622,
    "length": 60,
    "time": 120132.867861,
    "actor_loss": -72.27864074707031,
    "critic_loss": 10.72996711730957,
    "ent_coef": 0.06854863464832306,
    "learning_rate": 0.001
  },
  {
    "episode": 8007,
    "reward": 90.284221,
    "length": 66,
    "time": 120145.252999,
    "actor_loss": -62.61687088012695,
    "critic_loss": 29.161293029785156,
    "ent_coef": 0.07264959067106247,
    "learning_rate": 0.001
  },
  {
    "episode": 8008,
    "reward": 89.489931,
    "length": 65,
    "time": 120157.437142,
    "actor_loss": -71.22103881835938,
    "critic_loss": 5.527292728424072,
    "ent_coef": 0.07167013734579086,
    "learning_rate": 0.001
  },
  {
    "episode": 8009,
    "reward": 88.160947,
    "length": 71,
    "time": 120171.161823,
    "actor_loss": -74.30828094482422,
    "critic_loss": 2.256895065307617,
    "ent_coef": 0.06993784010410309,
    "learning_rate": 0.001
  },
  {
    "episode": 8010,
    "reward": 90.037788,
    "length": 66,
    "time": 120182.884743,
    "actor_loss": -70.13203430175781,
    "critic_loss": 1.7539833784103394,
    "ent_coef": 0.06912732869386673,
    "learning_rate": 0.001
  },
  {
    "episode": 8011,
    "reward": 89.446285,
    "length": 64,
    "time": 120195.827815,
    "actor_loss": -73.98039245605469,
    "critic_loss": 6.188297271728516,
    "ent_coef": 0.0682375356554985,
    "learning_rate": 0.001
  },
  {
    "episode": 8012,
    "reward": 90.114733,
    "length": 65,
    "time": 120210.091034,
    "actor_loss": -77.02166748046875,
    "critic_loss": 83.77978515625,
    "ent_coef": 0.06825128197669983,
    "learning_rate": 0.001
  },
  {
    "episode": 8013,
    "reward": 87.352823,
    "length": 72,
    "time": 120224.152239,
    "actor_loss": -75.42699432373047,
    "critic_loss": 7.963133335113525,
    "ent_coef": 0.06534307450056076,
    "learning_rate": 0.001
  },
  {
    "episode": 8014,
    "reward": 88.214335,
    "length": 68,
    "time": 120236.125232,
    "actor_loss": -68.19902038574219,
    "critic_loss": 2.3851537704467773,
    "ent_coef": 0.06310778856277466,
    "learning_rate": 0.001
  },
  {
    "episode": 8015,
    "reward": 86.321235,
    "length": 75,
    "time": 120249.320033,
    "actor_loss": -68.28221893310547,
    "critic_loss": 4.59480619430542,
    "ent_coef": 0.059511616826057434,
    "learning_rate": 0.001
  },
  {
    "episode": 8016,
    "reward": 76.541502,
    "length": 87,
    "time": 120264.25416,
    "actor_loss": -64.36775207519531,
    "critic_loss": 3.2606749534606934,
    "ent_coef": 0.05206577479839325,
    "learning_rate": 0.001
  },
  {
    "episode": 8017,
    "reward": 92.64479,
    "length": 58,
    "time": 120276.620999,
    "actor_loss": -67.73419189453125,
    "critic_loss": 4.022675514221191,
    "ent_coef": 0.05538259819149971,
    "learning_rate": 0.001
  },
  {
    "episode": 8018,
    "reward": 89.513035,
    "length": 67,
    "time": 120288.36789,
    "actor_loss": -70.83152770996094,
    "critic_loss": 3.388810873031616,
    "ent_coef": 0.056566379964351654,
    "learning_rate": 0.001
  },
  {
    "episode": 8019,
    "reward": 88.197215,
    "length": 71,
    "time": 120300.429327,
    "actor_loss": -70.45659637451172,
    "critic_loss": 2.3677361011505127,
    "ent_coef": 0.059084389358758926,
    "learning_rate": 0.001
  },
  {
    "episode": 8020,
    "reward": 90.414267,
    "length": 63,
    "time": 120312.121239,
    "actor_loss": -71.09708404541016,
    "critic_loss": 2.349703311920166,
    "ent_coef": 0.0598871074616909,
    "learning_rate": 0.001
  },
  {
    "episode": 8021,
    "reward": 89.74624,
    "length": 65,
    "time": 120324.576304,
    "actor_loss": -69.4697265625,
    "critic_loss": 5.529695510864258,
    "ent_coef": 0.06242375075817108,
    "learning_rate": 0.001
  },
  {
    "episode": 8022,
    "reward": 90.951164,
    "length": 62,
    "time": 120338.656968,
    "actor_loss": -66.67932891845703,
    "critic_loss": 46.93674087524414,
    "ent_coef": 0.06575614213943481,
    "learning_rate": 0.001
  },
  {
    "episode": 8023,
    "reward": 86.838361,
    "length": 75,
    "time": 120352.744056,
    "actor_loss": -71.93721008300781,
    "critic_loss": 2.472288131713867,
    "ent_coef": 0.0658014640212059,
    "learning_rate": 0.001
  },
  {
    "episode": 8024,
    "reward": 90.436181,
    "length": 63,
    "time": 120364.859757,
    "actor_loss": -70.61929321289062,
    "critic_loss": 15.197879791259766,
    "ent_coef": 0.06565656512975693,
    "learning_rate": 0.001
  },
  {
    "episode": 8025,
    "reward": 91.189193,
    "length": 61,
    "time": 120375.715363,
    "actor_loss": -67.7812271118164,
    "critic_loss": 5.15305233001709,
    "ent_coef": 0.06831841915845871,
    "learning_rate": 0.001
  },
  {
    "episode": 8026,
    "reward": 89.817117,
    "length": 65,
    "time": 120387.377616,
    "actor_loss": -63.72174835205078,
    "critic_loss": 2.764126777648926,
    "ent_coef": 0.06801990419626236,
    "learning_rate": 0.001
  },
  {
    "episode": 8027,
    "reward": 91.425341,
    "length": 62,
    "time": 120398.517912,
    "actor_loss": -74.12413787841797,
    "critic_loss": 14.051109313964844,
    "ent_coef": 0.06900700181722641,
    "learning_rate": 0.001
  },
  {
    "episode": 8028,
    "reward": 89.388856,
    "length": 64,
    "time": 120412.585974,
    "actor_loss": -65.94549560546875,
    "critic_loss": 2.694780111312866,
    "ent_coef": 0.07090306282043457,
    "learning_rate": 0.001
  },
  {
    "episode": 8029,
    "reward": 89.142646,
    "length": 67,
    "time": 120425.695447,
    "actor_loss": -68.3522720336914,
    "critic_loss": 4.737612724304199,
    "ent_coef": 0.07570075243711472,
    "learning_rate": 0.001
  },
  {
    "episode": 8030,
    "reward": 88.169816,
    "length": 66,
    "time": 120439.865571,
    "actor_loss": -71.32907104492188,
    "critic_loss": 2.3518083095550537,
    "ent_coef": 0.07608801126480103,
    "learning_rate": 0.001
  },
  {
    "episode": 8031,
    "reward": 89.322163,
    "length": 66,
    "time": 120452.670934,
    "actor_loss": -69.52384185791016,
    "critic_loss": 446.42730712890625,
    "ent_coef": 0.07404502481222153,
    "learning_rate": 0.001
  },
  {
    "episode": 8032,
    "reward": 90.086771,
    "length": 63,
    "time": 120466.19206,
    "actor_loss": -69.98533630371094,
    "critic_loss": 1.6236172914505005,
    "ent_coef": 0.07513919472694397,
    "learning_rate": 0.001
  },
  {
    "episode": 8033,
    "reward": 89.797314,
    "length": 68,
    "time": 120479.056821,
    "actor_loss": -72.40605163574219,
    "critic_loss": 4.265340805053711,
    "ent_coef": 0.07655294239521027,
    "learning_rate": 0.001
  },
  {
    "episode": 8034,
    "reward": 83.829027,
    "length": 75,
    "time": 120492.777277,
    "actor_loss": -63.48694610595703,
    "critic_loss": 8.738525390625,
    "ent_coef": 0.07032549381256104,
    "learning_rate": 0.001
  },
  {
    "episode": 8035,
    "reward": 82.39552,
    "length": 77,
    "time": 120506.744628,
    "actor_loss": -68.92953491210938,
    "critic_loss": 4.731026649475098,
    "ent_coef": 0.06421323865652084,
    "learning_rate": 0.001
  },
  {
    "episode": 8036,
    "reward": 87.854899,
    "length": 69,
    "time": 120519.138376,
    "actor_loss": -72.48640441894531,
    "critic_loss": 4.462315082550049,
    "ent_coef": 0.0589430145919323,
    "learning_rate": 0.001
  },
  {
    "episode": 8037,
    "reward": 86.972566,
    "length": 70,
    "time": 120531.300417,
    "actor_loss": -64.70783233642578,
    "critic_loss": 3.4953932762145996,
    "ent_coef": 0.05704674869775772,
    "learning_rate": 0.001
  },
  {
    "episode": 8038,
    "reward": 84.39964,
    "length": 85,
    "time": 120545.845799,
    "actor_loss": -69.85711669921875,
    "critic_loss": 34.27043914794922,
    "ent_coef": 0.05600030720233917,
    "learning_rate": 0.001
  },
  {
    "episode": 8039,
    "reward": 88.846567,
    "length": 64,
    "time": 120559.278441,
    "actor_loss": -69.1192626953125,
    "critic_loss": 13.011894226074219,
    "ent_coef": 0.05792669206857681,
    "learning_rate": 0.001
  },
  {
    "episode": 8040,
    "reward": 91.021751,
    "length": 62,
    "time": 120571.497783,
    "actor_loss": -68.91201782226562,
    "critic_loss": 4.919849395751953,
    "ent_coef": 0.06282848119735718,
    "learning_rate": 0.001
  },
  {
    "episode": 8041,
    "reward": 90.848761,
    "length": 62,
    "time": 120584.79085,
    "actor_loss": -67.00080871582031,
    "critic_loss": 2.8559367656707764,
    "ent_coef": 0.06617822498083115,
    "learning_rate": 0.001
  },
  {
    "episode": 8042,
    "reward": 91.080743,
    "length": 63,
    "time": 120598.457794,
    "actor_loss": -67.95732116699219,
    "critic_loss": 109.60435485839844,
    "ent_coef": 0.07147463411092758,
    "learning_rate": 0.001
  },
  {
    "episode": 8043,
    "reward": 90.254956,
    "length": 63,
    "time": 120609.977679,
    "actor_loss": -71.26664733886719,
    "critic_loss": 2.507711887359619,
    "ent_coef": 0.07305479794740677,
    "learning_rate": 0.001
  },
  {
    "episode": 8044,
    "reward": 90.754603,
    "length": 66,
    "time": 120622.389904,
    "actor_loss": -72.98959350585938,
    "critic_loss": 4.24172830581665,
    "ent_coef": 0.07431142032146454,
    "learning_rate": 0.001
  },
  {
    "episode": 8045,
    "reward": 88.587742,
    "length": 71,
    "time": 120635.542625,
    "actor_loss": -63.70330810546875,
    "critic_loss": 164.4178466796875,
    "ent_coef": 0.07963745296001434,
    "learning_rate": 0.001
  },
  {
    "episode": 8046,
    "reward": 89.560191,
    "length": 65,
    "time": 120647.117044,
    "actor_loss": -69.10479736328125,
    "critic_loss": 2.967705249786377,
    "ent_coef": 0.08234815299510956,
    "learning_rate": 0.001
  },
  {
    "episode": 8047,
    "reward": 90.193232,
    "length": 67,
    "time": 120660.698514,
    "actor_loss": -68.53018188476562,
    "critic_loss": 4.241445541381836,
    "ent_coef": 0.08675211668014526,
    "learning_rate": 0.001
  },
  {
    "episode": 8048,
    "reward": 90.983955,
    "length": 62,
    "time": 120673.15722,
    "actor_loss": -65.359619140625,
    "critic_loss": 20.25902557373047,
    "ent_coef": 0.08810389041900635,
    "learning_rate": 0.001
  },
  {
    "episode": 8049,
    "reward": 89.135115,
    "length": 68,
    "time": 120686.007617,
    "actor_loss": -68.2175521850586,
    "critic_loss": 6.99289608001709,
    "ent_coef": 0.08941111713647842,
    "learning_rate": 0.001
  },
  {
    "episode": 8050,
    "reward": 89.751486,
    "length": 63,
    "time": 120699.32131,
    "actor_loss": -67.60791015625,
    "critic_loss": 6.613686561584473,
    "ent_coef": 0.08803890645503998,
    "learning_rate": 0.001
  },
  {
    "episode": 8051,
    "reward": 86.338377,
    "length": 70,
    "time": 120712.827811,
    "actor_loss": -65.73782348632812,
    "critic_loss": 2.564492702484131,
    "ent_coef": 0.08237066119909286,
    "learning_rate": 0.001
  },
  {
    "episode": 8052,
    "reward": 87.960093,
    "length": 71,
    "time": 120726.007146,
    "actor_loss": -68.105224609375,
    "critic_loss": 19.856338500976562,
    "ent_coef": 0.07768159359693527,
    "learning_rate": 0.001
  },
  {
    "episode": 8053,
    "reward": 89.250869,
    "length": 64,
    "time": 120737.561078,
    "actor_loss": -66.80812072753906,
    "critic_loss": 2.595170736312866,
    "ent_coef": 0.07513697445392609,
    "learning_rate": 0.001
  },
  {
    "episode": 8054,
    "reward": 87.6826,
    "length": 69,
    "time": 120749.604766,
    "actor_loss": -71.38929748535156,
    "critic_loss": 9.760290145874023,
    "ent_coef": 0.07383374869823456,
    "learning_rate": 0.001
  },
  {
    "episode": 8055,
    "reward": 88.002034,
    "length": 67,
    "time": 120764.972391,
    "actor_loss": -67.53329467773438,
    "critic_loss": 29.1470947265625,
    "ent_coef": 0.07358691096305847,
    "learning_rate": 0.001
  },
  {
    "episode": 8056,
    "reward": 85.939639,
    "length": 72,
    "time": 120781.16251,
    "actor_loss": -69.98194885253906,
    "critic_loss": 6.591575622558594,
    "ent_coef": 0.0677870362997055,
    "learning_rate": 0.001
  },
  {
    "episode": 8057,
    "reward": 88.101899,
    "length": 66,
    "time": 120793.433729,
    "actor_loss": -66.16773986816406,
    "critic_loss": 3.958395481109619,
    "ent_coef": 0.06606199592351913,
    "learning_rate": 0.001
  },
  {
    "episode": 8058,
    "reward": 77.908898,
    "length": 82,
    "time": 120809.466668,
    "actor_loss": -64.64228057861328,
    "critic_loss": 4.390249252319336,
    "ent_coef": 0.06168125197291374,
    "learning_rate": 0.001
  },
  {
    "episode": 8059,
    "reward": 89.897937,
    "length": 63,
    "time": 120821.700203,
    "actor_loss": -67.38298034667969,
    "critic_loss": 14.211248397827148,
    "ent_coef": 0.06288401782512665,
    "learning_rate": 0.001
  },
  {
    "episode": 8060,
    "reward": 90.490616,
    "length": 63,
    "time": 120835.14504,
    "actor_loss": -67.77020263671875,
    "critic_loss": 3.939053773880005,
    "ent_coef": 0.06554592400789261,
    "learning_rate": 0.001
  },
  {
    "episode": 8061,
    "reward": 86.915332,
    "length": 74,
    "time": 120849.662018,
    "actor_loss": -69.14059448242188,
    "critic_loss": 2.802955150604248,
    "ent_coef": 0.06651213020086288,
    "learning_rate": 0.001
  },
  {
    "episode": 8062,
    "reward": 88.618989,
    "length": 69,
    "time": 120862.539035,
    "actor_loss": -70.85992431640625,
    "critic_loss": 5.104541778564453,
    "ent_coef": 0.06648366898298264,
    "learning_rate": 0.001
  },
  {
    "episode": 8063,
    "reward": 88.475343,
    "length": 71,
    "time": 120876.34021,
    "actor_loss": -76.29417419433594,
    "critic_loss": 9.893606185913086,
    "ent_coef": 0.06922559440135956,
    "learning_rate": 0.001
  },
  {
    "episode": 8064,
    "reward": 86.009681,
    "length": 76,
    "time": 120889.488746,
    "actor_loss": -68.39537048339844,
    "critic_loss": 33.066200256347656,
    "ent_coef": 0.06713613122701645,
    "learning_rate": 0.001
  },
  {
    "episode": 8065,
    "reward": 89.981283,
    "length": 66,
    "time": 120903.122568,
    "actor_loss": -72.72822570800781,
    "critic_loss": 13.100275039672852,
    "ent_coef": 0.07092586904764175,
    "learning_rate": 0.001
  },
  {
    "episode": 8066,
    "reward": 88.279893,
    "length": 77,
    "time": 120917.722046,
    "actor_loss": -72.45745849609375,
    "critic_loss": 2.5964369773864746,
    "ent_coef": 0.07633350789546967,
    "learning_rate": 0.001
  },
  {
    "episode": 8067,
    "reward": 88.221791,
    "length": 68,
    "time": 120930.974865,
    "actor_loss": -73.98921203613281,
    "critic_loss": 8.487518310546875,
    "ent_coef": 0.07420436292886734,
    "learning_rate": 0.001
  },
  {
    "episode": 8068,
    "reward": 71.285268,
    "length": 95,
    "time": 120948.387419,
    "actor_loss": -67.88211822509766,
    "critic_loss": 30.133934020996094,
    "ent_coef": 0.06314481049776077,
    "learning_rate": 0.001
  },
  {
    "episode": 8069,
    "reward": 88.798563,
    "length": 69,
    "time": 120960.861507,
    "actor_loss": -75.06137084960938,
    "critic_loss": 6.327749252319336,
    "ent_coef": 0.061939988285303116,
    "learning_rate": 0.001
  },
  {
    "episode": 8070,
    "reward": 86.584039,
    "length": 75,
    "time": 120975.623466,
    "actor_loss": -67.53499603271484,
    "critic_loss": 8.378690719604492,
    "ent_coef": 0.061479851603507996,
    "learning_rate": 0.001
  },
  {
    "episode": 8071,
    "reward": 89.077418,
    "length": 64,
    "time": 120988.281076,
    "actor_loss": -73.30231475830078,
    "critic_loss": 54.03681564331055,
    "ent_coef": 0.06480570137500763,
    "learning_rate": 0.001
  },
  {
    "episode": 8072,
    "reward": 88.589148,
    "length": 65,
    "time": 121002.154747,
    "actor_loss": -69.15890502929688,
    "critic_loss": 87.736083984375,
    "ent_coef": 0.06763190031051636,
    "learning_rate": 0.001
  },
  {
    "episode": 8073,
    "reward": 91.143575,
    "length": 60,
    "time": 121016.640258,
    "actor_loss": -68.29878234863281,
    "critic_loss": 3.791612148284912,
    "ent_coef": 0.07083731144666672,
    "learning_rate": 0.001
  },
  {
    "episode": 8074,
    "reward": 89.41853,
    "length": 66,
    "time": 121030.602853,
    "actor_loss": -73.98857116699219,
    "critic_loss": 51.787322998046875,
    "ent_coef": 0.07665550708770752,
    "learning_rate": 0.001
  },
  {
    "episode": 8075,
    "reward": 87.350701,
    "length": 67,
    "time": 121043.775647,
    "actor_loss": -69.71795654296875,
    "critic_loss": 4.814054012298584,
    "ent_coef": 0.07496237009763718,
    "learning_rate": 0.001
  },
  {
    "episode": 8076,
    "reward": 89.048693,
    "length": 66,
    "time": 121056.332802,
    "actor_loss": -72.45576477050781,
    "critic_loss": 3.9103143215179443,
    "ent_coef": 0.0749560222029686,
    "learning_rate": 0.001
  },
  {
    "episode": 8077,
    "reward": 88.767296,
    "length": 65,
    "time": 121068.134382,
    "actor_loss": -74.16278839111328,
    "critic_loss": 2.328237771987915,
    "ent_coef": 0.07666898518800735,
    "learning_rate": 0.001
  },
  {
    "episode": 8078,
    "reward": 89.945093,
    "length": 65,
    "time": 121083.183226,
    "actor_loss": -73.01387023925781,
    "critic_loss": 7.425424575805664,
    "ent_coef": 0.07874073088169098,
    "learning_rate": 0.001
  },
  {
    "episode": 8079,
    "reward": 91.377531,
    "length": 61,
    "time": 121095.041544,
    "actor_loss": -66.19746398925781,
    "critic_loss": 2.916513442993164,
    "ent_coef": 0.08049003779888153,
    "learning_rate": 0.001
  },
  {
    "episode": 8080,
    "reward": 86.994537,
    "length": 67,
    "time": 121107.340595,
    "actor_loss": -74.08810424804688,
    "critic_loss": 10.507831573486328,
    "ent_coef": 0.08037250488996506,
    "learning_rate": 0.001
  },
  {
    "episode": 8081,
    "reward": 87.464757,
    "length": 67,
    "time": 121122.972986,
    "actor_loss": -69.62353515625,
    "critic_loss": 32.926143646240234,
    "ent_coef": 0.08149240165948868,
    "learning_rate": 0.001
  },
  {
    "episode": 8082,
    "reward": 87.097095,
    "length": 68,
    "time": 121135.90277,
    "actor_loss": -67.87507629394531,
    "critic_loss": 19.927001953125,
    "ent_coef": 0.0794544517993927,
    "learning_rate": 0.001
  },
  {
    "episode": 8083,
    "reward": 81.781311,
    "length": 78,
    "time": 121151.027223,
    "actor_loss": -67.0982666015625,
    "critic_loss": 5.658472537994385,
    "ent_coef": 0.07680132985115051,
    "learning_rate": 0.001
  },
  {
    "episode": 8084,
    "reward": 90.124802,
    "length": 62,
    "time": 121162.066623,
    "actor_loss": -72.24305725097656,
    "critic_loss": 3.526772975921631,
    "ent_coef": 0.07884671539068222,
    "learning_rate": 0.001
  },
  {
    "episode": 8085,
    "reward": 89.151938,
    "length": 69,
    "time": 121174.174645,
    "actor_loss": -63.9521598815918,
    "critic_loss": 47.925750732421875,
    "ent_coef": 0.0788164734840393,
    "learning_rate": 0.001
  },
  {
    "episode": 8086,
    "reward": 89.990889,
    "length": 63,
    "time": 121186.202287,
    "actor_loss": -64.0198974609375,
    "critic_loss": 3.264258623123169,
    "ent_coef": 0.07997424900531769,
    "learning_rate": 0.001
  },
  {
    "episode": 8087,
    "reward": 90.352424,
    "length": 64,
    "time": 121198.652857,
    "actor_loss": -61.7462158203125,
    "critic_loss": 14.8792724609375,
    "ent_coef": 0.0799364522099495,
    "learning_rate": 0.001
  },
  {
    "episode": 8088,
    "reward": 85.042345,
    "length": 78,
    "time": 121212.779882,
    "actor_loss": -71.25358581542969,
    "critic_loss": 4.508241176605225,
    "ent_coef": 0.07454527914524078,
    "learning_rate": 0.001
  },
  {
    "episode": 8089,
    "reward": 82.70975,
    "length": 78,
    "time": 121227.148826,
    "actor_loss": -74.77108764648438,
    "critic_loss": 6.941461563110352,
    "ent_coef": 0.06598467379808426,
    "learning_rate": 0.001
  },
  {
    "episode": 8090,
    "reward": 86.354594,
    "length": 71,
    "time": 121243.00359,
    "actor_loss": -69.58172607421875,
    "critic_loss": 3.9616470336914062,
    "ent_coef": 0.0629122406244278,
    "learning_rate": 0.001
  },
  {
    "episode": 8091,
    "reward": 90.813101,
    "length": 62,
    "time": 121254.337883,
    "actor_loss": -68.63412475585938,
    "critic_loss": 2.852644681930542,
    "ent_coef": 0.06082792952656746,
    "learning_rate": 0.001
  },
  {
    "episode": 8092,
    "reward": 86.485791,
    "length": 70,
    "time": 121269.719568,
    "actor_loss": -67.15042877197266,
    "critic_loss": 2.3989408016204834,
    "ent_coef": 0.05952746793627739,
    "learning_rate": 0.001
  },
  {
    "episode": 8093,
    "reward": 89.257976,
    "length": 65,
    "time": 121284.159598,
    "actor_loss": -67.26380920410156,
    "critic_loss": 5.565692901611328,
    "ent_coef": 0.0633535161614418,
    "learning_rate": 0.001
  },
  {
    "episode": 8094,
    "reward": 89.990958,
    "length": 63,
    "time": 121295.389842,
    "actor_loss": -60.673160552978516,
    "critic_loss": 13.438292503356934,
    "ent_coef": 0.06800278276205063,
    "learning_rate": 0.001
  },
  {
    "episode": 8095,
    "reward": 90.743048,
    "length": 62,
    "time": 121306.644857,
    "actor_loss": -74.16230773925781,
    "critic_loss": 13.137510299682617,
    "ent_coef": 0.07055702060461044,
    "learning_rate": 0.001
  },
  {
    "episode": 8096,
    "reward": 88.558004,
    "length": 66,
    "time": 121318.400239,
    "actor_loss": -66.3861312866211,
    "critic_loss": 69.47451782226562,
    "ent_coef": 0.070804163813591,
    "learning_rate": 0.001
  },
  {
    "episode": 8097,
    "reward": 86.89958,
    "length": 69,
    "time": 121330.860194,
    "actor_loss": -67.89561462402344,
    "critic_loss": 8.82448959350586,
    "ent_coef": 0.069935642182827,
    "learning_rate": 0.001
  },
  {
    "episode": 8098,
    "reward": 90.911155,
    "length": 61,
    "time": 121345.267417,
    "actor_loss": -70.82496643066406,
    "critic_loss": 18.81653594970703,
    "ent_coef": 0.07206235080957413,
    "learning_rate": 0.001
  },
  {
    "episode": 8099,
    "reward": 88.39711,
    "length": 65,
    "time": 121359.249786,
    "actor_loss": -61.68018341064453,
    "critic_loss": 5.721528053283691,
    "ent_coef": 0.0720379427075386,
    "learning_rate": 0.001
  },
  {
    "episode": 8100,
    "reward": 88.372678,
    "length": 68,
    "time": 121371.466275,
    "actor_loss": -72.31272888183594,
    "critic_loss": 48.78062438964844,
    "ent_coef": 0.07009842246770859,
    "learning_rate": 0.001
  },
  {
    "episode": 8101,
    "reward": 88.940616,
    "length": 65,
    "time": 121385.05189,
    "actor_loss": -70.83621215820312,
    "critic_loss": 7.87763786315918,
    "ent_coef": 0.07188323140144348,
    "learning_rate": 0.001
  },
  {
    "episode": 8102,
    "reward": 88.957343,
    "length": 69,
    "time": 121397.449453,
    "actor_loss": -67.80928039550781,
    "critic_loss": 98.702392578125,
    "ent_coef": 0.07474785298109055,
    "learning_rate": 0.001
  },
  {
    "episode": 8103,
    "reward": 87.76119,
    "length": 70,
    "time": 121409.550418,
    "actor_loss": -68.99678039550781,
    "critic_loss": 7.558664798736572,
    "ent_coef": 0.07134512066841125,
    "learning_rate": 0.001
  },
  {
    "episode": 8104,
    "reward": 83.087703,
    "length": 78,
    "time": 121423.988594,
    "actor_loss": -65.25865936279297,
    "critic_loss": 2.5926413536071777,
    "ent_coef": 0.06260121613740921,
    "learning_rate": 0.001
  },
  {
    "episode": 8105,
    "reward": 89.335033,
    "length": 64,
    "time": 121436.481247,
    "actor_loss": -66.55070495605469,
    "critic_loss": 2.2734627723693848,
    "ent_coef": 0.059555377811193466,
    "learning_rate": 0.001
  },
  {
    "episode": 8106,
    "reward": 87.593244,
    "length": 69,
    "time": 121449.34345,
    "actor_loss": -66.98342895507812,
    "critic_loss": 4.563788414001465,
    "ent_coef": 0.057223014533519745,
    "learning_rate": 0.001
  },
  {
    "episode": 8107,
    "reward": 88.817222,
    "length": 65,
    "time": 121462.601929,
    "actor_loss": -63.84626388549805,
    "critic_loss": 4.2854905128479,
    "ent_coef": 0.056917835026979446,
    "learning_rate": 0.001
  },
  {
    "episode": 8108,
    "reward": 87.862274,
    "length": 71,
    "time": 121477.27163,
    "actor_loss": -62.971527099609375,
    "critic_loss": 4.53886079788208,
    "ent_coef": 0.056970905512571335,
    "learning_rate": 0.001
  },
  {
    "episode": 8109,
    "reward": 90.553322,
    "length": 64,
    "time": 121488.673119,
    "actor_loss": -65.31443786621094,
    "critic_loss": 3.054262638092041,
    "ent_coef": 0.0590956024825573,
    "learning_rate": 0.001
  },
  {
    "episode": 8110,
    "reward": 91.005355,
    "length": 61,
    "time": 121500.551537,
    "actor_loss": -68.61102294921875,
    "critic_loss": 3.1989364624023438,
    "ent_coef": 0.06267818808555603,
    "learning_rate": 0.001
  },
  {
    "episode": 8111,
    "reward": 91.525247,
    "length": 61,
    "time": 121511.736904,
    "actor_loss": -69.32208251953125,
    "critic_loss": 2.809889316558838,
    "ent_coef": 0.064482182264328,
    "learning_rate": 0.001
  },
  {
    "episode": 8112,
    "reward": 90.02082,
    "length": 62,
    "time": 121524.884188,
    "actor_loss": -69.2518081665039,
    "critic_loss": 3.2518064975738525,
    "ent_coef": 0.06596952676773071,
    "learning_rate": 0.001
  },
  {
    "episode": 8113,
    "reward": 88.777365,
    "length": 65,
    "time": 121536.321362,
    "actor_loss": -70.52200317382812,
    "critic_loss": 3.280919075012207,
    "ent_coef": 0.06639956682920456,
    "learning_rate": 0.001
  },
  {
    "episode": 8114,
    "reward": 87.917024,
    "length": 66,
    "time": 121549.086098,
    "actor_loss": -71.1185302734375,
    "critic_loss": 4.2747344970703125,
    "ent_coef": 0.06928795576095581,
    "learning_rate": 0.001
  },
  {
    "episode": 8115,
    "reward": 91.9609,
    "length": 60,
    "time": 121562.899925,
    "actor_loss": -69.08729553222656,
    "critic_loss": 53.356998443603516,
    "ent_coef": 0.07468553632497787,
    "learning_rate": 0.001
  },
  {
    "episode": 8116,
    "reward": 90.548176,
    "length": 63,
    "time": 121576.190683,
    "actor_loss": -68.54724884033203,
    "critic_loss": 4.104828357696533,
    "ent_coef": 0.07651051878929138,
    "learning_rate": 0.001
  },
  {
    "episode": 8117,
    "reward": 89.495405,
    "length": 63,
    "time": 121587.783545,
    "actor_loss": -75.2419662475586,
    "critic_loss": 3.5770065784454346,
    "ent_coef": 0.07457844913005829,
    "learning_rate": 0.001
  },
  {
    "episode": 8118,
    "reward": 87.478789,
    "length": 69,
    "time": 121600.032116,
    "actor_loss": -72.26399230957031,
    "critic_loss": 12.952943801879883,
    "ent_coef": 0.06938178837299347,
    "learning_rate": 0.001
  },
  {
    "episode": 8119,
    "reward": 89.836635,
    "length": 63,
    "time": 121612.387598,
    "actor_loss": -65.11741638183594,
    "critic_loss": 7.741035461425781,
    "ent_coef": 0.069283626973629,
    "learning_rate": 0.001
  },
  {
    "episode": 8120,
    "reward": 91.53844,
    "length": 61,
    "time": 121624.530086,
    "actor_loss": -69.45057678222656,
    "critic_loss": 1.86277174949646,
    "ent_coef": 0.07057125121355057,
    "learning_rate": 0.001
  },
  {
    "episode": 8121,
    "reward": 87.393965,
    "length": 70,
    "time": 121637.257774,
    "actor_loss": -64.91697692871094,
    "critic_loss": 5.160686492919922,
    "ent_coef": 0.0648566260933876,
    "learning_rate": 0.001
  },
  {
    "episode": 8122,
    "reward": 79.575495,
    "length": 81,
    "time": 121650.60503,
    "actor_loss": -67.17363739013672,
    "critic_loss": 2.001330614089966,
    "ent_coef": 0.05705908685922623,
    "learning_rate": 0.001
  },
  {
    "episode": 8123,
    "reward": 89.741355,
    "length": 64,
    "time": 121661.859955,
    "actor_loss": -68.41619110107422,
    "critic_loss": 565.7484130859375,
    "ent_coef": 0.05741346254944801,
    "learning_rate": 0.001
  },
  {
    "episode": 8124,
    "reward": 89.186064,
    "length": 65,
    "time": 121674.282322,
    "actor_loss": -70.06546020507812,
    "critic_loss": 5.222537040710449,
    "ent_coef": 0.05976167693734169,
    "learning_rate": 0.001
  },
  {
    "episode": 8125,
    "reward": 91.273835,
    "length": 60,
    "time": 121686.201084,
    "actor_loss": -70.97563171386719,
    "critic_loss": 13.438730239868164,
    "ent_coef": 0.06288352608680725,
    "learning_rate": 0.001
  },
  {
    "episode": 8126,
    "reward": 89.807517,
    "length": 65,
    "time": 121698.22885,
    "actor_loss": -72.4292221069336,
    "critic_loss": 32.95734786987305,
    "ent_coef": 0.06404444575309753,
    "learning_rate": 0.001
  },
  {
    "episode": 8127,
    "reward": 86.417076,
    "length": 70,
    "time": 121710.697694,
    "actor_loss": -65.8168716430664,
    "critic_loss": 3.2649431228637695,
    "ent_coef": 0.06042730435729027,
    "learning_rate": 0.001
  },
  {
    "episode": 8128,
    "reward": 90.317839,
    "length": 63,
    "time": 121723.056142,
    "actor_loss": -71.09185791015625,
    "critic_loss": 3.079604148864746,
    "ent_coef": 0.05988806486129761,
    "learning_rate": 0.001
  },
  {
    "episode": 8129,
    "reward": 88.516573,
    "length": 66,
    "time": 121735.697979,
    "actor_loss": -71.72456359863281,
    "critic_loss": 4.733658790588379,
    "ent_coef": 0.05864167585968971,
    "learning_rate": 0.001
  },
  {
    "episode": 8130,
    "reward": 91.440167,
    "length": 61,
    "time": 121747.881955,
    "actor_loss": -65.51656341552734,
    "critic_loss": 18.60919189453125,
    "ent_coef": 0.060518600046634674,
    "learning_rate": 0.001
  },
  {
    "episode": 8131,
    "reward": 91.415853,
    "length": 61,
    "time": 121759.315436,
    "actor_loss": -67.24749755859375,
    "critic_loss": 7.627490043640137,
    "ent_coef": 0.06139306351542473,
    "learning_rate": 0.001
  },
  {
    "episode": 8132,
    "reward": 91.945295,
    "length": 60,
    "time": 121771.107879,
    "actor_loss": -67.0538330078125,
    "critic_loss": 14.19246768951416,
    "ent_coef": 0.06693502515554428,
    "learning_rate": 0.001
  },
  {
    "episode": 8133,
    "reward": 92.081665,
    "length": 61,
    "time": 121783.970254,
    "actor_loss": -65.61992645263672,
    "critic_loss": 80.36579895019531,
    "ent_coef": 0.07297299802303314,
    "learning_rate": 0.001
  },
  {
    "episode": 8134,
    "reward": 90.816299,
    "length": 63,
    "time": 121796.996939,
    "actor_loss": -71.05758666992188,
    "critic_loss": 1513.879150390625,
    "ent_coef": 0.0754828006029129,
    "learning_rate": 0.001
  },
  {
    "episode": 8135,
    "reward": 91.007819,
    "length": 62,
    "time": 121811.879399,
    "actor_loss": -68.12416076660156,
    "critic_loss": 7.06262731552124,
    "ent_coef": 0.07613568007946014,
    "learning_rate": 0.001
  },
  {
    "episode": 8136,
    "reward": 89.26657,
    "length": 65,
    "time": 121826.966825,
    "actor_loss": -70.75409698486328,
    "critic_loss": 10.655268669128418,
    "ent_coef": 0.07597645372152328,
    "learning_rate": 0.001
  },
  {
    "episode": 8137,
    "reward": 89.097665,
    "length": 68,
    "time": 121842.647615,
    "actor_loss": -70.46922302246094,
    "critic_loss": 65.23509216308594,
    "ent_coef": 0.07549308240413666,
    "learning_rate": 0.001
  },
  {
    "episode": 8138,
    "reward": 85.216109,
    "length": 77,
    "time": 121855.643555,
    "actor_loss": -68.34954833984375,
    "critic_loss": 7.918011665344238,
    "ent_coef": 0.0708165392279625,
    "learning_rate": 0.001
  },
  {
    "episode": 8139,
    "reward": 86.37721,
    "length": 70,
    "time": 121868.585778,
    "actor_loss": -74.67276000976562,
    "critic_loss": 110.93807220458984,
    "ent_coef": 0.06626874208450317,
    "learning_rate": 0.001
  },
  {
    "episode": 8140,
    "reward": 88.879385,
    "length": 67,
    "time": 121883.006642,
    "actor_loss": -67.28644561767578,
    "critic_loss": 3.6281051635742188,
    "ent_coef": 0.06359651684761047,
    "learning_rate": 0.001
  },
  {
    "episode": 8141,
    "reward": 87.79445,
    "length": 71,
    "time": 121895.446803,
    "actor_loss": -69.28793334960938,
    "critic_loss": 96.4111328125,
    "ent_coef": 0.0632028803229332,
    "learning_rate": 0.001
  },
  {
    "episode": 8142,
    "reward": 90.949825,
    "length": 63,
    "time": 121909.126395,
    "actor_loss": -67.51425170898438,
    "critic_loss": 3.0301289558410645,
    "ent_coef": 0.06604018807411194,
    "learning_rate": 0.001
  },
  {
    "episode": 8143,
    "reward": 91.539878,
    "length": 61,
    "time": 121922.668954,
    "actor_loss": -69.31168365478516,
    "critic_loss": 3.0948095321655273,
    "ent_coef": 0.06728602945804596,
    "learning_rate": 0.001
  },
  {
    "episode": 8144,
    "reward": 90.949967,
    "length": 62,
    "time": 121936.044005,
    "actor_loss": -67.00080871582031,
    "critic_loss": 2.723193407058716,
    "ent_coef": 0.06843499839305878,
    "learning_rate": 0.001
  },
  {
    "episode": 8145,
    "reward": 92.201331,
    "length": 60,
    "time": 121947.870078,
    "actor_loss": -69.47547912597656,
    "critic_loss": 8.356569290161133,
    "ent_coef": 0.07200983911752701,
    "learning_rate": 0.001
  },
  {
    "episode": 8146,
    "reward": 91.408304,
    "length": 66,
    "time": 121960.551871,
    "actor_loss": -67.56901550292969,
    "critic_loss": 18.114103317260742,
    "ent_coef": 0.07957237213850021,
    "learning_rate": 0.001
  },
  {
    "episode": 8147,
    "reward": 91.357905,
    "length": 61,
    "time": 121973.837655,
    "actor_loss": -74.71351623535156,
    "critic_loss": 22.990432739257812,
    "ent_coef": 0.08222103118896484,
    "learning_rate": 0.001
  },
  {
    "episode": 8148,
    "reward": 90.631814,
    "length": 63,
    "time": 121985.913424,
    "actor_loss": -65.4083480834961,
    "critic_loss": 258.9977722167969,
    "ent_coef": 0.08257418870925903,
    "learning_rate": 0.001
  },
  {
    "episode": 8149,
    "reward": 91.100744,
    "length": 62,
    "time": 121998.503464,
    "actor_loss": -66.6216049194336,
    "critic_loss": 7.686043739318848,
    "ent_coef": 0.08350447565317154,
    "learning_rate": 0.001
  },
  {
    "episode": 8150,
    "reward": 91.777259,
    "length": 60,
    "time": 122009.553483,
    "actor_loss": -65.83773803710938,
    "critic_loss": 17.45742416381836,
    "ent_coef": 0.08316904306411743,
    "learning_rate": 0.001
  },
  {
    "episode": 8151,
    "reward": 91.340017,
    "length": 61,
    "time": 122020.90582,
    "actor_loss": -70.41061401367188,
    "critic_loss": 1.913156270980835,
    "ent_coef": 0.08442246913909912,
    "learning_rate": 0.001
  },
  {
    "episode": 8152,
    "reward": 90.381922,
    "length": 64,
    "time": 122036.302942,
    "actor_loss": -70.36082458496094,
    "critic_loss": 2.288883924484253,
    "ent_coef": 0.08565866947174072,
    "learning_rate": 0.001
  },
  {
    "episode": 8153,
    "reward": 89.981564,
    "length": 64,
    "time": 122051.12249,
    "actor_loss": -65.50141906738281,
    "critic_loss": 4.8090081214904785,
    "ent_coef": 0.08473120629787445,
    "learning_rate": 0.001
  },
  {
    "episode": 8154,
    "reward": 87.061932,
    "length": 69,
    "time": 122064.864985,
    "actor_loss": -67.63494110107422,
    "critic_loss": 7.835285186767578,
    "ent_coef": 0.08220238983631134,
    "learning_rate": 0.001
  },
  {
    "episode": 8155,
    "reward": 90.781479,
    "length": 63,
    "time": 122078.874872,
    "actor_loss": -71.99559020996094,
    "critic_loss": 6.838876724243164,
    "ent_coef": 0.08190698176622391,
    "learning_rate": 0.001
  },
  {
    "episode": 8156,
    "reward": 88.708919,
    "length": 67,
    "time": 122094.246281,
    "actor_loss": -70.31432342529297,
    "critic_loss": 7.174351692199707,
    "ent_coef": 0.07647532224655151,
    "learning_rate": 0.001
  },
  {
    "episode": 8157,
    "reward": 61.816196,
    "length": 112,
    "time": 122113.718955,
    "actor_loss": -67.20535278320312,
    "critic_loss": 11.662958145141602,
    "ent_coef": 0.06763317435979843,
    "learning_rate": 0.001
  },
  {
    "episode": 8158,
    "reward": 88.968557,
    "length": 69,
    "time": 122125.680774,
    "actor_loss": -56.204261779785156,
    "critic_loss": 18.493989944458008,
    "ent_coef": 0.06668364256620407,
    "learning_rate": 0.001
  },
  {
    "episode": 8159,
    "reward": 87.899718,
    "length": 68,
    "time": 122139.777193,
    "actor_loss": -69.80044555664062,
    "critic_loss": 3.3142638206481934,
    "ent_coef": 0.06381287425756454,
    "learning_rate": 0.001
  },
  {
    "episode": 8160,
    "reward": 89.663636,
    "length": 64,
    "time": 122151.14753,
    "actor_loss": -70.43382263183594,
    "critic_loss": 7.769712448120117,
    "ent_coef": 0.06304742395877838,
    "learning_rate": 0.001
  },
  {
    "episode": 8161,
    "reward": 90.732165,
    "length": 65,
    "time": 122166.412953,
    "actor_loss": -65.65361022949219,
    "critic_loss": 7.086789608001709,
    "ent_coef": 0.06516843289136887,
    "learning_rate": 0.001
  },
  {
    "episode": 8162,
    "reward": 90.594278,
    "length": 65,
    "time": 122179.689968,
    "actor_loss": -73.90242767333984,
    "critic_loss": 3.395531177520752,
    "ent_coef": 0.06522252410650253,
    "learning_rate": 0.001
  },
  {
    "episode": 8163,
    "reward": 89.726861,
    "length": 65,
    "time": 122193.150296,
    "actor_loss": -69.27114868164062,
    "critic_loss": 3.10172700881958,
    "ent_coef": 0.0646766871213913,
    "learning_rate": 0.001
  },
  {
    "episode": 8164,
    "reward": 89.825632,
    "length": 64,
    "time": 122204.386658,
    "actor_loss": -66.61619567871094,
    "critic_loss": 83.6298828125,
    "ent_coef": 0.06426022946834564,
    "learning_rate": 0.001
  },
  {
    "episode": 8165,
    "reward": 89.932891,
    "length": 66,
    "time": 122215.913587,
    "actor_loss": -66.35792541503906,
    "critic_loss": 23.805065155029297,
    "ent_coef": 0.06526972353458405,
    "learning_rate": 0.001
  },
  {
    "episode": 8166,
    "reward": 86.925679,
    "length": 70,
    "time": 122228.26413,
    "actor_loss": -73.09162139892578,
    "critic_loss": 3.354091167449951,
    "ent_coef": 0.06156771257519722,
    "learning_rate": 0.001
  },
  {
    "episode": 8167,
    "reward": 92.129798,
    "length": 61,
    "time": 122239.378434,
    "actor_loss": -60.60813522338867,
    "critic_loss": 4.689619064331055,
    "ent_coef": 0.06264358758926392,
    "learning_rate": 0.001
  },
  {
    "episode": 8168,
    "reward": 92.034998,
    "length": 60,
    "time": 122250.294316,
    "actor_loss": -66.53430938720703,
    "critic_loss": 80.00001525878906,
    "ent_coef": 0.06688793003559113,
    "learning_rate": 0.001
  },
  {
    "episode": 8169,
    "reward": 91.493897,
    "length": 61,
    "time": 122261.664819,
    "actor_loss": -64.17854309082031,
    "critic_loss": 3.7823750972747803,
    "ent_coef": 0.07124308496713638,
    "learning_rate": 0.001
  },
  {
    "episode": 8170,
    "reward": 90.293559,
    "length": 64,
    "time": 122273.989778,
    "actor_loss": -68.97884368896484,
    "critic_loss": 2.6445138454437256,
    "ent_coef": 0.07300759851932526,
    "learning_rate": 0.001
  },
  {
    "episode": 8171,
    "reward": 85.48403,
    "length": 73,
    "time": 122288.703703,
    "actor_loss": -65.81391906738281,
    "critic_loss": 5.981898784637451,
    "ent_coef": 0.06676122546195984,
    "learning_rate": 0.001
  },
  {
    "episode": 8172,
    "reward": 84.594443,
    "length": 78,
    "time": 122302.183659,
    "actor_loss": -68.39704895019531,
    "critic_loss": 2.2751028537750244,
    "ent_coef": 0.06752631813287735,
    "learning_rate": 0.001
  },
  {
    "episode": 8173,
    "reward": 88.844934,
    "length": 72,
    "time": 122315.465412,
    "actor_loss": -67.53791809082031,
    "critic_loss": 10.180870056152344,
    "ent_coef": 0.07081009447574615,
    "learning_rate": 0.001
  },
  {
    "episode": 8174,
    "reward": 85.858631,
    "length": 75,
    "time": 122329.648918,
    "actor_loss": -75.58143615722656,
    "critic_loss": 5.743884086608887,
    "ent_coef": 0.06621817499399185,
    "learning_rate": 0.001
  },
  {
    "episode": 8175,
    "reward": 89.395287,
    "length": 66,
    "time": 122343.237415,
    "actor_loss": -69.45079040527344,
    "critic_loss": 8.191157341003418,
    "ent_coef": 0.06399954855442047,
    "learning_rate": 0.001
  },
  {
    "episode": 8176,
    "reward": 90.669202,
    "length": 63,
    "time": 122357.962782,
    "actor_loss": -63.64643096923828,
    "critic_loss": 1.1293513774871826,
    "ent_coef": 0.06433772295713425,
    "learning_rate": 0.001
  },
  {
    "episode": 8177,
    "reward": 88.212567,
    "length": 70,
    "time": 122373.649944,
    "actor_loss": -72.6741714477539,
    "critic_loss": 2.917637348175049,
    "ent_coef": 0.06419061869382858,
    "learning_rate": 0.001
  },
  {
    "episode": 8178,
    "reward": 89.770985,
    "length": 64,
    "time": 122385.456209,
    "actor_loss": -68.44007873535156,
    "critic_loss": 88.77236938476562,
    "ent_coef": 0.06543806195259094,
    "learning_rate": 0.001
  },
  {
    "episode": 8179,
    "reward": 90.454662,
    "length": 64,
    "time": 122397.041529,
    "actor_loss": -68.57594299316406,
    "critic_loss": 9.328306198120117,
    "ent_coef": 0.06846868246793747,
    "learning_rate": 0.001
  },
  {
    "episode": 8180,
    "reward": 92.074782,
    "length": 60,
    "time": 122408.559894,
    "actor_loss": -73.30349731445312,
    "critic_loss": 11.189266204833984,
    "ent_coef": 0.07222677767276764,
    "learning_rate": 0.001
  },
  {
    "episode": 8181,
    "reward": 88.596004,
    "length": 73,
    "time": 122422.505354,
    "actor_loss": -71.92623138427734,
    "critic_loss": 51.20341873168945,
    "ent_coef": 0.07430199533700943,
    "learning_rate": 0.001
  },
  {
    "episode": 8182,
    "reward": 91.029107,
    "length": 61,
    "time": 122435.590634,
    "actor_loss": -67.04185485839844,
    "critic_loss": 6.20603084564209,
    "ent_coef": 0.0736820325255394,
    "learning_rate": 0.001
  },
  {
    "episode": 8183,
    "reward": 89.204527,
    "length": 66,
    "time": 122447.014661,
    "actor_loss": -63.51771545410156,
    "critic_loss": 3.737589120864868,
    "ent_coef": 0.0691671073436737,
    "learning_rate": 0.001
  },
  {
    "episode": 8184,
    "reward": 86.837693,
    "length": 71,
    "time": 122459.804708,
    "actor_loss": -70.26280212402344,
    "critic_loss": 4.951762676239014,
    "ent_coef": 0.061943311244249344,
    "learning_rate": 0.001
  },
  {
    "episode": 8185,
    "reward": 89.328408,
    "length": 69,
    "time": 122473.898221,
    "actor_loss": -69.24305725097656,
    "critic_loss": 3.571624279022217,
    "ent_coef": 0.059857357293367386,
    "learning_rate": 0.001
  },
  {
    "episode": 8186,
    "reward": 81.909156,
    "length": 81,
    "time": 122489.293186,
    "actor_loss": -73.65625,
    "critic_loss": 1.838076114654541,
    "ent_coef": 0.056303080171346664,
    "learning_rate": 0.001
  },
  {
    "episode": 8187,
    "reward": 90.489159,
    "length": 63,
    "time": 122503.400516,
    "actor_loss": -64.52304077148438,
    "critic_loss": 6.642663478851318,
    "ent_coef": 0.054484300315380096,
    "learning_rate": 0.001
  },
  {
    "episode": 8188,
    "reward": 91.569568,
    "length": 61,
    "time": 122516.695273,
    "actor_loss": -75.95384216308594,
    "critic_loss": 13.717557907104492,
    "ent_coef": 0.05567536875605583,
    "learning_rate": 0.001
  },
  {
    "episode": 8189,
    "reward": 87.580127,
    "length": 70,
    "time": 122530.265518,
    "actor_loss": -68.48078918457031,
    "critic_loss": 5.513836860656738,
    "ent_coef": 0.05446053296327591,
    "learning_rate": 0.001
  },
  {
    "episode": 8190,
    "reward": 84.92592,
    "length": 78,
    "time": 122545.257532,
    "actor_loss": -71.09274291992188,
    "critic_loss": 5.682372570037842,
    "ent_coef": 0.05242729187011719,
    "learning_rate": 0.001
  },
  {
    "episode": 8191,
    "reward": 90.983729,
    "length": 63,
    "time": 122559.267865,
    "actor_loss": -68.73832702636719,
    "critic_loss": 2.22517728805542,
    "ent_coef": 0.054291997104883194,
    "learning_rate": 0.001
  },
  {
    "episode": 8192,
    "reward": 91.476028,
    "length": 61,
    "time": 122570.674333,
    "actor_loss": -69.08395385742188,
    "critic_loss": 4.110593795776367,
    "ent_coef": 0.05811057984828949,
    "learning_rate": 0.001
  },
  {
    "episode": 8193,
    "reward": 89.314939,
    "length": 66,
    "time": 122582.202263,
    "actor_loss": -68.13475799560547,
    "critic_loss": 84.55961608886719,
    "ent_coef": 0.061366572976112366,
    "learning_rate": 0.001
  },
  {
    "episode": 8194,
    "reward": 88.24528,
    "length": 70,
    "time": 122595.922471,
    "actor_loss": -73.6646499633789,
    "critic_loss": 2.9358131885528564,
    "ent_coef": 0.060016121715307236,
    "learning_rate": 0.001
  },
  {
    "episode": 8195,
    "reward": 80.846922,
    "length": 80,
    "time": 122609.192631,
    "actor_loss": -70.35960388183594,
    "critic_loss": 5.872666835784912,
    "ent_coef": 0.05576371029019356,
    "learning_rate": 0.001
  },
  {
    "episode": 8196,
    "reward": 92.119942,
    "length": 60,
    "time": 122620.078738,
    "actor_loss": -70.70796966552734,
    "critic_loss": 8.14974594116211,
    "ent_coef": 0.05711076408624649,
    "learning_rate": 0.001
  },
  {
    "episode": 8197,
    "reward": 91.836409,
    "length": 60,
    "time": 122632.944574,
    "actor_loss": -66.71337127685547,
    "critic_loss": 7.218147277832031,
    "ent_coef": 0.05692608654499054,
    "learning_rate": 0.001
  },
  {
    "episode": 8198,
    "reward": 88.22168,
    "length": 68,
    "time": 122646.71221,
    "actor_loss": -72.8465576171875,
    "critic_loss": 5.624135971069336,
    "ent_coef": 0.05502106249332428,
    "learning_rate": 0.001
  },
  {
    "episode": 8199,
    "reward": 89.866032,
    "length": 64,
    "time": 122659.816783,
    "actor_loss": -65.06718444824219,
    "critic_loss": 11.07974624633789,
    "ent_coef": 0.057504232972860336,
    "learning_rate": 0.001
  },
  {
    "episode": 8200,
    "reward": 88.673728,
    "length": 70,
    "time": 122673.734013,
    "actor_loss": -70.2767333984375,
    "critic_loss": 3.8686039447784424,
    "ent_coef": 0.06084340438246727,
    "learning_rate": 0.001
  },
  {
    "episode": 8201,
    "reward": 88.994524,
    "length": 66,
    "time": 122685.540311,
    "actor_loss": -70.34869384765625,
    "critic_loss": 13.77501106262207,
    "ent_coef": 0.0646732822060585,
    "learning_rate": 0.001
  },
  {
    "episode": 8202,
    "reward": 87.956781,
    "length": 67,
    "time": 122697.532819,
    "actor_loss": -76.2529296875,
    "critic_loss": 21.369075775146484,
    "ent_coef": 0.061741963028907776,
    "learning_rate": 0.001
  },
  {
    "episode": 8203,
    "reward": 86.244236,
    "length": 70,
    "time": 122710.571185,
    "actor_loss": -67.99342346191406,
    "critic_loss": 216.12161254882812,
    "ent_coef": 0.058048784732818604,
    "learning_rate": 0.001
  },
  {
    "episode": 8204,
    "reward": 91.571271,
    "length": 60,
    "time": 122721.769215,
    "actor_loss": -70.49537658691406,
    "critic_loss": 20.412975311279297,
    "ent_coef": 0.062179673463106155,
    "learning_rate": 0.001
  },
  {
    "episode": 8205,
    "reward": 91.74214,
    "length": 62,
    "time": 122732.755128,
    "actor_loss": -71.12498474121094,
    "critic_loss": 2.945709228515625,
    "ent_coef": 0.06756261736154556,
    "learning_rate": 0.001
  },
  {
    "episode": 8206,
    "reward": 89.932563,
    "length": 64,
    "time": 122745.248607,
    "actor_loss": -69.95938110351562,
    "critic_loss": 57.68859100341797,
    "ent_coef": 0.06883212178945541,
    "learning_rate": 0.001
  },
  {
    "episode": 8207,
    "reward": 87.310867,
    "length": 69,
    "time": 122757.864962,
    "actor_loss": -68.90436553955078,
    "critic_loss": 21.267478942871094,
    "ent_coef": 0.0658770278096199,
    "learning_rate": 0.001
  },
  {
    "episode": 8208,
    "reward": 83.467308,
    "length": 75,
    "time": 122771.55459,
    "actor_loss": -68.16952514648438,
    "critic_loss": 2.4460978507995605,
    "ent_coef": 0.061920393258333206,
    "learning_rate": 0.001
  },
  {
    "episode": 8209,
    "reward": 90.959695,
    "length": 62,
    "time": 122782.710239,
    "actor_loss": -69.40736389160156,
    "critic_loss": 2.7933034896850586,
    "ent_coef": 0.06427635997533798,
    "learning_rate": 0.001
  },
  {
    "episode": 8210,
    "reward": 90.538963,
    "length": 64,
    "time": 122796.010007,
    "actor_loss": -65.94425964355469,
    "critic_loss": 3.3130316734313965,
    "ent_coef": 0.06770921498537064,
    "learning_rate": 0.001
  },
  {
    "episode": 8211,
    "reward": 90.423903,
    "length": 63,
    "time": 122807.68252,
    "actor_loss": -65.06785583496094,
    "critic_loss": 3.341747522354126,
    "ent_coef": 0.07107646018266678,
    "learning_rate": 0.001
  },
  {
    "episode": 8212,
    "reward": 88.686119,
    "length": 68,
    "time": 122819.546862,
    "actor_loss": -67.48477172851562,
    "critic_loss": 4.215797424316406,
    "ent_coef": 0.07125537842512131,
    "learning_rate": 0.001
  },
  {
    "episode": 8213,
    "reward": 87.256556,
    "length": 69,
    "time": 122831.576262,
    "actor_loss": -71.9332504272461,
    "critic_loss": 10.143599510192871,
    "ent_coef": 0.07082121819257736,
    "learning_rate": 0.001
  },
  {
    "episode": 8214,
    "reward": 89.597293,
    "length": 66,
    "time": 122846.715701,
    "actor_loss": -66.82344818115234,
    "critic_loss": 3.458883762359619,
    "ent_coef": 0.06965386867523193,
    "learning_rate": 0.001
  },
  {
    "episode": 8215,
    "reward": 83.80616,
    "length": 74,
    "time": 122859.511094,
    "actor_loss": -67.04340362548828,
    "critic_loss": 4.139920711517334,
    "ent_coef": 0.0640227347612381,
    "learning_rate": 0.001
  },
  {
    "episode": 8216,
    "reward": 89.735241,
    "length": 66,
    "time": 122872.249738,
    "actor_loss": -65.96751403808594,
    "critic_loss": 9.604183197021484,
    "ent_coef": 0.060300469398498535,
    "learning_rate": 0.001
  },
  {
    "episode": 8217,
    "reward": 90.296414,
    "length": 63,
    "time": 122886.10634,
    "actor_loss": -66.95458984375,
    "critic_loss": 22.656959533691406,
    "ent_coef": 0.06176887825131416,
    "learning_rate": 0.001
  },
  {
    "episode": 8218,
    "reward": 92.045442,
    "length": 59,
    "time": 122900.302383,
    "actor_loss": -69.58245849609375,
    "critic_loss": 3.639690399169922,
    "ent_coef": 0.06500817090272903,
    "learning_rate": 0.001
  },
  {
    "episode": 8219,
    "reward": 90.334423,
    "length": 63,
    "time": 122911.532289,
    "actor_loss": -63.614749908447266,
    "critic_loss": 2.29533314704895,
    "ent_coef": 0.06791852414608002,
    "learning_rate": 0.001
  },
  {
    "episode": 8220,
    "reward": 91.407807,
    "length": 62,
    "time": 122924.038572,
    "actor_loss": -67.61181640625,
    "critic_loss": 4.345219135284424,
    "ent_coef": 0.06832053512334824,
    "learning_rate": 0.001
  },
  {
    "episode": 8221,
    "reward": 87.353289,
    "length": 67,
    "time": 122936.237881,
    "actor_loss": -73.4090576171875,
    "critic_loss": 20.269790649414062,
    "ent_coef": 0.06507021933794022,
    "learning_rate": 0.001
  },
  {
    "episode": 8222,
    "reward": 88.804884,
    "length": 67,
    "time": 122949.334988,
    "actor_loss": -70.69139099121094,
    "critic_loss": 21.89375877380371,
    "ent_coef": 0.06273796409368515,
    "learning_rate": 0.001
  },
  {
    "episode": 8223,
    "reward": 90.543822,
    "length": 63,
    "time": 122960.682932,
    "actor_loss": -67.01652526855469,
    "critic_loss": 1.5554460287094116,
    "ent_coef": 0.06218480318784714,
    "learning_rate": 0.001
  },
  {
    "episode": 8224,
    "reward": 84.901144,
    "length": 73,
    "time": 122977.293236,
    "actor_loss": -66.45673370361328,
    "critic_loss": 7.375607490539551,
    "ent_coef": 0.05846522003412247,
    "learning_rate": 0.001
  },
  {
    "episode": 8225,
    "reward": 88.847362,
    "length": 66,
    "time": 122989.650528,
    "actor_loss": -68.75125885009766,
    "critic_loss": 1.861283540725708,
    "ent_coef": 0.058596085757017136,
    "learning_rate": 0.001
  },
  {
    "episode": 8226,
    "reward": 82.937448,
    "length": 75,
    "time": 123002.597674,
    "actor_loss": -74.67453002929688,
    "critic_loss": 2.879336357116699,
    "ent_coef": 0.05556776747107506,
    "learning_rate": 0.001
  },
  {
    "episode": 8227,
    "reward": 88.451985,
    "length": 66,
    "time": 123014.231399,
    "actor_loss": -67.10023498535156,
    "critic_loss": 1.6670454740524292,
    "ent_coef": 0.054446276277303696,
    "learning_rate": 0.001
  },
  {
    "episode": 8228,
    "reward": 90.034913,
    "length": 65,
    "time": 123028.629143,
    "actor_loss": -71.20584106445312,
    "critic_loss": 2.034520149230957,
    "ent_coef": 0.056131985038518906,
    "learning_rate": 0.001
  },
  {
    "episode": 8229,
    "reward": 88.484881,
    "length": 69,
    "time": 123040.44201,
    "actor_loss": -73.60922241210938,
    "critic_loss": 6.439798355102539,
    "ent_coef": 0.060955263674259186,
    "learning_rate": 0.001
  },
  {
    "episode": 8230,
    "reward": 90.871604,
    "length": 63,
    "time": 123053.99985,
    "actor_loss": -69.07473754882812,
    "critic_loss": 2.806360960006714,
    "ent_coef": 0.0628773495554924,
    "learning_rate": 0.001
  },
  {
    "episode": 8231,
    "reward": 85.642197,
    "length": 73,
    "time": 123070.358729,
    "actor_loss": -71.37399291992188,
    "critic_loss": 12.902835845947266,
    "ent_coef": 0.06030423566699028,
    "learning_rate": 0.001
  },
  {
    "episode": 8232,
    "reward": 88.76678,
    "length": 65,
    "time": 123082.569065,
    "actor_loss": -65.55375671386719,
    "critic_loss": 2.0959324836730957,
    "ent_coef": 0.061513904482126236,
    "learning_rate": 0.001
  },
  {
    "episode": 8233,
    "reward": 91.758168,
    "length": 61,
    "time": 123093.683039,
    "actor_loss": -69.74575805664062,
    "critic_loss": 8.86111068725586,
    "ent_coef": 0.06840905547142029,
    "learning_rate": 0.001
  },
  {
    "episode": 8234,
    "reward": 80.372814,
    "length": 81,
    "time": 123108.872052,
    "actor_loss": -69.53919982910156,
    "critic_loss": 91.09066772460938,
    "ent_coef": 0.06760063767433167,
    "learning_rate": 0.001
  },
  {
    "episode": 8235,
    "reward": 88.233736,
    "length": 68,
    "time": 123123.550588,
    "actor_loss": -75.14363098144531,
    "critic_loss": 59.19725799560547,
    "ent_coef": 0.06595510989427567,
    "learning_rate": 0.001
  },
  {
    "episode": 8236,
    "reward": 87.617345,
    "length": 69,
    "time": 123135.303127,
    "actor_loss": -69.1269302368164,
    "critic_loss": 9.074531555175781,
    "ent_coef": 0.06342542171478271,
    "learning_rate": 0.001
  },
  {
    "episode": 8237,
    "reward": 86.91048,
    "length": 70,
    "time": 123147.862719,
    "actor_loss": -68.46720886230469,
    "critic_loss": 8.322461128234863,
    "ent_coef": 0.062148742377758026,
    "learning_rate": 0.001
  },
  {
    "episode": 8238,
    "reward": 87.65907,
    "length": 71,
    "time": 123163.027443,
    "actor_loss": -73.4557876586914,
    "critic_loss": 77.34597778320312,
    "ent_coef": 0.06220507249236107,
    "learning_rate": 0.001
  },
  {
    "episode": 8239,
    "reward": 90.146388,
    "length": 64,
    "time": 123177.435098,
    "actor_loss": -70.80174255371094,
    "critic_loss": 13.918449401855469,
    "ent_coef": 0.06253649294376373,
    "learning_rate": 0.001
  },
  {
    "episode": 8240,
    "reward": 89.501634,
    "length": 65,
    "time": 123190.993471,
    "actor_loss": -70.26585388183594,
    "critic_loss": 3.1760175228118896,
    "ent_coef": 0.06149795278906822,
    "learning_rate": 0.001
  },
  {
    "episode": 8241,
    "reward": 89.296005,
    "length": 65,
    "time": 123202.559312,
    "actor_loss": -66.93433380126953,
    "critic_loss": 6.909422874450684,
    "ent_coef": 0.0601620227098465,
    "learning_rate": 0.001
  },
  {
    "episode": 8242,
    "reward": 86.291678,
    "length": 69,
    "time": 123216.612264,
    "actor_loss": -64.80127716064453,
    "critic_loss": 27.01498031616211,
    "ent_coef": 0.057727962732315063,
    "learning_rate": 0.001
  },
  {
    "episode": 8243,
    "reward": 88.34692,
    "length": 69,
    "time": 123231.738606,
    "actor_loss": -73.18382263183594,
    "critic_loss": 7.805690288543701,
    "ent_coef": 0.057103995233774185,
    "learning_rate": 0.001
  },
  {
    "episode": 8244,
    "reward": 90.068615,
    "length": 65,
    "time": 123246.301996,
    "actor_loss": -70.0038833618164,
    "critic_loss": 3.8472447395324707,
    "ent_coef": 0.0567292645573616,
    "learning_rate": 0.001
  },
  {
    "episode": 8245,
    "reward": 88.762548,
    "length": 69,
    "time": 123258.776054,
    "actor_loss": -66.06608581542969,
    "critic_loss": 4.65164852142334,
    "ent_coef": 0.05567025765776634,
    "learning_rate": 0.001
  },
  {
    "episode": 8246,
    "reward": 89.199854,
    "length": 67,
    "time": 123270.695644,
    "actor_loss": -65.74217987060547,
    "critic_loss": 3.035141944885254,
    "ent_coef": 0.05357188731431961,
    "learning_rate": 0.001
  },
  {
    "episode": 8247,
    "reward": 87.541134,
    "length": 69,
    "time": 123282.510186,
    "actor_loss": -71.7153549194336,
    "critic_loss": 10.077620506286621,
    "ent_coef": 0.053323499858379364,
    "learning_rate": 0.001
  },
  {
    "episode": 8248,
    "reward": 90.648907,
    "length": 63,
    "time": 123296.987562,
    "actor_loss": -67.89944458007812,
    "critic_loss": 17.449481964111328,
    "ent_coef": 0.055286966264247894,
    "learning_rate": 0.001
  },
  {
    "episode": 8249,
    "reward": 90.094069,
    "length": 68,
    "time": 123308.905178,
    "actor_loss": -69.83653259277344,
    "critic_loss": 10.805416107177734,
    "ent_coef": 0.058035608381032944,
    "learning_rate": 0.001
  },
  {
    "episode": 8250,
    "reward": 91.205937,
    "length": 64,
    "time": 123322.352161,
    "actor_loss": -70.32566833496094,
    "critic_loss": 6.090097427368164,
    "ent_coef": 0.06217057257890701,
    "learning_rate": 0.001
  },
  {
    "episode": 8251,
    "reward": 90.627667,
    "length": 64,
    "time": 123334.948252,
    "actor_loss": -76.31852722167969,
    "critic_loss": 6.36019229888916,
    "ent_coef": 0.06470075994729996,
    "learning_rate": 0.001
  },
  {
    "episode": 8252,
    "reward": 90.723506,
    "length": 62,
    "time": 123346.063506,
    "actor_loss": -71.85151672363281,
    "critic_loss": 3.994067668914795,
    "ent_coef": 0.06630510836839676,
    "learning_rate": 0.001
  },
  {
    "episode": 8253,
    "reward": 90.844502,
    "length": 64,
    "time": 123358.062093,
    "actor_loss": -70.078369140625,
    "critic_loss": 1.8322577476501465,
    "ent_coef": 0.07081210613250732,
    "learning_rate": 0.001
  },
  {
    "episode": 8254,
    "reward": 90.530816,
    "length": 65,
    "time": 123370.010175,
    "actor_loss": -72.79851531982422,
    "critic_loss": 17.726476669311523,
    "ent_coef": 0.07078643143177032,
    "learning_rate": 0.001
  },
  {
    "episode": 8255,
    "reward": 85.880932,
    "length": 76,
    "time": 123383.285089,
    "actor_loss": -71.32559204101562,
    "critic_loss": 5.590962886810303,
    "ent_coef": 0.06732723861932755,
    "learning_rate": 0.001
  },
  {
    "episode": 8256,
    "reward": 89.424873,
    "length": 65,
    "time": 123395.69501,
    "actor_loss": -71.10704040527344,
    "critic_loss": 94.38814544677734,
    "ent_coef": 0.06663787364959717,
    "learning_rate": 0.001
  },
  {
    "episode": 8257,
    "reward": 91.36053,
    "length": 62,
    "time": 123406.96452,
    "actor_loss": -67.56901550292969,
    "critic_loss": 2.123037338256836,
    "ent_coef": 0.07200440764427185,
    "learning_rate": 0.001
  },
  {
    "episode": 8258,
    "reward": 89.42668,
    "length": 66,
    "time": 123419.483758,
    "actor_loss": -70.25498962402344,
    "critic_loss": 42.63409423828125,
    "ent_coef": 0.07088577002286911,
    "learning_rate": 0.001
  },
  {
    "episode": 8259,
    "reward": 89.721793,
    "length": 65,
    "time": 123432.397254,
    "actor_loss": -74.5521011352539,
    "critic_loss": 5.242751121520996,
    "ent_coef": 0.06957987695932388,
    "learning_rate": 0.001
  },
  {
    "episode": 8260,
    "reward": 89.929512,
    "length": 65,
    "time": 123444.333045,
    "actor_loss": -71.05419921875,
    "critic_loss": 2.2718801498413086,
    "ent_coef": 0.06789074838161469,
    "learning_rate": 0.001
  },
  {
    "episode": 8261,
    "reward": 78.518025,
    "length": 83,
    "time": 123461.802697,
    "actor_loss": -67.52630615234375,
    "critic_loss": 3.745352029800415,
    "ent_coef": 0.060302697122097015,
    "learning_rate": 0.001
  },
  {
    "episode": 8262,
    "reward": 89.47644,
    "length": 65,
    "time": 123475.759713,
    "actor_loss": -71.10240173339844,
    "critic_loss": 7.839691162109375,
    "ent_coef": 0.05883357301354408,
    "learning_rate": 0.001
  },
  {
    "episode": 8263,
    "reward": 90.987113,
    "length": 63,
    "time": 123488.078915,
    "actor_loss": -71.8150405883789,
    "critic_loss": 21.15155029296875,
    "ent_coef": 0.06067348271608353,
    "learning_rate": 0.001
  },
  {
    "episode": 8264,
    "reward": 89.489085,
    "length": 65,
    "time": 123499.817214,
    "actor_loss": -74.18636322021484,
    "critic_loss": 3.7178173065185547,
    "ent_coef": 0.06211395934224129,
    "learning_rate": 0.001
  },
  {
    "episode": 8265,
    "reward": 89.577125,
    "length": 65,
    "time": 123512.42819,
    "actor_loss": -67.75847625732422,
    "critic_loss": 3.256779432296753,
    "ent_coef": 0.060377087444067,
    "learning_rate": 0.001
  },
  {
    "episode": 8266,
    "reward": 90.412088,
    "length": 64,
    "time": 123524.97522,
    "actor_loss": -63.42586898803711,
    "critic_loss": 22.53814697265625,
    "ent_coef": 0.060214813798666,
    "learning_rate": 0.001
  },
  {
    "episode": 8267,
    "reward": 89.293141,
    "length": 67,
    "time": 123536.665749,
    "actor_loss": -67.41452026367188,
    "critic_loss": 67.09739685058594,
    "ent_coef": 0.05945902690291405,
    "learning_rate": 0.001
  },
  {
    "episode": 8268,
    "reward": 80.151332,
    "length": 83,
    "time": 123553.791222,
    "actor_loss": -70.2305679321289,
    "critic_loss": 2.4015936851501465,
    "ent_coef": 0.05262785777449608,
    "learning_rate": 0.001
  },
  {
    "episode": 8269,
    "reward": 88.317138,
    "length": 62,
    "time": 123566.936231,
    "actor_loss": -74.88919067382812,
    "critic_loss": 603.3367309570312,
    "ent_coef": 0.052509989589452744,
    "learning_rate": 0.001
  },
  {
    "episode": 8270,
    "reward": 92.48025,
    "length": 59,
    "time": 123581.619707,
    "actor_loss": -68.79400634765625,
    "critic_loss": 8.700904846191406,
    "ent_coef": 0.05710940435528755,
    "learning_rate": 0.001
  },
  {
    "episode": 8271,
    "reward": 91.299052,
    "length": 61,
    "time": 123593.063202,
    "actor_loss": -70.9616928100586,
    "critic_loss": 19.255151748657227,
    "ent_coef": 0.06047582998871803,
    "learning_rate": 0.001
  },
  {
    "episode": 8272,
    "reward": 91.055313,
    "length": 62,
    "time": 123604.082395,
    "actor_loss": -68.2047348022461,
    "critic_loss": 8.165901184082031,
    "ent_coef": 0.06247812882065773,
    "learning_rate": 0.001
  },
  {
    "episode": 8273,
    "reward": 89.79919,
    "length": 64,
    "time": 123615.359628,
    "actor_loss": -71.92649841308594,
    "critic_loss": 3.250596046447754,
    "ent_coef": 0.06293511390686035,
    "learning_rate": 0.001
  },
  {
    "episode": 8274,
    "reward": 88.120894,
    "length": 70,
    "time": 123628.001263,
    "actor_loss": -69.18875885009766,
    "critic_loss": 4.541306495666504,
    "ent_coef": 0.06005071848630905,
    "learning_rate": 0.001
  },
  {
    "episode": 8275,
    "reward": 87.910663,
    "length": 68,
    "time": 123642.73107,
    "actor_loss": -70.6373062133789,
    "critic_loss": 6.912864685058594,
    "ent_coef": 0.05771788954734802,
    "learning_rate": 0.001
  },
  {
    "episode": 8276,
    "reward": 89.138722,
    "length": 66,
    "time": 123655.916676,
    "actor_loss": -71.65690612792969,
    "critic_loss": 5.182107448577881,
    "ent_coef": 0.056132469326257706,
    "learning_rate": 0.001
  },
  {
    "episode": 8277,
    "reward": 86.500137,
    "length": 70,
    "time": 123669.843306,
    "actor_loss": -68.24293518066406,
    "critic_loss": 6.851898193359375,
    "ent_coef": 0.05456025153398514,
    "learning_rate": 0.001
  },
  {
    "episode": 8278,
    "reward": 89.490193,
    "length": 67,
    "time": 123682.687913,
    "actor_loss": -72.24507141113281,
    "critic_loss": 7.624232292175293,
    "ent_coef": 0.05219021067023277,
    "learning_rate": 0.001
  },
  {
    "episode": 8279,
    "reward": 85.724741,
    "length": 74,
    "time": 123695.386169,
    "actor_loss": -72.6727523803711,
    "critic_loss": 1.8099669218063354,
    "ent_coef": 0.04849192127585411,
    "learning_rate": 0.001
  },
  {
    "episode": 8280,
    "reward": 89.246069,
    "length": 66,
    "time": 123711.356133,
    "actor_loss": -71.2913589477539,
    "critic_loss": 5.4862518310546875,
    "ent_coef": 0.049558088183403015,
    "learning_rate": 0.001
  },
  {
    "episode": 8281,
    "reward": 90.77374,
    "length": 63,
    "time": 123724.952824,
    "actor_loss": -68.91639709472656,
    "critic_loss": 4.962859153747559,
    "ent_coef": 0.05213020741939545,
    "learning_rate": 0.001
  },
  {
    "episode": 8282,
    "reward": 87.839912,
    "length": 68,
    "time": 123742.772103,
    "actor_loss": -65.02725219726562,
    "critic_loss": 7.478921413421631,
    "ent_coef": 0.05238300934433937,
    "learning_rate": 0.001
  },
  {
    "episode": 8283,
    "reward": 90.887799,
    "length": 62,
    "time": 123753.708611,
    "actor_loss": -69.72042846679688,
    "critic_loss": 2.1473946571350098,
    "ent_coef": 0.05476875603199005,
    "learning_rate": 0.001
  },
  {
    "episode": 8284,
    "reward": 90.87853,
    "length": 62,
    "time": 123766.239689,
    "actor_loss": -75.82609558105469,
    "critic_loss": 3.4992008209228516,
    "ent_coef": 0.05681219324469566,
    "learning_rate": 0.001
  },
  {
    "episode": 8285,
    "reward": 90.284751,
    "length": 64,
    "time": 123777.553862,
    "actor_loss": -71.87982940673828,
    "critic_loss": 4.297484397888184,
    "ent_coef": 0.05772930011153221,
    "learning_rate": 0.001
  },
  {
    "episode": 8286,
    "reward": 83.820503,
    "length": 77,
    "time": 123791.988822,
    "actor_loss": -74.11769104003906,
    "critic_loss": 2.259535789489746,
    "ent_coef": 0.054728567600250244,
    "learning_rate": 0.001
  },
  {
    "episode": 8287,
    "reward": 70.35866,
    "length": 98,
    "time": 123808.392976,
    "actor_loss": -68.7589340209961,
    "critic_loss": 39.23660659790039,
    "ent_coef": 0.051660820841789246,
    "learning_rate": 0.001
  },
  {
    "episode": 8288,
    "reward": 87.86751,
    "length": 67,
    "time": 123822.575166,
    "actor_loss": -68.66143798828125,
    "critic_loss": 24.267757415771484,
    "ent_coef": 0.05023984983563423,
    "learning_rate": 0.001
  },
  {
    "episode": 8289,
    "reward": 89.590692,
    "length": 66,
    "time": 123834.507642,
    "actor_loss": -69.86375427246094,
    "critic_loss": 2.7841548919677734,
    "ent_coef": 0.05003800243139267,
    "learning_rate": 0.001
  },
  {
    "episode": 8290,
    "reward": 88.25315,
    "length": 68,
    "time": 123846.773011,
    "actor_loss": -73.15145111083984,
    "critic_loss": 10.107377052307129,
    "ent_coef": 0.05087112635374069,
    "learning_rate": 0.001
  },
  {
    "episode": 8291,
    "reward": 88.263031,
    "length": 69,
    "time": 123858.977307,
    "actor_loss": -70.84741973876953,
    "critic_loss": 6.050044059753418,
    "ent_coef": 0.05100265517830849,
    "learning_rate": 0.001
  },
  {
    "episode": 8292,
    "reward": 89.167448,
    "length": 69,
    "time": 123871.896521,
    "actor_loss": -69.0135726928711,
    "critic_loss": 26.9869441986084,
    "ent_coef": 0.05511060357093811,
    "learning_rate": 0.001
  },
  {
    "episode": 8293,
    "reward": 90.890018,
    "length": 63,
    "time": 123888.523185,
    "actor_loss": -69.7208480834961,
    "critic_loss": 3.147444009780884,
    "ent_coef": 0.06056331470608711,
    "learning_rate": 0.001
  },
  {
    "episode": 8294,
    "reward": 89.718765,
    "length": 65,
    "time": 123900.774935,
    "actor_loss": -72.75466918945312,
    "critic_loss": 2.50882625579834,
    "ent_coef": 0.06269093602895737,
    "learning_rate": 0.001
  },
  {
    "episode": 8295,
    "reward": 89.655704,
    "length": 65,
    "time": 123913.820873,
    "actor_loss": -73.2104263305664,
    "critic_loss": 42.24547576904297,
    "ent_coef": 0.06352528184652328,
    "learning_rate": 0.001
  },
  {
    "episode": 8296,
    "reward": 91.723951,
    "length": 61,
    "time": 123924.969949,
    "actor_loss": -72.86024475097656,
    "critic_loss": 45.962623596191406,
    "ent_coef": 0.06424141675233841,
    "learning_rate": 0.001
  },
  {
    "episode": 8297,
    "reward": 84.185917,
    "length": 83,
    "time": 123938.720644,
    "actor_loss": -64.93363952636719,
    "critic_loss": 6.267807483673096,
    "ent_coef": 0.06424105167388916,
    "learning_rate": 0.001
  },
  {
    "episode": 8298,
    "reward": 85.941043,
    "length": 77,
    "time": 123952.708501,
    "actor_loss": -68.69464111328125,
    "critic_loss": 15.267876625061035,
    "ent_coef": 0.05912422388792038,
    "learning_rate": 0.001
  },
  {
    "episode": 8299,
    "reward": 87.597248,
    "length": 71,
    "time": 123965.399444,
    "actor_loss": -74.51287841796875,
    "critic_loss": 4.011740684509277,
    "ent_coef": 0.05620260909199715,
    "learning_rate": 0.001
  },
  {
    "episode": 8300,
    "reward": 69.683941,
    "length": 184,
    "time": 123993.455191,
    "actor_loss": -72.06118774414062,
    "critic_loss": 4.134612083435059,
    "ent_coef": 0.053034842014312744,
    "learning_rate": 0.001
  },
  {
    "episode": 8301,
    "reward": 84.666786,
    "length": 78,
    "time": 124006.572773,
    "actor_loss": -72.14044952392578,
    "critic_loss": 7.71315860748291,
    "ent_coef": 0.05244588106870651,
    "learning_rate": 0.001
  },
  {
    "episode": 8302,
    "reward": 86.019913,
    "length": 74,
    "time": 124019.365894,
    "actor_loss": -72.86835479736328,
    "critic_loss": 17.34101676940918,
    "ent_coef": 0.04994528740644455,
    "learning_rate": 0.001
  },
  {
    "episode": 8303,
    "reward": 89.966775,
    "length": 69,
    "time": 124036.933808,
    "actor_loss": -70.52702331542969,
    "critic_loss": 4.661552906036377,
    "ent_coef": 0.05119837075471878,
    "learning_rate": 0.001
  },
  {
    "episode": 8304,
    "reward": 90.701585,
    "length": 63,
    "time": 124048.686268,
    "actor_loss": -75.12594604492188,
    "critic_loss": 1.7356183528900146,
    "ent_coef": 0.05241423100233078,
    "learning_rate": 0.001
  },
  {
    "episode": 8305,
    "reward": 89.522505,
    "length": 66,
    "time": 124060.174464,
    "actor_loss": -70.44865417480469,
    "critic_loss": 39.52104187011719,
    "ent_coef": 0.05548640340566635,
    "learning_rate": 0.001
  },
  {
    "episode": 8306,
    "reward": 89.13352,
    "length": 69,
    "time": 124072.884706,
    "actor_loss": -66.57974243164062,
    "critic_loss": 3.298961639404297,
    "ent_coef": 0.06006639450788498,
    "learning_rate": 0.001
  },
  {
    "episode": 8307,
    "reward": 88.368978,
    "length": 72,
    "time": 124085.229572,
    "actor_loss": -67.26628112792969,
    "critic_loss": 71.30072021484375,
    "ent_coef": 0.061606552451848984,
    "learning_rate": 0.001
  },
  {
    "episode": 8308,
    "reward": 90.563487,
    "length": 63,
    "time": 124097.440197,
    "actor_loss": -67.06108856201172,
    "critic_loss": 4.056156158447266,
    "ent_coef": 0.06210119649767876,
    "learning_rate": 0.001
  },
  {
    "episode": 8309,
    "reward": 88.71551,
    "length": 67,
    "time": 124112.035269,
    "actor_loss": -73.52342987060547,
    "critic_loss": 5.830960750579834,
    "ent_coef": 0.05945102125406265,
    "learning_rate": 0.001
  },
  {
    "episode": 8310,
    "reward": 88.543914,
    "length": 66,
    "time": 124125.500199,
    "actor_loss": -71.44159698486328,
    "critic_loss": 2.294696807861328,
    "ent_coef": 0.05903331935405731,
    "learning_rate": 0.001
  },
  {
    "episode": 8311,
    "reward": 90.874531,
    "length": 64,
    "time": 124138.011618,
    "actor_loss": -69.2909164428711,
    "critic_loss": 6.3827223777771,
    "ent_coef": 0.06020383536815643,
    "learning_rate": 0.001
  },
  {
    "episode": 8312,
    "reward": 90.987931,
    "length": 62,
    "time": 124150.133169,
    "actor_loss": -63.085052490234375,
    "critic_loss": 3.953484058380127,
    "ent_coef": 0.06028302013874054,
    "learning_rate": 0.001
  },
  {
    "episode": 8313,
    "reward": 90.086677,
    "length": 68,
    "time": 124162.115679,
    "actor_loss": -63.91626739501953,
    "critic_loss": 5.9153218269348145,
    "ent_coef": 0.061953235417604446,
    "learning_rate": 0.001
  },
  {
    "episode": 8314,
    "reward": 89.317959,
    "length": 65,
    "time": 124173.936445,
    "actor_loss": -67.96910095214844,
    "critic_loss": 3.2949016094207764,
    "ent_coef": 0.06223522871732712,
    "learning_rate": 0.001
  },
  {
    "episode": 8315,
    "reward": 91.429462,
    "length": 62,
    "time": 124184.995152,
    "actor_loss": -72.13337707519531,
    "critic_loss": 5.20046329498291,
    "ent_coef": 0.06224061921238899,
    "learning_rate": 0.001
  },
  {
    "episode": 8316,
    "reward": 89.651648,
    "length": 65,
    "time": 124196.951537,
    "actor_loss": -74.015380859375,
    "critic_loss": 3.7646806240081787,
    "ent_coef": 0.06325320899486542,
    "learning_rate": 0.001
  },
  {
    "episode": 8317,
    "reward": 89.304689,
    "length": 66,
    "time": 124211.497058,
    "actor_loss": -71.23700714111328,
    "critic_loss": 1.5195574760437012,
    "ent_coef": 0.06262531131505966,
    "learning_rate": 0.001
  },
  {
    "episode": 8318,
    "reward": 87.391223,
    "length": 69,
    "time": 124226.936164,
    "actor_loss": -63.662635803222656,
    "critic_loss": 16.439002990722656,
    "ent_coef": 0.06340963393449783,
    "learning_rate": 0.001
  },
  {
    "episode": 8319,
    "reward": 87.022637,
    "length": 71,
    "time": 124240.026137,
    "actor_loss": -62.85215759277344,
    "critic_loss": 3.8483176231384277,
    "ent_coef": 0.06337892264127731,
    "learning_rate": 0.001
  },
  {
    "episode": 8320,
    "reward": 88.302185,
    "length": 68,
    "time": 124254.592108,
    "actor_loss": -75.59437561035156,
    "critic_loss": 7.37156867980957,
    "ent_coef": 0.0629526749253273,
    "learning_rate": 0.001
  },
  {
    "episode": 8321,
    "reward": 88.182038,
    "length": 68,
    "time": 124266.703473,
    "actor_loss": -81.45904541015625,
    "critic_loss": 7.981291770935059,
    "ent_coef": 0.06491678953170776,
    "learning_rate": 0.001
  },
  {
    "episode": 8322,
    "reward": 88.629869,
    "length": 67,
    "time": 124278.530166,
    "actor_loss": -74.08668518066406,
    "critic_loss": 21.169265747070312,
    "ent_coef": 0.06854840368032455,
    "learning_rate": 0.001
  },
  {
    "episode": 8323,
    "reward": 85.169977,
    "length": 76,
    "time": 124291.584603,
    "actor_loss": -68.32115173339844,
    "critic_loss": 3.6791727542877197,
    "ent_coef": 0.06477092951536179,
    "learning_rate": 0.001
  },
  {
    "episode": 8324,
    "reward": 85.817569,
    "length": 74,
    "time": 124305.329973,
    "actor_loss": -65.6480484008789,
    "critic_loss": 3.697397232055664,
    "ent_coef": 0.060966990888118744,
    "learning_rate": 0.001
  },
  {
    "episode": 8325,
    "reward": 88.163647,
    "length": 74,
    "time": 124318.507774,
    "actor_loss": -78.70529174804688,
    "critic_loss": 3.828176498413086,
    "ent_coef": 0.06474350392818451,
    "learning_rate": 0.001
  },
  {
    "episode": 8326,
    "reward": 90.273595,
    "length": 65,
    "time": 124329.902192,
    "actor_loss": -67.6067123413086,
    "critic_loss": 1.968355655670166,
    "ent_coef": 0.06792575120925903,
    "learning_rate": 0.001
  },
  {
    "episode": 8327,
    "reward": 90.21866,
    "length": 64,
    "time": 124341.218019,
    "actor_loss": -68.99246215820312,
    "critic_loss": 5.8806328773498535,
    "ent_coef": 0.07040497660636902,
    "learning_rate": 0.001
  },
  {
    "episode": 8328,
    "reward": 91.713792,
    "length": 61,
    "time": 124355.814995,
    "actor_loss": -68.99664306640625,
    "critic_loss": 2.270216703414917,
    "ent_coef": 0.07373257726430893,
    "learning_rate": 0.001
  },
  {
    "episode": 8329,
    "reward": 89.116777,
    "length": 70,
    "time": 124369.127491,
    "actor_loss": -71.1048583984375,
    "critic_loss": 38.098655700683594,
    "ent_coef": 0.07245286554098129,
    "learning_rate": 0.001
  },
  {
    "episode": 8330,
    "reward": 90.41672,
    "length": 62,
    "time": 124382.777818,
    "actor_loss": -73.6441650390625,
    "critic_loss": 4.086515426635742,
    "ent_coef": 0.06858956813812256,
    "learning_rate": 0.001
  },
  {
    "episode": 8331,
    "reward": 82.165684,
    "length": 81,
    "time": 124400.515594,
    "actor_loss": -71.70178985595703,
    "critic_loss": 5.513599395751953,
    "ent_coef": 0.06259715557098389,
    "learning_rate": 0.001
  },
  {
    "episode": 8332,
    "reward": 88.97557,
    "length": 68,
    "time": 124413.5731,
    "actor_loss": -64.46922302246094,
    "critic_loss": 246.65689086914062,
    "ent_coef": 0.06253371387720108,
    "learning_rate": 0.001
  },
  {
    "episode": 8333,
    "reward": 91.078878,
    "length": 60,
    "time": 124427.627276,
    "actor_loss": -71.33519744873047,
    "critic_loss": 3.6183056831359863,
    "ent_coef": 0.06699251383543015,
    "learning_rate": 0.001
  },
  {
    "episode": 8334,
    "reward": 91.229619,
    "length": 63,
    "time": 124441.373408,
    "actor_loss": -73.20359802246094,
    "critic_loss": 19.216976165771484,
    "ent_coef": 0.07099428027868271,
    "learning_rate": 0.001
  },
  {
    "episode": 8335,
    "reward": 89.759514,
    "length": 65,
    "time": 124455.224795,
    "actor_loss": -72.80477905273438,
    "critic_loss": 41.47315216064453,
    "ent_coef": 0.0738193467259407,
    "learning_rate": 0.001
  },
  {
    "episode": 8336,
    "reward": 89.054387,
    "length": 65,
    "time": 124466.784256,
    "actor_loss": -68.55593872070312,
    "critic_loss": 11.085428237915039,
    "ent_coef": 0.07116639614105225,
    "learning_rate": 0.001
  },
  {
    "episode": 8337,
    "reward": 90.769105,
    "length": 63,
    "time": 124477.958755,
    "actor_loss": -71.49006652832031,
    "critic_loss": 3.307976245880127,
    "ent_coef": 0.07056333124637604,
    "learning_rate": 0.001
  },
  {
    "episode": 8338,
    "reward": 89.646976,
    "length": 65,
    "time": 124489.840485,
    "actor_loss": -72.46074676513672,
    "critic_loss": 29.646148681640625,
    "ent_coef": 0.06826644390821457,
    "learning_rate": 0.001
  },
  {
    "episode": 8339,
    "reward": 90.081636,
    "length": 64,
    "time": 124501.244373,
    "actor_loss": -73.27278900146484,
    "critic_loss": 39.970909118652344,
    "ent_coef": 0.06595907360315323,
    "learning_rate": 0.001
  },
  {
    "episode": 8340,
    "reward": 89.950699,
    "length": 65,
    "time": 124515.312767,
    "actor_loss": -69.61581420898438,
    "critic_loss": 14.971094131469727,
    "ent_coef": 0.06269389390945435,
    "learning_rate": 0.001
  },
  {
    "episode": 8341,
    "reward": 85.741324,
    "length": 70,
    "time": 124527.978557,
    "actor_loss": -75.49037170410156,
    "critic_loss": 5.048293113708496,
    "ent_coef": 0.05852045863866806,
    "learning_rate": 0.001
  },
  {
    "episode": 8342,
    "reward": 89.933834,
    "length": 63,
    "time": 124541.390465,
    "actor_loss": -74.38491821289062,
    "critic_loss": 1.9102566242218018,
    "ent_coef": 0.05717017501592636,
    "learning_rate": 0.001
  },
  {
    "episode": 8343,
    "reward": 89.078977,
    "length": 68,
    "time": 124557.164572,
    "actor_loss": -70.96168518066406,
    "critic_loss": 11.033531188964844,
    "ent_coef": 0.05985785648226738,
    "learning_rate": 0.001
  },
  {
    "episode": 8344,
    "reward": 89.844628,
    "length": 64,
    "time": 124569.014894,
    "actor_loss": -66.57736206054688,
    "critic_loss": 31.475685119628906,
    "ent_coef": 0.06031220033764839,
    "learning_rate": 0.001
  },
  {
    "episode": 8345,
    "reward": 88.715886,
    "length": 67,
    "time": 124583.764214,
    "actor_loss": -72.05430603027344,
    "critic_loss": 3.4065957069396973,
    "ent_coef": 0.058616623282432556,
    "learning_rate": 0.001
  },
  {
    "episode": 8346,
    "reward": 90.216055,
    "length": 64,
    "time": 124596.126702,
    "actor_loss": -71.46383666992188,
    "critic_loss": 2.1944680213928223,
    "ent_coef": 0.055483270436525345,
    "learning_rate": 0.001
  },
  {
    "episode": 8347,
    "reward": 92.2084,
    "length": 59,
    "time": 124606.667395,
    "actor_loss": -71.6378173828125,
    "critic_loss": 5.82694149017334,
    "ent_coef": 0.055540747940540314,
    "learning_rate": 0.001
  },
  {
    "episode": 8348,
    "reward": 91.924844,
    "length": 60,
    "time": 124619.536968,
    "actor_loss": -71.75639343261719,
    "critic_loss": 3.315645694732666,
    "ent_coef": 0.06326725333929062,
    "learning_rate": 0.001
  },
  {
    "episode": 8349,
    "reward": 89.963861,
    "length": 68,
    "time": 124632.545098,
    "actor_loss": -67.6771011352539,
    "critic_loss": 5.74886417388916,
    "ent_coef": 0.06990952044725418,
    "learning_rate": 0.001
  },
  {
    "episode": 8350,
    "reward": 88.342047,
    "length": 69,
    "time": 124644.588717,
    "actor_loss": -71.80387878417969,
    "critic_loss": 1.9711869955062866,
    "ent_coef": 0.07222124934196472,
    "learning_rate": 0.001
  },
  {
    "episode": 8351,
    "reward": 88.409021,
    "length": 67,
    "time": 124656.491948,
    "actor_loss": -68.06776428222656,
    "critic_loss": 16.111732482910156,
    "ent_coef": 0.06846468150615692,
    "learning_rate": 0.001
  },
  {
    "episode": 8352,
    "reward": 88.298984,
    "length": 70,
    "time": 124671.782712,
    "actor_loss": -68.65129089355469,
    "critic_loss": 7.252726078033447,
    "ent_coef": 0.06405441462993622,
    "learning_rate": 0.001
  },
  {
    "episode": 8353,
    "reward": 89.824148,
    "length": 64,
    "time": 124684.486825,
    "actor_loss": -67.35860443115234,
    "critic_loss": 12.033185958862305,
    "ent_coef": 0.06186222657561302,
    "learning_rate": 0.001
  },
  {
    "episode": 8354,
    "reward": 89.724056,
    "length": 65,
    "time": 124696.150161,
    "actor_loss": -70.55473327636719,
    "critic_loss": 1.8493142127990723,
    "ent_coef": 0.060820359736680984,
    "learning_rate": 0.001
  },
  {
    "episode": 8355,
    "reward": 90.061896,
    "length": 65,
    "time": 124708.856008,
    "actor_loss": -66.33584594726562,
    "critic_loss": 2.6672730445861816,
    "ent_coef": 0.060520678758621216,
    "learning_rate": 0.001
  },
  {
    "episode": 8356,
    "reward": 86.64453,
    "length": 69,
    "time": 124720.817731,
    "actor_loss": -76.04292297363281,
    "critic_loss": 5.191661357879639,
    "ent_coef": 0.0590556301176548,
    "learning_rate": 0.001
  },
  {
    "episode": 8357,
    "reward": 89.811213,
    "length": 67,
    "time": 124734.407085,
    "actor_loss": -74.3875503540039,
    "critic_loss": 13.25069522857666,
    "ent_coef": 0.060199230909347534,
    "learning_rate": 0.001
  },
  {
    "episode": 8358,
    "reward": 90.602089,
    "length": 63,
    "time": 124745.945792,
    "actor_loss": -70.09510803222656,
    "critic_loss": 1.833400011062622,
    "ent_coef": 0.06194303184747696,
    "learning_rate": 0.001
  },
  {
    "episode": 8359,
    "reward": 88.19395,
    "length": 69,
    "time": 124758.982611,
    "actor_loss": -67.35855102539062,
    "critic_loss": 4.438565731048584,
    "ent_coef": 0.059487827122211456,
    "learning_rate": 0.001
  },
  {
    "episode": 8360,
    "reward": 88.328925,
    "length": 68,
    "time": 124773.636759,
    "actor_loss": -71.46790313720703,
    "critic_loss": 11.36054801940918,
    "ent_coef": 0.05794191360473633,
    "learning_rate": 0.001
  },
  {
    "episode": 8361,
    "reward": 87.216118,
    "length": 68,
    "time": 124786.028543,
    "actor_loss": -67.29295349121094,
    "critic_loss": 12.759471893310547,
    "ent_coef": 0.059826482087373734,
    "learning_rate": 0.001
  },
  {
    "episode": 8362,
    "reward": 89.459159,
    "length": 65,
    "time": 124800.286077,
    "actor_loss": -67.39706420898438,
    "critic_loss": 5.713099479675293,
    "ent_coef": 0.061245329678058624,
    "learning_rate": 0.001
  },
  {
    "episode": 8363,
    "reward": 89.615433,
    "length": 64,
    "time": 124811.852403,
    "actor_loss": -74.36756896972656,
    "critic_loss": 8.183951377868652,
    "ent_coef": 0.06018444895744324,
    "learning_rate": 0.001
  },
  {
    "episode": 8364,
    "reward": 87.925481,
    "length": 70,
    "time": 124824.993124,
    "actor_loss": -70.35337829589844,
    "critic_loss": 3.962761878967285,
    "ent_coef": 0.058117203414440155,
    "learning_rate": 0.001
  },
  {
    "episode": 8365,
    "reward": 89.721068,
    "length": 64,
    "time": 124836.318489,
    "actor_loss": -73.14230346679688,
    "critic_loss": 8.687944412231445,
    "ent_coef": 0.059456322342157364,
    "learning_rate": 0.001
  },
  {
    "episode": 8366,
    "reward": 83.872773,
    "length": 76,
    "time": 124850.353125,
    "actor_loss": -76.4190444946289,
    "critic_loss": 2.489102363586426,
    "ent_coef": 0.056087639182806015,
    "learning_rate": 0.001
  },
  {
    "episode": 8367,
    "reward": 86.791157,
    "length": 71,
    "time": 124864.056478,
    "actor_loss": -72.90864562988281,
    "critic_loss": 54.514320373535156,
    "ent_coef": 0.05347500368952751,
    "learning_rate": 0.001
  },
  {
    "episode": 8368,
    "reward": 85.509932,
    "length": 71,
    "time": 124877.484428,
    "actor_loss": -68.05436706542969,
    "critic_loss": 10.380264282226562,
    "ent_coef": 0.052010465413331985,
    "learning_rate": 0.001
  },
  {
    "episode": 8369,
    "reward": 86.978403,
    "length": 68,
    "time": 124889.631351,
    "actor_loss": -70.0582275390625,
    "critic_loss": 4.690551280975342,
    "ent_coef": 0.05397050827741623,
    "learning_rate": 0.001
  },
  {
    "episode": 8370,
    "reward": 89.030369,
    "length": 66,
    "time": 124901.677898,
    "actor_loss": -67.62083435058594,
    "critic_loss": 11.99924087524414,
    "ent_coef": 0.0529179573059082,
    "learning_rate": 0.001
  },
  {
    "episode": 8371,
    "reward": 84.209045,
    "length": 73,
    "time": 124916.756243,
    "actor_loss": -73.03211212158203,
    "critic_loss": 1.728584885597229,
    "ent_coef": 0.05237333104014397,
    "learning_rate": 0.001
  },
  {
    "episode": 8372,
    "reward": 89.015087,
    "length": 66,
    "time": 124930.852046,
    "actor_loss": -75.43470001220703,
    "critic_loss": 12.964164733886719,
    "ent_coef": 0.05345311760902405,
    "learning_rate": 0.001
  },
  {
    "episode": 8373,
    "reward": 90.480083,
    "length": 63,
    "time": 124944.054824,
    "actor_loss": -64.47193145751953,
    "critic_loss": 5.057548999786377,
    "ent_coef": 0.057011112570762634,
    "learning_rate": 0.001
  },
  {
    "episode": 8374,
    "reward": 88.716375,
    "length": 66,
    "time": 124956.234651,
    "actor_loss": -68.62261962890625,
    "critic_loss": 18.229312896728516,
    "ent_coef": 0.060327861458063126,
    "learning_rate": 0.001
  },
  {
    "episode": 8375,
    "reward": 86.935478,
    "length": 70,
    "time": 124968.324075,
    "actor_loss": -67.29469299316406,
    "critic_loss": 3.5804386138916016,
    "ent_coef": 0.06429851055145264,
    "learning_rate": 0.001
  },
  {
    "episode": 8376,
    "reward": 90.07816,
    "length": 64,
    "time": 124979.708734,
    "actor_loss": -76.6279296875,
    "critic_loss": 6.558657169342041,
    "ent_coef": 0.06435862928628922,
    "learning_rate": 0.001
  },
  {
    "episode": 8377,
    "reward": 83.71465,
    "length": 73,
    "time": 124996.484582,
    "actor_loss": -70.21690368652344,
    "critic_loss": 55.70317840576172,
    "ent_coef": 0.061709970235824585,
    "learning_rate": 0.001
  },
  {
    "episode": 8378,
    "reward": 87.708867,
    "length": 68,
    "time": 125009.551713,
    "actor_loss": -67.22805786132812,
    "critic_loss": 3.2027392387390137,
    "ent_coef": 0.06179571524262428,
    "learning_rate": 0.001
  },
  {
    "episode": 8379,
    "reward": 90.491527,
    "length": 62,
    "time": 125020.520662,
    "actor_loss": -71.72953033447266,
    "critic_loss": 4.7228803634643555,
    "ent_coef": 0.06252267211675644,
    "learning_rate": 0.001
  },
  {
    "episode": 8380,
    "reward": 84.345289,
    "length": 78,
    "time": 125033.486682,
    "actor_loss": -72.09835815429688,
    "critic_loss": 3.5360047817230225,
    "ent_coef": 0.05808933451771736,
    "learning_rate": 0.001
  },
  {
    "episode": 8381,
    "reward": 81.861743,
    "length": 76,
    "time": 125049.417112,
    "actor_loss": -71.090087890625,
    "critic_loss": 2.391611337661743,
    "ent_coef": 0.055223479866981506,
    "learning_rate": 0.001
  },
  {
    "episode": 8382,
    "reward": 90.997419,
    "length": 62,
    "time": 125062.119908,
    "actor_loss": -76.00595092773438,
    "critic_loss": 3.4051547050476074,
    "ent_coef": 0.05880587920546532,
    "learning_rate": 0.001
  },
  {
    "episode": 8383,
    "reward": 87.947674,
    "length": 67,
    "time": 125076.634409,
    "actor_loss": -72.83755493164062,
    "critic_loss": 4.095840930938721,
    "ent_coef": 0.060647640377283096,
    "learning_rate": 0.001
  },
  {
    "episode": 8384,
    "reward": 87.319052,
    "length": 68,
    "time": 125090.513519,
    "actor_loss": -72.02726745605469,
    "critic_loss": 3.7860236167907715,
    "ent_coef": 0.0610954649746418,
    "learning_rate": 0.001
  },
  {
    "episode": 8385,
    "reward": 85.208622,
    "length": 71,
    "time": 125103.852568,
    "actor_loss": -68.37553405761719,
    "critic_loss": 14.894319534301758,
    "ent_coef": 0.06177463382482529,
    "learning_rate": 0.001
  },
  {
    "episode": 8386,
    "reward": 84.962019,
    "length": 72,
    "time": 125116.45575,
    "actor_loss": -73.63092041015625,
    "critic_loss": 23.20819091796875,
    "ent_coef": 0.06130142882466316,
    "learning_rate": 0.001
  },
  {
    "episode": 8387,
    "reward": 85.657603,
    "length": 75,
    "time": 125129.308888,
    "actor_loss": -71.45701599121094,
    "critic_loss": 9.011849403381348,
    "ent_coef": 0.05945121496915817,
    "learning_rate": 0.001
  },
  {
    "episode": 8388,
    "reward": 88.682996,
    "length": 66,
    "time": 125140.9577,
    "actor_loss": -65.36495208740234,
    "critic_loss": 4.761075496673584,
    "ent_coef": 0.05625980719923973,
    "learning_rate": 0.001
  },
  {
    "episode": 8389,
    "reward": 89.630085,
    "length": 66,
    "time": 125152.688917,
    "actor_loss": -73.84425354003906,
    "critic_loss": 7.245624542236328,
    "ent_coef": 0.05740289390087128,
    "learning_rate": 0.001
  },
  {
    "episode": 8390,
    "reward": 89.039833,
    "length": 64,
    "time": 125165.110579,
    "actor_loss": -63.96961975097656,
    "critic_loss": 38.25220489501953,
    "ent_coef": 0.05900917574763298,
    "learning_rate": 0.001
  },
  {
    "episode": 8391,
    "reward": 86.652558,
    "length": 69,
    "time": 125177.422136,
    "actor_loss": -73.842041015625,
    "critic_loss": 84.7540054321289,
    "ent_coef": 0.05699026212096214,
    "learning_rate": 0.001
  },
  {
    "episode": 8392,
    "reward": 88.253296,
    "length": 67,
    "time": 125190.441579,
    "actor_loss": -70.08073425292969,
    "critic_loss": 4.455378532409668,
    "ent_coef": 0.056324709206819534,
    "learning_rate": 0.001
  },
  {
    "episode": 8393,
    "reward": 88.57956,
    "length": 67,
    "time": 125202.620637,
    "actor_loss": -73.40837097167969,
    "critic_loss": 67.59310913085938,
    "ent_coef": 0.05653425306081772,
    "learning_rate": 0.001
  },
  {
    "episode": 8394,
    "reward": 90.653318,
    "length": 62,
    "time": 125214.743642,
    "actor_loss": -71.83535766601562,
    "critic_loss": 3.2079739570617676,
    "ent_coef": 0.05943867564201355,
    "learning_rate": 0.001
  },
  {
    "episode": 8395,
    "reward": 89.599584,
    "length": 64,
    "time": 125225.90123,
    "actor_loss": -68.51963806152344,
    "critic_loss": 2.9816384315490723,
    "ent_coef": 0.06014152988791466,
    "learning_rate": 0.001
  },
  {
    "episode": 8396,
    "reward": 88.688794,
    "length": 67,
    "time": 125241.408055,
    "actor_loss": -74.85301208496094,
    "critic_loss": 22.292673110961914,
    "ent_coef": 0.059782665222883224,
    "learning_rate": 0.001
  },
  {
    "episode": 8397,
    "reward": 86.307807,
    "length": 80,
    "time": 125258.249218,
    "actor_loss": -74.31513977050781,
    "critic_loss": 34.71990203857422,
    "ent_coef": 0.06137703359127045,
    "learning_rate": 0.001
  },
  {
    "episode": 8398,
    "reward": 91.11134,
    "length": 60,
    "time": 125273.613508,
    "actor_loss": -72.07884216308594,
    "critic_loss": 48.36677551269531,
    "ent_coef": 0.06613554060459137,
    "learning_rate": 0.001
  },
  {
    "episode": 8399,
    "reward": 79.137398,
    "length": 76,
    "time": 125286.336221,
    "actor_loss": -72.97576904296875,
    "critic_loss": 180.71331787109375,
    "ent_coef": 0.07116314023733139,
    "learning_rate": 0.001
  },
  {
    "episode": 8400,
    "reward": 86.488954,
    "length": 69,
    "time": 125300.460099,
    "actor_loss": -71.83750915527344,
    "critic_loss": 135.77899169921875,
    "ent_coef": 0.06690565496683121,
    "learning_rate": 0.001
  },
  {
    "episode": 8401,
    "reward": 87.904026,
    "length": 67,
    "time": 125313.292215,
    "actor_loss": -69.68950653076172,
    "critic_loss": 3.9078502655029297,
    "ent_coef": 0.0653204545378685,
    "learning_rate": 0.001
  },
  {
    "episode": 8402,
    "reward": 91.353144,
    "length": 61,
    "time": 125325.092219,
    "actor_loss": -69.09630584716797,
    "critic_loss": 3.8562240600585938,
    "ent_coef": 0.06759458035230637,
    "learning_rate": 0.001
  },
  {
    "episode": 8403,
    "reward": 86.970771,
    "length": 69,
    "time": 125337.728271,
    "actor_loss": -64.54875183105469,
    "critic_loss": 2.159090995788574,
    "ent_coef": 0.06539880484342575,
    "learning_rate": 0.001
  },
  {
    "episode": 8404,
    "reward": 65.026868,
    "length": 175,
    "time": 125365.798808,
    "actor_loss": -70.99734497070312,
    "critic_loss": 4.958374977111816,
    "ent_coef": 0.056671347469091415,
    "learning_rate": 0.001
  },
  {
    "episode": 8405,
    "reward": 90.694193,
    "length": 61,
    "time": 125376.789981,
    "actor_loss": -73.53870391845703,
    "critic_loss": 4.7629828453063965,
    "ent_coef": 0.06150924414396286,
    "learning_rate": 0.001
  },
  {
    "episode": 8406,
    "reward": -162.339407,
    "length": 166,
    "time": 125401.157656,
    "actor_loss": -71.4954833984375,
    "critic_loss": 3.1642496585845947,
    "ent_coef": 0.07146306335926056,
    "learning_rate": 0.001
  },
  {
    "episode": 8407,
    "reward": 89.143659,
    "length": 66,
    "time": 125412.639786,
    "actor_loss": -67.86824035644531,
    "critic_loss": 12.879871368408203,
    "ent_coef": 0.07139705121517181,
    "learning_rate": 0.001
  },
  {
    "episode": 8408,
    "reward": 87.316159,
    "length": 71,
    "time": 125425.041512,
    "actor_loss": -66.15577697753906,
    "critic_loss": 114.24540710449219,
    "ent_coef": 0.07057575136423111,
    "learning_rate": 0.001
  },
  {
    "episode": 8409,
    "reward": 82.280174,
    "length": 77,
    "time": 125440.859916,
    "actor_loss": -74.22968292236328,
    "critic_loss": 5.519081115722656,
    "ent_coef": 0.07179000228643417,
    "learning_rate": 0.001
  },
  {
    "episode": 8410,
    "reward": 89.136341,
    "length": 65,
    "time": 125454.326579,
    "actor_loss": -74.37141418457031,
    "critic_loss": 40.723445892333984,
    "ent_coef": 0.07329585403203964,
    "learning_rate": 0.001
  },
  {
    "episode": 8411,
    "reward": 88.460974,
    "length": 67,
    "time": 125467.111564,
    "actor_loss": -76.05824279785156,
    "critic_loss": 3.777066946029663,
    "ent_coef": 0.07299429178237915,
    "learning_rate": 0.001
  },
  {
    "episode": 8412,
    "reward": 89.552039,
    "length": 64,
    "time": 125481.220245,
    "actor_loss": -73.13683319091797,
    "critic_loss": 20.50045394897461,
    "ent_coef": 0.07360097765922546,
    "learning_rate": 0.001
  },
  {
    "episode": 8413,
    "reward": 90.412656,
    "length": 62,
    "time": 125492.786279,
    "actor_loss": -72.50315856933594,
    "critic_loss": 6.608180999755859,
    "ent_coef": 0.07541024684906006,
    "learning_rate": 0.001
  },
  {
    "episode": 8414,
    "reward": 89.342313,
    "length": 68,
    "time": 125506.550288,
    "actor_loss": -63.42442321777344,
    "critic_loss": 5.2654523849487305,
    "ent_coef": 0.08175534754991531,
    "learning_rate": 0.001
  },
  {
    "episode": 8415,
    "reward": 89.917142,
    "length": 64,
    "time": 125517.980915,
    "actor_loss": -71.34500122070312,
    "critic_loss": 113.27247619628906,
    "ent_coef": 0.08349204808473587,
    "learning_rate": 0.001
  },
  {
    "episode": 8416,
    "reward": 85.505021,
    "length": 74,
    "time": 125533.538661,
    "actor_loss": -72.71896362304688,
    "critic_loss": 2.842867374420166,
    "ent_coef": 0.07923027127981186,
    "learning_rate": 0.001
  },
  {
    "episode": 8417,
    "reward": 66.564636,
    "length": 103,
    "time": 125550.276146,
    "actor_loss": -69.17379760742188,
    "critic_loss": 11.69334602355957,
    "ent_coef": 0.07044713199138641,
    "learning_rate": 0.001
  },
  {
    "episode": 8418,
    "reward": 43.44289,
    "length": 135,
    "time": 125570.841471,
    "actor_loss": -66.43528747558594,
    "critic_loss": 6.372720718383789,
    "ent_coef": 0.05839620158076286,
    "learning_rate": 0.001
  },
  {
    "episode": 8419,
    "reward": 76.539184,
    "length": 89,
    "time": 125589.445,
    "actor_loss": -74.37286376953125,
    "critic_loss": 25.686519622802734,
    "ent_coef": 0.05284843593835831,
    "learning_rate": 0.001
  },
  {
    "episode": 8420,
    "reward": 87.196305,
    "length": 69,
    "time": 125601.734874,
    "actor_loss": -68.29313659667969,
    "critic_loss": 10.686652183532715,
    "ent_coef": 0.0506269671022892,
    "learning_rate": 0.001
  },
  {
    "episode": 8421,
    "reward": 87.087801,
    "length": 69,
    "time": 125615.844203,
    "actor_loss": -65.1407241821289,
    "critic_loss": 4.449667930603027,
    "ent_coef": 0.04864169657230377,
    "learning_rate": 0.001
  },
  {
    "episode": 8422,
    "reward": 74.76841,
    "length": 157,
    "time": 125640.215234,
    "actor_loss": -73.88243103027344,
    "critic_loss": 30.374011993408203,
    "ent_coef": 0.05286300182342529,
    "learning_rate": 0.001
  },
  {
    "episode": 8423,
    "reward": 90.919534,
    "length": 62,
    "time": 125651.056499,
    "actor_loss": -65.671142578125,
    "critic_loss": 7.962951183319092,
    "ent_coef": 0.05569472536444664,
    "learning_rate": 0.001
  },
  {
    "episode": 8424,
    "reward": 77.813717,
    "length": 180,
    "time": 125677.231002,
    "actor_loss": -76.33855438232422,
    "critic_loss": 10.487815856933594,
    "ent_coef": 0.05769118294119835,
    "learning_rate": 0.001
  },
  {
    "episode": 8425,
    "reward": 89.322809,
    "length": 67,
    "time": 125690.034094,
    "actor_loss": -71.24539184570312,
    "critic_loss": 15.036494255065918,
    "ent_coef": 0.05728832259774208,
    "learning_rate": 0.001
  },
  {
    "episode": 8426,
    "reward": 81.502871,
    "length": 92,
    "time": 125704.860656,
    "actor_loss": -71.9690933227539,
    "critic_loss": 1.8697774410247803,
    "ent_coef": 0.059258319437503815,
    "learning_rate": 0.001
  },
  {
    "episode": 8427,
    "reward": -158.096536,
    "length": 149,
    "time": 125727.232017,
    "actor_loss": -70.5329818725586,
    "critic_loss": 18.262285232543945,
    "ent_coef": 0.058515921235084534,
    "learning_rate": 0.001
  },
  {
    "episode": 8428,
    "reward": 84.147084,
    "length": 80,
    "time": 125740.341583,
    "actor_loss": -73.96937561035156,
    "critic_loss": 9.142341613769531,
    "ent_coef": 0.058965686708688736,
    "learning_rate": 0.001
  },
  {
    "episode": 8429,
    "reward": 91.386662,
    "length": 61,
    "time": 125753.696867,
    "actor_loss": -76.67595672607422,
    "critic_loss": 7.260519981384277,
    "ent_coef": 0.06290796399116516,
    "learning_rate": 0.001
  },
  {
    "episode": 8430,
    "reward": 90.700925,
    "length": 63,
    "time": 125765.072919,
    "actor_loss": -76.76602172851562,
    "critic_loss": 37.577781677246094,
    "ent_coef": 0.06933168321847916,
    "learning_rate": 0.001
  },
  {
    "episode": 8431,
    "reward": 85.905868,
    "length": 78,
    "time": 125780.371117,
    "actor_loss": -70.11456298828125,
    "critic_loss": 22.91911506652832,
    "ent_coef": 0.07296550273895264,
    "learning_rate": 0.001
  },
  {
    "episode": 8432,
    "reward": 89.681631,
    "length": 64,
    "time": 125793.259195,
    "actor_loss": -78.1503677368164,
    "critic_loss": 40.552982330322266,
    "ent_coef": 0.07448537647724152,
    "learning_rate": 0.001
  },
  {
    "episode": 8433,
    "reward": 90.345085,
    "length": 62,
    "time": 125807.086695,
    "actor_loss": -67.21166229248047,
    "critic_loss": 7.2509379386901855,
    "ent_coef": 0.07597734034061432,
    "learning_rate": 0.001
  },
  {
    "episode": 8434,
    "reward": 71.442331,
    "length": 221,
    "time": 125840.536459,
    "actor_loss": -69.34635162353516,
    "critic_loss": 3.261474609375,
    "ent_coef": 0.07165896147489548,
    "learning_rate": 0.001
  },
  {
    "episode": 8435,
    "reward": 79.093559,
    "length": 91,
    "time": 125855.038974,
    "actor_loss": -69.08897399902344,
    "critic_loss": 3.9110496044158936,
    "ent_coef": 0.07007641345262527,
    "learning_rate": 0.001
  },
  {
    "episode": 8436,
    "reward": 87.401918,
    "length": 72,
    "time": 125867.62748,
    "actor_loss": -72.545166015625,
    "critic_loss": 2.050257921218872,
    "ent_coef": 0.07164326310157776,
    "learning_rate": 0.001
  },
  {
    "episode": 8437,
    "reward": 79.588807,
    "length": 127,
    "time": 125891.093591,
    "actor_loss": -66.90357208251953,
    "critic_loss": 5.088394641876221,
    "ent_coef": 0.07405249774456024,
    "learning_rate": 0.001
  },
  {
    "episode": 8438,
    "reward": 83.898693,
    "length": 77,
    "time": 125904.269404,
    "actor_loss": -64.49256896972656,
    "critic_loss": 46.724571228027344,
    "ent_coef": 0.07097818702459335,
    "learning_rate": 0.001
  },
  {
    "episode": 8439,
    "reward": 84.881799,
    "length": 77,
    "time": 125917.340009,
    "actor_loss": -69.6741714477539,
    "critic_loss": 2.897421360015869,
    "ent_coef": 0.06716025620698929,
    "learning_rate": 0.001
  },
  {
    "episode": 8440,
    "reward": 85.912485,
    "length": 74,
    "time": 125930.04075,
    "actor_loss": -67.68907928466797,
    "critic_loss": 2.2477855682373047,
    "ent_coef": 0.06487628072500229,
    "learning_rate": 0.001
  },
  {
    "episode": 8441,
    "reward": 87.106468,
    "length": 70,
    "time": 125943.100857,
    "actor_loss": -63.68074417114258,
    "critic_loss": 45.17472839355469,
    "ent_coef": 0.06550024449825287,
    "learning_rate": 0.001
  },
  {
    "episode": 8442,
    "reward": 85.106156,
    "length": 79,
    "time": 125958.394476,
    "actor_loss": -73.51469421386719,
    "critic_loss": 26.583663940429688,
    "ent_coef": 0.06458988040685654,
    "learning_rate": 0.001
  },
  {
    "episode": 8443,
    "reward": 86.44172,
    "length": 72,
    "time": 125974.862856,
    "actor_loss": -73.42501068115234,
    "critic_loss": 4.205451011657715,
    "ent_coef": 0.06403184682130814,
    "learning_rate": 0.001
  },
  {
    "episode": 8444,
    "reward": 79.804623,
    "length": 89,
    "time": 125990.368227,
    "actor_loss": -69.49507141113281,
    "critic_loss": 4.658568382263184,
    "ent_coef": 0.06314082443714142,
    "learning_rate": 0.001
  },
  {
    "episode": 8445,
    "reward": 84.236079,
    "length": 80,
    "time": 126003.83728,
    "actor_loss": -71.77696228027344,
    "critic_loss": 70.85317993164062,
    "ent_coef": 0.06477447599172592,
    "learning_rate": 0.001
  },
  {
    "episode": 8446,
    "reward": 78.166749,
    "length": 94,
    "time": 126019.185153,
    "actor_loss": -72.2742919921875,
    "critic_loss": 5.351889610290527,
    "ent_coef": 0.07011488080024719,
    "learning_rate": 0.001
  },
  {
    "episode": 8447,
    "reward": 76.95847,
    "length": 96,
    "time": 126036.893278,
    "actor_loss": -65.82891082763672,
    "critic_loss": 10.399887084960938,
    "ent_coef": 0.06673330813646317,
    "learning_rate": 0.001
  },
  {
    "episode": 8448,
    "reward": -14.657754,
    "length": 195,
    "time": 126067.980162,
    "actor_loss": -66.45077514648438,
    "critic_loss": 79.79898071289062,
    "ent_coef": 0.06292306631803513,
    "learning_rate": 0.001
  },
  {
    "episode": 8449,
    "reward": 85.306969,
    "length": 70,
    "time": 126082.087024,
    "actor_loss": -70.443603515625,
    "critic_loss": 55.661842346191406,
    "ent_coef": 0.0620977021753788,
    "learning_rate": 0.001
  },
  {
    "episode": 8450,
    "reward": 73.164047,
    "length": 144,
    "time": 126103.606362,
    "actor_loss": -69.57658386230469,
    "critic_loss": 2.8832926750183105,
    "ent_coef": 0.0706498771905899,
    "learning_rate": 0.001
  },
  {
    "episode": 8451,
    "reward": 77.144435,
    "length": 93,
    "time": 126119.488268,
    "actor_loss": -75.52859497070312,
    "critic_loss": 6.724923133850098,
    "ent_coef": 0.06750362366437912,
    "learning_rate": 0.001
  },
  {
    "episode": 8452,
    "reward": 73.276709,
    "length": 135,
    "time": 126139.989352,
    "actor_loss": -66.61511993408203,
    "critic_loss": 8.611464500427246,
    "ent_coef": 0.06664090603590012,
    "learning_rate": 0.001
  },
  {
    "episode": 8453,
    "reward": 75.503236,
    "length": 133,
    "time": 126160.509269,
    "actor_loss": -74.65412902832031,
    "critic_loss": 14.30843448638916,
    "ent_coef": 0.0683441162109375,
    "learning_rate": 0.001
  },
  {
    "episode": 8454,
    "reward": 54.773725,
    "length": 208,
    "time": 126190.794072,
    "actor_loss": -68.52975463867188,
    "critic_loss": 29.666107177734375,
    "ent_coef": 0.07096270471811295,
    "learning_rate": 0.001
  },
  {
    "episode": 8455,
    "reward": 81.655589,
    "length": 89,
    "time": 126205.875694,
    "actor_loss": -67.17781066894531,
    "critic_loss": 5.60075044631958,
    "ent_coef": 0.07432043552398682,
    "learning_rate": 0.001
  },
  {
    "episode": 8456,
    "reward": 87.759018,
    "length": 72,
    "time": 126219.592973,
    "actor_loss": -67.65957641601562,
    "critic_loss": 4.581396102905273,
    "ent_coef": 0.0725988820195198,
    "learning_rate": 0.001
  },
  {
    "episode": 8457,
    "reward": 85.91399,
    "length": 74,
    "time": 126232.137372,
    "actor_loss": -73.43895721435547,
    "critic_loss": 1.8746694326400757,
    "ent_coef": 0.07548334449529648,
    "learning_rate": 0.001
  },
  {
    "episode": 8458,
    "reward": 82.104998,
    "length": 116,
    "time": 126251.107624,
    "actor_loss": -74.01354217529297,
    "critic_loss": 16.579410552978516,
    "ent_coef": 0.07971179485321045,
    "learning_rate": 0.001
  },
  {
    "episode": 8459,
    "reward": 74.350476,
    "length": 131,
    "time": 126271.180246,
    "actor_loss": -66.26486206054688,
    "critic_loss": 2.9074289798736572,
    "ent_coef": 0.07721496373414993,
    "learning_rate": 0.001
  },
  {
    "episode": 8460,
    "reward": 83.554196,
    "length": 80,
    "time": 126284.624888,
    "actor_loss": -65.39891815185547,
    "critic_loss": 48.893463134765625,
    "ent_coef": 0.07772650569677353,
    "learning_rate": 0.001
  },
  {
    "episode": 8461,
    "reward": 83.021712,
    "length": 77,
    "time": 126297.911053,
    "actor_loss": -74.3705062866211,
    "critic_loss": 16.1551570892334,
    "ent_coef": 0.07329382747411728,
    "learning_rate": 0.001
  },
  {
    "episode": 8462,
    "reward": 71.725399,
    "length": 102,
    "time": 126314.100841,
    "actor_loss": -69.3398208618164,
    "critic_loss": 3.4990553855895996,
    "ent_coef": 0.0711885616183281,
    "learning_rate": 0.001
  },
  {
    "episode": 8463,
    "reward": 82.782091,
    "length": 79,
    "time": 126329.096776,
    "actor_loss": -71.60200500488281,
    "critic_loss": 12.835301399230957,
    "ent_coef": 0.06335406005382538,
    "learning_rate": 0.001
  },
  {
    "episode": 8464,
    "reward": 74.968372,
    "length": 145,
    "time": 126351.838216,
    "actor_loss": -71.46997833251953,
    "critic_loss": 4.537310600280762,
    "ent_coef": 0.06496603041887283,
    "learning_rate": 0.001
  },
  {
    "episode": 8465,
    "reward": 83.272906,
    "length": 76,
    "time": 126366.02131,
    "actor_loss": -71.18287658691406,
    "critic_loss": 14.967018127441406,
    "ent_coef": 0.06135480850934982,
    "learning_rate": 0.001
  },
  {
    "episode": 8466,
    "reward": 88.810547,
    "length": 69,
    "time": 126378.022648,
    "actor_loss": -73.5694808959961,
    "critic_loss": 5.241783142089844,
    "ent_coef": 0.06170789524912834,
    "learning_rate": 0.001
  },
  {
    "episode": 8467,
    "reward": 79.068379,
    "length": 131,
    "time": 126400.211311,
    "actor_loss": -69.33616638183594,
    "critic_loss": 57.72145462036133,
    "ent_coef": 0.059813980013132095,
    "learning_rate": 0.001
  },
  {
    "episode": 8468,
    "reward": 79.556254,
    "length": 125,
    "time": 126420.307087,
    "actor_loss": -67.47724914550781,
    "critic_loss": 2.892460346221924,
    "ent_coef": 0.059616126120090485,
    "learning_rate": 0.001
  },
  {
    "episode": 8469,
    "reward": 71.768771,
    "length": 132,
    "time": 126444.047626,
    "actor_loss": -74.25547790527344,
    "critic_loss": 67.39480590820312,
    "ent_coef": 0.06113457307219505,
    "learning_rate": 0.001
  },
  {
    "episode": 8470,
    "reward": 77.788018,
    "length": 143,
    "time": 126467.523779,
    "actor_loss": -68.72268676757812,
    "critic_loss": 2.317514419555664,
    "ent_coef": 0.0694543793797493,
    "learning_rate": 0.001
  },
  {
    "episode": 8471,
    "reward": 80.503986,
    "length": 140,
    "time": 126490.287834,
    "actor_loss": -64.89752197265625,
    "critic_loss": 2.7584595680236816,
    "ent_coef": 0.06792695820331573,
    "learning_rate": 0.001
  },
  {
    "episode": 8472,
    "reward": 84.971924,
    "length": 72,
    "time": 126502.986328,
    "actor_loss": -67.92642211914062,
    "critic_loss": 3.686551570892334,
    "ent_coef": 0.0664554312825203,
    "learning_rate": 0.001
  },
  {
    "episode": 8473,
    "reward": 88.255907,
    "length": 67,
    "time": 126514.684425,
    "actor_loss": -72.05838012695312,
    "critic_loss": 2.075514793395996,
    "ent_coef": 0.06568661332130432,
    "learning_rate": 0.001
  },
  {
    "episode": 8474,
    "reward": 85.21752,
    "length": 80,
    "time": 126528.306533,
    "actor_loss": -71.4675064086914,
    "critic_loss": 21.853652954101562,
    "ent_coef": 0.067859947681427,
    "learning_rate": 0.001
  },
  {
    "episode": 8475,
    "reward": 84.998628,
    "length": 77,
    "time": 126541.48788,
    "actor_loss": -72.975341796875,
    "critic_loss": 3.564530372619629,
    "ent_coef": 0.06790115684270859,
    "learning_rate": 0.001
  },
  {
    "episode": 8476,
    "reward": 86.268624,
    "length": 73,
    "time": 126553.954025,
    "actor_loss": -68.0089111328125,
    "critic_loss": 5.150542259216309,
    "ent_coef": 0.07033117860555649,
    "learning_rate": 0.001
  },
  {
    "episode": 8477,
    "reward": 90.52269,
    "length": 62,
    "time": 126566.931942,
    "actor_loss": -71.74224853515625,
    "critic_loss": 3.994164228439331,
    "ent_coef": 0.07325100898742676,
    "learning_rate": 0.001
  },
  {
    "episode": 8478,
    "reward": 89.946066,
    "length": 63,
    "time": 126578.240765,
    "actor_loss": -67.45841217041016,
    "critic_loss": 3.59238600730896,
    "ent_coef": 0.07691334187984467,
    "learning_rate": 0.001
  },
  {
    "episode": 8479,
    "reward": 88.686362,
    "length": 66,
    "time": 126589.874859,
    "actor_loss": -70.60600280761719,
    "critic_loss": 2.921253204345703,
    "ent_coef": 0.07630548626184464,
    "learning_rate": 0.001
  },
  {
    "episode": 8480,
    "reward": 87.900686,
    "length": 68,
    "time": 126602.02402,
    "actor_loss": -73.59304809570312,
    "critic_loss": 2.402833938598633,
    "ent_coef": 0.07614178210496902,
    "learning_rate": 0.001
  },
  {
    "episode": 8481,
    "reward": 83.954011,
    "length": 74,
    "time": 126615.269944,
    "actor_loss": -75.24278259277344,
    "critic_loss": 53.71141052246094,
    "ent_coef": 0.07554513216018677,
    "learning_rate": 0.001
  },
  {
    "episode": 8482,
    "reward": -157.446606,
    "length": 147,
    "time": 126637.461196,
    "actor_loss": -68.44705200195312,
    "critic_loss": 41.57363510131836,
    "ent_coef": 0.091341033577919,
    "learning_rate": 0.001
  },
  {
    "episode": 8483,
    "reward": -160.503933,
    "length": 139,
    "time": 126658.082569,
    "actor_loss": -67.63180541992188,
    "critic_loss": 2.623274326324463,
    "ent_coef": 0.08949875086545944,
    "learning_rate": 0.001
  },
  {
    "episode": 8484,
    "reward": 80.514193,
    "length": 84,
    "time": 126674.902629,
    "actor_loss": -67.32533264160156,
    "critic_loss": 48.13835144042969,
    "ent_coef": 0.08650408685207367,
    "learning_rate": 0.001
  },
  {
    "episode": 8485,
    "reward": -156.110986,
    "length": 133,
    "time": 126695.158644,
    "actor_loss": -78.13394165039062,
    "critic_loss": 14.410082817077637,
    "ent_coef": 0.08178652822971344,
    "learning_rate": 0.001
  },
  {
    "episode": 8486,
    "reward": -160.999536,
    "length": 141,
    "time": 126720.413495,
    "actor_loss": -72.27732849121094,
    "critic_loss": 38.63923645019531,
    "ent_coef": 0.07920864969491959,
    "learning_rate": 0.001
  },
  {
    "episode": 8487,
    "reward": 90.953284,
    "length": 61,
    "time": 126734.8479,
    "actor_loss": -72.66856384277344,
    "critic_loss": 15.742033004760742,
    "ent_coef": 0.08381567150354385,
    "learning_rate": 0.001
  },
  {
    "episode": 8488,
    "reward": 83.412204,
    "length": 99,
    "time": 126750.900287,
    "actor_loss": -66.97677612304688,
    "critic_loss": 6.835038185119629,
    "ent_coef": 0.08847825229167938,
    "learning_rate": 0.001
  },
  {
    "episode": 8489,
    "reward": -157.216588,
    "length": 128,
    "time": 126771.573145,
    "actor_loss": -69.97386169433594,
    "critic_loss": 3.4469926357269287,
    "ent_coef": 0.09923052042722702,
    "learning_rate": 0.001
  },
  {
    "episode": 8490,
    "reward": 72.029468,
    "length": 252,
    "time": 126807.959054,
    "actor_loss": -67.21336364746094,
    "critic_loss": 22.862863540649414,
    "ent_coef": 0.09769316017627716,
    "learning_rate": 0.001
  },
  {
    "episode": 8491,
    "reward": -174.646618,
    "length": 154,
    "time": 126831.076802,
    "actor_loss": -69.4278335571289,
    "critic_loss": 6.791139602661133,
    "ent_coef": 0.08747672289609909,
    "learning_rate": 0.001
  },
  {
    "episode": 8492,
    "reward": 77.309473,
    "length": 126,
    "time": 126854.206548,
    "actor_loss": -69.00222778320312,
    "critic_loss": 4.7017011642456055,
    "ent_coef": 0.08427709341049194,
    "learning_rate": 0.001
  },
  {
    "episode": 8493,
    "reward": 86.867712,
    "length": 68,
    "time": 126867.717759,
    "actor_loss": -66.79784393310547,
    "critic_loss": 7.8378424644470215,
    "ent_coef": 0.08308365941047668,
    "learning_rate": 0.001
  },
  {
    "episode": 8494,
    "reward": 84.627061,
    "length": 72,
    "time": 126882.125057,
    "actor_loss": -70.91260528564453,
    "critic_loss": 2.620467185974121,
    "ent_coef": 0.07879191637039185,
    "learning_rate": 0.001
  },
  {
    "episode": 8495,
    "reward": -157.596647,
    "length": 135,
    "time": 126902.582506,
    "actor_loss": -68.62049865722656,
    "critic_loss": 4.008513450622559,
    "ent_coef": 0.07496002316474915,
    "learning_rate": 0.001
  },
  {
    "episode": 8496,
    "reward": -157.233288,
    "length": 134,
    "time": 126927.142909,
    "actor_loss": -67.18650817871094,
    "critic_loss": 4.068973541259766,
    "ent_coef": 0.07135096937417984,
    "learning_rate": 0.001
  },
  {
    "episode": 8497,
    "reward": 82.776565,
    "length": 135,
    "time": 126948.568568,
    "actor_loss": -67.94776153564453,
    "critic_loss": 4.902138710021973,
    "ent_coef": 0.07466655969619751,
    "learning_rate": 0.001
  },
  {
    "episode": 8498,
    "reward": 89.177012,
    "length": 66,
    "time": 126961.372054,
    "actor_loss": -64.78142547607422,
    "critic_loss": 5.464529037475586,
    "ent_coef": 0.07437063753604889,
    "learning_rate": 0.001
  },
  {
    "episode": 8499,
    "reward": 72.374588,
    "length": 103,
    "time": 126980.568482,
    "actor_loss": -67.07786560058594,
    "critic_loss": 1.9247822761535645,
    "ent_coef": 0.0761217251420021,
    "learning_rate": 0.001
  },
  {
    "episode": 8500,
    "reward": 90.084343,
    "length": 63,
    "time": 126992.056422,
    "actor_loss": -69.56047058105469,
    "critic_loss": 75.66044616699219,
    "ent_coef": 0.07915463298559189,
    "learning_rate": 0.001
  },
  {
    "episode": 8501,
    "reward": 86.634047,
    "length": 71,
    "time": 127005.363859,
    "actor_loss": -71.30220031738281,
    "critic_loss": 3.040123701095581,
    "ent_coef": 0.07358383387327194,
    "learning_rate": 0.001
  },
  {
    "episode": 8502,
    "reward": 91.065548,
    "length": 61,
    "time": 127016.350174,
    "actor_loss": -71.11064147949219,
    "critic_loss": 47.16249084472656,
    "ent_coef": 0.07100279629230499,
    "learning_rate": 0.001
  },
  {
    "episode": 8503,
    "reward": -154.300158,
    "length": 126,
    "time": 127035.716661,
    "actor_loss": -63.45586013793945,
    "critic_loss": 2.8245956897735596,
    "ent_coef": 0.07214433699846268,
    "learning_rate": 0.001
  },
  {
    "episode": 8504,
    "reward": -167.710753,
    "length": 149,
    "time": 127057.891906,
    "actor_loss": -69.51187896728516,
    "critic_loss": 3.290635108947754,
    "ent_coef": 0.07021759450435638,
    "learning_rate": 0.001
  },
  {
    "episode": 8505,
    "reward": -155.766864,
    "length": 130,
    "time": 127079.503685,
    "actor_loss": -72.19277954101562,
    "critic_loss": 8.091012954711914,
    "ent_coef": 0.07134496420621872,
    "learning_rate": 0.001
  },
  {
    "episode": 8506,
    "reward": 86.896334,
    "length": 69,
    "time": 127094.272275,
    "actor_loss": -69.86177062988281,
    "critic_loss": 4.443103790283203,
    "ent_coef": 0.07114120572805405,
    "learning_rate": 0.001
  },
  {
    "episode": 8507,
    "reward": 44.902101,
    "length": 125,
    "time": 127115.399639,
    "actor_loss": -73.5026626586914,
    "critic_loss": 11.428951263427734,
    "ent_coef": 0.06591837853193283,
    "learning_rate": 0.001
  },
  {
    "episode": 8508,
    "reward": 89.187478,
    "length": 65,
    "time": 127128.335475,
    "actor_loss": -65.06071472167969,
    "critic_loss": 3.0500497817993164,
    "ent_coef": 0.06671348959207535,
    "learning_rate": 0.001
  },
  {
    "episode": 8509,
    "reward": -157.127071,
    "length": 132,
    "time": 127148.802018,
    "actor_loss": -63.53971862792969,
    "critic_loss": 28.09795379638672,
    "ent_coef": 0.07236135751008987,
    "learning_rate": 0.001
  },
  {
    "episode": 8510,
    "reward": 88.724421,
    "length": 66,
    "time": 127162.770413,
    "actor_loss": -70.85482788085938,
    "critic_loss": 12.383964538574219,
    "ent_coef": 0.0733681172132492,
    "learning_rate": 0.001
  },
  {
    "episode": 8511,
    "reward": 88.46031,
    "length": 67,
    "time": 127176.809095,
    "actor_loss": -69.09333801269531,
    "critic_loss": 11.341500282287598,
    "ent_coef": 0.07300665229558945,
    "learning_rate": 0.001
  },
  {
    "episode": 8512,
    "reward": 88.113882,
    "length": 66,
    "time": 127191.375654,
    "actor_loss": -73.03695678710938,
    "critic_loss": 5.968230247497559,
    "ent_coef": 0.07134729623794556,
    "learning_rate": 0.001
  },
  {
    "episode": 8513,
    "reward": 87.959579,
    "length": 68,
    "time": 127204.338711,
    "actor_loss": -65.94392395019531,
    "critic_loss": 4.867966651916504,
    "ent_coef": 0.07251688092947006,
    "learning_rate": 0.001
  },
  {
    "episode": 8514,
    "reward": -156.50579,
    "length": 130,
    "time": 127224.321066,
    "actor_loss": -70.84304809570312,
    "critic_loss": 938.1582641601562,
    "ent_coef": 0.0735456719994545,
    "learning_rate": 0.001
  },
  {
    "episode": 8515,
    "reward": 90.023289,
    "length": 62,
    "time": 127235.280382,
    "actor_loss": -68.53427124023438,
    "critic_loss": 3.490050792694092,
    "ent_coef": 0.07667256146669388,
    "learning_rate": 0.001
  },
  {
    "episode": 8516,
    "reward": 91.483468,
    "length": 60,
    "time": 127247.97023,
    "actor_loss": -70.06721496582031,
    "critic_loss": 3.56063175201416,
    "ent_coef": 0.07943901419639587,
    "learning_rate": 0.001
  },
  {
    "episode": 8517,
    "reward": 92.119399,
    "length": 59,
    "time": 127258.79039,
    "actor_loss": -67.81150817871094,
    "critic_loss": 3.9219131469726562,
    "ent_coef": 0.08266907185316086,
    "learning_rate": 0.001
  },
  {
    "episode": 8518,
    "reward": -159.346611,
    "length": 136,
    "time": 127280.036368,
    "actor_loss": -68.9278335571289,
    "critic_loss": 24.689729690551758,
    "ent_coef": 0.0837540477514267,
    "learning_rate": 0.001
  },
  {
    "episode": 8519,
    "reward": 88.213033,
    "length": 65,
    "time": 127291.5398,
    "actor_loss": -70.83841705322266,
    "critic_loss": 29.320777893066406,
    "ent_coef": 0.08427319675683975,
    "learning_rate": 0.001
  },
  {
    "episode": 8520,
    "reward": 90.593739,
    "length": 63,
    "time": 127303.843197,
    "actor_loss": -63.21195983886719,
    "critic_loss": 21.520999908447266,
    "ent_coef": 0.08553269505500793,
    "learning_rate": 0.001
  },
  {
    "episode": 8521,
    "reward": 88.639346,
    "length": 65,
    "time": 127315.767699,
    "actor_loss": -68.40516662597656,
    "critic_loss": 786.533203125,
    "ent_coef": 0.08798334002494812,
    "learning_rate": 0.001
  },
  {
    "episode": 8522,
    "reward": 89.641728,
    "length": 65,
    "time": 127327.589441,
    "actor_loss": -69.35594177246094,
    "critic_loss": 7.508571624755859,
    "ent_coef": 0.08827278763055801,
    "learning_rate": 0.001
  },
  {
    "episode": 8523,
    "reward": 91.478421,
    "length": 60,
    "time": 127339.31874,
    "actor_loss": -70.01868438720703,
    "critic_loss": 2.448866844177246,
    "ent_coef": 0.08822521567344666,
    "learning_rate": 0.001
  },
  {
    "episode": 8524,
    "reward": 87.852399,
    "length": 67,
    "time": 127352.317456,
    "actor_loss": -67.7443618774414,
    "critic_loss": 18.94894790649414,
    "ent_coef": 0.08688686788082123,
    "learning_rate": 0.001
  },
  {
    "episode": 8525,
    "reward": 90.114031,
    "length": 63,
    "time": 127363.997803,
    "actor_loss": -68.26461791992188,
    "critic_loss": 14.862781524658203,
    "ent_coef": 0.08514136075973511,
    "learning_rate": 0.001
  },
  {
    "episode": 8526,
    "reward": 85.473691,
    "length": 70,
    "time": 127376.980782,
    "actor_loss": -65.34213256835938,
    "critic_loss": 4.286760330200195,
    "ent_coef": 0.08268272131681442,
    "learning_rate": 0.001
  },
  {
    "episode": 8527,
    "reward": 89.716247,
    "length": 64,
    "time": 127389.277587,
    "actor_loss": -64.73074340820312,
    "critic_loss": 6.232364654541016,
    "ent_coef": 0.08317451179027557,
    "learning_rate": 0.001
  },
  {
    "episode": 8528,
    "reward": 89.79547,
    "length": 64,
    "time": 127402.957439,
    "actor_loss": -64.3802490234375,
    "critic_loss": 21.36524772644043,
    "ent_coef": 0.08312273025512695,
    "learning_rate": 0.001
  },
  {
    "episode": 8529,
    "reward": -161.696414,
    "length": 144,
    "time": 127426.243305,
    "actor_loss": -67.10537719726562,
    "critic_loss": 42.1724853515625,
    "ent_coef": 0.07471127063035965,
    "learning_rate": 0.001
  },
  {
    "episode": 8530,
    "reward": 88.632982,
    "length": 65,
    "time": 127439.447842,
    "actor_loss": -65.03743743896484,
    "critic_loss": 4.814644813537598,
    "ent_coef": 0.07717114686965942,
    "learning_rate": 0.001
  },
  {
    "episode": 8531,
    "reward": 89.368325,
    "length": 65,
    "time": 127452.563609,
    "actor_loss": -72.944091796875,
    "critic_loss": 10.73452091217041,
    "ent_coef": 0.07998033612966537,
    "learning_rate": 0.001
  },
  {
    "episode": 8532,
    "reward": 91.077047,
    "length": 61,
    "time": 127463.609917,
    "actor_loss": -72.62142944335938,
    "critic_loss": 6.7104082107543945,
    "ent_coef": 0.0838870033621788,
    "learning_rate": 0.001
  },
  {
    "episode": 8533,
    "reward": 90.443832,
    "length": 62,
    "time": 127477.230896,
    "actor_loss": -72.28741455078125,
    "critic_loss": 12.846647262573242,
    "ent_coef": 0.08690086752176285,
    "learning_rate": 0.001
  },
  {
    "episode": 8534,
    "reward": 90.684091,
    "length": 63,
    "time": 127489.464911,
    "actor_loss": -71.03067779541016,
    "critic_loss": 2.5503768920898438,
    "ent_coef": 0.09049447625875473,
    "learning_rate": 0.001
  },
  {
    "episode": 8535,
    "reward": 90.881645,
    "length": 63,
    "time": 127501.424931,
    "actor_loss": -72.08894348144531,
    "critic_loss": 7.805180549621582,
    "ent_coef": 0.09178071469068527,
    "learning_rate": 0.001
  },
  {
    "episode": 8536,
    "reward": 86.408347,
    "length": 71,
    "time": 127514.30284,
    "actor_loss": -71.71304321289062,
    "critic_loss": 16.82059097290039,
    "ent_coef": 0.08836238831281662,
    "learning_rate": 0.001
  },
  {
    "episode": 8537,
    "reward": 87.179488,
    "length": 68,
    "time": 127527.684435,
    "actor_loss": -74.63011169433594,
    "critic_loss": 8.237781524658203,
    "ent_coef": 0.0862298458814621,
    "learning_rate": 0.001
  },
  {
    "episode": 8538,
    "reward": 80.330508,
    "length": 129,
    "time": 127548.324028,
    "actor_loss": -66.10202026367188,
    "critic_loss": 5.2239990234375,
    "ent_coef": 0.08178338408470154,
    "learning_rate": 0.001
  },
  {
    "episode": 8539,
    "reward": -155.803971,
    "length": 129,
    "time": 127568.755031,
    "actor_loss": -67.81195068359375,
    "critic_loss": 4.196369171142578,
    "ent_coef": 0.07996174693107605,
    "learning_rate": 0.001
  },
  {
    "episode": 8540,
    "reward": 87.954016,
    "length": 69,
    "time": 127582.0313,
    "actor_loss": -71.207763671875,
    "critic_loss": 18.69015884399414,
    "ent_coef": 0.08001299202442169,
    "learning_rate": 0.001
  },
  {
    "episode": 8541,
    "reward": 87.582985,
    "length": 76,
    "time": 127595.252123,
    "actor_loss": -68.00161743164062,
    "critic_loss": 2.159395694732666,
    "ent_coef": 0.08085278421640396,
    "learning_rate": 0.001
  },
  {
    "episode": 8542,
    "reward": 89.829493,
    "length": 64,
    "time": 127606.629209,
    "actor_loss": -65.78611755371094,
    "critic_loss": 5.443845748901367,
    "ent_coef": 0.07815756648778915,
    "learning_rate": 0.001
  },
  {
    "episode": 8543,
    "reward": 87.470205,
    "length": 68,
    "time": 127619.61422,
    "actor_loss": -66.87420654296875,
    "critic_loss": 3.280643939971924,
    "ent_coef": 0.07514198869466782,
    "learning_rate": 0.001
  },
  {
    "episode": 8544,
    "reward": 87.652865,
    "length": 68,
    "time": 127633.974552,
    "actor_loss": -68.01399230957031,
    "critic_loss": 6.877628326416016,
    "ent_coef": 0.0747847631573677,
    "learning_rate": 0.001
  },
  {
    "episode": 8545,
    "reward": 90.369743,
    "length": 63,
    "time": 127645.102731,
    "actor_loss": -64.23253631591797,
    "critic_loss": 2.557326316833496,
    "ent_coef": 0.07628647983074188,
    "learning_rate": 0.001
  },
  {
    "episode": 8546,
    "reward": 90.265038,
    "length": 63,
    "time": 127658.468913,
    "actor_loss": -65.03755950927734,
    "critic_loss": 4.072865962982178,
    "ent_coef": 0.07896352559328079,
    "learning_rate": 0.001
  },
  {
    "episode": 8547,
    "reward": 89.497123,
    "length": 65,
    "time": 127670.024499,
    "actor_loss": -64.36845397949219,
    "critic_loss": 6.270804405212402,
    "ent_coef": 0.079531230032444,
    "learning_rate": 0.001
  },
  {
    "episode": 8548,
    "reward": 88.388693,
    "length": 70,
    "time": 127684.154968,
    "actor_loss": -69.78856658935547,
    "critic_loss": 23.81185531616211,
    "ent_coef": 0.08200198411941528,
    "learning_rate": 0.001
  },
  {
    "episode": 8549,
    "reward": 91.431488,
    "length": 61,
    "time": 127698.019465,
    "actor_loss": -64.72250366210938,
    "critic_loss": 15.257671356201172,
    "ent_coef": 0.08086620271205902,
    "learning_rate": 0.001
  },
  {
    "episode": 8550,
    "reward": 87.861168,
    "length": 67,
    "time": 127711.988945,
    "actor_loss": -70.42745208740234,
    "critic_loss": 5.300512313842773,
    "ent_coef": 0.07974259555339813,
    "learning_rate": 0.001
  },
  {
    "episode": 8551,
    "reward": 86.069482,
    "length": 73,
    "time": 127725.068729,
    "actor_loss": -64.09363555908203,
    "critic_loss": 4.454183578491211,
    "ent_coef": 0.07814530283212662,
    "learning_rate": 0.001
  },
  {
    "episode": 8552,
    "reward": 91.12245,
    "length": 61,
    "time": 127737.964108,
    "actor_loss": -72.2992172241211,
    "critic_loss": 4.312342643737793,
    "ent_coef": 0.08106596022844315,
    "learning_rate": 0.001
  },
  {
    "episode": 8553,
    "reward": 89.151249,
    "length": 66,
    "time": 127749.3678,
    "actor_loss": -65.34806823730469,
    "critic_loss": 4.878884315490723,
    "ent_coef": 0.08065764605998993,
    "learning_rate": 0.001
  },
  {
    "episode": 8554,
    "reward": 87.664299,
    "length": 67,
    "time": 127764.909315,
    "actor_loss": -67.56783294677734,
    "critic_loss": 69.89286804199219,
    "ent_coef": 0.07738819718360901,
    "learning_rate": 0.001
  },
  {
    "episode": 8555,
    "reward": 84.956982,
    "length": 73,
    "time": 127778.827601,
    "actor_loss": -72.18824768066406,
    "critic_loss": 12.520909309387207,
    "ent_coef": 0.074046790599823,
    "learning_rate": 0.001
  },
  {
    "episode": 8556,
    "reward": 88.184176,
    "length": 71,
    "time": 127791.555655,
    "actor_loss": -71.68154907226562,
    "critic_loss": 10.23160171508789,
    "ent_coef": 0.07247817516326904,
    "learning_rate": 0.001
  },
  {
    "episode": 8557,
    "reward": 88.915084,
    "length": 66,
    "time": 127803.215623,
    "actor_loss": -70.04847717285156,
    "critic_loss": 13.326042175292969,
    "ent_coef": 0.06969114392995834,
    "learning_rate": 0.001
  },
  {
    "episode": 8558,
    "reward": 89.825949,
    "length": 63,
    "time": 127816.474888,
    "actor_loss": -72.83662414550781,
    "critic_loss": 27.0842342376709,
    "ent_coef": 0.06932199746370316,
    "learning_rate": 0.001
  },
  {
    "episode": 8559,
    "reward": 87.499178,
    "length": 67,
    "time": 127829.025913,
    "actor_loss": -61.92793273925781,
    "critic_loss": 2.7516939640045166,
    "ent_coef": 0.06724853068590164,
    "learning_rate": 0.001
  },
  {
    "episode": 8560,
    "reward": 88.992433,
    "length": 66,
    "time": 127840.936917,
    "actor_loss": -73.50656127929688,
    "critic_loss": 14.114816665649414,
    "ent_coef": 0.06616838276386261,
    "learning_rate": 0.001
  },
  {
    "episode": 8561,
    "reward": 87.22227,
    "length": 67,
    "time": 127852.819864,
    "actor_loss": -66.22801208496094,
    "critic_loss": 2.687249183654785,
    "ent_coef": 0.06461888551712036,
    "learning_rate": 0.001
  },
  {
    "episode": 8562,
    "reward": 90.869981,
    "length": 62,
    "time": 127866.26391,
    "actor_loss": -67.22654724121094,
    "critic_loss": 8.480215072631836,
    "ent_coef": 0.06952065229415894,
    "learning_rate": 0.001
  },
  {
    "episode": 8563,
    "reward": 90.142295,
    "length": 63,
    "time": 127878.244675,
    "actor_loss": -69.16349792480469,
    "critic_loss": 8.172370910644531,
    "ent_coef": 0.0713733658194542,
    "learning_rate": 0.001
  },
  {
    "episode": 8564,
    "reward": 89.893844,
    "length": 64,
    "time": 127889.893312,
    "actor_loss": -73.474365234375,
    "critic_loss": 179.18484497070312,
    "ent_coef": 0.07232286036014557,
    "learning_rate": 0.001
  },
  {
    "episode": 8565,
    "reward": 85.231682,
    "length": 71,
    "time": 127904.665365,
    "actor_loss": -63.37033462524414,
    "critic_loss": 50.9010009765625,
    "ent_coef": 0.0692465603351593,
    "learning_rate": 0.001
  },
  {
    "episode": 8566,
    "reward": 87.98099,
    "length": 66,
    "time": 127916.30457,
    "actor_loss": -68.47926330566406,
    "critic_loss": 9.635570526123047,
    "ent_coef": 0.0690646767616272,
    "learning_rate": 0.001
  },
  {
    "episode": 8567,
    "reward": 89.660105,
    "length": 63,
    "time": 127929.568112,
    "actor_loss": -68.54727935791016,
    "critic_loss": 5.244697570800781,
    "ent_coef": 0.07086668908596039,
    "learning_rate": 0.001
  },
  {
    "episode": 8568,
    "reward": 89.930106,
    "length": 64,
    "time": 127941.471075,
    "actor_loss": -64.77320861816406,
    "critic_loss": 2.9849853515625,
    "ent_coef": 0.07335823774337769,
    "learning_rate": 0.001
  },
  {
    "episode": 8569,
    "reward": 89.573235,
    "length": 66,
    "time": 127953.232128,
    "actor_loss": -63.224735260009766,
    "critic_loss": 4.184165954589844,
    "ent_coef": 0.07082010060548782,
    "learning_rate": 0.001
  },
  {
    "episode": 8570,
    "reward": 90.883415,
    "length": 61,
    "time": 127965.126186,
    "actor_loss": -71.20609283447266,
    "critic_loss": 2.347031593322754,
    "ent_coef": 0.07054971903562546,
    "learning_rate": 0.001
  },
  {
    "episode": 8571,
    "reward": 90.976073,
    "length": 61,
    "time": 127980.015253,
    "actor_loss": -67.48529052734375,
    "critic_loss": 11.412412643432617,
    "ent_coef": 0.07076486200094223,
    "learning_rate": 0.001
  },
  {
    "episode": 8572,
    "reward": 91.023061,
    "length": 63,
    "time": 127992.266906,
    "actor_loss": -69.1787109375,
    "critic_loss": 15.661166191101074,
    "ent_coef": 0.07107232511043549,
    "learning_rate": 0.001
  },
  {
    "episode": 8573,
    "reward": 90.652763,
    "length": 62,
    "time": 128003.380291,
    "actor_loss": -65.42083740234375,
    "critic_loss": 4.3144211769104,
    "ent_coef": 0.07237034291028976,
    "learning_rate": 0.001
  },
  {
    "episode": 8574,
    "reward": 89.612717,
    "length": 64,
    "time": 128014.848697,
    "actor_loss": -64.74658203125,
    "critic_loss": 17.249526977539062,
    "ent_coef": 0.07335986196994781,
    "learning_rate": 0.001
  },
  {
    "episode": 8575,
    "reward": 90.139033,
    "length": 64,
    "time": 128027.077036,
    "actor_loss": -60.48115539550781,
    "critic_loss": 13.916678428649902,
    "ent_coef": 0.06919610500335693,
    "learning_rate": 0.001
  },
  {
    "episode": 8576,
    "reward": 88.425418,
    "length": 66,
    "time": 128039.770071,
    "actor_loss": -64.32223510742188,
    "critic_loss": 5.802428245544434,
    "ent_coef": 0.06800122559070587,
    "learning_rate": 0.001
  },
  {
    "episode": 8577,
    "reward": 89.544223,
    "length": 65,
    "time": 128055.649936,
    "actor_loss": -65.78285217285156,
    "critic_loss": 15.68545150756836,
    "ent_coef": 0.06887111067771912,
    "learning_rate": 0.001
  },
  {
    "episode": 8578,
    "reward": 89.609865,
    "length": 65,
    "time": 128068.81894,
    "actor_loss": -65.055908203125,
    "critic_loss": 11.359126091003418,
    "ent_coef": 0.07102368772029877,
    "learning_rate": 0.001
  },
  {
    "episode": 8579,
    "reward": 90.161732,
    "length": 63,
    "time": 128081.002389,
    "actor_loss": -69.19100952148438,
    "critic_loss": 16.365386962890625,
    "ent_coef": 0.07037772238254547,
    "learning_rate": 0.001
  },
  {
    "episode": 8580,
    "reward": 91.287971,
    "length": 62,
    "time": 128091.996536,
    "actor_loss": -67.0614013671875,
    "critic_loss": 3.540757179260254,
    "ent_coef": 0.07087981700897217,
    "learning_rate": 0.001
  },
  {
    "episode": 8581,
    "reward": 88.882841,
    "length": 70,
    "time": 128105.346613,
    "actor_loss": -67.38143920898438,
    "critic_loss": 37.2679443359375,
    "ent_coef": 0.07028226554393768,
    "learning_rate": 0.001
  },
  {
    "episode": 8582,
    "reward": 89.971583,
    "length": 63,
    "time": 128116.653816,
    "actor_loss": -67.42626953125,
    "critic_loss": 4.9688215255737305,
    "ent_coef": 0.07002391666173935,
    "learning_rate": 0.001
  },
  {
    "episode": 8583,
    "reward": 91.465708,
    "length": 61,
    "time": 128127.631233,
    "actor_loss": -67.00721740722656,
    "critic_loss": 40.60681915283203,
    "ent_coef": 0.07286142557859421,
    "learning_rate": 0.001
  },
  {
    "episode": 8584,
    "reward": 88.274072,
    "length": 66,
    "time": 128144.346539,
    "actor_loss": -69.56388854980469,
    "critic_loss": 2.0437474250793457,
    "ent_coef": 0.07495196908712387,
    "learning_rate": 0.001
  },
  {
    "episode": 8585,
    "reward": 88.603725,
    "length": 67,
    "time": 128155.975776,
    "actor_loss": -65.47666931152344,
    "critic_loss": 43.40960693359375,
    "ent_coef": 0.07445178925991058,
    "learning_rate": 0.001
  },
  {
    "episode": 8586,
    "reward": 90.194539,
    "length": 64,
    "time": 128169.526725,
    "actor_loss": -61.50717544555664,
    "critic_loss": 104.26470947265625,
    "ent_coef": 0.07513654232025146,
    "learning_rate": 0.001
  },
  {
    "episode": 8587,
    "reward": 86.780667,
    "length": 70,
    "time": 128182.025872,
    "actor_loss": -67.88444519042969,
    "critic_loss": 20.635236740112305,
    "ent_coef": 0.07229093462228775,
    "learning_rate": 0.001
  },
  {
    "episode": 8588,
    "reward": 87.911332,
    "length": 69,
    "time": 128197.245081,
    "actor_loss": -68.38688659667969,
    "critic_loss": 10.618535995483398,
    "ent_coef": 0.06865620613098145,
    "learning_rate": 0.001
  },
  {
    "episode": 8589,
    "reward": 89.034105,
    "length": 66,
    "time": 128208.814404,
    "actor_loss": -63.932029724121094,
    "critic_loss": 3.1193699836730957,
    "ent_coef": 0.06744317710399628,
    "learning_rate": 0.001
  },
  {
    "episode": 8590,
    "reward": 90.213408,
    "length": 64,
    "time": 128221.633018,
    "actor_loss": -69.90099334716797,
    "critic_loss": 2.7191855907440186,
    "ent_coef": 0.0675523579120636,
    "learning_rate": 0.001
  },
  {
    "episode": 8591,
    "reward": 89.255397,
    "length": 66,
    "time": 128234.141102,
    "actor_loss": -67.91788482666016,
    "critic_loss": 2.131350040435791,
    "ent_coef": 0.06713130325078964,
    "learning_rate": 0.001
  },
  {
    "episode": 8592,
    "reward": 90.169955,
    "length": 63,
    "time": 128247.240577,
    "actor_loss": -65.66270446777344,
    "critic_loss": 2.1564972400665283,
    "ent_coef": 0.06832195073366165,
    "learning_rate": 0.001
  },
  {
    "episode": 8593,
    "reward": 91.354503,
    "length": 61,
    "time": 128258.416846,
    "actor_loss": -69.6939697265625,
    "critic_loss": 15.974666595458984,
    "ent_coef": 0.07288967818021774,
    "learning_rate": 0.001
  },
  {
    "episode": 8594,
    "reward": 88.766996,
    "length": 65,
    "time": 128272.679831,
    "actor_loss": -68.09446716308594,
    "critic_loss": 12.17529296875,
    "ent_coef": 0.07799288630485535,
    "learning_rate": 0.001
  },
  {
    "episode": 8595,
    "reward": 90.21589,
    "length": 62,
    "time": 128286.188568,
    "actor_loss": -68.36480712890625,
    "critic_loss": 4.381928443908691,
    "ent_coef": 0.0823364183306694,
    "learning_rate": 0.001
  },
  {
    "episode": 8596,
    "reward": 88.460392,
    "length": 69,
    "time": 128299.183653,
    "actor_loss": -71.16851043701172,
    "critic_loss": 14.18301773071289,
    "ent_coef": 0.08019892871379852,
    "learning_rate": 0.001
  },
  {
    "episode": 8597,
    "reward": 88.824765,
    "length": 66,
    "time": 128310.812931,
    "actor_loss": -61.19264602661133,
    "critic_loss": 3.7681617736816406,
    "ent_coef": 0.07758063822984695,
    "learning_rate": 0.001
  },
  {
    "episode": 8598,
    "reward": 90.60717,
    "length": 63,
    "time": 128325.167272,
    "actor_loss": -70.57474517822266,
    "critic_loss": 9.286491394042969,
    "ent_coef": 0.07893066108226776,
    "learning_rate": 0.001
  },
  {
    "episode": 8599,
    "reward": 90.550308,
    "length": 63,
    "time": 128337.233247,
    "actor_loss": -67.84649658203125,
    "critic_loss": 56.60301971435547,
    "ent_coef": 0.08010502904653549,
    "learning_rate": 0.001
  },
  {
    "episode": 8600,
    "reward": 87.78681,
    "length": 68,
    "time": 128352.67105,
    "actor_loss": -68.24716186523438,
    "critic_loss": 4.634265899658203,
    "ent_coef": 0.07813692092895508,
    "learning_rate": 0.001
  },
  {
    "episode": 8601,
    "reward": 90.977873,
    "length": 62,
    "time": 128364.14008,
    "actor_loss": -67.73617553710938,
    "critic_loss": 52.17356872558594,
    "ent_coef": 0.0770295113325119,
    "learning_rate": 0.001
  },
  {
    "episode": 8602,
    "reward": 86.293946,
    "length": 72,
    "time": 128377.339507,
    "actor_loss": -67.07652282714844,
    "critic_loss": 3.8056092262268066,
    "ent_coef": 0.07487455755472183,
    "learning_rate": 0.001
  },
  {
    "episode": 8603,
    "reward": 86.258577,
    "length": 70,
    "time": 128389.360263,
    "actor_loss": -68.11839294433594,
    "critic_loss": 107.68788146972656,
    "ent_coef": 0.07065559923648834,
    "learning_rate": 0.001
  },
  {
    "episode": 8604,
    "reward": 86.84021,
    "length": 70,
    "time": 128402.846123,
    "actor_loss": -69.37763977050781,
    "critic_loss": 11.29173469543457,
    "ent_coef": 0.06901814788579941,
    "learning_rate": 0.001
  },
  {
    "episode": 8605,
    "reward": 91.920057,
    "length": 60,
    "time": 128415.872975,
    "actor_loss": -67.44319152832031,
    "critic_loss": 10.393543243408203,
    "ent_coef": 0.06974726170301437,
    "learning_rate": 0.001
  },
  {
    "episode": 8606,
    "reward": 90.518076,
    "length": 62,
    "time": 128427.271573,
    "actor_loss": -67.24433135986328,
    "critic_loss": 37.3795051574707,
    "ent_coef": 0.07219211757183075,
    "learning_rate": 0.001
  },
  {
    "episode": 8607,
    "reward": 91.141058,
    "length": 62,
    "time": 128442.023456,
    "actor_loss": -66.4252700805664,
    "critic_loss": 24.099868774414062,
    "ent_coef": 0.07694035768508911,
    "learning_rate": 0.001
  },
  {
    "episode": 8608,
    "reward": 89.508467,
    "length": 64,
    "time": 128453.665847,
    "actor_loss": -64.85938262939453,
    "critic_loss": 4.722553253173828,
    "ent_coef": 0.07918383926153183,
    "learning_rate": 0.001
  },
  {
    "episode": 8609,
    "reward": 91.308635,
    "length": 62,
    "time": 128466.050081,
    "actor_loss": -64.24859619140625,
    "critic_loss": 607.14111328125,
    "ent_coef": 0.076325923204422,
    "learning_rate": 0.001
  },
  {
    "episode": 8610,
    "reward": 89.01618,
    "length": 66,
    "time": 128480.141902,
    "actor_loss": -68.9803695678711,
    "critic_loss": 5.029208183288574,
    "ent_coef": 0.07701356709003448,
    "learning_rate": 0.001
  },
  {
    "episode": 8611,
    "reward": 88.801456,
    "length": 67,
    "time": 128493.786784,
    "actor_loss": -54.0962028503418,
    "critic_loss": 16.579593658447266,
    "ent_coef": 0.07811401039361954,
    "learning_rate": 0.001
  },
  {
    "episode": 8612,
    "reward": 88.366748,
    "length": 68,
    "time": 128506.993652,
    "actor_loss": -66.3484878540039,
    "critic_loss": 9.778343200683594,
    "ent_coef": 0.07702532410621643,
    "learning_rate": 0.001
  },
  {
    "episode": 8613,
    "reward": 89.577591,
    "length": 63,
    "time": 128519.436648,
    "actor_loss": -67.41261291503906,
    "critic_loss": 5.355252265930176,
    "ent_coef": 0.07746289670467377,
    "learning_rate": 0.001
  },
  {
    "episode": 8614,
    "reward": 89.401144,
    "length": 66,
    "time": 128530.919473,
    "actor_loss": -65.01216125488281,
    "critic_loss": 6.740229606628418,
    "ent_coef": 0.0762539654970169,
    "learning_rate": 0.001
  },
  {
    "episode": 8615,
    "reward": 88.618688,
    "length": 66,
    "time": 128542.380971,
    "actor_loss": -71.378662109375,
    "critic_loss": 19.29758071899414,
    "ent_coef": 0.07731465995311737,
    "learning_rate": 0.001
  },
  {
    "episode": 8616,
    "reward": 84.794526,
    "length": 73,
    "time": 128555.980599,
    "actor_loss": -63.70088577270508,
    "critic_loss": 6.755831241607666,
    "ent_coef": 0.07395338267087936,
    "learning_rate": 0.001
  },
  {
    "episode": 8617,
    "reward": 88.737295,
    "length": 66,
    "time": 128567.593331,
    "actor_loss": -68.91238403320312,
    "critic_loss": 3.1859772205352783,
    "ent_coef": 0.07135394215583801,
    "learning_rate": 0.001
  },
  {
    "episode": 8618,
    "reward": 86.959815,
    "length": 69,
    "time": 128581.208473,
    "actor_loss": -62.17818069458008,
    "critic_loss": 71.779296875,
    "ent_coef": 0.07074856758117676,
    "learning_rate": 0.001
  },
  {
    "episode": 8619,
    "reward": 88.232207,
    "length": 66,
    "time": 128592.7895,
    "actor_loss": -65.32626342773438,
    "critic_loss": 4.006436824798584,
    "ent_coef": 0.07370338588953018,
    "learning_rate": 0.001
  },
  {
    "episode": 8620,
    "reward": 91.297999,
    "length": 61,
    "time": 128603.718301,
    "actor_loss": -68.42103576660156,
    "critic_loss": 8.377254486083984,
    "ent_coef": 0.07467161118984222,
    "learning_rate": 0.001
  },
  {
    "episode": 8621,
    "reward": 89.422457,
    "length": 65,
    "time": 128615.537776,
    "actor_loss": -65.56510925292969,
    "critic_loss": 7.724556922912598,
    "ent_coef": 0.07523853331804276,
    "learning_rate": 0.001
  },
  {
    "episode": 8622,
    "reward": 88.142434,
    "length": 66,
    "time": 128629.173099,
    "actor_loss": -57.29389190673828,
    "critic_loss": 2.6803879737854004,
    "ent_coef": 0.07797864079475403,
    "learning_rate": 0.001
  },
  {
    "episode": 8623,
    "reward": 90.765739,
    "length": 62,
    "time": 128640.21268,
    "actor_loss": -65.84468078613281,
    "critic_loss": 7.113284111022949,
    "ent_coef": 0.08277202397584915,
    "learning_rate": 0.001
  },
  {
    "episode": 8624,
    "reward": 90.008567,
    "length": 63,
    "time": 128652.445632,
    "actor_loss": -67.95140075683594,
    "critic_loss": 3.1615912914276123,
    "ent_coef": 0.08441566675901413,
    "learning_rate": 0.001
  },
  {
    "episode": 8625,
    "reward": 89.907368,
    "length": 63,
    "time": 128666.193845,
    "actor_loss": -68.52332305908203,
    "critic_loss": 6.569772720336914,
    "ent_coef": 0.08592412620782852,
    "learning_rate": 0.001
  },
  {
    "episode": 8626,
    "reward": 88.537166,
    "length": 66,
    "time": 128679.515759,
    "actor_loss": -64.14704132080078,
    "critic_loss": 7.135275840759277,
    "ent_coef": 0.08736185729503632,
    "learning_rate": 0.001
  },
  {
    "episode": 8627,
    "reward": 90.327736,
    "length": 63,
    "time": 128692.36768,
    "actor_loss": -64.98970031738281,
    "critic_loss": 33.865394592285156,
    "ent_coef": 0.09351760894060135,
    "learning_rate": 0.001
  },
  {
    "episode": 8628,
    "reward": 88.276156,
    "length": 66,
    "time": 128704.036312,
    "actor_loss": -68.15645599365234,
    "critic_loss": 4.386762619018555,
    "ent_coef": 0.09648456424474716,
    "learning_rate": 0.001
  },
  {
    "episode": 8629,
    "reward": 90.396821,
    "length": 63,
    "time": 128715.629615,
    "actor_loss": -63.940948486328125,
    "critic_loss": 3.006732940673828,
    "ent_coef": 0.09570159018039703,
    "learning_rate": 0.001
  },
  {
    "episode": 8630,
    "reward": 87.987072,
    "length": 67,
    "time": 128729.065964,
    "actor_loss": -67.83489990234375,
    "critic_loss": 5.650447368621826,
    "ent_coef": 0.09372952580451965,
    "learning_rate": 0.001
  },
  {
    "episode": 8631,
    "reward": 88.528045,
    "length": 67,
    "time": 128740.984034,
    "actor_loss": -66.58540344238281,
    "critic_loss": 8.788387298583984,
    "ent_coef": 0.09070812910795212,
    "learning_rate": 0.001
  },
  {
    "episode": 8632,
    "reward": 79.626525,
    "length": 83,
    "time": 128755.037375,
    "actor_loss": -68.60082244873047,
    "critic_loss": 3.4520726203918457,
    "ent_coef": 0.08249294757843018,
    "learning_rate": 0.001
  },
  {
    "episode": 8633,
    "reward": 89.769527,
    "length": 64,
    "time": 128766.778769,
    "actor_loss": -67.52313232421875,
    "critic_loss": 51.505516052246094,
    "ent_coef": 0.07992810755968094,
    "learning_rate": 0.001
  },
  {
    "episode": 8634,
    "reward": 89.89116,
    "length": 64,
    "time": 128778.107749,
    "actor_loss": -66.72144317626953,
    "critic_loss": 93.40727233886719,
    "ent_coef": 0.07854896783828735,
    "learning_rate": 0.001
  },
  {
    "episode": 8635,
    "reward": 90.345927,
    "length": 63,
    "time": 128793.279634,
    "actor_loss": -70.46987915039062,
    "critic_loss": 28.18958854675293,
    "ent_coef": 0.07727539539337158,
    "learning_rate": 0.001
  },
  {
    "episode": 8636,
    "reward": 88.664187,
    "length": 67,
    "time": 128805.668324,
    "actor_loss": -65.56552124023438,
    "critic_loss": 36.91374206542969,
    "ent_coef": 0.07574987411499023,
    "learning_rate": 0.001
  },
  {
    "episode": 8637,
    "reward": 88.524623,
    "length": 67,
    "time": 128817.450514,
    "actor_loss": -69.86955261230469,
    "critic_loss": 2.5975794792175293,
    "ent_coef": 0.07273335754871368,
    "learning_rate": 0.001
  },
  {
    "episode": 8638,
    "reward": 90.666235,
    "length": 64,
    "time": 128829.529907,
    "actor_loss": -61.52103042602539,
    "critic_loss": 8.774751663208008,
    "ent_coef": 0.07139556854963303,
    "learning_rate": 0.001
  },
  {
    "episode": 8639,
    "reward": 87.41843,
    "length": 67,
    "time": 128842.835178,
    "actor_loss": -71.88519287109375,
    "critic_loss": 10.741483688354492,
    "ent_coef": 0.06866803020238876,
    "learning_rate": 0.001
  },
  {
    "episode": 8640,
    "reward": 91.320753,
    "length": 61,
    "time": 128855.127592,
    "actor_loss": -66.43391418457031,
    "critic_loss": 7.081974029541016,
    "ent_coef": 0.07073218375444412,
    "learning_rate": 0.001
  },
  {
    "episode": 8641,
    "reward": 89.053628,
    "length": 65,
    "time": 128867.239935,
    "actor_loss": -69.20928955078125,
    "critic_loss": 5.820648193359375,
    "ent_coef": 0.07205874472856522,
    "learning_rate": 0.001
  },
  {
    "episode": 8642,
    "reward": 89.040849,
    "length": 65,
    "time": 128879.002106,
    "actor_loss": -64.7298812866211,
    "critic_loss": 2.5444443225860596,
    "ent_coef": 0.07300122827291489,
    "learning_rate": 0.001
  },
  {
    "episode": 8643,
    "reward": 90.166461,
    "length": 65,
    "time": 128891.115416,
    "actor_loss": -68.15460968017578,
    "critic_loss": 11.322381973266602,
    "ent_coef": 0.07440972328186035,
    "learning_rate": 0.001
  },
  {
    "episode": 8644,
    "reward": 86.200663,
    "length": 71,
    "time": 128903.453206,
    "actor_loss": -68.71951293945312,
    "critic_loss": 61.512245178222656,
    "ent_coef": 0.07147761434316635,
    "learning_rate": 0.001
  },
  {
    "episode": 8645,
    "reward": 87.730109,
    "length": 69,
    "time": 128916.138688,
    "actor_loss": -61.59905242919922,
    "critic_loss": 28.186342239379883,
    "ent_coef": 0.06784969568252563,
    "learning_rate": 0.001
  },
  {
    "episode": 8646,
    "reward": 88.560645,
    "length": 67,
    "time": 128928.834804,
    "actor_loss": -68.66024780273438,
    "critic_loss": 5.77872371673584,
    "ent_coef": 0.06819519400596619,
    "learning_rate": 0.001
  },
  {
    "episode": 8647,
    "reward": 88.578867,
    "length": 67,
    "time": 128941.845328,
    "actor_loss": -67.84959411621094,
    "critic_loss": 39.43778991699219,
    "ent_coef": 0.06728088110685349,
    "learning_rate": 0.001
  },
  {
    "episode": 8648,
    "reward": 90.489824,
    "length": 62,
    "time": 128955.171272,
    "actor_loss": -63.0164909362793,
    "critic_loss": 11.561551094055176,
    "ent_coef": 0.06786508113145828,
    "learning_rate": 0.001
  },
  {
    "episode": 8649,
    "reward": 90.365125,
    "length": 62,
    "time": 128967.142726,
    "actor_loss": -67.52058410644531,
    "critic_loss": 4.489153861999512,
    "ent_coef": 0.0731983408331871,
    "learning_rate": 0.001
  },
  {
    "episode": 8650,
    "reward": 89.786209,
    "length": 64,
    "time": 128978.851038,
    "actor_loss": -70.46825408935547,
    "critic_loss": 20.433252334594727,
    "ent_coef": 0.07358165830373764,
    "learning_rate": 0.001
  },
  {
    "episode": 8651,
    "reward": 90.382087,
    "length": 63,
    "time": 128991.548882,
    "actor_loss": -70.54725646972656,
    "critic_loss": 28.99163246154785,
    "ent_coef": 0.0748869851231575,
    "learning_rate": 0.001
  },
  {
    "episode": 8652,
    "reward": 89.715141,
    "length": 64,
    "time": 129003.32267,
    "actor_loss": -63.771690368652344,
    "critic_loss": 109.59407806396484,
    "ent_coef": 0.07760782539844513,
    "learning_rate": 0.001
  },
  {
    "episode": 8653,
    "reward": 87.225412,
    "length": 68,
    "time": 129016.145763,
    "actor_loss": -66.50167083740234,
    "critic_loss": 13.932114601135254,
    "ent_coef": 0.07607868313789368,
    "learning_rate": 0.001
  },
  {
    "episode": 8654,
    "reward": 87.800147,
    "length": 69,
    "time": 129028.219379,
    "actor_loss": -65.88070678710938,
    "critic_loss": 6.599002361297607,
    "ent_coef": 0.07415224611759186,
    "learning_rate": 0.001
  },
  {
    "episode": 8655,
    "reward": 84.222209,
    "length": 74,
    "time": 129041.735865,
    "actor_loss": -65.1537094116211,
    "critic_loss": 2.3662924766540527,
    "ent_coef": 0.07057258486747742,
    "learning_rate": 0.001
  },
  {
    "episode": 8656,
    "reward": 84.289549,
    "length": 73,
    "time": 129056.134752,
    "actor_loss": -70.11734008789062,
    "critic_loss": 22.772912979125977,
    "ent_coef": 0.06558480113744736,
    "learning_rate": 0.001
  },
  {
    "episode": 8657,
    "reward": 87.434182,
    "length": 69,
    "time": 129068.130061,
    "actor_loss": -64.58261108398438,
    "critic_loss": 34.064544677734375,
    "ent_coef": 0.06454271823167801,
    "learning_rate": 0.001
  },
  {
    "episode": 8658,
    "reward": 83.134905,
    "length": 78,
    "time": 129081.197947,
    "actor_loss": -66.07621765136719,
    "critic_loss": 5.0045671463012695,
    "ent_coef": 0.06197195127606392,
    "learning_rate": 0.001
  },
  {
    "episode": 8659,
    "reward": 90.268604,
    "length": 63,
    "time": 129094.71912,
    "actor_loss": -69.5115966796875,
    "critic_loss": 12.334304809570312,
    "ent_coef": 0.060931842774152756,
    "learning_rate": 0.001
  },
  {
    "episode": 8660,
    "reward": 89.337485,
    "length": 66,
    "time": 129106.919684,
    "actor_loss": -65.5181884765625,
    "critic_loss": 5.5152201652526855,
    "ent_coef": 0.06004871428012848,
    "learning_rate": 0.001
  },
  {
    "episode": 8661,
    "reward": 82.215509,
    "length": 78,
    "time": 129120.192927,
    "actor_loss": -70.87532043457031,
    "critic_loss": 6.561578273773193,
    "ent_coef": 0.05882180482149124,
    "learning_rate": 0.001
  },
  {
    "episode": 8662,
    "reward": 83.596016,
    "length": 77,
    "time": 129135.19542,
    "actor_loss": -68.4414291381836,
    "critic_loss": 2.619004011154175,
    "ent_coef": 0.05979401245713234,
    "learning_rate": 0.001
  },
  {
    "episode": 8663,
    "reward": 80.309893,
    "length": 83,
    "time": 129150.826672,
    "actor_loss": -68.01856994628906,
    "critic_loss": 6.861048698425293,
    "ent_coef": 0.05930619314312935,
    "learning_rate": 0.001
  },
  {
    "episode": 8664,
    "reward": 81.703311,
    "length": 80,
    "time": 129164.718291,
    "actor_loss": -73.77531433105469,
    "critic_loss": 7.7274932861328125,
    "ent_coef": 0.05998227745294571,
    "learning_rate": 0.001
  },
  {
    "episode": 8665,
    "reward": 84.781504,
    "length": 72,
    "time": 129181.355044,
    "actor_loss": -64.99774169921875,
    "critic_loss": 14.77497673034668,
    "ent_coef": 0.061364538967609406,
    "learning_rate": 0.001
  },
  {
    "episode": 8666,
    "reward": 86.924868,
    "length": 70,
    "time": 129194.174803,
    "actor_loss": -66.51866149902344,
    "critic_loss": 4.948850154876709,
    "ent_coef": 0.06502282619476318,
    "learning_rate": 0.001
  },
  {
    "episode": 8667,
    "reward": 87.591933,
    "length": 68,
    "time": 129206.155775,
    "actor_loss": -68.67509460449219,
    "critic_loss": 26.94582748413086,
    "ent_coef": 0.0661138966679573,
    "learning_rate": 0.001
  },
  {
    "episode": 8668,
    "reward": 87.299412,
    "length": 69,
    "time": 129218.137486,
    "actor_loss": -66.12244415283203,
    "critic_loss": 5.194986343383789,
    "ent_coef": 0.06467851996421814,
    "learning_rate": 0.001
  },
  {
    "episode": 8669,
    "reward": 88.645117,
    "length": 67,
    "time": 129229.796496,
    "actor_loss": -66.97000122070312,
    "critic_loss": 21.1915283203125,
    "ent_coef": 0.06327351182699203,
    "learning_rate": 0.001
  },
  {
    "episode": 8670,
    "reward": 89.243837,
    "length": 64,
    "time": 129243.397252,
    "actor_loss": -64.40623474121094,
    "critic_loss": 76.03172302246094,
    "ent_coef": 0.06328299641609192,
    "learning_rate": 0.001
  },
  {
    "episode": 8671,
    "reward": 85.105029,
    "length": 74,
    "time": 129256.160933,
    "actor_loss": -68.21910095214844,
    "critic_loss": 7.041630744934082,
    "ent_coef": 0.06180932745337486,
    "learning_rate": 0.001
  },
  {
    "episode": 8672,
    "reward": 87.485301,
    "length": 70,
    "time": 129268.278431,
    "actor_loss": -68.44496154785156,
    "critic_loss": 2.994107723236084,
    "ent_coef": 0.06282166391611099,
    "learning_rate": 0.001
  },
  {
    "episode": 8673,
    "reward": 91.10385,
    "length": 62,
    "time": 129279.419429,
    "actor_loss": -71.33403015136719,
    "critic_loss": 42.64899444580078,
    "ent_coef": 0.06878882646560669,
    "learning_rate": 0.001
  },
  {
    "episode": 8674,
    "reward": 87.340447,
    "length": 70,
    "time": 129291.67003,
    "actor_loss": -64.22293090820312,
    "critic_loss": 9.819853782653809,
    "ent_coef": 0.07010319828987122,
    "learning_rate": 0.001
  },
  {
    "episode": 8675,
    "reward": 86.281274,
    "length": 70,
    "time": 129307.183136,
    "actor_loss": -66.82713317871094,
    "critic_loss": 4.145806312561035,
    "ent_coef": 0.07008947432041168,
    "learning_rate": 0.001
  },
  {
    "episode": 8676,
    "reward": 87.903855,
    "length": 68,
    "time": 129319.058205,
    "actor_loss": -66.84342193603516,
    "critic_loss": 7.923519134521484,
    "ent_coef": 0.07176065444946289,
    "learning_rate": 0.001
  },
  {
    "episode": 8677,
    "reward": 86.466281,
    "length": 71,
    "time": 129332.36162,
    "actor_loss": -70.63214111328125,
    "critic_loss": 11.283614158630371,
    "ent_coef": 0.07276613265275955,
    "learning_rate": 0.001
  },
  {
    "episode": 8678,
    "reward": 85.708379,
    "length": 73,
    "time": 129346.409394,
    "actor_loss": -66.35740661621094,
    "critic_loss": 7.919025897979736,
    "ent_coef": 0.07276102155447006,
    "learning_rate": 0.001
  },
  {
    "episode": 8679,
    "reward": 88.38051,
    "length": 66,
    "time": 129357.968558,
    "actor_loss": -72.62120819091797,
    "critic_loss": 23.11286163330078,
    "ent_coef": 0.070580393075943,
    "learning_rate": 0.001
  },
  {
    "episode": 8680,
    "reward": 84.078837,
    "length": 76,
    "time": 129371.284052,
    "actor_loss": -70.22895812988281,
    "critic_loss": 11.90052318572998,
    "ent_coef": 0.06636486202478409,
    "learning_rate": 0.001
  },
  {
    "episode": 8681,
    "reward": 88.940187,
    "length": 66,
    "time": 129384.943907,
    "actor_loss": -63.11863708496094,
    "critic_loss": 51.291412353515625,
    "ent_coef": 0.06512980163097382,
    "learning_rate": 0.001
  },
  {
    "episode": 8682,
    "reward": 87.697175,
    "length": 69,
    "time": 129398.110536,
    "actor_loss": -66.62068176269531,
    "critic_loss": 3.6789073944091797,
    "ent_coef": 0.06644321233034134,
    "learning_rate": 0.001
  },
  {
    "episode": 8683,
    "reward": 88.565445,
    "length": 67,
    "time": 129409.764781,
    "actor_loss": -67.90339660644531,
    "critic_loss": 5.821429252624512,
    "ent_coef": 0.06680438667535782,
    "learning_rate": 0.001
  },
  {
    "episode": 8684,
    "reward": 89.967354,
    "length": 65,
    "time": 129421.352809,
    "actor_loss": -63.777976989746094,
    "critic_loss": 3.297947883605957,
    "ent_coef": 0.06812366098165512,
    "learning_rate": 0.001
  },
  {
    "episode": 8685,
    "reward": 87.915479,
    "length": 70,
    "time": 129433.476862,
    "actor_loss": -67.37548065185547,
    "critic_loss": 16.469022750854492,
    "ent_coef": 0.06929131597280502,
    "learning_rate": 0.001
  },
  {
    "episode": 8686,
    "reward": 90.0053,
    "length": 64,
    "time": 129445.685065,
    "actor_loss": -64.62483215332031,
    "critic_loss": 4.783344268798828,
    "ent_coef": 0.06838834285736084,
    "learning_rate": 0.001
  },
  {
    "episode": 8687,
    "reward": 84.275452,
    "length": 76,
    "time": 129460.642475,
    "actor_loss": -61.615543365478516,
    "critic_loss": 36.83632278442383,
    "ent_coef": 0.06513306498527527,
    "learning_rate": 0.001
  },
  {
    "episode": 8688,
    "reward": 90.570294,
    "length": 62,
    "time": 129471.706187,
    "actor_loss": -63.121681213378906,
    "critic_loss": 19.693164825439453,
    "ent_coef": 0.0714147761464119,
    "learning_rate": 0.001
  },
  {
    "episode": 8689,
    "reward": 89.710281,
    "length": 65,
    "time": 129483.213532,
    "actor_loss": -63.47357177734375,
    "critic_loss": 14.462949752807617,
    "ent_coef": 0.07554294914007187,
    "learning_rate": 0.001
  },
  {
    "episode": 8690,
    "reward": 89.870985,
    "length": 63,
    "time": 129495.3689,
    "actor_loss": -72.54171752929688,
    "critic_loss": 5.957116603851318,
    "ent_coef": 0.07691557705402374,
    "learning_rate": 0.001
  },
  {
    "episode": 8691,
    "reward": 92.254416,
    "length": 59,
    "time": 129506.97,
    "actor_loss": -67.9664306640625,
    "critic_loss": 6.138099670410156,
    "ent_coef": 0.08190633356571198,
    "learning_rate": 0.001
  },
  {
    "episode": 8692,
    "reward": 89.147934,
    "length": 66,
    "time": 129519.386697,
    "actor_loss": -66.32527160644531,
    "critic_loss": 4.424469947814941,
    "ent_coef": 0.07982242852449417,
    "learning_rate": 0.001
  },
  {
    "episode": 8693,
    "reward": 87.706062,
    "length": 67,
    "time": 129532.06634,
    "actor_loss": -68.69161224365234,
    "critic_loss": 6.220573425292969,
    "ent_coef": 0.07483356446027756,
    "learning_rate": 0.001
  },
  {
    "episode": 8694,
    "reward": 89.099965,
    "length": 68,
    "time": 129543.900642,
    "actor_loss": -60.302276611328125,
    "critic_loss": 4.36881160736084,
    "ent_coef": 0.07321401685476303,
    "learning_rate": 0.001
  },
  {
    "episode": 8695,
    "reward": 84.970924,
    "length": 73,
    "time": 129556.33059,
    "actor_loss": -66.5611572265625,
    "critic_loss": 7.408100128173828,
    "ent_coef": 0.06916516274213791,
    "learning_rate": 0.001
  },
  {
    "episode": 8696,
    "reward": 84.82299,
    "length": 78,
    "time": 129570.646966,
    "actor_loss": -67.98084259033203,
    "critic_loss": 4.940244674682617,
    "ent_coef": 0.06599732488393784,
    "learning_rate": 0.001
  },
  {
    "episode": 8697,
    "reward": 88.818599,
    "length": 67,
    "time": 129583.275257,
    "actor_loss": -65.76046752929688,
    "critic_loss": 19.564315795898438,
    "ent_coef": 0.06606093794107437,
    "learning_rate": 0.001
  },
  {
    "episode": 8698,
    "reward": 88.232785,
    "length": 70,
    "time": 129595.924741,
    "actor_loss": -69.80392456054688,
    "critic_loss": 5.669689178466797,
    "ent_coef": 0.06787186115980148,
    "learning_rate": 0.001
  },
  {
    "episode": 8699,
    "reward": 88.046836,
    "length": 69,
    "time": 129608.912739,
    "actor_loss": -67.7552261352539,
    "critic_loss": 71.5447998046875,
    "ent_coef": 0.06656457483768463,
    "learning_rate": 0.001
  },
  {
    "episode": 8700,
    "reward": 84.061237,
    "length": 75,
    "time": 129625.745899,
    "actor_loss": -69.66328430175781,
    "critic_loss": 8.382306098937988,
    "ent_coef": 0.06298775225877762,
    "learning_rate": 0.001
  },
  {
    "episode": 8701,
    "reward": 85.779382,
    "length": 73,
    "time": 129638.454225,
    "actor_loss": -68.43464660644531,
    "critic_loss": 2.7033610343933105,
    "ent_coef": 0.06016045808792114,
    "learning_rate": 0.001
  },
  {
    "episode": 8702,
    "reward": 88.496337,
    "length": 69,
    "time": 129651.844843,
    "actor_loss": -71.11810302734375,
    "critic_loss": 4.970623016357422,
    "ent_coef": 0.059364303946495056,
    "learning_rate": 0.001
  },
  {
    "episode": 8703,
    "reward": 82.214746,
    "length": 81,
    "time": 129666.933862,
    "actor_loss": -64.45967102050781,
    "critic_loss": 3.4951398372650146,
    "ent_coef": 0.05610921233892441,
    "learning_rate": 0.001
  },
  {
    "episode": 8704,
    "reward": 84.929966,
    "length": 73,
    "time": 129680.539093,
    "actor_loss": -64.04844665527344,
    "critic_loss": 12.314786911010742,
    "ent_coef": 0.0564441941678524,
    "learning_rate": 0.001
  },
  {
    "episode": 8705,
    "reward": 86.95121,
    "length": 70,
    "time": 129695.619252,
    "actor_loss": -67.0733642578125,
    "critic_loss": 2.184837818145752,
    "ent_coef": 0.05773429572582245,
    "learning_rate": 0.001
  },
  {
    "episode": 8706,
    "reward": 88.561783,
    "length": 67,
    "time": 129707.421108,
    "actor_loss": -71.32478332519531,
    "critic_loss": 7.957597255706787,
    "ent_coef": 0.05810896307229996,
    "learning_rate": 0.001
  },
  {
    "episode": 8707,
    "reward": 88.130857,
    "length": 66,
    "time": 129720.599427,
    "actor_loss": -71.0992431640625,
    "critic_loss": 64.43759155273438,
    "ent_coef": 0.05839558690786362,
    "learning_rate": 0.001
  },
  {
    "episode": 8708,
    "reward": 90.165287,
    "length": 64,
    "time": 129732.508528,
    "actor_loss": -65.78591918945312,
    "critic_loss": 6.982288360595703,
    "ent_coef": 0.06119151413440704,
    "learning_rate": 0.001
  },
  {
    "episode": 8709,
    "reward": 89.88212,
    "length": 67,
    "time": 129744.91079,
    "actor_loss": -67.66383361816406,
    "critic_loss": 6.935913562774658,
    "ent_coef": 0.06403952836990356,
    "learning_rate": 0.001
  },
  {
    "episode": 8710,
    "reward": 88.735665,
    "length": 67,
    "time": 129757.992039,
    "actor_loss": -66.2292251586914,
    "critic_loss": 3.2197482585906982,
    "ent_coef": 0.06559762358665466,
    "learning_rate": 0.001
  },
  {
    "episode": 8711,
    "reward": 88.71357,
    "length": 66,
    "time": 129771.996939,
    "actor_loss": -61.272003173828125,
    "critic_loss": 36.63214111328125,
    "ent_coef": 0.06389106810092926,
    "learning_rate": 0.001
  },
  {
    "episode": 8712,
    "reward": 86.517075,
    "length": 70,
    "time": 129787.162663,
    "actor_loss": -66.96031188964844,
    "critic_loss": 4.438923358917236,
    "ent_coef": 0.06322541832923889,
    "learning_rate": 0.001
  },
  {
    "episode": 8713,
    "reward": 88.109124,
    "length": 67,
    "time": 129799.260258,
    "actor_loss": -63.71931457519531,
    "critic_loss": 5.647313594818115,
    "ent_coef": 0.06316057592630386,
    "learning_rate": 0.001
  },
  {
    "episode": 8714,
    "reward": 90.325131,
    "length": 66,
    "time": 129813.50575,
    "actor_loss": -72.50938415527344,
    "critic_loss": 52.668701171875,
    "ent_coef": 0.06713715940713882,
    "learning_rate": 0.001
  },
  {
    "episode": 8715,
    "reward": 87.222033,
    "length": 70,
    "time": 129825.931682,
    "actor_loss": -63.052459716796875,
    "critic_loss": 28.919391632080078,
    "ent_coef": 0.06537455320358276,
    "learning_rate": 0.001
  },
  {
    "episode": 8716,
    "reward": 82.425584,
    "length": 76,
    "time": 129838.944785,
    "actor_loss": -70.8414306640625,
    "critic_loss": 1.2775089740753174,
    "ent_coef": 0.06098264828324318,
    "learning_rate": 0.001
  },
  {
    "episode": 8717,
    "reward": 88.902866,
    "length": 66,
    "time": 129851.195905,
    "actor_loss": -62.40974807739258,
    "critic_loss": 6.881359577178955,
    "ent_coef": 0.061370186507701874,
    "learning_rate": 0.001
  },
  {
    "episode": 8718,
    "reward": 88.827821,
    "length": 66,
    "time": 129862.883405,
    "actor_loss": -67.61773681640625,
    "critic_loss": 4.5001091957092285,
    "ent_coef": 0.0635712742805481,
    "learning_rate": 0.001
  },
  {
    "episode": 8719,
    "reward": 89.633346,
    "length": 64,
    "time": 129874.199151,
    "actor_loss": -65.66796875,
    "critic_loss": 5.210494518280029,
    "ent_coef": 0.06442812085151672,
    "learning_rate": 0.001
  },
  {
    "episode": 8720,
    "reward": 89.187722,
    "length": 66,
    "time": 129886.014145,
    "actor_loss": -66.6048812866211,
    "critic_loss": 3.9351415634155273,
    "ent_coef": 0.06629129499197006,
    "learning_rate": 0.001
  },
  {
    "episode": 8721,
    "reward": 87.357869,
    "length": 69,
    "time": 129899.436123,
    "actor_loss": -65.70370483398438,
    "critic_loss": 3.5035500526428223,
    "ent_coef": 0.06394965946674347,
    "learning_rate": 0.001
  },
  {
    "episode": 8722,
    "reward": 89.571782,
    "length": 64,
    "time": 129911.208403,
    "actor_loss": -66.65886688232422,
    "critic_loss": 51.603660583496094,
    "ent_coef": 0.06504549086093903,
    "learning_rate": 0.001
  },
  {
    "episode": 8723,
    "reward": 88.389498,
    "length": 67,
    "time": 129924.695427,
    "actor_loss": -67.19535827636719,
    "critic_loss": 6.32608699798584,
    "ent_coef": 0.06799621880054474,
    "learning_rate": 0.001
  },
  {
    "episode": 8724,
    "reward": 88.60767,
    "length": 68,
    "time": 129939.884791,
    "actor_loss": -65.94393920898438,
    "critic_loss": 38.16944885253906,
    "ent_coef": 0.06922480463981628,
    "learning_rate": 0.001
  },
  {
    "episode": 8725,
    "reward": 88.852151,
    "length": 66,
    "time": 129951.63057,
    "actor_loss": -67.43434143066406,
    "critic_loss": 5.172214508056641,
    "ent_coef": 0.07249291986227036,
    "learning_rate": 0.001
  },
  {
    "episode": 8726,
    "reward": 86.843379,
    "length": 70,
    "time": 129964.041663,
    "actor_loss": -61.896087646484375,
    "critic_loss": 4.792576789855957,
    "ent_coef": 0.07472233474254608,
    "learning_rate": 0.001
  },
  {
    "episode": 8727,
    "reward": 89.836464,
    "length": 64,
    "time": 129976.492089,
    "actor_loss": -67.1816635131836,
    "critic_loss": 46.469947814941406,
    "ent_coef": 0.08147136121988297,
    "learning_rate": 0.001
  },
  {
    "episode": 8728,
    "reward": 91.540876,
    "length": 60,
    "time": 129989.826985,
    "actor_loss": -64.36677551269531,
    "critic_loss": 21.0087947845459,
    "ent_coef": 0.08789023011922836,
    "learning_rate": 0.001
  },
  {
    "episode": 8729,
    "reward": 90.778075,
    "length": 62,
    "time": 130001.796158,
    "actor_loss": -68.85699462890625,
    "critic_loss": 4.228322505950928,
    "ent_coef": 0.09089250862598419,
    "learning_rate": 0.001
  },
  {
    "episode": 8730,
    "reward": 85.943688,
    "length": 70,
    "time": 130013.709561,
    "actor_loss": -64.00466918945312,
    "critic_loss": 2.147850513458252,
    "ent_coef": 0.08767092227935791,
    "learning_rate": 0.001
  },
  {
    "episode": 8731,
    "reward": 89.872631,
    "length": 64,
    "time": 130028.234287,
    "actor_loss": -68.51420593261719,
    "critic_loss": 2.6594667434692383,
    "ent_coef": 0.08798063546419144,
    "learning_rate": 0.001
  },
  {
    "episode": 8732,
    "reward": 87.82803,
    "length": 68,
    "time": 130040.900554,
    "actor_loss": -62.845237731933594,
    "critic_loss": 7.65397834777832,
    "ent_coef": 0.08770305663347244,
    "learning_rate": 0.001
  },
  {
    "episode": 8733,
    "reward": 87.155015,
    "length": 70,
    "time": 130053.183165,
    "actor_loss": -66.54216003417969,
    "critic_loss": 6.240043640136719,
    "ent_coef": 0.08495461195707321,
    "learning_rate": 0.001
  },
  {
    "episode": 8734,
    "reward": 86.743189,
    "length": 71,
    "time": 130068.617639,
    "actor_loss": -62.180145263671875,
    "critic_loss": 3.3936972618103027,
    "ent_coef": 0.08368005603551865,
    "learning_rate": 0.001
  },
  {
    "episode": 8735,
    "reward": 85.793261,
    "length": 72,
    "time": 130080.895354,
    "actor_loss": -63.073795318603516,
    "critic_loss": 3.1647839546203613,
    "ent_coef": 0.08167470991611481,
    "learning_rate": 0.001
  },
  {
    "episode": 8736,
    "reward": 88.12383,
    "length": 68,
    "time": 130092.870427,
    "actor_loss": -67.90165710449219,
    "critic_loss": 11.545135498046875,
    "ent_coef": 0.08118230849504471,
    "learning_rate": 0.001
  },
  {
    "episode": 8737,
    "reward": 90.308598,
    "length": 62,
    "time": 130105.346616,
    "actor_loss": -64.94235229492188,
    "critic_loss": 3.839625597000122,
    "ent_coef": 0.08358398079872131,
    "learning_rate": 0.001
  },
  {
    "episode": 8738,
    "reward": 82.409385,
    "length": 78,
    "time": 130121.293012,
    "actor_loss": -68.04243469238281,
    "critic_loss": 9.275381088256836,
    "ent_coef": 0.0771937444806099,
    "learning_rate": 0.001
  },
  {
    "episode": 8739,
    "reward": 87.554556,
    "length": 68,
    "time": 130136.677836,
    "actor_loss": -57.79307556152344,
    "critic_loss": 11.088424682617188,
    "ent_coef": 0.07372596859931946,
    "learning_rate": 0.001
  },
  {
    "episode": 8740,
    "reward": 80.696463,
    "length": 82,
    "time": 130150.493288,
    "actor_loss": -69.43756103515625,
    "critic_loss": 15.139251708984375,
    "ent_coef": 0.07049040496349335,
    "learning_rate": 0.001
  },
  {
    "episode": 8741,
    "reward": 85.333114,
    "length": 71,
    "time": 130164.730807,
    "actor_loss": -63.51487731933594,
    "critic_loss": 6.187384128570557,
    "ent_coef": 0.06698571145534515,
    "learning_rate": 0.001
  },
  {
    "episode": 8742,
    "reward": 86.628176,
    "length": 70,
    "time": 130179.893603,
    "actor_loss": -63.49412155151367,
    "critic_loss": 7.603338718414307,
    "ent_coef": 0.06667716801166534,
    "learning_rate": 0.001
  },
  {
    "episode": 8743,
    "reward": 88.656956,
    "length": 67,
    "time": 130191.564703,
    "actor_loss": -67.3884048461914,
    "critic_loss": 29.56609344482422,
    "ent_coef": 0.06759271770715714,
    "learning_rate": 0.001
  },
  {
    "episode": 8744,
    "reward": 86.988581,
    "length": 70,
    "time": 130203.760779,
    "actor_loss": -68.62905883789062,
    "critic_loss": 15.160685539245605,
    "ent_coef": 0.071234330534935,
    "learning_rate": 0.001
  },
  {
    "episode": 8745,
    "reward": 87.404217,
    "length": 69,
    "time": 130216.787886,
    "actor_loss": -67.38188171386719,
    "critic_loss": 7.417951583862305,
    "ent_coef": 0.07345244288444519,
    "learning_rate": 0.001
  },
  {
    "episode": 8746,
    "reward": 88.854778,
    "length": 66,
    "time": 130230.673936,
    "actor_loss": -65.901611328125,
    "critic_loss": 7.655881881713867,
    "ent_coef": 0.07458177953958511,
    "learning_rate": 0.001
  },
  {
    "episode": 8747,
    "reward": 88.80906,
    "length": 66,
    "time": 130242.634815,
    "actor_loss": -64.081298828125,
    "critic_loss": 3.0838327407836914,
    "ent_coef": 0.07461795210838318,
    "learning_rate": 0.001
  },
  {
    "episode": 8748,
    "reward": 86.926463,
    "length": 69,
    "time": 130254.594299,
    "actor_loss": -61.417503356933594,
    "critic_loss": 5.823871612548828,
    "ent_coef": 0.07437262684106827,
    "learning_rate": 0.001
  },
  {
    "episode": 8749,
    "reward": 89.050188,
    "length": 66,
    "time": 130266.331118,
    "actor_loss": -60.591583251953125,
    "critic_loss": 3.9649717807769775,
    "ent_coef": 0.07611481100320816,
    "learning_rate": 0.001
  },
  {
    "episode": 8750,
    "reward": 84.301729,
    "length": 74,
    "time": 130279.939311,
    "actor_loss": -69.14714813232422,
    "critic_loss": 6.248294353485107,
    "ent_coef": 0.07631223648786545,
    "learning_rate": 0.001
  },
  {
    "episode": 8751,
    "reward": 85.659216,
    "length": 72,
    "time": 130292.935547,
    "actor_loss": -64.46391296386719,
    "critic_loss": 45.566715240478516,
    "ent_coef": 0.07720533758401871,
    "learning_rate": 0.001
  },
  {
    "episode": 8752,
    "reward": 89.585561,
    "length": 65,
    "time": 130305.391136,
    "actor_loss": -68.98609924316406,
    "critic_loss": 4.787827491760254,
    "ent_coef": 0.07849746942520142,
    "learning_rate": 0.001
  },
  {
    "episode": 8753,
    "reward": 85.668789,
    "length": 72,
    "time": 130317.875816,
    "actor_loss": -70.87275695800781,
    "critic_loss": 130.5485382080078,
    "ent_coef": 0.07696457952260971,
    "learning_rate": 0.001
  },
  {
    "episode": 8754,
    "reward": 86.665047,
    "length": 70,
    "time": 130330.078524,
    "actor_loss": -68.84745788574219,
    "critic_loss": 182.81756591796875,
    "ent_coef": 0.07370518147945404,
    "learning_rate": 0.001
  },
  {
    "episode": 8755,
    "reward": 86.6741,
    "length": 71,
    "time": 130342.383898,
    "actor_loss": -67.440673828125,
    "critic_loss": 116.24639892578125,
    "ent_coef": 0.0722929835319519,
    "learning_rate": 0.001
  },
  {
    "episode": 8756,
    "reward": 85.267306,
    "length": 73,
    "time": 130355.078331,
    "actor_loss": -64.89007568359375,
    "critic_loss": 6.923802375793457,
    "ent_coef": 0.07114245742559433,
    "learning_rate": 0.001
  },
  {
    "episode": 8757,
    "reward": 86.014848,
    "length": 72,
    "time": 130367.786054,
    "actor_loss": -63.78173065185547,
    "critic_loss": 4.8281965255737305,
    "ent_coef": 0.06902400404214859,
    "learning_rate": 0.001
  },
  {
    "episode": 8758,
    "reward": 86.198761,
    "length": 71,
    "time": 130380.127335,
    "actor_loss": -65.47737884521484,
    "critic_loss": 7.2792744636535645,
    "ent_coef": 0.06757067143917084,
    "learning_rate": 0.001
  },
  {
    "episode": 8759,
    "reward": 89.369683,
    "length": 65,
    "time": 130395.609954,
    "actor_loss": -62.90699768066406,
    "critic_loss": 40.658042907714844,
    "ent_coef": 0.06896346807479858,
    "learning_rate": 0.001
  },
  {
    "episode": 8760,
    "reward": 87.83913,
    "length": 69,
    "time": 130408.600509,
    "actor_loss": -67.61396789550781,
    "critic_loss": 20.397214889526367,
    "ent_coef": 0.0719674602150917,
    "learning_rate": 0.001
  },
  {
    "episode": 8761,
    "reward": 88.924627,
    "length": 67,
    "time": 130422.025781,
    "actor_loss": -66.36006164550781,
    "critic_loss": 4.669892311096191,
    "ent_coef": 0.07299520075321198,
    "learning_rate": 0.001
  },
  {
    "episode": 8762,
    "reward": 88.85735,
    "length": 66,
    "time": 130434.674269,
    "actor_loss": -66.80433654785156,
    "critic_loss": 60.581886291503906,
    "ent_coef": 0.07000170648097992,
    "learning_rate": 0.001
  },
  {
    "episode": 8763,
    "reward": 85.049922,
    "length": 72,
    "time": 130448.929548,
    "actor_loss": -67.372802734375,
    "critic_loss": 3.783155679702759,
    "ent_coef": 0.06785393506288528,
    "learning_rate": 0.001
  },
  {
    "episode": 8764,
    "reward": 87.965228,
    "length": 69,
    "time": 130461.020246,
    "actor_loss": -61.48390197753906,
    "critic_loss": 3.0507681369781494,
    "ent_coef": 0.06940814107656479,
    "learning_rate": 0.001
  },
  {
    "episode": 8765,
    "reward": 86.118679,
    "length": 70,
    "time": 130473.989872,
    "actor_loss": -72.73533630371094,
    "critic_loss": 54.05659103393555,
    "ent_coef": 0.0685303658246994,
    "learning_rate": 0.001
  },
  {
    "episode": 8766,
    "reward": 87.081702,
    "length": 69,
    "time": 130489.028732,
    "actor_loss": -66.22005462646484,
    "critic_loss": 41.353031158447266,
    "ent_coef": 0.0719890296459198,
    "learning_rate": 0.001
  },
  {
    "episode": 8767,
    "reward": 90.367641,
    "length": 62,
    "time": 130500.222201,
    "actor_loss": -66.87579345703125,
    "critic_loss": 4.588567733764648,
    "ent_coef": 0.07829774916172028,
    "learning_rate": 0.001
  },
  {
    "episode": 8768,
    "reward": 89.352064,
    "length": 64,
    "time": 130514.036866,
    "actor_loss": -70.46815490722656,
    "critic_loss": 34.9339599609375,
    "ent_coef": 0.08288808166980743,
    "learning_rate": 0.001
  },
  {
    "episode": 8769,
    "reward": 88.30266,
    "length": 67,
    "time": 130527.75303,
    "actor_loss": -68.16246032714844,
    "critic_loss": 4.146291255950928,
    "ent_coef": 0.08330929279327393,
    "learning_rate": 0.001
  },
  {
    "episode": 8770,
    "reward": 89.095425,
    "length": 65,
    "time": 130539.153321,
    "actor_loss": -67.38151550292969,
    "critic_loss": 12.97148323059082,
    "ent_coef": 0.08569317311048508,
    "learning_rate": 0.001
  },
  {
    "episode": 8771,
    "reward": 88.727708,
    "length": 65,
    "time": 130550.647258,
    "actor_loss": -63.45556640625,
    "critic_loss": 2.456308364868164,
    "ent_coef": 0.09114247560501099,
    "learning_rate": 0.001
  },
  {
    "episode": 8772,
    "reward": 88.87635,
    "length": 65,
    "time": 130562.278273,
    "actor_loss": -67.70668029785156,
    "critic_loss": 3.1958794593811035,
    "ent_coef": 0.09279705584049225,
    "learning_rate": 0.001
  },
  {
    "episode": 8773,
    "reward": 87.39483,
    "length": 67,
    "time": 130574.14093,
    "actor_loss": -68.60325622558594,
    "critic_loss": 4.450470924377441,
    "ent_coef": 0.09139806777238846,
    "learning_rate": 0.001
  },
  {
    "episode": 8774,
    "reward": 82.624183,
    "length": 75,
    "time": 130586.980927,
    "actor_loss": -67.39643859863281,
    "critic_loss": 18.640308380126953,
    "ent_coef": 0.08513322472572327,
    "learning_rate": 0.001
  },
  {
    "episode": 8775,
    "reward": 79.338359,
    "length": 82,
    "time": 130602.864738,
    "actor_loss": -69.34369659423828,
    "critic_loss": 10.713838577270508,
    "ent_coef": 0.07844763994216919,
    "learning_rate": 0.001
  },
  {
    "episode": 8776,
    "reward": 88.566173,
    "length": 66,
    "time": 130614.613188,
    "actor_loss": -65.81633758544922,
    "critic_loss": 15.072153091430664,
    "ent_coef": 0.07718678563833237,
    "learning_rate": 0.001
  },
  {
    "episode": 8777,
    "reward": 87.577783,
    "length": 69,
    "time": 130629.918233,
    "actor_loss": -65.55606079101562,
    "critic_loss": 17.621826171875,
    "ent_coef": 0.07494494318962097,
    "learning_rate": 0.001
  },
  {
    "episode": 8778,
    "reward": 85.473351,
    "length": 71,
    "time": 130643.603615,
    "actor_loss": -62.255470275878906,
    "critic_loss": 20.81770896911621,
    "ent_coef": 0.07212609052658081,
    "learning_rate": 0.001
  },
  {
    "episode": 8779,
    "reward": 89.272899,
    "length": 65,
    "time": 130656.517054,
    "actor_loss": -66.09022521972656,
    "critic_loss": 3.1167778968811035,
    "ent_coef": 0.069588303565979,
    "learning_rate": 0.001
  },
  {
    "episode": 8780,
    "reward": 88.625042,
    "length": 66,
    "time": 130669.257888,
    "actor_loss": -67.38816833496094,
    "critic_loss": 3.844072103500366,
    "ent_coef": 0.06897662580013275,
    "learning_rate": 0.001
  },
  {
    "episode": 8781,
    "reward": 86.325789,
    "length": 70,
    "time": 130682.950121,
    "actor_loss": -66.08688354492188,
    "critic_loss": 4.234445571899414,
    "ent_coef": 0.06892334669828415,
    "learning_rate": 0.001
  },
  {
    "episode": 8782,
    "reward": 90.804779,
    "length": 62,
    "time": 130694.276722,
    "actor_loss": -67.67353820800781,
    "critic_loss": 4.701883316040039,
    "ent_coef": 0.07081229984760284,
    "learning_rate": 0.001
  },
  {
    "episode": 8783,
    "reward": 90.030842,
    "length": 64,
    "time": 130705.564677,
    "actor_loss": -65.64178466796875,
    "critic_loss": 5.589888572692871,
    "ent_coef": 0.07293321937322617,
    "learning_rate": 0.001
  },
  {
    "episode": 8784,
    "reward": 88.59078,
    "length": 67,
    "time": 130717.250995,
    "actor_loss": -69.37117004394531,
    "critic_loss": 3.838677406311035,
    "ent_coef": 0.07359329611063004,
    "learning_rate": 0.001
  },
  {
    "episode": 8785,
    "reward": 89.252601,
    "length": 66,
    "time": 130728.929954,
    "actor_loss": -66.31597900390625,
    "critic_loss": 5.0334978103637695,
    "ent_coef": 0.07616026699542999,
    "learning_rate": 0.001
  },
  {
    "episode": 8786,
    "reward": 89.036222,
    "length": 65,
    "time": 130740.906334,
    "actor_loss": -66.23435974121094,
    "critic_loss": 6.735291957855225,
    "ent_coef": 0.07794852554798126,
    "learning_rate": 0.001
  },
  {
    "episode": 8787,
    "reward": 87.88738,
    "length": 67,
    "time": 130756.090647,
    "actor_loss": -66.04718017578125,
    "critic_loss": 3.77740478515625,
    "ent_coef": 0.07556737959384918,
    "learning_rate": 0.001
  },
  {
    "episode": 8788,
    "reward": 90.594435,
    "length": 62,
    "time": 130769.128654,
    "actor_loss": -67.09519958496094,
    "critic_loss": 11.242403984069824,
    "ent_coef": 0.07518194615840912,
    "learning_rate": 0.001
  },
  {
    "episode": 8789,
    "reward": 87.351534,
    "length": 68,
    "time": 130783.294671,
    "actor_loss": -66.73509216308594,
    "critic_loss": 5.485161781311035,
    "ent_coef": 0.07374826073646545,
    "learning_rate": 0.001
  },
  {
    "episode": 8790,
    "reward": 88.902141,
    "length": 67,
    "time": 130796.2912,
    "actor_loss": -69.07330322265625,
    "critic_loss": 10.173197746276855,
    "ent_coef": 0.07331707328557968,
    "learning_rate": 0.001
  },
  {
    "episode": 8791,
    "reward": 88.815783,
    "length": 66,
    "time": 130813.274447,
    "actor_loss": -68.35406494140625,
    "critic_loss": 32.556304931640625,
    "ent_coef": 0.07194390147924423,
    "learning_rate": 0.001
  },
  {
    "episode": 8792,
    "reward": 89.518848,
    "length": 64,
    "time": 130825.823693,
    "actor_loss": -61.53650665283203,
    "critic_loss": 15.393183708190918,
    "ent_coef": 0.0704561099410057,
    "learning_rate": 0.001
  },
  {
    "episode": 8793,
    "reward": 90.840835,
    "length": 61,
    "time": 130839.703697,
    "actor_loss": -64.41783142089844,
    "critic_loss": 2.454141616821289,
    "ent_coef": 0.07315782457590103,
    "learning_rate": 0.001
  },
  {
    "episode": 8794,
    "reward": 88.906565,
    "length": 66,
    "time": 130852.903474,
    "actor_loss": -69.25113677978516,
    "critic_loss": 2.8395485877990723,
    "ent_coef": 0.07609543204307556,
    "learning_rate": 0.001
  },
  {
    "episode": 8795,
    "reward": 89.387519,
    "length": 64,
    "time": 130865.495834,
    "actor_loss": -68.16364288330078,
    "critic_loss": 3.905604124069214,
    "ent_coef": 0.07778146862983704,
    "learning_rate": 0.001
  },
  {
    "episode": 8796,
    "reward": 89.507468,
    "length": 64,
    "time": 130878.730026,
    "actor_loss": -66.404541015625,
    "critic_loss": 2.562370777130127,
    "ent_coef": 0.07566718757152557,
    "learning_rate": 0.001
  },
  {
    "episode": 8797,
    "reward": 89.511894,
    "length": 65,
    "time": 130892.104828,
    "actor_loss": -69.140625,
    "critic_loss": 6.493573188781738,
    "ent_coef": 0.07483468949794769,
    "learning_rate": 0.001
  },
  {
    "episode": 8798,
    "reward": 89.794136,
    "length": 64,
    "time": 130904.405304,
    "actor_loss": -66.08515930175781,
    "critic_loss": 8.19339370727539,
    "ent_coef": 0.07695272564888,
    "learning_rate": 0.001
  },
  {
    "episode": 8799,
    "reward": 88.049548,
    "length": 71,
    "time": 130920.402562,
    "actor_loss": -65.76365661621094,
    "critic_loss": 9.642095565795898,
    "ent_coef": 0.07504808157682419,
    "learning_rate": 0.001
  },
  {
    "episode": 8800,
    "reward": 89.400008,
    "length": 66,
    "time": 130936.208538,
    "actor_loss": -65.46820068359375,
    "critic_loss": 28.009292602539062,
    "ent_coef": 0.0731004849076271,
    "learning_rate": 0.001
  },
  {
    "episode": 8801,
    "reward": 89.449271,
    "length": 67,
    "time": 130949.733321,
    "actor_loss": -72.85186767578125,
    "critic_loss": 35.57592010498047,
    "ent_coef": 0.07391432672739029,
    "learning_rate": 0.001
  },
  {
    "episode": 8802,
    "reward": 89.706773,
    "length": 66,
    "time": 130962.59211,
    "actor_loss": -68.32643127441406,
    "critic_loss": 5.516952037811279,
    "ent_coef": 0.07229425758123398,
    "learning_rate": 0.001
  },
  {
    "episode": 8803,
    "reward": 89.777858,
    "length": 64,
    "time": 130976.570686,
    "actor_loss": -65.1284408569336,
    "critic_loss": 6.100725173950195,
    "ent_coef": 0.07148797065019608,
    "learning_rate": 0.001
  },
  {
    "episode": 8804,
    "reward": 90.668328,
    "length": 62,
    "time": 130989.420229,
    "actor_loss": -66.15428161621094,
    "critic_loss": 2.3246042728424072,
    "ent_coef": 0.07275701314210892,
    "learning_rate": 0.001
  },
  {
    "episode": 8805,
    "reward": 88.294748,
    "length": 69,
    "time": 131002.269857,
    "actor_loss": -65.87688446044922,
    "critic_loss": 5.488163948059082,
    "ent_coef": 0.07127772271633148,
    "learning_rate": 0.001
  },
  {
    "episode": 8806,
    "reward": 88.947085,
    "length": 66,
    "time": 131014.870478,
    "actor_loss": -65.78868865966797,
    "critic_loss": 3.212575912475586,
    "ent_coef": 0.07017111033201218,
    "learning_rate": 0.001
  },
  {
    "episode": 8807,
    "reward": 79.860206,
    "length": 85,
    "time": 131030.142318,
    "actor_loss": -67.614013671875,
    "critic_loss": 5.954209804534912,
    "ent_coef": 0.0666227638721466,
    "learning_rate": 0.001
  },
  {
    "episode": 8808,
    "reward": 89.222477,
    "length": 65,
    "time": 131043.091801,
    "actor_loss": -66.20691680908203,
    "critic_loss": 134.20947265625,
    "ent_coef": 0.0667002871632576,
    "learning_rate": 0.001
  },
  {
    "episode": 8809,
    "reward": 88.939483,
    "length": 65,
    "time": 131058.424523,
    "actor_loss": -66.43545532226562,
    "critic_loss": 5.302973747253418,
    "ent_coef": 0.06829418987035751,
    "learning_rate": 0.001
  },
  {
    "episode": 8810,
    "reward": 87.402225,
    "length": 71,
    "time": 131071.359903,
    "actor_loss": -66.65005493164062,
    "critic_loss": 6.391847610473633,
    "ent_coef": 0.06870885193347931,
    "learning_rate": 0.001
  },
  {
    "episode": 8811,
    "reward": 88.735651,
    "length": 67,
    "time": 131083.618598,
    "actor_loss": -66.43665313720703,
    "critic_loss": 2.3585410118103027,
    "ent_coef": 0.07010475546121597,
    "learning_rate": 0.001
  },
  {
    "episode": 8812,
    "reward": 85.237727,
    "length": 73,
    "time": 131097.020772,
    "actor_loss": -66.00780487060547,
    "critic_loss": 14.887102127075195,
    "ent_coef": 0.07074527442455292,
    "learning_rate": 0.001
  },
  {
    "episode": 8813,
    "reward": 89.438037,
    "length": 64,
    "time": 131108.498953,
    "actor_loss": -63.10762405395508,
    "critic_loss": 5.055470943450928,
    "ent_coef": 0.07301294058561325,
    "learning_rate": 0.001
  },
  {
    "episode": 8814,
    "reward": 81.378265,
    "length": 80,
    "time": 131122.893911,
    "actor_loss": -65.16044616699219,
    "critic_loss": 4.578861236572266,
    "ent_coef": 0.06984216719865799,
    "learning_rate": 0.001
  },
  {
    "episode": 8815,
    "reward": 87.198703,
    "length": 67,
    "time": 131136.832219,
    "actor_loss": -70.5541763305664,
    "critic_loss": 4.395509719848633,
    "ent_coef": 0.06920663267374039,
    "learning_rate": 0.001
  },
  {
    "episode": 8816,
    "reward": 87.622574,
    "length": 70,
    "time": 131156.410666,
    "actor_loss": -66.66970825195312,
    "critic_loss": 50.43534851074219,
    "ent_coef": 0.06891819089651108,
    "learning_rate": 0.001
  },
  {
    "episode": 8817,
    "reward": 86.344093,
    "length": 71,
    "time": 131171.657286,
    "actor_loss": -62.40956497192383,
    "critic_loss": 3.542874574661255,
    "ent_coef": 0.06975110620260239,
    "learning_rate": 0.001
  },
  {
    "episode": 8818,
    "reward": 87.671147,
    "length": 71,
    "time": 131185.092548,
    "actor_loss": -63.629417419433594,
    "critic_loss": 2.4435296058654785,
    "ent_coef": 0.07083892077207565,
    "learning_rate": 0.001
  },
  {
    "episode": 8819,
    "reward": 83.747991,
    "length": 77,
    "time": 131198.670038,
    "actor_loss": -62.76357650756836,
    "critic_loss": 23.898218154907227,
    "ent_coef": 0.07015450298786163,
    "learning_rate": 0.001
  },
  {
    "episode": 8820,
    "reward": 87.123341,
    "length": 72,
    "time": 131213.700552,
    "actor_loss": -65.63274383544922,
    "critic_loss": 76.11337280273438,
    "ent_coef": 0.0698794424533844,
    "learning_rate": 0.001
  },
  {
    "episode": 8821,
    "reward": 82.639904,
    "length": 80,
    "time": 131231.587354,
    "actor_loss": -63.727630615234375,
    "critic_loss": 3.84651517868042,
    "ent_coef": 0.06717526912689209,
    "learning_rate": 0.001
  },
  {
    "episode": 8822,
    "reward": 87.723046,
    "length": 70,
    "time": 131243.794486,
    "actor_loss": -67.91297149658203,
    "critic_loss": 16.025854110717773,
    "ent_coef": 0.06887498497962952,
    "learning_rate": 0.001
  },
  {
    "episode": 8823,
    "reward": 86.857203,
    "length": 71,
    "time": 131257.212952,
    "actor_loss": -64.89946746826172,
    "critic_loss": 11.453369140625,
    "ent_coef": 0.06805332005023956,
    "learning_rate": 0.001
  },
  {
    "episode": 8824,
    "reward": 78.267834,
    "length": 86,
    "time": 131272.585016,
    "actor_loss": -64.16968536376953,
    "critic_loss": 3.896951675415039,
    "ent_coef": 0.06314717233181,
    "learning_rate": 0.001
  },
  {
    "episode": 8825,
    "reward": 88.924422,
    "length": 67,
    "time": 131286.73496,
    "actor_loss": -62.70127868652344,
    "critic_loss": 2.9439468383789062,
    "ent_coef": 0.06299009174108505,
    "learning_rate": 0.001
  },
  {
    "episode": 8826,
    "reward": 86.839597,
    "length": 71,
    "time": 131300.256738,
    "actor_loss": -68.60317993164062,
    "critic_loss": 13.589378356933594,
    "ent_coef": 0.06332260370254517,
    "learning_rate": 0.001
  },
  {
    "episode": 8827,
    "reward": 89.356757,
    "length": 66,
    "time": 131311.757529,
    "actor_loss": -65.79605865478516,
    "critic_loss": 6.683864116668701,
    "ent_coef": 0.06499329209327698,
    "learning_rate": 0.001
  },
  {
    "episode": 8828,
    "reward": 88.885232,
    "length": 66,
    "time": 131324.57875,
    "actor_loss": -65.91242218017578,
    "critic_loss": 2.562619686126709,
    "ent_coef": 0.06707406789064407,
    "learning_rate": 0.001
  },
  {
    "episode": 8829,
    "reward": 78.458465,
    "length": 90,
    "time": 131339.649153,
    "actor_loss": -65.29297637939453,
    "critic_loss": 2.495185375213623,
    "ent_coef": 0.06333382427692413,
    "learning_rate": 0.001
  },
  {
    "episode": 8830,
    "reward": 86.104789,
    "length": 73,
    "time": 131353.789095,
    "actor_loss": -60.586029052734375,
    "critic_loss": 15.214781761169434,
    "ent_coef": 0.06042831391096115,
    "learning_rate": 0.001
  },
  {
    "episode": 8831,
    "reward": 88.821349,
    "length": 68,
    "time": 131368.252102,
    "actor_loss": -65.08076477050781,
    "critic_loss": 14.940431594848633,
    "ent_coef": 0.05996047332882881,
    "learning_rate": 0.001
  },
  {
    "episode": 8832,
    "reward": 90.24673,
    "length": 65,
    "time": 131379.779804,
    "actor_loss": -68.43082427978516,
    "critic_loss": 5.102375030517578,
    "ent_coef": 0.0633971318602562,
    "learning_rate": 0.001
  },
  {
    "episode": 8833,
    "reward": 88.261801,
    "length": 67,
    "time": 131391.867119,
    "actor_loss": -69.967041015625,
    "critic_loss": 47.65716552734375,
    "ent_coef": 0.06749327480792999,
    "learning_rate": 0.001
  },
  {
    "episode": 8834,
    "reward": 88.640065,
    "length": 67,
    "time": 131404.008361,
    "actor_loss": -71.93901062011719,
    "critic_loss": 7.035333156585693,
    "ent_coef": 0.0679883360862732,
    "learning_rate": 0.001
  },
  {
    "episode": 8835,
    "reward": 88.655792,
    "length": 66,
    "time": 131415.805943,
    "actor_loss": -67.21612548828125,
    "critic_loss": 4.646190643310547,
    "ent_coef": 0.06785841286182404,
    "learning_rate": 0.001
  },
  {
    "episode": 8836,
    "reward": 87.687669,
    "length": 68,
    "time": 131429.540787,
    "actor_loss": -66.73458862304688,
    "critic_loss": 86.00743103027344,
    "ent_coef": 0.07081659138202667,
    "learning_rate": 0.001
  },
  {
    "episode": 8837,
    "reward": 88.713528,
    "length": 67,
    "time": 131441.241684,
    "actor_loss": -64.10922241210938,
    "critic_loss": 6.907636642456055,
    "ent_coef": 0.07444509118795395,
    "learning_rate": 0.001
  },
  {
    "episode": 8838,
    "reward": 89.156286,
    "length": 65,
    "time": 131454.548825,
    "actor_loss": -65.80641174316406,
    "critic_loss": 3.047184467315674,
    "ent_coef": 0.07990935444831848,
    "learning_rate": 0.001
  },
  {
    "episode": 8839,
    "reward": 87.729421,
    "length": 69,
    "time": 131467.130719,
    "actor_loss": -66.61617279052734,
    "critic_loss": 2.361738920211792,
    "ent_coef": 0.0820188969373703,
    "learning_rate": 0.001
  },
  {
    "episode": 8840,
    "reward": 83.387896,
    "length": 76,
    "time": 131482.943917,
    "actor_loss": -67.69906616210938,
    "critic_loss": 80.60350799560547,
    "ent_coef": 0.07938127219676971,
    "learning_rate": 0.001
  },
  {
    "episode": 8841,
    "reward": 83.510144,
    "length": 77,
    "time": 131497.619286,
    "actor_loss": -63.738670349121094,
    "critic_loss": 9.141547203063965,
    "ent_coef": 0.07440724223852158,
    "learning_rate": 0.001
  },
  {
    "episode": 8842,
    "reward": 89.289028,
    "length": 65,
    "time": 131509.305071,
    "actor_loss": -78.43527221679688,
    "critic_loss": 4.417183876037598,
    "ent_coef": 0.07331333309412003,
    "learning_rate": 0.001
  },
  {
    "episode": 8843,
    "reward": 88.880432,
    "length": 66,
    "time": 131522.132983,
    "actor_loss": -66.50808715820312,
    "critic_loss": 4.320624351501465,
    "ent_coef": 0.07662145048379898,
    "learning_rate": 0.001
  },
  {
    "episode": 8844,
    "reward": 87.241045,
    "length": 69,
    "time": 131534.102314,
    "actor_loss": -69.33311462402344,
    "critic_loss": 5.037590980529785,
    "ent_coef": 0.07585979998111725,
    "learning_rate": 0.001
  },
  {
    "episode": 8845,
    "reward": 89.752659,
    "length": 65,
    "time": 131547.458545,
    "actor_loss": -70.70037078857422,
    "critic_loss": 5.658604621887207,
    "ent_coef": 0.07501839846372604,
    "learning_rate": 0.001
  },
  {
    "episode": 8846,
    "reward": 89.693997,
    "length": 65,
    "time": 131559.44142,
    "actor_loss": -70.16142272949219,
    "critic_loss": 3.1503543853759766,
    "ent_coef": 0.0787569135427475,
    "learning_rate": 0.001
  },
  {
    "episode": 8847,
    "reward": 86.814384,
    "length": 70,
    "time": 131571.735913,
    "actor_loss": -68.64828491210938,
    "critic_loss": 6.559409141540527,
    "ent_coef": 0.07947482168674469,
    "learning_rate": 0.001
  },
  {
    "episode": 8848,
    "reward": 86.043859,
    "length": 72,
    "time": 131584.488037,
    "actor_loss": -60.11384582519531,
    "critic_loss": 157.13397216796875,
    "ent_coef": 0.07508483529090881,
    "learning_rate": 0.001
  },
  {
    "episode": 8849,
    "reward": 88.884282,
    "length": 68,
    "time": 131596.664607,
    "actor_loss": -67.09414672851562,
    "critic_loss": 4.682253360748291,
    "ent_coef": 0.07324756681919098,
    "learning_rate": 0.001
  },
  {
    "episode": 8850,
    "reward": 87.297106,
    "length": 69,
    "time": 131610.46395,
    "actor_loss": -70.44406127929688,
    "critic_loss": 156.28526306152344,
    "ent_coef": 0.07541484385728836,
    "learning_rate": 0.001
  },
  {
    "episode": 8851,
    "reward": 89.158102,
    "length": 65,
    "time": 131622.89077,
    "actor_loss": -60.531192779541016,
    "critic_loss": 4.2577009201049805,
    "ent_coef": 0.07768581807613373,
    "learning_rate": 0.001
  },
  {
    "episode": 8852,
    "reward": 86.697791,
    "length": 70,
    "time": 131635.084973,
    "actor_loss": -73.21082305908203,
    "critic_loss": 23.86802864074707,
    "ent_coef": 0.0753118097782135,
    "learning_rate": 0.001
  },
  {
    "episode": 8853,
    "reward": 85.304107,
    "length": 73,
    "time": 131649.971788,
    "actor_loss": -65.16928100585938,
    "critic_loss": 4.130041599273682,
    "ent_coef": 0.07197420299053192,
    "learning_rate": 0.001
  },
  {
    "episode": 8854,
    "reward": 89.263021,
    "length": 65,
    "time": 131662.903564,
    "actor_loss": -67.8402328491211,
    "critic_loss": 4.699100494384766,
    "ent_coef": 0.07428394258022308,
    "learning_rate": 0.001
  },
  {
    "episode": 8855,
    "reward": 86.991275,
    "length": 71,
    "time": 131676.654572,
    "actor_loss": -63.987152099609375,
    "critic_loss": 6.130883693695068,
    "ent_coef": 0.07390137761831284,
    "learning_rate": 0.001
  },
  {
    "episode": 8856,
    "reward": 87.601802,
    "length": 70,
    "time": 131690.695904,
    "actor_loss": -65.35791015625,
    "critic_loss": 2.1889383792877197,
    "ent_coef": 0.07319024205207825,
    "learning_rate": 0.001
  },
  {
    "episode": 8857,
    "reward": 88.650132,
    "length": 67,
    "time": 131705.204173,
    "actor_loss": -72.19310760498047,
    "critic_loss": 31.965604782104492,
    "ent_coef": 0.07341708987951279,
    "learning_rate": 0.001
  },
  {
    "episode": 8858,
    "reward": 87.919662,
    "length": 68,
    "time": 131718.85923,
    "actor_loss": -67.07807159423828,
    "critic_loss": 2.1755974292755127,
    "ent_coef": 0.07163303345441818,
    "learning_rate": 0.001
  },
  {
    "episode": 8859,
    "reward": 90.27752,
    "length": 64,
    "time": 131732.487769,
    "actor_loss": -61.66307067871094,
    "critic_loss": 3.162508487701416,
    "ent_coef": 0.07156362384557724,
    "learning_rate": 0.001
  },
  {
    "episode": 8860,
    "reward": 88.0329,
    "length": 67,
    "time": 131744.672518,
    "actor_loss": -64.83805847167969,
    "critic_loss": 143.62298583984375,
    "ent_coef": 0.0714084729552269,
    "learning_rate": 0.001
  },
  {
    "episode": 8861,
    "reward": 87.739989,
    "length": 68,
    "time": 131759.542398,
    "actor_loss": -69.45623779296875,
    "critic_loss": 7.087656021118164,
    "ent_coef": 0.07122108340263367,
    "learning_rate": 0.001
  },
  {
    "episode": 8862,
    "reward": 87.321537,
    "length": 70,
    "time": 131776.197287,
    "actor_loss": -67.51260375976562,
    "critic_loss": 24.593143463134766,
    "ent_coef": 0.06866782903671265,
    "learning_rate": 0.001
  },
  {
    "episode": 8863,
    "reward": 86.237374,
    "length": 71,
    "time": 131789.657197,
    "actor_loss": -72.4052963256836,
    "critic_loss": 3.459684371948242,
    "ent_coef": 0.06653790175914764,
    "learning_rate": 0.001
  },
  {
    "episode": 8864,
    "reward": 84.317487,
    "length": 76,
    "time": 131802.539597,
    "actor_loss": -66.59100341796875,
    "critic_loss": 57.67340850830078,
    "ent_coef": 0.06409478932619095,
    "learning_rate": 0.001
  },
  {
    "episode": 8865,
    "reward": 86.78742,
    "length": 70,
    "time": 131814.994064,
    "actor_loss": -67.91729736328125,
    "critic_loss": 8.786918640136719,
    "ent_coef": 0.0648927167057991,
    "learning_rate": 0.001
  },
  {
    "episode": 8866,
    "reward": 87.670004,
    "length": 70,
    "time": 131828.309192,
    "actor_loss": -63.65592956542969,
    "critic_loss": 35.78736877441406,
    "ent_coef": 0.06621348112821579,
    "learning_rate": 0.001
  },
  {
    "episode": 8867,
    "reward": 86.393538,
    "length": 75,
    "time": 131842.425474,
    "actor_loss": -67.87141418457031,
    "critic_loss": 2.8766069412231445,
    "ent_coef": 0.06724150478839874,
    "learning_rate": 0.001
  },
  {
    "episode": 8868,
    "reward": 87.217443,
    "length": 69,
    "time": 131857.087324,
    "actor_loss": -65.89545440673828,
    "critic_loss": 17.156721115112305,
    "ent_coef": 0.06649842858314514,
    "learning_rate": 0.001
  },
  {
    "episode": 8869,
    "reward": 87.88519,
    "length": 68,
    "time": 131869.926459,
    "actor_loss": -72.34649658203125,
    "critic_loss": 4.479475021362305,
    "ent_coef": 0.06725027412176132,
    "learning_rate": 0.001
  },
  {
    "episode": 8870,
    "reward": 88.451582,
    "length": 67,
    "time": 131882.514718,
    "actor_loss": -65.59638214111328,
    "critic_loss": 6.1262617111206055,
    "ent_coef": 0.06982780992984772,
    "learning_rate": 0.001
  },
  {
    "episode": 8871,
    "reward": 90.053454,
    "length": 64,
    "time": 131895.738467,
    "actor_loss": -59.165565490722656,
    "critic_loss": 3.354808807373047,
    "ent_coef": 0.07251423597335815,
    "learning_rate": 0.001
  },
  {
    "episode": 8872,
    "reward": 89.431864,
    "length": 67,
    "time": 131910.618512,
    "actor_loss": -71.57795715332031,
    "critic_loss": 142.9886474609375,
    "ent_coef": 0.07927916198968887,
    "learning_rate": 0.001
  },
  {
    "episode": 8873,
    "reward": 90.393557,
    "length": 62,
    "time": 131921.755496,
    "actor_loss": -64.51734924316406,
    "critic_loss": 4.193885326385498,
    "ent_coef": 0.08374909311532974,
    "learning_rate": 0.001
  },
  {
    "episode": 8874,
    "reward": 89.166242,
    "length": 67,
    "time": 131933.518288,
    "actor_loss": -63.996299743652344,
    "critic_loss": 8.299577713012695,
    "ent_coef": 0.08307730406522751,
    "learning_rate": 0.001
  },
  {
    "episode": 8875,
    "reward": 84.906227,
    "length": 73,
    "time": 131946.335965,
    "actor_loss": -62.32164001464844,
    "critic_loss": 16.14492416381836,
    "ent_coef": 0.07732557505369186,
    "learning_rate": 0.001
  },
  {
    "episode": 8876,
    "reward": 88.23447,
    "length": 67,
    "time": 131958.245036,
    "actor_loss": -67.36483001708984,
    "critic_loss": 3.752187967300415,
    "ent_coef": 0.07786265760660172,
    "learning_rate": 0.001
  },
  {
    "episode": 8877,
    "reward": 88.780434,
    "length": 67,
    "time": 131971.082028,
    "actor_loss": -65.79205322265625,
    "critic_loss": 56.128028869628906,
    "ent_coef": 0.07774510979652405,
    "learning_rate": 0.001
  },
  {
    "episode": 8878,
    "reward": 89.40207,
    "length": 66,
    "time": 131983.722114,
    "actor_loss": -68.89704895019531,
    "critic_loss": 4.871003150939941,
    "ent_coef": 0.07936550676822662,
    "learning_rate": 0.001
  },
  {
    "episode": 8879,
    "reward": 89.390406,
    "length": 65,
    "time": 131996.392998,
    "actor_loss": -64.56587219238281,
    "critic_loss": 4.4489898681640625,
    "ent_coef": 0.07950611412525177,
    "learning_rate": 0.001
  },
  {
    "episode": 8880,
    "reward": 89.110462,
    "length": 66,
    "time": 132009.605463,
    "actor_loss": -65.33794403076172,
    "critic_loss": 41.96893310546875,
    "ent_coef": 0.07723799347877502,
    "learning_rate": 0.001
  },
  {
    "episode": 8881,
    "reward": 89.99818,
    "length": 63,
    "time": 132023.296299,
    "actor_loss": -69.62373352050781,
    "critic_loss": 134.37478637695312,
    "ent_coef": 0.07956711202859879,
    "learning_rate": 0.001
  },
  {
    "episode": 8882,
    "reward": 88.418842,
    "length": 67,
    "time": 132035.14918,
    "actor_loss": -71.78564453125,
    "critic_loss": 3.026095390319824,
    "ent_coef": 0.08580274879932404,
    "learning_rate": 0.001
  },
  {
    "episode": 8883,
    "reward": 87.994557,
    "length": 66,
    "time": 132046.716404,
    "actor_loss": -61.80944061279297,
    "critic_loss": 5.990702152252197,
    "ent_coef": 0.08752001076936722,
    "learning_rate": 0.001
  },
  {
    "episode": 8884,
    "reward": 86.546947,
    "length": 70,
    "time": 132060.016067,
    "actor_loss": -66.46551513671875,
    "critic_loss": 3.094538450241089,
    "ent_coef": 0.08611562103033066,
    "learning_rate": 0.001
  },
  {
    "episode": 8885,
    "reward": 88.071098,
    "length": 68,
    "time": 132074.047925,
    "actor_loss": -64.86836242675781,
    "critic_loss": 3.2879695892333984,
    "ent_coef": 0.08426732569932938,
    "learning_rate": 0.001
  },
  {
    "episode": 8886,
    "reward": 87.197565,
    "length": 69,
    "time": 132088.156733,
    "actor_loss": -64.1061019897461,
    "critic_loss": 3.8762381076812744,
    "ent_coef": 0.08306682854890823,
    "learning_rate": 0.001
  },
  {
    "episode": 8887,
    "reward": 83.953502,
    "length": 76,
    "time": 132104.130254,
    "actor_loss": -63.052886962890625,
    "critic_loss": 2.8900880813598633,
    "ent_coef": 0.08422771841287613,
    "learning_rate": 0.001
  },
  {
    "episode": 8888,
    "reward": 87.601444,
    "length": 70,
    "time": 132118.275847,
    "actor_loss": -67.57832336425781,
    "critic_loss": 10.482975006103516,
    "ent_coef": 0.0836881548166275,
    "learning_rate": 0.001
  },
  {
    "episode": 8889,
    "reward": 87.194493,
    "length": 70,
    "time": 132133.117495,
    "actor_loss": -66.90528106689453,
    "critic_loss": 4.8513383865356445,
    "ent_coef": 0.07975754141807556,
    "learning_rate": 0.001
  },
  {
    "episode": 8890,
    "reward": 88.442418,
    "length": 66,
    "time": 132144.774622,
    "actor_loss": -67.62205505371094,
    "critic_loss": 3.559906005859375,
    "ent_coef": 0.07669320702552795,
    "learning_rate": 0.001
  },
  {
    "episode": 8891,
    "reward": 88.180103,
    "length": 67,
    "time": 132157.278761,
    "actor_loss": -67.25096893310547,
    "critic_loss": 3.9063942432403564,
    "ent_coef": 0.07655856758356094,
    "learning_rate": 0.001
  },
  {
    "episode": 8892,
    "reward": 86.926578,
    "length": 69,
    "time": 132169.251308,
    "actor_loss": -72.0992431640625,
    "critic_loss": 7.5067620277404785,
    "ent_coef": 0.07613404840230942,
    "learning_rate": 0.001
  },
  {
    "episode": 8893,
    "reward": 86.24685,
    "length": 70,
    "time": 132181.362419,
    "actor_loss": -62.263519287109375,
    "critic_loss": 3.558588981628418,
    "ent_coef": 0.07335634529590607,
    "learning_rate": 0.001
  },
  {
    "episode": 8894,
    "reward": 89.824967,
    "length": 64,
    "time": 132195.329246,
    "actor_loss": -61.98703384399414,
    "critic_loss": 2.5629396438598633,
    "ent_coef": 0.0711318776011467,
    "learning_rate": 0.001
  },
  {
    "episode": 8895,
    "reward": 84.285976,
    "length": 73,
    "time": 132208.5043,
    "actor_loss": -66.50354766845703,
    "critic_loss": 10.78801155090332,
    "ent_coef": 0.06830476969480515,
    "learning_rate": 0.001
  },
  {
    "episode": 8896,
    "reward": 82.617101,
    "length": 80,
    "time": 132223.231775,
    "actor_loss": -68.306884765625,
    "critic_loss": 8.14314079284668,
    "ent_coef": 0.0635230615735054,
    "learning_rate": 0.001
  },
  {
    "episode": 8897,
    "reward": 88.066039,
    "length": 69,
    "time": 132238.069647,
    "actor_loss": -63.85594940185547,
    "critic_loss": 6.296197891235352,
    "ent_coef": 0.06254024803638458,
    "learning_rate": 0.001
  },
  {
    "episode": 8898,
    "reward": 84.503788,
    "length": 74,
    "time": 132250.696832,
    "actor_loss": -61.521995544433594,
    "critic_loss": 7.783418655395508,
    "ent_coef": 0.061575885862112045,
    "learning_rate": 0.001
  },
  {
    "episode": 8899,
    "reward": 88.86798,
    "length": 67,
    "time": 132263.459133,
    "actor_loss": -69.12811279296875,
    "critic_loss": 2.273974895477295,
    "ent_coef": 0.0628645122051239,
    "learning_rate": 0.001
  },
  {
    "episode": 8900,
    "reward": 89.069868,
    "length": 65,
    "time": 132275.156097,
    "actor_loss": -62.617530822753906,
    "critic_loss": 78.93464660644531,
    "ent_coef": 0.06628802418708801,
    "learning_rate": 0.001
  },
  {
    "episode": 8901,
    "reward": 86.673587,
    "length": 72,
    "time": 132289.770708,
    "actor_loss": -67.2777099609375,
    "critic_loss": 3.1301655769348145,
    "ent_coef": 0.06753077358007431,
    "learning_rate": 0.001
  },
  {
    "episode": 8902,
    "reward": 88.982142,
    "length": 65,
    "time": 132302.171473,
    "actor_loss": -69.61955261230469,
    "critic_loss": 2.7054290771484375,
    "ent_coef": 0.06635120511054993,
    "learning_rate": 0.001
  },
  {
    "episode": 8903,
    "reward": 86.908673,
    "length": 73,
    "time": 132315.823452,
    "actor_loss": -62.56165313720703,
    "critic_loss": 7.5504560470581055,
    "ent_coef": 0.06676951795816422,
    "learning_rate": 0.001
  },
  {
    "episode": 8904,
    "reward": 88.335851,
    "length": 67,
    "time": 132330.711687,
    "actor_loss": -70.14688873291016,
    "critic_loss": 42.39931869506836,
    "ent_coef": 0.06538992375135422,
    "learning_rate": 0.001
  },
  {
    "episode": 8905,
    "reward": 90.074383,
    "length": 65,
    "time": 132345.682457,
    "actor_loss": -71.40751647949219,
    "critic_loss": 10.690217971801758,
    "ent_coef": 0.06427938491106033,
    "learning_rate": 0.001
  },
  {
    "episode": 8906,
    "reward": 85.201389,
    "length": 74,
    "time": 132359.386096,
    "actor_loss": -70.11903381347656,
    "critic_loss": 13.857870101928711,
    "ent_coef": 0.06268937885761261,
    "learning_rate": 0.001
  },
  {
    "episode": 8907,
    "reward": 87.25685,
    "length": 70,
    "time": 132371.869644,
    "actor_loss": -69.17901611328125,
    "critic_loss": 3.132136344909668,
    "ent_coef": 0.06311109662055969,
    "learning_rate": 0.001
  },
  {
    "episode": 8908,
    "reward": 90.15664,
    "length": 63,
    "time": 132384.352607,
    "actor_loss": -72.39869689941406,
    "critic_loss": 6.490109443664551,
    "ent_coef": 0.06642749905586243,
    "learning_rate": 0.001
  },
  {
    "episode": 8909,
    "reward": 91.229371,
    "length": 62,
    "time": 132395.357407,
    "actor_loss": -69.0510482788086,
    "critic_loss": 41.83588409423828,
    "ent_coef": 0.07070904225111008,
    "learning_rate": 0.001
  },
  {
    "episode": 8910,
    "reward": 89.086491,
    "length": 66,
    "time": 132407.195844,
    "actor_loss": -67.63648986816406,
    "critic_loss": 6.704433441162109,
    "ent_coef": 0.06989876925945282,
    "learning_rate": 0.001
  },
  {
    "episode": 8911,
    "reward": 89.118072,
    "length": 68,
    "time": 132421.24657,
    "actor_loss": -64.80146789550781,
    "critic_loss": 4.777524948120117,
    "ent_coef": 0.06994593143463135,
    "learning_rate": 0.001
  },
  {
    "episode": 8912,
    "reward": 82.421508,
    "length": 76,
    "time": 132434.219847,
    "actor_loss": -76.15704345703125,
    "critic_loss": 44.001041412353516,
    "ent_coef": 0.06768465042114258,
    "learning_rate": 0.001
  },
  {
    "episode": 8913,
    "reward": 85.125175,
    "length": 72,
    "time": 132446.71525,
    "actor_loss": -65.06500244140625,
    "critic_loss": 41.63670349121094,
    "ent_coef": 0.06491211801767349,
    "learning_rate": 0.001
  },
  {
    "episode": 8914,
    "reward": 87.874328,
    "length": 69,
    "time": 132460.071959,
    "actor_loss": -64.85113525390625,
    "critic_loss": 4.912030220031738,
    "ent_coef": 0.06439799070358276,
    "learning_rate": 0.001
  },
  {
    "episode": 8915,
    "reward": 89.823473,
    "length": 64,
    "time": 132471.656179,
    "actor_loss": -67.52684020996094,
    "critic_loss": 9.885170936584473,
    "ent_coef": 0.06723110377788544,
    "learning_rate": 0.001
  },
  {
    "episode": 8916,
    "reward": 89.356587,
    "length": 65,
    "time": 132486.564626,
    "actor_loss": -73.2088623046875,
    "critic_loss": 4.984210014343262,
    "ent_coef": 0.0736914575099945,
    "learning_rate": 0.001
  },
  {
    "episode": 8917,
    "reward": 89.791859,
    "length": 64,
    "time": 132499.741788,
    "actor_loss": -68.77581024169922,
    "critic_loss": 35.104766845703125,
    "ent_coef": 0.07902984321117401,
    "learning_rate": 0.001
  },
  {
    "episode": 8918,
    "reward": 90.657197,
    "length": 61,
    "time": 132511.728924,
    "actor_loss": -72.3536605834961,
    "critic_loss": 12.160989761352539,
    "ent_coef": 0.08384466916322708,
    "learning_rate": 0.001
  },
  {
    "episode": 8919,
    "reward": 90.41833,
    "length": 62,
    "time": 132522.906278,
    "actor_loss": -65.21067810058594,
    "critic_loss": 11.710524559020996,
    "ent_coef": 0.08957545459270477,
    "learning_rate": 0.001
  },
  {
    "episode": 8920,
    "reward": 88.865335,
    "length": 66,
    "time": 132534.627537,
    "actor_loss": -65.43894958496094,
    "critic_loss": 40.598262786865234,
    "ent_coef": 0.08906631171703339,
    "learning_rate": 0.001
  },
  {
    "episode": 8921,
    "reward": 87.583794,
    "length": 68,
    "time": 132549.03619,
    "actor_loss": -67.01331329345703,
    "critic_loss": 41.92772674560547,
    "ent_coef": 0.08660229295492172,
    "learning_rate": 0.001
  },
  {
    "episode": 8922,
    "reward": 89.141054,
    "length": 66,
    "time": 132563.059295,
    "actor_loss": -68.65164947509766,
    "critic_loss": 12.749658584594727,
    "ent_coef": 0.08568965643644333,
    "learning_rate": 0.001
  },
  {
    "episode": 8923,
    "reward": 87.169701,
    "length": 68,
    "time": 132577.094961,
    "actor_loss": -69.27242279052734,
    "critic_loss": 140.85714721679688,
    "ent_coef": 0.08595076203346252,
    "learning_rate": 0.001
  },
  {
    "episode": 8924,
    "reward": 86.197535,
    "length": 72,
    "time": 132592.354724,
    "actor_loss": -68.98985290527344,
    "critic_loss": 26.81682777404785,
    "ent_coef": 0.08389682322740555,
    "learning_rate": 0.001
  },
  {
    "episode": 8925,
    "reward": 85.889293,
    "length": 70,
    "time": 132607.278677,
    "actor_loss": -67.92508697509766,
    "critic_loss": 5.506540298461914,
    "ent_coef": 0.079817995429039,
    "learning_rate": 0.001
  },
  {
    "episode": 8926,
    "reward": 87.685489,
    "length": 67,
    "time": 132620.798234,
    "actor_loss": -69.94993591308594,
    "critic_loss": 47.549781799316406,
    "ent_coef": 0.07863799482584,
    "learning_rate": 0.001
  },
  {
    "episode": 8927,
    "reward": 90.61328,
    "length": 63,
    "time": 132633.649858,
    "actor_loss": -70.34640502929688,
    "critic_loss": 29.690128326416016,
    "ent_coef": 0.07888947427272797,
    "learning_rate": 0.001
  },
  {
    "episode": 8928,
    "reward": 91.273542,
    "length": 61,
    "time": 132647.234715,
    "actor_loss": -70.7587661743164,
    "critic_loss": 2.6661722660064697,
    "ent_coef": 0.08103076368570328,
    "learning_rate": 0.001
  },
  {
    "episode": 8929,
    "reward": 90.744563,
    "length": 61,
    "time": 132658.93453,
    "actor_loss": -63.88440704345703,
    "critic_loss": 6.24331521987915,
    "ent_coef": 0.08586471527814865,
    "learning_rate": 0.001
  },
  {
    "episode": 8930,
    "reward": 87.765254,
    "length": 70,
    "time": 132671.506674,
    "actor_loss": -64.06224822998047,
    "critic_loss": 19.638364791870117,
    "ent_coef": 0.08541955053806305,
    "learning_rate": 0.001
  },
  {
    "episode": 8931,
    "reward": 89.716052,
    "length": 65,
    "time": 132686.592648,
    "actor_loss": -66.91825103759766,
    "critic_loss": 28.09808349609375,
    "ent_coef": 0.08250241726636887,
    "learning_rate": 0.001
  },
  {
    "episode": 8932,
    "reward": 85.726363,
    "length": 71,
    "time": 132699.359577,
    "actor_loss": -70.12994384765625,
    "critic_loss": 275.3473205566406,
    "ent_coef": 0.08050817996263504,
    "learning_rate": 0.001
  },
  {
    "episode": 8933,
    "reward": 89.202646,
    "length": 65,
    "time": 132710.930615,
    "actor_loss": -69.32681274414062,
    "critic_loss": 8.282880783081055,
    "ent_coef": 0.08232805132865906,
    "learning_rate": 0.001
  },
  {
    "episode": 8934,
    "reward": 89.774329,
    "length": 64,
    "time": 132722.71748,
    "actor_loss": -70.6397705078125,
    "critic_loss": 3.2095766067504883,
    "ent_coef": 0.08085361868143082,
    "learning_rate": 0.001
  },
  {
    "episode": 8935,
    "reward": 87.195126,
    "length": 72,
    "time": 132736.398232,
    "actor_loss": -69.09742736816406,
    "critic_loss": 3.693692684173584,
    "ent_coef": 0.07925306260585785,
    "learning_rate": 0.001
  },
  {
    "episode": 8936,
    "reward": 77.399347,
    "length": 161,
    "time": 132761.730226,
    "actor_loss": -69.77584838867188,
    "critic_loss": 3.198578357696533,
    "ent_coef": 0.0760217159986496,
    "learning_rate": 0.001
  },
  {
    "episode": 8937,
    "reward": 86.554793,
    "length": 70,
    "time": 132774.762952,
    "actor_loss": -71.53770446777344,
    "critic_loss": 8.333162307739258,
    "ent_coef": 0.07175981998443604,
    "learning_rate": 0.001
  },
  {
    "episode": 8938,
    "reward": 89.412172,
    "length": 64,
    "time": 132789.55154,
    "actor_loss": -69.57131958007812,
    "critic_loss": 1.8396245241165161,
    "ent_coef": 0.07100838422775269,
    "learning_rate": 0.001
  },
  {
    "episode": 8939,
    "reward": 87.140726,
    "length": 69,
    "time": 132803.753707,
    "actor_loss": -67.75071716308594,
    "critic_loss": 8.809476852416992,
    "ent_coef": 0.0706702470779419,
    "learning_rate": 0.001
  },
  {
    "episode": 8940,
    "reward": 87.70801,
    "length": 66,
    "time": 132817.058314,
    "actor_loss": -63.70338439941406,
    "critic_loss": 33.03042984008789,
    "ent_coef": 0.06923756003379822,
    "learning_rate": 0.001
  },
  {
    "episode": 8941,
    "reward": 88.486823,
    "length": 65,
    "time": 132830.260281,
    "actor_loss": -66.24774169921875,
    "critic_loss": 61.06317138671875,
    "ent_coef": 0.06929811835289001,
    "learning_rate": 0.001
  },
  {
    "episode": 8942,
    "reward": 88.110424,
    "length": 67,
    "time": 132844.246479,
    "actor_loss": -73.04603576660156,
    "critic_loss": 3.782254695892334,
    "ent_coef": 0.07081037759780884,
    "learning_rate": 0.001
  },
  {
    "episode": 8943,
    "reward": 88.09997,
    "length": 67,
    "time": 132856.318745,
    "actor_loss": -63.39901351928711,
    "critic_loss": 5.411916732788086,
    "ent_coef": 0.0693376362323761,
    "learning_rate": 0.001
  },
  {
    "episode": 8944,
    "reward": 88.814413,
    "length": 64,
    "time": 132870.51613,
    "actor_loss": -69.21194458007812,
    "critic_loss": 8.368301391601562,
    "ent_coef": 0.07121521234512329,
    "learning_rate": 0.001
  },
  {
    "episode": 8945,
    "reward": 89.084148,
    "length": 65,
    "time": 132883.229277,
    "actor_loss": -69.28579711914062,
    "critic_loss": 4.5105743408203125,
    "ent_coef": 0.07206421345472336,
    "learning_rate": 0.001
  },
  {
    "episode": 8946,
    "reward": 86.923081,
    "length": 71,
    "time": 132895.641131,
    "actor_loss": -67.21408081054688,
    "critic_loss": 8.04425048828125,
    "ent_coef": 0.07174023240804672,
    "learning_rate": 0.001
  },
  {
    "episode": 8947,
    "reward": 88.461704,
    "length": 65,
    "time": 132907.189812,
    "actor_loss": -72.4373779296875,
    "critic_loss": 1.974324345588684,
    "ent_coef": 0.07171380519866943,
    "learning_rate": 0.001
  },
  {
    "episode": 8948,
    "reward": 89.329464,
    "length": 66,
    "time": 132921.732568,
    "actor_loss": -68.12863159179688,
    "critic_loss": 2.718618869781494,
    "ent_coef": 0.07521916925907135,
    "learning_rate": 0.001
  },
  {
    "episode": 8949,
    "reward": 88.622677,
    "length": 66,
    "time": 132933.505702,
    "actor_loss": -65.73490142822266,
    "critic_loss": 2.291475772857666,
    "ent_coef": 0.07870660722255707,
    "learning_rate": 0.001
  },
  {
    "episode": 8950,
    "reward": 83.975382,
    "length": 72,
    "time": 132945.833502,
    "actor_loss": -70.88179016113281,
    "critic_loss": 18.289018630981445,
    "ent_coef": 0.07688822597265244,
    "learning_rate": 0.001
  },
  {
    "episode": 8951,
    "reward": 87.826334,
    "length": 67,
    "time": 132959.424371,
    "actor_loss": -71.26979064941406,
    "critic_loss": 3.187971353530884,
    "ent_coef": 0.07504389435052872,
    "learning_rate": 0.001
  },
  {
    "episode": 8952,
    "reward": 89.538724,
    "length": 64,
    "time": 132973.943389,
    "actor_loss": -71.96551513671875,
    "critic_loss": 14.813811302185059,
    "ent_coef": 0.07594689726829529,
    "learning_rate": 0.001
  },
  {
    "episode": 8953,
    "reward": 91.099733,
    "length": 61,
    "time": 132986.318678,
    "actor_loss": -63.13115310668945,
    "critic_loss": 20.873001098632812,
    "ent_coef": 0.08020731806755066,
    "learning_rate": 0.001
  },
  {
    "episode": 8954,
    "reward": 88.519258,
    "length": 66,
    "time": 132998.859049,
    "actor_loss": -66.16109466552734,
    "critic_loss": 1.9495079517364502,
    "ent_coef": 0.0832049772143364,
    "learning_rate": 0.001
  },
  {
    "episode": 8955,
    "reward": 88.148337,
    "length": 66,
    "time": 133010.39513,
    "actor_loss": -62.58774185180664,
    "critic_loss": 373.5688171386719,
    "ent_coef": 0.08437969535589218,
    "learning_rate": 0.001
  },
  {
    "episode": 8956,
    "reward": 89.463584,
    "length": 64,
    "time": 133022.260643,
    "actor_loss": -70.10551452636719,
    "critic_loss": 11.744754791259766,
    "ent_coef": 0.0864352285861969,
    "learning_rate": 0.001
  },
  {
    "episode": 8957,
    "reward": 88.687724,
    "length": 65,
    "time": 133034.420698,
    "actor_loss": -71.02702331542969,
    "critic_loss": 64.957275390625,
    "ent_coef": 0.08457505702972412,
    "learning_rate": 0.001
  },
  {
    "episode": 8958,
    "reward": 88.274628,
    "length": 68,
    "time": 133046.280913,
    "actor_loss": -70.34786987304688,
    "critic_loss": 53.18743133544922,
    "ent_coef": 0.08183015137910843,
    "learning_rate": 0.001
  },
  {
    "episode": 8959,
    "reward": 88.380282,
    "length": 66,
    "time": 133057.79064,
    "actor_loss": -69.44284057617188,
    "critic_loss": 13.606107711791992,
    "ent_coef": 0.0802517756819725,
    "learning_rate": 0.001
  },
  {
    "episode": 8960,
    "reward": 89.090079,
    "length": 65,
    "time": 133069.353064,
    "actor_loss": -63.57234191894531,
    "critic_loss": 4.213883876800537,
    "ent_coef": 0.07736575603485107,
    "learning_rate": 0.001
  },
  {
    "episode": 8961,
    "reward": 88.473351,
    "length": 67,
    "time": 133082.557741,
    "actor_loss": -62.416812896728516,
    "critic_loss": 3.4395766258239746,
    "ent_coef": 0.07698804885149002,
    "learning_rate": 0.001
  },
  {
    "episode": 8962,
    "reward": 88.769824,
    "length": 65,
    "time": 133095.506139,
    "actor_loss": -68.80876159667969,
    "critic_loss": 15.66305923461914,
    "ent_coef": 0.07385121285915375,
    "learning_rate": 0.001
  },
  {
    "episode": 8963,
    "reward": 89.786971,
    "length": 64,
    "time": 133107.647594,
    "actor_loss": -67.60838317871094,
    "critic_loss": 4.580303192138672,
    "ent_coef": 0.07340511679649353,
    "learning_rate": 0.001
  },
  {
    "episode": 8964,
    "reward": 90.038805,
    "length": 63,
    "time": 133119.352114,
    "actor_loss": -70.74171447753906,
    "critic_loss": 4.189463138580322,
    "ent_coef": 0.07612758129835129,
    "learning_rate": 0.001
  },
  {
    "episode": 8965,
    "reward": 87.708616,
    "length": 68,
    "time": 133134.93635,
    "actor_loss": -65.41268157958984,
    "critic_loss": 14.068401336669922,
    "ent_coef": 0.07754255831241608,
    "learning_rate": 0.001
  },
  {
    "episode": 8966,
    "reward": 90.789896,
    "length": 62,
    "time": 133146.203193,
    "actor_loss": -68.87422180175781,
    "critic_loss": 4.593100547790527,
    "ent_coef": 0.0803118571639061,
    "learning_rate": 0.001
  },
  {
    "episode": 8967,
    "reward": 89.655195,
    "length": 63,
    "time": 133157.458977,
    "actor_loss": -68.9813461303711,
    "critic_loss": 59.16054916381836,
    "ent_coef": 0.08271355926990509,
    "learning_rate": 0.001
  },
  {
    "episode": 8968,
    "reward": 83.400702,
    "length": 74,
    "time": 133173.042629,
    "actor_loss": -69.26597595214844,
    "critic_loss": 11.154123306274414,
    "ent_coef": 0.07769393175840378,
    "learning_rate": 0.001
  },
  {
    "episode": 8969,
    "reward": 92.177589,
    "length": 60,
    "time": 133184.561227,
    "actor_loss": -69.1002197265625,
    "critic_loss": 7.267892837524414,
    "ent_coef": 0.07863818109035492,
    "learning_rate": 0.001
  },
  {
    "episode": 8970,
    "reward": 89.578541,
    "length": 65,
    "time": 133197.658431,
    "actor_loss": -67.18729400634766,
    "critic_loss": 3.7174105644226074,
    "ent_coef": 0.07803276181221008,
    "learning_rate": 0.001
  },
  {
    "episode": 8971,
    "reward": 89.318764,
    "length": 65,
    "time": 133209.745258,
    "actor_loss": -68.32844543457031,
    "critic_loss": 5.050933361053467,
    "ent_coef": 0.07636931538581848,
    "learning_rate": 0.001
  },
  {
    "episode": 8972,
    "reward": 83.743065,
    "length": 73,
    "time": 133222.848758,
    "actor_loss": -65.3589859008789,
    "critic_loss": 12.114494323730469,
    "ent_coef": 0.07486817985773087,
    "learning_rate": 0.001
  },
  {
    "episode": 8973,
    "reward": 89.157061,
    "length": 66,
    "time": 133236.72237,
    "actor_loss": -67.20755004882812,
    "critic_loss": 94.10952758789062,
    "ent_coef": 0.07477764785289764,
    "learning_rate": 0.001
  },
  {
    "episode": 8974,
    "reward": 88.080007,
    "length": 66,
    "time": 133248.864479,
    "actor_loss": -70.76512145996094,
    "critic_loss": 2.9264094829559326,
    "ent_coef": 0.07347582280635834,
    "learning_rate": 0.001
  },
  {
    "episode": 8975,
    "reward": 88.898301,
    "length": 66,
    "time": 133260.641159,
    "actor_loss": -68.32691955566406,
    "critic_loss": 4.48989200592041,
    "ent_coef": 0.07105346769094467,
    "learning_rate": 0.001
  },
  {
    "episode": 8976,
    "reward": 87.838343,
    "length": 66,
    "time": 133272.420024,
    "actor_loss": -72.80741882324219,
    "critic_loss": 5.345629692077637,
    "ent_coef": 0.06951406598091125,
    "learning_rate": 0.001
  },
  {
    "episode": 8977,
    "reward": 89.004497,
    "length": 64,
    "time": 133286.038989,
    "actor_loss": -68.99930572509766,
    "critic_loss": 3.9026401042938232,
    "ent_coef": 0.06849101185798645,
    "learning_rate": 0.001
  },
  {
    "episode": 8978,
    "reward": 88.01338,
    "length": 67,
    "time": 133297.690947,
    "actor_loss": -71.47647094726562,
    "critic_loss": 3.6280391216278076,
    "ent_coef": 0.06844956427812576,
    "learning_rate": 0.001
  },
  {
    "episode": 8979,
    "reward": 88.725823,
    "length": 67,
    "time": 133310.458034,
    "actor_loss": -67.06941223144531,
    "critic_loss": 3.7481932640075684,
    "ent_coef": 0.06733278930187225,
    "learning_rate": 0.001
  },
  {
    "episode": 8980,
    "reward": 90.119206,
    "length": 63,
    "time": 133321.633624,
    "actor_loss": -67.74172973632812,
    "critic_loss": 22.98474884033203,
    "ent_coef": 0.06885170191526413,
    "learning_rate": 0.001
  },
  {
    "episode": 8981,
    "reward": 88.646201,
    "length": 66,
    "time": 133335.983023,
    "actor_loss": -68.4825439453125,
    "critic_loss": 15.341585159301758,
    "ent_coef": 0.06892682611942291,
    "learning_rate": 0.001
  },
  {
    "episode": 8982,
    "reward": 88.701307,
    "length": 66,
    "time": 133348.199239,
    "actor_loss": -66.69429779052734,
    "critic_loss": 18.17214584350586,
    "ent_coef": 0.0703425481915474,
    "learning_rate": 0.001
  },
  {
    "episode": 8983,
    "reward": 87.735139,
    "length": 69,
    "time": 133361.259883,
    "actor_loss": -63.249267578125,
    "critic_loss": 3.3399176597595215,
    "ent_coef": 0.07028856873512268,
    "learning_rate": 0.001
  },
  {
    "episode": 8984,
    "reward": 85.991543,
    "length": 72,
    "time": 133373.941109,
    "actor_loss": -70.16888427734375,
    "critic_loss": 18.831687927246094,
    "ent_coef": 0.06829703599214554,
    "learning_rate": 0.001
  },
  {
    "episode": 8985,
    "reward": 90.56866,
    "length": 63,
    "time": 133385.738119,
    "actor_loss": -68.72488403320312,
    "critic_loss": 60.05033874511719,
    "ent_coef": 0.06833422183990479,
    "learning_rate": 0.001
  },
  {
    "episode": 8986,
    "reward": 89.798109,
    "length": 63,
    "time": 133398.057892,
    "actor_loss": -67.02729797363281,
    "critic_loss": 2.910822868347168,
    "ent_coef": 0.06820176541805267,
    "learning_rate": 0.001
  },
  {
    "episode": 8987,
    "reward": 87.784016,
    "length": 70,
    "time": 133410.237393,
    "actor_loss": -68.07925415039062,
    "critic_loss": 9.478885650634766,
    "ent_coef": 0.06743679940700531,
    "learning_rate": 0.001
  },
  {
    "episode": 8988,
    "reward": 90.130872,
    "length": 64,
    "time": 133422.097211,
    "actor_loss": -67.55189514160156,
    "critic_loss": 29.598388671875,
    "ent_coef": 0.06767112761735916,
    "learning_rate": 0.001
  },
  {
    "episode": 8989,
    "reward": 89.313674,
    "length": 66,
    "time": 133433.968742,
    "actor_loss": -70.69384765625,
    "critic_loss": 2.928973913192749,
    "ent_coef": 0.0709586814045906,
    "learning_rate": 0.001
  },
  {
    "episode": 8990,
    "reward": 88.458638,
    "length": 69,
    "time": 133447.969744,
    "actor_loss": -65.20513916015625,
    "critic_loss": 7.702803611755371,
    "ent_coef": 0.07219718396663666,
    "learning_rate": 0.001
  },
  {
    "episode": 8991,
    "reward": 87.04591,
    "length": 72,
    "time": 133462.727243,
    "actor_loss": -73.75338745117188,
    "critic_loss": 3.265613555908203,
    "ent_coef": 0.07066208869218826,
    "learning_rate": 0.001
  },
  {
    "episode": 8992,
    "reward": 87.676025,
    "length": 68,
    "time": 133477.01792,
    "actor_loss": -66.73985290527344,
    "critic_loss": 5.6057233810424805,
    "ent_coef": 0.06901098787784576,
    "learning_rate": 0.001
  },
  {
    "episode": 8993,
    "reward": 86.964978,
    "length": 70,
    "time": 133489.02113,
    "actor_loss": -71.35751342773438,
    "critic_loss": 3.363058567047119,
    "ent_coef": 0.0692024752497673,
    "learning_rate": 0.001
  },
  {
    "episode": 8994,
    "reward": 90.5091,
    "length": 62,
    "time": 133500.282617,
    "actor_loss": -63.12066650390625,
    "critic_loss": 31.808883666992188,
    "ent_coef": 0.06778489053249359,
    "learning_rate": 0.001
  },
  {
    "episode": 8995,
    "reward": 87.467416,
    "length": 67,
    "time": 133512.139284,
    "actor_loss": -68.16946411132812,
    "critic_loss": 3.0759952068328857,
    "ent_coef": 0.06704425066709518,
    "learning_rate": 0.001
  },
  {
    "episode": 8996,
    "reward": 87.990291,
    "length": 70,
    "time": 133525.248582,
    "actor_loss": -68.69902038574219,
    "critic_loss": 7.503106117248535,
    "ent_coef": 0.0677950382232666,
    "learning_rate": 0.001
  },
  {
    "episode": 8997,
    "reward": 89.553011,
    "length": 65,
    "time": 133539.660992,
    "actor_loss": -62.836883544921875,
    "critic_loss": 4.81281852722168,
    "ent_coef": 0.06827502697706223,
    "learning_rate": 0.001
  },
  {
    "episode": 8998,
    "reward": 75.482424,
    "length": 95,
    "time": 133557.332936,
    "actor_loss": -69.37507629394531,
    "critic_loss": 3.09639573097229,
    "ent_coef": 0.06498289853334427,
    "learning_rate": 0.001
  },
  {
    "episode": 8999,
    "reward": 84.456478,
    "length": 74,
    "time": 133573.812703,
    "actor_loss": -67.51263427734375,
    "critic_loss": 13.395163536071777,
    "ent_coef": 0.06524617969989777,
    "learning_rate": 0.001
  },
  {
    "episode": 9000,
    "reward": 84.750108,
    "length": 72,
    "time": 133587.081294,
    "actor_loss": -71.13720703125,
    "critic_loss": 4.415681838989258,
    "ent_coef": 0.06661181896924973,
    "learning_rate": 0.001
  },
  {
    "episode": 9001,
    "reward": 86.840731,
    "length": 72,
    "time": 133600.815166,
    "actor_loss": -65.39122009277344,
    "critic_loss": 9.889863014221191,
    "ent_coef": 0.06381474435329437,
    "learning_rate": 0.001
  },
  {
    "episode": 9002,
    "reward": 89.494791,
    "length": 66,
    "time": 133612.629029,
    "actor_loss": -71.10891723632812,
    "critic_loss": 2.5515592098236084,
    "ent_coef": 0.0657932460308075,
    "learning_rate": 0.001
  },
  {
    "episode": 9003,
    "reward": 90.269163,
    "length": 65,
    "time": 133626.689092,
    "actor_loss": -70.50935363769531,
    "critic_loss": 3.995953321456909,
    "ent_coef": 0.06934178620576859,
    "learning_rate": 0.001
  },
  {
    "episode": 9004,
    "reward": 87.405437,
    "length": 71,
    "time": 133642.381883,
    "actor_loss": -64.41964721679688,
    "critic_loss": 9.599288940429688,
    "ent_coef": 0.0700511559844017,
    "learning_rate": 0.001
  },
  {
    "episode": 9005,
    "reward": 90.013739,
    "length": 64,
    "time": 133656.593938,
    "actor_loss": -69.0108642578125,
    "critic_loss": 17.863685607910156,
    "ent_coef": 0.07303924113512039,
    "learning_rate": 0.001
  },
  {
    "episode": 9006,
    "reward": 88.203754,
    "length": 67,
    "time": 133670.159656,
    "actor_loss": -67.42106628417969,
    "critic_loss": 8.154827117919922,
    "ent_coef": 0.07615937292575836,
    "learning_rate": 0.001
  },
  {
    "episode": 9007,
    "reward": 89.954636,
    "length": 64,
    "time": 133681.711222,
    "actor_loss": -69.24320220947266,
    "critic_loss": 8.54234504699707,
    "ent_coef": 0.07769522815942764,
    "learning_rate": 0.001
  },
  {
    "episode": 9008,
    "reward": 88.250808,
    "length": 68,
    "time": 133693.560623,
    "actor_loss": -64.74964141845703,
    "critic_loss": 2.0006861686706543,
    "ent_coef": 0.07691941410303116,
    "learning_rate": 0.001
  },
  {
    "episode": 9009,
    "reward": 88.505632,
    "length": 66,
    "time": 133707.730316,
    "actor_loss": -71.25230407714844,
    "critic_loss": 2.8907790184020996,
    "ent_coef": 0.07427243888378143,
    "learning_rate": 0.001
  },
  {
    "episode": 9010,
    "reward": 88.272687,
    "length": 68,
    "time": 133720.933614,
    "actor_loss": -66.26277160644531,
    "critic_loss": 5.405427932739258,
    "ent_coef": 0.07201555371284485,
    "learning_rate": 0.001
  },
  {
    "episode": 9011,
    "reward": 84.768125,
    "length": 73,
    "time": 133733.976213,
    "actor_loss": -71.01851654052734,
    "critic_loss": 10.161426544189453,
    "ent_coef": 0.06655578315258026,
    "learning_rate": 0.001
  },
  {
    "episode": 9012,
    "reward": 84.261233,
    "length": 76,
    "time": 133750.905113,
    "actor_loss": -63.86598205566406,
    "critic_loss": 8.94245719909668,
    "ent_coef": 0.06321782618761063,
    "learning_rate": 0.001
  },
  {
    "episode": 9013,
    "reward": 88.541274,
    "length": 67,
    "time": 133763.700896,
    "actor_loss": -62.72768783569336,
    "critic_loss": 10.490026473999023,
    "ent_coef": 0.06406278163194656,
    "learning_rate": 0.001
  },
  {
    "episode": 9014,
    "reward": 88.697424,
    "length": 66,
    "time": 133779.003022,
    "actor_loss": -68.82180786132812,
    "critic_loss": 2.952791213989258,
    "ent_coef": 0.0667843222618103,
    "learning_rate": 0.001
  },
  {
    "episode": 9015,
    "reward": 89.079305,
    "length": 65,
    "time": 133791.688562,
    "actor_loss": -63.70746612548828,
    "critic_loss": 2.6799581050872803,
    "ent_coef": 0.06947749853134155,
    "learning_rate": 0.001
  },
  {
    "episode": 9016,
    "reward": 89.671073,
    "length": 64,
    "time": 133804.182758,
    "actor_loss": -66.54104614257812,
    "critic_loss": 10.590097427368164,
    "ent_coef": 0.07233541458845139,
    "learning_rate": 0.001
  },
  {
    "episode": 9017,
    "reward": 89.453361,
    "length": 65,
    "time": 133816.656609,
    "actor_loss": -70.39849853515625,
    "critic_loss": 4.528884410858154,
    "ent_coef": 0.07354406267404556,
    "learning_rate": 0.001
  },
  {
    "episode": 9018,
    "reward": 88.630929,
    "length": 67,
    "time": 133828.374553,
    "actor_loss": -68.74761199951172,
    "critic_loss": 2.505291700363159,
    "ent_coef": 0.0749591514468193,
    "learning_rate": 0.001
  },
  {
    "episode": 9019,
    "reward": 88.043537,
    "length": 69,
    "time": 133840.391966,
    "actor_loss": -70.70650482177734,
    "critic_loss": 3.3299360275268555,
    "ent_coef": 0.07366430014371872,
    "learning_rate": 0.001
  },
  {
    "episode": 9020,
    "reward": 84.378823,
    "length": 73,
    "time": 133854.21837,
    "actor_loss": -66.47341918945312,
    "critic_loss": 20.206106185913086,
    "ent_coef": 0.06824453920125961,
    "learning_rate": 0.001
  },
  {
    "episode": 9021,
    "reward": 88.402058,
    "length": 66,
    "time": 133866.954822,
    "actor_loss": -67.40170288085938,
    "critic_loss": 1.8114962577819824,
    "ent_coef": 0.06848780065774918,
    "learning_rate": 0.001
  },
  {
    "episode": 9022,
    "reward": 87.379972,
    "length": 69,
    "time": 133882.08129,
    "actor_loss": -60.7150764465332,
    "critic_loss": 14.510210037231445,
    "ent_coef": 0.06812333315610886,
    "learning_rate": 0.001
  },
  {
    "episode": 9023,
    "reward": 91.877198,
    "length": 60,
    "time": 133893.91918,
    "actor_loss": -68.73734283447266,
    "critic_loss": 6.306449890136719,
    "ent_coef": 0.07345860451459885,
    "learning_rate": 0.001
  },
  {
    "episode": 9024,
    "reward": 89.151963,
    "length": 67,
    "time": 133905.73125,
    "actor_loss": -68.016845703125,
    "critic_loss": 2.8468832969665527,
    "ent_coef": 0.07857408374547958,
    "learning_rate": 0.001
  },
  {
    "episode": 9025,
    "reward": 87.00719,
    "length": 68,
    "time": 133918.292482,
    "actor_loss": -69.86187744140625,
    "critic_loss": 5.469185829162598,
    "ent_coef": 0.07879579067230225,
    "learning_rate": 0.001
  },
  {
    "episode": 9026,
    "reward": 90.406344,
    "length": 63,
    "time": 133932.486036,
    "actor_loss": -68.34757995605469,
    "critic_loss": 2.0076375007629395,
    "ent_coef": 0.0802837386727333,
    "learning_rate": 0.001
  },
  {
    "episode": 9027,
    "reward": 87.5097,
    "length": 68,
    "time": 133944.296743,
    "actor_loss": -69.38504028320312,
    "critic_loss": 2.0393285751342773,
    "ent_coef": 0.08040225505828857,
    "learning_rate": 0.001
  },
  {
    "episode": 9028,
    "reward": 87.9821,
    "length": 67,
    "time": 133958.51698,
    "actor_loss": -67.41555786132812,
    "critic_loss": 29.632104873657227,
    "ent_coef": 0.07789424061775208,
    "learning_rate": 0.001
  },
  {
    "episode": 9029,
    "reward": 86.846197,
    "length": 72,
    "time": 133974.063649,
    "actor_loss": -68.07946014404297,
    "critic_loss": 2.5033164024353027,
    "ent_coef": 0.07481333613395691,
    "learning_rate": 0.001
  },
  {
    "episode": 9030,
    "reward": 85.155413,
    "length": 72,
    "time": 133987.459758,
    "actor_loss": -64.63124084472656,
    "critic_loss": 3.8288087844848633,
    "ent_coef": 0.07279933243989944,
    "learning_rate": 0.001
  },
  {
    "episode": 9031,
    "reward": 87.910181,
    "length": 68,
    "time": 133999.688179,
    "actor_loss": -63.6614990234375,
    "critic_loss": 5.474186897277832,
    "ent_coef": 0.0724564790725708,
    "learning_rate": 0.001
  },
  {
    "episode": 9032,
    "reward": 87.975325,
    "length": 68,
    "time": 134012.109893,
    "actor_loss": -68.54428100585938,
    "critic_loss": 6.96533727645874,
    "ent_coef": 0.07217833399772644,
    "learning_rate": 0.001
  },
  {
    "episode": 9033,
    "reward": 88.719383,
    "length": 67,
    "time": 134026.107891,
    "actor_loss": -68.7755126953125,
    "critic_loss": 5.184045791625977,
    "ent_coef": 0.07425852119922638,
    "learning_rate": 0.001
  },
  {
    "episode": 9034,
    "reward": 85.435806,
    "length": 72,
    "time": 134038.457534,
    "actor_loss": -65.177490234375,
    "critic_loss": 2.593214988708496,
    "ent_coef": 0.07241062819957733,
    "learning_rate": 0.001
  },
  {
    "episode": 9035,
    "reward": 81.075523,
    "length": 83,
    "time": 134052.655879,
    "actor_loss": -67.17204284667969,
    "critic_loss": 9.28663444519043,
    "ent_coef": 0.06679481267929077,
    "learning_rate": 0.001
  },
  {
    "episode": 9036,
    "reward": 87.301217,
    "length": 69,
    "time": 134064.477552,
    "actor_loss": -74.62351989746094,
    "critic_loss": 2.602375030517578,
    "ent_coef": 0.0635308250784874,
    "learning_rate": 0.001
  },
  {
    "episode": 9037,
    "reward": 87.417704,
    "length": 69,
    "time": 134076.730676,
    "actor_loss": -70.2156982421875,
    "critic_loss": 89.91586303710938,
    "ent_coef": 0.06329741328954697,
    "learning_rate": 0.001
  },
  {
    "episode": 9038,
    "reward": 89.582642,
    "length": 64,
    "time": 134088.520226,
    "actor_loss": -61.36988830566406,
    "critic_loss": 81.65763854980469,
    "ent_coef": 0.06396853923797607,
    "learning_rate": 0.001
  },
  {
    "episode": 9039,
    "reward": 89.212228,
    "length": 64,
    "time": 134100.083004,
    "actor_loss": -63.73402404785156,
    "critic_loss": 37.81866455078125,
    "ent_coef": 0.06646742671728134,
    "learning_rate": 0.001
  },
  {
    "episode": 9040,
    "reward": 89.514896,
    "length": 65,
    "time": 134111.471014,
    "actor_loss": -67.2313232421875,
    "critic_loss": 3.605492353439331,
    "ent_coef": 0.06907215714454651,
    "learning_rate": 0.001
  },
  {
    "episode": 9041,
    "reward": 88.985357,
    "length": 67,
    "time": 134125.289279,
    "actor_loss": -70.06800842285156,
    "critic_loss": 109.9344482421875,
    "ent_coef": 0.06986325979232788,
    "learning_rate": 0.001
  },
  {
    "episode": 9042,
    "reward": 86.580857,
    "length": 69,
    "time": 134137.593357,
    "actor_loss": -64.51322937011719,
    "critic_loss": 4.550985336303711,
    "ent_coef": 0.06598003208637238,
    "learning_rate": 0.001
  },
  {
    "episode": 9043,
    "reward": 88.988264,
    "length": 67,
    "time": 134150.228868,
    "actor_loss": -66.30792999267578,
    "critic_loss": 3.5408473014831543,
    "ent_coef": 0.06447884440422058,
    "learning_rate": 0.001
  },
  {
    "episode": 9044,
    "reward": 87.53276,
    "length": 71,
    "time": 134163.499372,
    "actor_loss": -66.7122802734375,
    "critic_loss": 2.255887031555176,
    "ent_coef": 0.06253653019666672,
    "learning_rate": 0.001
  },
  {
    "episode": 9045,
    "reward": 89.416573,
    "length": 64,
    "time": 134177.019528,
    "actor_loss": -64.67908477783203,
    "critic_loss": 14.988082885742188,
    "ent_coef": 0.06395828723907471,
    "learning_rate": 0.001
  },
  {
    "episode": 9046,
    "reward": 89.52055,
    "length": 65,
    "time": 134188.538335,
    "actor_loss": -68.54542541503906,
    "critic_loss": 5.472721099853516,
    "ent_coef": 0.06894382834434509,
    "learning_rate": 0.001
  },
  {
    "episode": 9047,
    "reward": 90.566377,
    "length": 64,
    "time": 134199.69447,
    "actor_loss": -66.89830017089844,
    "critic_loss": 5.241642951965332,
    "ent_coef": 0.07016413658857346,
    "learning_rate": 0.001
  },
  {
    "episode": 9048,
    "reward": 88.638302,
    "length": 66,
    "time": 134211.946921,
    "actor_loss": -74.29206848144531,
    "critic_loss": 4.191090106964111,
    "ent_coef": 0.07007358968257904,
    "learning_rate": 0.001
  },
  {
    "episode": 9049,
    "reward": 88.876387,
    "length": 65,
    "time": 134225.247611,
    "actor_loss": -68.2650146484375,
    "critic_loss": 4.246428966522217,
    "ent_coef": 0.07204000651836395,
    "learning_rate": 0.001
  },
  {
    "episode": 9050,
    "reward": 90.560584,
    "length": 63,
    "time": 134237.703672,
    "actor_loss": -67.56160736083984,
    "critic_loss": 4.741885185241699,
    "ent_coef": 0.07348914444446564,
    "learning_rate": 0.001
  },
  {
    "episode": 9051,
    "reward": 88.97705,
    "length": 65,
    "time": 134250.960321,
    "actor_loss": -65.66200256347656,
    "critic_loss": 4.164672374725342,
    "ent_coef": 0.07546751201152802,
    "learning_rate": 0.001
  },
  {
    "episode": 9052,
    "reward": 90.425898,
    "length": 66,
    "time": 134263.994262,
    "actor_loss": -67.9355239868164,
    "critic_loss": 3.701033115386963,
    "ent_coef": 0.0767827257514,
    "learning_rate": 0.001
  },
  {
    "episode": 9053,
    "reward": 89.644825,
    "length": 63,
    "time": 134277.812571,
    "actor_loss": -66.79350280761719,
    "critic_loss": 4.51171350479126,
    "ent_coef": 0.07814687490463257,
    "learning_rate": 0.001
  },
  {
    "episode": 9054,
    "reward": 87.144511,
    "length": 68,
    "time": 134290.107023,
    "actor_loss": -72.51869201660156,
    "critic_loss": 28.399253845214844,
    "ent_coef": 0.0755104348063469,
    "learning_rate": 0.001
  },
  {
    "episode": 9055,
    "reward": 87.468167,
    "length": 70,
    "time": 134303.614858,
    "actor_loss": -65.3121109008789,
    "critic_loss": 2.8278565406799316,
    "ent_coef": 0.07381130754947662,
    "learning_rate": 0.001
  },
  {
    "episode": 9056,
    "reward": 88.296754,
    "length": 69,
    "time": 134319.515019,
    "actor_loss": -68.50050354003906,
    "critic_loss": 92.61647033691406,
    "ent_coef": 0.07431752979755402,
    "learning_rate": 0.001
  },
  {
    "episode": 9057,
    "reward": 89.709146,
    "length": 65,
    "time": 134333.300135,
    "actor_loss": -70.58509826660156,
    "critic_loss": 4.863733291625977,
    "ent_coef": 0.0745496153831482,
    "learning_rate": 0.001
  },
  {
    "episode": 9058,
    "reward": 88.014377,
    "length": 66,
    "time": 134345.308127,
    "actor_loss": -66.01963806152344,
    "critic_loss": 3.4058141708374023,
    "ent_coef": 0.07579529285430908,
    "learning_rate": 0.001
  },
  {
    "episode": 9059,
    "reward": 87.65867,
    "length": 68,
    "time": 134359.141247,
    "actor_loss": -70.3230209350586,
    "critic_loss": 16.183155059814453,
    "ent_coef": 0.0755000114440918,
    "learning_rate": 0.001
  },
  {
    "episode": 9060,
    "reward": 88.355955,
    "length": 66,
    "time": 134372.675961,
    "actor_loss": -69.42233276367188,
    "critic_loss": 27.17955780029297,
    "ent_coef": 0.07406799495220184,
    "learning_rate": 0.001
  },
  {
    "episode": 9061,
    "reward": 86.656099,
    "length": 71,
    "time": 134389.722484,
    "actor_loss": -66.87557983398438,
    "critic_loss": 3.414364814758301,
    "ent_coef": 0.07299579679965973,
    "learning_rate": 0.001
  },
  {
    "episode": 9062,
    "reward": 89.752076,
    "length": 63,
    "time": 134403.441648,
    "actor_loss": -66.70712280273438,
    "critic_loss": 4.781876564025879,
    "ent_coef": 0.07281793653964996,
    "learning_rate": 0.001
  },
  {
    "episode": 9063,
    "reward": 89.160341,
    "length": 67,
    "time": 134419.073034,
    "actor_loss": -66.96701049804688,
    "critic_loss": 2.8125481605529785,
    "ent_coef": 0.07713192701339722,
    "learning_rate": 0.001
  },
  {
    "episode": 9064,
    "reward": 86.638994,
    "length": 70,
    "time": 134431.300995,
    "actor_loss": -69.00617980957031,
    "critic_loss": 3.851090908050537,
    "ent_coef": 0.07607627660036087,
    "learning_rate": 0.001
  },
  {
    "episode": 9065,
    "reward": 87.217211,
    "length": 69,
    "time": 134443.391534,
    "actor_loss": -74.4190673828125,
    "critic_loss": 2.164788246154785,
    "ent_coef": 0.07407116889953613,
    "learning_rate": 0.001
  },
  {
    "episode": 9066,
    "reward": 88.583206,
    "length": 66,
    "time": 134456.042933,
    "actor_loss": -70.55645751953125,
    "critic_loss": 4.492851257324219,
    "ent_coef": 0.07177555561065674,
    "learning_rate": 0.001
  },
  {
    "episode": 9067,
    "reward": 88.327397,
    "length": 66,
    "time": 134469.647873,
    "actor_loss": -68.340576171875,
    "critic_loss": 2.259204864501953,
    "ent_coef": 0.07192529737949371,
    "learning_rate": 0.001
  },
  {
    "episode": 9068,
    "reward": 89.921372,
    "length": 64,
    "time": 134481.13201,
    "actor_loss": -63.53136444091797,
    "critic_loss": 25.710365295410156,
    "ent_coef": 0.07167603075504303,
    "learning_rate": 0.001
  },
  {
    "episode": 9069,
    "reward": 90.177957,
    "length": 63,
    "time": 134492.610005,
    "actor_loss": -64.34148406982422,
    "critic_loss": 4.958634376525879,
    "ent_coef": 0.06917484104633331,
    "learning_rate": 0.001
  },
  {
    "episode": 9070,
    "reward": 88.232124,
    "length": 66,
    "time": 134505.979717,
    "actor_loss": -68.10163879394531,
    "critic_loss": 4.68182373046875,
    "ent_coef": 0.0691608265042305,
    "learning_rate": 0.001
  },
  {
    "episode": 9071,
    "reward": 91.079797,
    "length": 62,
    "time": 134517.753664,
    "actor_loss": -70.81773376464844,
    "critic_loss": 16.75507354736328,
    "ent_coef": 0.07023415714502335,
    "learning_rate": 0.001
  },
  {
    "episode": 9072,
    "reward": 88.096373,
    "length": 67,
    "time": 134530.170508,
    "actor_loss": -68.95028686523438,
    "critic_loss": 8.218095779418945,
    "ent_coef": 0.06847766041755676,
    "learning_rate": 0.001
  },
  {
    "episode": 9073,
    "reward": 90.257407,
    "length": 63,
    "time": 134544.613741,
    "actor_loss": -69.42572021484375,
    "critic_loss": 19.546640396118164,
    "ent_coef": 0.06755675375461578,
    "learning_rate": 0.001
  },
  {
    "episode": 9074,
    "reward": 90.678577,
    "length": 62,
    "time": 134556.664325,
    "actor_loss": -70.20654296875,
    "critic_loss": 4.981029510498047,
    "ent_coef": 0.06986349821090698,
    "learning_rate": 0.001
  },
  {
    "episode": 9075,
    "reward": 91.807483,
    "length": 61,
    "time": 134571.371636,
    "actor_loss": -68.50276184082031,
    "critic_loss": 23.59270477294922,
    "ent_coef": 0.07391129434108734,
    "learning_rate": 0.001
  },
  {
    "episode": 9076,
    "reward": 90.250655,
    "length": 64,
    "time": 134583.935255,
    "actor_loss": -72.08792114257812,
    "critic_loss": 6.254972457885742,
    "ent_coef": 0.07638375461101532,
    "learning_rate": 0.001
  },
  {
    "episode": 9077,
    "reward": 88.15001,
    "length": 67,
    "time": 134599.067564,
    "actor_loss": -65.37421417236328,
    "critic_loss": 269.7974853515625,
    "ent_coef": 0.07659681886434555,
    "learning_rate": 0.001
  },
  {
    "episode": 9078,
    "reward": 88.038703,
    "length": 68,
    "time": 134614.098495,
    "actor_loss": -71.19381713867188,
    "critic_loss": 3.283193349838257,
    "ent_coef": 0.07559138536453247,
    "learning_rate": 0.001
  },
  {
    "episode": 9079,
    "reward": 88.130278,
    "length": 66,
    "time": 134627.172883,
    "actor_loss": -66.44328308105469,
    "critic_loss": 392.3240966796875,
    "ent_coef": 0.07360758632421494,
    "learning_rate": 0.001
  },
  {
    "episode": 9080,
    "reward": 88.341881,
    "length": 66,
    "time": 134638.852882,
    "actor_loss": -66.61028289794922,
    "critic_loss": 16.252159118652344,
    "ent_coef": 0.07528676837682724,
    "learning_rate": 0.001
  },
  {
    "episode": 9081,
    "reward": 87.249706,
    "length": 68,
    "time": 134651.484629,
    "actor_loss": -74.88619995117188,
    "critic_loss": 9.78469181060791,
    "ent_coef": 0.07277503609657288,
    "learning_rate": 0.001
  },
  {
    "episode": 9082,
    "reward": 89.072651,
    "length": 66,
    "time": 134663.168285,
    "actor_loss": -67.39201354980469,
    "critic_loss": 4.0427985191345215,
    "ent_coef": 0.07083207368850708,
    "learning_rate": 0.001
  },
  {
    "episode": 9083,
    "reward": 88.950456,
    "length": 65,
    "time": 134674.783462,
    "actor_loss": -62.29082489013672,
    "critic_loss": 69.55682373046875,
    "ent_coef": 0.07016585767269135,
    "learning_rate": 0.001
  },
  {
    "episode": 9084,
    "reward": 89.74808,
    "length": 65,
    "time": 134688.669733,
    "actor_loss": -76.75344848632812,
    "critic_loss": 2.894469738006592,
    "ent_coef": 0.07200980186462402,
    "learning_rate": 0.001
  },
  {
    "episode": 9085,
    "reward": 87.036114,
    "length": 69,
    "time": 134701.495882,
    "actor_loss": -67.27323913574219,
    "critic_loss": 501.98980712890625,
    "ent_coef": 0.06903013586997986,
    "learning_rate": 0.001
  },
  {
    "episode": 9086,
    "reward": 90.167212,
    "length": 63,
    "time": 134713.822993,
    "actor_loss": -64.89017486572266,
    "critic_loss": 5.003547668457031,
    "ent_coef": 0.06616609543561935,
    "learning_rate": 0.001
  },
  {
    "episode": 9087,
    "reward": 86.475282,
    "length": 72,
    "time": 134726.791764,
    "actor_loss": -66.08123779296875,
    "critic_loss": 3.406871795654297,
    "ent_coef": 0.06220928579568863,
    "learning_rate": 0.001
  },
  {
    "episode": 9088,
    "reward": 88.319927,
    "length": 65,
    "time": 134739.24082,
    "actor_loss": -67.44776916503906,
    "critic_loss": 3.364318370819092,
    "ent_coef": 0.06082182005047798,
    "learning_rate": 0.001
  },
  {
    "episode": 9089,
    "reward": 90.395019,
    "length": 64,
    "time": 134750.497258,
    "actor_loss": -65.05209350585938,
    "critic_loss": 2.2809786796569824,
    "ent_coef": 0.05951191484928131,
    "learning_rate": 0.001
  },
  {
    "episode": 9090,
    "reward": 87.48146,
    "length": 69,
    "time": 134762.475669,
    "actor_loss": -70.00397491455078,
    "critic_loss": 16.960643768310547,
    "ent_coef": 0.05702727288007736,
    "learning_rate": 0.001
  },
  {
    "episode": 9091,
    "reward": 90.78701,
    "length": 62,
    "time": 134774.072478,
    "actor_loss": -68.016845703125,
    "critic_loss": 16.69171714782715,
    "ent_coef": 0.056710291653871536,
    "learning_rate": 0.001
  },
  {
    "episode": 9092,
    "reward": 89.120969,
    "length": 64,
    "time": 134785.953204,
    "actor_loss": -70.73200988769531,
    "critic_loss": 339.828125,
    "ent_coef": 0.057560473680496216,
    "learning_rate": 0.001
  },
  {
    "episode": 9093,
    "reward": 89.933313,
    "length": 65,
    "time": 134798.173283,
    "actor_loss": -60.50000762939453,
    "critic_loss": 8.230778694152832,
    "ent_coef": 0.06125166639685631,
    "learning_rate": 0.001
  },
  {
    "episode": 9094,
    "reward": 85.572182,
    "length": 75,
    "time": 134811.020427,
    "actor_loss": -64.80165100097656,
    "critic_loss": 4.62809944152832,
    "ent_coef": 0.06209952384233475,
    "learning_rate": 0.001
  },
  {
    "episode": 9095,
    "reward": 90.146578,
    "length": 63,
    "time": 134822.527606,
    "actor_loss": -65.68598937988281,
    "critic_loss": 8.368911743164062,
    "ent_coef": 0.06333394348621368,
    "learning_rate": 0.001
  },
  {
    "episode": 9096,
    "reward": 89.655242,
    "length": 65,
    "time": 134835.769603,
    "actor_loss": -64.736572265625,
    "critic_loss": 6.915915489196777,
    "ent_coef": 0.06415633112192154,
    "learning_rate": 0.001
  },
  {
    "episode": 9097,
    "reward": 89.520241,
    "length": 64,
    "time": 134847.366054,
    "actor_loss": -66.44908905029297,
    "critic_loss": 424.69818115234375,
    "ent_coef": 0.0671703964471817,
    "learning_rate": 0.001
  },
  {
    "episode": 9098,
    "reward": 91.625051,
    "length": 61,
    "time": 134862.239647,
    "actor_loss": -67.07112121582031,
    "critic_loss": 7.171216011047363,
    "ent_coef": 0.07378869503736496,
    "learning_rate": 0.001
  },
  {
    "episode": 9099,
    "reward": 90.771868,
    "length": 62,
    "time": 134874.541692,
    "actor_loss": -69.05361938476562,
    "critic_loss": 4.387955665588379,
    "ent_coef": 0.07695085555315018,
    "learning_rate": 0.001
  },
  {
    "episode": 9100,
    "reward": 89.003262,
    "length": 68,
    "time": 134886.466729,
    "actor_loss": -68.50394439697266,
    "critic_loss": 3.76051664352417,
    "ent_coef": 0.07824820280075073,
    "learning_rate": 0.001
  },
  {
    "episode": 9101,
    "reward": 88.998275,
    "length": 67,
    "time": 134899.6225,
    "actor_loss": -69.19635009765625,
    "critic_loss": 3.349557876586914,
    "ent_coef": 0.07817309349775314,
    "learning_rate": 0.001
  },
  {
    "episode": 9102,
    "reward": 88.641885,
    "length": 66,
    "time": 134911.251323,
    "actor_loss": -66.13648986816406,
    "critic_loss": 105.53993225097656,
    "ent_coef": 0.07783003151416779,
    "learning_rate": 0.001
  },
  {
    "episode": 9103,
    "reward": 88.920125,
    "length": 65,
    "time": 134922.819736,
    "actor_loss": -70.79095458984375,
    "critic_loss": 8.119651794433594,
    "ent_coef": 0.07995699346065521,
    "learning_rate": 0.001
  },
  {
    "episode": 9104,
    "reward": 88.147816,
    "length": 68,
    "time": 134935.869131,
    "actor_loss": -68.02532958984375,
    "critic_loss": 6.580313205718994,
    "ent_coef": 0.07625727355480194,
    "learning_rate": 0.001
  },
  {
    "episode": 9105,
    "reward": 90.199133,
    "length": 63,
    "time": 134947.410482,
    "actor_loss": -71.1808090209961,
    "critic_loss": 16.849634170532227,
    "ent_coef": 0.07527312636375427,
    "learning_rate": 0.001
  },
  {
    "episode": 9106,
    "reward": 89.682462,
    "length": 64,
    "time": 134959.735753,
    "actor_loss": -63.60006332397461,
    "critic_loss": 8.80028247833252,
    "ent_coef": 0.07340598106384277,
    "learning_rate": 0.001
  },
  {
    "episode": 9107,
    "reward": 90.382342,
    "length": 63,
    "time": 134970.968501,
    "actor_loss": -71.81619262695312,
    "critic_loss": 12.51164436340332,
    "ent_coef": 0.07420611381530762,
    "learning_rate": 0.001
  },
  {
    "episode": 9108,
    "reward": 89.13124,
    "length": 66,
    "time": 134983.706045,
    "actor_loss": -68.29611206054688,
    "critic_loss": 476.64007568359375,
    "ent_coef": 0.06955460458993912,
    "learning_rate": 0.001
  },
  {
    "episode": 9109,
    "reward": 87.678377,
    "length": 68,
    "time": 134998.42567,
    "actor_loss": -72.76539611816406,
    "critic_loss": 2.7945830821990967,
    "ent_coef": 0.06573454290628433,
    "learning_rate": 0.001
  },
  {
    "episode": 9110,
    "reward": 90.233408,
    "length": 63,
    "time": 135009.742524,
    "actor_loss": -73.58447265625,
    "critic_loss": 18.866832733154297,
    "ent_coef": 0.06650020182132721,
    "learning_rate": 0.001
  },
  {
    "episode": 9111,
    "reward": 89.49237,
    "length": 65,
    "time": 135023.681179,
    "actor_loss": -68.78353881835938,
    "critic_loss": 4.959151268005371,
    "ent_coef": 0.06703125685453415,
    "learning_rate": 0.001
  },
  {
    "episode": 9112,
    "reward": 88.524116,
    "length": 67,
    "time": 135036.018822,
    "actor_loss": -65.32362365722656,
    "critic_loss": 5.9605021476745605,
    "ent_coef": 0.06547490507364273,
    "learning_rate": 0.001
  },
  {
    "episode": 9113,
    "reward": 86.501212,
    "length": 70,
    "time": 135050.016174,
    "actor_loss": -70.34608459472656,
    "critic_loss": 3.4396309852600098,
    "ent_coef": 0.0648839995265007,
    "learning_rate": 0.001
  },
  {
    "episode": 9114,
    "reward": 86.720708,
    "length": 68,
    "time": 135062.211387,
    "actor_loss": -76.97047424316406,
    "critic_loss": 3.3194079399108887,
    "ent_coef": 0.0649445652961731,
    "learning_rate": 0.001
  },
  {
    "episode": 9115,
    "reward": 88.32965,
    "length": 66,
    "time": 135074.068058,
    "actor_loss": -68.08491516113281,
    "critic_loss": 4.174648284912109,
    "ent_coef": 0.0660765990614891,
    "learning_rate": 0.001
  },
  {
    "episode": 9116,
    "reward": 90.447974,
    "length": 63,
    "time": 135087.707388,
    "actor_loss": -65.65972900390625,
    "critic_loss": 32.071327209472656,
    "ent_coef": 0.06816653907299042,
    "learning_rate": 0.001
  },
  {
    "episode": 9117,
    "reward": 89.670129,
    "length": 64,
    "time": 135100.913791,
    "actor_loss": -67.81436157226562,
    "critic_loss": 10.672652244567871,
    "ent_coef": 0.07113747298717499,
    "learning_rate": 0.001
  },
  {
    "episode": 9118,
    "reward": 88.680554,
    "length": 66,
    "time": 135113.373414,
    "actor_loss": -67.40609741210938,
    "critic_loss": 1.9057199954986572,
    "ent_coef": 0.07213711738586426,
    "learning_rate": 0.001
  },
  {
    "episode": 9119,
    "reward": 90.392874,
    "length": 62,
    "time": 135126.382023,
    "actor_loss": -67.90478515625,
    "critic_loss": 24.820430755615234,
    "ent_coef": 0.07454957067966461,
    "learning_rate": 0.001
  },
  {
    "episode": 9120,
    "reward": 90.973888,
    "length": 63,
    "time": 135139.881013,
    "actor_loss": -74.32283020019531,
    "critic_loss": 2.4780750274658203,
    "ent_coef": 0.0788443312048912,
    "learning_rate": 0.001
  },
  {
    "episode": 9121,
    "reward": 89.46724,
    "length": 64,
    "time": 135154.127673,
    "actor_loss": -69.12326049804688,
    "critic_loss": 6.289452075958252,
    "ent_coef": 0.0813119187951088,
    "learning_rate": 0.001
  },
  {
    "episode": 9122,
    "reward": 88.077566,
    "length": 68,
    "time": 135168.078283,
    "actor_loss": -69.78912353515625,
    "critic_loss": 4.0129594802856445,
    "ent_coef": 0.07627123594284058,
    "learning_rate": 0.001
  },
  {
    "episode": 9123,
    "reward": 88.050807,
    "length": 66,
    "time": 135179.840826,
    "actor_loss": -66.4785385131836,
    "critic_loss": 8.000251770019531,
    "ent_coef": 0.07506083697080612,
    "learning_rate": 0.001
  },
  {
    "episode": 9124,
    "reward": 88.477471,
    "length": 67,
    "time": 135194.20522,
    "actor_loss": -67.06755065917969,
    "critic_loss": 23.773746490478516,
    "ent_coef": 0.07326190918684006,
    "learning_rate": 0.001
  },
  {
    "episode": 9125,
    "reward": 90.55856,
    "length": 62,
    "time": 135207.416106,
    "actor_loss": -75.62962341308594,
    "critic_loss": 8.295745849609375,
    "ent_coef": 0.07476375997066498,
    "learning_rate": 0.001
  },
  {
    "episode": 9126,
    "reward": 86.544112,
    "length": 73,
    "time": 135221.981463,
    "actor_loss": -66.24642944335938,
    "critic_loss": 3.4598350524902344,
    "ent_coef": 0.07485731691122055,
    "learning_rate": 0.001
  },
  {
    "episode": 9127,
    "reward": 88.433153,
    "length": 67,
    "time": 135234.232394,
    "actor_loss": -65.6537857055664,
    "critic_loss": 11.232311248779297,
    "ent_coef": 0.07503122836351395,
    "learning_rate": 0.001
  },
  {
    "episode": 9128,
    "reward": 88.4151,
    "length": 66,
    "time": 135249.816578,
    "actor_loss": -67.10250091552734,
    "critic_loss": 16.669292449951172,
    "ent_coef": 0.07321366667747498,
    "learning_rate": 0.001
  },
  {
    "episode": 9129,
    "reward": 91.516393,
    "length": 62,
    "time": 135260.934735,
    "actor_loss": -69.89556121826172,
    "critic_loss": 2.73655104637146,
    "ent_coef": 0.07337779551744461,
    "learning_rate": 0.001
  },
  {
    "episode": 9130,
    "reward": 87.940949,
    "length": 70,
    "time": 135274.658134,
    "actor_loss": -63.559913635253906,
    "critic_loss": 4.3119001388549805,
    "ent_coef": 0.07010714709758759,
    "learning_rate": 0.001
  },
  {
    "episode": 9131,
    "reward": 89.954373,
    "length": 63,
    "time": 135288.769294,
    "actor_loss": -69.4886703491211,
    "critic_loss": 31.08186149597168,
    "ent_coef": 0.07022830098867416,
    "learning_rate": 0.001
  },
  {
    "episode": 9132,
    "reward": 88.44509,
    "length": 66,
    "time": 135300.67726,
    "actor_loss": -66.68711853027344,
    "critic_loss": 3.682159900665283,
    "ent_coef": 0.07005703449249268,
    "learning_rate": 0.001
  },
  {
    "episode": 9133,
    "reward": 90.269519,
    "length": 63,
    "time": 135312.10483,
    "actor_loss": -68.53515625,
    "critic_loss": 9.692235946655273,
    "ent_coef": 0.0707002729177475,
    "learning_rate": 0.001
  },
  {
    "episode": 9134,
    "reward": 87.438659,
    "length": 68,
    "time": 135327.879407,
    "actor_loss": -62.712059020996094,
    "critic_loss": 6.459436893463135,
    "ent_coef": 0.07288588583469391,
    "learning_rate": 0.001
  },
  {
    "episode": 9135,
    "reward": 89.686063,
    "length": 65,
    "time": 135339.590611,
    "actor_loss": -66.18142700195312,
    "critic_loss": 4.539979934692383,
    "ent_coef": 0.0759776309132576,
    "learning_rate": 0.001
  },
  {
    "episode": 9136,
    "reward": 88.034428,
    "length": 67,
    "time": 135354.798254,
    "actor_loss": -66.96134948730469,
    "critic_loss": 2.8178913593292236,
    "ent_coef": 0.07740027457475662,
    "learning_rate": 0.001
  },
  {
    "episode": 9137,
    "reward": 86.270024,
    "length": 70,
    "time": 135368.636448,
    "actor_loss": -70.43553161621094,
    "critic_loss": 3.1115469932556152,
    "ent_coef": 0.07375913113355637,
    "learning_rate": 0.001
  },
  {
    "episode": 9138,
    "reward": 87.681327,
    "length": 70,
    "time": 135383.805596,
    "actor_loss": -66.23321533203125,
    "critic_loss": 24.867095947265625,
    "ent_coef": 0.07017785310745239,
    "learning_rate": 0.001
  },
  {
    "episode": 9139,
    "reward": 86.839941,
    "length": 70,
    "time": 135397.56378,
    "actor_loss": -67.11746978759766,
    "critic_loss": 6.268666744232178,
    "ent_coef": 0.06552049517631531,
    "learning_rate": 0.001
  },
  {
    "episode": 9140,
    "reward": 90.172262,
    "length": 64,
    "time": 135409.090889,
    "actor_loss": -74.477294921875,
    "critic_loss": 3.0479559898376465,
    "ent_coef": 0.06345632672309875,
    "learning_rate": 0.001
  },
  {
    "episode": 9141,
    "reward": 88.675652,
    "length": 65,
    "time": 135424.151376,
    "actor_loss": -71.45494842529297,
    "critic_loss": 20.60112953186035,
    "ent_coef": 0.06565842032432556,
    "learning_rate": 0.001
  },
  {
    "episode": 9142,
    "reward": 85.98721,
    "length": 71,
    "time": 135436.727202,
    "actor_loss": -73.11981201171875,
    "critic_loss": 2.3897080421447754,
    "ent_coef": 0.06463025510311127,
    "learning_rate": 0.001
  },
  {
    "episode": 9143,
    "reward": 89.008597,
    "length": 65,
    "time": 135449.053939,
    "actor_loss": -66.57963562011719,
    "critic_loss": 10.056922912597656,
    "ent_coef": 0.06307358294725418,
    "learning_rate": 0.001
  },
  {
    "episode": 9144,
    "reward": 88.382074,
    "length": 67,
    "time": 135460.716071,
    "actor_loss": -64.75841522216797,
    "critic_loss": 4.803603172302246,
    "ent_coef": 0.06304003298282623,
    "learning_rate": 0.001
  },
  {
    "episode": 9145,
    "reward": 88.669383,
    "length": 66,
    "time": 135473.107861,
    "actor_loss": -71.99694061279297,
    "critic_loss": 5.245767593383789,
    "ent_coef": 0.06371632218360901,
    "learning_rate": 0.001
  },
  {
    "episode": 9146,
    "reward": 89.378721,
    "length": 65,
    "time": 135485.544581,
    "actor_loss": -71.81364440917969,
    "critic_loss": 3.4097418785095215,
    "ent_coef": 0.06401756405830383,
    "learning_rate": 0.001
  },
  {
    "episode": 9147,
    "reward": 89.408654,
    "length": 67,
    "time": 135501.349068,
    "actor_loss": -69.5152816772461,
    "critic_loss": 4.2305192947387695,
    "ent_coef": 0.06698844581842422,
    "learning_rate": 0.001
  },
  {
    "episode": 9148,
    "reward": 87.445414,
    "length": 68,
    "time": 135513.367157,
    "actor_loss": -69.0455322265625,
    "critic_loss": 4.319639682769775,
    "ent_coef": 0.06839938461780548,
    "learning_rate": 0.001
  },
  {
    "episode": 9149,
    "reward": 88.641982,
    "length": 67,
    "time": 135525.05515,
    "actor_loss": -70.6514892578125,
    "critic_loss": 35.728515625,
    "ent_coef": 0.06815410405397415,
    "learning_rate": 0.001
  },
  {
    "episode": 9150,
    "reward": 90.262438,
    "length": 63,
    "time": 135537.48016,
    "actor_loss": -69.35704040527344,
    "critic_loss": 23.704700469970703,
    "ent_coef": 0.06863348186016083,
    "learning_rate": 0.001
  },
  {
    "episode": 9151,
    "reward": 88.752579,
    "length": 66,
    "time": 135550.088837,
    "actor_loss": -65.45661926269531,
    "critic_loss": 2.569855213165283,
    "ent_coef": 0.07129748910665512,
    "learning_rate": 0.001
  },
  {
    "episode": 9152,
    "reward": 88.824872,
    "length": 66,
    "time": 135561.860061,
    "actor_loss": -65.29566192626953,
    "critic_loss": 3.0814502239227295,
    "ent_coef": 0.07150191813707352,
    "learning_rate": 0.001
  },
  {
    "episode": 9153,
    "reward": 90.77444,
    "length": 62,
    "time": 135573.052167,
    "actor_loss": -71.3513412475586,
    "critic_loss": 1.8959825038909912,
    "ent_coef": 0.07388608157634735,
    "learning_rate": 0.001
  },
  {
    "episode": 9154,
    "reward": 90.130757,
    "length": 63,
    "time": 135584.837848,
    "actor_loss": -69.30714416503906,
    "critic_loss": 25.728778839111328,
    "ent_coef": 0.07685648649930954,
    "learning_rate": 0.001
  },
  {
    "episode": 9155,
    "reward": 87.3365,
    "length": 69,
    "time": 135596.97208,
    "actor_loss": -66.12643432617188,
    "critic_loss": 4.643052101135254,
    "ent_coef": 0.0738213062286377,
    "learning_rate": 0.001
  },
  {
    "episode": 9156,
    "reward": 88.782551,
    "length": 68,
    "time": 135608.980043,
    "actor_loss": -66.40383911132812,
    "critic_loss": 13.873884201049805,
    "ent_coef": 0.06913892924785614,
    "learning_rate": 0.001
  },
  {
    "episode": 9157,
    "reward": 90.70403,
    "length": 62,
    "time": 135620.156133,
    "actor_loss": -67.84152221679688,
    "critic_loss": 2.5506255626678467,
    "ent_coef": 0.07077083736658096,
    "learning_rate": 0.001
  },
  {
    "episode": 9158,
    "reward": 91.314081,
    "length": 61,
    "time": 135632.021407,
    "actor_loss": -70.05280303955078,
    "critic_loss": 18.19533920288086,
    "ent_coef": 0.07190048694610596,
    "learning_rate": 0.001
  },
  {
    "episode": 9159,
    "reward": 90.283105,
    "length": 64,
    "time": 135643.817955,
    "actor_loss": -72.35552978515625,
    "critic_loss": 2.3776473999023438,
    "ent_coef": 0.07456693053245544,
    "learning_rate": 0.001
  },
  {
    "episode": 9160,
    "reward": 88.216194,
    "length": 66,
    "time": 135657.957713,
    "actor_loss": -68.94267272949219,
    "critic_loss": 3.2921218872070312,
    "ent_coef": 0.07464932650327682,
    "learning_rate": 0.001
  },
  {
    "episode": 9161,
    "reward": 91.218185,
    "length": 62,
    "time": 135669.187851,
    "actor_loss": -68.04389953613281,
    "critic_loss": 154.419677734375,
    "ent_coef": 0.07459980994462967,
    "learning_rate": 0.001
  },
  {
    "episode": 9162,
    "reward": 89.895595,
    "length": 64,
    "time": 135680.706158,
    "actor_loss": -66.62422180175781,
    "critic_loss": 49.53926086425781,
    "ent_coef": 0.07856661081314087,
    "learning_rate": 0.001
  },
  {
    "episode": 9163,
    "reward": 86.498345,
    "length": 70,
    "time": 135694.516359,
    "actor_loss": -71.19041442871094,
    "critic_loss": 5.018926620483398,
    "ent_coef": 0.07822662591934204,
    "learning_rate": 0.001
  },
  {
    "episode": 9164,
    "reward": 89.702617,
    "length": 64,
    "time": 135707.413066,
    "actor_loss": -65.903076171875,
    "critic_loss": 4.142732620239258,
    "ent_coef": 0.07774042338132858,
    "learning_rate": 0.001
  },
  {
    "episode": 9165,
    "reward": 87.794993,
    "length": 67,
    "time": 135719.633879,
    "actor_loss": -65.3501205444336,
    "critic_loss": 2.9481027126312256,
    "ent_coef": 0.07609320431947708,
    "learning_rate": 0.001
  },
  {
    "episode": 9166,
    "reward": 89.754853,
    "length": 65,
    "time": 135732.867623,
    "actor_loss": -71.5596923828125,
    "critic_loss": 2.6064257621765137,
    "ent_coef": 0.07348733395338058,
    "learning_rate": 0.001
  },
  {
    "episode": 9167,
    "reward": 80.414442,
    "length": 82,
    "time": 135746.628623,
    "actor_loss": -66.93450164794922,
    "critic_loss": 3.9738903045654297,
    "ent_coef": 0.06581249088048935,
    "learning_rate": 0.001
  },
  {
    "episode": 9168,
    "reward": 88.945227,
    "length": 66,
    "time": 135761.007199,
    "actor_loss": -69.18046569824219,
    "critic_loss": 2.8465847969055176,
    "ent_coef": 0.0644829049706459,
    "learning_rate": 0.001
  },
  {
    "episode": 9169,
    "reward": 89.940261,
    "length": 64,
    "time": 135772.850681,
    "actor_loss": -64.59526824951172,
    "critic_loss": 4.188525676727295,
    "ent_coef": 0.06610650569200516,
    "learning_rate": 0.001
  },
  {
    "episode": 9170,
    "reward": 86.844897,
    "length": 68,
    "time": 135785.550313,
    "actor_loss": -71.81287384033203,
    "critic_loss": 6.794442176818848,
    "ent_coef": 0.06659587472677231,
    "learning_rate": 0.001
  },
  {
    "episode": 9171,
    "reward": 84.543639,
    "length": 74,
    "time": 135798.402487,
    "actor_loss": -70.69486236572266,
    "critic_loss": 3.0743467807769775,
    "ent_coef": 0.06253844499588013,
    "learning_rate": 0.001
  },
  {
    "episode": 9172,
    "reward": 86.055706,
    "length": 72,
    "time": 135811.518028,
    "actor_loss": -68.31571960449219,
    "critic_loss": 4.502053260803223,
    "ent_coef": 0.0602380745112896,
    "learning_rate": 0.001
  },
  {
    "episode": 9173,
    "reward": 88.077712,
    "length": 67,
    "time": 135823.060642,
    "actor_loss": -70.88762664794922,
    "critic_loss": 2.486708164215088,
    "ent_coef": 0.059347860515117645,
    "learning_rate": 0.001
  },
  {
    "episode": 9174,
    "reward": 78.973314,
    "length": 98,
    "time": 135839.155762,
    "actor_loss": -63.75679397583008,
    "critic_loss": 5.839652061462402,
    "ent_coef": 0.0599951334297657,
    "learning_rate": 0.001
  },
  {
    "episode": 9175,
    "reward": 89.19548,
    "length": 63,
    "time": 135850.454928,
    "actor_loss": -65.79740142822266,
    "critic_loss": 43.571556091308594,
    "ent_coef": 0.06350007653236389,
    "learning_rate": 0.001
  },
  {
    "episode": 9176,
    "reward": 87.614511,
    "length": 67,
    "time": 135864.991374,
    "actor_loss": -68.71463012695312,
    "critic_loss": 2.384261131286621,
    "ent_coef": 0.06682328134775162,
    "learning_rate": 0.001
  },
  {
    "episode": 9177,
    "reward": 87.925315,
    "length": 68,
    "time": 135879.882294,
    "actor_loss": -65.61865234375,
    "critic_loss": 5.264076232910156,
    "ent_coef": 0.06562533229589462,
    "learning_rate": 0.001
  },
  {
    "episode": 9178,
    "reward": 87.153111,
    "length": 69,
    "time": 135892.981302,
    "actor_loss": -66.61091613769531,
    "critic_loss": 420.6092529296875,
    "ent_coef": 0.06300413608551025,
    "learning_rate": 0.001
  },
  {
    "episode": 9179,
    "reward": 87.643882,
    "length": 67,
    "time": 135904.598712,
    "actor_loss": -64.61090087890625,
    "critic_loss": 8.651798248291016,
    "ent_coef": 0.06230854243040085,
    "learning_rate": 0.001
  },
  {
    "episode": 9180,
    "reward": 88.674123,
    "length": 67,
    "time": 135917.20575,
    "actor_loss": -68.11576843261719,
    "critic_loss": 3.4018330574035645,
    "ent_coef": 0.06314973533153534,
    "learning_rate": 0.001
  },
  {
    "episode": 9181,
    "reward": 89.329799,
    "length": 65,
    "time": 135930.14368,
    "actor_loss": -63.1678581237793,
    "critic_loss": 2.776333808898926,
    "ent_coef": 0.06217395141720772,
    "learning_rate": 0.001
  },
  {
    "episode": 9182,
    "reward": 89.718317,
    "length": 63,
    "time": 135946.671905,
    "actor_loss": -69.57721710205078,
    "critic_loss": 7.9050984382629395,
    "ent_coef": 0.06164676323533058,
    "learning_rate": 0.001
  },
  {
    "episode": 9183,
    "reward": 88.436294,
    "length": 67,
    "time": 135959.139066,
    "actor_loss": -73.97317504882812,
    "critic_loss": 4.094141960144043,
    "ent_coef": 0.059583596885204315,
    "learning_rate": 0.001
  },
  {
    "episode": 9184,
    "reward": 88.158182,
    "length": 68,
    "time": 135971.632977,
    "actor_loss": -66.73506927490234,
    "critic_loss": 7.385017395019531,
    "ent_coef": 0.05781964585185051,
    "learning_rate": 0.001
  },
  {
    "episode": 9185,
    "reward": 87.907759,
    "length": 67,
    "time": 135984.818554,
    "actor_loss": -69.32105255126953,
    "critic_loss": 7.810959339141846,
    "ent_coef": 0.0576874278485775,
    "learning_rate": 0.001
  },
  {
    "episode": 9186,
    "reward": 90.415591,
    "length": 63,
    "time": 135997.866002,
    "actor_loss": -70.4438705444336,
    "critic_loss": 1.7005438804626465,
    "ent_coef": 0.05892595648765564,
    "learning_rate": 0.001
  },
  {
    "episode": 9187,
    "reward": 89.775925,
    "length": 64,
    "time": 136009.814118,
    "actor_loss": -67.99759674072266,
    "critic_loss": 49.98876953125,
    "ent_coef": 0.06253632158041,
    "learning_rate": 0.001
  },
  {
    "episode": 9188,
    "reward": 91.761262,
    "length": 62,
    "time": 136023.664886,
    "actor_loss": -63.720977783203125,
    "critic_loss": 3.8211028575897217,
    "ent_coef": 0.06546516716480255,
    "learning_rate": 0.001
  },
  {
    "episode": 9189,
    "reward": 86.929821,
    "length": 68,
    "time": 136039.149722,
    "actor_loss": -64.53324890136719,
    "critic_loss": 2.373438835144043,
    "ent_coef": 0.06476655602455139,
    "learning_rate": 0.001
  },
  {
    "episode": 9190,
    "reward": 87.390705,
    "length": 68,
    "time": 136051.879872,
    "actor_loss": -66.2409439086914,
    "critic_loss": 4.571181297302246,
    "ent_coef": 0.06192170828580856,
    "learning_rate": 0.001
  },
  {
    "episode": 9191,
    "reward": 88.615077,
    "length": 65,
    "time": 136063.670243,
    "actor_loss": -69.60025024414062,
    "critic_loss": 3.8595497608184814,
    "ent_coef": 0.06321549415588379,
    "learning_rate": 0.001
  },
  {
    "episode": 9192,
    "reward": 87.327224,
    "length": 69,
    "time": 136075.35998,
    "actor_loss": -72.3909912109375,
    "critic_loss": 20.308334350585938,
    "ent_coef": 0.06054309010505676,
    "learning_rate": 0.001
  },
  {
    "episode": 9193,
    "reward": 87.116451,
    "length": 70,
    "time": 136087.544853,
    "actor_loss": -63.61912536621094,
    "critic_loss": 63.92462158203125,
    "ent_coef": 0.06025366112589836,
    "learning_rate": 0.001
  },
  {
    "episode": 9194,
    "reward": 88.873444,
    "length": 66,
    "time": 136100.044152,
    "actor_loss": -70.77000427246094,
    "critic_loss": 2.0736160278320312,
    "ent_coef": 0.060729265213012695,
    "learning_rate": 0.001
  },
  {
    "episode": 9195,
    "reward": 87.49165,
    "length": 72,
    "time": 136112.747434,
    "actor_loss": -67.80743408203125,
    "critic_loss": 1.8349084854125977,
    "ent_coef": 0.05934042111039162,
    "learning_rate": 0.001
  },
  {
    "episode": 9196,
    "reward": 86.65592,
    "length": 74,
    "time": 136125.245376,
    "actor_loss": -66.29541015625,
    "critic_loss": 5.87162971496582,
    "ent_coef": 0.057522907853126526,
    "learning_rate": 0.001
  },
  {
    "episode": 9197,
    "reward": 89.820701,
    "length": 64,
    "time": 136137.439909,
    "actor_loss": -77.11180114746094,
    "critic_loss": 19.901479721069336,
    "ent_coef": 0.05741622671484947,
    "learning_rate": 0.001
  },
  {
    "episode": 9198,
    "reward": 89.080609,
    "length": 66,
    "time": 136150.871037,
    "actor_loss": -66.17644500732422,
    "critic_loss": 6.3922014236450195,
    "ent_coef": 0.05773737654089928,
    "learning_rate": 0.001
  },
  {
    "episode": 9199,
    "reward": 89.937113,
    "length": 65,
    "time": 136164.95277,
    "actor_loss": -66.74808502197266,
    "critic_loss": 14.503963470458984,
    "ent_coef": 0.0574820414185524,
    "learning_rate": 0.001
  },
  {
    "episode": 9200,
    "reward": 88.637148,
    "length": 68,
    "time": 136178.475313,
    "actor_loss": -65.35747528076172,
    "critic_loss": 6.287578582763672,
    "ent_coef": 0.05790660157799721,
    "learning_rate": 0.001
  },
  {
    "episode": 9201,
    "reward": 87.709344,
    "length": 72,
    "time": 136194.042001,
    "actor_loss": -74.65890502929688,
    "critic_loss": 1.7405362129211426,
    "ent_coef": 0.058361224830150604,
    "learning_rate": 0.001
  },
  {
    "episode": 9202,
    "reward": 88.657768,
    "length": 69,
    "time": 136208.642894,
    "actor_loss": -69.55909729003906,
    "critic_loss": 16.54753303527832,
    "ent_coef": 0.05584612116217613,
    "learning_rate": 0.001
  },
  {
    "episode": 9203,
    "reward": 83.948044,
    "length": 73,
    "time": 136225.685087,
    "actor_loss": -69.78868103027344,
    "critic_loss": 17.22052574157715,
    "ent_coef": 0.05343538150191307,
    "learning_rate": 0.001
  },
  {
    "episode": 9204,
    "reward": 87.951889,
    "length": 70,
    "time": 136238.373991,
    "actor_loss": -71.27493286132812,
    "critic_loss": 3.464815378189087,
    "ent_coef": 0.05037133768200874,
    "learning_rate": 0.001
  },
  {
    "episode": 9205,
    "reward": 88.771398,
    "length": 68,
    "time": 136252.103504,
    "actor_loss": -73.1908187866211,
    "critic_loss": 11.47668743133545,
    "ent_coef": 0.04792879894375801,
    "learning_rate": 0.001
  },
  {
    "episode": 9206,
    "reward": 90.610159,
    "length": 62,
    "time": 136263.479403,
    "actor_loss": -65.13916015625,
    "critic_loss": 4.040165424346924,
    "ent_coef": 0.04591519013047218,
    "learning_rate": 0.001
  },
  {
    "episode": 9207,
    "reward": 87.059085,
    "length": 70,
    "time": 136275.682485,
    "actor_loss": -62.495052337646484,
    "critic_loss": 24.083271026611328,
    "ent_coef": 0.04691292345523834,
    "learning_rate": 0.001
  },
  {
    "episode": 9208,
    "reward": 87.657582,
    "length": 68,
    "time": 136287.615056,
    "actor_loss": -70.73324584960938,
    "critic_loss": 16.905426025390625,
    "ent_coef": 0.047066837549209595,
    "learning_rate": 0.001
  },
  {
    "episode": 9209,
    "reward": 87.289512,
    "length": 70,
    "time": 136299.675296,
    "actor_loss": -67.50155639648438,
    "critic_loss": 27.206422805786133,
    "ent_coef": 0.0470193587243557,
    "learning_rate": 0.001
  },
  {
    "episode": 9210,
    "reward": 89.531316,
    "length": 65,
    "time": 136311.437933,
    "actor_loss": -70.33421325683594,
    "critic_loss": 65.08991241455078,
    "ent_coef": 0.04640202596783638,
    "learning_rate": 0.001
  },
  {
    "episode": 9211,
    "reward": 89.325986,
    "length": 65,
    "time": 136326.023404,
    "actor_loss": -66.67869567871094,
    "critic_loss": 3.042499542236328,
    "ent_coef": 0.045992013067007065,
    "learning_rate": 0.001
  },
  {
    "episode": 9212,
    "reward": 86.989394,
    "length": 71,
    "time": 136338.103081,
    "actor_loss": -69.11827087402344,
    "critic_loss": 55.38580322265625,
    "ent_coef": 0.04519408568739891,
    "learning_rate": 0.001
  },
  {
    "episode": 9213,
    "reward": 80.271497,
    "length": 85,
    "time": 136354.37256,
    "actor_loss": -74.3702392578125,
    "critic_loss": 190.62884521484375,
    "ent_coef": 0.04133935645222664,
    "learning_rate": 0.001
  },
  {
    "episode": 9214,
    "reward": 85.333193,
    "length": 73,
    "time": 136368.003273,
    "actor_loss": -71.51825714111328,
    "critic_loss": 6.938024997711182,
    "ent_coef": 0.040112078189849854,
    "learning_rate": 0.001
  },
  {
    "episode": 9215,
    "reward": 88.196382,
    "length": 69,
    "time": 136379.935923,
    "actor_loss": -64.4399185180664,
    "critic_loss": 8.459009170532227,
    "ent_coef": 0.03920727223157883,
    "learning_rate": 0.001
  },
  {
    "episode": 9216,
    "reward": 89.460419,
    "length": 66,
    "time": 136393.817165,
    "actor_loss": -66.00927734375,
    "critic_loss": 3.504758358001709,
    "ent_coef": 0.04059845581650734,
    "learning_rate": 0.001
  },
  {
    "episode": 9217,
    "reward": 88.739577,
    "length": 69,
    "time": 136407.350385,
    "actor_loss": -71.63941955566406,
    "critic_loss": 66.93222045898438,
    "ent_coef": 0.04227672144770622,
    "learning_rate": 0.001
  },
  {
    "episode": 9218,
    "reward": 87.64337,
    "length": 69,
    "time": 136420.103113,
    "actor_loss": -66.39498901367188,
    "critic_loss": 9.87971305847168,
    "ent_coef": 0.04393194615840912,
    "learning_rate": 0.001
  },
  {
    "episode": 9219,
    "reward": 88.826618,
    "length": 67,
    "time": 136434.943308,
    "actor_loss": -69.13457489013672,
    "critic_loss": 58.370967864990234,
    "ent_coef": 0.045922644436359406,
    "learning_rate": 0.001
  },
  {
    "episode": 9220,
    "reward": 91.215774,
    "length": 62,
    "time": 136445.865811,
    "actor_loss": -68.25405883789062,
    "critic_loss": 39.769405364990234,
    "ent_coef": 0.049318425357341766,
    "learning_rate": 0.001
  },
  {
    "episode": 9221,
    "reward": 86.494151,
    "length": 70,
    "time": 136461.651387,
    "actor_loss": -66.39801025390625,
    "critic_loss": 6.248763084411621,
    "ent_coef": 0.048936229199171066,
    "learning_rate": 0.001
  },
  {
    "episode": 9222,
    "reward": 87.824871,
    "length": 71,
    "time": 136475.377676,
    "actor_loss": -70.55255126953125,
    "critic_loss": 30.86496353149414,
    "ent_coef": 0.05021568387746811,
    "learning_rate": 0.001
  },
  {
    "episode": 9223,
    "reward": 87.797601,
    "length": 68,
    "time": 136488.392339,
    "actor_loss": -76.54009246826172,
    "critic_loss": 7.664935111999512,
    "ent_coef": 0.050807513296604156,
    "learning_rate": 0.001
  },
  {
    "episode": 9224,
    "reward": 89.99463,
    "length": 64,
    "time": 136500.024232,
    "actor_loss": -75.442626953125,
    "critic_loss": 3.8139266967773438,
    "ent_coef": 0.05416512116789818,
    "learning_rate": 0.001
  },
  {
    "episode": 9225,
    "reward": 89.860881,
    "length": 64,
    "time": 136511.524169,
    "actor_loss": -62.652645111083984,
    "critic_loss": 2.1977806091308594,
    "ent_coef": 0.05731140822172165,
    "learning_rate": 0.001
  },
  {
    "episode": 9226,
    "reward": 90.83531,
    "length": 63,
    "time": 136522.710202,
    "actor_loss": -71.89607238769531,
    "critic_loss": 41.34648513793945,
    "ent_coef": 0.05979666858911514,
    "learning_rate": 0.001
  },
  {
    "episode": 9227,
    "reward": 89.22668,
    "length": 65,
    "time": 136535.223338,
    "actor_loss": -71.0135498046875,
    "critic_loss": 3.615628242492676,
    "ent_coef": 0.05934194475412369,
    "learning_rate": 0.001
  },
  {
    "episode": 9228,
    "reward": 88.771944,
    "length": 66,
    "time": 136548.687304,
    "actor_loss": -63.354122161865234,
    "critic_loss": 17.966413497924805,
    "ent_coef": 0.06019177660346031,
    "learning_rate": 0.001
  },
  {
    "episode": 9229,
    "reward": 90.157028,
    "length": 64,
    "time": 136559.919338,
    "actor_loss": -68.38529205322266,
    "critic_loss": 2.9823925495147705,
    "ent_coef": 0.061984796077013016,
    "learning_rate": 0.001
  },
  {
    "episode": 9230,
    "reward": 85.727439,
    "length": 72,
    "time": 136572.459074,
    "actor_loss": -68.09819030761719,
    "critic_loss": 2.0248961448669434,
    "ent_coef": 0.05992221459746361,
    "learning_rate": 0.001
  },
  {
    "episode": 9231,
    "reward": 88.71206,
    "length": 67,
    "time": 136585.711605,
    "actor_loss": -69.25883483886719,
    "critic_loss": 2.565225601196289,
    "ent_coef": 0.05945172905921936,
    "learning_rate": 0.001
  },
  {
    "episode": 9232,
    "reward": 88.564183,
    "length": 67,
    "time": 136599.94258,
    "actor_loss": -67.91870880126953,
    "critic_loss": 2.009031295776367,
    "ent_coef": 0.059823207557201385,
    "learning_rate": 0.001
  },
  {
    "episode": 9233,
    "reward": 88.646259,
    "length": 67,
    "time": 136611.520506,
    "actor_loss": -71.5459976196289,
    "critic_loss": 19.78411865234375,
    "ent_coef": 0.060847122222185135,
    "learning_rate": 0.001
  },
  {
    "episode": 9234,
    "reward": 88.730752,
    "length": 65,
    "time": 136625.147377,
    "actor_loss": -64.5177993774414,
    "critic_loss": 150.53079223632812,
    "ent_coef": 0.05904023349285126,
    "learning_rate": 0.001
  },
  {
    "episode": 9235,
    "reward": 83.855213,
    "length": 76,
    "time": 136637.810338,
    "actor_loss": -70.58567810058594,
    "critic_loss": 29.887754440307617,
    "ent_coef": 0.05724241957068443,
    "learning_rate": 0.001
  },
  {
    "episode": 9236,
    "reward": 86.472992,
    "length": 70,
    "time": 136654.616434,
    "actor_loss": -67.548828125,
    "critic_loss": 8.837849617004395,
    "ent_coef": 0.0583399273455143,
    "learning_rate": 0.001
  },
  {
    "episode": 9237,
    "reward": 87.513934,
    "length": 68,
    "time": 136668.972592,
    "actor_loss": -68.19882202148438,
    "critic_loss": 12.546635627746582,
    "ent_coef": 0.05706778168678284,
    "learning_rate": 0.001
  },
  {
    "episode": 9238,
    "reward": 89.17686,
    "length": 66,
    "time": 136680.901227,
    "actor_loss": -71.80998229980469,
    "critic_loss": 4.681331634521484,
    "ent_coef": 0.05709526687860489,
    "learning_rate": 0.001
  },
  {
    "episode": 9239,
    "reward": 90.125989,
    "length": 63,
    "time": 136695.569589,
    "actor_loss": -73.35295104980469,
    "critic_loss": 34.845252990722656,
    "ent_coef": 0.05809834599494934,
    "learning_rate": 0.001
  },
  {
    "episode": 9240,
    "reward": 90.548492,
    "length": 64,
    "time": 136708.100187,
    "actor_loss": -72.10006713867188,
    "critic_loss": 5.481849193572998,
    "ent_coef": 0.06082770973443985,
    "learning_rate": 0.001
  },
  {
    "episode": 9241,
    "reward": 85.54295,
    "length": 73,
    "time": 136720.691896,
    "actor_loss": -68.13890838623047,
    "critic_loss": 2.016345977783203,
    "ent_coef": 0.06001032516360283,
    "learning_rate": 0.001
  },
  {
    "episode": 9242,
    "reward": 88.798966,
    "length": 66,
    "time": 136737.765949,
    "actor_loss": -73.0221939086914,
    "critic_loss": 2.3322432041168213,
    "ent_coef": 0.05881336331367493,
    "learning_rate": 0.001
  },
  {
    "episode": 9243,
    "reward": 87.345475,
    "length": 69,
    "time": 136753.304765,
    "actor_loss": -71.385986328125,
    "critic_loss": 3.386622190475464,
    "ent_coef": 0.05536796897649765,
    "learning_rate": 0.001
  },
  {
    "episode": 9244,
    "reward": 83.413001,
    "length": 76,
    "time": 136766.987239,
    "actor_loss": -67.48832702636719,
    "critic_loss": 3.5856738090515137,
    "ent_coef": 0.05308268591761589,
    "learning_rate": 0.001
  },
  {
    "episode": 9245,
    "reward": 88.941969,
    "length": 65,
    "time": 136778.687234,
    "actor_loss": -68.70732116699219,
    "critic_loss": 8.569721221923828,
    "ent_coef": 0.0542447455227375,
    "learning_rate": 0.001
  },
  {
    "episode": 9246,
    "reward": 89.501323,
    "length": 66,
    "time": 136792.980447,
    "actor_loss": -69.40352630615234,
    "critic_loss": 46.30592727661133,
    "ent_coef": 0.05640026926994324,
    "learning_rate": 0.001
  },
  {
    "episode": 9247,
    "reward": 86.052613,
    "length": 71,
    "time": 136805.167178,
    "actor_loss": -67.77055358886719,
    "critic_loss": 8.077882766723633,
    "ent_coef": 0.0574454739689827,
    "learning_rate": 0.001
  },
  {
    "episode": 9248,
    "reward": 86.764223,
    "length": 69,
    "time": 136818.403039,
    "actor_loss": -63.32443618774414,
    "critic_loss": 3.3585643768310547,
    "ent_coef": 0.05781705677509308,
    "learning_rate": 0.001
  },
  {
    "episode": 9249,
    "reward": 89.607718,
    "length": 65,
    "time": 136829.846321,
    "actor_loss": -67.43456268310547,
    "critic_loss": 3.4801900386810303,
    "ent_coef": 0.05835190415382385,
    "learning_rate": 0.001
  },
  {
    "episode": 9250,
    "reward": 89.68115,
    "length": 65,
    "time": 136841.604203,
    "actor_loss": -71.54063415527344,
    "critic_loss": 8.410797119140625,
    "ent_coef": 0.059742800891399384,
    "learning_rate": 0.001
  },
  {
    "episode": 9251,
    "reward": 88.389354,
    "length": 67,
    "time": 136853.561819,
    "actor_loss": -68.14874267578125,
    "critic_loss": 1.681095838546753,
    "ent_coef": 0.059583213180303574,
    "learning_rate": 0.001
  },
  {
    "episode": 9252,
    "reward": -158.576036,
    "length": 133,
    "time": 136875.000215,
    "actor_loss": -64.6962890625,
    "critic_loss": 57.83263397216797,
    "ent_coef": 0.057007454335689545,
    "learning_rate": 0.001
  },
  {
    "episode": 9253,
    "reward": 84.541812,
    "length": 73,
    "time": 136891.397532,
    "actor_loss": -70.26760864257812,
    "critic_loss": 8.35489273071289,
    "ent_coef": 0.05526972562074661,
    "learning_rate": 0.001
  },
  {
    "episode": 9254,
    "reward": 88.719066,
    "length": 67,
    "time": 136904.150662,
    "actor_loss": -70.70407104492188,
    "critic_loss": 21.0435791015625,
    "ent_coef": 0.05287327617406845,
    "learning_rate": 0.001
  },
  {
    "episode": 9255,
    "reward": 89.852231,
    "length": 65,
    "time": 136916.073217,
    "actor_loss": -73.16178894042969,
    "critic_loss": 3.538947582244873,
    "ent_coef": 0.05253724008798599,
    "learning_rate": 0.001
  },
  {
    "episode": 9256,
    "reward": 89.325288,
    "length": 65,
    "time": 136928.616108,
    "actor_loss": -67.7540283203125,
    "critic_loss": 4.378913879394531,
    "ent_coef": 0.05278254300355911,
    "learning_rate": 0.001
  },
  {
    "episode": 9257,
    "reward": -155.132648,
    "length": 124,
    "time": 136951.721787,
    "actor_loss": -69.65623474121094,
    "critic_loss": 9.061767578125,
    "ent_coef": 0.05750029534101486,
    "learning_rate": 0.001
  },
  {
    "episode": 9258,
    "reward": -165.603051,
    "length": 165,
    "time": 136982.544777,
    "actor_loss": -70.4530258178711,
    "critic_loss": 3.2244598865509033,
    "ent_coef": 0.06102769449353218,
    "learning_rate": 0.001
  },
  {
    "episode": 9259,
    "reward": 41.984667,
    "length": 118,
    "time": 137005.280491,
    "actor_loss": -68.18185424804688,
    "critic_loss": 42.76683044433594,
    "ent_coef": 0.05837664380669594,
    "learning_rate": 0.001
  },
  {
    "episode": 9260,
    "reward": 87.563427,
    "length": 65,
    "time": 137020.41257,
    "actor_loss": -68.07999420166016,
    "critic_loss": 11.813394546508789,
    "ent_coef": 0.061003852635622025,
    "learning_rate": 0.001
  },
  {
    "episode": 9261,
    "reward": 85.996339,
    "length": 62,
    "time": 137035.52971,
    "actor_loss": -66.61885070800781,
    "critic_loss": 4.396404266357422,
    "ent_coef": 0.06442226469516754,
    "learning_rate": 0.001
  },
  {
    "episode": 9262,
    "reward": 90.014047,
    "length": 64,
    "time": 137050.044902,
    "actor_loss": -70.86483764648438,
    "critic_loss": 25.167762756347656,
    "ent_coef": 0.06425650417804718,
    "learning_rate": 0.001
  },
  {
    "episode": 9263,
    "reward": 89.254223,
    "length": 66,
    "time": 137061.993511,
    "actor_loss": -66.66143798828125,
    "critic_loss": 3.2545175552368164,
    "ent_coef": 0.06324125081300735,
    "learning_rate": 0.001
  },
  {
    "episode": 9264,
    "reward": 90.539027,
    "length": 63,
    "time": 137074.98038,
    "actor_loss": -73.62660217285156,
    "critic_loss": 9.593650817871094,
    "ent_coef": 0.0641496405005455,
    "learning_rate": 0.001
  },
  {
    "episode": 9265,
    "reward": 91.591866,
    "length": 61,
    "time": 137088.218944,
    "actor_loss": -70.39382934570312,
    "critic_loss": 1.5737619400024414,
    "ent_coef": 0.0654703825712204,
    "learning_rate": 0.001
  },
  {
    "episode": 9266,
    "reward": 89.548439,
    "length": 65,
    "time": 137100.094909,
    "actor_loss": -68.66957092285156,
    "critic_loss": 9.501046180725098,
    "ent_coef": 0.06595546752214432,
    "learning_rate": 0.001
  },
  {
    "episode": 9267,
    "reward": 87.555257,
    "length": 66,
    "time": 137114.54143,
    "actor_loss": -69.93915557861328,
    "critic_loss": 2.4597151279449463,
    "ent_coef": 0.06614672392606735,
    "learning_rate": 0.001
  },
  {
    "episode": 9268,
    "reward": 88.866368,
    "length": 65,
    "time": 137126.650114,
    "actor_loss": -71.18278503417969,
    "critic_loss": 2.606780529022217,
    "ent_coef": 0.06628318876028061,
    "learning_rate": 0.001
  },
  {
    "episode": 9269,
    "reward": 88.546897,
    "length": 66,
    "time": 137139.017606,
    "actor_loss": -73.82340240478516,
    "critic_loss": 10.346314430236816,
    "ent_coef": 0.06591140478849411,
    "learning_rate": 0.001
  },
  {
    "episode": 9270,
    "reward": 86.451453,
    "length": 70,
    "time": 137152.267262,
    "actor_loss": -65.64541625976562,
    "critic_loss": 67.04283905029297,
    "ent_coef": 0.05979056656360626,
    "learning_rate": 0.001
  },
  {
    "episode": 9271,
    "reward": 83.244851,
    "length": 78,
    "time": 137167.641383,
    "actor_loss": -65.07576751708984,
    "critic_loss": 4.406302452087402,
    "ent_coef": 0.0567159578204155,
    "learning_rate": 0.001
  },
  {
    "episode": 9272,
    "reward": 88.941574,
    "length": 66,
    "time": 137179.728076,
    "actor_loss": -72.25094604492188,
    "critic_loss": 3.830714702606201,
    "ent_coef": 0.05539999157190323,
    "learning_rate": 0.001
  },
  {
    "episode": 9273,
    "reward": 89.446892,
    "length": 65,
    "time": 137192.329063,
    "actor_loss": -68.0583724975586,
    "critic_loss": 4.334818363189697,
    "ent_coef": 0.0563085712492466,
    "learning_rate": 0.001
  },
  {
    "episode": 9274,
    "reward": 87.760359,
    "length": 68,
    "time": 137205.119112,
    "actor_loss": -67.35247039794922,
    "critic_loss": 7.540434837341309,
    "ent_coef": 0.055000681430101395,
    "learning_rate": 0.001
  },
  {
    "episode": 9275,
    "reward": 88.77152,
    "length": 65,
    "time": 137219.589076,
    "actor_loss": -67.73206329345703,
    "critic_loss": 2.9317283630371094,
    "ent_coef": 0.05302144214510918,
    "learning_rate": 0.001
  },
  {
    "episode": 9276,
    "reward": 88.85208,
    "length": 65,
    "time": 137232.839148,
    "actor_loss": -65.87884521484375,
    "critic_loss": 7.7564239501953125,
    "ent_coef": 0.052691418677568436,
    "learning_rate": 0.001
  },
  {
    "episode": 9277,
    "reward": 88.100241,
    "length": 67,
    "time": 137245.928036,
    "actor_loss": -69.29054260253906,
    "critic_loss": 2.049058675765991,
    "ent_coef": 0.05095614120364189,
    "learning_rate": 0.001
  },
  {
    "episode": 9278,
    "reward": 90.409723,
    "length": 64,
    "time": 137257.927795,
    "actor_loss": -73.19039916992188,
    "critic_loss": 3.3321213722229004,
    "ent_coef": 0.05224617198109627,
    "learning_rate": 0.001
  },
  {
    "episode": 9279,
    "reward": 77.604583,
    "length": 102,
    "time": 137275.238379,
    "actor_loss": -72.16726684570312,
    "critic_loss": 2.9245264530181885,
    "ent_coef": 0.0541190505027771,
    "learning_rate": 0.001
  },
  {
    "episode": 9280,
    "reward": 83.498217,
    "length": 76,
    "time": 137289.89343,
    "actor_loss": -69.71183776855469,
    "critic_loss": 2.21107816696167,
    "ent_coef": 0.049662623554468155,
    "learning_rate": 0.001
  },
  {
    "episode": 9281,
    "reward": 89.602837,
    "length": 62,
    "time": 137303.788692,
    "actor_loss": -71.92179107666016,
    "critic_loss": 2.6782383918762207,
    "ent_coef": 0.04804832488298416,
    "learning_rate": 0.001
  },
  {
    "episode": 9282,
    "reward": 90.619751,
    "length": 63,
    "time": 137316.021842,
    "actor_loss": -73.96479797363281,
    "critic_loss": 36.83880615234375,
    "ent_coef": 0.047998543828725815,
    "learning_rate": 0.001
  },
  {
    "episode": 9283,
    "reward": 89.607554,
    "length": 63,
    "time": 137327.924913,
    "actor_loss": -64.36175537109375,
    "critic_loss": 5.005331993103027,
    "ent_coef": 0.0504680797457695,
    "learning_rate": 0.001
  },
  {
    "episode": 9284,
    "reward": 89.463444,
    "length": 65,
    "time": 137340.728985,
    "actor_loss": -78.58786010742188,
    "critic_loss": 2.37045955657959,
    "ent_coef": 0.05018029361963272,
    "learning_rate": 0.001
  },
  {
    "episode": 9285,
    "reward": 89.253186,
    "length": 64,
    "time": 137355.659943,
    "actor_loss": -70.76667785644531,
    "critic_loss": 14.504026412963867,
    "ent_coef": 0.05191216617822647,
    "learning_rate": 0.001
  },
  {
    "episode": 9286,
    "reward": 88.454956,
    "length": 67,
    "time": 137367.61789,
    "actor_loss": -70.38904571533203,
    "critic_loss": 16.44385528564453,
    "ent_coef": 0.051912713795900345,
    "learning_rate": 0.001
  },
  {
    "episode": 9287,
    "reward": 86.297098,
    "length": 72,
    "time": 137380.818312,
    "actor_loss": -72.21684265136719,
    "critic_loss": 51.65221405029297,
    "ent_coef": 0.0522853285074234,
    "learning_rate": 0.001
  },
  {
    "episode": 9288,
    "reward": 86.561055,
    "length": 70,
    "time": 137396.029647,
    "actor_loss": -68.12348175048828,
    "critic_loss": 3.148036479949951,
    "ent_coef": 0.05532383173704147,
    "learning_rate": 0.001
  },
  {
    "episode": 9289,
    "reward": 89.0551,
    "length": 66,
    "time": 137410.142499,
    "actor_loss": -67.47362518310547,
    "critic_loss": 42.4816780090332,
    "ent_coef": 0.0517171286046505,
    "learning_rate": 0.001
  },
  {
    "episode": 9290,
    "reward": 88.989406,
    "length": 65,
    "time": 137421.984272,
    "actor_loss": -68.72264862060547,
    "critic_loss": 3.3014819622039795,
    "ent_coef": 0.05139962583780289,
    "learning_rate": 0.001
  },
  {
    "episode": 9291,
    "reward": 90.046059,
    "length": 64,
    "time": 137434.340021,
    "actor_loss": -71.45111083984375,
    "critic_loss": 112.18440246582031,
    "ent_coef": 0.05306871235370636,
    "learning_rate": 0.001
  },
  {
    "episode": 9292,
    "reward": 89.408078,
    "length": 64,
    "time": 137447.241622,
    "actor_loss": -65.21910095214844,
    "critic_loss": 1.4701694250106812,
    "ent_coef": 0.0512806735932827,
    "learning_rate": 0.001
  },
  {
    "episode": 9293,
    "reward": 85.293805,
    "length": 72,
    "time": 137461.618115,
    "actor_loss": -70.52961730957031,
    "critic_loss": 2.8899760246276855,
    "ent_coef": 0.048340804874897,
    "learning_rate": 0.001
  },
  {
    "episode": 9294,
    "reward": 86.254641,
    "length": 73,
    "time": 137474.508906,
    "actor_loss": -70.60431671142578,
    "critic_loss": 5.631429672241211,
    "ent_coef": 0.046871982514858246,
    "learning_rate": 0.001
  },
  {
    "episode": 9295,
    "reward": 87.056042,
    "length": 69,
    "time": 137488.269122,
    "actor_loss": -68.23951721191406,
    "critic_loss": 5.2639312744140625,
    "ent_coef": 0.045908547937870026,
    "learning_rate": 0.001
  },
  {
    "episode": 9296,
    "reward": 84.783536,
    "length": 75,
    "time": 137502.332483,
    "actor_loss": -69.4838638305664,
    "critic_loss": 3.294826030731201,
    "ent_coef": 0.04321246221661568,
    "learning_rate": 0.001
  },
  {
    "episode": 9297,
    "reward": 89.440437,
    "length": 65,
    "time": 137515.086087,
    "actor_loss": -66.39444732666016,
    "critic_loss": 3.1607093811035156,
    "ent_coef": 0.04444903880357742,
    "learning_rate": 0.001
  },
  {
    "episode": 9298,
    "reward": 87.621532,
    "length": 69,
    "time": 137527.969918,
    "actor_loss": -75.20375061035156,
    "critic_loss": 4.408580780029297,
    "ent_coef": 0.04646771028637886,
    "learning_rate": 0.001
  },
  {
    "episode": 9299,
    "reward": 89.901981,
    "length": 63,
    "time": 137541.308711,
    "actor_loss": -71.13058471679688,
    "critic_loss": 27.31246566772461,
    "ent_coef": 0.048238348215818405,
    "learning_rate": 0.001
  },
  {
    "episode": 9300,
    "reward": 90.558751,
    "length": 63,
    "time": 137552.454067,
    "actor_loss": -69.79849243164062,
    "critic_loss": 24.476736068725586,
    "ent_coef": 0.04972009360790253,
    "learning_rate": 0.001
  },
  {
    "episode": 9301,
    "reward": 90.343062,
    "length": 62,
    "time": 137565.693128,
    "actor_loss": -62.58514404296875,
    "critic_loss": 3.9232890605926514,
    "ent_coef": 0.05070709437131882,
    "learning_rate": 0.001
  },
  {
    "episode": 9302,
    "reward": 88.519668,
    "length": 66,
    "time": 137577.201615,
    "actor_loss": -73.88964080810547,
    "critic_loss": 3.5417287349700928,
    "ent_coef": 0.05078468471765518,
    "learning_rate": 0.001
  },
  {
    "episode": 9303,
    "reward": 89.405571,
    "length": 70,
    "time": 137592.116241,
    "actor_loss": -69.0460205078125,
    "critic_loss": 12.872342109680176,
    "ent_coef": 0.05300459265708923,
    "learning_rate": 0.001
  },
  {
    "episode": 9304,
    "reward": 88.219929,
    "length": 67,
    "time": 137604.815599,
    "actor_loss": -69.53844451904297,
    "critic_loss": 4.721870422363281,
    "ent_coef": 0.05431966856122017,
    "learning_rate": 0.001
  },
  {
    "episode": 9305,
    "reward": 87.219429,
    "length": 68,
    "time": 137618.033656,
    "actor_loss": -66.44931030273438,
    "critic_loss": 2.773730993270874,
    "ent_coef": 0.055566150695085526,
    "learning_rate": 0.001
  },
  {
    "episode": 9306,
    "reward": 86.553087,
    "length": 72,
    "time": 137632.894199,
    "actor_loss": -74.35279846191406,
    "critic_loss": 3.8999650478363037,
    "ent_coef": 0.054021451622247696,
    "learning_rate": 0.001
  },
  {
    "episode": 9307,
    "reward": 86.066317,
    "length": 70,
    "time": 137646.119392,
    "actor_loss": -71.10558319091797,
    "critic_loss": 9.475197792053223,
    "ent_coef": 0.052786439657211304,
    "learning_rate": 0.001
  },
  {
    "episode": 9308,
    "reward": 88.36252,
    "length": 66,
    "time": 137658.769431,
    "actor_loss": -69.27488708496094,
    "critic_loss": 3.106365203857422,
    "ent_coef": 0.05341104045510292,
    "learning_rate": 0.001
  },
  {
    "episode": 9309,
    "reward": 88.553802,
    "length": 66,
    "time": 137672.282654,
    "actor_loss": -66.15950012207031,
    "critic_loss": 3.3242461681365967,
    "ent_coef": 0.053440194576978683,
    "learning_rate": 0.001
  },
  {
    "episode": 9310,
    "reward": 89.295508,
    "length": 66,
    "time": 137683.952421,
    "actor_loss": -69.75914764404297,
    "critic_loss": 44.28444290161133,
    "ent_coef": 0.055289413779973984,
    "learning_rate": 0.001
  },
  {
    "episode": 9311,
    "reward": 88.537725,
    "length": 66,
    "time": 137696.469661,
    "actor_loss": -66.97537231445312,
    "critic_loss": 3.7572789192199707,
    "ent_coef": 0.05732077360153198,
    "learning_rate": 0.001
  },
  {
    "episode": 9312,
    "reward": 78.200004,
    "length": 87,
    "time": 137710.951976,
    "actor_loss": -71.87042236328125,
    "critic_loss": 23.070354461669922,
    "ent_coef": 0.06037294119596481,
    "learning_rate": 0.001
  },
  {
    "episode": 9313,
    "reward": 89.01468,
    "length": 65,
    "time": 137723.345993,
    "actor_loss": -67.39460754394531,
    "critic_loss": 6.216684341430664,
    "ent_coef": 0.06029700115323067,
    "learning_rate": 0.001
  },
  {
    "episode": 9314,
    "reward": 89.470606,
    "length": 65,
    "time": 137735.304296,
    "actor_loss": -71.87499237060547,
    "critic_loss": 2.3252296447753906,
    "ent_coef": 0.06015467643737793,
    "learning_rate": 0.001
  },
  {
    "episode": 9315,
    "reward": 86.730479,
    "length": 73,
    "time": 137749.979402,
    "actor_loss": -64.59838104248047,
    "critic_loss": 3.2866032123565674,
    "ent_coef": 0.05850741267204285,
    "learning_rate": 0.001
  },
  {
    "episode": 9316,
    "reward": 88.815355,
    "length": 66,
    "time": 137763.746654,
    "actor_loss": -64.57543182373047,
    "critic_loss": 452.16949462890625,
    "ent_coef": 0.055651307106018066,
    "learning_rate": 0.001
  },
  {
    "episode": 9317,
    "reward": 89.089772,
    "length": 66,
    "time": 137777.445442,
    "actor_loss": -67.87860107421875,
    "critic_loss": 16.461687088012695,
    "ent_coef": 0.05430552735924721,
    "learning_rate": 0.001
  },
  {
    "episode": 9318,
    "reward": 88.481065,
    "length": 66,
    "time": 137789.967149,
    "actor_loss": -67.62496185302734,
    "critic_loss": 2.4824533462524414,
    "ent_coef": 0.05402471125125885,
    "learning_rate": 0.001
  },
  {
    "episode": 9319,
    "reward": 89.577116,
    "length": 64,
    "time": 137805.658257,
    "actor_loss": -72.5484619140625,
    "critic_loss": 3.0659372806549072,
    "ent_coef": 0.055720824748277664,
    "learning_rate": 0.001
  },
  {
    "episode": 9320,
    "reward": 89.527401,
    "length": 65,
    "time": 137820.737304,
    "actor_loss": -67.98104858398438,
    "critic_loss": 5.911838531494141,
    "ent_coef": 0.05988176539540291,
    "learning_rate": 0.001
  },
  {
    "episode": 9321,
    "reward": 86.967486,
    "length": 71,
    "time": 137835.506696,
    "actor_loss": -69.16046142578125,
    "critic_loss": 2.3829479217529297,
    "ent_coef": 0.06189235299825668,
    "learning_rate": 0.001
  },
  {
    "episode": 9322,
    "reward": 88.383319,
    "length": 66,
    "time": 137847.375398,
    "actor_loss": -66.27235412597656,
    "critic_loss": 23.137409210205078,
    "ent_coef": 0.060571327805519104,
    "learning_rate": 0.001
  },
  {
    "episode": 9323,
    "reward": 86.168983,
    "length": 70,
    "time": 137863.340629,
    "actor_loss": -67.32826232910156,
    "critic_loss": 4.065430641174316,
    "ent_coef": 0.059490520507097244,
    "learning_rate": 0.001
  },
  {
    "episode": 9324,
    "reward": 90.902384,
    "length": 62,
    "time": 137874.679462,
    "actor_loss": -77.35042572021484,
    "critic_loss": 6.074944496154785,
    "ent_coef": 0.061335377395153046,
    "learning_rate": 0.001
  },
  {
    "episode": 9325,
    "reward": 91.582174,
    "length": 61,
    "time": 137886.2743,
    "actor_loss": -65.18498229980469,
    "critic_loss": 28.80072593688965,
    "ent_coef": 0.06413333863019943,
    "learning_rate": 0.001
  },
  {
    "episode": 9326,
    "reward": 89.620887,
    "length": 65,
    "time": 137898.722456,
    "actor_loss": -70.28850555419922,
    "critic_loss": 2.188051700592041,
    "ent_coef": 0.06398902088403702,
    "learning_rate": 0.001
  },
  {
    "episode": 9327,
    "reward": 89.857101,
    "length": 65,
    "time": 137912.557776,
    "actor_loss": -63.58186721801758,
    "critic_loss": 5.736534118652344,
    "ent_coef": 0.06511848419904709,
    "learning_rate": 0.001
  },
  {
    "episode": 9328,
    "reward": 91.858387,
    "length": 62,
    "time": 137924.005224,
    "actor_loss": -72.05014038085938,
    "critic_loss": 2.5205936431884766,
    "ent_coef": 0.0669211596250534,
    "learning_rate": 0.001
  },
  {
    "episode": 9329,
    "reward": 83.271398,
    "length": 73,
    "time": 137939.505698,
    "actor_loss": -72.32616424560547,
    "critic_loss": 4.9393110275268555,
    "ent_coef": 0.06527642905712128,
    "learning_rate": 0.001
  },
  {
    "episode": 9330,
    "reward": -172.060908,
    "length": 196,
    "time": 137972.356961,
    "actor_loss": -66.44500732421875,
    "critic_loss": 26.442550659179688,
    "ent_coef": 0.05512802675366402,
    "learning_rate": 0.001
  },
  {
    "episode": 9331,
    "reward": 88.559566,
    "length": 65,
    "time": 137987.728034,
    "actor_loss": -72.63040161132812,
    "critic_loss": 103.73228454589844,
    "ent_coef": 0.055532924830913544,
    "learning_rate": 0.001
  },
  {
    "episode": 9332,
    "reward": 90.809631,
    "length": 62,
    "time": 138000.366739,
    "actor_loss": -71.70234680175781,
    "critic_loss": 4.542925834655762,
    "ent_coef": 0.05814923718571663,
    "learning_rate": 0.001
  },
  {
    "episode": 9333,
    "reward": 88.408697,
    "length": 66,
    "time": 138012.783817,
    "actor_loss": -71.49120330810547,
    "critic_loss": 64.2393798828125,
    "ent_coef": 0.05861160531640053,
    "learning_rate": 0.001
  },
  {
    "episode": 9334,
    "reward": 88.869023,
    "length": 66,
    "time": 138024.646245,
    "actor_loss": -68.79643249511719,
    "critic_loss": 15.8490571975708,
    "ent_coef": 0.059551455080509186,
    "learning_rate": 0.001
  },
  {
    "episode": 9335,
    "reward": 86.960763,
    "length": 70,
    "time": 138037.944529,
    "actor_loss": -69.99726104736328,
    "critic_loss": 22.871719360351562,
    "ent_coef": 0.05841519683599472,
    "learning_rate": 0.001
  },
  {
    "episode": 9336,
    "reward": 86.003771,
    "length": 71,
    "time": 138051.263845,
    "actor_loss": -76.87783813476562,
    "critic_loss": 10.554158210754395,
    "ent_coef": 0.05793255940079689,
    "learning_rate": 0.001
  },
  {
    "episode": 9337,
    "reward": 91.536461,
    "length": 60,
    "time": 138063.291804,
    "actor_loss": -67.76953887939453,
    "critic_loss": 4.542973518371582,
    "ent_coef": 0.05915383622050285,
    "learning_rate": 0.001
  },
  {
    "episode": 9338,
    "reward": 91.969649,
    "length": 60,
    "time": 138075.224062,
    "actor_loss": -70.376220703125,
    "critic_loss": 4.001919746398926,
    "ent_coef": 0.06012716144323349,
    "learning_rate": 0.001
  },
  {
    "episode": 9339,
    "reward": 89.280736,
    "length": 64,
    "time": 138087.677021,
    "actor_loss": -70.62548828125,
    "critic_loss": 17.529516220092773,
    "ent_coef": 0.06142731010913849,
    "learning_rate": 0.001
  },
  {
    "episode": 9340,
    "reward": 89.719893,
    "length": 64,
    "time": 138099.670603,
    "actor_loss": -63.88188552856445,
    "critic_loss": 21.731807708740234,
    "ent_coef": 0.06311140209436417,
    "learning_rate": 0.001
  },
  {
    "episode": 9341,
    "reward": 89.42457,
    "length": 66,
    "time": 138114.663807,
    "actor_loss": -70.7567138671875,
    "critic_loss": 33.86185836791992,
    "ent_coef": 0.06325560808181763,
    "learning_rate": 0.001
  },
  {
    "episode": 9342,
    "reward": 83.48002,
    "length": 74,
    "time": 138127.371896,
    "actor_loss": -69.92768859863281,
    "critic_loss": 8.625531196594238,
    "ent_coef": 0.06250655651092529,
    "learning_rate": 0.001
  },
  {
    "episode": 9343,
    "reward": 90.150931,
    "length": 64,
    "time": 138139.852386,
    "actor_loss": -70.09371185302734,
    "critic_loss": 8.869706153869629,
    "ent_coef": 0.06216512992978096,
    "learning_rate": 0.001
  },
  {
    "episode": 9344,
    "reward": 90.95406,
    "length": 61,
    "time": 138151.567124,
    "actor_loss": -66.08537292480469,
    "critic_loss": 4.312414169311523,
    "ent_coef": 0.06623052060604095,
    "learning_rate": 0.001
  },
  {
    "episode": 9345,
    "reward": 88.828248,
    "length": 67,
    "time": 138163.385576,
    "actor_loss": -67.66127014160156,
    "critic_loss": 4.131739616394043,
    "ent_coef": 0.06604345887899399,
    "learning_rate": 0.001
  },
  {
    "episode": 9346,
    "reward": 87.249125,
    "length": 68,
    "time": 138175.334052,
    "actor_loss": -67.93228149414062,
    "critic_loss": 2.264284133911133,
    "ent_coef": 0.06781362742185593,
    "learning_rate": 0.001
  },
  {
    "episode": 9347,
    "reward": 89.008935,
    "length": 65,
    "time": 138186.874847,
    "actor_loss": -78.23106384277344,
    "critic_loss": 12.352863311767578,
    "ent_coef": 0.06874512881040573,
    "learning_rate": 0.001
  },
  {
    "episode": 9348,
    "reward": 86.534648,
    "length": 69,
    "time": 138201.599397,
    "actor_loss": -65.97990417480469,
    "critic_loss": 6.598913192749023,
    "ent_coef": 0.06540482491254807,
    "learning_rate": 0.001
  },
  {
    "episode": 9349,
    "reward": 78.388479,
    "length": 81,
    "time": 138215.749206,
    "actor_loss": -67.81803894042969,
    "critic_loss": 2.9894046783447266,
    "ent_coef": 0.06095101684331894,
    "learning_rate": 0.001
  },
  {
    "episode": 9350,
    "reward": 72.050536,
    "length": 99,
    "time": 138233.307298,
    "actor_loss": -69.67015838623047,
    "critic_loss": 103.58906555175781,
    "ent_coef": 0.055994778871536255,
    "learning_rate": 0.001
  },
  {
    "episode": 9351,
    "reward": 10.166414,
    "length": 217,
    "time": 138265.108006,
    "actor_loss": -74.27606964111328,
    "critic_loss": 6.814106464385986,
    "ent_coef": 0.05557563528418541,
    "learning_rate": 0.001
  },
  {
    "episode": 9352,
    "reward": 89.590116,
    "length": 66,
    "time": 138277.032152,
    "actor_loss": -67.6875228881836,
    "critic_loss": 13.9772310256958,
    "ent_coef": 0.05680158734321594,
    "learning_rate": 0.001
  },
  {
    "episode": 9353,
    "reward": 88.26566,
    "length": 67,
    "time": 138291.250736,
    "actor_loss": -72.71772003173828,
    "critic_loss": 53.84309387207031,
    "ent_coef": 0.057929232716560364,
    "learning_rate": 0.001
  },
  {
    "episode": 9354,
    "reward": 68.838613,
    "length": 104,
    "time": 138309.999614,
    "actor_loss": -69.06246948242188,
    "critic_loss": 3.396293878555298,
    "ent_coef": 0.05776761844754219,
    "learning_rate": 0.001
  },
  {
    "episode": 9355,
    "reward": 91.979262,
    "length": 60,
    "time": 138320.912722,
    "actor_loss": -69.85975646972656,
    "critic_loss": 11.554262161254883,
    "ent_coef": 0.06341675668954849,
    "learning_rate": 0.001
  },
  {
    "episode": 9356,
    "reward": 89.903752,
    "length": 63,
    "time": 138334.67081,
    "actor_loss": -69.5694580078125,
    "critic_loss": 3.1167209148406982,
    "ent_coef": 0.06858785450458527,
    "learning_rate": 0.001
  },
  {
    "episode": 9357,
    "reward": 81.403117,
    "length": 79,
    "time": 138349.385237,
    "actor_loss": -75.26555633544922,
    "critic_loss": 2.474583148956299,
    "ent_coef": 0.07060148566961288,
    "learning_rate": 0.001
  },
  {
    "episode": 9358,
    "reward": 89.623281,
    "length": 64,
    "time": 138362.044698,
    "actor_loss": -68.65061950683594,
    "critic_loss": 4.099743366241455,
    "ent_coef": 0.06924170255661011,
    "learning_rate": 0.001
  },
  {
    "episode": 9359,
    "reward": 88.793021,
    "length": 66,
    "time": 138374.524848,
    "actor_loss": -69.88096618652344,
    "critic_loss": 3.2375988960266113,
    "ent_coef": 0.06960891932249069,
    "learning_rate": 0.001
  },
  {
    "episode": 9360,
    "reward": 86.725569,
    "length": 72,
    "time": 138388.751462,
    "actor_loss": -62.613258361816406,
    "critic_loss": 40.029075622558594,
    "ent_coef": 0.07219027727842331,
    "learning_rate": 0.001
  },
  {
    "episode": 9361,
    "reward": 89.394264,
    "length": 65,
    "time": 138400.607002,
    "actor_loss": -66.51081848144531,
    "critic_loss": 2.9697060585021973,
    "ent_coef": 0.07129323482513428,
    "learning_rate": 0.001
  },
  {
    "episode": 9362,
    "reward": 90.036398,
    "length": 65,
    "time": 138414.966687,
    "actor_loss": -64.29029083251953,
    "critic_loss": 34.72550964355469,
    "ent_coef": 0.0716133788228035,
    "learning_rate": 0.001
  },
  {
    "episode": 9363,
    "reward": 88.362253,
    "length": 67,
    "time": 138427.755748,
    "actor_loss": -62.83313751220703,
    "critic_loss": 2.3959457874298096,
    "ent_coef": 0.0705936998128891,
    "learning_rate": 0.001
  },
  {
    "episode": 9364,
    "reward": 89.602215,
    "length": 66,
    "time": 138439.58558,
    "actor_loss": -66.43663024902344,
    "critic_loss": 2.7655043601989746,
    "ent_coef": 0.06890394538640976,
    "learning_rate": 0.001
  },
  {
    "episode": 9365,
    "reward": 90.060069,
    "length": 64,
    "time": 138453.729601,
    "actor_loss": -70.76988220214844,
    "critic_loss": 31.312339782714844,
    "ent_coef": 0.06739763915538788,
    "learning_rate": 0.001
  },
  {
    "episode": 9366,
    "reward": 89.887733,
    "length": 65,
    "time": 138465.76832,
    "actor_loss": -69.25054931640625,
    "critic_loss": 2.9894025325775146,
    "ent_coef": 0.06600911170244217,
    "learning_rate": 0.001
  },
  {
    "episode": 9367,
    "reward": 89.297737,
    "length": 64,
    "time": 138477.349443,
    "actor_loss": -66.78471374511719,
    "critic_loss": 5.607981204986572,
    "ent_coef": 0.062331993132829666,
    "learning_rate": 0.001
  },
  {
    "episode": 9368,
    "reward": 87.138682,
    "length": 70,
    "time": 138493.354675,
    "actor_loss": -68.84192657470703,
    "critic_loss": 14.64523696899414,
    "ent_coef": 0.0574411079287529,
    "learning_rate": 0.001
  },
  {
    "episode": 9369,
    "reward": 89.72754,
    "length": 64,
    "time": 138507.482814,
    "actor_loss": -75.14700317382812,
    "critic_loss": 5.728422164916992,
    "ent_coef": 0.05493567883968353,
    "learning_rate": 0.001
  },
  {
    "episode": 9370,
    "reward": 88.538854,
    "length": 68,
    "time": 138522.044366,
    "actor_loss": -68.0112533569336,
    "critic_loss": 10.83913803100586,
    "ent_coef": 0.05402374640107155,
    "learning_rate": 0.001
  },
  {
    "episode": 9371,
    "reward": 90.775492,
    "length": 63,
    "time": 138533.639961,
    "actor_loss": -70.09333038330078,
    "critic_loss": 3.430408000946045,
    "ent_coef": 0.053189150989055634,
    "learning_rate": 0.001
  },
  {
    "episode": 9372,
    "reward": 89.028167,
    "length": 65,
    "time": 138545.083489,
    "actor_loss": -67.32586669921875,
    "critic_loss": 2.3617982864379883,
    "ent_coef": 0.053755320608615875,
    "learning_rate": 0.001
  },
  {
    "episode": 9373,
    "reward": 86.178502,
    "length": 68,
    "time": 138558.095697,
    "actor_loss": -71.56002807617188,
    "critic_loss": 2.392632007598877,
    "ent_coef": 0.05264225974678993,
    "learning_rate": 0.001
  },
  {
    "episode": 9374,
    "reward": 89.149497,
    "length": 66,
    "time": 138570.629298,
    "actor_loss": -72.2482681274414,
    "critic_loss": 25.39191436767578,
    "ent_coef": 0.05347300320863724,
    "learning_rate": 0.001
  },
  {
    "episode": 9375,
    "reward": 88.913564,
    "length": 65,
    "time": 138582.124518,
    "actor_loss": -67.42256164550781,
    "critic_loss": 3.6880886554718018,
    "ent_coef": 0.05481817573308945,
    "learning_rate": 0.001
  },
  {
    "episode": 9376,
    "reward": 89.556946,
    "length": 64,
    "time": 138596.221611,
    "actor_loss": -70.211181640625,
    "critic_loss": 3.3387389183044434,
    "ent_coef": 0.05428861454129219,
    "learning_rate": 0.001
  },
  {
    "episode": 9377,
    "reward": 89.51484,
    "length": 64,
    "time": 138607.749228,
    "actor_loss": -65.946533203125,
    "critic_loss": 9.986820220947266,
    "ent_coef": 0.055663809180259705,
    "learning_rate": 0.001
  },
  {
    "episode": 9378,
    "reward": 90.588205,
    "length": 63,
    "time": 138619.450137,
    "actor_loss": -69.35092163085938,
    "critic_loss": 1.5537891387939453,
    "ent_coef": 0.05664870887994766,
    "learning_rate": 0.001
  },
  {
    "episode": 9379,
    "reward": 89.818413,
    "length": 64,
    "time": 138630.788778,
    "actor_loss": -68.57295227050781,
    "critic_loss": 4.976066589355469,
    "ent_coef": 0.05919933691620827,
    "learning_rate": 0.001
  },
  {
    "episode": 9380,
    "reward": 89.072202,
    "length": 64,
    "time": 138643.167089,
    "actor_loss": -69.59136199951172,
    "critic_loss": 4.801153182983398,
    "ent_coef": 0.061596695333719254,
    "learning_rate": 0.001
  },
  {
    "episode": 9381,
    "reward": 89.257418,
    "length": 66,
    "time": 138656.389187,
    "actor_loss": -69.23036193847656,
    "critic_loss": 3.617729663848877,
    "ent_coef": 0.06276429444551468,
    "learning_rate": 0.001
  },
  {
    "episode": 9382,
    "reward": 89.963264,
    "length": 64,
    "time": 138669.703288,
    "actor_loss": -71.27955627441406,
    "critic_loss": 3.105785846710205,
    "ent_coef": 0.06217445433139801,
    "learning_rate": 0.001
  },
  {
    "episode": 9383,
    "reward": 82.861298,
    "length": 75,
    "time": 138682.941533,
    "actor_loss": -65.36991882324219,
    "critic_loss": 2.25551176071167,
    "ent_coef": 0.06180921196937561,
    "learning_rate": 0.001
  },
  {
    "episode": 9384,
    "reward": 88.863185,
    "length": 66,
    "time": 138694.904398,
    "actor_loss": -74.29828643798828,
    "critic_loss": 6.58165168762207,
    "ent_coef": 0.06153131648898125,
    "learning_rate": 0.001
  },
  {
    "episode": 9385,
    "reward": 88.699266,
    "length": 67,
    "time": 138707.050464,
    "actor_loss": -69.2699203491211,
    "critic_loss": 7.637239933013916,
    "ent_coef": 0.06023263558745384,
    "learning_rate": 0.001
  },
  {
    "episode": 9386,
    "reward": 88.74299,
    "length": 65,
    "time": 138719.122192,
    "actor_loss": -71.87454223632812,
    "critic_loss": 5.815354347229004,
    "ent_coef": 0.060418907552957535,
    "learning_rate": 0.001
  },
  {
    "episode": 9387,
    "reward": 86.135188,
    "length": 69,
    "time": 138731.568409,
    "actor_loss": -68.6766586303711,
    "critic_loss": 5.497176170349121,
    "ent_coef": 0.05929044261574745,
    "learning_rate": 0.001
  },
  {
    "episode": 9388,
    "reward": 89.735775,
    "length": 66,
    "time": 138743.175582,
    "actor_loss": -68.27587890625,
    "critic_loss": 3.9855241775512695,
    "ent_coef": 0.057438820600509644,
    "learning_rate": 0.001
  },
  {
    "episode": 9389,
    "reward": 86.815472,
    "length": 68,
    "time": 138755.406332,
    "actor_loss": -65.78455352783203,
    "critic_loss": 2.3132877349853516,
    "ent_coef": 0.05603304132819176,
    "learning_rate": 0.001
  },
  {
    "episode": 9390,
    "reward": 81.659786,
    "length": 78,
    "time": 138768.489118,
    "actor_loss": -63.13727951049805,
    "critic_loss": 3.537761926651001,
    "ent_coef": 0.055411167442798615,
    "learning_rate": 0.001
  },
  {
    "episode": 9391,
    "reward": 89.298927,
    "length": 65,
    "time": 138780.345231,
    "actor_loss": -67.56243896484375,
    "critic_loss": 64.9452133178711,
    "ent_coef": 0.055919911712408066,
    "learning_rate": 0.001
  },
  {
    "episode": 9392,
    "reward": 90.296867,
    "length": 63,
    "time": 138792.70553,
    "actor_loss": -70.55598449707031,
    "critic_loss": 131.3211212158203,
    "ent_coef": 0.053107280284166336,
    "learning_rate": 0.001
  },
  {
    "episode": 9393,
    "reward": 86.185752,
    "length": 71,
    "time": 138805.616924,
    "actor_loss": -68.62782287597656,
    "critic_loss": 2.330214500427246,
    "ent_coef": 0.05087602138519287,
    "learning_rate": 0.001
  },
  {
    "episode": 9394,
    "reward": 71.981678,
    "length": 98,
    "time": 138824.009993,
    "actor_loss": -70.5518798828125,
    "critic_loss": 7.920928955078125,
    "ent_coef": 0.0518844872713089,
    "learning_rate": 0.001
  },
  {
    "episode": 9395,
    "reward": 89.361211,
    "length": 66,
    "time": 138838.246666,
    "actor_loss": -63.063262939453125,
    "critic_loss": 3.868380069732666,
    "ent_coef": 0.048769328743219376,
    "learning_rate": 0.001
  },
  {
    "episode": 9396,
    "reward": 87.957416,
    "length": 71,
    "time": 138851.777908,
    "actor_loss": -65.18406677246094,
    "critic_loss": 5.063432216644287,
    "ent_coef": 0.04730841517448425,
    "learning_rate": 0.001
  },
  {
    "episode": 9397,
    "reward": 90.226597,
    "length": 63,
    "time": 138867.504223,
    "actor_loss": -68.94319152832031,
    "critic_loss": 25.462554931640625,
    "ent_coef": 0.050242986530065536,
    "learning_rate": 0.001
  },
  {
    "episode": 9398,
    "reward": 87.761123,
    "length": 68,
    "time": 138880.792384,
    "actor_loss": -70.82768249511719,
    "critic_loss": 2.663086175918579,
    "ent_coef": 0.051499463617801666,
    "learning_rate": 0.001
  },
  {
    "episode": 9399,
    "reward": 90.297128,
    "length": 62,
    "time": 138892.933547,
    "actor_loss": -63.641075134277344,
    "critic_loss": 18.668441772460938,
    "ent_coef": 0.05413427948951721,
    "learning_rate": 0.001
  },
  {
    "episode": 9400,
    "reward": 89.804162,
    "length": 66,
    "time": 138906.997688,
    "actor_loss": -66.15744018554688,
    "critic_loss": 2.6868813037872314,
    "ent_coef": 0.05251740291714668,
    "learning_rate": 0.001
  },
  {
    "episode": 9401,
    "reward": 88.278922,
    "length": 67,
    "time": 138920.627079,
    "actor_loss": -74.05178833007812,
    "critic_loss": 48.53116226196289,
    "ent_coef": 0.0514439195394516,
    "learning_rate": 0.001
  },
  {
    "episode": 9402,
    "reward": 85.531044,
    "length": 72,
    "time": 138934.57286,
    "actor_loss": -68.10147857666016,
    "critic_loss": 10.614519119262695,
    "ent_coef": 0.050669848918914795,
    "learning_rate": 0.001
  },
  {
    "episode": 9403,
    "reward": 87.895743,
    "length": 67,
    "time": 138946.349689,
    "actor_loss": -60.746246337890625,
    "critic_loss": 2.5400004386901855,
    "ent_coef": 0.05212761089205742,
    "learning_rate": 0.001
  },
  {
    "episode": 9404,
    "reward": 90.442664,
    "length": 66,
    "time": 138959.78694,
    "actor_loss": -65.10816192626953,
    "critic_loss": 8.34415340423584,
    "ent_coef": 0.05299646407365799,
    "learning_rate": 0.001
  },
  {
    "episode": 9405,
    "reward": 88.841225,
    "length": 67,
    "time": 138973.000441,
    "actor_loss": -66.40040588378906,
    "critic_loss": 3.8095316886901855,
    "ent_coef": 0.053122855722904205,
    "learning_rate": 0.001
  },
  {
    "episode": 9406,
    "reward": 89.65211,
    "length": 64,
    "time": 138984.210715,
    "actor_loss": -62.206260681152344,
    "critic_loss": 2.1153616905212402,
    "ent_coef": 0.05644925311207771,
    "learning_rate": 0.001
  },
  {
    "episode": 9407,
    "reward": 89.693169,
    "length": 64,
    "time": 138996.537062,
    "actor_loss": -67.07839965820312,
    "critic_loss": 3.400235176086426,
    "ent_coef": 0.06098403036594391,
    "learning_rate": 0.001
  },
  {
    "episode": 9408,
    "reward": 84.70546,
    "length": 71,
    "time": 139009.506369,
    "actor_loss": -64.71080017089844,
    "critic_loss": 21.27005386352539,
    "ent_coef": 0.06391164660453796,
    "learning_rate": 0.001
  },
  {
    "episode": 9409,
    "reward": 89.947022,
    "length": 64,
    "time": 139022.606306,
    "actor_loss": -63.58580780029297,
    "critic_loss": 3.164673328399658,
    "ent_coef": 0.06555155664682388,
    "learning_rate": 0.001
  },
  {
    "episode": 9410,
    "reward": 90.918526,
    "length": 62,
    "time": 139033.758387,
    "actor_loss": -70.23916625976562,
    "critic_loss": 12.016197204589844,
    "ent_coef": 0.06859900802373886,
    "learning_rate": 0.001
  },
  {
    "episode": 9411,
    "reward": 89.668751,
    "length": 65,
    "time": 139045.911981,
    "actor_loss": -67.80473327636719,
    "critic_loss": 3.0234262943267822,
    "ent_coef": 0.06657092273235321,
    "learning_rate": 0.001
  },
  {
    "episode": 9412,
    "reward": 88.657182,
    "length": 68,
    "time": 139057.937151,
    "actor_loss": -72.76033020019531,
    "critic_loss": 4.360177040100098,
    "ent_coef": 0.06473373621702194,
    "learning_rate": 0.001
  },
  {
    "episode": 9413,
    "reward": 89.742211,
    "length": 63,
    "time": 139069.125554,
    "actor_loss": -67.85047149658203,
    "critic_loss": 15.772626876831055,
    "ent_coef": 0.06651753932237625,
    "learning_rate": 0.001
  },
  {
    "episode": 9414,
    "reward": 87.711459,
    "length": 69,
    "time": 139081.644179,
    "actor_loss": -67.5174560546875,
    "critic_loss": 6.051270961761475,
    "ent_coef": 0.06491879373788834,
    "learning_rate": 0.001
  },
  {
    "episode": 9415,
    "reward": 86.652831,
    "length": 71,
    "time": 139095.249562,
    "actor_loss": -73.154052734375,
    "critic_loss": 2.405951499938965,
    "ent_coef": 0.06200931593775749,
    "learning_rate": 0.001
  },
  {
    "episode": 9416,
    "reward": 88.855658,
    "length": 65,
    "time": 139106.739821,
    "actor_loss": -64.93058776855469,
    "critic_loss": 3.6844539642333984,
    "ent_coef": 0.06349733471870422,
    "learning_rate": 0.001
  },
  {
    "episode": 9417,
    "reward": 85.340573,
    "length": 71,
    "time": 139119.014937,
    "actor_loss": -64.36618041992188,
    "critic_loss": 20.627384185791016,
    "ent_coef": 0.06246088445186615,
    "learning_rate": 0.001
  },
  {
    "episode": 9418,
    "reward": 90.424316,
    "length": 63,
    "time": 139130.351057,
    "actor_loss": -73.25650024414062,
    "critic_loss": 4.260787010192871,
    "ent_coef": 0.0635366216301918,
    "learning_rate": 0.001
  },
  {
    "episode": 9419,
    "reward": 89.624649,
    "length": 64,
    "time": 139143.646228,
    "actor_loss": -66.8822250366211,
    "critic_loss": 4.355935573577881,
    "ent_coef": 0.06563670933246613,
    "learning_rate": 0.001
  },
  {
    "episode": 9420,
    "reward": 88.850375,
    "length": 66,
    "time": 139155.831082,
    "actor_loss": -67.92756652832031,
    "critic_loss": 4.18536376953125,
    "ent_coef": 0.06212145462632179,
    "learning_rate": 0.001
  },
  {
    "episode": 9421,
    "reward": 88.115244,
    "length": 67,
    "time": 139169.660826,
    "actor_loss": -69.731689453125,
    "critic_loss": 6.097042083740234,
    "ent_coef": 0.06068258360028267,
    "learning_rate": 0.001
  },
  {
    "episode": 9422,
    "reward": 88.966933,
    "length": 66,
    "time": 139181.432877,
    "actor_loss": -67.05339050292969,
    "critic_loss": 84.14833068847656,
    "ent_coef": 0.05790088325738907,
    "learning_rate": 0.001
  },
  {
    "episode": 9423,
    "reward": 85.625683,
    "length": 71,
    "time": 139194.188709,
    "actor_loss": -73.00846099853516,
    "critic_loss": 16.20589828491211,
    "ent_coef": 0.05527196452021599,
    "learning_rate": 0.001
  },
  {
    "episode": 9424,
    "reward": 87.519186,
    "length": 68,
    "time": 139206.141463,
    "actor_loss": -72.94979858398438,
    "critic_loss": 4.654232025146484,
    "ent_coef": 0.05344092473387718,
    "learning_rate": 0.001
  },
  {
    "episode": 9425,
    "reward": 87.188346,
    "length": 68,
    "time": 139218.371035,
    "actor_loss": -70.10234832763672,
    "critic_loss": 2.7599990367889404,
    "ent_coef": 0.052088845521211624,
    "learning_rate": 0.001
  },
  {
    "episode": 9426,
    "reward": 85.961605,
    "length": 70,
    "time": 139230.26708,
    "actor_loss": -67.3779296875,
    "critic_loss": 2.4199278354644775,
    "ent_coef": 0.05405362322926521,
    "learning_rate": 0.001
  },
  {
    "episode": 9427,
    "reward": 90.750489,
    "length": 63,
    "time": 139241.60573,
    "actor_loss": -74.54328155517578,
    "critic_loss": 2.516230583190918,
    "ent_coef": 0.057259947061538696,
    "learning_rate": 0.001
  },
  {
    "episode": 9428,
    "reward": 88.571177,
    "length": 66,
    "time": 139257.884286,
    "actor_loss": -64.34536743164062,
    "critic_loss": 1.773141622543335,
    "ent_coef": 0.057899873703718185,
    "learning_rate": 0.001
  },
  {
    "episode": 9429,
    "reward": 83.949975,
    "length": 72,
    "time": 139273.685068,
    "actor_loss": -71.44884490966797,
    "critic_loss": 15.992778778076172,
    "ent_coef": 0.05875251069664955,
    "learning_rate": 0.001
  },
  {
    "episode": 9430,
    "reward": 87.897418,
    "length": 67,
    "time": 139285.436791,
    "actor_loss": -71.20780181884766,
    "critic_loss": 13.338743209838867,
    "ent_coef": 0.05863911658525467,
    "learning_rate": 0.001
  },
  {
    "episode": 9431,
    "reward": 88.637289,
    "length": 67,
    "time": 139305.215659,
    "actor_loss": -66.75382995605469,
    "critic_loss": 3.1708006858825684,
    "ent_coef": 0.06028267368674278,
    "learning_rate": 0.001
  },
  {
    "episode": 9432,
    "reward": 86.586258,
    "length": 69,
    "time": 139321.223032,
    "actor_loss": -70.99085998535156,
    "critic_loss": 36.120914459228516,
    "ent_coef": 0.062112726271152496,
    "learning_rate": 0.001
  },
  {
    "episode": 9433,
    "reward": 88.09169,
    "length": 68,
    "time": 139333.171736,
    "actor_loss": -65.35113525390625,
    "critic_loss": 6.973379611968994,
    "ent_coef": 0.05999847874045372,
    "learning_rate": 0.001
  },
  {
    "episode": 9434,
    "reward": 87.854393,
    "length": 68,
    "time": 139345.944018,
    "actor_loss": -63.53591537475586,
    "critic_loss": 2.925830364227295,
    "ent_coef": 0.05902707204222679,
    "learning_rate": 0.001
  },
  {
    "episode": 9435,
    "reward": 88.671497,
    "length": 66,
    "time": 139357.820462,
    "actor_loss": -72.33197021484375,
    "critic_loss": 3.946204900741577,
    "ent_coef": 0.05788173899054527,
    "learning_rate": 0.001
  },
  {
    "episode": 9436,
    "reward": 83.227734,
    "length": 75,
    "time": 139371.399302,
    "actor_loss": -69.07273864746094,
    "critic_loss": 2.956467390060425,
    "ent_coef": 0.05495104193687439,
    "learning_rate": 0.001
  },
  {
    "episode": 9437,
    "reward": 88.950752,
    "length": 66,
    "time": 139383.491354,
    "actor_loss": -72.4095458984375,
    "critic_loss": 4.3029327392578125,
    "ent_coef": 0.05464095249772072,
    "learning_rate": 0.001
  },
  {
    "episode": 9438,
    "reward": 85.855339,
    "length": 73,
    "time": 139395.995016,
    "actor_loss": -67.83157348632812,
    "critic_loss": 5.9624528884887695,
    "ent_coef": 0.05246705561876297,
    "learning_rate": 0.001
  },
  {
    "episode": 9439,
    "reward": 86.779489,
    "length": 70,
    "time": 139409.016003,
    "actor_loss": -77.1853256225586,
    "critic_loss": 3.339989185333252,
    "ent_coef": 0.050935275852680206,
    "learning_rate": 0.001
  },
  {
    "episode": 9440,
    "reward": 89.005986,
    "length": 66,
    "time": 139421.652911,
    "actor_loss": -70.1801986694336,
    "critic_loss": 3.0976195335388184,
    "ent_coef": 0.049152225255966187,
    "learning_rate": 0.001
  },
  {
    "episode": 9441,
    "reward": 90.013024,
    "length": 63,
    "time": 139433.242891,
    "actor_loss": -71.64201354980469,
    "critic_loss": 6.115843772888184,
    "ent_coef": 0.05031700059771538,
    "learning_rate": 0.001
  },
  {
    "episode": 9442,
    "reward": 87.816526,
    "length": 68,
    "time": 139446.113935,
    "actor_loss": -70.60969543457031,
    "critic_loss": 20.526790618896484,
    "ent_coef": 0.05037866160273552,
    "learning_rate": 0.001
  },
  {
    "episode": 9443,
    "reward": 85.673919,
    "length": 73,
    "time": 139458.765048,
    "actor_loss": -69.35550689697266,
    "critic_loss": 30.009981155395508,
    "ent_coef": 0.047820694744586945,
    "learning_rate": 0.001
  },
  {
    "episode": 9444,
    "reward": 89.421551,
    "length": 65,
    "time": 139472.124171,
    "actor_loss": -65.94256591796875,
    "critic_loss": 2.1225461959838867,
    "ent_coef": 0.04754575714468956,
    "learning_rate": 0.001
  },
  {
    "episode": 9445,
    "reward": 88.196527,
    "length": 70,
    "time": 139484.228657,
    "actor_loss": -69.84257507324219,
    "critic_loss": 4.179457187652588,
    "ent_coef": 0.047872498631477356,
    "learning_rate": 0.001
  },
  {
    "episode": 9446,
    "reward": 89.249166,
    "length": 67,
    "time": 139497.898414,
    "actor_loss": -67.54498291015625,
    "critic_loss": 8.283895492553711,
    "ent_coef": 0.049824055284261703,
    "learning_rate": 0.001
  },
  {
    "episode": 9447,
    "reward": 89.101483,
    "length": 65,
    "time": 139509.34804,
    "actor_loss": -69.22932434082031,
    "critic_loss": 2.9236695766448975,
    "ent_coef": 0.05270359292626381,
    "learning_rate": 0.001
  },
  {
    "episode": 9448,
    "reward": 89.338997,
    "length": 66,
    "time": 139520.911113,
    "actor_loss": -67.00456237792969,
    "critic_loss": 4.380785942077637,
    "ent_coef": 0.055698830634355545,
    "learning_rate": 0.001
  },
  {
    "episode": 9449,
    "reward": 90.612786,
    "length": 63,
    "time": 139532.430942,
    "actor_loss": -71.48001861572266,
    "critic_loss": 8.582193374633789,
    "ent_coef": 0.057408999651670456,
    "learning_rate": 0.001
  },
  {
    "episode": 9450,
    "reward": 89.311779,
    "length": 65,
    "time": 139544.869729,
    "actor_loss": -70.12931823730469,
    "critic_loss": 4.322255611419678,
    "ent_coef": 0.060036905109882355,
    "learning_rate": 0.001
  },
  {
    "episode": 9451,
    "reward": 88.152079,
    "length": 67,
    "time": 139557.872508,
    "actor_loss": -70.83857727050781,
    "critic_loss": 3.063236713409424,
    "ent_coef": 0.06076430901885033,
    "learning_rate": 0.001
  },
  {
    "episode": 9452,
    "reward": 87.499052,
    "length": 70,
    "time": 139572.024893,
    "actor_loss": -66.80742645263672,
    "critic_loss": 3.444912910461426,
    "ent_coef": 0.05750183388590813,
    "learning_rate": 0.001
  },
  {
    "episode": 9453,
    "reward": 79.249074,
    "length": 81,
    "time": 139585.48844,
    "actor_loss": -67.47278594970703,
    "critic_loss": 4.593818664550781,
    "ent_coef": 0.0535399504005909,
    "learning_rate": 0.001
  },
  {
    "episode": 9454,
    "reward": 85.540577,
    "length": 73,
    "time": 139597.91081,
    "actor_loss": -72.30723571777344,
    "critic_loss": 5.691237926483154,
    "ent_coef": 0.05051315203309059,
    "learning_rate": 0.001
  },
  {
    "episode": 9455,
    "reward": 89.127367,
    "length": 65,
    "time": 139610.312036,
    "actor_loss": -66.05580139160156,
    "critic_loss": 3.3607840538024902,
    "ent_coef": 0.04822368547320366,
    "learning_rate": 0.001
  },
  {
    "episode": 9456,
    "reward": 88.038669,
    "length": 68,
    "time": 139622.200492,
    "actor_loss": -70.0916748046875,
    "critic_loss": 13.17226791381836,
    "ent_coef": 0.0492091067135334,
    "learning_rate": 0.001
  },
  {
    "episode": 9457,
    "reward": 90.579945,
    "length": 62,
    "time": 139633.950753,
    "actor_loss": -67.44173431396484,
    "critic_loss": 2.548513412475586,
    "ent_coef": 0.04910137131810188,
    "learning_rate": 0.001
  },
  {
    "episode": 9458,
    "reward": 90.535496,
    "length": 63,
    "time": 139647.560404,
    "actor_loss": -65.17439270019531,
    "critic_loss": 2.3511641025543213,
    "ent_coef": 0.04881439357995987,
    "learning_rate": 0.001
  },
  {
    "episode": 9459,
    "reward": 89.947149,
    "length": 64,
    "time": 139659.672907,
    "actor_loss": -74.03053283691406,
    "critic_loss": 2.2039194107055664,
    "ent_coef": 0.04869154468178749,
    "learning_rate": 0.001
  },
  {
    "episode": 9460,
    "reward": 89.637276,
    "length": 64,
    "time": 139671.819315,
    "actor_loss": -68.78297424316406,
    "critic_loss": 29.274337768554688,
    "ent_coef": 0.04851364716887474,
    "learning_rate": 0.001
  },
  {
    "episode": 9461,
    "reward": 89.359302,
    "length": 64,
    "time": 139684.200428,
    "actor_loss": -66.70203399658203,
    "critic_loss": 42.13972473144531,
    "ent_coef": 0.050287339836359024,
    "learning_rate": 0.001
  },
  {
    "episode": 9462,
    "reward": 89.565237,
    "length": 64,
    "time": 139695.777313,
    "actor_loss": -61.72437286376953,
    "critic_loss": 4.940195083618164,
    "ent_coef": 0.0520508848130703,
    "learning_rate": 0.001
  },
  {
    "episode": 9463,
    "reward": 88.912474,
    "length": 66,
    "time": 139708.541472,
    "actor_loss": -70.72465515136719,
    "critic_loss": 2.5423595905303955,
    "ent_coef": 0.05365104228258133,
    "learning_rate": 0.001
  },
  {
    "episode": 9464,
    "reward": 88.743023,
    "length": 66,
    "time": 139720.549571,
    "actor_loss": -63.6324348449707,
    "critic_loss": 8.353982925415039,
    "ent_coef": 0.053535714745521545,
    "learning_rate": 0.001
  },
  {
    "episode": 9465,
    "reward": 90.244221,
    "length": 62,
    "time": 139734.464091,
    "actor_loss": -74.7994384765625,
    "critic_loss": 2.330353021621704,
    "ent_coef": 0.05681585147976875,
    "learning_rate": 0.001
  },
  {
    "episode": 9466,
    "reward": 90.478715,
    "length": 63,
    "time": 139745.815474,
    "actor_loss": -65.8623046875,
    "critic_loss": 3.608384609222412,
    "ent_coef": 0.05791056528687477,
    "learning_rate": 0.001
  },
  {
    "episode": 9467,
    "reward": 90.345484,
    "length": 63,
    "time": 139758.460027,
    "actor_loss": -66.8333511352539,
    "critic_loss": 4.199716567993164,
    "ent_coef": 0.0576489195227623,
    "learning_rate": 0.001
  },
  {
    "episode": 9468,
    "reward": 90.610543,
    "length": 63,
    "time": 139773.755779,
    "actor_loss": -67.21476745605469,
    "critic_loss": 3.4513778686523438,
    "ent_coef": 0.060884226113557816,
    "learning_rate": 0.001
  },
  {
    "episode": 9469,
    "reward": 89.973259,
    "length": 63,
    "time": 139784.953108,
    "actor_loss": -71.47270202636719,
    "critic_loss": 3.0785555839538574,
    "ent_coef": 0.06300709396600723,
    "learning_rate": 0.001
  },
  {
    "episode": 9470,
    "reward": 90.511157,
    "length": 63,
    "time": 139796.282713,
    "actor_loss": -67.85223388671875,
    "critic_loss": 3.6003222465515137,
    "ent_coef": 0.06679070740938187,
    "learning_rate": 0.001
  },
  {
    "episode": 9471,
    "reward": 90.586324,
    "length": 63,
    "time": 139807.908514,
    "actor_loss": -68.72470092773438,
    "critic_loss": 13.677414894104004,
    "ent_coef": 0.06750431656837463,
    "learning_rate": 0.001
  },
  {
    "episode": 9472,
    "reward": 90.802242,
    "length": 63,
    "time": 139819.198515,
    "actor_loss": -69.7850570678711,
    "critic_loss": 4.951817035675049,
    "ent_coef": 0.06907042860984802,
    "learning_rate": 0.001
  },
  {
    "episode": 9473,
    "reward": 89.759969,
    "length": 65,
    "time": 139830.812187,
    "actor_loss": -71.25567626953125,
    "critic_loss": 3.8645553588867188,
    "ent_coef": 0.07186751067638397,
    "learning_rate": 0.001
  },
  {
    "episode": 9474,
    "reward": 88.379455,
    "length": 68,
    "time": 139844.528254,
    "actor_loss": -66.5398178100586,
    "critic_loss": 3.500894546508789,
    "ent_coef": 0.06881353259086609,
    "learning_rate": 0.001
  },
  {
    "episode": 9475,
    "reward": 87.748319,
    "length": 69,
    "time": 139857.691402,
    "actor_loss": -70.91172790527344,
    "critic_loss": 3.968043327331543,
    "ent_coef": 0.06639344245195389,
    "learning_rate": 0.001
  },
  {
    "episode": 9476,
    "reward": 87.343275,
    "length": 69,
    "time": 139870.717362,
    "actor_loss": -64.93232727050781,
    "critic_loss": 2.879243850708008,
    "ent_coef": 0.06482508778572083,
    "learning_rate": 0.001
  },
  {
    "episode": 9477,
    "reward": 89.025697,
    "length": 66,
    "time": 139884.983974,
    "actor_loss": -68.87548065185547,
    "critic_loss": 47.86042785644531,
    "ent_coef": 0.06456936150789261,
    "learning_rate": 0.001
  },
  {
    "episode": 9478,
    "reward": 92.168015,
    "length": 60,
    "time": 139896.005952,
    "actor_loss": -69.04446411132812,
    "critic_loss": 2.6125850677490234,
    "ent_coef": 0.0682653933763504,
    "learning_rate": 0.001
  },
  {
    "episode": 9479,
    "reward": 88.313733,
    "length": 67,
    "time": 139908.733757,
    "actor_loss": -63.60166931152344,
    "critic_loss": 44.94109344482422,
    "ent_coef": 0.06699901819229126,
    "learning_rate": 0.001
  },
  {
    "episode": 9480,
    "reward": 86.868663,
    "length": 69,
    "time": 139924.59408,
    "actor_loss": -62.64788055419922,
    "critic_loss": 7.017406940460205,
    "ent_coef": 0.06469012051820755,
    "learning_rate": 0.001
  },
  {
    "episode": 9481,
    "reward": 89.594071,
    "length": 64,
    "time": 139936.055887,
    "actor_loss": -75.15213012695312,
    "critic_loss": 4.021047592163086,
    "ent_coef": 0.0637044757604599,
    "learning_rate": 0.001
  },
  {
    "episode": 9482,
    "reward": 86.310499,
    "length": 74,
    "time": 139948.829212,
    "actor_loss": -67.72776794433594,
    "critic_loss": 5.4348859786987305,
    "ent_coef": 0.05878501757979393,
    "learning_rate": 0.001
  },
  {
    "episode": 9483,
    "reward": 88.805812,
    "length": 65,
    "time": 139960.300666,
    "actor_loss": -68.91539764404297,
    "critic_loss": 5.048460006713867,
    "ent_coef": 0.060120727866888046,
    "learning_rate": 0.001
  },
  {
    "episode": 9484,
    "reward": 90.051747,
    "length": 64,
    "time": 139974.611941,
    "actor_loss": -64.44351196289062,
    "critic_loss": 19.05265998840332,
    "ent_coef": 0.06345634907484055,
    "learning_rate": 0.001
  },
  {
    "episode": 9485,
    "reward": 88.433421,
    "length": 66,
    "time": 139986.146206,
    "actor_loss": -72.9698257446289,
    "critic_loss": 391.6092224121094,
    "ent_coef": 0.06310368329286575,
    "learning_rate": 0.001
  },
  {
    "episode": 9486,
    "reward": 88.260584,
    "length": 68,
    "time": 139998.118749,
    "actor_loss": -74.92402648925781,
    "critic_loss": 24.45996856689453,
    "ent_coef": 0.061191312968730927,
    "learning_rate": 0.001
  },
  {
    "episode": 9487,
    "reward": 89.37666,
    "length": 65,
    "time": 140009.925133,
    "actor_loss": -71.48486328125,
    "critic_loss": 1.7793716192245483,
    "ent_coef": 0.06245024874806404,
    "learning_rate": 0.001
  },
  {
    "episode": 9488,
    "reward": 89.835953,
    "length": 64,
    "time": 140024.053175,
    "actor_loss": -64.10696411132812,
    "critic_loss": 45.69512939453125,
    "ent_coef": 0.06492092460393906,
    "learning_rate": 0.001
  },
  {
    "episode": 9489,
    "reward": 90.359124,
    "length": 63,
    "time": 140037.505037,
    "actor_loss": -66.02944946289062,
    "critic_loss": 3.177156686782837,
    "ent_coef": 0.06773039698600769,
    "learning_rate": 0.001
  },
  {
    "episode": 9490,
    "reward": 86.638893,
    "length": 69,
    "time": 140049.848961,
    "actor_loss": -69.63569641113281,
    "critic_loss": 4.488067626953125,
    "ent_coef": 0.06848118454217911,
    "learning_rate": 0.001
  },
  {
    "episode": 9491,
    "reward": 88.445518,
    "length": 66,
    "time": 140062.695541,
    "actor_loss": -65.33038330078125,
    "critic_loss": 62.87519836425781,
    "ent_coef": 0.06780272722244263,
    "learning_rate": 0.001
  },
  {
    "episode": 9492,
    "reward": 87.651541,
    "length": 69,
    "time": 140074.770381,
    "actor_loss": -68.9523696899414,
    "critic_loss": 3.725780963897705,
    "ent_coef": 0.06853114813566208,
    "learning_rate": 0.001
  },
  {
    "episode": 9493,
    "reward": 88.896118,
    "length": 65,
    "time": 140087.045434,
    "actor_loss": -70.5085678100586,
    "critic_loss": 7.791664123535156,
    "ent_coef": 0.0700957402586937,
    "learning_rate": 0.001
  },
  {
    "episode": 9494,
    "reward": 91.141722,
    "length": 61,
    "time": 140098.759385,
    "actor_loss": -66.28359985351562,
    "critic_loss": 158.81246948242188,
    "ent_coef": 0.07248925417661667,
    "learning_rate": 0.001
  },
  {
    "episode": 9495,
    "reward": 86.675097,
    "length": 71,
    "time": 140111.087506,
    "actor_loss": -67.69865417480469,
    "critic_loss": 4.3669819831848145,
    "ent_coef": 0.07105477154254913,
    "learning_rate": 0.001
  },
  {
    "episode": 9496,
    "reward": 84.874893,
    "length": 75,
    "time": 140124.304565,
    "actor_loss": -64.56365966796875,
    "critic_loss": 1.5605194568634033,
    "ent_coef": 0.06380123645067215,
    "learning_rate": 0.001
  },
  {
    "episode": 9497,
    "reward": 86.395944,
    "length": 69,
    "time": 140136.256867,
    "actor_loss": -63.53235626220703,
    "critic_loss": 6.899559020996094,
    "ent_coef": 0.06164417788386345,
    "learning_rate": 0.001
  },
  {
    "episode": 9498,
    "reward": 88.244419,
    "length": 69,
    "time": 140149.056602,
    "actor_loss": -67.50143432617188,
    "critic_loss": 7.763790607452393,
    "ent_coef": 0.06413672119379044,
    "learning_rate": 0.001
  },
  {
    "episode": 9499,
    "reward": 88.487514,
    "length": 67,
    "time": 140163.12379,
    "actor_loss": -72.39118957519531,
    "critic_loss": 2.113328456878662,
    "ent_coef": 0.06356681883335114,
    "learning_rate": 0.001
  },
  {
    "episode": 9500,
    "reward": 87.293116,
    "length": 69,
    "time": 140178.637047,
    "actor_loss": -66.08094024658203,
    "critic_loss": 27.48170280456543,
    "ent_coef": 0.05926775932312012,
    "learning_rate": 0.001
  },
  {
    "episode": 9501,
    "reward": -159.955263,
    "length": 127,
    "time": 140199.187897,
    "actor_loss": -71.99747467041016,
    "critic_loss": 533.613037109375,
    "ent_coef": 0.05318251997232437,
    "learning_rate": 0.001
  },
  {
    "episode": 9502,
    "reward": 88.999582,
    "length": 65,
    "time": 140211.011877,
    "actor_loss": -69.99470520019531,
    "critic_loss": 2.7347235679626465,
    "ent_coef": 0.05552072823047638,
    "learning_rate": 0.001
  },
  {
    "episode": 9503,
    "reward": 88.605706,
    "length": 67,
    "time": 140225.740109,
    "actor_loss": -71.3228759765625,
    "critic_loss": 2.6752963066101074,
    "ent_coef": 0.05665077269077301,
    "learning_rate": 0.001
  },
  {
    "episode": 9504,
    "reward": 86.979586,
    "length": 68,
    "time": 140239.14275,
    "actor_loss": -62.56632995605469,
    "critic_loss": 3.1527085304260254,
    "ent_coef": 0.05361172556877136,
    "learning_rate": 0.001
  },
  {
    "episode": 9505,
    "reward": 88.388157,
    "length": 67,
    "time": 140252.017765,
    "actor_loss": -72.69847106933594,
    "critic_loss": 1.9527153968811035,
    "ent_coef": 0.05144333466887474,
    "learning_rate": 0.001
  },
  {
    "episode": 9506,
    "reward": 89.299015,
    "length": 65,
    "time": 140263.693737,
    "actor_loss": -64.92464447021484,
    "critic_loss": 2.9713315963745117,
    "ent_coef": 0.04934842512011528,
    "learning_rate": 0.001
  },
  {
    "episode": 9507,
    "reward": 89.946443,
    "length": 63,
    "time": 140275.961455,
    "actor_loss": -64.55291748046875,
    "critic_loss": 22.216201782226562,
    "ent_coef": 0.052650369703769684,
    "learning_rate": 0.001
  },
  {
    "episode": 9508,
    "reward": 88.033576,
    "length": 67,
    "time": 140290.080706,
    "actor_loss": -73.47667694091797,
    "critic_loss": 3.9816906452178955,
    "ent_coef": 0.055483464151620865,
    "learning_rate": 0.001
  },
  {
    "episode": 9509,
    "reward": 90.222817,
    "length": 64,
    "time": 140301.506365,
    "actor_loss": -63.00774002075195,
    "critic_loss": 88.64207458496094,
    "ent_coef": 0.05850018560886383,
    "learning_rate": 0.001
  },
  {
    "episode": 9510,
    "reward": 90.021734,
    "length": 64,
    "time": 140313.706752,
    "actor_loss": -70.36256408691406,
    "critic_loss": 161.52249145507812,
    "ent_coef": 0.05841164290904999,
    "learning_rate": 0.001
  },
  {
    "episode": 9511,
    "reward": 88.565659,
    "length": 67,
    "time": 140325.893616,
    "actor_loss": -65.546630859375,
    "critic_loss": 12.094589233398438,
    "ent_coef": 0.06067962199449539,
    "learning_rate": 0.001
  },
  {
    "episode": 9512,
    "reward": 83.769894,
    "length": 74,
    "time": 140341.295787,
    "actor_loss": -66.92051696777344,
    "critic_loss": 63.26395034790039,
    "ent_coef": 0.060746438801288605,
    "learning_rate": 0.001
  },
  {
    "episode": 9513,
    "reward": 87.224456,
    "length": 68,
    "time": 140354.552646,
    "actor_loss": -70.3360595703125,
    "critic_loss": 21.109973907470703,
    "ent_coef": 0.0610075481235981,
    "learning_rate": 0.001
  },
  {
    "episode": 9514,
    "reward": 86.898042,
    "length": 69,
    "time": 140366.88888,
    "actor_loss": -69.49310302734375,
    "critic_loss": 4.21356725692749,
    "ent_coef": 0.059910956770181656,
    "learning_rate": 0.001
  },
  {
    "episode": 9515,
    "reward": 86.896195,
    "length": 70,
    "time": 140378.876679,
    "actor_loss": -71.31727600097656,
    "critic_loss": 25.2752685546875,
    "ent_coef": 0.061142705380916595,
    "learning_rate": 0.001
  },
  {
    "episode": 9516,
    "reward": 88.304676,
    "length": 66,
    "time": 140391.84058,
    "actor_loss": -69.47633361816406,
    "critic_loss": 2.9387853145599365,
    "ent_coef": 0.060077179223299026,
    "learning_rate": 0.001
  },
  {
    "episode": 9517,
    "reward": 88.919433,
    "length": 68,
    "time": 140403.722829,
    "actor_loss": -65.80122375488281,
    "critic_loss": 13.710424423217773,
    "ent_coef": 0.06107957661151886,
    "learning_rate": 0.001
  },
  {
    "episode": 9518,
    "reward": 88.634124,
    "length": 67,
    "time": 140417.441986,
    "actor_loss": -68.44027709960938,
    "critic_loss": 23.44816780090332,
    "ent_coef": 0.0591251440346241,
    "learning_rate": 0.001
  },
  {
    "episode": 9519,
    "reward": 84.086776,
    "length": 73,
    "time": 140430.223045,
    "actor_loss": -70.72066497802734,
    "critic_loss": 3.5117557048797607,
    "ent_coef": 0.05696332827210426,
    "learning_rate": 0.001
  },
  {
    "episode": 9520,
    "reward": 77.900933,
    "length": 85,
    "time": 140445.357367,
    "actor_loss": -67.48668670654297,
    "critic_loss": 5.07028865814209,
    "ent_coef": 0.053497906774282455,
    "learning_rate": 0.001
  },
  {
    "episode": 9521,
    "reward": 86.244865,
    "length": 70,
    "time": 140459.456208,
    "actor_loss": -69.56520080566406,
    "critic_loss": 15.404160499572754,
    "ent_coef": 0.051006633788347244,
    "learning_rate": 0.001
  },
  {
    "episode": 9522,
    "reward": 82.00511,
    "length": 81,
    "time": 140472.961162,
    "actor_loss": -66.94941711425781,
    "critic_loss": 4.286074638366699,
    "ent_coef": 0.046584539115428925,
    "learning_rate": 0.001
  },
  {
    "episode": 9523,
    "reward": 82.319603,
    "length": 77,
    "time": 140485.985976,
    "actor_loss": -71.11788177490234,
    "critic_loss": 4.462060928344727,
    "ent_coef": 0.04381896182894707,
    "learning_rate": 0.001
  },
  {
    "episode": 9524,
    "reward": 90.34747,
    "length": 63,
    "time": 140499.493036,
    "actor_loss": -74.80785369873047,
    "critic_loss": 1.740952968597412,
    "ent_coef": 0.04441376402974129,
    "learning_rate": 0.001
  },
  {
    "episode": 9525,
    "reward": 90.49523,
    "length": 63,
    "time": 140511.162952,
    "actor_loss": -65.35992431640625,
    "critic_loss": 14.243837356567383,
    "ent_coef": 0.04722807556390762,
    "learning_rate": 0.001
  },
  {
    "episode": 9526,
    "reward": 89.721339,
    "length": 64,
    "time": 140523.678218,
    "actor_loss": -78.01419067382812,
    "critic_loss": 4.073044776916504,
    "ent_coef": 0.050593845546245575,
    "learning_rate": 0.001
  },
  {
    "episode": 9527,
    "reward": 89.062108,
    "length": 66,
    "time": 140535.920924,
    "actor_loss": -72.35903930664062,
    "critic_loss": 14.421073913574219,
    "ent_coef": 0.05377662181854248,
    "learning_rate": 0.001
  },
  {
    "episode": 9528,
    "reward": 88.912883,
    "length": 65,
    "time": 140547.597488,
    "actor_loss": -67.7652587890625,
    "critic_loss": 87.5418930053711,
    "ent_coef": 0.05504915490746498,
    "learning_rate": 0.001
  },
  {
    "episode": 9529,
    "reward": 89.717536,
    "length": 64,
    "time": 140559.042784,
    "actor_loss": -70.6296157836914,
    "critic_loss": 2.790302038192749,
    "ent_coef": 0.05624213069677353,
    "learning_rate": 0.001
  },
  {
    "episode": 9530,
    "reward": 90.284471,
    "length": 63,
    "time": 140570.921724,
    "actor_loss": -76.16280364990234,
    "critic_loss": 3.3110156059265137,
    "ent_coef": 0.05855894461274147,
    "learning_rate": 0.001
  },
  {
    "episode": 9531,
    "reward": 89.008769,
    "length": 65,
    "time": 140584.152961,
    "actor_loss": -75.63682556152344,
    "critic_loss": 2.366849899291992,
    "ent_coef": 0.05998729541897774,
    "learning_rate": 0.001
  },
  {
    "episode": 9532,
    "reward": 89.340637,
    "length": 65,
    "time": 140597.108908,
    "actor_loss": -72.20698547363281,
    "critic_loss": 3.4247493743896484,
    "ent_coef": 0.061830952763557434,
    "learning_rate": 0.001
  },
  {
    "episode": 9533,
    "reward": 86.927126,
    "length": 69,
    "time": 140611.553877,
    "actor_loss": -72.94146728515625,
    "critic_loss": 18.279460906982422,
    "ent_coef": 0.060115352272987366,
    "learning_rate": 0.001
  },
  {
    "episode": 9534,
    "reward": 87.240684,
    "length": 68,
    "time": 140626.308388,
    "actor_loss": -73.8103256225586,
    "critic_loss": 3.049825429916382,
    "ent_coef": 0.05922317877411842,
    "learning_rate": 0.001
  },
  {
    "episode": 9535,
    "reward": 89.302803,
    "length": 65,
    "time": 140639.471772,
    "actor_loss": -66.79450988769531,
    "critic_loss": 8.258017539978027,
    "ent_coef": 0.06108492985367775,
    "learning_rate": 0.001
  },
  {
    "episode": 9536,
    "reward": 90.664741,
    "length": 63,
    "time": 140651.119456,
    "actor_loss": -66.77433776855469,
    "critic_loss": 2.8336234092712402,
    "ent_coef": 0.06369276344776154,
    "learning_rate": 0.001
  },
  {
    "episode": 9537,
    "reward": 84.724993,
    "length": 73,
    "time": 140663.413951,
    "actor_loss": -68.8664779663086,
    "critic_loss": 4.574288368225098,
    "ent_coef": 0.06387953460216522,
    "learning_rate": 0.001
  },
  {
    "episode": 9538,
    "reward": 85.746659,
    "length": 70,
    "time": 140675.63816,
    "actor_loss": -68.57005310058594,
    "critic_loss": 34.52733612060547,
    "ent_coef": 0.06387253105640411,
    "learning_rate": 0.001
  },
  {
    "episode": 9539,
    "reward": 86.908334,
    "length": 67,
    "time": 140689.029816,
    "actor_loss": -66.70117950439453,
    "critic_loss": 2.3935372829437256,
    "ent_coef": 0.06249640882015228,
    "learning_rate": 0.001
  },
  {
    "episode": 9540,
    "reward": 90.012926,
    "length": 64,
    "time": 140700.589266,
    "actor_loss": -71.19303131103516,
    "critic_loss": 8.58387565612793,
    "ent_coef": 0.06067623570561409,
    "learning_rate": 0.001
  },
  {
    "episode": 9541,
    "reward": 87.322592,
    "length": 70,
    "time": 140716.925444,
    "actor_loss": -71.90394592285156,
    "critic_loss": 3.7470014095306396,
    "ent_coef": 0.058158762753009796,
    "learning_rate": 0.001
  },
  {
    "episode": 9542,
    "reward": 83.367882,
    "length": 79,
    "time": 140730.830784,
    "actor_loss": -67.26470947265625,
    "critic_loss": 33.502540588378906,
    "ent_coef": 0.052146393805742264,
    "learning_rate": 0.001
  },
  {
    "episode": 9543,
    "reward": 69.397,
    "length": 76,
    "time": 140743.657004,
    "actor_loss": -66.13140869140625,
    "critic_loss": 23.013025283813477,
    "ent_coef": 0.049363937228918076,
    "learning_rate": 0.001
  },
  {
    "episode": 9544,
    "reward": 88.292354,
    "length": 68,
    "time": 140755.586482,
    "actor_loss": -64.04302978515625,
    "critic_loss": 16.724895477294922,
    "ent_coef": 0.04927708953619003,
    "learning_rate": 0.001
  },
  {
    "episode": 9545,
    "reward": 86.533193,
    "length": 73,
    "time": 140768.460198,
    "actor_loss": -72.80780029296875,
    "critic_loss": 4.150835037231445,
    "ent_coef": 0.049790605902671814,
    "learning_rate": 0.001
  },
  {
    "episode": 9546,
    "reward": 85.445465,
    "length": 73,
    "time": 140781.405919,
    "actor_loss": -73.13228607177734,
    "critic_loss": 13.004353523254395,
    "ent_coef": 0.04839007556438446,
    "learning_rate": 0.001
  },
  {
    "episode": 9547,
    "reward": 85.828701,
    "length": 72,
    "time": 140797.965385,
    "actor_loss": -74.02699279785156,
    "critic_loss": 8.659963607788086,
    "ent_coef": 0.046080708503723145,
    "learning_rate": 0.001
  },
  {
    "episode": 9548,
    "reward": 87.571698,
    "length": 68,
    "time": 140810.600711,
    "actor_loss": -71.15756225585938,
    "critic_loss": 25.91400909423828,
    "ent_coef": 0.045512016862630844,
    "learning_rate": 0.001
  },
  {
    "episode": 9549,
    "reward": 90.557947,
    "length": 64,
    "time": 140823.836857,
    "actor_loss": -72.64404296875,
    "critic_loss": 4.58148717880249,
    "ent_coef": 0.046198081225156784,
    "learning_rate": 0.001
  },
  {
    "episode": 9550,
    "reward": 88.172196,
    "length": 69,
    "time": 140836.230755,
    "actor_loss": -67.8520736694336,
    "critic_loss": 3.180104970932007,
    "ent_coef": 0.04649410769343376,
    "learning_rate": 0.001
  },
  {
    "episode": 9551,
    "reward": 87.084104,
    "length": 76,
    "time": 140852.655111,
    "actor_loss": -72.21065521240234,
    "critic_loss": 2.227764129638672,
    "ent_coef": 0.046986084431409836,
    "learning_rate": 0.001
  },
  {
    "episode": 9552,
    "reward": 89.246122,
    "length": 65,
    "time": 140864.677884,
    "actor_loss": -69.59469604492188,
    "critic_loss": 51.95463180541992,
    "ent_coef": 0.048627618700265884,
    "learning_rate": 0.001
  },
  {
    "episode": 9553,
    "reward": -153.636279,
    "length": 129,
    "time": 140885.94614,
    "actor_loss": -68.5891342163086,
    "critic_loss": 20.380477905273438,
    "ent_coef": 0.05239882320165634,
    "learning_rate": 0.001
  },
  {
    "episode": 9554,
    "reward": 84.89323,
    "length": 74,
    "time": 140900.042676,
    "actor_loss": -71.00588989257812,
    "critic_loss": 2.9028215408325195,
    "ent_coef": 0.051005151122808456,
    "learning_rate": 0.001
  },
  {
    "episode": 9555,
    "reward": 89.159234,
    "length": 65,
    "time": 140912.46187,
    "actor_loss": -75.5920181274414,
    "critic_loss": 24.902774810791016,
    "ent_coef": 0.04939345270395279,
    "learning_rate": 0.001
  },
  {
    "episode": 9556,
    "reward": 85.892717,
    "length": 72,
    "time": 140925.797171,
    "actor_loss": -68.2541275024414,
    "critic_loss": 5.707262992858887,
    "ent_coef": 0.048906221985816956,
    "learning_rate": 0.001
  },
  {
    "episode": 9557,
    "reward": 88.885448,
    "length": 66,
    "time": 140940.004954,
    "actor_loss": -68.87730407714844,
    "critic_loss": 2.825021982192993,
    "ent_coef": 0.04793862625956535,
    "learning_rate": 0.001
  },
  {
    "episode": 9558,
    "reward": 85.133479,
    "length": 74,
    "time": 140956.977917,
    "actor_loss": -69.59892272949219,
    "critic_loss": 26.284912109375,
    "ent_coef": 0.04562250152230263,
    "learning_rate": 0.001
  },
  {
    "episode": 9559,
    "reward": 84.334793,
    "length": 74,
    "time": 140969.857844,
    "actor_loss": -67.12737274169922,
    "critic_loss": 5.111934661865234,
    "ent_coef": 0.04514257609844208,
    "learning_rate": 0.001
  },
  {
    "episode": 9560,
    "reward": 84.61886,
    "length": 74,
    "time": 140982.384493,
    "actor_loss": -67.06941223144531,
    "critic_loss": 20.527690887451172,
    "ent_coef": 0.04560702666640282,
    "learning_rate": 0.001
  },
  {
    "episode": 9561,
    "reward": 87.210209,
    "length": 70,
    "time": 140995.247243,
    "actor_loss": -71.41436767578125,
    "critic_loss": 34.816532135009766,
    "ent_coef": 0.04694394767284393,
    "learning_rate": 0.001
  },
  {
    "episode": 9562,
    "reward": 90.049803,
    "length": 64,
    "time": 141006.800404,
    "actor_loss": -71.63131713867188,
    "critic_loss": 4.481259346008301,
    "ent_coef": 0.049279000610113144,
    "learning_rate": 0.001
  },
  {
    "episode": 9563,
    "reward": 89.265535,
    "length": 66,
    "time": 141020.132532,
    "actor_loss": -74.45199584960938,
    "critic_loss": 4.765995979309082,
    "ent_coef": 0.05024793744087219,
    "learning_rate": 0.001
  },
  {
    "episode": 9564,
    "reward": 87.618299,
    "length": 69,
    "time": 141032.336872,
    "actor_loss": -66.49308776855469,
    "critic_loss": 4.737998962402344,
    "ent_coef": 0.05223115161061287,
    "learning_rate": 0.001
  },
  {
    "episode": 9565,
    "reward": 87.706981,
    "length": 68,
    "time": 141045.407527,
    "actor_loss": -75.20138549804688,
    "critic_loss": 49.36052703857422,
    "ent_coef": 0.051945678889751434,
    "learning_rate": 0.001
  },
  {
    "episode": 9566,
    "reward": 87.294783,
    "length": 72,
    "time": 141058.781212,
    "actor_loss": -65.13630676269531,
    "critic_loss": 19.092266082763672,
    "ent_coef": 0.050509948283433914,
    "learning_rate": 0.001
  },
  {
    "episode": 9567,
    "reward": 83.119305,
    "length": 76,
    "time": 141071.941082,
    "actor_loss": -70.8042984008789,
    "critic_loss": 453.8584289550781,
    "ent_coef": 0.05186144635081291,
    "learning_rate": 0.001
  },
  {
    "episode": 9568,
    "reward": 90.417428,
    "length": 63,
    "time": 141083.545101,
    "actor_loss": -66.55113220214844,
    "critic_loss": 190.96194458007812,
    "ent_coef": 0.05676852539181709,
    "learning_rate": 0.001
  },
  {
    "episode": 9569,
    "reward": 87.252164,
    "length": 71,
    "time": 141096.636554,
    "actor_loss": -70.74664306640625,
    "critic_loss": 87.8526611328125,
    "ent_coef": 0.059809695929288864,
    "learning_rate": 0.001
  },
  {
    "episode": 9570,
    "reward": 76.150985,
    "length": 88,
    "time": 141113.365589,
    "actor_loss": -65.8958740234375,
    "critic_loss": 20.39767837524414,
    "ent_coef": 0.05491698905825615,
    "learning_rate": 0.001
  },
  {
    "episode": 9571,
    "reward": 88.047333,
    "length": 68,
    "time": 141125.399892,
    "actor_loss": -60.74360275268555,
    "critic_loss": 36.74483108520508,
    "ent_coef": 0.05315982922911644,
    "learning_rate": 0.001
  },
  {
    "episode": 9572,
    "reward": 86.800731,
    "length": 69,
    "time": 141139.659842,
    "actor_loss": -72.8540267944336,
    "critic_loss": 3.891550302505493,
    "ent_coef": 0.054174888879060745,
    "learning_rate": 0.001
  },
  {
    "episode": 9573,
    "reward": 90.388661,
    "length": 63,
    "time": 141153.555157,
    "actor_loss": -69.98553466796875,
    "critic_loss": 3.9722914695739746,
    "ent_coef": 0.055293768644332886,
    "learning_rate": 0.001
  },
  {
    "episode": 9574,
    "reward": 90.154984,
    "length": 66,
    "time": 141169.428626,
    "actor_loss": -65.85514831542969,
    "critic_loss": 51.12160110473633,
    "ent_coef": 0.05810598284006119,
    "learning_rate": 0.001
  },
  {
    "episode": 9575,
    "reward": 65.902442,
    "length": 116,
    "time": 141188.290976,
    "actor_loss": -70.97835540771484,
    "critic_loss": 57.54052734375,
    "ent_coef": 0.05336165428161621,
    "learning_rate": 0.001
  },
  {
    "episode": 9576,
    "reward": 82.862272,
    "length": 76,
    "time": 141201.800939,
    "actor_loss": -68.0029296875,
    "critic_loss": 3.3672425746917725,
    "ent_coef": 0.05143994465470314,
    "learning_rate": 0.001
  },
  {
    "episode": 9577,
    "reward": 89.162706,
    "length": 69,
    "time": 141217.406881,
    "actor_loss": -70.4421615600586,
    "critic_loss": 6.810443878173828,
    "ent_coef": 0.050600625574588776,
    "learning_rate": 0.001
  },
  {
    "episode": 9578,
    "reward": 89.492323,
    "length": 68,
    "time": 141231.046902,
    "actor_loss": -77.83264923095703,
    "critic_loss": 12.882377624511719,
    "ent_coef": 0.052609965205192566,
    "learning_rate": 0.001
  },
  {
    "episode": 9579,
    "reward": 89.767541,
    "length": 65,
    "time": 141246.898032,
    "actor_loss": -70.96791076660156,
    "critic_loss": 2.6629116535186768,
    "ent_coef": 0.05584608390927315,
    "learning_rate": 0.001
  },
  {
    "episode": 9580,
    "reward": 89.312528,
    "length": 64,
    "time": 141258.037639,
    "actor_loss": -71.14594268798828,
    "critic_loss": 14.635555267333984,
    "ent_coef": 0.057755909860134125,
    "learning_rate": 0.001
  },
  {
    "episode": 9581,
    "reward": 89.235061,
    "length": 66,
    "time": 141269.989038,
    "actor_loss": -62.45106506347656,
    "critic_loss": 10.62771987915039,
    "ent_coef": 0.0586373545229435,
    "learning_rate": 0.001
  },
  {
    "episode": 9582,
    "reward": 90.493889,
    "length": 63,
    "time": 141281.16592,
    "actor_loss": -70.75410461425781,
    "critic_loss": 6.822729110717773,
    "ent_coef": 0.05876883491873741,
    "learning_rate": 0.001
  },
  {
    "episode": 9583,
    "reward": 88.914102,
    "length": 66,
    "time": 141292.761198,
    "actor_loss": -70.94551086425781,
    "critic_loss": 4.495530128479004,
    "ent_coef": 0.057444870471954346,
    "learning_rate": 0.001
  },
  {
    "episode": 9584,
    "reward": 87.262424,
    "length": 70,
    "time": 141311.01012,
    "actor_loss": -68.98069763183594,
    "critic_loss": 7.834362983703613,
    "ent_coef": 0.059885796159505844,
    "learning_rate": 0.001
  },
  {
    "episode": 9585,
    "reward": 87.097779,
    "length": 69,
    "time": 141323.216145,
    "actor_loss": -70.79844665527344,
    "critic_loss": 3.455493927001953,
    "ent_coef": 0.059407658874988556,
    "learning_rate": 0.001
  },
  {
    "episode": 9586,
    "reward": 90.110138,
    "length": 63,
    "time": 141334.628973,
    "actor_loss": -71.3048324584961,
    "critic_loss": 3.978762626647949,
    "ent_coef": 0.06203034520149231,
    "learning_rate": 0.001
  },
  {
    "episode": 9587,
    "reward": 89.424944,
    "length": 65,
    "time": 141347.347481,
    "actor_loss": -64.86040496826172,
    "critic_loss": 4.060183525085449,
    "ent_coef": 0.0638333261013031,
    "learning_rate": 0.001
  },
  {
    "episode": 9588,
    "reward": 89.953422,
    "length": 65,
    "time": 141359.223791,
    "actor_loss": -66.20689392089844,
    "critic_loss": 5.571795463562012,
    "ent_coef": 0.0629035085439682,
    "learning_rate": 0.001
  },
  {
    "episode": 9589,
    "reward": 87.336701,
    "length": 69,
    "time": 141371.147363,
    "actor_loss": -71.50629425048828,
    "critic_loss": 5.938198089599609,
    "ent_coef": 0.06348071992397308,
    "learning_rate": 0.001
  },
  {
    "episode": 9590,
    "reward": 89.366283,
    "length": 65,
    "time": 141382.516326,
    "actor_loss": -66.38714599609375,
    "critic_loss": 1.6927919387817383,
    "ent_coef": 0.06391184031963348,
    "learning_rate": 0.001
  },
  {
    "episode": 9591,
    "reward": 87.469987,
    "length": 68,
    "time": 141395.928016,
    "actor_loss": -68.21361541748047,
    "critic_loss": 19.22681999206543,
    "ent_coef": 0.06578461825847626,
    "learning_rate": 0.001
  },
  {
    "episode": 9592,
    "reward": 90.200327,
    "length": 65,
    "time": 141407.459547,
    "actor_loss": -73.09844970703125,
    "critic_loss": 11.705528259277344,
    "ent_coef": 0.06883789598941803,
    "learning_rate": 0.001
  },
  {
    "episode": 9593,
    "reward": 86.874745,
    "length": 69,
    "time": 141421.217368,
    "actor_loss": -66.84806823730469,
    "critic_loss": 1.4972223043441772,
    "ent_coef": 0.06906764209270477,
    "learning_rate": 0.001
  },
  {
    "episode": 9594,
    "reward": 89.831694,
    "length": 67,
    "time": 141434.379114,
    "actor_loss": -67.76007080078125,
    "critic_loss": 3.1397528648376465,
    "ent_coef": 0.07099460810422897,
    "learning_rate": 0.001
  },
  {
    "episode": 9595,
    "reward": 85.389536,
    "length": 73,
    "time": 141447.457046,
    "actor_loss": -68.15900421142578,
    "critic_loss": 2.502655029296875,
    "ent_coef": 0.06636583805084229,
    "learning_rate": 0.001
  },
  {
    "episode": 9596,
    "reward": 88.075567,
    "length": 67,
    "time": 141461.561697,
    "actor_loss": -68.86616516113281,
    "critic_loss": 27.387500762939453,
    "ent_coef": 0.06591392308473587,
    "learning_rate": 0.001
  },
  {
    "episode": 9597,
    "reward": 89.432196,
    "length": 64,
    "time": 141474.803818,
    "actor_loss": -71.29011535644531,
    "critic_loss": 26.374530792236328,
    "ent_coef": 0.06921334564685822,
    "learning_rate": 0.001
  },
  {
    "episode": 9598,
    "reward": 88.926221,
    "length": 66,
    "time": 141490.113961,
    "actor_loss": -69.35401153564453,
    "critic_loss": 24.92186737060547,
    "ent_coef": 0.06947438418865204,
    "learning_rate": 0.001
  },
  {
    "episode": 9599,
    "reward": 87.951585,
    "length": 67,
    "time": 141501.817706,
    "actor_loss": -72.79364776611328,
    "critic_loss": 3.2147178649902344,
    "ent_coef": 0.07047014683485031,
    "learning_rate": 0.001
  },
  {
    "episode": 9600,
    "reward": 83.557709,
    "length": 76,
    "time": 141515.387161,
    "actor_loss": -65.05384826660156,
    "critic_loss": 7.052424430847168,
    "ent_coef": 0.06939462572336197,
    "learning_rate": 0.001
  },
  {
    "episode": 9601,
    "reward": 89.334575,
    "length": 66,
    "time": 141527.397116,
    "actor_loss": -70.396240234375,
    "critic_loss": 426.7975769042969,
    "ent_coef": 0.0688127726316452,
    "learning_rate": 0.001
  },
  {
    "episode": 9602,
    "reward": 87.587642,
    "length": 68,
    "time": 141539.728656,
    "actor_loss": -65.08883666992188,
    "critic_loss": 24.160409927368164,
    "ent_coef": 0.06684308499097824,
    "learning_rate": 0.001
  },
  {
    "episode": 9603,
    "reward": 89.933243,
    "length": 63,
    "time": 141552.885652,
    "actor_loss": -65.974853515625,
    "critic_loss": 5.252002716064453,
    "ent_coef": 0.06615999341011047,
    "learning_rate": 0.001
  },
  {
    "episode": 9604,
    "reward": 90.960778,
    "length": 64,
    "time": 141566.283648,
    "actor_loss": -71.84298706054688,
    "critic_loss": 6.518110275268555,
    "ent_coef": 0.06613278388977051,
    "learning_rate": 0.001
  },
  {
    "episode": 9605,
    "reward": 89.131006,
    "length": 66,
    "time": 141579.441846,
    "actor_loss": -68.52178955078125,
    "critic_loss": 10.995368957519531,
    "ent_coef": 0.06463572382926941,
    "learning_rate": 0.001
  },
  {
    "episode": 9606,
    "reward": 88.862234,
    "length": 64,
    "time": 141594.034509,
    "actor_loss": -67.18623352050781,
    "critic_loss": 1.9295483827590942,
    "ent_coef": 0.06320932507514954,
    "learning_rate": 0.001
  },
  {
    "episode": 9607,
    "reward": 88.381338,
    "length": 67,
    "time": 141606.202755,
    "actor_loss": -69.32853698730469,
    "critic_loss": 5.845950126647949,
    "ent_coef": 0.062364619225263596,
    "learning_rate": 0.001
  },
  {
    "episode": 9608,
    "reward": 90.982546,
    "length": 62,
    "time": 141622.129945,
    "actor_loss": -73.48731994628906,
    "critic_loss": 3.9207634925842285,
    "ent_coef": 0.0630723088979721,
    "learning_rate": 0.001
  },
  {
    "episode": 9609,
    "reward": 88.760217,
    "length": 66,
    "time": 141637.182228,
    "actor_loss": -67.60488891601562,
    "critic_loss": 15.137011528015137,
    "ent_coef": 0.06540951877832413,
    "learning_rate": 0.001
  },
  {
    "episode": 9610,
    "reward": 91.048764,
    "length": 62,
    "time": 141649.764999,
    "actor_loss": -71.03511047363281,
    "critic_loss": 3.2854549884796143,
    "ent_coef": 0.06816151738166809,
    "learning_rate": 0.001
  },
  {
    "episode": 9611,
    "reward": 87.510447,
    "length": 68,
    "time": 141663.15552,
    "actor_loss": -70.99992370605469,
    "critic_loss": 3.7719056606292725,
    "ent_coef": 0.06490622460842133,
    "learning_rate": 0.001
  },
  {
    "episode": 9612,
    "reward": 86.945469,
    "length": 75,
    "time": 141677.230238,
    "actor_loss": -73.2547607421875,
    "critic_loss": 2.6610422134399414,
    "ent_coef": 0.06378781050443649,
    "learning_rate": 0.001
  },
  {
    "episode": 9613,
    "reward": 77.505392,
    "length": 81,
    "time": 141694.057457,
    "actor_loss": -63.61131286621094,
    "critic_loss": 3.7638697624206543,
    "ent_coef": 0.06148013845086098,
    "learning_rate": 0.001
  },
  {
    "episode": 9614,
    "reward": 86.08955,
    "length": 73,
    "time": 141709.504765,
    "actor_loss": -65.79998016357422,
    "critic_loss": 4.5440592765808105,
    "ent_coef": 0.05898330360651016,
    "learning_rate": 0.001
  },
  {
    "episode": 9615,
    "reward": 84.185813,
    "length": 76,
    "time": 141723.196772,
    "actor_loss": -69.99024963378906,
    "critic_loss": 2.748915910720825,
    "ent_coef": 0.0561637245118618,
    "learning_rate": 0.001
  },
  {
    "episode": 9616,
    "reward": 90.243491,
    "length": 63,
    "time": 141734.841893,
    "actor_loss": -66.04077911376953,
    "critic_loss": 4.681606769561768,
    "ent_coef": 0.05495883896946907,
    "learning_rate": 0.001
  },
  {
    "episode": 9617,
    "reward": 88.474082,
    "length": 66,
    "time": 141747.25985,
    "actor_loss": -70.64517211914062,
    "critic_loss": 4.102520942687988,
    "ent_coef": 0.0542227104306221,
    "learning_rate": 0.001
  },
  {
    "episode": 9618,
    "reward": 90.636572,
    "length": 62,
    "time": 141758.999401,
    "actor_loss": -67.859619140625,
    "critic_loss": 5.694336891174316,
    "ent_coef": 0.057442888617515564,
    "learning_rate": 0.001
  },
  {
    "episode": 9619,
    "reward": 91.428041,
    "length": 61,
    "time": 141770.881721,
    "actor_loss": -70.9422607421875,
    "critic_loss": 2.5452117919921875,
    "ent_coef": 0.06019647419452667,
    "learning_rate": 0.001
  },
  {
    "episode": 9620,
    "reward": 85.291636,
    "length": 72,
    "time": 141787.096086,
    "actor_loss": -68.43863677978516,
    "critic_loss": 16.23793601989746,
    "ent_coef": 0.05625297874212265,
    "learning_rate": 0.001
  },
  {
    "episode": 9621,
    "reward": 89.345037,
    "length": 59,
    "time": 141800.280378,
    "actor_loss": -71.72765350341797,
    "critic_loss": 2.874178409576416,
    "ent_coef": 0.05671161785721779,
    "learning_rate": 0.001
  },
  {
    "episode": 9622,
    "reward": 86.355904,
    "length": 71,
    "time": 141814.015483,
    "actor_loss": -69.8821792602539,
    "critic_loss": 6.786921501159668,
    "ent_coef": 0.0556030310690403,
    "learning_rate": 0.001
  },
  {
    "episode": 9623,
    "reward": 91.172042,
    "length": 62,
    "time": 141827.112267,
    "actor_loss": -65.34890747070312,
    "critic_loss": 23.62449836730957,
    "ent_coef": 0.05839763581752777,
    "learning_rate": 0.001
  },
  {
    "episode": 9624,
    "reward": 89.533207,
    "length": 65,
    "time": 141839.679791,
    "actor_loss": -71.15512084960938,
    "critic_loss": 20.844058990478516,
    "ent_coef": 0.05939575284719467,
    "learning_rate": 0.001
  },
  {
    "episode": 9625,
    "reward": 89.698411,
    "length": 65,
    "time": 141852.289433,
    "actor_loss": -72.72390747070312,
    "critic_loss": 5.045108795166016,
    "ent_coef": 0.06240418553352356,
    "learning_rate": 0.001
  },
  {
    "episode": 9626,
    "reward": 90.829929,
    "length": 62,
    "time": 141864.578632,
    "actor_loss": -72.74977111816406,
    "critic_loss": 4.659599304199219,
    "ent_coef": 0.06392239034175873,
    "learning_rate": 0.001
  },
  {
    "episode": 9627,
    "reward": 87.706073,
    "length": 66,
    "time": 141877.157737,
    "actor_loss": -73.74385833740234,
    "critic_loss": 67.4760513305664,
    "ent_coef": 0.06642141938209534,
    "learning_rate": 0.001
  },
  {
    "episode": 9628,
    "reward": 89.891393,
    "length": 63,
    "time": 141891.365369,
    "actor_loss": -69.4266357421875,
    "critic_loss": 66.35912322998047,
    "ent_coef": 0.06697680056095123,
    "learning_rate": 0.001
  },
  {
    "episode": 9629,
    "reward": 91.742252,
    "length": 60,
    "time": 141903.555873,
    "actor_loss": -69.27824401855469,
    "critic_loss": 35.55339813232422,
    "ent_coef": 0.07109405100345612,
    "learning_rate": 0.001
  },
  {
    "episode": 9630,
    "reward": 89.618668,
    "length": 65,
    "time": 141917.764839,
    "actor_loss": -68.24200439453125,
    "critic_loss": 3.7680959701538086,
    "ent_coef": 0.0705055296421051,
    "learning_rate": 0.001
  },
  {
    "episode": 9631,
    "reward": 89.815817,
    "length": 65,
    "time": 141931.576702,
    "actor_loss": -65.04790496826172,
    "critic_loss": 2.8484644889831543,
    "ent_coef": 0.06990738213062286,
    "learning_rate": 0.001
  },
  {
    "episode": 9632,
    "reward": 90.106611,
    "length": 65,
    "time": 141944.903949,
    "actor_loss": -66.41532135009766,
    "critic_loss": 6.024886131286621,
    "ent_coef": 0.07058491557836533,
    "learning_rate": 0.001
  },
  {
    "episode": 9633,
    "reward": 81.233758,
    "length": 116,
    "time": 141966.19963,
    "actor_loss": -75.89859771728516,
    "critic_loss": 5.355441093444824,
    "ent_coef": 0.06990991532802582,
    "learning_rate": 0.001
  },
  {
    "episode": 9634,
    "reward": 83.467788,
    "length": 78,
    "time": 141980.374603,
    "actor_loss": -68.55021667480469,
    "critic_loss": 12.142669677734375,
    "ent_coef": 0.066668301820755,
    "learning_rate": 0.001
  },
  {
    "episode": 9635,
    "reward": 83.475931,
    "length": 79,
    "time": 141994.620609,
    "actor_loss": -69.42890930175781,
    "critic_loss": 2.5528550148010254,
    "ent_coef": 0.06287074834108353,
    "learning_rate": 0.001
  },
  {
    "episode": 9636,
    "reward": 68.372241,
    "length": 105,
    "time": 142013.765697,
    "actor_loss": -63.2327880859375,
    "critic_loss": 28.404808044433594,
    "ent_coef": 0.05623282119631767,
    "learning_rate": 0.001
  },
  {
    "episode": 9637,
    "reward": 87.119295,
    "length": 69,
    "time": 142027.858762,
    "actor_loss": -68.99568176269531,
    "critic_loss": 46.793052673339844,
    "ent_coef": 0.05654964596033096,
    "learning_rate": 0.001
  },
  {
    "episode": 9638,
    "reward": 88.564451,
    "length": 68,
    "time": 142041.257404,
    "actor_loss": -65.9520034790039,
    "critic_loss": 4.123943328857422,
    "ent_coef": 0.05834357067942619,
    "learning_rate": 0.001
  },
  {
    "episode": 9639,
    "reward": 86.85636,
    "length": 68,
    "time": 142056.383784,
    "actor_loss": -66.98094177246094,
    "critic_loss": 4.271917343139648,
    "ent_coef": 0.059769243001937866,
    "learning_rate": 0.001
  },
  {
    "episode": 9640,
    "reward": 89.491816,
    "length": 65,
    "time": 142070.674203,
    "actor_loss": -70.68531799316406,
    "critic_loss": 3.0118346214294434,
    "ent_coef": 0.061800770461559296,
    "learning_rate": 0.001
  },
  {
    "episode": 9641,
    "reward": 90.086988,
    "length": 64,
    "time": 142086.546246,
    "actor_loss": -78.53404235839844,
    "critic_loss": 4.747461318969727,
    "ent_coef": 0.06334597617387772,
    "learning_rate": 0.001
  },
  {
    "episode": 9642,
    "reward": 88.445221,
    "length": 68,
    "time": 142102.758913,
    "actor_loss": -66.06240844726562,
    "critic_loss": 7.453902721405029,
    "ent_coef": 0.0642915666103363,
    "learning_rate": 0.001
  },
  {
    "episode": 9643,
    "reward": 91.27916,
    "length": 62,
    "time": 142115.319824,
    "actor_loss": -70.71237182617188,
    "critic_loss": 4.441011905670166,
    "ent_coef": 0.06470918655395508,
    "learning_rate": 0.001
  },
  {
    "episode": 9644,
    "reward": 91.588465,
    "length": 60,
    "time": 142126.767738,
    "actor_loss": -77.58010864257812,
    "critic_loss": 156.09298706054688,
    "ent_coef": 0.06801794469356537,
    "learning_rate": 0.001
  },
  {
    "episode": 9645,
    "reward": 88.437688,
    "length": 69,
    "time": 142139.600048,
    "actor_loss": -72.1466064453125,
    "critic_loss": 32.180423736572266,
    "ent_coef": 0.0711432620882988,
    "learning_rate": 0.001
  },
  {
    "episode": 9646,
    "reward": 88.888603,
    "length": 65,
    "time": 142152.728019,
    "actor_loss": -69.45038604736328,
    "critic_loss": 10.353548049926758,
    "ent_coef": 0.07013937830924988,
    "learning_rate": 0.001
  },
  {
    "episode": 9647,
    "reward": 90.862482,
    "length": 62,
    "time": 142166.497066,
    "actor_loss": -66.59115600585938,
    "critic_loss": 9.396771430969238,
    "ent_coef": 0.07173749059438705,
    "learning_rate": 0.001
  },
  {
    "episode": 9648,
    "reward": 91.210093,
    "length": 61,
    "time": 142179.748698,
    "actor_loss": -71.3116455078125,
    "critic_loss": 11.156599998474121,
    "ent_coef": 0.07453332096338272,
    "learning_rate": 0.001
  },
  {
    "episode": 9649,
    "reward": 88.99077,
    "length": 65,
    "time": 142191.838368,
    "actor_loss": -66.57733154296875,
    "critic_loss": 13.014494895935059,
    "ent_coef": 0.07767859101295471,
    "learning_rate": 0.001
  },
  {
    "episode": 9650,
    "reward": 90.949059,
    "length": 62,
    "time": 142203.571404,
    "actor_loss": -69.84756469726562,
    "critic_loss": 17.19352912902832,
    "ent_coef": 0.07855541259050369,
    "learning_rate": 0.001
  },
  {
    "episode": 9651,
    "reward": 90.318735,
    "length": 63,
    "time": 142215.673407,
    "actor_loss": -69.71931457519531,
    "critic_loss": 2.8245368003845215,
    "ent_coef": 0.07984506338834763,
    "learning_rate": 0.001
  },
  {
    "episode": 9652,
    "reward": 88.791954,
    "length": 68,
    "time": 142228.505218,
    "actor_loss": -69.54315948486328,
    "critic_loss": 39.22313690185547,
    "ent_coef": 0.07797949016094208,
    "learning_rate": 0.001
  },
  {
    "episode": 9653,
    "reward": 77.210179,
    "length": 90,
    "time": 142243.281448,
    "actor_loss": -69.98953247070312,
    "critic_loss": 5.646942138671875,
    "ent_coef": 0.0721319317817688,
    "learning_rate": 0.001
  },
  {
    "episode": 9654,
    "reward": 90.387107,
    "length": 63,
    "time": 142255.745232,
    "actor_loss": -68.82962799072266,
    "critic_loss": 4.685449600219727,
    "ent_coef": 0.07120241224765778,
    "learning_rate": 0.001
  },
  {
    "episode": 9655,
    "reward": 91.341238,
    "length": 60,
    "time": 142267.583255,
    "actor_loss": -65.1583023071289,
    "critic_loss": 18.412883758544922,
    "ent_coef": 0.0743398442864418,
    "learning_rate": 0.001
  },
  {
    "episode": 9656,
    "reward": 87.416264,
    "length": 70,
    "time": 142281.156693,
    "actor_loss": -70.38409423828125,
    "critic_loss": 3.072413444519043,
    "ent_coef": 0.07361585646867752,
    "learning_rate": 0.001
  },
  {
    "episode": 9657,
    "reward": 83.642675,
    "length": 77,
    "time": 142294.673325,
    "actor_loss": -62.75848388671875,
    "critic_loss": 4.834103584289551,
    "ent_coef": 0.0703166276216507,
    "learning_rate": 0.001
  },
  {
    "episode": 9658,
    "reward": 89.389382,
    "length": 65,
    "time": 142313.110593,
    "actor_loss": -67.01167297363281,
    "critic_loss": 3.4954237937927246,
    "ent_coef": 0.06806782633066177,
    "learning_rate": 0.001
  },
  {
    "episode": 9659,
    "reward": 87.695664,
    "length": 70,
    "time": 142326.422749,
    "actor_loss": -69.99105072021484,
    "critic_loss": 1.941083312034607,
    "ent_coef": 0.06732528656721115,
    "learning_rate": 0.001
  },
  {
    "episode": 9660,
    "reward": 86.983139,
    "length": 72,
    "time": 142341.868684,
    "actor_loss": -77.13605499267578,
    "critic_loss": 5.0797319412231445,
    "ent_coef": 0.06876208633184433,
    "learning_rate": 0.001
  },
  {
    "episode": 9661,
    "reward": 88.012884,
    "length": 67,
    "time": 142354.760981,
    "actor_loss": -68.5430908203125,
    "critic_loss": 4.398036003112793,
    "ent_coef": 0.06839467585086823,
    "learning_rate": 0.001
  },
  {
    "episode": 9662,
    "reward": 87.929577,
    "length": 66,
    "time": 142370.479369,
    "actor_loss": -68.60649108886719,
    "critic_loss": 4.5588274002075195,
    "ent_coef": 0.06696118414402008,
    "learning_rate": 0.001
  },
  {
    "episode": 9663,
    "reward": 83.702571,
    "length": 80,
    "time": 142386.829736,
    "actor_loss": -63.32368469238281,
    "critic_loss": 20.95166015625,
    "ent_coef": 0.0645359680056572,
    "learning_rate": 0.001
  },
  {
    "episode": 9664,
    "reward": 83.957749,
    "length": 73,
    "time": 142403.524821,
    "actor_loss": -59.44340515136719,
    "critic_loss": 31.735130310058594,
    "ent_coef": 0.06537088751792908,
    "learning_rate": 0.001
  },
  {
    "episode": 9665,
    "reward": 86.699672,
    "length": 72,
    "time": 142418.63699,
    "actor_loss": -73.91641998291016,
    "critic_loss": 6.166744232177734,
    "ent_coef": 0.06493820250034332,
    "learning_rate": 0.001
  },
  {
    "episode": 9666,
    "reward": 88.223887,
    "length": 67,
    "time": 142435.594889,
    "actor_loss": -74.01448059082031,
    "critic_loss": 8.244516372680664,
    "ent_coef": 0.06354043632745743,
    "learning_rate": 0.001
  },
  {
    "episode": 9667,
    "reward": 85.629837,
    "length": 74,
    "time": 142450.132422,
    "actor_loss": -71.59844970703125,
    "critic_loss": 5.039900302886963,
    "ent_coef": 0.061425477266311646,
    "learning_rate": 0.001
  },
  {
    "episode": 9668,
    "reward": 88.529596,
    "length": 67,
    "time": 142463.201365,
    "actor_loss": -67.98524475097656,
    "critic_loss": 6.692415237426758,
    "ent_coef": 0.06062179431319237,
    "learning_rate": 0.001
  },
  {
    "episode": 9669,
    "reward": 90.060425,
    "length": 64,
    "time": 142476.674529,
    "actor_loss": -67.6087417602539,
    "critic_loss": 2.629830837249756,
    "ent_coef": 0.06278195232152939,
    "learning_rate": 0.001
  },
  {
    "episode": 9670,
    "reward": 89.399168,
    "length": 67,
    "time": 142492.44592,
    "actor_loss": -71.52191162109375,
    "critic_loss": 7.356714248657227,
    "ent_coef": 0.06395066529512405,
    "learning_rate": 0.001
  },
  {
    "episode": 9671,
    "reward": 88.883693,
    "length": 63,
    "time": 142507.608009,
    "actor_loss": -64.97087860107422,
    "critic_loss": 16.439342498779297,
    "ent_coef": 0.06252612173557281,
    "learning_rate": 0.001
  },
  {
    "episode": 9672,
    "reward": 83.61599,
    "length": 118,
    "time": 142528.467688,
    "actor_loss": -68.1678695678711,
    "critic_loss": 5.0520734786987305,
    "ent_coef": 0.059212565422058105,
    "learning_rate": 0.001
  },
  {
    "episode": 9673,
    "reward": 88.220038,
    "length": 65,
    "time": 142541.783765,
    "actor_loss": -69.39533996582031,
    "critic_loss": 48.95960998535156,
    "ent_coef": 0.05965033173561096,
    "learning_rate": 0.001
  },
  {
    "episode": 9674,
    "reward": 88.410898,
    "length": 67,
    "time": 142555.610317,
    "actor_loss": -73.01183319091797,
    "critic_loss": 2.755837917327881,
    "ent_coef": 0.058240100741386414,
    "learning_rate": 0.001
  },
  {
    "episode": 9675,
    "reward": 87.754154,
    "length": 68,
    "time": 142567.952698,
    "actor_loss": -70.57672119140625,
    "critic_loss": 6.532318592071533,
    "ent_coef": 0.05681384727358818,
    "learning_rate": 0.001
  },
  {
    "episode": 9676,
    "reward": 88.992932,
    "length": 66,
    "time": 142581.180533,
    "actor_loss": -71.6385726928711,
    "critic_loss": 33.80806350708008,
    "ent_coef": 0.056063950061798096,
    "learning_rate": 0.001
  },
  {
    "episode": 9677,
    "reward": 91.304828,
    "length": 61,
    "time": 142594.612831,
    "actor_loss": -68.18418884277344,
    "critic_loss": 4.241213321685791,
    "ent_coef": 0.05665712431073189,
    "learning_rate": 0.001
  },
  {
    "episode": 9678,
    "reward": 90.448569,
    "length": 63,
    "time": 142607.886647,
    "actor_loss": -76.23128509521484,
    "critic_loss": 6.040071964263916,
    "ent_coef": 0.057814035564661026,
    "learning_rate": 0.001
  },
  {
    "episode": 9679,
    "reward": 79.418268,
    "length": 86,
    "time": 142623.880287,
    "actor_loss": -67.1869125366211,
    "critic_loss": 6.885567665100098,
    "ent_coef": 0.05609181150794029,
    "learning_rate": 0.001
  },
  {
    "episode": 9680,
    "reward": 92.448691,
    "length": 61,
    "time": 142637.27285,
    "actor_loss": -65.64552307128906,
    "critic_loss": 6.826176643371582,
    "ent_coef": 0.05821976438164711,
    "learning_rate": 0.001
  },
  {
    "episode": 9681,
    "reward": 90.178738,
    "length": 63,
    "time": 142650.583038,
    "actor_loss": -71.54197692871094,
    "critic_loss": 3.258394241333008,
    "ent_coef": 0.05977185070514679,
    "learning_rate": 0.001
  },
  {
    "episode": 9682,
    "reward": 91.368409,
    "length": 61,
    "time": 142662.473214,
    "actor_loss": -72.30770111083984,
    "critic_loss": 43.39495086669922,
    "ent_coef": 0.06247564032673836,
    "learning_rate": 0.001
  },
  {
    "episode": 9683,
    "reward": 89.920449,
    "length": 65,
    "time": 142675.095922,
    "actor_loss": -76.61520385742188,
    "critic_loss": 3.829500198364258,
    "ent_coef": 0.06249585375189781,
    "learning_rate": 0.001
  },
  {
    "episode": 9684,
    "reward": 90.783336,
    "length": 62,
    "time": 142686.713655,
    "actor_loss": -65.32527160644531,
    "critic_loss": 17.587501525878906,
    "ent_coef": 0.06287169456481934,
    "learning_rate": 0.001
  },
  {
    "episode": 9685,
    "reward": 92.414381,
    "length": 58,
    "time": 142697.926473,
    "actor_loss": -71.96823120117188,
    "critic_loss": 2.902350902557373,
    "ent_coef": 0.06547030061483383,
    "learning_rate": 0.001
  },
  {
    "episode": 9686,
    "reward": 90.535025,
    "length": 64,
    "time": 142711.188687,
    "actor_loss": -70.15162658691406,
    "critic_loss": 65.76262664794922,
    "ent_coef": 0.0674068033695221,
    "learning_rate": 0.001
  },
  {
    "episode": 9687,
    "reward": 89.611492,
    "length": 65,
    "time": 142722.798641,
    "actor_loss": -63.48782730102539,
    "critic_loss": 8.069718360900879,
    "ent_coef": 0.06801792234182358,
    "learning_rate": 0.001
  },
  {
    "episode": 9688,
    "reward": 83.813643,
    "length": 75,
    "time": 142736.177881,
    "actor_loss": -67.6512222290039,
    "critic_loss": 50.675636291503906,
    "ent_coef": 0.06338087469339371,
    "learning_rate": 0.001
  },
  {
    "episode": 9689,
    "reward": 78.028925,
    "length": 88,
    "time": 142750.676311,
    "actor_loss": -70.45384979248047,
    "critic_loss": 3.298884630203247,
    "ent_coef": 0.05790066346526146,
    "learning_rate": 0.001
  },
  {
    "episode": 9690,
    "reward": 89.280887,
    "length": 65,
    "time": 142764.147816,
    "actor_loss": -72.8208999633789,
    "critic_loss": 3.155512571334839,
    "ent_coef": 0.05863960459828377,
    "learning_rate": 0.001
  },
  {
    "episode": 9691,
    "reward": 91.038115,
    "length": 62,
    "time": 142780.700522,
    "actor_loss": -69.78251647949219,
    "critic_loss": 10.70113754272461,
    "ent_coef": 0.06009336933493614,
    "learning_rate": 0.001
  },
  {
    "episode": 9692,
    "reward": 84.929282,
    "length": 73,
    "time": 142794.588087,
    "actor_loss": -66.29267883300781,
    "critic_loss": 4.281948089599609,
    "ent_coef": 0.05915837734937668,
    "learning_rate": 0.001
  },
  {
    "episode": 9693,
    "reward": 85.042725,
    "length": 74,
    "time": 142809.143529,
    "actor_loss": -72.41853332519531,
    "critic_loss": 23.6113338470459,
    "ent_coef": 0.05720061808824539,
    "learning_rate": 0.001
  },
  {
    "episode": 9694,
    "reward": 80.456989,
    "length": 84,
    "time": 142824.888407,
    "actor_loss": -70.2783203125,
    "critic_loss": 4.737213134765625,
    "ent_coef": 0.05480504035949707,
    "learning_rate": 0.001
  },
  {
    "episode": 9695,
    "reward": 90.035055,
    "length": 65,
    "time": 142838.55391,
    "actor_loss": -67.75389099121094,
    "critic_loss": 36.10326385498047,
    "ent_coef": 0.05585499107837677,
    "learning_rate": 0.001
  },
  {
    "episode": 9696,
    "reward": 89.587019,
    "length": 65,
    "time": 142855.782492,
    "actor_loss": -69.58931732177734,
    "critic_loss": 15.86232852935791,
    "ent_coef": 0.05608304962515831,
    "learning_rate": 0.001
  },
  {
    "episode": 9697,
    "reward": 91.678011,
    "length": 61,
    "time": 142869.122848,
    "actor_loss": -71.30101013183594,
    "critic_loss": 2.5927681922912598,
    "ent_coef": 0.059393640607595444,
    "learning_rate": 0.001
  },
  {
    "episode": 9698,
    "reward": 93.36939,
    "length": 57,
    "time": 142880.797481,
    "actor_loss": -66.35648345947266,
    "critic_loss": 2.508972644805908,
    "ent_coef": 0.06263801455497742,
    "learning_rate": 0.001
  },
  {
    "episode": 9699,
    "reward": 90.938569,
    "length": 62,
    "time": 142895.671334,
    "actor_loss": -73.67527770996094,
    "critic_loss": 42.75236129760742,
    "ent_coef": 0.06612151116132736,
    "learning_rate": 0.001
  },
  {
    "episode": 9700,
    "reward": 91.212657,
    "length": 62,
    "time": 142908.063101,
    "actor_loss": -66.42499542236328,
    "critic_loss": 4.145812034606934,
    "ent_coef": 0.06921273469924927,
    "learning_rate": 0.001
  },
  {
    "episode": 9701,
    "reward": 88.809334,
    "length": 67,
    "time": 142921.36765,
    "actor_loss": -77.28233337402344,
    "critic_loss": 3.1313061714172363,
    "ent_coef": 0.07103793323040009,
    "learning_rate": 0.001
  },
  {
    "episode": 9702,
    "reward": 87.139522,
    "length": 71,
    "time": 142933.741122,
    "actor_loss": -72.97998046875,
    "critic_loss": 5.549150466918945,
    "ent_coef": 0.06800077110528946,
    "learning_rate": 0.001
  },
  {
    "episode": 9703,
    "reward": 88.276236,
    "length": 67,
    "time": 142945.544699,
    "actor_loss": -70.96055603027344,
    "critic_loss": 37.1197624206543,
    "ent_coef": 0.06631072610616684,
    "learning_rate": 0.001
  },
  {
    "episode": 9704,
    "reward": 86.276999,
    "length": 71,
    "time": 142967.070335,
    "actor_loss": -67.94857788085938,
    "critic_loss": 9.446826934814453,
    "ent_coef": 0.06509183347225189,
    "learning_rate": 0.001
  },
  {
    "episode": 9705,
    "reward": 89.816527,
    "length": 64,
    "time": 142978.537889,
    "actor_loss": -72.86282348632812,
    "critic_loss": 3.507913589477539,
    "ent_coef": 0.0683010071516037,
    "learning_rate": 0.001
  },
  {
    "episode": 9706,
    "reward": 91.205345,
    "length": 61,
    "time": 142992.315783,
    "actor_loss": -69.20769500732422,
    "critic_loss": 3.3856706619262695,
    "ent_coef": 0.06879345327615738,
    "learning_rate": 0.001
  },
  {
    "episode": 9707,
    "reward": 87.012071,
    "length": 69,
    "time": 143006.772939,
    "actor_loss": -67.02252197265625,
    "critic_loss": 20.129764556884766,
    "ent_coef": 0.07007116824388504,
    "learning_rate": 0.001
  },
  {
    "episode": 9708,
    "reward": 87.446195,
    "length": 68,
    "time": 143020.43137,
    "actor_loss": -61.88861846923828,
    "critic_loss": 3.4849414825439453,
    "ent_coef": 0.06834471225738525,
    "learning_rate": 0.001
  },
  {
    "episode": 9709,
    "reward": 87.885019,
    "length": 69,
    "time": 143032.405407,
    "actor_loss": -74.81755065917969,
    "critic_loss": 3.2957069873809814,
    "ent_coef": 0.0676511749625206,
    "learning_rate": 0.001
  },
  {
    "episode": 9710,
    "reward": 90.038735,
    "length": 64,
    "time": 143044.626967,
    "actor_loss": -71.46160888671875,
    "critic_loss": 2.512424945831299,
    "ent_coef": 0.06440947204828262,
    "learning_rate": 0.001
  },
  {
    "episode": 9711,
    "reward": 74.648722,
    "length": 97,
    "time": 143063.344691,
    "actor_loss": -69.6873550415039,
    "critic_loss": 5.941401958465576,
    "ent_coef": 0.0560549795627594,
    "learning_rate": 0.001
  },
  {
    "episode": 9712,
    "reward": 80.57982,
    "length": 81,
    "time": 143077.947182,
    "actor_loss": -70.51423645019531,
    "critic_loss": 2.5468406677246094,
    "ent_coef": 0.05347887799143791,
    "learning_rate": 0.001
  },
  {
    "episode": 9713,
    "reward": 88.215827,
    "length": 67,
    "time": 143089.629554,
    "actor_loss": -71.9986572265625,
    "critic_loss": 5.343466758728027,
    "ent_coef": 0.05486167594790459,
    "learning_rate": 0.001
  },
  {
    "episode": 9714,
    "reward": 90.358648,
    "length": 65,
    "time": 143103.218871,
    "actor_loss": -67.28703308105469,
    "critic_loss": 2.4783453941345215,
    "ent_coef": 0.05649034306406975,
    "learning_rate": 0.001
  },
  {
    "episode": 9715,
    "reward": 90.237311,
    "length": 63,
    "time": 143115.693207,
    "actor_loss": -64.83940124511719,
    "critic_loss": 4.48725700378418,
    "ent_coef": 0.05649203807115555,
    "learning_rate": 0.001
  },
  {
    "episode": 9716,
    "reward": 87.690251,
    "length": 70,
    "time": 143131.757425,
    "actor_loss": -70.50093841552734,
    "critic_loss": 142.05740356445312,
    "ent_coef": 0.054714135825634,
    "learning_rate": 0.001
  },
  {
    "episode": 9717,
    "reward": 80.365,
    "length": 81,
    "time": 143145.34361,
    "actor_loss": -74.28045654296875,
    "critic_loss": 4.690656661987305,
    "ent_coef": 0.05201088637113571,
    "learning_rate": 0.001
  },
  {
    "episode": 9718,
    "reward": 83.932685,
    "length": 77,
    "time": 143158.385498,
    "actor_loss": -68.9830322265625,
    "critic_loss": 92.77949523925781,
    "ent_coef": 0.052515458315610886,
    "learning_rate": 0.001
  },
  {
    "episode": 9719,
    "reward": 84.113876,
    "length": 75,
    "time": 143171.367361,
    "actor_loss": -68.23240661621094,
    "critic_loss": 3.3896484375,
    "ent_coef": 0.05142934247851372,
    "learning_rate": 0.001
  },
  {
    "episode": 9720,
    "reward": 86.065208,
    "length": 71,
    "time": 143183.469197,
    "actor_loss": -68.42257690429688,
    "critic_loss": 76.04959869384766,
    "ent_coef": 0.05213434621691704,
    "learning_rate": 0.001
  },
  {
    "episode": 9721,
    "reward": 89.14231,
    "length": 65,
    "time": 143196.284708,
    "actor_loss": -65.64959716796875,
    "critic_loss": 14.479536056518555,
    "ent_coef": 0.052836429327726364,
    "learning_rate": 0.001
  },
  {
    "episode": 9722,
    "reward": 88.447174,
    "length": 67,
    "time": 143209.205728,
    "actor_loss": -69.27088928222656,
    "critic_loss": 5.8509521484375,
    "ent_coef": 0.057175204157829285,
    "learning_rate": 0.001
  },
  {
    "episode": 9723,
    "reward": 88.929458,
    "length": 66,
    "time": 143221.169378,
    "actor_loss": -71.69607543945312,
    "critic_loss": 3.943800926208496,
    "ent_coef": 0.06005232036113739,
    "learning_rate": 0.001
  },
  {
    "episode": 9724,
    "reward": 90.648251,
    "length": 63,
    "time": 143232.184278,
    "actor_loss": -63.70084762573242,
    "critic_loss": 6.8141021728515625,
    "ent_coef": 0.06284819543361664,
    "learning_rate": 0.001
  },
  {
    "episode": 9725,
    "reward": 88.227278,
    "length": 69,
    "time": 143244.368825,
    "actor_loss": -66.90294647216797,
    "critic_loss": 13.237502098083496,
    "ent_coef": 0.06395921856164932,
    "learning_rate": 0.001
  },
  {
    "episode": 9726,
    "reward": 87.006879,
    "length": 71,
    "time": 143259.43195,
    "actor_loss": -69.83824920654297,
    "critic_loss": 3.3821258544921875,
    "ent_coef": 0.0628727450966835,
    "learning_rate": 0.001
  },
  {
    "episode": 9727,
    "reward": 85.698885,
    "length": 73,
    "time": 143273.00868,
    "actor_loss": -78.19584655761719,
    "critic_loss": 30.648286819458008,
    "ent_coef": 0.06345225870609283,
    "learning_rate": 0.001
  },
  {
    "episode": 9728,
    "reward": 89.590298,
    "length": 65,
    "time": 143285.304198,
    "actor_loss": -71.73019409179688,
    "critic_loss": 4.538664817810059,
    "ent_coef": 0.06676255911588669,
    "learning_rate": 0.001
  },
  {
    "episode": 9729,
    "reward": 89.595172,
    "length": 66,
    "time": 143299.199177,
    "actor_loss": -69.51025390625,
    "critic_loss": 2.5401837825775146,
    "ent_coef": 0.06811778247356415,
    "learning_rate": 0.001
  },
  {
    "episode": 9730,
    "reward": 90.371156,
    "length": 63,
    "time": 143310.292303,
    "actor_loss": -68.73592376708984,
    "critic_loss": 4.356891632080078,
    "ent_coef": 0.06900636106729507,
    "learning_rate": 0.001
  },
  {
    "episode": 9731,
    "reward": 89.929208,
    "length": 64,
    "time": 143321.919499,
    "actor_loss": -70.8487548828125,
    "critic_loss": 4.7470879554748535,
    "ent_coef": 0.07172134518623352,
    "learning_rate": 0.001
  },
  {
    "episode": 9732,
    "reward": 83.930701,
    "length": 76,
    "time": 143336.420455,
    "actor_loss": -71.86741638183594,
    "critic_loss": 2.8671605587005615,
    "ent_coef": 0.06995358318090439,
    "learning_rate": 0.001
  },
  {
    "episode": 9733,
    "reward": 89.950524,
    "length": 64,
    "time": 143349.802667,
    "actor_loss": -68.7772216796875,
    "critic_loss": 3.3689403533935547,
    "ent_coef": 0.07052379101514816,
    "learning_rate": 0.001
  },
  {
    "episode": 9734,
    "reward": 86.534312,
    "length": 70,
    "time": 143362.584774,
    "actor_loss": -70.30685424804688,
    "critic_loss": 15.68508243560791,
    "ent_coef": 0.06902599334716797,
    "learning_rate": 0.001
  },
  {
    "episode": 9735,
    "reward": 88.747855,
    "length": 66,
    "time": 143374.442922,
    "actor_loss": -65.58872985839844,
    "critic_loss": 17.020469665527344,
    "ent_coef": 0.07077005505561829,
    "learning_rate": 0.001
  },
  {
    "episode": 9736,
    "reward": 87.312009,
    "length": 71,
    "time": 143387.6852,
    "actor_loss": -67.75749206542969,
    "critic_loss": 15.787199020385742,
    "ent_coef": 0.06998094171285629,
    "learning_rate": 0.001
  },
  {
    "episode": 9737,
    "reward": 88.495066,
    "length": 68,
    "time": 143400.853894,
    "actor_loss": -72.7274169921875,
    "critic_loss": 2.6202468872070312,
    "ent_coef": 0.06948471814393997,
    "learning_rate": 0.001
  },
  {
    "episode": 9738,
    "reward": 89.993207,
    "length": 65,
    "time": 143414.134073,
    "actor_loss": -68.32122802734375,
    "critic_loss": 16.446720123291016,
    "ent_coef": 0.06945939362049103,
    "learning_rate": 0.001
  },
  {
    "episode": 9739,
    "reward": 82.115115,
    "length": 81,
    "time": 143428.271838,
    "actor_loss": -73.82730102539062,
    "critic_loss": 1.9161624908447266,
    "ent_coef": 0.0666666179895401,
    "learning_rate": 0.001
  },
  {
    "episode": 9740,
    "reward": 91.423596,
    "length": 61,
    "time": 143439.226547,
    "actor_loss": -67.59124755859375,
    "critic_loss": 4.09405517578125,
    "ent_coef": 0.06808438152074814,
    "learning_rate": 0.001
  },
  {
    "episode": 9741,
    "reward": 90.042693,
    "length": 64,
    "time": 143450.985272,
    "actor_loss": -69.13520050048828,
    "critic_loss": 14.878740310668945,
    "ent_coef": 0.0711006447672844,
    "learning_rate": 0.001
  },
  {
    "episode": 9742,
    "reward": 88.44981,
    "length": 66,
    "time": 143464.158136,
    "actor_loss": -72.15318298339844,
    "critic_loss": 3.7281670570373535,
    "ent_coef": 0.06888172030448914,
    "learning_rate": 0.001
  },
  {
    "episode": 9743,
    "reward": 86.881524,
    "length": 69,
    "time": 143476.147931,
    "actor_loss": -66.27117919921875,
    "critic_loss": 15.759333610534668,
    "ent_coef": 0.06611698865890503,
    "learning_rate": 0.001
  },
  {
    "episode": 9744,
    "reward": 86.772169,
    "length": 72,
    "time": 143488.486048,
    "actor_loss": -71.51483154296875,
    "critic_loss": 3.9331915378570557,
    "ent_coef": 0.06625531613826752,
    "learning_rate": 0.001
  },
  {
    "episode": 9745,
    "reward": 83.233343,
    "length": 77,
    "time": 143504.586987,
    "actor_loss": -66.44633483886719,
    "critic_loss": 7.902906894683838,
    "ent_coef": 0.06499835103750229,
    "learning_rate": 0.001
  },
  {
    "episode": 9746,
    "reward": 86.084709,
    "length": 70,
    "time": 143518.563209,
    "actor_loss": -70.53021240234375,
    "critic_loss": 2.7596302032470703,
    "ent_coef": 0.062483012676239014,
    "learning_rate": 0.001
  },
  {
    "episode": 9747,
    "reward": 90.209693,
    "length": 63,
    "time": 143529.793543,
    "actor_loss": -70.82209014892578,
    "critic_loss": 31.744861602783203,
    "ent_coef": 0.06404868513345718,
    "learning_rate": 0.001
  },
  {
    "episode": 9748,
    "reward": 89.42768,
    "length": 65,
    "time": 143542.22902,
    "actor_loss": -71.80880737304688,
    "critic_loss": 8.48106575012207,
    "ent_coef": 0.06178334355354309,
    "learning_rate": 0.001
  },
  {
    "episode": 9749,
    "reward": 87.81205,
    "length": 67,
    "time": 143555.439809,
    "actor_loss": -68.4613037109375,
    "critic_loss": 65.38604736328125,
    "ent_coef": 0.061081815510988235,
    "learning_rate": 0.001
  },
  {
    "episode": 9750,
    "reward": 89.700561,
    "length": 65,
    "time": 143568.938779,
    "actor_loss": -65.28311157226562,
    "critic_loss": 2.5039596557617188,
    "ent_coef": 0.06158049777150154,
    "learning_rate": 0.001
  },
  {
    "episode": 9751,
    "reward": 89.545138,
    "length": 64,
    "time": 143581.756708,
    "actor_loss": -68.69923400878906,
    "critic_loss": 68.09056854248047,
    "ent_coef": 0.06005329266190529,
    "learning_rate": 0.001
  },
  {
    "episode": 9752,
    "reward": 83.265293,
    "length": 78,
    "time": 143596.002871,
    "actor_loss": -65.38182830810547,
    "critic_loss": 6.309413909912109,
    "ent_coef": 0.0590246245265007,
    "learning_rate": 0.001
  },
  {
    "episode": 9753,
    "reward": 91.822715,
    "length": 60,
    "time": 143606.751033,
    "actor_loss": -68.86027526855469,
    "critic_loss": 4.823852062225342,
    "ent_coef": 0.06054043397307396,
    "learning_rate": 0.001
  },
  {
    "episode": 9754,
    "reward": 87.957302,
    "length": 67,
    "time": 143619.969082,
    "actor_loss": -65.82289123535156,
    "critic_loss": 133.02175903320312,
    "ent_coef": 0.06111989542841911,
    "learning_rate": 0.001
  },
  {
    "episode": 9755,
    "reward": 82.191101,
    "length": 81,
    "time": 143633.516845,
    "actor_loss": -72.82101440429688,
    "critic_loss": 2.2147436141967773,
    "ent_coef": 0.05822453647851944,
    "learning_rate": 0.001
  },
  {
    "episode": 9756,
    "reward": 89.238918,
    "length": 65,
    "time": 143644.966268,
    "actor_loss": -66.52677917480469,
    "critic_loss": 3.5339715480804443,
    "ent_coef": 0.05674119293689728,
    "learning_rate": 0.001
  },
  {
    "episode": 9757,
    "reward": 88.363152,
    "length": 68,
    "time": 143658.463817,
    "actor_loss": -74.57368469238281,
    "critic_loss": 9.1414213180542,
    "ent_coef": 0.05515177920460701,
    "learning_rate": 0.001
  },
  {
    "episode": 9758,
    "reward": 88.28889,
    "length": 68,
    "time": 143671.391508,
    "actor_loss": -65.34455108642578,
    "critic_loss": 3.6509392261505127,
    "ent_coef": 0.05497713387012482,
    "learning_rate": 0.001
  },
  {
    "episode": 9759,
    "reward": 89.999121,
    "length": 65,
    "time": 143682.952517,
    "actor_loss": -70.11859130859375,
    "critic_loss": 9.702557563781738,
    "ent_coef": 0.05883786454796791,
    "learning_rate": 0.001
  },
  {
    "episode": 9760,
    "reward": 90.58225,
    "length": 63,
    "time": 143694.133167,
    "actor_loss": -69.74270629882812,
    "critic_loss": 2.8477187156677246,
    "ent_coef": 0.06085537374019623,
    "learning_rate": 0.001
  },
  {
    "episode": 9761,
    "reward": 89.528744,
    "length": 64,
    "time": 143705.640028,
    "actor_loss": -72.092041015625,
    "critic_loss": 2.413677453994751,
    "ent_coef": 0.06191345676779747,
    "learning_rate": 0.001
  },
  {
    "episode": 9762,
    "reward": 84.684724,
    "length": 74,
    "time": 143718.185817,
    "actor_loss": -67.25761413574219,
    "critic_loss": 7.267716884613037,
    "ent_coef": 0.061528872698545456,
    "learning_rate": 0.001
  },
  {
    "episode": 9763,
    "reward": 90.135989,
    "length": 64,
    "time": 143733.246238,
    "actor_loss": -64.44052124023438,
    "critic_loss": 2.8251256942749023,
    "ent_coef": 0.06035325303673744,
    "learning_rate": 0.001
  },
  {
    "episode": 9764,
    "reward": 85.54151,
    "length": 73,
    "time": 143746.428566,
    "actor_loss": -67.69247436523438,
    "critic_loss": 6.618024826049805,
    "ent_coef": 0.0599353052675724,
    "learning_rate": 0.001
  },
  {
    "episode": 9765,
    "reward": 91.791151,
    "length": 60,
    "time": 143757.46493,
    "actor_loss": -65.83553314208984,
    "critic_loss": 10.656026840209961,
    "ent_coef": 0.062196604907512665,
    "learning_rate": 0.001
  },
  {
    "episode": 9766,
    "reward": 91.456471,
    "length": 61,
    "time": 143768.686688,
    "actor_loss": -75.81877136230469,
    "critic_loss": 46.9052734375,
    "ent_coef": 0.06331827491521835,
    "learning_rate": 0.001
  },
  {
    "episode": 9767,
    "reward": 91.445232,
    "length": 62,
    "time": 143780.60804,
    "actor_loss": -74.5254135131836,
    "critic_loss": 3.9474387168884277,
    "ent_coef": 0.06529350578784943,
    "learning_rate": 0.001
  },
  {
    "episode": 9768,
    "reward": 90.761088,
    "length": 63,
    "time": 143792.212514,
    "actor_loss": -73.26199340820312,
    "critic_loss": 29.61839485168457,
    "ent_coef": 0.06564911454916,
    "learning_rate": 0.001
  },
  {
    "episode": 9769,
    "reward": 89.250524,
    "length": 65,
    "time": 143803.858422,
    "actor_loss": -64.38297271728516,
    "critic_loss": 2.433082342147827,
    "ent_coef": 0.06660851836204529,
    "learning_rate": 0.001
  },
  {
    "episode": 9770,
    "reward": 90.855245,
    "length": 63,
    "time": 143816.98782,
    "actor_loss": -68.7853012084961,
    "critic_loss": 5.961406707763672,
    "ent_coef": 0.06747755408287048,
    "learning_rate": 0.001
  },
  {
    "episode": 9771,
    "reward": 89.083894,
    "length": 66,
    "time": 143831.622489,
    "actor_loss": -67.09027862548828,
    "critic_loss": 1.519805908203125,
    "ent_coef": 0.06702638417482376,
    "learning_rate": 0.001
  },
  {
    "episode": 9772,
    "reward": 87.792025,
    "length": 68,
    "time": 143845.354675,
    "actor_loss": -70.12355041503906,
    "critic_loss": 2.641566753387451,
    "ent_coef": 0.06507876515388489,
    "learning_rate": 0.001
  },
  {
    "episode": 9773,
    "reward": 87.00966,
    "length": 71,
    "time": 143860.530998,
    "actor_loss": -70.07087707519531,
    "critic_loss": 2.3092427253723145,
    "ent_coef": 0.06393039226531982,
    "learning_rate": 0.001
  },
  {
    "episode": 9774,
    "reward": 90.733115,
    "length": 62,
    "time": 143871.668107,
    "actor_loss": -66.25724792480469,
    "critic_loss": 3.0813050270080566,
    "ent_coef": 0.06374061852693558,
    "learning_rate": 0.001
  },
  {
    "episode": 9775,
    "reward": 89.868852,
    "length": 65,
    "time": 143885.550086,
    "actor_loss": -70.2235107421875,
    "critic_loss": 2.3371129035949707,
    "ent_coef": 0.06492626667022705,
    "learning_rate": 0.001
  },
  {
    "episode": 9776,
    "reward": 88.305072,
    "length": 69,
    "time": 143898.351977,
    "actor_loss": -67.42210388183594,
    "critic_loss": 37.11336898803711,
    "ent_coef": 0.06450473517179489,
    "learning_rate": 0.001
  },
  {
    "episode": 9777,
    "reward": 88.23791,
    "length": 68,
    "time": 143912.931577,
    "actor_loss": -68.27139282226562,
    "critic_loss": 5.414174556732178,
    "ent_coef": 0.06345537304878235,
    "learning_rate": 0.001
  },
  {
    "episode": 9778,
    "reward": 89.965077,
    "length": 66,
    "time": 143926.240282,
    "actor_loss": -71.23820495605469,
    "critic_loss": 3.59060001373291,
    "ent_coef": 0.06281465291976929,
    "learning_rate": 0.001
  },
  {
    "episode": 9779,
    "reward": 91.669498,
    "length": 62,
    "time": 143937.299046,
    "actor_loss": -68.5377426147461,
    "critic_loss": 7.3635735511779785,
    "ent_coef": 0.06364183872938156,
    "learning_rate": 0.001
  },
  {
    "episode": 9780,
    "reward": 89.245634,
    "length": 65,
    "time": 143949.963914,
    "actor_loss": -70.04938507080078,
    "critic_loss": 13.870612144470215,
    "ent_coef": 0.06482867151498795,
    "learning_rate": 0.001
  },
  {
    "episode": 9781,
    "reward": 89.004047,
    "length": 66,
    "time": 143963.287972,
    "actor_loss": -72.24508666992188,
    "critic_loss": 3.0388474464416504,
    "ent_coef": 0.06525347381830215,
    "learning_rate": 0.001
  },
  {
    "episode": 9782,
    "reward": 88.844025,
    "length": 66,
    "time": 143976.442975,
    "actor_loss": -73.02726745605469,
    "critic_loss": 6.149827003479004,
    "ent_coef": 0.06198543310165405,
    "learning_rate": 0.001
  },
  {
    "episode": 9783,
    "reward": 89.854117,
    "length": 65,
    "time": 143988.81081,
    "actor_loss": -68.08428192138672,
    "critic_loss": 3.549586772918701,
    "ent_coef": 0.06013144925236702,
    "learning_rate": 0.001
  },
  {
    "episode": 9784,
    "reward": 90.931973,
    "length": 63,
    "time": 144000.215766,
    "actor_loss": -68.80928039550781,
    "critic_loss": 3.7422800064086914,
    "ent_coef": 0.061906490474939346,
    "learning_rate": 0.001
  },
  {
    "episode": 9785,
    "reward": 89.030945,
    "length": 66,
    "time": 144013.010943,
    "actor_loss": -66.02721405029297,
    "critic_loss": 3.111837148666382,
    "ent_coef": 0.06051940843462944,
    "learning_rate": 0.001
  },
  {
    "episode": 9786,
    "reward": 88.259624,
    "length": 69,
    "time": 144027.040159,
    "actor_loss": -68.12928009033203,
    "critic_loss": 19.491710662841797,
    "ent_coef": 0.058788228780031204,
    "learning_rate": 0.001
  },
  {
    "episode": 9787,
    "reward": 85.557058,
    "length": 74,
    "time": 144039.503203,
    "actor_loss": -71.51786804199219,
    "critic_loss": 6.468814849853516,
    "ent_coef": 0.05563163384795189,
    "learning_rate": 0.001
  },
  {
    "episode": 9788,
    "reward": 88.205924,
    "length": 66,
    "time": 144055.523513,
    "actor_loss": -65.97350311279297,
    "critic_loss": 2.6034669876098633,
    "ent_coef": 0.05388680845499039,
    "learning_rate": 0.001
  },
  {
    "episode": 9789,
    "reward": 89.077576,
    "length": 66,
    "time": 144070.165214,
    "actor_loss": -66.05670928955078,
    "critic_loss": 54.082550048828125,
    "ent_coef": 0.05542207881808281,
    "learning_rate": 0.001
  },
  {
    "episode": 9790,
    "reward": 92.134248,
    "length": 60,
    "time": 144081.675948,
    "actor_loss": -64.71125793457031,
    "critic_loss": 5.314052581787109,
    "ent_coef": 0.056292906403541565,
    "learning_rate": 0.001
  },
  {
    "episode": 9791,
    "reward": 90.133671,
    "length": 63,
    "time": 144094.68355,
    "actor_loss": -73.8765869140625,
    "critic_loss": 11.090372085571289,
    "ent_coef": 0.0568414181470871,
    "learning_rate": 0.001
  },
  {
    "episode": 9792,
    "reward": 90.398092,
    "length": 64,
    "time": 144109.15188,
    "actor_loss": -67.3558349609375,
    "critic_loss": 4.389206886291504,
    "ent_coef": 0.05570625513792038,
    "learning_rate": 0.001
  },
  {
    "episode": 9793,
    "reward": 89.578317,
    "length": 65,
    "time": 144120.835513,
    "actor_loss": -75.16133117675781,
    "critic_loss": 359.8226013183594,
    "ent_coef": 0.054993271827697754,
    "learning_rate": 0.001
  },
  {
    "episode": 9794,
    "reward": 91.090753,
    "length": 61,
    "time": 144132.764313,
    "actor_loss": -74.72874450683594,
    "critic_loss": 35.400821685791016,
    "ent_coef": 0.057535141706466675,
    "learning_rate": 0.001
  },
  {
    "episode": 9795,
    "reward": 90.618133,
    "length": 63,
    "time": 144144.295369,
    "actor_loss": -70.45387268066406,
    "critic_loss": 3.7967729568481445,
    "ent_coef": 0.05775587260723114,
    "learning_rate": 0.001
  },
  {
    "episode": 9796,
    "reward": 88.577776,
    "length": 69,
    "time": 144158.599765,
    "actor_loss": -64.28845977783203,
    "critic_loss": 3.794696807861328,
    "ent_coef": 0.058334071189165115,
    "learning_rate": 0.001
  },
  {
    "episode": 9797,
    "reward": 88.654847,
    "length": 66,
    "time": 144172.354984,
    "actor_loss": -62.830326080322266,
    "critic_loss": 41.50914001464844,
    "ent_coef": 0.05759367719292641,
    "learning_rate": 0.001
  },
  {
    "episode": 9798,
    "reward": 90.370628,
    "length": 64,
    "time": 144185.339711,
    "actor_loss": -69.48112487792969,
    "critic_loss": 4.303487300872803,
    "ent_coef": 0.056149762123823166,
    "learning_rate": 0.001
  },
  {
    "episode": 9799,
    "reward": 90.824444,
    "length": 63,
    "time": 144198.763303,
    "actor_loss": -76.27774810791016,
    "critic_loss": 2.029080867767334,
    "ent_coef": 0.055537570267915726,
    "learning_rate": 0.001
  },
  {
    "episode": 9800,
    "reward": 90.442488,
    "length": 62,
    "time": 144210.916675,
    "actor_loss": -68.87864685058594,
    "critic_loss": 4.717848777770996,
    "ent_coef": 0.05643665790557861,
    "learning_rate": 0.001
  },
  {
    "episode": 9801,
    "reward": 89.474134,
    "length": 66,
    "time": 144223.919397,
    "actor_loss": -68.01210021972656,
    "critic_loss": 1.9744834899902344,
    "ent_coef": 0.05489538237452507,
    "learning_rate": 0.001
  },
  {
    "episode": 9802,
    "reward": 87.614413,
    "length": 69,
    "time": 144238.46786,
    "actor_loss": -75.91514587402344,
    "critic_loss": 17.312015533447266,
    "ent_coef": 0.0550670363008976,
    "learning_rate": 0.001
  },
  {
    "episode": 9803,
    "reward": 88.725329,
    "length": 67,
    "time": 144251.978462,
    "actor_loss": -68.19583129882812,
    "critic_loss": 6.089856147766113,
    "ent_coef": 0.05403652414679527,
    "learning_rate": 0.001
  },
  {
    "episode": 9804,
    "reward": 89.742217,
    "length": 64,
    "time": 144266.168177,
    "actor_loss": -71.18914794921875,
    "critic_loss": 2.5859286785125732,
    "ent_coef": 0.05366670340299606,
    "learning_rate": 0.001
  },
  {
    "episode": 9805,
    "reward": 88.993845,
    "length": 66,
    "time": 144278.67033,
    "actor_loss": -64.93602752685547,
    "critic_loss": 3.6179118156433105,
    "ent_coef": 0.0550265870988369,
    "learning_rate": 0.001
  },
  {
    "episode": 9806,
    "reward": 89.499814,
    "length": 66,
    "time": 144291.30368,
    "actor_loss": -66.96255493164062,
    "critic_loss": 7.782203674316406,
    "ent_coef": 0.05787111446261406,
    "learning_rate": 0.001
  },
  {
    "episode": 9807,
    "reward": 88.537146,
    "length": 68,
    "time": 144306.33856,
    "actor_loss": -66.95242309570312,
    "critic_loss": 2.4518308639526367,
    "ent_coef": 0.060729432851076126,
    "learning_rate": 0.001
  },
  {
    "episode": 9808,
    "reward": 89.001794,
    "length": 68,
    "time": 144320.891969,
    "actor_loss": -70.16111755371094,
    "critic_loss": 2.711772918701172,
    "ent_coef": 0.0628938376903534,
    "learning_rate": 0.001
  },
  {
    "episode": 9809,
    "reward": 90.960856,
    "length": 62,
    "time": 144332.183208,
    "actor_loss": -78.1838150024414,
    "critic_loss": 18.68028450012207,
    "ent_coef": 0.06397727876901627,
    "learning_rate": 0.001
  },
  {
    "episode": 9810,
    "reward": 90.144995,
    "length": 63,
    "time": 144344.042247,
    "actor_loss": -71.29475402832031,
    "critic_loss": 21.622304916381836,
    "ent_coef": 0.06397023051977158,
    "learning_rate": 0.001
  },
  {
    "episode": 9811,
    "reward": 90.825751,
    "length": 62,
    "time": 144356.19015,
    "actor_loss": -67.83788299560547,
    "critic_loss": 3.2346718311309814,
    "ent_coef": 0.06384436041116714,
    "learning_rate": 0.001
  },
  {
    "episode": 9812,
    "reward": 88.778884,
    "length": 65,
    "time": 144368.489245,
    "actor_loss": -66.23201751708984,
    "critic_loss": 11.694531440734863,
    "ent_coef": 0.06200866773724556,
    "learning_rate": 0.001
  },
  {
    "episode": 9813,
    "reward": 88.739814,
    "length": 65,
    "time": 144380.5489,
    "actor_loss": -69.96040344238281,
    "critic_loss": 3.7913808822631836,
    "ent_coef": 0.06043325364589691,
    "learning_rate": 0.001
  },
  {
    "episode": 9814,
    "reward": 85.831527,
    "length": 70,
    "time": 144392.939441,
    "actor_loss": -62.443580627441406,
    "critic_loss": 8.227385520935059,
    "ent_coef": 0.057097285985946655,
    "learning_rate": 0.001
  },
  {
    "episode": 9815,
    "reward": 88.945571,
    "length": 67,
    "time": 144404.858945,
    "actor_loss": -70.50810241699219,
    "critic_loss": 100.2635498046875,
    "ent_coef": 0.055848345160484314,
    "learning_rate": 0.001
  },
  {
    "episode": 9816,
    "reward": 88.462453,
    "length": 68,
    "time": 144418.258977,
    "actor_loss": -72.23236846923828,
    "critic_loss": 67.83431243896484,
    "ent_coef": 0.054978303611278534,
    "learning_rate": 0.001
  },
  {
    "episode": 9817,
    "reward": 82.244777,
    "length": 77,
    "time": 144434.503973,
    "actor_loss": -67.03099060058594,
    "critic_loss": 6.8147077560424805,
    "ent_coef": 0.0538107268512249,
    "learning_rate": 0.001
  },
  {
    "episode": 9818,
    "reward": 88.173342,
    "length": 67,
    "time": 144446.042379,
    "actor_loss": -74.17515563964844,
    "critic_loss": 12.08349895477295,
    "ent_coef": 0.05153099074959755,
    "learning_rate": 0.001
  },
  {
    "episode": 9819,
    "reward": 86.922638,
    "length": 69,
    "time": 144460.621561,
    "actor_loss": -70.64158630371094,
    "critic_loss": 132.25216674804688,
    "ent_coef": 0.04886592552065849,
    "learning_rate": 0.001
  },
  {
    "episode": 9820,
    "reward": 86.575928,
    "length": 71,
    "time": 144472.853576,
    "actor_loss": -69.39361572265625,
    "critic_loss": 52.21617126464844,
    "ent_coef": 0.05012420192360878,
    "learning_rate": 0.001
  },
  {
    "episode": 9821,
    "reward": 82.202758,
    "length": 78,
    "time": 144487.395792,
    "actor_loss": -70.27838134765625,
    "critic_loss": 3.8024439811706543,
    "ent_coef": 0.04723381623625755,
    "learning_rate": 0.001
  },
  {
    "episode": 9822,
    "reward": 79.607463,
    "length": 82,
    "time": 144502.493114,
    "actor_loss": -73.9185791015625,
    "critic_loss": 8.059306144714355,
    "ent_coef": 0.04630419984459877,
    "learning_rate": 0.001
  },
  {
    "episode": 9823,
    "reward": -158.304173,
    "length": 132,
    "time": 144524.090233,
    "actor_loss": -70.38047790527344,
    "critic_loss": 24.902555465698242,
    "ent_coef": 0.04894649237394333,
    "learning_rate": 0.001
  },
  {
    "episode": 9824,
    "reward": 82.102275,
    "length": 82,
    "time": 144538.573485,
    "actor_loss": -67.78994750976562,
    "critic_loss": 26.01038360595703,
    "ent_coef": 0.048743728548288345,
    "learning_rate": 0.001
  },
  {
    "episode": 9825,
    "reward": 84.320799,
    "length": 77,
    "time": 144554.064799,
    "actor_loss": -70.19559478759766,
    "critic_loss": 8.137225151062012,
    "ent_coef": 0.04657784104347229,
    "learning_rate": 0.001
  },
  {
    "episode": 9826,
    "reward": 86.626748,
    "length": 70,
    "time": 144568.58257,
    "actor_loss": -73.27999877929688,
    "critic_loss": 3.8542895317077637,
    "ent_coef": 0.046427711844444275,
    "learning_rate": 0.001
  },
  {
    "episode": 9827,
    "reward": 80.71566,
    "length": 82,
    "time": 144582.263808,
    "actor_loss": -69.1866226196289,
    "critic_loss": 41.66172790527344,
    "ent_coef": 0.045262813568115234,
    "learning_rate": 0.001
  },
  {
    "episode": 9828,
    "reward": 70.400938,
    "length": 98,
    "time": 144599.224429,
    "actor_loss": -67.38398742675781,
    "critic_loss": 2.4117774963378906,
    "ent_coef": 0.04439915344119072,
    "learning_rate": 0.001
  },
  {
    "episode": 9829,
    "reward": 84.848865,
    "length": 75,
    "time": 144611.926888,
    "actor_loss": -64.68646240234375,
    "critic_loss": 4.007054328918457,
    "ent_coef": 0.04511613771319389,
    "learning_rate": 0.001
  },
  {
    "episode": 9830,
    "reward": 87.396098,
    "length": 71,
    "time": 144624.678974,
    "actor_loss": -64.11679077148438,
    "critic_loss": 5.97258996963501,
    "ent_coef": 0.04560873284935951,
    "learning_rate": 0.001
  },
  {
    "episode": 9831,
    "reward": 87.797557,
    "length": 69,
    "time": 144638.042252,
    "actor_loss": -68.31396484375,
    "critic_loss": 1.8437604904174805,
    "ent_coef": 0.046919871121644974,
    "learning_rate": 0.001
  },
  {
    "episode": 9832,
    "reward": 87.273065,
    "length": 70,
    "time": 144650.588061,
    "actor_loss": -71.00370788574219,
    "critic_loss": 6.1760382652282715,
    "ent_coef": 0.04815877228975296,
    "learning_rate": 0.001
  },
  {
    "episode": 9833,
    "reward": 83.055921,
    "length": 75,
    "time": 144663.355726,
    "actor_loss": -69.46155548095703,
    "critic_loss": 54.457889556884766,
    "ent_coef": 0.04603544622659683,
    "learning_rate": 0.001
  },
  {
    "episode": 9834,
    "reward": 84.427693,
    "length": 73,
    "time": 144676.75229,
    "actor_loss": -69.11520385742188,
    "critic_loss": 28.836275100708008,
    "ent_coef": 0.046813786029815674,
    "learning_rate": 0.001
  },
  {
    "episode": 9835,
    "reward": 86.121887,
    "length": 69,
    "time": 144689.783832,
    "actor_loss": -72.16584777832031,
    "critic_loss": 4.195335388183594,
    "ent_coef": 0.04917200282216072,
    "learning_rate": 0.001
  },
  {
    "episode": 9836,
    "reward": 86.051017,
    "length": 72,
    "time": 144703.045097,
    "actor_loss": -69.78645324707031,
    "critic_loss": 10.514713287353516,
    "ent_coef": 0.048978835344314575,
    "learning_rate": 0.001
  },
  {
    "episode": 9837,
    "reward": 86.670421,
    "length": 69,
    "time": 144717.801176,
    "actor_loss": -68.39425659179688,
    "critic_loss": 22.10619354248047,
    "ent_coef": 0.04845581576228142,
    "learning_rate": 0.001
  },
  {
    "episode": 9838,
    "reward": 78.915872,
    "length": 83,
    "time": 144731.412552,
    "actor_loss": -65.5738525390625,
    "critic_loss": 8.214152336120605,
    "ent_coef": 0.04804891347885132,
    "learning_rate": 0.001
  },
  {
    "episode": 9839,
    "reward": 86.406286,
    "length": 70,
    "time": 144744.420383,
    "actor_loss": -72.64353942871094,
    "critic_loss": 4.411362648010254,
    "ent_coef": 0.047152310609817505,
    "learning_rate": 0.001
  },
  {
    "episode": 9840,
    "reward": 78.223675,
    "length": 84,
    "time": 144760.632108,
    "actor_loss": -64.9999771118164,
    "critic_loss": 1.7315493822097778,
    "ent_coef": 0.044275034219026566,
    "learning_rate": 0.001
  },
  {
    "episode": 9841,
    "reward": 75.845337,
    "length": 93,
    "time": 144775.743212,
    "actor_loss": -68.18317413330078,
    "critic_loss": 47.1433219909668,
    "ent_coef": 0.041018083691596985,
    "learning_rate": 0.001
  },
  {
    "episode": 9842,
    "reward": 68.799074,
    "length": 96,
    "time": 144792.562789,
    "actor_loss": -65.5536880493164,
    "critic_loss": 10.257200241088867,
    "ent_coef": 0.04217331111431122,
    "learning_rate": 0.001
  },
  {
    "episode": 9843,
    "reward": 85.340751,
    "length": 71,
    "time": 144805.814307,
    "actor_loss": -68.48426055908203,
    "critic_loss": 31.574569702148438,
    "ent_coef": 0.04352333024144173,
    "learning_rate": 0.001
  },
  {
    "episode": 9844,
    "reward": 87.460071,
    "length": 72,
    "time": 144820.449211,
    "actor_loss": -73.50587463378906,
    "critic_loss": 12.737188339233398,
    "ent_coef": 0.04556537792086601,
    "learning_rate": 0.001
  },
  {
    "episode": 9845,
    "reward": 85.153346,
    "length": 73,
    "time": 144836.299447,
    "actor_loss": -68.70852661132812,
    "critic_loss": 6.8875346183776855,
    "ent_coef": 0.045880481600761414,
    "learning_rate": 0.001
  },
  {
    "episode": 9846,
    "reward": 87.721953,
    "length": 65,
    "time": 144848.934485,
    "actor_loss": -65.52959442138672,
    "critic_loss": 15.421995162963867,
    "ent_coef": 0.047237690538167953,
    "learning_rate": 0.001
  },
  {
    "episode": 9847,
    "reward": 91.017454,
    "length": 61,
    "time": 144862.983075,
    "actor_loss": -71.48981475830078,
    "critic_loss": 65.81785583496094,
    "ent_coef": 0.052191220223903656,
    "learning_rate": 0.001
  },
  {
    "episode": 9848,
    "reward": 90.476577,
    "length": 62,
    "time": 144875.033964,
    "actor_loss": -64.90916442871094,
    "critic_loss": 2.200273036956787,
    "ent_coef": 0.05478515848517418,
    "learning_rate": 0.001
  },
  {
    "episode": 9849,
    "reward": 87.350551,
    "length": 70,
    "time": 144889.47844,
    "actor_loss": -68.88883972167969,
    "critic_loss": 1.9801489114761353,
    "ent_coef": 0.056691739708185196,
    "learning_rate": 0.001
  },
  {
    "episode": 9850,
    "reward": 88.944029,
    "length": 66,
    "time": 144902.15028,
    "actor_loss": -64.26216125488281,
    "critic_loss": 3.638723373413086,
    "ent_coef": 0.05816157907247543,
    "learning_rate": 0.001
  },
  {
    "episode": 9851,
    "reward": 84.864644,
    "length": 73,
    "time": 144915.507496,
    "actor_loss": -65.8728256225586,
    "critic_loss": 543.8707275390625,
    "ent_coef": 0.05914083123207092,
    "learning_rate": 0.001
  },
  {
    "episode": 9852,
    "reward": 86.938878,
    "length": 70,
    "time": 144927.673827,
    "actor_loss": -69.11458587646484,
    "critic_loss": 8.323907852172852,
    "ent_coef": 0.055996086448431015,
    "learning_rate": 0.001
  },
  {
    "episode": 9853,
    "reward": 83.485074,
    "length": 78,
    "time": 144944.647129,
    "actor_loss": -69.48693084716797,
    "critic_loss": 2.045910596847534,
    "ent_coef": 0.05414025858044624,
    "learning_rate": 0.001
  },
  {
    "episode": 9854,
    "reward": 79.680507,
    "length": 80,
    "time": 144959.803911,
    "actor_loss": -70.01885986328125,
    "critic_loss": 17.502029418945312,
    "ent_coef": 0.05184253305196762,
    "learning_rate": 0.001
  },
  {
    "episode": 9855,
    "reward": 87.788338,
    "length": 68,
    "time": 144971.597745,
    "actor_loss": -73.62240600585938,
    "critic_loss": 78.59727478027344,
    "ent_coef": 0.051055338233709335,
    "learning_rate": 0.001
  },
  {
    "episode": 9856,
    "reward": 82.216569,
    "length": 77,
    "time": 144985.512202,
    "actor_loss": -66.86671447753906,
    "critic_loss": 3.308529853820801,
    "ent_coef": 0.04856349155306816,
    "learning_rate": 0.001
  },
  {
    "episode": 9857,
    "reward": 89.041218,
    "length": 66,
    "time": 144998.377353,
    "actor_loss": -67.41639709472656,
    "critic_loss": 3.5710058212280273,
    "ent_coef": 0.04974430426955223,
    "learning_rate": 0.001
  },
  {
    "episode": 9858,
    "reward": 78.158989,
    "length": 88,
    "time": 145013.097369,
    "actor_loss": -69.86334228515625,
    "critic_loss": 4.205620288848877,
    "ent_coef": 0.04708723723888397,
    "learning_rate": 0.001
  },
  {
    "episode": 9859,
    "reward": 83.834706,
    "length": 75,
    "time": 145026.605171,
    "actor_loss": -70.46080780029297,
    "critic_loss": 2.738448143005371,
    "ent_coef": 0.044505245983600616,
    "learning_rate": 0.001
  },
  {
    "episode": 9860,
    "reward": 90.217254,
    "length": 63,
    "time": 145037.740849,
    "actor_loss": -68.10018920898438,
    "critic_loss": 9.242889404296875,
    "ent_coef": 0.046033263206481934,
    "learning_rate": 0.001
  },
  {
    "episode": 9861,
    "reward": 91.779861,
    "length": 61,
    "time": 145050.875141,
    "actor_loss": -71.56978607177734,
    "critic_loss": 10.101106643676758,
    "ent_coef": 0.05072637274861336,
    "learning_rate": 0.001
  },
  {
    "episode": 9862,
    "reward": 89.043073,
    "length": 67,
    "time": 145066.224819,
    "actor_loss": -71.518310546875,
    "critic_loss": 2.940889358520508,
    "ent_coef": 0.0529918298125267,
    "learning_rate": 0.001
  },
  {
    "episode": 9863,
    "reward": 90.860807,
    "length": 63,
    "time": 145078.357274,
    "actor_loss": -66.98798370361328,
    "critic_loss": 2.576378345489502,
    "ent_coef": 0.055517446249723434,
    "learning_rate": 0.001
  },
  {
    "episode": 9864,
    "reward": 89.768208,
    "length": 66,
    "time": 145091.507422,
    "actor_loss": -71.3157958984375,
    "critic_loss": 3.3920693397521973,
    "ent_coef": 0.05777425691485405,
    "learning_rate": 0.001
  },
  {
    "episode": 9865,
    "reward": 91.16236,
    "length": 63,
    "time": 145104.648264,
    "actor_loss": -66.42828369140625,
    "critic_loss": 19.482221603393555,
    "ent_coef": 0.06152385473251343,
    "learning_rate": 0.001
  },
  {
    "episode": 9866,
    "reward": 87.467543,
    "length": 70,
    "time": 145117.13594,
    "actor_loss": -67.52845764160156,
    "critic_loss": 4.115985870361328,
    "ent_coef": 0.06071969121694565,
    "learning_rate": 0.001
  },
  {
    "episode": 9867,
    "reward": 90.455282,
    "length": 64,
    "time": 145129.525072,
    "actor_loss": -64.935546875,
    "critic_loss": 3.122450828552246,
    "ent_coef": 0.059495557099580765,
    "learning_rate": 0.001
  },
  {
    "episode": 9868,
    "reward": 84.35978,
    "length": 74,
    "time": 145142.234982,
    "actor_loss": -68.8442153930664,
    "critic_loss": 11.356669425964355,
    "ent_coef": 0.05791807174682617,
    "learning_rate": 0.001
  },
  {
    "episode": 9869,
    "reward": 90.37178,
    "length": 63,
    "time": 145154.437687,
    "actor_loss": -71.22994995117188,
    "critic_loss": 5.9396185874938965,
    "ent_coef": 0.060874443501234055,
    "learning_rate": 0.001
  },
  {
    "episode": 9870,
    "reward": 89.345235,
    "length": 67,
    "time": 145166.938927,
    "actor_loss": -69.65697479248047,
    "critic_loss": 22.631059646606445,
    "ent_coef": 0.06177821382880211,
    "learning_rate": 0.001
  },
  {
    "episode": 9871,
    "reward": 85.097211,
    "length": 74,
    "time": 145181.513304,
    "actor_loss": -67.36813354492188,
    "critic_loss": 4.252355575561523,
    "ent_coef": 0.06001994013786316,
    "learning_rate": 0.001
  },
  {
    "episode": 9872,
    "reward": 90.918158,
    "length": 63,
    "time": 145194.708829,
    "actor_loss": -66.7698974609375,
    "critic_loss": 11.62710189819336,
    "ent_coef": 0.058441706001758575,
    "learning_rate": 0.001
  },
  {
    "episode": 9873,
    "reward": 90.841422,
    "length": 63,
    "time": 145206.011826,
    "actor_loss": -66.71050262451172,
    "critic_loss": 2.7130541801452637,
    "ent_coef": 0.058801982551813126,
    "learning_rate": 0.001
  },
  {
    "episode": 9874,
    "reward": 89.194878,
    "length": 65,
    "time": 145217.470688,
    "actor_loss": -66.4134521484375,
    "critic_loss": 1.8327823877334595,
    "ent_coef": 0.05955114588141441,
    "learning_rate": 0.001
  },
  {
    "episode": 9875,
    "reward": 87.631509,
    "length": 69,
    "time": 145229.45934,
    "actor_loss": -68.79224395751953,
    "critic_loss": 2.2165398597717285,
    "ent_coef": 0.06017675623297691,
    "learning_rate": 0.001
  },
  {
    "episode": 9876,
    "reward": 85.333751,
    "length": 75,
    "time": 145242.839077,
    "actor_loss": -70.67595672607422,
    "critic_loss": 4.341801166534424,
    "ent_coef": 0.05772731453180313,
    "learning_rate": 0.001
  },
  {
    "episode": 9877,
    "reward": 87.570593,
    "length": 69,
    "time": 145258.558968,
    "actor_loss": -68.5495834350586,
    "critic_loss": 4.09963321685791,
    "ent_coef": 0.05525391176342964,
    "learning_rate": 0.001
  },
  {
    "episode": 9878,
    "reward": 87.958417,
    "length": 68,
    "time": 145270.42802,
    "actor_loss": -66.25564575195312,
    "critic_loss": 2.542773962020874,
    "ent_coef": 0.05221987143158913,
    "learning_rate": 0.001
  },
  {
    "episode": 9879,
    "reward": 78.405271,
    "length": 86,
    "time": 145287.163254,
    "actor_loss": -74.16514587402344,
    "critic_loss": 3.476113796234131,
    "ent_coef": 0.04784465208649635,
    "learning_rate": 0.001
  },
  {
    "episode": 9880,
    "reward": 81.986363,
    "length": 81,
    "time": 145305.07426,
    "actor_loss": -69.93696594238281,
    "critic_loss": 19.322959899902344,
    "ent_coef": 0.044508300721645355,
    "learning_rate": 0.001
  },
  {
    "episode": 9881,
    "reward": 50.132781,
    "length": 148,
    "time": 145327.369686,
    "actor_loss": -69.30854034423828,
    "critic_loss": 3.7969512939453125,
    "ent_coef": 0.03724268078804016,
    "learning_rate": 0.001
  },
  {
    "episode": 9882,
    "reward": 87.961912,
    "length": 69,
    "time": 145341.231586,
    "actor_loss": -67.21835327148438,
    "critic_loss": 3.0307278633117676,
    "ent_coef": 0.0364014096558094,
    "learning_rate": 0.001
  },
  {
    "episode": 9883,
    "reward": -156.483011,
    "length": 125,
    "time": 145360.642635,
    "actor_loss": -74.69205474853516,
    "critic_loss": 6.4307050704956055,
    "ent_coef": 0.03872770071029663,
    "learning_rate": 0.001
  },
  {
    "episode": 9884,
    "reward": 86.191209,
    "length": 74,
    "time": 145376.331163,
    "actor_loss": -69.87432861328125,
    "critic_loss": 28.953205108642578,
    "ent_coef": 0.03812611848115921,
    "learning_rate": 0.001
  },
  {
    "episode": 9885,
    "reward": 85.728033,
    "length": 78,
    "time": 145391.597385,
    "actor_loss": -65.06898498535156,
    "critic_loss": 13.635666847229004,
    "ent_coef": 0.03983619809150696,
    "learning_rate": 0.001
  },
  {
    "episode": 9886,
    "reward": 87.065374,
    "length": 72,
    "time": 145404.261046,
    "actor_loss": -68.50538635253906,
    "critic_loss": 4.465968132019043,
    "ent_coef": 0.038312189280986786,
    "learning_rate": 0.001
  },
  {
    "episode": 9887,
    "reward": 86.849489,
    "length": 73,
    "time": 145419.354424,
    "actor_loss": -70.07316589355469,
    "critic_loss": 3.446641206741333,
    "ent_coef": 0.038041386753320694,
    "learning_rate": 0.001
  },
  {
    "episode": 9888,
    "reward": 89.727612,
    "length": 68,
    "time": 145433.617763,
    "actor_loss": -65.83602905273438,
    "critic_loss": 2.3821635246276855,
    "ent_coef": 0.037727709859609604,
    "learning_rate": 0.001
  },
  {
    "episode": 9889,
    "reward": 89.510895,
    "length": 66,
    "time": 145446.229566,
    "actor_loss": -65.58444213867188,
    "critic_loss": 2.0812597274780273,
    "ent_coef": 0.03732358664274216,
    "learning_rate": 0.001
  },
  {
    "episode": 9890,
    "reward": 90.640098,
    "length": 66,
    "time": 145457.741042,
    "actor_loss": -68.3259048461914,
    "critic_loss": 0.9778571128845215,
    "ent_coef": 0.03852979838848114,
    "learning_rate": 0.001
  },
  {
    "episode": 9891,
    "reward": 88.928724,
    "length": 68,
    "time": 145470.221439,
    "actor_loss": -67.41655731201172,
    "critic_loss": 4.355290412902832,
    "ent_coef": 0.038998235017061234,
    "learning_rate": 0.001
  },
  {
    "episode": 9892,
    "reward": 89.098263,
    "length": 72,
    "time": 145482.885027,
    "actor_loss": -70.11241912841797,
    "critic_loss": 6.452142238616943,
    "ent_coef": 0.042445383965969086,
    "learning_rate": 0.001
  },
  {
    "episode": 9893,
    "reward": 55.443094,
    "length": 120,
    "time": 145502.432163,
    "actor_loss": -74.46065521240234,
    "critic_loss": 13.013299942016602,
    "ent_coef": 0.04177641496062279,
    "learning_rate": 0.001
  },
  {
    "episode": 9894,
    "reward": 88.086731,
    "length": 70,
    "time": 145515.557288,
    "actor_loss": -64.40213012695312,
    "critic_loss": 200.3174285888672,
    "ent_coef": 0.042391661554574966,
    "learning_rate": 0.001
  },
  {
    "episode": 9895,
    "reward": 90.608754,
    "length": 64,
    "time": 145527.028193,
    "actor_loss": -68.19615173339844,
    "critic_loss": 1.9361984729766846,
    "ent_coef": 0.04409682750701904,
    "learning_rate": 0.001
  },
  {
    "episode": 9896,
    "reward": 88.849248,
    "length": 67,
    "time": 145538.678426,
    "actor_loss": -69.63290405273438,
    "critic_loss": 6.095186233520508,
    "ent_coef": 0.04438244178891182,
    "learning_rate": 0.001
  },
  {
    "episode": 9897,
    "reward": 90.040337,
    "length": 66,
    "time": 145550.417154,
    "actor_loss": -66.04751586914062,
    "critic_loss": 15.10896110534668,
    "ent_coef": 0.045465487986803055,
    "learning_rate": 0.001
  },
  {
    "episode": 9898,
    "reward": 91.013953,
    "length": 63,
    "time": 145562.348663,
    "actor_loss": -70.02876281738281,
    "critic_loss": 3.8047232627868652,
    "ent_coef": 0.04788237065076828,
    "learning_rate": 0.001
  },
  {
    "episode": 9899,
    "reward": 88.947906,
    "length": 68,
    "time": 145574.986131,
    "actor_loss": -69.144287109375,
    "critic_loss": 5.141663551330566,
    "ent_coef": 0.048128802329301834,
    "learning_rate": 0.001
  },
  {
    "episode": 9900,
    "reward": 89.037722,
    "length": 69,
    "time": 145588.68414,
    "actor_loss": -62.05450439453125,
    "critic_loss": 22.306297302246094,
    "ent_coef": 0.04893716424703598,
    "learning_rate": 0.001
  },
  {
    "episode": 9901,
    "reward": 84.353106,
    "length": 77,
    "time": 145603.590755,
    "actor_loss": -67.3570785522461,
    "critic_loss": 3.581916332244873,
    "ent_coef": 0.04576730355620384,
    "learning_rate": 0.001
  },
  {
    "episode": 9902,
    "reward": 90.2913,
    "length": 66,
    "time": 145618.277261,
    "actor_loss": -72.83169555664062,
    "critic_loss": 4.0187811851501465,
    "ent_coef": 0.04881223663687706,
    "learning_rate": 0.001
  },
  {
    "episode": 9903,
    "reward": 90.747703,
    "length": 64,
    "time": 145631.505149,
    "actor_loss": -71.27879333496094,
    "critic_loss": 5.636234283447266,
    "ent_coef": 0.050049468874931335,
    "learning_rate": 0.001
  },
  {
    "episode": 9904,
    "reward": 89.368409,
    "length": 67,
    "time": 145645.308674,
    "actor_loss": -70.10108947753906,
    "critic_loss": 3.0539073944091797,
    "ent_coef": 0.04932587966322899,
    "learning_rate": 0.001
  },
  {
    "episode": 9905,
    "reward": 88.705293,
    "length": 68,
    "time": 145658.691251,
    "actor_loss": -64.47216796875,
    "critic_loss": 30.561304092407227,
    "ent_coef": 0.05002019926905632,
    "learning_rate": 0.001
  },
  {
    "episode": 9906,
    "reward": 91.926046,
    "length": 61,
    "time": 145669.836819,
    "actor_loss": -70.79696655273438,
    "critic_loss": 5.844035625457764,
    "ent_coef": 0.051419299095869064,
    "learning_rate": 0.001
  },
  {
    "episode": 9907,
    "reward": 90.918388,
    "length": 63,
    "time": 145680.902819,
    "actor_loss": -71.76350402832031,
    "critic_loss": 3.5634586811065674,
    "ent_coef": 0.05116463080048561,
    "learning_rate": 0.001
  },
  {
    "episode": 9908,
    "reward": 90.261191,
    "length": 64,
    "time": 145693.247263,
    "actor_loss": -76.21173095703125,
    "critic_loss": 8.981225967407227,
    "ent_coef": 0.05131116136908531,
    "learning_rate": 0.001
  },
  {
    "episode": 9909,
    "reward": 90.266774,
    "length": 66,
    "time": 145706.023586,
    "actor_loss": -71.6716537475586,
    "critic_loss": 4.182675838470459,
    "ent_coef": 0.050555020570755005,
    "learning_rate": 0.001
  },
  {
    "episode": 9910,
    "reward": 90.351683,
    "length": 64,
    "time": 145718.256329,
    "actor_loss": -70.38041687011719,
    "critic_loss": 19.233192443847656,
    "ent_coef": 0.04856227710843086,
    "learning_rate": 0.001
  },
  {
    "episode": 9911,
    "reward": 89.460012,
    "length": 65,
    "time": 145732.230502,
    "actor_loss": -67.94178771972656,
    "critic_loss": 4.631303787231445,
    "ent_coef": 0.0495481975376606,
    "learning_rate": 0.001
  },
  {
    "episode": 9912,
    "reward": 89.888993,
    "length": 66,
    "time": 145744.191967,
    "actor_loss": -68.54788970947266,
    "critic_loss": 7.368238925933838,
    "ent_coef": 0.0489332340657711,
    "learning_rate": 0.001
  },
  {
    "episode": 9913,
    "reward": 90.674229,
    "length": 65,
    "time": 145756.117223,
    "actor_loss": -66.888427734375,
    "critic_loss": 3.207435369491577,
    "ent_coef": 0.04950341209769249,
    "learning_rate": 0.001
  },
  {
    "episode": 9914,
    "reward": 89.578096,
    "length": 66,
    "time": 145767.621736,
    "actor_loss": -66.88776397705078,
    "critic_loss": 11.462491989135742,
    "ent_coef": 0.04808371886610985,
    "learning_rate": 0.001
  },
  {
    "episode": 9915,
    "reward": 89.479201,
    "length": 66,
    "time": 145779.217309,
    "actor_loss": -67.82373046875,
    "critic_loss": 4.150857448577881,
    "ent_coef": 0.047226451337337494,
    "learning_rate": 0.001
  },
  {
    "episode": 9916,
    "reward": 92.234659,
    "length": 60,
    "time": 145791.340718,
    "actor_loss": -68.63262939453125,
    "critic_loss": 14.494179725646973,
    "ent_coef": 0.04980390518903732,
    "learning_rate": 0.001
  },
  {
    "episode": 9917,
    "reward": 88.697691,
    "length": 68,
    "time": 145804.438814,
    "actor_loss": -66.34410095214844,
    "critic_loss": 4.519970893859863,
    "ent_coef": 0.047817572951316833,
    "learning_rate": 0.001
  },
  {
    "episode": 9918,
    "reward": 90.068214,
    "length": 65,
    "time": 145815.866319,
    "actor_loss": -67.73698425292969,
    "critic_loss": 2.4123597145080566,
    "ent_coef": 0.047739505767822266,
    "learning_rate": 0.001
  },
  {
    "episode": 9919,
    "reward": 91.918584,
    "length": 61,
    "time": 145833.864605,
    "actor_loss": -69.51045227050781,
    "critic_loss": 2.296621561050415,
    "ent_coef": 0.0488065704703331,
    "learning_rate": 0.001
  },
  {
    "episode": 9920,
    "reward": 91.462652,
    "length": 62,
    "time": 145844.817028,
    "actor_loss": -70.45515441894531,
    "critic_loss": 4.865482330322266,
    "ent_coef": 0.0499296560883522,
    "learning_rate": 0.001
  },
  {
    "episode": 9921,
    "reward": 90.030465,
    "length": 66,
    "time": 145857.462899,
    "actor_loss": -77.06007385253906,
    "critic_loss": 1.9873812198638916,
    "ent_coef": 0.050074394792318344,
    "learning_rate": 0.001
  },
  {
    "episode": 9922,
    "reward": 89.755287,
    "length": 66,
    "time": 145869.295793,
    "actor_loss": -67.36012268066406,
    "critic_loss": 3.1711513996124268,
    "ent_coef": 0.05035475268959999,
    "learning_rate": 0.001
  },
  {
    "episode": 9923,
    "reward": 85.180355,
    "length": 73,
    "time": 145883.191619,
    "actor_loss": -70.91847229003906,
    "critic_loss": 8.955735206604004,
    "ent_coef": 0.044889554381370544,
    "learning_rate": 0.001
  },
  {
    "episode": 9924,
    "reward": 86.253973,
    "length": 73,
    "time": 145895.88339,
    "actor_loss": -69.08845520019531,
    "critic_loss": 42.23480224609375,
    "ent_coef": 0.041209738701581955,
    "learning_rate": 0.001
  },
  {
    "episode": 9925,
    "reward": 87.303897,
    "length": 70,
    "time": 145909.537463,
    "actor_loss": -69.90090942382812,
    "critic_loss": 4.268932342529297,
    "ent_coef": 0.04015711694955826,
    "learning_rate": 0.001
  },
  {
    "episode": 9926,
    "reward": 90.538149,
    "length": 63,
    "time": 145920.996941,
    "actor_loss": -71.72697448730469,
    "critic_loss": 1.6315988302230835,
    "ent_coef": 0.04059683904051781,
    "learning_rate": 0.001
  },
  {
    "episode": 9927,
    "reward": 86.311899,
    "length": 73,
    "time": 145935.175678,
    "actor_loss": -72.462890625,
    "critic_loss": 2.7149181365966797,
    "ent_coef": 0.03987361863255501,
    "learning_rate": 0.001
  },
  {
    "episode": 9928,
    "reward": 87.644886,
    "length": 71,
    "time": 145950.124736,
    "actor_loss": -72.57568359375,
    "critic_loss": 1.6340612173080444,
    "ent_coef": 0.04160375893115997,
    "learning_rate": 0.001
  },
  {
    "episode": 9929,
    "reward": 90.437238,
    "length": 64,
    "time": 145965.837713,
    "actor_loss": -74.28622436523438,
    "critic_loss": 36.814659118652344,
    "ent_coef": 0.04283040761947632,
    "learning_rate": 0.001
  },
  {
    "episode": 9930,
    "reward": 89.192802,
    "length": 68,
    "time": 145981.344907,
    "actor_loss": -68.84088134765625,
    "critic_loss": 8.600362777709961,
    "ent_coef": 0.044055160135030746,
    "learning_rate": 0.001
  },
  {
    "episode": 9931,
    "reward": 87.546859,
    "length": 71,
    "time": 145994.223839,
    "actor_loss": -69.01028442382812,
    "critic_loss": 1.8477784395217896,
    "ent_coef": 0.043204981833696365,
    "learning_rate": 0.001
  },
  {
    "episode": 9932,
    "reward": 85.923067,
    "length": 76,
    "time": 146007.757034,
    "actor_loss": -70.38751220703125,
    "critic_loss": 36.932682037353516,
    "ent_coef": 0.04175328090786934,
    "learning_rate": 0.001
  },
  {
    "episode": 9933,
    "reward": 90.647817,
    "length": 64,
    "time": 146019.871824,
    "actor_loss": -70.6805648803711,
    "critic_loss": 1.849374771118164,
    "ent_coef": 0.04265262931585312,
    "learning_rate": 0.001
  },
  {
    "episode": 9934,
    "reward": 91.341268,
    "length": 63,
    "time": 146031.187045,
    "actor_loss": -68.2567138671875,
    "critic_loss": 5.962405204772949,
    "ent_coef": 0.04542778059840202,
    "learning_rate": 0.001
  },
  {
    "episode": 9935,
    "reward": 89.57051,
    "length": 65,
    "time": 146043.567875,
    "actor_loss": -67.6488037109375,
    "critic_loss": 17.05872917175293,
    "ent_coef": 0.046237070113420486,
    "learning_rate": 0.001
  },
  {
    "episode": 9936,
    "reward": 87.236092,
    "length": 72,
    "time": 146056.085518,
    "actor_loss": -73.29127502441406,
    "critic_loss": 4.655453681945801,
    "ent_coef": 0.0449354387819767,
    "learning_rate": 0.001
  },
  {
    "episode": 9937,
    "reward": 85.662783,
    "length": 72,
    "time": 146070.012618,
    "actor_loss": -68.92030334472656,
    "critic_loss": 13.257110595703125,
    "ent_coef": 0.043198779225349426,
    "learning_rate": 0.001
  },
  {
    "episode": 9938,
    "reward": 89.989904,
    "length": 67,
    "time": 146084.366115,
    "actor_loss": -67.7652587890625,
    "critic_loss": 34.153587341308594,
    "ent_coef": 0.044215261936187744,
    "learning_rate": 0.001
  },
  {
    "episode": 9939,
    "reward": 89.971471,
    "length": 65,
    "time": 146095.820349,
    "actor_loss": -69.31053161621094,
    "critic_loss": 33.955078125,
    "ent_coef": 0.04580710455775261,
    "learning_rate": 0.001
  },
  {
    "episode": 9940,
    "reward": 91.190532,
    "length": 61,
    "time": 146108.081973,
    "actor_loss": -70.19483947753906,
    "critic_loss": 2.212705612182617,
    "ent_coef": 0.04884466156363487,
    "learning_rate": 0.001
  },
  {
    "episode": 9941,
    "reward": 90.819181,
    "length": 65,
    "time": 146120.593773,
    "actor_loss": -71.85099792480469,
    "critic_loss": 4.083067893981934,
    "ent_coef": 0.050996456295251846,
    "learning_rate": 0.001
  },
  {
    "episode": 9942,
    "reward": 90.57593,
    "length": 64,
    "time": 146132.896072,
    "actor_loss": -72.26516723632812,
    "critic_loss": 6.931693077087402,
    "ent_coef": 0.053600210696458817,
    "learning_rate": 0.001
  },
  {
    "episode": 9943,
    "reward": -156.713326,
    "length": 152,
    "time": 146156.402405,
    "actor_loss": -65.11009216308594,
    "critic_loss": 2.9012012481689453,
    "ent_coef": 0.06769825518131256,
    "learning_rate": 0.001
  },
  {
    "episode": 9944,
    "reward": 90.944932,
    "length": 62,
    "time": 146167.428169,
    "actor_loss": -76.27137756347656,
    "critic_loss": 22.504117965698242,
    "ent_coef": 0.06820406019687653,
    "learning_rate": 0.001
  },
  {
    "episode": 9945,
    "reward": 88.105932,
    "length": 68,
    "time": 146180.714791,
    "actor_loss": -67.62934112548828,
    "critic_loss": 3.6741037368774414,
    "ent_coef": 0.0663367509841919,
    "learning_rate": 0.001
  },
  {
    "episode": 9946,
    "reward": 89.530932,
    "length": 65,
    "time": 146192.605019,
    "actor_loss": -65.74920654296875,
    "critic_loss": 36.79679489135742,
    "ent_coef": 0.06422363966703415,
    "learning_rate": 0.001
  },
  {
    "episode": 9947,
    "reward": 90.081464,
    "length": 64,
    "time": 146205.065738,
    "actor_loss": -68.08345794677734,
    "critic_loss": 3.289354085922241,
    "ent_coef": 0.06224583834409714,
    "learning_rate": 0.001
  },
  {
    "episode": 9948,
    "reward": 86.912537,
    "length": 70,
    "time": 146217.242271,
    "actor_loss": -75.91209411621094,
    "critic_loss": 1.591320276260376,
    "ent_coef": 0.056377362459897995,
    "learning_rate": 0.001
  },
  {
    "episode": 9949,
    "reward": 89.883523,
    "length": 66,
    "time": 146231.505719,
    "actor_loss": -63.61366653442383,
    "critic_loss": 11.468945503234863,
    "ent_coef": 0.05590449646115303,
    "learning_rate": 0.001
  },
  {
    "episode": 9950,
    "reward": 90.48237,
    "length": 64,
    "time": 146248.782893,
    "actor_loss": -70.88507080078125,
    "critic_loss": 2.7874796390533447,
    "ent_coef": 0.053851399570703506,
    "learning_rate": 0.001
  },
  {
    "episode": 9951,
    "reward": 87.854382,
    "length": 68,
    "time": 146261.82532,
    "actor_loss": -66.62564086914062,
    "critic_loss": 23.674955368041992,
    "ent_coef": 0.05033475533127785,
    "learning_rate": 0.001
  },
  {
    "episode": 9952,
    "reward": 86.626981,
    "length": 71,
    "time": 146274.029475,
    "actor_loss": -71.98471069335938,
    "critic_loss": 11.938655853271484,
    "ent_coef": 0.04810004308819771,
    "learning_rate": 0.001
  },
  {
    "episode": 9953,
    "reward": 86.572462,
    "length": 72,
    "time": 146290.272081,
    "actor_loss": -68.71906280517578,
    "critic_loss": 112.44888305664062,
    "ent_coef": 0.04607716202735901,
    "learning_rate": 0.001
  },
  {
    "episode": 9954,
    "reward": 89.17589,
    "length": 66,
    "time": 146303.26585,
    "actor_loss": -64.79000854492188,
    "critic_loss": 3.7470011711120605,
    "ent_coef": 0.046012766659259796,
    "learning_rate": 0.001
  },
  {
    "episode": 9955,
    "reward": 89.064013,
    "length": 66,
    "time": 146315.115181,
    "actor_loss": -71.64381408691406,
    "critic_loss": 2.4850988388061523,
    "ent_coef": 0.046556223183870316,
    "learning_rate": 0.001
  },
  {
    "episode": 9956,
    "reward": 91.67508,
    "length": 60,
    "time": 146326.815312,
    "actor_loss": -71.85231018066406,
    "critic_loss": 2.904738426208496,
    "ent_coef": 0.04717380926012993,
    "learning_rate": 0.001
  },
  {
    "episode": 9957,
    "reward": 90.697298,
    "length": 62,
    "time": 146337.70259,
    "actor_loss": -70.00521850585938,
    "critic_loss": 2.669245481491089,
    "ent_coef": 0.04908273369073868,
    "learning_rate": 0.001
  },
  {
    "episode": 9958,
    "reward": 90.26706,
    "length": 64,
    "time": 146352.189145,
    "actor_loss": -59.269371032714844,
    "critic_loss": 5.91585636138916,
    "ent_coef": 0.04942524805665016,
    "learning_rate": 0.001
  },
  {
    "episode": 9959,
    "reward": 90.568772,
    "length": 64,
    "time": 146367.720132,
    "actor_loss": -70.2904281616211,
    "critic_loss": 5.205448150634766,
    "ent_coef": 0.0508803054690361,
    "learning_rate": 0.001
  },
  {
    "episode": 9960,
    "reward": 91.620258,
    "length": 62,
    "time": 146378.896239,
    "actor_loss": -73.85372924804688,
    "critic_loss": 4.524320602416992,
    "ent_coef": 0.052293144166469574,
    "learning_rate": 0.001
  },
  {
    "episode": 9961,
    "reward": 91.074262,
    "length": 62,
    "time": 146390.282004,
    "actor_loss": -70.89295959472656,
    "critic_loss": 2.2522499561309814,
    "ent_coef": 0.05335476994514465,
    "learning_rate": 0.001
  },
  {
    "episode": 9962,
    "reward": 88.541369,
    "length": 65,
    "time": 146404.129234,
    "actor_loss": -66.46684265136719,
    "critic_loss": 5.87995719909668,
    "ent_coef": 0.05759838595986366,
    "learning_rate": 0.001
  },
  {
    "episode": 9963,
    "reward": 92.634519,
    "length": 59,
    "time": 146415.522117,
    "actor_loss": -66.83944702148438,
    "critic_loss": 13.617596626281738,
    "ent_coef": 0.060810383409261703,
    "learning_rate": 0.001
  },
  {
    "episode": 9964,
    "reward": 90.690329,
    "length": 63,
    "time": 146427.58184,
    "actor_loss": -67.94976043701172,
    "critic_loss": 2.7895281314849854,
    "ent_coef": 0.062395479530096054,
    "learning_rate": 0.001
  },
  {
    "episode": 9965,
    "reward": 89.346147,
    "length": 66,
    "time": 146440.192174,
    "actor_loss": -65.11518096923828,
    "critic_loss": 37.274742126464844,
    "ent_coef": 0.06338948756456375,
    "learning_rate": 0.001
  },
  {
    "episode": 9966,
    "reward": 91.268537,
    "length": 62,
    "time": 146454.11241,
    "actor_loss": -65.80296325683594,
    "critic_loss": 3.6664910316467285,
    "ent_coef": 0.06479795277118683,
    "learning_rate": 0.001
  },
  {
    "episode": 9967,
    "reward": 90.092298,
    "length": 64,
    "time": 146469.244454,
    "actor_loss": -67.67803955078125,
    "critic_loss": 2.9446628093719482,
    "ent_coef": 0.06596687436103821,
    "learning_rate": 0.001
  },
  {
    "episode": 9968,
    "reward": 91.176322,
    "length": 62,
    "time": 146481.706541,
    "actor_loss": -66.28569030761719,
    "critic_loss": 13.25162410736084,
    "ent_coef": 0.06841998547315598,
    "learning_rate": 0.001
  },
  {
    "episode": 9969,
    "reward": 91.541071,
    "length": 62,
    "time": 146493.09071,
    "actor_loss": -68.12496948242188,
    "critic_loss": 11.063125610351562,
    "ent_coef": 0.07129820436239243,
    "learning_rate": 0.001
  },
  {
    "episode": 9970,
    "reward": 90.579745,
    "length": 63,
    "time": 146505.667913,
    "actor_loss": -69.52725982666016,
    "critic_loss": 53.80333709716797,
    "ent_coef": 0.0726778656244278,
    "learning_rate": 0.001
  },
  {
    "episode": 9971,
    "reward": 90.433641,
    "length": 63,
    "time": 146517.283373,
    "actor_loss": -72.99950408935547,
    "critic_loss": 60.27037811279297,
    "ent_coef": 0.07043307274580002,
    "learning_rate": 0.001
  },
  {
    "episode": 9972,
    "reward": 84.072737,
    "length": 74,
    "time": 146531.659855,
    "actor_loss": -71.22079467773438,
    "critic_loss": 14.2102632522583,
    "ent_coef": 0.0658186748623848,
    "learning_rate": 0.001
  },
  {
    "episode": 9973,
    "reward": 90.249143,
    "length": 64,
    "time": 146544.70936,
    "actor_loss": -67.56246185302734,
    "critic_loss": 4.095127105712891,
    "ent_coef": 0.06790636479854584,
    "learning_rate": 0.001
  },
  {
    "episode": 9974,
    "reward": 87.455374,
    "length": 69,
    "time": 146559.478352,
    "actor_loss": -71.1539306640625,
    "critic_loss": 2.0941319465637207,
    "ent_coef": 0.0665983036160469,
    "learning_rate": 0.001
  },
  {
    "episode": 9975,
    "reward": 88.842374,
    "length": 65,
    "time": 146572.705495,
    "actor_loss": -61.56884765625,
    "critic_loss": 5.312119483947754,
    "ent_coef": 0.06419846415519714,
    "learning_rate": 0.001
  },
  {
    "episode": 9976,
    "reward": 86.986371,
    "length": 68,
    "time": 146584.7028,
    "actor_loss": -61.183319091796875,
    "critic_loss": 7.849806785583496,
    "ent_coef": 0.06201016157865524,
    "learning_rate": 0.001
  },
  {
    "episode": 9977,
    "reward": 87.480155,
    "length": 68,
    "time": 146597.381801,
    "actor_loss": -70.61802673339844,
    "critic_loss": 42.9254150390625,
    "ent_coef": 0.06367819011211395,
    "learning_rate": 0.001
  },
  {
    "episode": 9978,
    "reward": 88.601588,
    "length": 67,
    "time": 146610.603614,
    "actor_loss": -68.83887481689453,
    "critic_loss": 2.9467861652374268,
    "ent_coef": 0.06303712725639343,
    "learning_rate": 0.001
  },
  {
    "episode": 9979,
    "reward": 91.207808,
    "length": 61,
    "time": 146621.398156,
    "actor_loss": -70.12557983398438,
    "critic_loss": 14.706205368041992,
    "ent_coef": 0.06539303809404373,
    "learning_rate": 0.001
  },
  {
    "episode": 9980,
    "reward": 89.349118,
    "length": 66,
    "time": 146634.145836,
    "actor_loss": -67.1421127319336,
    "critic_loss": 34.82537841796875,
    "ent_coef": 0.06853673607110977,
    "learning_rate": 0.001
  },
  {
    "episode": 9981,
    "reward": 88.606518,
    "length": 67,
    "time": 146646.268208,
    "actor_loss": -69.96319580078125,
    "critic_loss": 9.252811431884766,
    "ent_coef": 0.07193496823310852,
    "learning_rate": 0.001
  },
  {
    "episode": 9982,
    "reward": 85.934794,
    "length": 72,
    "time": 146658.730182,
    "actor_loss": -66.41819763183594,
    "critic_loss": 2.5355372428894043,
    "ent_coef": 0.06965739279985428,
    "learning_rate": 0.001
  },
  {
    "episode": 9983,
    "reward": 91.154033,
    "length": 62,
    "time": 146670.80791,
    "actor_loss": -66.73518371582031,
    "critic_loss": 16.01593780517578,
    "ent_coef": 0.06948740780353546,
    "learning_rate": 0.001
  },
  {
    "episode": 9984,
    "reward": 85.185667,
    "length": 73,
    "time": 146686.347551,
    "actor_loss": -67.6282958984375,
    "critic_loss": 2.207869529724121,
    "ent_coef": 0.06544021517038345,
    "learning_rate": 0.001
  },
  {
    "episode": 9985,
    "reward": 88.845476,
    "length": 65,
    "time": 146698.124444,
    "actor_loss": -69.01814270019531,
    "critic_loss": 3.226145029067993,
    "ent_coef": 0.06561405211687088,
    "learning_rate": 0.001
  },
  {
    "episode": 9986,
    "reward": 89.560546,
    "length": 64,
    "time": 146709.400512,
    "actor_loss": -67.60057067871094,
    "critic_loss": 5.195000171661377,
    "ent_coef": 0.06746849417686462,
    "learning_rate": 0.001
  },
  {
    "episode": 9987,
    "reward": 88.971698,
    "length": 66,
    "time": 146721.136522,
    "actor_loss": -70.16378784179688,
    "critic_loss": 2.443854808807373,
    "ent_coef": 0.06648770719766617,
    "learning_rate": 0.001
  },
  {
    "episode": 9988,
    "reward": 87.84909,
    "length": 68,
    "time": 146734.260542,
    "actor_loss": -71.34111022949219,
    "critic_loss": 3.2535223960876465,
    "ent_coef": 0.06517858058214188,
    "learning_rate": 0.001
  },
  {
    "episode": 9989,
    "reward": 87.098401,
    "length": 68,
    "time": 146747.213057,
    "actor_loss": -65.46393585205078,
    "critic_loss": 3.1852259635925293,
    "ent_coef": 0.06214066594839096,
    "learning_rate": 0.001
  },
  {
    "episode": 9990,
    "reward": 90.18089,
    "length": 64,
    "time": 146758.562774,
    "actor_loss": -74.16586303710938,
    "critic_loss": 23.889339447021484,
    "ent_coef": 0.06345978379249573,
    "learning_rate": 0.001
  },
  {
    "episode": 9991,
    "reward": 89.789835,
    "length": 64,
    "time": 146770.291953,
    "actor_loss": -64.06144714355469,
    "critic_loss": 2.82102370262146,
    "ent_coef": 0.06504502892494202,
    "learning_rate": 0.001
  },
  {
    "episode": 9992,
    "reward": 89.702097,
    "length": 67,
    "time": 146785.367074,
    "actor_loss": -69.22760009765625,
    "critic_loss": 1.7358886003494263,
    "ent_coef": 0.0642273873090744,
    "learning_rate": 0.001
  },
  {
    "episode": 9993,
    "reward": 73.865653,
    "length": 87,
    "time": 146801.899119,
    "actor_loss": -72.4593505859375,
    "critic_loss": 2.188246250152588,
    "ent_coef": 0.05856376513838768,
    "learning_rate": 0.001
  },
  {
    "episode": 9994,
    "reward": 87.858099,
    "length": 67,
    "time": 146813.63783,
    "actor_loss": -68.73577880859375,
    "critic_loss": 3.4389967918395996,
    "ent_coef": 0.058528244495391846,
    "learning_rate": 0.001
  },
  {
    "episode": 9995,
    "reward": 87.106089,
    "length": 70,
    "time": 146826.608121,
    "actor_loss": -64.51394653320312,
    "critic_loss": 3.3091444969177246,
    "ent_coef": 0.056332819163799286,
    "learning_rate": 0.001
  },
  {
    "episode": 9996,
    "reward": 85.405042,
    "length": 71,
    "time": 146842.759706,
    "actor_loss": -71.53694152832031,
    "critic_loss": 9.08467960357666,
    "ent_coef": 0.05581977963447571,
    "learning_rate": 0.001
  },
  {
    "episode": 9997,
    "reward": 89.097567,
    "length": 65,
    "time": 146855.245471,
    "actor_loss": -73.94702911376953,
    "critic_loss": 2.5877304077148438,
    "ent_coef": 0.056881681084632874,
    "learning_rate": 0.001
  },
  {
    "episode": 9998,
    "reward": 88.762759,
    "length": 66,
    "time": 146867.344635,
    "actor_loss": -65.59915161132812,
    "critic_loss": 2.829583168029785,
    "ent_coef": 0.0589527003467083,
    "learning_rate": 0.001
  },
  {
    "episode": 9999,
    "reward": 89.440154,
    "length": 65,
    "time": 146879.790587,
    "actor_loss": -69.2260971069336,
    "critic_loss": 3.67728328704834,
    "ent_coef": 0.05989566072821617,
    "learning_rate": 0.001
  },
  {
    "episode": 10000,
    "reward": 87.705416,
    "length": 68,
    "time": 146893.125569,
    "actor_loss": -71.21441650390625,
    "critic_loss": 5.532370567321777,
    "ent_coef": 0.059106409549713135,
    "learning_rate": 0.001
  },
  {
    "episode": 10001,
    "reward": 86.092533,
    "length": 71,
    "time": 146905.788739,
    "actor_loss": -74.37630462646484,
    "critic_loss": 7.124256134033203,
    "ent_coef": 0.05547596514225006,
    "learning_rate": 0.001
  },
  {
    "episode": 10002,
    "reward": 83.868439,
    "length": 73,
    "time": 146921.001703,
    "actor_loss": -64.58154296875,
    "critic_loss": 14.41938591003418,
    "ent_coef": 0.051484595984220505,
    "learning_rate": 0.001
  },
  {
    "episode": 10003,
    "reward": 87.008377,
    "length": 70,
    "time": 146939.852907,
    "actor_loss": -61.836124420166016,
    "critic_loss": 1.7826716899871826,
    "ent_coef": 0.051821447908878326,
    "learning_rate": 0.001
  },
  {
    "episode": 10004,
    "reward": 90.235264,
    "length": 64,
    "time": 146951.033998,
    "actor_loss": -72.73453521728516,
    "critic_loss": 3.061598062515259,
    "ent_coef": 0.05459340661764145,
    "learning_rate": 0.001
  },
  {
    "episode": 10005,
    "reward": 87.607209,
    "length": 67,
    "time": 146965.345045,
    "actor_loss": -71.07209014892578,
    "critic_loss": 1.939792513847351,
    "ent_coef": 0.05397667735815048,
    "learning_rate": 0.001
  },
  {
    "episode": 10006,
    "reward": 77.979041,
    "length": 84,
    "time": 146979.5159,
    "actor_loss": -71.04454803466797,
    "critic_loss": 3.0228068828582764,
    "ent_coef": 0.050636641681194305,
    "learning_rate": 0.001
  },
  {
    "episode": 10007,
    "reward": -207.910016,
    "length": 431,
    "time": 147038.027978,
    "actor_loss": -70.79643249511719,
    "critic_loss": 2.805755138397217,
    "ent_coef": 0.04085172712802887,
    "learning_rate": 0.001
  },
  {
    "episode": 10008,
    "reward": 90.668445,
    "length": 63,
    "time": 147050.172016,
    "actor_loss": -68.29804992675781,
    "critic_loss": 1.9677670001983643,
    "ent_coef": 0.04244234040379524,
    "learning_rate": 0.001
  },
  {
    "episode": 10009,
    "reward": 87.067397,
    "length": 70,
    "time": 147063.356693,
    "actor_loss": -72.91214752197266,
    "critic_loss": 22.904802322387695,
    "ent_coef": 0.04150637984275818,
    "learning_rate": 0.001
  },
  {
    "episode": 10010,
    "reward": 88.316962,
    "length": 68,
    "time": 147075.143813,
    "actor_loss": -65.5709228515625,
    "critic_loss": 2.050588607788086,
    "ent_coef": 0.038381148129701614,
    "learning_rate": 0.001
  },
  {
    "episode": 10011,
    "reward": 80.885068,
    "length": 78,
    "time": 147088.824759,
    "actor_loss": -62.82898712158203,
    "critic_loss": 3.273014783859253,
    "ent_coef": 0.0354352630674839,
    "learning_rate": 0.001
  },
  {
    "episode": 10012,
    "reward": 89.888587,
    "length": 64,
    "time": 147102.942531,
    "actor_loss": -77.4366455078125,
    "critic_loss": 2.3154191970825195,
    "ent_coef": 0.03675438091158867,
    "learning_rate": 0.001
  },
  {
    "episode": 10013,
    "reward": 86.383306,
    "length": 72,
    "time": 147116.359643,
    "actor_loss": -68.31229400634766,
    "critic_loss": 1.5326846837997437,
    "ent_coef": 0.03434939682483673,
    "learning_rate": 0.001
  },
  {
    "episode": 10014,
    "reward": 82.870957,
    "length": 81,
    "time": 147130.031769,
    "actor_loss": -67.18660736083984,
    "critic_loss": 2.600691318511963,
    "ent_coef": 0.031185314059257507,
    "learning_rate": 0.001
  },
  {
    "episode": 10015,
    "reward": 79.010349,
    "length": 95,
    "time": 147145.152051,
    "actor_loss": -74.82012939453125,
    "critic_loss": 2.0170857906341553,
    "ent_coef": 0.028869571164250374,
    "learning_rate": 0.001
  },
  {
    "episode": 10016,
    "reward": 84.602462,
    "length": 75,
    "time": 147161.421365,
    "actor_loss": -75.58252716064453,
    "critic_loss": 3.281346321105957,
    "ent_coef": 0.028975646942853928,
    "learning_rate": 0.001
  },
  {
    "episode": 10017,
    "reward": 88.445841,
    "length": 69,
    "time": 147174.442015,
    "actor_loss": -71.7939224243164,
    "critic_loss": 3.0228896141052246,
    "ent_coef": 0.02942690998315811,
    "learning_rate": 0.001
  },
  {
    "episode": 10018,
    "reward": 83.025746,
    "length": 87,
    "time": 147192.885532,
    "actor_loss": -76.00677490234375,
    "critic_loss": 5.516209602355957,
    "ent_coef": 0.028557609766721725,
    "learning_rate": 0.001
  },
  {
    "episode": 10019,
    "reward": 78.080537,
    "length": 102,
    "time": 147212.74702,
    "actor_loss": -73.75930786132812,
    "critic_loss": 2.3928098678588867,
    "ent_coef": 0.02663968876004219,
    "learning_rate": 0.001
  },
  {
    "episode": 10020,
    "reward": 87.949553,
    "length": 72,
    "time": 147227.022564,
    "actor_loss": -74.638671875,
    "critic_loss": 2.71744704246521,
    "ent_coef": 0.02569602057337761,
    "learning_rate": 0.001
  },
  {
    "episode": 10021,
    "reward": 79.737042,
    "length": 104,
    "time": 147245.758822,
    "actor_loss": -67.138427734375,
    "critic_loss": 2.792478084564209,
    "ent_coef": 0.024430733174085617,
    "learning_rate": 0.001
  },
  {
    "episode": 10022,
    "reward": 85.180717,
    "length": 78,
    "time": 147260.79095,
    "actor_loss": -73.36357116699219,
    "critic_loss": 10.299360275268555,
    "ent_coef": 0.024596717208623886,
    "learning_rate": 0.001
  },
  {
    "episode": 10023,
    "reward": 91.97883,
    "length": 63,
    "time": 147273.82214,
    "actor_loss": -70.38805389404297,
    "critic_loss": 2.182997703552246,
    "ent_coef": 0.027143370360136032,
    "learning_rate": 0.001
  },
  {
    "episode": 10024,
    "reward": 90.577326,
    "length": 64,
    "time": 147285.755807,
    "actor_loss": -65.25934600830078,
    "critic_loss": 2.4820804595947266,
    "ent_coef": 0.030325736850500107,
    "learning_rate": 0.001
  },
  {
    "episode": 10025,
    "reward": 92.183335,
    "length": 62,
    "time": 147300.716628,
    "actor_loss": -72.197265625,
    "critic_loss": 3.739802837371826,
    "ent_coef": 0.03352852165699005,
    "learning_rate": 0.001
  },
  {
    "episode": 10026,
    "reward": 71.667593,
    "length": 85,
    "time": 147315.52155,
    "actor_loss": -68.49226379394531,
    "critic_loss": 49.637611389160156,
    "ent_coef": 0.035510577261447906,
    "learning_rate": 0.001
  },
  {
    "episode": 10027,
    "reward": 86.744884,
    "length": 78,
    "time": 147331.084815,
    "actor_loss": -69.49468994140625,
    "critic_loss": 8.265482902526855,
    "ent_coef": 0.03609567880630493,
    "learning_rate": 0.001
  },
  {
    "episode": 10028,
    "reward": 86.248022,
    "length": 79,
    "time": 147344.230326,
    "actor_loss": -73.3377685546875,
    "critic_loss": 59.104156494140625,
    "ent_coef": 0.03604831174015999,
    "learning_rate": 0.001
  },
  {
    "episode": 10029,
    "reward": 90.948692,
    "length": 63,
    "time": 147355.426408,
    "actor_loss": -68.98320007324219,
    "critic_loss": 2.2020263671875,
    "ent_coef": 0.03933298587799072,
    "learning_rate": 0.001
  },
  {
    "episode": 10030,
    "reward": 89.91568,
    "length": 66,
    "time": 147367.128149,
    "actor_loss": -78.28140258789062,
    "critic_loss": 45.8714714050293,
    "ent_coef": 0.04066869989037514,
    "learning_rate": 0.001
  },
  {
    "episode": 10031,
    "reward": 74.709045,
    "length": 99,
    "time": 147385.627252,
    "actor_loss": -72.75569152832031,
    "critic_loss": 82.6853256225586,
    "ent_coef": 0.03703915327787399,
    "learning_rate": 0.001
  },
  {
    "episode": 10032,
    "reward": 89.036834,
    "length": 66,
    "time": 147397.23522,
    "actor_loss": -69.14640045166016,
    "critic_loss": 3.062412738800049,
    "ent_coef": 0.0392531119287014,
    "learning_rate": 0.001
  },
  {
    "episode": 10033,
    "reward": 88.256927,
    "length": 71,
    "time": 147411.07139,
    "actor_loss": -73.11505889892578,
    "critic_loss": 1.9193416833877563,
    "ent_coef": 0.040991175919771194,
    "learning_rate": 0.001
  },
  {
    "episode": 10034,
    "reward": 88.050801,
    "length": 69,
    "time": 147427.467391,
    "actor_loss": -67.78742218017578,
    "critic_loss": 3.120396137237549,
    "ent_coef": 0.042584944516420364,
    "learning_rate": 0.001
  },
  {
    "episode": 10035,
    "reward": 83.19889,
    "length": 72,
    "time": 147442.280921,
    "actor_loss": -64.15849304199219,
    "critic_loss": 9.952051162719727,
    "ent_coef": 0.04656460881233215,
    "learning_rate": 0.001
  },
  {
    "episode": 10036,
    "reward": 90.532922,
    "length": 64,
    "time": 147453.719601,
    "actor_loss": -67.00912475585938,
    "critic_loss": 4.634117126464844,
    "ent_coef": 0.048242319375276566,
    "learning_rate": 0.001
  },
  {
    "episode": 10037,
    "reward": 90.402499,
    "length": 63,
    "time": 147465.923241,
    "actor_loss": -73.51811981201172,
    "critic_loss": 3.1216092109680176,
    "ent_coef": 0.049107398837804794,
    "learning_rate": 0.001
  },
  {
    "episode": 10038,
    "reward": 84.390106,
    "length": 78,
    "time": 147480.999045,
    "actor_loss": -69.31646728515625,
    "critic_loss": 15.021349906921387,
    "ent_coef": 0.04712996259331703,
    "learning_rate": 0.001
  },
  {
    "episode": 10039,
    "reward": 89.17619,
    "length": 67,
    "time": 147492.681728,
    "actor_loss": -74.36451721191406,
    "critic_loss": 2.983717679977417,
    "ent_coef": 0.046616703271865845,
    "learning_rate": 0.001
  },
  {
    "episode": 10040,
    "reward": 91.642798,
    "length": 61,
    "time": 147503.911737,
    "actor_loss": -72.27745056152344,
    "critic_loss": 1.8883540630340576,
    "ent_coef": 0.048461973667144775,
    "learning_rate": 0.001
  },
  {
    "episode": 10041,
    "reward": 88.525267,
    "length": 71,
    "time": 147516.685515,
    "actor_loss": -67.9715347290039,
    "critic_loss": 3.441685676574707,
    "ent_coef": 0.04944370314478874,
    "learning_rate": 0.001
  },
  {
    "episode": 10042,
    "reward": 87.397121,
    "length": 69,
    "time": 147532.643213,
    "actor_loss": -81.50935363769531,
    "critic_loss": 1.9213225841522217,
    "ent_coef": 0.05037275329232216,
    "learning_rate": 0.001
  },
  {
    "episode": 10043,
    "reward": 90.978473,
    "length": 63,
    "time": 147543.724605,
    "actor_loss": -74.5313720703125,
    "critic_loss": 48.58007049560547,
    "ent_coef": 0.05426652729511261,
    "learning_rate": 0.001
  },
  {
    "episode": 10044,
    "reward": 92.398345,
    "length": 60,
    "time": 147558.481019,
    "actor_loss": -68.33828735351562,
    "critic_loss": 3.72381854057312,
    "ent_coef": 0.058451417833566666,
    "learning_rate": 0.001
  },
  {
    "episode": 10045,
    "reward": 90.863246,
    "length": 64,
    "time": 147570.866547,
    "actor_loss": -72.63665771484375,
    "critic_loss": 3.817695379257202,
    "ent_coef": 0.059368569403886795,
    "learning_rate": 0.001
  },
  {
    "episode": 10046,
    "reward": 86.893863,
    "length": 73,
    "time": 147587.013597,
    "actor_loss": -71.65744018554688,
    "critic_loss": 1.9818484783172607,
    "ent_coef": 0.05781574174761772,
    "learning_rate": 0.001
  },
  {
    "episode": 10047,
    "reward": 87.418982,
    "length": 68,
    "time": 147600.714457,
    "actor_loss": -72.17156982421875,
    "critic_loss": 9.168041229248047,
    "ent_coef": 0.055956851691007614,
    "learning_rate": 0.001
  },
  {
    "episode": 10048,
    "reward": 90.392951,
    "length": 63,
    "time": 147614.399299,
    "actor_loss": -69.2728271484375,
    "critic_loss": 8.869811058044434,
    "ent_coef": 0.05626273155212402,
    "learning_rate": 0.001
  },
  {
    "episode": 10049,
    "reward": 89.96992,
    "length": 66,
    "time": 147625.970933,
    "actor_loss": -74.9775161743164,
    "critic_loss": 3.308868408203125,
    "ent_coef": 0.056391749531030655,
    "learning_rate": 0.001
  },
  {
    "episode": 10050,
    "reward": 90.003301,
    "length": 66,
    "time": 147640.156711,
    "actor_loss": -62.78824996948242,
    "critic_loss": 33.52546691894531,
    "ent_coef": 0.056066352874040604,
    "learning_rate": 0.001
  },
  {
    "episode": 10051,
    "reward": 85.6138,
    "length": 75,
    "time": 147656.856929,
    "actor_loss": -70.81160736083984,
    "critic_loss": 6.78173828125,
    "ent_coef": 0.05354621633887291,
    "learning_rate": 0.001
  },
  {
    "episode": 10052,
    "reward": 90.24866,
    "length": 64,
    "time": 147668.380126,
    "actor_loss": -74.54862976074219,
    "critic_loss": 31.067447662353516,
    "ent_coef": 0.05237189680337906,
    "learning_rate": 0.001
  },
  {
    "episode": 10053,
    "reward": 90.801067,
    "length": 61,
    "time": 147680.275354,
    "actor_loss": -86.10562133789062,
    "critic_loss": 24.032920837402344,
    "ent_coef": 0.05266985297203064,
    "learning_rate": 0.001
  },
  {
    "episode": 10054,
    "reward": 92.12952,
    "length": 59,
    "time": 147691.478622,
    "actor_loss": -74.16667175292969,
    "critic_loss": 2.249588966369629,
    "ent_coef": 0.05616748705506325,
    "learning_rate": 0.001
  },
  {
    "episode": 10055,
    "reward": 89.974969,
    "length": 65,
    "time": 147703.734123,
    "actor_loss": -65.31796264648438,
    "critic_loss": 4.6346940994262695,
    "ent_coef": 0.058649543672800064,
    "learning_rate": 0.001
  },
  {
    "episode": 10056,
    "reward": 90.784369,
    "length": 62,
    "time": 147717.075639,
    "actor_loss": -72.40894317626953,
    "critic_loss": 6.929405689239502,
    "ent_coef": 0.05886752903461456,
    "learning_rate": 0.001
  },
  {
    "episode": 10057,
    "reward": 85.087882,
    "length": 109,
    "time": 147737.460744,
    "actor_loss": -73.63645935058594,
    "critic_loss": 17.491775512695312,
    "ent_coef": 0.06435836106538773,
    "learning_rate": 0.001
  },
  {
    "episode": 10058,
    "reward": 88.770939,
    "length": 66,
    "time": 147749.811063,
    "actor_loss": -72.73789978027344,
    "critic_loss": 2.2040610313415527,
    "ent_coef": 0.06495168805122375,
    "learning_rate": 0.001
  },
  {
    "episode": 10059,
    "reward": 88.249466,
    "length": 71,
    "time": 147764.039515,
    "actor_loss": -68.28325653076172,
    "critic_loss": 55.68503952026367,
    "ent_coef": 0.06361471116542816,
    "learning_rate": 0.001
  },
  {
    "episode": 10060,
    "reward": 81.742093,
    "length": 171,
    "time": 147791.789925,
    "actor_loss": -66.93460845947266,
    "critic_loss": 6.6585798263549805,
    "ent_coef": 0.06177014112472534,
    "learning_rate": 0.001
  },
  {
    "episode": 10061,
    "reward": 85.334032,
    "length": 71,
    "time": 147806.202742,
    "actor_loss": -82.34993743896484,
    "critic_loss": 38.22499084472656,
    "ent_coef": 0.06680053472518921,
    "learning_rate": 0.001
  },
  {
    "episode": 10062,
    "reward": 83.023698,
    "length": 70,
    "time": 147819.070805,
    "actor_loss": -76.3638687133789,
    "critic_loss": 10.19983959197998,
    "ent_coef": 0.07032051682472229,
    "learning_rate": 0.001
  },
  {
    "episode": 10063,
    "reward": -156.987271,
    "length": 143,
    "time": 147840.944028,
    "actor_loss": -68.09808349609375,
    "critic_loss": 11.259641647338867,
    "ent_coef": 0.06911253184080124,
    "learning_rate": 0.001
  },
  {
    "episode": 10064,
    "reward": 90.7077,
    "length": 61,
    "time": 147855.550664,
    "actor_loss": -77.9141845703125,
    "critic_loss": 15.466720581054688,
    "ent_coef": 0.06956160068511963,
    "learning_rate": 0.001
  },
  {
    "episode": 10065,
    "reward": 89.095867,
    "length": 66,
    "time": 147868.076284,
    "actor_loss": -79.31491088867188,
    "critic_loss": 3.409898519515991,
    "ent_coef": 0.0686982199549675,
    "learning_rate": 0.001
  },
  {
    "episode": 10066,
    "reward": 90.186132,
    "length": 63,
    "time": 147879.252055,
    "actor_loss": -63.81547546386719,
    "critic_loss": 2.440286636352539,
    "ent_coef": 0.06717744469642639,
    "learning_rate": 0.001
  },
  {
    "episode": 10067,
    "reward": 90.138526,
    "length": 62,
    "time": 147891.184914,
    "actor_loss": -75.86216735839844,
    "critic_loss": 41.56462097167969,
    "ent_coef": 0.06564810127019882,
    "learning_rate": 0.001
  },
  {
    "episode": 10068,
    "reward": 91.37336,
    "length": 61,
    "time": 147902.185773,
    "actor_loss": -69.41603088378906,
    "critic_loss": 3.252565622329712,
    "ent_coef": 0.06663230806589127,
    "learning_rate": 0.001
  },
  {
    "episode": 10069,
    "reward": 91.473679,
    "length": 60,
    "time": 147913.623395,
    "actor_loss": -69.56695556640625,
    "critic_loss": 3.9443747997283936,
    "ent_coef": 0.06895118206739426,
    "learning_rate": 0.001
  },
  {
    "episode": 10070,
    "reward": -158.003786,
    "length": 137,
    "time": 147936.378237,
    "actor_loss": -73.27830505371094,
    "critic_loss": 36.97611999511719,
    "ent_coef": 0.08054938167333603,
    "learning_rate": 0.001
  },
  {
    "episode": 10071,
    "reward": 81.614797,
    "length": 78,
    "time": 147950.511858,
    "actor_loss": -64.20893859863281,
    "critic_loss": 12.008828163146973,
    "ent_coef": 0.07915658503770828,
    "learning_rate": 0.001
  },
  {
    "episode": 10072,
    "reward": 86.431147,
    "length": 71,
    "time": 147962.653642,
    "actor_loss": -68.05631256103516,
    "critic_loss": 8.319255828857422,
    "ent_coef": 0.07502363622188568,
    "learning_rate": 0.001
  },
  {
    "episode": 10073,
    "reward": 70.105046,
    "length": 78,
    "time": 147975.811292,
    "actor_loss": -75.10594940185547,
    "critic_loss": 5.738733291625977,
    "ent_coef": 0.08120511472225189,
    "learning_rate": 0.001
  },
  {
    "episode": 10074,
    "reward": -153.736616,
    "length": 132,
    "time": 147995.666658,
    "actor_loss": -72.48008728027344,
    "critic_loss": 2.961930274963379,
    "ent_coef": 0.0912139043211937,
    "learning_rate": 0.001
  },
  {
    "episode": 10075,
    "reward": -157.747572,
    "length": 125,
    "time": 148020.492197,
    "actor_loss": -78.61695861816406,
    "critic_loss": 24.200218200683594,
    "ent_coef": 0.0903223529458046,
    "learning_rate": 0.001
  },
  {
    "episode": 10076,
    "reward": -398.667302,
    "length": 567,
    "time": 148100.568305,
    "actor_loss": -77.60574340820312,
    "critic_loss": 162.64080810546875,
    "ent_coef": 0.11138775944709778,
    "learning_rate": 0.001
  },
  {
    "episode": 10077,
    "reward": 89.77483,
    "length": 69,
    "time": 148112.377292,
    "actor_loss": -85.95252990722656,
    "critic_loss": 139.7262725830078,
    "ent_coef": 0.11470593512058258,
    "learning_rate": 0.001
  },
  {
    "episode": 10078,
    "reward": 71.027681,
    "length": 149,
    "time": 148135.128928,
    "actor_loss": -70.20113372802734,
    "critic_loss": 80.20404052734375,
    "ent_coef": 0.11285579204559326,
    "learning_rate": 0.001
  },
  {
    "episode": 10079,
    "reward": -169.642393,
    "length": 137,
    "time": 148158.474045,
    "actor_loss": -76.36572265625,
    "critic_loss": 6.978413105010986,
    "ent_coef": 0.11211802810430527,
    "learning_rate": 0.001
  },
  {
    "episode": 10080,
    "reward": -166.273917,
    "length": 127,
    "time": 148180.561161,
    "actor_loss": -76.5469970703125,
    "critic_loss": 39.93024826049805,
    "ent_coef": 0.1210191622376442,
    "learning_rate": 0.001
  },
  {
    "episode": 10081,
    "reward": -160.476083,
    "length": 110,
    "time": 148197.803678,
    "actor_loss": -82.16218566894531,
    "critic_loss": 95.99884033203125,
    "ent_coef": 0.12784788012504578,
    "learning_rate": 0.001
  },
  {
    "episode": 10082,
    "reward": 86.621333,
    "length": 97,
    "time": 148217.054397,
    "actor_loss": -69.23292541503906,
    "critic_loss": 5.70780086517334,
    "ent_coef": 0.13277922570705414,
    "learning_rate": 0.001
  },
  {
    "episode": 10083,
    "reward": -267.424244,
    "length": 576,
    "time": 148297.086921,
    "actor_loss": -81.44276428222656,
    "critic_loss": 66.45362854003906,
    "ent_coef": 0.1636103242635727,
    "learning_rate": 0.001
  },
  {
    "episode": 10084,
    "reward": 83.492395,
    "length": 114,
    "time": 148317.469017,
    "actor_loss": -82.26487731933594,
    "critic_loss": 20.61669921875,
    "ent_coef": 0.1762848049402237,
    "learning_rate": 0.001
  },
  {
    "episode": 10085,
    "reward": 80.857814,
    "length": 74,
    "time": 148329.980264,
    "actor_loss": -92.88475036621094,
    "critic_loss": 35.775978088378906,
    "ent_coef": 0.18439921736717224,
    "learning_rate": 0.001
  },
  {
    "episode": 10086,
    "reward": 64.709299,
    "length": 149,
    "time": 148355.919873,
    "actor_loss": -87.62030029296875,
    "critic_loss": 88.08821105957031,
    "ent_coef": 0.1895591765642166,
    "learning_rate": 0.001
  },
  {
    "episode": 10087,
    "reward": 71.189872,
    "length": 78,
    "time": 148369.910858,
    "actor_loss": -79.50833129882812,
    "critic_loss": 102.51947021484375,
    "ent_coef": 0.19404609501361847,
    "learning_rate": 0.001
  },
  {
    "episode": 10088,
    "reward": -184.368682,
    "length": 192,
    "time": 148398.609519,
    "actor_loss": -76.8446044921875,
    "critic_loss": 17.14945411682129,
    "ent_coef": 0.18472616374492645,
    "learning_rate": 0.001
  },
  {
    "episode": 10089,
    "reward": -147.222955,
    "length": 83,
    "time": 148414.602353,
    "actor_loss": -74.18490600585938,
    "critic_loss": 17.240028381347656,
    "ent_coef": 0.18474654853343964,
    "learning_rate": 0.001
  },
  {
    "episode": 10090,
    "reward": -169.579364,
    "length": 172,
    "time": 148439.679252,
    "actor_loss": -84.72553253173828,
    "critic_loss": 73.71649169921875,
    "ent_coef": 0.16631510853767395,
    "learning_rate": 0.001
  },
  {
    "episode": 10091,
    "reward": 83.697658,
    "length": 72,
    "time": 148454.273461,
    "actor_loss": -70.96804809570312,
    "critic_loss": 31.388912200927734,
    "ent_coef": 0.1549936681985855,
    "learning_rate": 0.001
  },
  {
    "episode": 10092,
    "reward": -210.048124,
    "length": 214,
    "time": 148485.521832,
    "actor_loss": -86.53919219970703,
    "critic_loss": 56.889766693115234,
    "ent_coef": 0.12765176594257355,
    "learning_rate": 0.001
  },
  {
    "episode": 10093,
    "reward": -218.370075,
    "length": 231,
    "time": 148520.610775,
    "actor_loss": -87.57058715820312,
    "critic_loss": 256.577392578125,
    "ent_coef": 0.1038568913936615,
    "learning_rate": 0.001
  },
  {
    "episode": 10094,
    "reward": -170.179612,
    "length": 128,
    "time": 148541.90309,
    "actor_loss": -87.18046569824219,
    "critic_loss": 70.55474090576172,
    "ent_coef": 0.11567089706659317,
    "learning_rate": 0.001
  },
  {
    "episode": 10095,
    "reward": -178.628635,
    "length": 158,
    "time": 148566.909155,
    "actor_loss": -88.49183654785156,
    "critic_loss": 62.539756774902344,
    "ent_coef": 0.13076677918434143,
    "learning_rate": 0.001
  },
  {
    "episode": 10096,
    "reward": -156.297502,
    "length": 116,
    "time": 148585.134877,
    "actor_loss": -72.31941223144531,
    "critic_loss": 77.82186889648438,
    "ent_coef": 0.1402159035205841,
    "learning_rate": 0.001
  },
  {
    "episode": 10097,
    "reward": 90.462952,
    "length": 62,
    "time": 148598.304702,
    "actor_loss": -76.21261596679688,
    "critic_loss": 28.435123443603516,
    "ent_coef": 0.146157905459404,
    "learning_rate": 0.001
  },
  {
    "episode": 10098,
    "reward": -163.131572,
    "length": 132,
    "time": 148619.952524,
    "actor_loss": -93.83071899414062,
    "critic_loss": 51.27507019042969,
    "ent_coef": 0.15951411426067352,
    "learning_rate": 0.001
  },
  {
    "episode": 10099,
    "reward": -184.583531,
    "length": 205,
    "time": 148649.795983,
    "actor_loss": -78.56912231445312,
    "critic_loss": 2231.03369140625,
    "ent_coef": 0.16462057828903198,
    "learning_rate": 0.001
  },
  {
    "episode": 10100,
    "reward": 83.69312,
    "length": 76,
    "time": 148662.650969,
    "actor_loss": -78.01600646972656,
    "critic_loss": 55.383514404296875,
    "ent_coef": 0.15739943087100983,
    "learning_rate": 0.001
  },
  {
    "episode": 10101,
    "reward": 86.806383,
    "length": 72,
    "time": 148677.752736,
    "actor_loss": -84.2441635131836,
    "critic_loss": 34.67911148071289,
    "ent_coef": 0.14871469140052795,
    "learning_rate": 0.001
  },
  {
    "episode": 10102,
    "reward": -155.541007,
    "length": 129,
    "time": 148697.800394,
    "actor_loss": -93.99984741210938,
    "critic_loss": 108.39411926269531,
    "ent_coef": 0.1397911012172699,
    "learning_rate": 0.001
  },
  {
    "episode": 10103,
    "reward": -172.996929,
    "length": 158,
    "time": 148723.193885,
    "actor_loss": -72.8897476196289,
    "critic_loss": 40.89719772338867,
    "ent_coef": 0.12744678556919098,
    "learning_rate": 0.001
  },
  {
    "episode": 10104,
    "reward": -153.346694,
    "length": 130,
    "time": 148744.011285,
    "actor_loss": -82.88529968261719,
    "critic_loss": 40.63833236694336,
    "ent_coef": 0.14050894975662231,
    "learning_rate": 0.001
  },
  {
    "episode": 10105,
    "reward": -159.55755,
    "length": 142,
    "time": 148765.732358,
    "actor_loss": -83.10686492919922,
    "critic_loss": 23.643295288085938,
    "ent_coef": 0.13624490797519684,
    "learning_rate": 0.001
  },
  {
    "episode": 10106,
    "reward": 79.329441,
    "length": 106,
    "time": 148782.224437,
    "actor_loss": -79.20198059082031,
    "critic_loss": 59.57936477661133,
    "ent_coef": 0.13388729095458984,
    "learning_rate": 0.001
  },
  {
    "episode": 10107,
    "reward": -158.249514,
    "length": 140,
    "time": 148803.283756,
    "actor_loss": -98.3980712890625,
    "critic_loss": 99.57266235351562,
    "ent_coef": 0.14107584953308105,
    "learning_rate": 0.001
  },
  {
    "episode": 10108,
    "reward": 75.333288,
    "length": 115,
    "time": 148824.804578,
    "actor_loss": -80.93608093261719,
    "critic_loss": 80.09335327148438,
    "ent_coef": 0.1462385356426239,
    "learning_rate": 0.001
  },
  {
    "episode": 10109,
    "reward": 81.110571,
    "length": 98,
    "time": 148841.17774,
    "actor_loss": -76.23859405517578,
    "critic_loss": 177.25253295898438,
    "ent_coef": 0.15245790779590607,
    "learning_rate": 0.001
  },
  {
    "episode": 10110,
    "reward": 77.720261,
    "length": 109,
    "time": 148858.948907,
    "actor_loss": -86.48588562011719,
    "critic_loss": 70.32455444335938,
    "ent_coef": 0.15064600110054016,
    "learning_rate": 0.001
  },
  {
    "episode": 10111,
    "reward": 82.641791,
    "length": 94,
    "time": 148877.481811,
    "actor_loss": -87.16534423828125,
    "critic_loss": 94.34921264648438,
    "ent_coef": 0.14781063795089722,
    "learning_rate": 0.001
  },
  {
    "episode": 10112,
    "reward": 71.072138,
    "length": 153,
    "time": 148902.391335,
    "actor_loss": -78.44258117675781,
    "critic_loss": 15.506353378295898,
    "ent_coef": 0.14976263046264648,
    "learning_rate": 0.001
  },
  {
    "episode": 10113,
    "reward": 61.755433,
    "length": 194,
    "time": 148931.361884,
    "actor_loss": -84.14256286621094,
    "critic_loss": 43.14064025878906,
    "ent_coef": 0.15811680257320404,
    "learning_rate": 0.001
  },
  {
    "episode": 10114,
    "reward": 75.96955,
    "length": 120,
    "time": 148949.758168,
    "actor_loss": -87.23242950439453,
    "critic_loss": 12.243829727172852,
    "ent_coef": 0.16772231459617615,
    "learning_rate": 0.001
  },
  {
    "episode": 10115,
    "reward": 42.389208,
    "length": 288,
    "time": 148989.900225,
    "actor_loss": -87.83060455322266,
    "critic_loss": 70.39167785644531,
    "ent_coef": 0.18021072447299957,
    "learning_rate": 0.001
  },
  {
    "episode": 10116,
    "reward": 87.863515,
    "length": 67,
    "time": 149005.327488,
    "actor_loss": -86.47404479980469,
    "critic_loss": 48.629852294921875,
    "ent_coef": 0.18163441121578217,
    "learning_rate": 0.001
  },
  {
    "episode": 10117,
    "reward": 88.155133,
    "length": 66,
    "time": 149017.158046,
    "actor_loss": -90.28168487548828,
    "critic_loss": 13.990800857543945,
    "ent_coef": 0.18284541368484497,
    "learning_rate": 0.001
  },
  {
    "episode": 10118,
    "reward": 89.94441,
    "length": 63,
    "time": 149028.688313,
    "actor_loss": -90.24969482421875,
    "critic_loss": 79.41641235351562,
    "ent_coef": 0.17935369908809662,
    "learning_rate": 0.001
  },
  {
    "episode": 10119,
    "reward": 88.623275,
    "length": 66,
    "time": 149041.164975,
    "actor_loss": -71.56146240234375,
    "critic_loss": 7.987644195556641,
    "ent_coef": 0.17622795701026917,
    "learning_rate": 0.001
  },
  {
    "episode": 10120,
    "reward": 86.759169,
    "length": 69,
    "time": 149055.031164,
    "actor_loss": -75.94468688964844,
    "critic_loss": 12.389028549194336,
    "ent_coef": 0.17265158891677856,
    "learning_rate": 0.001
  },
  {
    "episode": 10121,
    "reward": 85.668726,
    "length": 71,
    "time": 149067.510989,
    "actor_loss": -87.38813781738281,
    "critic_loss": 127.32241821289062,
    "ent_coef": 0.1721821427345276,
    "learning_rate": 0.001
  },
  {
    "episode": 10122,
    "reward": 86.84111,
    "length": 68,
    "time": 149081.774945,
    "actor_loss": -79.69779968261719,
    "critic_loss": 123.80563354492188,
    "ent_coef": 0.15836071968078613,
    "learning_rate": 0.001
  },
  {
    "episode": 10123,
    "reward": 85.148322,
    "length": 72,
    "time": 149094.350761,
    "actor_loss": -87.25216674804688,
    "critic_loss": 11.46399974822998,
    "ent_coef": 0.14880962669849396,
    "learning_rate": 0.001
  },
  {
    "episode": 10124,
    "reward": 56.504187,
    "length": 209,
    "time": 149125.793359,
    "actor_loss": -81.35064697265625,
    "critic_loss": 19.922893524169922,
    "ent_coef": 0.12815985083580017,
    "learning_rate": 0.001
  },
  {
    "episode": 10125,
    "reward": 88.597735,
    "length": 66,
    "time": 149137.29919,
    "actor_loss": -93.47132873535156,
    "critic_loss": 54.01809310913086,
    "ent_coef": 0.12717179954051971,
    "learning_rate": 0.001
  },
  {
    "episode": 10126,
    "reward": 88.322118,
    "length": 66,
    "time": 149148.902814,
    "actor_loss": -94.03010559082031,
    "critic_loss": 33.56535339355469,
    "ent_coef": 0.13080091774463654,
    "learning_rate": 0.001
  },
  {
    "episode": 10127,
    "reward": 88.766579,
    "length": 64,
    "time": 149160.253821,
    "actor_loss": -95.81597137451172,
    "critic_loss": 85.79537200927734,
    "ent_coef": 0.13654804229736328,
    "learning_rate": 0.001
  },
  {
    "episode": 10128,
    "reward": 88.132051,
    "length": 66,
    "time": 149171.823035,
    "actor_loss": -87.98295593261719,
    "critic_loss": 27.815038681030273,
    "ent_coef": 0.14159302413463593,
    "learning_rate": 0.001
  },
  {
    "episode": 10129,
    "reward": 60.373818,
    "length": 204,
    "time": 149201.432758,
    "actor_loss": -83.12249755859375,
    "critic_loss": 70.4278335571289,
    "ent_coef": 0.14012083411216736,
    "learning_rate": 0.001
  },
  {
    "episode": 10130,
    "reward": 86.842941,
    "length": 67,
    "time": 149213.777692,
    "actor_loss": -85.58157348632812,
    "critic_loss": 30.60017204284668,
    "ent_coef": 0.14318592846393585,
    "learning_rate": 0.001
  },
  {
    "episode": 10131,
    "reward": 88.658271,
    "length": 65,
    "time": 149227.328159,
    "actor_loss": -87.98359680175781,
    "critic_loss": 27.567174911499023,
    "ent_coef": 0.14833365380764008,
    "learning_rate": 0.001
  },
  {
    "episode": 10132,
    "reward": 88.564043,
    "length": 65,
    "time": 149240.328166,
    "actor_loss": -85.78543853759766,
    "critic_loss": 40.01640319824219,
    "ent_coef": 0.1543295532464981,
    "learning_rate": 0.001
  },
  {
    "episode": 10133,
    "reward": 88.395211,
    "length": 65,
    "time": 149252.678158,
    "actor_loss": -78.81903839111328,
    "critic_loss": 16.125301361083984,
    "ent_coef": 0.15838348865509033,
    "learning_rate": 0.001
  },
  {
    "episode": 10134,
    "reward": 86.548469,
    "length": 70,
    "time": 149264.891985,
    "actor_loss": -80.13055419921875,
    "critic_loss": 11.306144714355469,
    "ent_coef": 0.14867499470710754,
    "learning_rate": 0.001
  },
  {
    "episode": 10135,
    "reward": 85.936519,
    "length": 69,
    "time": 149278.654955,
    "actor_loss": -89.97383880615234,
    "critic_loss": 64.58683776855469,
    "ent_coef": 0.13549761474132538,
    "learning_rate": 0.001
  },
  {
    "episode": 10136,
    "reward": 88.693951,
    "length": 65,
    "time": 149290.063288,
    "actor_loss": -81.60444641113281,
    "critic_loss": 68.1673583984375,
    "ent_coef": 0.13024450838565826,
    "learning_rate": 0.001
  },
  {
    "episode": 10137,
    "reward": 87.539918,
    "length": 67,
    "time": 149304.146305,
    "actor_loss": -82.39930725097656,
    "critic_loss": 41.29209899902344,
    "ent_coef": 0.12671862542629242,
    "learning_rate": 0.001
  },
  {
    "episode": 10138,
    "reward": 85.416685,
    "length": 70,
    "time": 149318.845003,
    "actor_loss": -88.52854919433594,
    "critic_loss": 37.45762634277344,
    "ent_coef": 0.1279173493385315,
    "learning_rate": 0.001
  },
  {
    "episode": 10139,
    "reward": 87.008751,
    "length": 67,
    "time": 149331.734881,
    "actor_loss": -78.05428314208984,
    "critic_loss": 114.03516387939453,
    "ent_coef": 0.1326911896467209,
    "learning_rate": 0.001
  },
  {
    "episode": 10140,
    "reward": 87.484628,
    "length": 68,
    "time": 149343.90683,
    "actor_loss": -84.99697875976562,
    "critic_loss": 28.407180786132812,
    "ent_coef": 0.13583499193191528,
    "learning_rate": 0.001
  },
  {
    "episode": 10141,
    "reward": 76.913686,
    "length": 122,
    "time": 149366.849514,
    "actor_loss": -89.43338775634766,
    "critic_loss": 53.05816650390625,
    "ent_coef": 0.13752499222755432,
    "learning_rate": 0.001
  },
  {
    "episode": 10142,
    "reward": 89.363672,
    "length": 64,
    "time": 149378.121411,
    "actor_loss": -82.43302917480469,
    "critic_loss": 349.8687744140625,
    "ent_coef": 0.13633453845977783,
    "learning_rate": 0.001
  },
  {
    "episode": 10143,
    "reward": 88.738322,
    "length": 65,
    "time": 149390.02642,
    "actor_loss": -83.69938659667969,
    "critic_loss": 26.691816329956055,
    "ent_coef": 0.14083722233772278,
    "learning_rate": 0.001
  },
  {
    "episode": 10144,
    "reward": 86.571942,
    "length": 69,
    "time": 149402.982335,
    "actor_loss": -79.95184326171875,
    "critic_loss": 14.478050231933594,
    "ent_coef": 0.1416177898645401,
    "learning_rate": 0.001
  },
  {
    "episode": 10145,
    "reward": 85.287331,
    "length": 71,
    "time": 149416.887072,
    "actor_loss": -81.61527252197266,
    "critic_loss": 67.38700866699219,
    "ent_coef": 0.1412886381149292,
    "learning_rate": 0.001
  },
  {
    "episode": 10146,
    "reward": 88.76149,
    "length": 65,
    "time": 149428.614873,
    "actor_loss": -81.75761413574219,
    "critic_loss": 20.264354705810547,
    "ent_coef": 0.14315064251422882,
    "learning_rate": 0.001
  },
  {
    "episode": 10147,
    "reward": 88.224815,
    "length": 66,
    "time": 149441.080969,
    "actor_loss": -84.59459686279297,
    "critic_loss": 18.575910568237305,
    "ent_coef": 0.15209974348545074,
    "learning_rate": 0.001
  },
  {
    "episode": 10148,
    "reward": 87.203258,
    "length": 68,
    "time": 149454.67561,
    "actor_loss": -84.58197021484375,
    "critic_loss": 18.819475173950195,
    "ent_coef": 0.1510152518749237,
    "learning_rate": 0.001
  },
  {
    "episode": 10149,
    "reward": 83.598627,
    "length": 79,
    "time": 149470.287167,
    "actor_loss": -82.4962387084961,
    "critic_loss": 49.071937561035156,
    "ent_coef": 0.1436704397201538,
    "learning_rate": 0.001
  },
  {
    "episode": 10150,
    "reward": 86.807732,
    "length": 68,
    "time": 149482.655804,
    "actor_loss": -88.10494995117188,
    "critic_loss": 39.60432052612305,
    "ent_coef": 0.13890090584754944,
    "learning_rate": 0.001
  },
  {
    "episode": 10151,
    "reward": 87.660105,
    "length": 66,
    "time": 149494.530236,
    "actor_loss": -76.330322265625,
    "critic_loss": 13.576719284057617,
    "ent_coef": 0.1361263394355774,
    "learning_rate": 0.001
  },
  {
    "episode": 10152,
    "reward": 87.040572,
    "length": 68,
    "time": 149506.327439,
    "actor_loss": -88.52550506591797,
    "critic_loss": 56.04883575439453,
    "ent_coef": 0.13467003405094147,
    "learning_rate": 0.001
  },
  {
    "episode": 10153,
    "reward": 83.791495,
    "length": 81,
    "time": 149519.833405,
    "actor_loss": -77.7591552734375,
    "critic_loss": 23.58307456970215,
    "ent_coef": 0.13299402594566345,
    "learning_rate": 0.001
  },
  {
    "episode": 10154,
    "reward": 86.668147,
    "length": 70,
    "time": 149532.982036,
    "actor_loss": -82.31732177734375,
    "critic_loss": 89.51824951171875,
    "ent_coef": 0.12536175549030304,
    "learning_rate": 0.001
  },
  {
    "episode": 10155,
    "reward": 84.638561,
    "length": 80,
    "time": 149550.305819,
    "actor_loss": -85.60447692871094,
    "critic_loss": 7.299444675445557,
    "ent_coef": 0.11932466924190521,
    "learning_rate": 0.001
  },
  {
    "episode": 10156,
    "reward": 85.280715,
    "length": 71,
    "time": 149565.399168,
    "actor_loss": -88.28274536132812,
    "critic_loss": 20.4444522857666,
    "ent_coef": 0.11440745741128922,
    "learning_rate": 0.001
  },
  {
    "episode": 10157,
    "reward": 88.776942,
    "length": 65,
    "time": 149577.860511,
    "actor_loss": -86.11670684814453,
    "critic_loss": 17.504215240478516,
    "ent_coef": 0.11405730247497559,
    "learning_rate": 0.001
  },
  {
    "episode": 10158,
    "reward": 87.55349,
    "length": 66,
    "time": 149593.66849,
    "actor_loss": -88.32015991210938,
    "critic_loss": 23.571552276611328,
    "ent_coef": 0.11658874899148941,
    "learning_rate": 0.001
  },
  {
    "episode": 10159,
    "reward": 82.756846,
    "length": 85,
    "time": 149608.558748,
    "actor_loss": -80.33641052246094,
    "critic_loss": 6.667409896850586,
    "ent_coef": 0.1100182756781578,
    "learning_rate": 0.001
  },
  {
    "episode": 10160,
    "reward": 82.916695,
    "length": 75,
    "time": 149621.35106,
    "actor_loss": -82.07525634765625,
    "critic_loss": 15.47491455078125,
    "ent_coef": 0.10391300916671753,
    "learning_rate": 0.001
  },
  {
    "episode": 10161,
    "reward": 89.264174,
    "length": 64,
    "time": 149634.404972,
    "actor_loss": -85.72441101074219,
    "critic_loss": 37.84791564941406,
    "ent_coef": 0.10651062428951263,
    "learning_rate": 0.001
  },
  {
    "episode": 10162,
    "reward": 86.296233,
    "length": 74,
    "time": 149647.062715,
    "actor_loss": -75.2171401977539,
    "critic_loss": 57.26380157470703,
    "ent_coef": 0.10795874893665314,
    "learning_rate": 0.001
  },
  {
    "episode": 10163,
    "reward": 85.686809,
    "length": 75,
    "time": 149660.106011,
    "actor_loss": -82.57487487792969,
    "critic_loss": 136.58111572265625,
    "ent_coef": 0.11163505911827087,
    "learning_rate": 0.001
  },
  {
    "episode": 10164,
    "reward": 86.000397,
    "length": 74,
    "time": 149673.591939,
    "actor_loss": -81.81349182128906,
    "critic_loss": 67.12342834472656,
    "ent_coef": 0.11456304043531418,
    "learning_rate": 0.001
  },
  {
    "episode": 10165,
    "reward": 87.490439,
    "length": 73,
    "time": 149689.626329,
    "actor_loss": -75.93002319335938,
    "critic_loss": 72.53221130371094,
    "ent_coef": 0.11969108879566193,
    "learning_rate": 0.001
  },
  {
    "episode": 10166,
    "reward": 80.429601,
    "length": 85,
    "time": 149706.167183,
    "actor_loss": -83.77804565429688,
    "critic_loss": 10.956783294677734,
    "ent_coef": 0.11287422478199005,
    "learning_rate": 0.001
  },
  {
    "episode": 10167,
    "reward": 87.921348,
    "length": 66,
    "time": 149717.696468,
    "actor_loss": -78.473876953125,
    "critic_loss": 6.062718391418457,
    "ent_coef": 0.1120074987411499,
    "learning_rate": 0.001
  },
  {
    "episode": 10168,
    "reward": 85.105796,
    "length": 77,
    "time": 149730.962861,
    "actor_loss": -87.83393859863281,
    "critic_loss": 7.450902462005615,
    "ent_coef": 0.11281630396842957,
    "learning_rate": 0.001
  },
  {
    "episode": 10169,
    "reward": 71.467479,
    "length": 149,
    "time": 149754.773553,
    "actor_loss": -81.82489013671875,
    "critic_loss": 70.9815673828125,
    "ent_coef": 0.1095636859536171,
    "learning_rate": 0.001
  },
  {
    "episode": 10170,
    "reward": 81.846849,
    "length": 115,
    "time": 149773.732129,
    "actor_loss": -82.45084381103516,
    "critic_loss": 6.013382911682129,
    "ent_coef": 0.1108456403017044,
    "learning_rate": 0.001
  },
  {
    "episode": 10171,
    "reward": 82.876243,
    "length": 112,
    "time": 149792.678832,
    "actor_loss": -86.66659545898438,
    "critic_loss": 7.629791259765625,
    "ent_coef": 0.12012225389480591,
    "learning_rate": 0.001
  },
  {
    "episode": 10172,
    "reward": 84.098371,
    "length": 91,
    "time": 149808.69521,
    "actor_loss": -79.10247802734375,
    "critic_loss": 16.390010833740234,
    "ent_coef": 0.12136068195104599,
    "learning_rate": 0.001
  },
  {
    "episode": 10173,
    "reward": 83.575002,
    "length": 86,
    "time": 149823.17704,
    "actor_loss": -84.58633422851562,
    "critic_loss": 15.710439682006836,
    "ent_coef": 0.12869980931282043,
    "learning_rate": 0.001
  },
  {
    "episode": 10174,
    "reward": -152.589823,
    "length": 588,
    "time": 149903.181824,
    "actor_loss": -80.89341735839844,
    "critic_loss": 24.40764808654785,
    "ent_coef": 0.14150278270244598,
    "learning_rate": 0.001
  },
  {
    "episode": 10175,
    "reward": 87.01046,
    "length": 74,
    "time": 149915.644697,
    "actor_loss": -80.96340942382812,
    "critic_loss": 13.095004081726074,
    "ent_coef": 0.13608278334140778,
    "learning_rate": 0.001
  },
  {
    "episode": 10176,
    "reward": 84.386669,
    "length": 80,
    "time": 149930.10182,
    "actor_loss": -81.93440246582031,
    "critic_loss": 5.751522064208984,
    "ent_coef": 0.1313026249408722,
    "learning_rate": 0.001
  },
  {
    "episode": 10177,
    "reward": 81.785807,
    "length": 85,
    "time": 149944.425429,
    "actor_loss": -73.42308044433594,
    "critic_loss": 21.886707305908203,
    "ent_coef": 0.12134115397930145,
    "learning_rate": 0.001
  },
  {
    "episode": 10178,
    "reward": -161.715287,
    "length": 157,
    "time": 149968.731688,
    "actor_loss": -84.7213363647461,
    "critic_loss": 13.835988998413086,
    "ent_coef": 0.11376623809337616,
    "learning_rate": 0.001
  },
  {
    "episode": 10179,
    "reward": 84.038876,
    "length": 79,
    "time": 149982.054934,
    "actor_loss": -80.7204818725586,
    "critic_loss": 14.09630012512207,
    "ent_coef": 0.11146508902311325,
    "learning_rate": 0.001
  },
  {
    "episode": 10180,
    "reward": 82.516067,
    "length": 111,
    "time": 150001.231911,
    "actor_loss": -79.62629699707031,
    "critic_loss": 4.6689348220825195,
    "ent_coef": 0.10847371071577072,
    "learning_rate": 0.001
  },
  {
    "episode": 10181,
    "reward": 86.112282,
    "length": 76,
    "time": 150015.371079,
    "actor_loss": -79.24579620361328,
    "critic_loss": 10.109094619750977,
    "ent_coef": 0.10662020742893219,
    "learning_rate": 0.001
  },
  {
    "episode": 10182,
    "reward": 81.988833,
    "length": 82,
    "time": 150029.326441,
    "actor_loss": -80.67794036865234,
    "critic_loss": 157.29656982421875,
    "ent_coef": 0.10739333182573318,
    "learning_rate": 0.001
  },
  {
    "episode": 10183,
    "reward": 82.232474,
    "length": 110,
    "time": 150049.14303,
    "actor_loss": -83.32772827148438,
    "critic_loss": 27.893020629882812,
    "ent_coef": 0.1235145777463913,
    "learning_rate": 0.001
  },
  {
    "episode": 10184,
    "reward": 84.428557,
    "length": 78,
    "time": 150062.518757,
    "actor_loss": -84.43319702148438,
    "critic_loss": 11.760190963745117,
    "ent_coef": 0.12888778746128082,
    "learning_rate": 0.001
  },
  {
    "episode": 10185,
    "reward": 79.221326,
    "length": 91,
    "time": 150078.47982,
    "actor_loss": -78.94374084472656,
    "critic_loss": 10.019376754760742,
    "ent_coef": 0.12239038199186325,
    "learning_rate": 0.001
  },
  {
    "episode": 10186,
    "reward": 82.850518,
    "length": 81,
    "time": 150092.044982,
    "actor_loss": -75.97989654541016,
    "critic_loss": 38.03934860229492,
    "ent_coef": 0.12044542282819748,
    "learning_rate": 0.001
  },
  {
    "episode": 10187,
    "reward": 84.351439,
    "length": 81,
    "time": 150108.182975,
    "actor_loss": -71.2500228881836,
    "critic_loss": 20.736230850219727,
    "ent_coef": 0.12357065826654434,
    "learning_rate": 0.001
  },
  {
    "episode": 10188,
    "reward": 86.375332,
    "length": 75,
    "time": 150121.948786,
    "actor_loss": -78.18630981445312,
    "critic_loss": 11.622008323669434,
    "ent_coef": 0.12407243251800537,
    "learning_rate": 0.001
  },
  {
    "episode": 10189,
    "reward": 81.617468,
    "length": 87,
    "time": 150138.078442,
    "actor_loss": -82.08145904541016,
    "critic_loss": 17.476802825927734,
    "ent_coef": 0.12149970978498459,
    "learning_rate": 0.001
  },
  {
    "episode": 10190,
    "reward": 83.698179,
    "length": 83,
    "time": 150151.764172,
    "actor_loss": -74.32025146484375,
    "critic_loss": 10.258726119995117,
    "ent_coef": 0.12131520360708237,
    "learning_rate": 0.001
  },
  {
    "episode": 10191,
    "reward": 85.655836,
    "length": 78,
    "time": 150165.10737,
    "actor_loss": -82.99283599853516,
    "critic_loss": 14.166475296020508,
    "ent_coef": 0.1217213124036789,
    "learning_rate": 0.001
  },
  {
    "episode": 10192,
    "reward": 86.141353,
    "length": 77,
    "time": 150179.327051,
    "actor_loss": -76.74781799316406,
    "critic_loss": 7.48280668258667,
    "ent_coef": 0.11993998289108276,
    "learning_rate": 0.001
  },
  {
    "episode": 10193,
    "reward": 82.101405,
    "length": 86,
    "time": 150193.843733,
    "actor_loss": -76.9853286743164,
    "critic_loss": 5.328599452972412,
    "ent_coef": 0.11384133994579315,
    "learning_rate": 0.001
  },
  {
    "episode": 10194,
    "reward": 81.53936,
    "length": 86,
    "time": 150211.199911,
    "actor_loss": -75.3582763671875,
    "critic_loss": 8.081429481506348,
    "ent_coef": 0.10490439087152481,
    "learning_rate": 0.001
  },
  {
    "episode": 10195,
    "reward": 83.929589,
    "length": 82,
    "time": 150226.835406,
    "actor_loss": -79.55265808105469,
    "critic_loss": 6.7228546142578125,
    "ent_coef": 0.10243461281061172,
    "learning_rate": 0.001
  },
  {
    "episode": 10196,
    "reward": 86.171151,
    "length": 75,
    "time": 150239.645143,
    "actor_loss": -73.37783813476562,
    "critic_loss": 20.181102752685547,
    "ent_coef": 0.10338393598794937,
    "learning_rate": 0.001
  },
  {
    "episode": 10197,
    "reward": 83.899248,
    "length": 80,
    "time": 150253.420175,
    "actor_loss": -81.43767547607422,
    "critic_loss": 5.060421943664551,
    "ent_coef": 0.10159371048212051,
    "learning_rate": 0.001
  },
  {
    "episode": 10198,
    "reward": 85.275004,
    "length": 78,
    "time": 150266.957464,
    "actor_loss": -82.21247863769531,
    "critic_loss": 82.21296691894531,
    "ent_coef": 0.09821723401546478,
    "learning_rate": 0.001
  },
  {
    "episode": 10199,
    "reward": 85.062522,
    "length": 78,
    "time": 150280.122713,
    "actor_loss": -81.523681640625,
    "critic_loss": 4.607126235961914,
    "ent_coef": 0.09909257292747498,
    "learning_rate": 0.001
  },
  {
    "episode": 10200,
    "reward": 87.941926,
    "length": 72,
    "time": 150294.889112,
    "actor_loss": -76.80936431884766,
    "critic_loss": 5.861893177032471,
    "ent_coef": 0.10527945309877396,
    "learning_rate": 0.001
  },
  {
    "episode": 10201,
    "reward": 85.27644,
    "length": 78,
    "time": 150312.563202,
    "actor_loss": -80.5542984008789,
    "critic_loss": 21.426536560058594,
    "ent_coef": 0.11019925773143768,
    "learning_rate": 0.001
  },
  {
    "episode": 10202,
    "reward": 82.111998,
    "length": 84,
    "time": 150326.372439,
    "actor_loss": -79.10868072509766,
    "critic_loss": 17.96303939819336,
    "ent_coef": 0.10484693199396133,
    "learning_rate": 0.001
  },
  {
    "episode": 10203,
    "reward": 83.728938,
    "length": 115,
    "time": 150345.047272,
    "actor_loss": -79.16512298583984,
    "critic_loss": 34.1124267578125,
    "ent_coef": 0.09969787299633026,
    "learning_rate": 0.001
  },
  {
    "episode": 10204,
    "reward": 82.652349,
    "length": 84,
    "time": 150359.005216,
    "actor_loss": -75.3037109375,
    "critic_loss": 4.533571243286133,
    "ent_coef": 0.09863047301769257,
    "learning_rate": 0.001
  },
  {
    "episode": 10205,
    "reward": 82.600263,
    "length": 83,
    "time": 150375.565542,
    "actor_loss": -72.1600570678711,
    "critic_loss": 32.133670806884766,
    "ent_coef": 0.09447021782398224,
    "learning_rate": 0.001
  },
  {
    "episode": 10206,
    "reward": -158.418183,
    "length": 144,
    "time": 150398.366376,
    "actor_loss": -76.60902404785156,
    "critic_loss": 21.694480895996094,
    "ent_coef": 0.09633738547563553,
    "learning_rate": 0.001
  },
  {
    "episode": 10207,
    "reward": 81.369056,
    "length": 84,
    "time": 150414.813553,
    "actor_loss": -77.31954956054688,
    "critic_loss": 19.31393051147461,
    "ent_coef": 0.09703566879034042,
    "learning_rate": 0.001
  },
  {
    "episode": 10208,
    "reward": 84.966178,
    "length": 80,
    "time": 150430.385443,
    "actor_loss": -79.63722229003906,
    "critic_loss": 26.308238983154297,
    "ent_coef": 0.09908411651849747,
    "learning_rate": 0.001
  },
  {
    "episode": 10209,
    "reward": 86.213582,
    "length": 76,
    "time": 150443.303488,
    "actor_loss": -80.8277816772461,
    "critic_loss": 22.038063049316406,
    "ent_coef": 0.10641269385814667,
    "learning_rate": 0.001
  },
  {
    "episode": 10210,
    "reward": 80.55875,
    "length": 88,
    "time": 150460.092352,
    "actor_loss": -74.16049194335938,
    "critic_loss": 24.712493896484375,
    "ent_coef": 0.10556687414646149,
    "learning_rate": 0.001
  },
  {
    "episode": 10211,
    "reward": 84.458266,
    "length": 80,
    "time": 150474.489821,
    "actor_loss": -74.37393188476562,
    "critic_loss": 11.085733413696289,
    "ent_coef": 0.09665229171514511,
    "learning_rate": 0.001
  },
  {
    "episode": 10212,
    "reward": 85.02184,
    "length": 78,
    "time": 150487.553173,
    "actor_loss": -76.40379333496094,
    "critic_loss": 27.206729888916016,
    "ent_coef": 0.09315543621778488,
    "learning_rate": 0.001
  },
  {
    "episode": 10213,
    "reward": -156.031164,
    "length": 140,
    "time": 150508.820962,
    "actor_loss": -73.16107177734375,
    "critic_loss": 26.60443687438965,
    "ent_coef": 0.0936301127076149,
    "learning_rate": 0.001
  },
  {
    "episode": 10214,
    "reward": 83.291296,
    "length": 83,
    "time": 150522.523295,
    "actor_loss": -73.12071228027344,
    "critic_loss": 11.887823104858398,
    "ent_coef": 0.09539484232664108,
    "learning_rate": 0.001
  },
  {
    "episode": 10215,
    "reward": 85.271479,
    "length": 80,
    "time": 150536.952378,
    "actor_loss": -69.87523651123047,
    "critic_loss": 252.17105102539062,
    "ent_coef": 0.09123721718788147,
    "learning_rate": 0.001
  },
  {
    "episode": 10216,
    "reward": 81.177517,
    "length": 87,
    "time": 150553.027874,
    "actor_loss": -71.1731948852539,
    "critic_loss": 15.77125358581543,
    "ent_coef": 0.08812679350376129,
    "learning_rate": 0.001
  },
  {
    "episode": 10217,
    "reward": 82.464755,
    "length": 84,
    "time": 150567.739899,
    "actor_loss": -74.92488098144531,
    "critic_loss": 7.328186988830566,
    "ent_coef": 0.0855586975812912,
    "learning_rate": 0.001
  },
  {
    "episode": 10218,
    "reward": 83.154261,
    "length": 82,
    "time": 150583.644364,
    "actor_loss": -74.00642395019531,
    "critic_loss": 9.894978523254395,
    "ent_coef": 0.08597484230995178,
    "learning_rate": 0.001
  },
  {
    "episode": 10219,
    "reward": 83.042605,
    "length": 82,
    "time": 150597.766211,
    "actor_loss": -74.46461486816406,
    "critic_loss": 11.26388168334961,
    "ent_coef": 0.08512911945581436,
    "learning_rate": 0.001
  },
  {
    "episode": 10220,
    "reward": 82.67585,
    "length": 85,
    "time": 150612.589305,
    "actor_loss": -76.03239440917969,
    "critic_loss": 9.07907485961914,
    "ent_coef": 0.08214422315359116,
    "learning_rate": 0.001
  },
  {
    "episode": 10221,
    "reward": 77.589663,
    "length": 97,
    "time": 150632.881096,
    "actor_loss": -79.02449798583984,
    "critic_loss": 10.697304725646973,
    "ent_coef": 0.07042092829942703,
    "learning_rate": 0.001
  },
  {
    "episode": 10222,
    "reward": 82.126989,
    "length": 87,
    "time": 150647.226184,
    "actor_loss": -72.44461822509766,
    "critic_loss": 3.7400269508361816,
    "ent_coef": 0.06700295954942703,
    "learning_rate": 0.001
  },
  {
    "episode": 10223,
    "reward": 82.125174,
    "length": 85,
    "time": 150662.170575,
    "actor_loss": -74.520751953125,
    "critic_loss": 5.655611038208008,
    "ent_coef": 0.06406356394290924,
    "learning_rate": 0.001
  },
  {
    "episode": 10224,
    "reward": 70.724815,
    "length": 118,
    "time": 150680.397937,
    "actor_loss": -72.70899963378906,
    "critic_loss": 5.264224052429199,
    "ent_coef": 0.055080559104681015,
    "learning_rate": 0.001
  },
  {
    "episode": 10225,
    "reward": 74.655963,
    "length": 102,
    "time": 150698.972664,
    "actor_loss": -72.20039367675781,
    "critic_loss": 11.06573486328125,
    "ent_coef": 0.05425473302602768,
    "learning_rate": 0.001
  },
  {
    "episode": 10226,
    "reward": 77.561842,
    "length": 95,
    "time": 150715.712679,
    "actor_loss": -71.48035430908203,
    "critic_loss": 4.201324462890625,
    "ent_coef": 0.05470316857099533,
    "learning_rate": 0.001
  },
  {
    "episode": 10227,
    "reward": 62.098982,
    "length": 133,
    "time": 150739.108992,
    "actor_loss": -75.11662292480469,
    "critic_loss": 4.011145114898682,
    "ent_coef": 0.057961367070674896,
    "learning_rate": 0.001
  },
  {
    "episode": 10228,
    "reward": 60.383089,
    "length": 143,
    "time": 150764.151672,
    "actor_loss": -69.91561889648438,
    "critic_loss": 6.778952598571777,
    "ent_coef": 0.0657372698187828,
    "learning_rate": 0.001
  },
  {
    "episode": 10229,
    "reward": 75.141904,
    "length": 97,
    "time": 150780.067943,
    "actor_loss": -71.20492553710938,
    "critic_loss": 10.276832580566406,
    "ent_coef": 0.07068806886672974,
    "learning_rate": 0.001
  },
  {
    "episode": 10230,
    "reward": 71.813589,
    "length": 112,
    "time": 150799.252377,
    "actor_loss": -74.98363494873047,
    "critic_loss": 66.36009216308594,
    "ent_coef": 0.08212481439113617,
    "learning_rate": 0.001
  },
  {
    "episode": 10231,
    "reward": -169.805915,
    "length": 172,
    "time": 150826.382763,
    "actor_loss": -73.91180419921875,
    "critic_loss": 16.874168395996094,
    "ent_coef": 0.08862098306417465,
    "learning_rate": 0.001
  },
  {
    "episode": 10232,
    "reward": 69.278686,
    "length": 115,
    "time": 150844.286865,
    "actor_loss": -72.14024353027344,
    "critic_loss": 8.9713134765625,
    "ent_coef": 0.08492639660835266,
    "learning_rate": 0.001
  },
  {
    "episode": 10233,
    "reward": -35.811713,
    "length": 412,
    "time": 150900.989959,
    "actor_loss": -72.38319396972656,
    "critic_loss": 4.896420955657959,
    "ent_coef": 0.08654054999351501,
    "learning_rate": 0.001
  },
  {
    "episode": 10234,
    "reward": 43.722749,
    "length": 189,
    "time": 150928.485535,
    "actor_loss": -70.93760681152344,
    "critic_loss": 10.958473205566406,
    "ent_coef": 0.09746447205543518,
    "learning_rate": 0.001
  },
  {
    "episode": 10235,
    "reward": 78.018491,
    "length": 91,
    "time": 150944.889649,
    "actor_loss": -68.85710144042969,
    "critic_loss": 78.38819122314453,
    "ent_coef": 0.1067059263586998,
    "learning_rate": 0.001
  },
  {
    "episode": 10236,
    "reward": 80.316233,
    "length": 86,
    "time": 150959.446727,
    "actor_loss": -70.42997741699219,
    "critic_loss": 4.862818717956543,
    "ent_coef": 0.1112823486328125,
    "learning_rate": 0.001
  },
  {
    "episode": 10237,
    "reward": 73.304492,
    "length": 114,
    "time": 150977.982964,
    "actor_loss": -72.34140014648438,
    "critic_loss": 6.089132308959961,
    "ent_coef": 0.10107892006635666,
    "learning_rate": 0.001
  },
  {
    "episode": 10238,
    "reward": 71.437696,
    "length": 116,
    "time": 150996.030241,
    "actor_loss": -73.41659545898438,
    "critic_loss": 8.46847915649414,
    "ent_coef": 0.09621214866638184,
    "learning_rate": 0.001
  },
  {
    "episode": 10239,
    "reward": 87.330412,
    "length": 72,
    "time": 151009.618979,
    "actor_loss": -75.03948974609375,
    "critic_loss": 14.884846687316895,
    "ent_coef": 0.10174127668142319,
    "learning_rate": 0.001
  },
  {
    "episode": 10240,
    "reward": 82.382187,
    "length": 88,
    "time": 151025.742477,
    "actor_loss": -67.67520904541016,
    "critic_loss": 22.92168426513672,
    "ent_coef": 0.10086534172296524,
    "learning_rate": 0.001
  },
  {
    "episode": 10241,
    "reward": 68.872022,
    "length": 126,
    "time": 151046.510781,
    "actor_loss": -75.85232543945312,
    "critic_loss": 15.197789192199707,
    "ent_coef": 0.09335645288228989,
    "learning_rate": 0.001
  },
  {
    "episode": 10242,
    "reward": 87.636729,
    "length": 73,
    "time": 151059.456388,
    "actor_loss": -74.94926452636719,
    "critic_loss": 9.411506652832031,
    "ent_coef": 0.09955351054668427,
    "learning_rate": 0.001
  },
  {
    "episode": 10243,
    "reward": 82.763733,
    "length": 87,
    "time": 151073.787973,
    "actor_loss": -74.39295196533203,
    "critic_loss": 8.112042427062988,
    "ent_coef": 0.09734780341386795,
    "learning_rate": 0.001
  },
  {
    "episode": 10244,
    "reward": 80.217644,
    "length": 86,
    "time": 151090.308744,
    "actor_loss": -73.52391052246094,
    "critic_loss": 62.66960144042969,
    "ent_coef": 0.09435033798217773,
    "learning_rate": 0.001
  },
  {
    "episode": 10245,
    "reward": 72.069867,
    "length": 107,
    "time": 151108.170852,
    "actor_loss": -75.38665771484375,
    "critic_loss": 9.640609741210938,
    "ent_coef": 0.0903034657239914,
    "learning_rate": 0.001
  },
  {
    "episode": 10246,
    "reward": 75.755028,
    "length": 99,
    "time": 151123.901103,
    "actor_loss": -70.79721069335938,
    "critic_loss": 55.71160888671875,
    "ent_coef": 0.08531084656715393,
    "learning_rate": 0.001
  },
  {
    "episode": 10247,
    "reward": 76.997184,
    "length": 95,
    "time": 151140.418319,
    "actor_loss": -71.31684875488281,
    "critic_loss": 18.77581787109375,
    "ent_coef": 0.08414024859666824,
    "learning_rate": 0.001
  },
  {
    "episode": 10248,
    "reward": 23.465355,
    "length": 199,
    "time": 151170.423522,
    "actor_loss": -72.49581909179688,
    "critic_loss": 11.88917350769043,
    "ent_coef": 0.07321672141551971,
    "learning_rate": 0.001
  },
  {
    "episode": 10249,
    "reward": 53.126092,
    "length": 150,
    "time": 151195.493137,
    "actor_loss": -71.74022674560547,
    "critic_loss": 10.730390548706055,
    "ent_coef": 0.07081612199544907,
    "learning_rate": 0.001
  },
  {
    "episode": 10250,
    "reward": 62.821605,
    "length": 132,
    "time": 151215.472012,
    "actor_loss": -69.71089935302734,
    "critic_loss": 4.6934494972229,
    "ent_coef": 0.07347177714109421,
    "learning_rate": 0.001
  },
  {
    "episode": 10251,
    "reward": 84.013921,
    "length": 78,
    "time": 151229.103755,
    "actor_loss": -73.38742065429688,
    "critic_loss": 602.1832275390625,
    "ent_coef": 0.07998912781476974,
    "learning_rate": 0.001
  },
  {
    "episode": 10252,
    "reward": 79.791977,
    "length": 89,
    "time": 151244.12552,
    "actor_loss": -71.26130676269531,
    "critic_loss": 257.0875549316406,
    "ent_coef": 0.082183338701725,
    "learning_rate": 0.001
  },
  {
    "episode": 10253,
    "reward": 78.857863,
    "length": 87,
    "time": 151260.582105,
    "actor_loss": -67.49858093261719,
    "critic_loss": 14.05375862121582,
    "ent_coef": 0.08364050090312958,
    "learning_rate": 0.001
  },
  {
    "episode": 10254,
    "reward": 75.379534,
    "length": 97,
    "time": 151278.46919,
    "actor_loss": -68.1793212890625,
    "critic_loss": 2.8868088722229004,
    "ent_coef": 0.08908870816230774,
    "learning_rate": 0.001
  },
  {
    "episode": 10255,
    "reward": 85.917655,
    "length": 72,
    "time": 151290.796304,
    "actor_loss": -68.6811752319336,
    "critic_loss": 9.991518020629883,
    "ent_coef": 0.09407360851764679,
    "learning_rate": 0.001
  },
  {
    "episode": 10256,
    "reward": 80.188857,
    "length": 84,
    "time": 151304.650022,
    "actor_loss": -74.35525512695312,
    "critic_loss": 4.469107627868652,
    "ent_coef": 0.0985085517168045,
    "learning_rate": 0.001
  },
  {
    "episode": 10257,
    "reward": 70.633159,
    "length": 103,
    "time": 151323.03072,
    "actor_loss": -66.58157348632812,
    "critic_loss": 45.30059814453125,
    "ent_coef": 0.09622121602296829,
    "learning_rate": 0.001
  },
  {
    "episode": 10258,
    "reward": 61.577684,
    "length": 123,
    "time": 151341.929559,
    "actor_loss": -72.6580810546875,
    "critic_loss": 4.999608993530273,
    "ent_coef": 0.08934016525745392,
    "learning_rate": 0.001
  },
  {
    "episode": 10259,
    "reward": 80.772682,
    "length": 82,
    "time": 151355.427882,
    "actor_loss": -64.36640167236328,
    "critic_loss": 6.007259368896484,
    "ent_coef": 0.08815951645374298,
    "learning_rate": 0.001
  },
  {
    "episode": 10260,
    "reward": 85.065574,
    "length": 74,
    "time": 151369.066294,
    "actor_loss": -71.09403991699219,
    "critic_loss": 24.824703216552734,
    "ent_coef": 0.09000008553266525,
    "learning_rate": 0.001
  },
  {
    "episode": 10261,
    "reward": 55.980719,
    "length": 132,
    "time": 151390.037235,
    "actor_loss": -71.34436798095703,
    "critic_loss": 13.181384086608887,
    "ent_coef": 0.08689011633396149,
    "learning_rate": 0.001
  },
  {
    "episode": 10262,
    "reward": 81.033385,
    "length": 93,
    "time": 151404.997706,
    "actor_loss": -65.99484252929688,
    "critic_loss": 15.043891906738281,
    "ent_coef": 0.0956244096159935,
    "learning_rate": 0.001
  },
  {
    "episode": 10263,
    "reward": 85.867728,
    "length": 72,
    "time": 151417.564447,
    "actor_loss": -64.92375946044922,
    "critic_loss": 3.383009433746338,
    "ent_coef": 0.10194569826126099,
    "learning_rate": 0.001
  },
  {
    "episode": 10264,
    "reward": 82.413391,
    "length": 79,
    "time": 151431.898101,
    "actor_loss": -70.09262084960938,
    "critic_loss": 58.83389663696289,
    "ent_coef": 0.10006848722696304,
    "learning_rate": 0.001
  },
  {
    "episode": 10265,
    "reward": 72.834957,
    "length": 98,
    "time": 151447.652429,
    "actor_loss": -71.00651550292969,
    "critic_loss": 5.781039237976074,
    "ent_coef": 0.09602263569831848,
    "learning_rate": 0.001
  },
  {
    "episode": 10266,
    "reward": 79.054407,
    "length": 85,
    "time": 151461.730731,
    "actor_loss": -65.70004272460938,
    "critic_loss": 11.57806396484375,
    "ent_coef": 0.09363354742527008,
    "learning_rate": 0.001
  },
  {
    "episode": 10267,
    "reward": 77.775493,
    "length": 87,
    "time": 151477.022807,
    "actor_loss": -68.8060302734375,
    "critic_loss": 6.445514678955078,
    "ent_coef": 0.09213070571422577,
    "learning_rate": 0.001
  },
  {
    "episode": 10268,
    "reward": 86.758217,
    "length": 69,
    "time": 151491.515798,
    "actor_loss": -68.88643646240234,
    "critic_loss": 21.348981857299805,
    "ent_coef": 0.09387970715761185,
    "learning_rate": 0.001
  },
  {
    "episode": 10269,
    "reward": 80.593305,
    "length": 82,
    "time": 151505.105447,
    "actor_loss": -70.21647644042969,
    "critic_loss": 52.91299057006836,
    "ent_coef": 0.09624920040369034,
    "learning_rate": 0.001
  },
  {
    "episode": 10270,
    "reward": 79.773698,
    "length": 83,
    "time": 151518.857478,
    "actor_loss": -72.17329406738281,
    "critic_loss": 17.245655059814453,
    "ent_coef": 0.09572047740221024,
    "learning_rate": 0.001
  },
  {
    "episode": 10271,
    "reward": 85.855212,
    "length": 72,
    "time": 151535.079739,
    "actor_loss": -66.91923522949219,
    "critic_loss": 14.481744766235352,
    "ent_coef": 0.09891563653945923,
    "learning_rate": 0.001
  },
  {
    "episode": 10272,
    "reward": 85.506154,
    "length": 73,
    "time": 151547.497473,
    "actor_loss": -66.30374145507812,
    "critic_loss": 4.562447547912598,
    "ent_coef": 0.10594068467617035,
    "learning_rate": 0.001
  },
  {
    "episode": 10273,
    "reward": 80.054795,
    "length": 82,
    "time": 151562.121119,
    "actor_loss": -69.25143432617188,
    "critic_loss": 7.199930191040039,
    "ent_coef": 0.10290185362100601,
    "learning_rate": 0.001
  },
  {
    "episode": 10274,
    "reward": 82.256565,
    "length": 78,
    "time": 151578.009333,
    "actor_loss": -69.67142486572266,
    "critic_loss": 12.015674591064453,
    "ent_coef": 0.10138612240552902,
    "learning_rate": 0.001
  },
  {
    "episode": 10275,
    "reward": 87.240842,
    "length": 68,
    "time": 151590.817456,
    "actor_loss": -71.78093719482422,
    "critic_loss": 4.297013282775879,
    "ent_coef": 0.10176563262939453,
    "learning_rate": 0.001
  },
  {
    "episode": 10276,
    "reward": 85.015652,
    "length": 72,
    "time": 151604.362086,
    "actor_loss": -67.31584930419922,
    "critic_loss": 25.622608184814453,
    "ent_coef": 0.10531545430421829,
    "learning_rate": 0.001
  },
  {
    "episode": 10277,
    "reward": 81.276167,
    "length": 90,
    "time": 151619.485081,
    "actor_loss": -65.91991424560547,
    "critic_loss": 11.145464897155762,
    "ent_coef": 0.10685423016548157,
    "learning_rate": 0.001
  },
  {
    "episode": 10278,
    "reward": 85.16381,
    "length": 73,
    "time": 151634.236811,
    "actor_loss": -67.11012268066406,
    "critic_loss": 9.576539993286133,
    "ent_coef": 0.10465250164270401,
    "learning_rate": 0.001
  },
  {
    "episode": 10279,
    "reward": 83.481536,
    "length": 76,
    "time": 151646.927749,
    "actor_loss": -63.53999710083008,
    "critic_loss": 5.928184509277344,
    "ent_coef": 0.10179730504751205,
    "learning_rate": 0.001
  },
  {
    "episode": 10280,
    "reward": 80.703741,
    "length": 82,
    "time": 151660.825501,
    "actor_loss": -68.78938293457031,
    "critic_loss": 5.807779312133789,
    "ent_coef": 0.0999138206243515,
    "learning_rate": 0.001
  },
  {
    "episode": 10281,
    "reward": 83.190986,
    "length": 76,
    "time": 151674.290472,
    "actor_loss": -70.88748168945312,
    "critic_loss": 4.84053897857666,
    "ent_coef": 0.10008348524570465,
    "learning_rate": 0.001
  },
  {
    "episode": 10282,
    "reward": 83.314815,
    "length": 75,
    "time": 151691.682195,
    "actor_loss": -63.5678825378418,
    "critic_loss": 10.019853591918945,
    "ent_coef": 0.10119133442640305,
    "learning_rate": 0.001
  },
  {
    "episode": 10283,
    "reward": 83.704356,
    "length": 74,
    "time": 151704.421838,
    "actor_loss": -64.52323913574219,
    "critic_loss": 10.928457260131836,
    "ent_coef": 0.1008879691362381,
    "learning_rate": 0.001
  },
  {
    "episode": 10284,
    "reward": 85.857798,
    "length": 71,
    "time": 151717.487968,
    "actor_loss": -73.2206802368164,
    "critic_loss": 20.104984283447266,
    "ent_coef": 0.10120183229446411,
    "learning_rate": 0.001
  },
  {
    "episode": 10285,
    "reward": 87.215954,
    "length": 68,
    "time": 151729.330794,
    "actor_loss": -63.23921203613281,
    "critic_loss": 10.537436485290527,
    "ent_coef": 0.10431531071662903,
    "learning_rate": 0.001
  },
  {
    "episode": 10286,
    "reward": 83.271043,
    "length": 77,
    "time": 151742.690499,
    "actor_loss": -64.99022674560547,
    "critic_loss": 34.815162658691406,
    "ent_coef": 0.10428892821073532,
    "learning_rate": 0.001
  },
  {
    "episode": 10287,
    "reward": 76.213227,
    "length": 90,
    "time": 151757.353118,
    "actor_loss": -67.67485046386719,
    "critic_loss": 76.8310317993164,
    "ent_coef": 0.10263746976852417,
    "learning_rate": 0.001
  },
  {
    "episode": 10288,
    "reward": 87.074739,
    "length": 69,
    "time": 151770.113384,
    "actor_loss": -67.8980484008789,
    "critic_loss": 5.36845588684082,
    "ent_coef": 0.10486720502376556,
    "learning_rate": 0.001
  },
  {
    "episode": 10289,
    "reward": 81.719658,
    "length": 79,
    "time": 151788.328804,
    "actor_loss": -62.341339111328125,
    "critic_loss": 108.33352661132812,
    "ent_coef": 0.10208425670862198,
    "learning_rate": 0.001
  },
  {
    "episode": 10290,
    "reward": 56.96544,
    "length": 123,
    "time": 151807.749154,
    "actor_loss": -65.32677459716797,
    "critic_loss": 4.408088684082031,
    "ent_coef": 0.09143710136413574,
    "learning_rate": 0.001
  },
  {
    "episode": 10291,
    "reward": 85.865659,
    "length": 72,
    "time": 151821.815367,
    "actor_loss": -66.34384155273438,
    "critic_loss": 59.966407775878906,
    "ent_coef": 0.09537961333990097,
    "learning_rate": 0.001
  },
  {
    "episode": 10292,
    "reward": 75.837683,
    "length": 93,
    "time": 151836.8539,
    "actor_loss": -68.61991119384766,
    "critic_loss": 9.073873519897461,
    "ent_coef": 0.09524592012166977,
    "learning_rate": 0.001
  },
  {
    "episode": 10293,
    "reward": 79.180941,
    "length": 84,
    "time": 151853.066927,
    "actor_loss": -66.61127471923828,
    "critic_loss": 18.294771194458008,
    "ent_coef": 0.09387478232383728,
    "learning_rate": 0.001
  },
  {
    "episode": 10294,
    "reward": 86.923193,
    "length": 70,
    "time": 151865.325479,
    "actor_loss": -64.56234741210938,
    "critic_loss": 7.070476531982422,
    "ent_coef": 0.09492305666208267,
    "learning_rate": 0.001
  },
  {
    "episode": 10295,
    "reward": 87.351252,
    "length": 69,
    "time": 151878.067185,
    "actor_loss": -71.70791625976562,
    "critic_loss": 8.158671379089355,
    "ent_coef": 0.0953667163848877,
    "learning_rate": 0.001
  },
  {
    "episode": 10296,
    "reward": 83.155866,
    "length": 77,
    "time": 151898.815601,
    "actor_loss": -68.48725891113281,
    "critic_loss": 17.710506439208984,
    "ent_coef": 0.09224488586187363,
    "learning_rate": 0.001
  },
  {
    "episode": 10297,
    "reward": 74.536098,
    "length": 94,
    "time": 151915.104319,
    "actor_loss": -63.670013427734375,
    "critic_loss": 14.288045883178711,
    "ent_coef": 0.08906213194131851,
    "learning_rate": 0.001
  },
  {
    "episode": 10298,
    "reward": 87.11309,
    "length": 70,
    "time": 151928.199578,
    "actor_loss": -65.96749877929688,
    "critic_loss": 15.991302490234375,
    "ent_coef": 0.09095239639282227,
    "learning_rate": 0.001
  },
  {
    "episode": 10299,
    "reward": 84.595747,
    "length": 73,
    "time": 151940.671474,
    "actor_loss": -65.41899108886719,
    "critic_loss": 4.866720676422119,
    "ent_coef": 0.09636878222227097,
    "learning_rate": 0.001
  },
  {
    "episode": 10300,
    "reward": 87.074171,
    "length": 68,
    "time": 151954.613044,
    "actor_loss": -62.50932312011719,
    "critic_loss": 27.624784469604492,
    "ent_coef": 0.10283476859331131,
    "learning_rate": 0.001
  },
  {
    "episode": 10301,
    "reward": 83.964176,
    "length": 73,
    "time": 151967.613493,
    "actor_loss": -68.42253112792969,
    "critic_loss": 7.156307697296143,
    "ent_coef": 0.1030004695057869,
    "learning_rate": 0.001
  },
  {
    "episode": 10302,
    "reward": 86.492519,
    "length": 70,
    "time": 151979.692498,
    "actor_loss": -68.47045135498047,
    "critic_loss": 7.590782642364502,
    "ent_coef": 0.09935899823904037,
    "learning_rate": 0.001
  },
  {
    "episode": 10303,
    "reward": 86.844734,
    "length": 70,
    "time": 151993.934174,
    "actor_loss": -69.27237701416016,
    "critic_loss": 26.872844696044922,
    "ent_coef": 0.1008957177400589,
    "learning_rate": 0.001
  },
  {
    "episode": 10304,
    "reward": 86.474038,
    "length": 71,
    "time": 152006.569845,
    "actor_loss": -71.20518493652344,
    "critic_loss": 31.912002563476562,
    "ent_coef": 0.0981670469045639,
    "learning_rate": 0.001
  },
  {
    "episode": 10305,
    "reward": 85.489816,
    "length": 72,
    "time": 152019.073637,
    "actor_loss": -66.17768096923828,
    "critic_loss": 2.0391898155212402,
    "ent_coef": 0.09804872423410416,
    "learning_rate": 0.001
  },
  {
    "episode": 10306,
    "reward": 86.940372,
    "length": 69,
    "time": 152031.33487,
    "actor_loss": -63.143898010253906,
    "critic_loss": 5.551196098327637,
    "ent_coef": 0.09778660535812378,
    "learning_rate": 0.001
  },
  {
    "episode": 10307,
    "reward": 84.157047,
    "length": 75,
    "time": 152045.17293,
    "actor_loss": -70.04623413085938,
    "critic_loss": 18.70511817932129,
    "ent_coef": 0.09953587502241135,
    "learning_rate": 0.001
  },
  {
    "episode": 10308,
    "reward": 83.988426,
    "length": 74,
    "time": 152060.448791,
    "actor_loss": -66.99067687988281,
    "critic_loss": 6.502386569976807,
    "ent_coef": 0.10112930089235306,
    "learning_rate": 0.001
  },
  {
    "episode": 10309,
    "reward": 83.388338,
    "length": 75,
    "time": 152073.379261,
    "actor_loss": -61.617919921875,
    "critic_loss": 19.559459686279297,
    "ent_coef": 0.09692306816577911,
    "learning_rate": 0.001
  },
  {
    "episode": 10310,
    "reward": 85.140016,
    "length": 73,
    "time": 152090.300032,
    "actor_loss": -69.80074310302734,
    "critic_loss": 606.0581665039062,
    "ent_coef": 0.09940008074045181,
    "learning_rate": 0.001
  },
  {
    "episode": 10311,
    "reward": 89.527765,
    "length": 64,
    "time": 152102.575163,
    "actor_loss": -64.87854766845703,
    "critic_loss": 11.105555534362793,
    "ent_coef": 0.11051807552576065,
    "learning_rate": 0.001
  },
  {
    "episode": 10312,
    "reward": 80.4787,
    "length": 83,
    "time": 152117.247193,
    "actor_loss": -71.47174835205078,
    "critic_loss": 28.483787536621094,
    "ent_coef": 0.10703500360250473,
    "learning_rate": 0.001
  },
  {
    "episode": 10313,
    "reward": 85.034423,
    "length": 73,
    "time": 152129.655786,
    "actor_loss": -68.61842346191406,
    "critic_loss": 24.29652214050293,
    "ent_coef": 0.10103306919336319,
    "learning_rate": 0.001
  },
  {
    "episode": 10314,
    "reward": 76.016672,
    "length": 90,
    "time": 152144.360118,
    "actor_loss": -65.96094512939453,
    "critic_loss": 17.364971160888672,
    "ent_coef": 0.09566980600357056,
    "learning_rate": 0.001
  },
  {
    "episode": 10315,
    "reward": 85.955665,
    "length": 69,
    "time": 152158.758322,
    "actor_loss": -59.87957763671875,
    "critic_loss": 6.267719268798828,
    "ent_coef": 0.1000356450676918,
    "learning_rate": 0.001
  },
  {
    "episode": 10316,
    "reward": 87.606638,
    "length": 68,
    "time": 152170.701269,
    "actor_loss": -61.221885681152344,
    "critic_loss": 6.865212440490723,
    "ent_coef": 0.108799047768116,
    "learning_rate": 0.001
  },
  {
    "episode": 10317,
    "reward": 90.570058,
    "length": 63,
    "time": 152181.929177,
    "actor_loss": -64.86167907714844,
    "critic_loss": 17.764171600341797,
    "ent_coef": 0.11494757980108261,
    "learning_rate": 0.001
  },
  {
    "episode": 10318,
    "reward": 89.063147,
    "length": 65,
    "time": 152196.042722,
    "actor_loss": -65.46942901611328,
    "critic_loss": 4.73979377746582,
    "ent_coef": 0.11672932654619217,
    "learning_rate": 0.001
  },
  {
    "episode": 10319,
    "reward": 86.114924,
    "length": 71,
    "time": 152208.087956,
    "actor_loss": -67.43382263183594,
    "critic_loss": 18.176620483398438,
    "ent_coef": 0.11759615689516068,
    "learning_rate": 0.001
  },
  {
    "episode": 10320,
    "reward": 85.845508,
    "length": 72,
    "time": 152220.822114,
    "actor_loss": -68.35289764404297,
    "critic_loss": 14.047550201416016,
    "ent_coef": 0.11427745223045349,
    "learning_rate": 0.001
  },
  {
    "episode": 10321,
    "reward": 82.794717,
    "length": 77,
    "time": 152234.792541,
    "actor_loss": -67.14509582519531,
    "critic_loss": 24.957305908203125,
    "ent_coef": 0.10826040059328079,
    "learning_rate": 0.001
  },
  {
    "episode": 10322,
    "reward": 79.600877,
    "length": 85,
    "time": 152249.673055,
    "actor_loss": -66.40839385986328,
    "critic_loss": 4.270995140075684,
    "ent_coef": 0.10045886039733887,
    "learning_rate": 0.001
  },
  {
    "episode": 10323,
    "reward": 85.847094,
    "length": 71,
    "time": 152262.933447,
    "actor_loss": -71.31909942626953,
    "critic_loss": 3.151026725769043,
    "ent_coef": 0.10039643943309784,
    "learning_rate": 0.001
  },
  {
    "episode": 10324,
    "reward": 68.235758,
    "length": 102,
    "time": 152280.197287,
    "actor_loss": -63.47953796386719,
    "critic_loss": 35.324913024902344,
    "ent_coef": 0.09153468906879425,
    "learning_rate": 0.001
  },
  {
    "episode": 10325,
    "reward": 82.695336,
    "length": 78,
    "time": 152296.082069,
    "actor_loss": -64.3255615234375,
    "critic_loss": 7.564321517944336,
    "ent_coef": 0.08754424005746841,
    "learning_rate": 0.001
  },
  {
    "episode": 10326,
    "reward": 75.496077,
    "length": 89,
    "time": 152312.759053,
    "actor_loss": -69.34782409667969,
    "critic_loss": 9.126922607421875,
    "ent_coef": 0.0798729881644249,
    "learning_rate": 0.001
  },
  {
    "episode": 10327,
    "reward": 83.407143,
    "length": 74,
    "time": 152327.294988,
    "actor_loss": -68.51722717285156,
    "critic_loss": 2.3450541496276855,
    "ent_coef": 0.0796186700463295,
    "learning_rate": 0.001
  },
  {
    "episode": 10328,
    "reward": 89.423909,
    "length": 64,
    "time": 152339.689773,
    "actor_loss": -65.82807159423828,
    "critic_loss": 4.238144874572754,
    "ent_coef": 0.08664338290691376,
    "learning_rate": 0.001
  },
  {
    "episode": 10329,
    "reward": 88.353391,
    "length": 67,
    "time": 152353.515852,
    "actor_loss": -66.3576431274414,
    "critic_loss": 11.761632919311523,
    "ent_coef": 0.08669587224721909,
    "learning_rate": 0.001
  },
  {
    "episode": 10330,
    "reward": 83.900822,
    "length": 73,
    "time": 152367.545561,
    "actor_loss": -59.280792236328125,
    "critic_loss": 21.88302993774414,
    "ent_coef": 0.08757292479276657,
    "learning_rate": 0.001
  },
  {
    "episode": 10331,
    "reward": 85.716255,
    "length": 73,
    "time": 152382.705737,
    "actor_loss": -65.18502807617188,
    "critic_loss": 33.71338653564453,
    "ent_coef": 0.08680778741836548,
    "learning_rate": 0.001
  },
  {
    "episode": 10332,
    "reward": 84.365628,
    "length": 73,
    "time": 152398.603096,
    "actor_loss": -66.85882568359375,
    "critic_loss": 4.230448246002197,
    "ent_coef": 0.08525901287794113,
    "learning_rate": 0.001
  },
  {
    "episode": 10333,
    "reward": 86.834732,
    "length": 71,
    "time": 152413.909611,
    "actor_loss": -60.01134490966797,
    "critic_loss": 5.962917327880859,
    "ent_coef": 0.08455272018909454,
    "learning_rate": 0.001
  },
  {
    "episode": 10334,
    "reward": 84.665156,
    "length": 74,
    "time": 152426.72263,
    "actor_loss": -67.12462615966797,
    "critic_loss": 10.251664161682129,
    "ent_coef": 0.08411236852407455,
    "learning_rate": 0.001
  },
  {
    "episode": 10335,
    "reward": 81.403159,
    "length": 80,
    "time": 152440.108949,
    "actor_loss": -65.64393615722656,
    "critic_loss": 15.262768745422363,
    "ent_coef": 0.07908350974321365,
    "learning_rate": 0.001
  },
  {
    "episode": 10336,
    "reward": 84.943843,
    "length": 72,
    "time": 152452.352305,
    "actor_loss": -62.19780349731445,
    "critic_loss": 14.13540267944336,
    "ent_coef": 0.07768124341964722,
    "learning_rate": 0.001
  },
  {
    "episode": 10337,
    "reward": 88.973663,
    "length": 65,
    "time": 152464.687586,
    "actor_loss": -67.06777954101562,
    "critic_loss": 25.323719024658203,
    "ent_coef": 0.08348707109689713,
    "learning_rate": 0.001
  },
  {
    "episode": 10338,
    "reward": 86.28845,
    "length": 71,
    "time": 152477.173179,
    "actor_loss": -62.162200927734375,
    "critic_loss": 12.75216293334961,
    "ent_coef": 0.08358152955770493,
    "learning_rate": 0.001
  },
  {
    "episode": 10339,
    "reward": 85.607044,
    "length": 71,
    "time": 152490.215276,
    "actor_loss": -66.05036926269531,
    "critic_loss": 7.3001837730407715,
    "ent_coef": 0.08373240381479263,
    "learning_rate": 0.001
  },
  {
    "episode": 10340,
    "reward": 88.072446,
    "length": 68,
    "time": 152506.691899,
    "actor_loss": -63.668392181396484,
    "critic_loss": 5.337277412414551,
    "ent_coef": 0.08908642828464508,
    "learning_rate": 0.001
  },
  {
    "episode": 10341,
    "reward": 84.190232,
    "length": 75,
    "time": 152520.863243,
    "actor_loss": -63.495391845703125,
    "critic_loss": 3.277927875518799,
    "ent_coef": 0.08611548691987991,
    "learning_rate": 0.001
  },
  {
    "episode": 10342,
    "reward": 84.716205,
    "length": 74,
    "time": 152533.455727,
    "actor_loss": -65.1846923828125,
    "critic_loss": 832.2212524414062,
    "ent_coef": 0.08731026202440262,
    "learning_rate": 0.001
  },
  {
    "episode": 10343,
    "reward": 83.830636,
    "length": 75,
    "time": 152547.169899,
    "actor_loss": -61.6135368347168,
    "critic_loss": 3.757634162902832,
    "ent_coef": 0.08820589631795883,
    "learning_rate": 0.001
  },
  {
    "episode": 10344,
    "reward": 85.148202,
    "length": 72,
    "time": 152559.756822,
    "actor_loss": -59.92587661743164,
    "critic_loss": 5.323447227478027,
    "ent_coef": 0.09250394999980927,
    "learning_rate": 0.001
  },
  {
    "episode": 10345,
    "reward": 84.634748,
    "length": 73,
    "time": 152574.439926,
    "actor_loss": -59.51434326171875,
    "critic_loss": 29.906787872314453,
    "ent_coef": 0.09581375122070312,
    "learning_rate": 0.001
  },
  {
    "episode": 10346,
    "reward": 86.862217,
    "length": 69,
    "time": 152589.240857,
    "actor_loss": -68.800048828125,
    "critic_loss": 7.729531288146973,
    "ent_coef": 0.09424428641796112,
    "learning_rate": 0.001
  },
  {
    "episode": 10347,
    "reward": 78.768403,
    "length": 86,
    "time": 152605.024166,
    "actor_loss": -66.92376708984375,
    "critic_loss": 5.421503067016602,
    "ent_coef": 0.08737191557884216,
    "learning_rate": 0.001
  },
  {
    "episode": 10348,
    "reward": 48.178852,
    "length": 137,
    "time": 152626.519668,
    "actor_loss": -60.80218505859375,
    "critic_loss": 21.3887939453125,
    "ent_coef": 0.07973907887935638,
    "learning_rate": 0.001
  },
  {
    "episode": 10349,
    "reward": 80.163583,
    "length": 80,
    "time": 152639.986935,
    "actor_loss": -64.32120513916016,
    "critic_loss": 20.009817123413086,
    "ent_coef": 0.07984549552202225,
    "learning_rate": 0.001
  },
  {
    "episode": 10350,
    "reward": 86.314462,
    "length": 70,
    "time": 152652.241064,
    "actor_loss": -63.25658416748047,
    "critic_loss": 16.49706268310547,
    "ent_coef": 0.08235015720129013,
    "learning_rate": 0.001
  },
  {
    "episode": 10351,
    "reward": 80.848735,
    "length": 79,
    "time": 152667.284791,
    "actor_loss": -64.88270568847656,
    "critic_loss": 3.2719240188598633,
    "ent_coef": 0.08044416457414627,
    "learning_rate": 0.001
  },
  {
    "episode": 10352,
    "reward": 85.418783,
    "length": 71,
    "time": 152679.525479,
    "actor_loss": -56.612064361572266,
    "critic_loss": 12.623537063598633,
    "ent_coef": 0.0827094316482544,
    "learning_rate": 0.001
  },
  {
    "episode": 10353,
    "reward": 86.482881,
    "length": 69,
    "time": 152691.506378,
    "actor_loss": -68.73974609375,
    "critic_loss": 87.66976928710938,
    "ent_coef": 0.08676280081272125,
    "learning_rate": 0.001
  },
  {
    "episode": 10354,
    "reward": 80.790272,
    "length": 81,
    "time": 152705.800222,
    "actor_loss": -63.342445373535156,
    "critic_loss": 8.37390422821045,
    "ent_coef": 0.08657080680131912,
    "learning_rate": 0.001
  },
  {
    "episode": 10355,
    "reward": 82.710547,
    "length": 76,
    "time": 152719.696198,
    "actor_loss": -67.16642761230469,
    "critic_loss": 5.715909481048584,
    "ent_coef": 0.08446892350912094,
    "learning_rate": 0.001
  },
  {
    "episode": 10356,
    "reward": 82.625032,
    "length": 77,
    "time": 152734.605378,
    "actor_loss": -64.56429290771484,
    "critic_loss": 11.794240951538086,
    "ent_coef": 0.08673899620771408,
    "learning_rate": 0.001
  },
  {
    "episode": 10357,
    "reward": 73.801214,
    "length": 93,
    "time": 152749.603024,
    "actor_loss": -66.64241027832031,
    "critic_loss": 28.107013702392578,
    "ent_coef": 0.0868462473154068,
    "learning_rate": 0.001
  },
  {
    "episode": 10358,
    "reward": 56.194649,
    "length": 129,
    "time": 152769.164605,
    "actor_loss": -61.29713439941406,
    "critic_loss": 4.754444122314453,
    "ent_coef": 0.08443358540534973,
    "learning_rate": 0.001
  },
  {
    "episode": 10359,
    "reward": 77.077226,
    "length": 89,
    "time": 152784.125805,
    "actor_loss": -61.15508270263672,
    "critic_loss": 22.494014739990234,
    "ent_coef": 0.0861501544713974,
    "learning_rate": 0.001
  },
  {
    "episode": 10360,
    "reward": 74.903821,
    "length": 91,
    "time": 152800.606452,
    "actor_loss": -66.73541259765625,
    "critic_loss": 86.10423278808594,
    "ent_coef": 0.08589454740285873,
    "learning_rate": 0.001
  },
  {
    "episode": 10361,
    "reward": 81.060365,
    "length": 80,
    "time": 152814.316919,
    "actor_loss": -68.53416442871094,
    "critic_loss": 106.83474731445312,
    "ent_coef": 0.09216699749231339,
    "learning_rate": 0.001
  },
  {
    "episode": 10362,
    "reward": 79.886772,
    "length": 81,
    "time": 152832.359879,
    "actor_loss": -67.28199768066406,
    "critic_loss": 6.761251926422119,
    "ent_coef": 0.09345059096813202,
    "learning_rate": 0.001
  },
  {
    "episode": 10363,
    "reward": 84.360224,
    "length": 66,
    "time": 152844.230767,
    "actor_loss": -59.926185607910156,
    "critic_loss": 3.1122169494628906,
    "ent_coef": 0.09750596433877945,
    "learning_rate": 0.001
  },
  {
    "episode": 10364,
    "reward": 78.619514,
    "length": 86,
    "time": 152858.187252,
    "actor_loss": -59.845008850097656,
    "critic_loss": 5.352819442749023,
    "ent_coef": 0.09631907939910889,
    "learning_rate": 0.001
  },
  {
    "episode": 10365,
    "reward": 85.405097,
    "length": 73,
    "time": 152873.401472,
    "actor_loss": -56.58436584472656,
    "critic_loss": 28.986507415771484,
    "ent_coef": 0.0946444422006607,
    "learning_rate": 0.001
  },
  {
    "episode": 10366,
    "reward": 76.880256,
    "length": 81,
    "time": 152887.519918,
    "actor_loss": -65.73822021484375,
    "critic_loss": 15.351616859436035,
    "ent_coef": 0.0920732393860817,
    "learning_rate": 0.001
  },
  {
    "episode": 10367,
    "reward": 92.264461,
    "length": 60,
    "time": 152901.675193,
    "actor_loss": -63.26990509033203,
    "critic_loss": 33.73754119873047,
    "ent_coef": 0.09343019872903824,
    "learning_rate": 0.001
  },
  {
    "episode": 10368,
    "reward": 87.263134,
    "length": 69,
    "time": 152916.309733,
    "actor_loss": -62.834564208984375,
    "critic_loss": 31.717205047607422,
    "ent_coef": 0.09467946738004684,
    "learning_rate": 0.001
  },
  {
    "episode": 10369,
    "reward": 81.953148,
    "length": 79,
    "time": 152932.622871,
    "actor_loss": -68.43610382080078,
    "critic_loss": 4.409759521484375,
    "ent_coef": 0.09233710914850235,
    "learning_rate": 0.001
  },
  {
    "episode": 10370,
    "reward": 85.845362,
    "length": 71,
    "time": 152944.965809,
    "actor_loss": -60.39945602416992,
    "critic_loss": 117.3782958984375,
    "ent_coef": 0.0920650064945221,
    "learning_rate": 0.001
  },
  {
    "episode": 10371,
    "reward": 84.977002,
    "length": 72,
    "time": 152960.119095,
    "actor_loss": -66.4016342163086,
    "critic_loss": 21.181503295898438,
    "ent_coef": 0.09403122961521149,
    "learning_rate": 0.001
  },
  {
    "episode": 10372,
    "reward": 78.76598,
    "length": 84,
    "time": 152976.58401,
    "actor_loss": -60.88898468017578,
    "critic_loss": 18.08557891845703,
    "ent_coef": 0.09318697452545166,
    "learning_rate": 0.001
  },
  {
    "episode": 10373,
    "reward": 80.316935,
    "length": 79,
    "time": 152990.937818,
    "actor_loss": -65.04833221435547,
    "critic_loss": 49.694740295410156,
    "ent_coef": 0.09401138126850128,
    "learning_rate": 0.001
  },
  {
    "episode": 10374,
    "reward": 82.715278,
    "length": 75,
    "time": 153004.734484,
    "actor_loss": -68.78166961669922,
    "critic_loss": 70.90926361083984,
    "ent_coef": 0.09573492407798767,
    "learning_rate": 0.001
  },
  {
    "episode": 10375,
    "reward": 74.921646,
    "length": 92,
    "time": 153019.964557,
    "actor_loss": -58.05380630493164,
    "critic_loss": 3.1123971939086914,
    "ent_coef": 0.09262187033891678,
    "learning_rate": 0.001
  },
  {
    "episode": 10376,
    "reward": 75.723586,
    "length": 90,
    "time": 153036.151187,
    "actor_loss": -69.25931549072266,
    "critic_loss": 6.04839563369751,
    "ent_coef": 0.08928896486759186,
    "learning_rate": 0.001
  },
  {
    "episode": 10377,
    "reward": 88.648867,
    "length": 65,
    "time": 153050.68893,
    "actor_loss": -66.22380828857422,
    "critic_loss": 34.271385192871094,
    "ent_coef": 0.09754860401153564,
    "learning_rate": 0.001
  },
  {
    "episode": 10378,
    "reward": 86.916398,
    "length": 68,
    "time": 153064.76245,
    "actor_loss": -57.677001953125,
    "critic_loss": 3.3814783096313477,
    "ent_coef": 0.09816308319568634,
    "learning_rate": 0.001
  },
  {
    "episode": 10379,
    "reward": 86.787853,
    "length": 68,
    "time": 153076.837488,
    "actor_loss": -66.92863464355469,
    "critic_loss": 9.149190902709961,
    "ent_coef": 0.0955190435051918,
    "learning_rate": 0.001
  },
  {
    "episode": 10380,
    "reward": 85.168872,
    "length": 71,
    "time": 153089.051108,
    "actor_loss": -61.53715515136719,
    "critic_loss": 10.990979194641113,
    "ent_coef": 0.09527942538261414,
    "learning_rate": 0.001
  },
  {
    "episode": 10381,
    "reward": 80.392076,
    "length": 79,
    "time": 153105.347761,
    "actor_loss": -61.93806457519531,
    "critic_loss": 21.522274017333984,
    "ent_coef": 0.09732630848884583,
    "learning_rate": 0.001
  },
  {
    "episode": 10382,
    "reward": 86.220323,
    "length": 69,
    "time": 153117.310119,
    "actor_loss": -67.20404052734375,
    "critic_loss": 51.17483901977539,
    "ent_coef": 0.09791437536478043,
    "learning_rate": 0.001
  },
  {
    "episode": 10383,
    "reward": 87.601708,
    "length": 68,
    "time": 153133.605847,
    "actor_loss": -65.62980651855469,
    "critic_loss": 29.12908172607422,
    "ent_coef": 0.09833579510450363,
    "learning_rate": 0.001
  },
  {
    "episode": 10384,
    "reward": 87.88798,
    "length": 67,
    "time": 153145.723031,
    "actor_loss": -63.16474914550781,
    "critic_loss": 6.787088871002197,
    "ent_coef": 0.0977839007973671,
    "learning_rate": 0.001
  },
  {
    "episode": 10385,
    "reward": 88.467193,
    "length": 68,
    "time": 153157.731961,
    "actor_loss": -63.54997634887695,
    "critic_loss": 897.8682250976562,
    "ent_coef": 0.09467678517103195,
    "learning_rate": 0.001
  },
  {
    "episode": 10386,
    "reward": 83.211291,
    "length": 77,
    "time": 153173.822463,
    "actor_loss": -62.479549407958984,
    "critic_loss": 7.664579391479492,
    "ent_coef": 0.0902167409658432,
    "learning_rate": 0.001
  },
  {
    "episode": 10387,
    "reward": 87.555254,
    "length": 68,
    "time": 153185.720775,
    "actor_loss": -60.048072814941406,
    "critic_loss": 115.74921417236328,
    "ent_coef": 0.09060783684253693,
    "learning_rate": 0.001
  },
  {
    "episode": 10388,
    "reward": 88.144148,
    "length": 69,
    "time": 153197.796187,
    "actor_loss": -63.24187469482422,
    "critic_loss": 6.721343040466309,
    "ent_coef": 0.08908314257860184,
    "learning_rate": 0.001
  },
  {
    "episode": 10389,
    "reward": 86.343151,
    "length": 71,
    "time": 153211.446028,
    "actor_loss": -64.4969482421875,
    "critic_loss": 58.609588623046875,
    "ent_coef": 0.08822570741176605,
    "learning_rate": 0.001
  },
  {
    "episode": 10390,
    "reward": 89.603232,
    "length": 64,
    "time": 153222.950674,
    "actor_loss": -65.11187744140625,
    "critic_loss": 81.95904541015625,
    "ent_coef": 0.09365371614694595,
    "learning_rate": 0.001
  },
  {
    "episode": 10391,
    "reward": 83.135425,
    "length": 75,
    "time": 153236.043307,
    "actor_loss": -64.99319458007812,
    "critic_loss": 3.9167089462280273,
    "ent_coef": 0.09571579843759537,
    "learning_rate": 0.001
  },
  {
    "episode": 10392,
    "reward": 89.52986,
    "length": 64,
    "time": 153250.283385,
    "actor_loss": -61.65182113647461,
    "critic_loss": 20.537200927734375,
    "ent_coef": 0.09781195968389511,
    "learning_rate": 0.001
  },
  {
    "episode": 10393,
    "reward": 81.084298,
    "length": 79,
    "time": 153265.846283,
    "actor_loss": -64.91072082519531,
    "critic_loss": 21.570274353027344,
    "ent_coef": 0.09563934057950974,
    "learning_rate": 0.001
  },
  {
    "episode": 10394,
    "reward": 84.209417,
    "length": 73,
    "time": 153279.472143,
    "actor_loss": -63.46875762939453,
    "critic_loss": 14.924144744873047,
    "ent_coef": 0.09549779444932938,
    "learning_rate": 0.001
  },
  {
    "episode": 10395,
    "reward": 74.816342,
    "length": 92,
    "time": 153295.514876,
    "actor_loss": -59.49114227294922,
    "critic_loss": 28.388500213623047,
    "ent_coef": 0.09083843231201172,
    "learning_rate": 0.001
  },
  {
    "episode": 10396,
    "reward": 84.998381,
    "length": 72,
    "time": 153311.100322,
    "actor_loss": -62.951499938964844,
    "critic_loss": 10.955894470214844,
    "ent_coef": 0.09020467847585678,
    "learning_rate": 0.001
  },
  {
    "episode": 10397,
    "reward": 81.791225,
    "length": 79,
    "time": 153324.541556,
    "actor_loss": -61.78255844116211,
    "critic_loss": 28.114883422851562,
    "ent_coef": 0.09640457481145859,
    "learning_rate": 0.001
  },
  {
    "episode": 10398,
    "reward": 86.579108,
    "length": 71,
    "time": 153337.623308,
    "actor_loss": -62.901241302490234,
    "critic_loss": 35.64692306518555,
    "ent_coef": 0.10282616317272186,
    "learning_rate": 0.001
  },
  {
    "episode": 10399,
    "reward": 75.618133,
    "length": 83,
    "time": 153353.372868,
    "actor_loss": -57.70840835571289,
    "critic_loss": 6.818581581115723,
    "ent_coef": 0.10646659880876541,
    "learning_rate": 0.001
  },
  {
    "episode": 10400,
    "reward": 77.239907,
    "length": 75,
    "time": 153368.726458,
    "actor_loss": -67.70346069335938,
    "critic_loss": 17.357412338256836,
    "ent_coef": 0.10196375846862793,
    "learning_rate": 0.001
  },
  {
    "episode": 10401,
    "reward": 87.638123,
    "length": 70,
    "time": 153382.648366,
    "actor_loss": -63.94982147216797,
    "critic_loss": 3.9175262451171875,
    "ent_coef": 0.10325224697589874,
    "learning_rate": 0.001
  },
  {
    "episode": 10402,
    "reward": 86.913937,
    "length": 68,
    "time": 153395.701059,
    "actor_loss": -69.6487808227539,
    "critic_loss": 2.981144428253174,
    "ent_coef": 0.10244179517030716,
    "learning_rate": 0.001
  },
  {
    "episode": 10403,
    "reward": 82.276559,
    "length": 75,
    "time": 153409.4311,
    "actor_loss": -60.27392578125,
    "critic_loss": 10.018810272216797,
    "ent_coef": 0.10192936658859253,
    "learning_rate": 0.001
  },
  {
    "episode": 10404,
    "reward": 49.880179,
    "length": 124,
    "time": 153428.509528,
    "actor_loss": -69.9036865234375,
    "critic_loss": 4.2688307762146,
    "ent_coef": 0.09649491310119629,
    "learning_rate": 0.001
  },
  {
    "episode": 10405,
    "reward": 76.423458,
    "length": 83,
    "time": 153442.764156,
    "actor_loss": -58.019691467285156,
    "critic_loss": 25.327363967895508,
    "ent_coef": 0.088954858481884,
    "learning_rate": 0.001
  },
  {
    "episode": 10406,
    "reward": 75.614598,
    "length": 81,
    "time": 153457.041251,
    "actor_loss": -58.417091369628906,
    "critic_loss": 4.956118583679199,
    "ent_coef": 0.09387057274580002,
    "learning_rate": 0.001
  },
  {
    "episode": 10407,
    "reward": 73.93669,
    "length": 96,
    "time": 153474.5275,
    "actor_loss": -65.94517517089844,
    "critic_loss": 7.680871486663818,
    "ent_coef": 0.08623135089874268,
    "learning_rate": 0.001
  },
  {
    "episode": 10408,
    "reward": 81.226741,
    "length": 78,
    "time": 153490.395605,
    "actor_loss": -66.80497741699219,
    "critic_loss": 5.666762351989746,
    "ent_coef": 0.08386574685573578,
    "learning_rate": 0.001
  },
  {
    "episode": 10409,
    "reward": 86.293324,
    "length": 70,
    "time": 153503.380864,
    "actor_loss": -61.04427719116211,
    "critic_loss": 3.1057581901550293,
    "ent_coef": 0.08173270523548126,
    "learning_rate": 0.001
  },
  {
    "episode": 10410,
    "reward": 90.358727,
    "length": 61,
    "time": 153514.357236,
    "actor_loss": -71.89319610595703,
    "critic_loss": 26.208459854125977,
    "ent_coef": 0.0885249674320221,
    "learning_rate": 0.001
  },
  {
    "episode": 10411,
    "reward": 88.905875,
    "length": 65,
    "time": 153526.194237,
    "actor_loss": -60.941993713378906,
    "critic_loss": 4.686720848083496,
    "ent_coef": 0.0913970023393631,
    "learning_rate": 0.001
  },
  {
    "episode": 10412,
    "reward": 84.793654,
    "length": 72,
    "time": 153542.250877,
    "actor_loss": -62.48615264892578,
    "critic_loss": 5.753487586975098,
    "ent_coef": 0.08916299045085907,
    "learning_rate": 0.001
  },
  {
    "episode": 10413,
    "reward": 75.921257,
    "length": 85,
    "time": 153558.234164,
    "actor_loss": -64.21961975097656,
    "critic_loss": 57.94656753540039,
    "ent_coef": 0.08457963168621063,
    "learning_rate": 0.001
  },
  {
    "episode": 10414,
    "reward": 81.717844,
    "length": 76,
    "time": 153572.711194,
    "actor_loss": -63.6699104309082,
    "critic_loss": 27.35034942626953,
    "ent_coef": 0.07803498953580856,
    "learning_rate": 0.001
  },
  {
    "episode": 10415,
    "reward": 72.064428,
    "length": 83,
    "time": 153586.589112,
    "actor_loss": -61.277137756347656,
    "critic_loss": 5.942341327667236,
    "ent_coef": 0.0758892148733139,
    "learning_rate": 0.001
  },
  {
    "episode": 10416,
    "reward": 88.34683,
    "length": 65,
    "time": 153599.4109,
    "actor_loss": -60.543540954589844,
    "critic_loss": 7.262125015258789,
    "ent_coef": 0.07934045791625977,
    "learning_rate": 0.001
  },
  {
    "episode": 10417,
    "reward": 88.887733,
    "length": 65,
    "time": 153611.56174,
    "actor_loss": -66.364990234375,
    "critic_loss": 24.12944221496582,
    "ent_coef": 0.08568713814020157,
    "learning_rate": 0.001
  },
  {
    "episode": 10418,
    "reward": 88.741298,
    "length": 65,
    "time": 153625.516448,
    "actor_loss": -55.977325439453125,
    "critic_loss": 5.504367828369141,
    "ent_coef": 0.0858149603009224,
    "learning_rate": 0.001
  },
  {
    "episode": 10419,
    "reward": 86.781835,
    "length": 67,
    "time": 153637.722264,
    "actor_loss": -67.48668670654297,
    "critic_loss": 13.570136070251465,
    "ent_coef": 0.0836951732635498,
    "learning_rate": 0.001
  },
  {
    "episode": 10420,
    "reward": 78.414593,
    "length": 74,
    "time": 153652.19263,
    "actor_loss": -61.31553649902344,
    "critic_loss": 60.48603820800781,
    "ent_coef": 0.08460633456707001,
    "learning_rate": 0.001
  },
  {
    "episode": 10421,
    "reward": 86.993702,
    "length": 68,
    "time": 153665.433148,
    "actor_loss": -59.15797805786133,
    "critic_loss": 9.480756759643555,
    "ent_coef": 0.08437948673963547,
    "learning_rate": 0.001
  },
  {
    "episode": 10422,
    "reward": 84.818986,
    "length": 71,
    "time": 153677.668937,
    "actor_loss": -67.41293334960938,
    "critic_loss": 60.899322509765625,
    "ent_coef": 0.08218216896057129,
    "learning_rate": 0.001
  },
  {
    "episode": 10423,
    "reward": 85.789264,
    "length": 72,
    "time": 153690.10008,
    "actor_loss": -59.47225570678711,
    "critic_loss": 16.328346252441406,
    "ent_coef": 0.08250337094068527,
    "learning_rate": 0.001
  },
  {
    "episode": 10424,
    "reward": 85.21812,
    "length": 70,
    "time": 153702.289896,
    "actor_loss": -55.7118034362793,
    "critic_loss": 7.877965450286865,
    "ent_coef": 0.08260494470596313,
    "learning_rate": 0.001
  },
  {
    "episode": 10425,
    "reward": 88.18021,
    "length": 66,
    "time": 153713.979066,
    "actor_loss": -60.541404724121094,
    "critic_loss": 3.243835926055908,
    "ent_coef": 0.0846802368760109,
    "learning_rate": 0.001
  },
  {
    "episode": 10426,
    "reward": 86.369249,
    "length": 70,
    "time": 153726.171052,
    "actor_loss": -63.98548889160156,
    "critic_loss": 2.5129172801971436,
    "ent_coef": 0.08240913599729538,
    "learning_rate": 0.001
  },
  {
    "episode": 10427,
    "reward": 85.493637,
    "length": 71,
    "time": 153738.394056,
    "actor_loss": -63.490684509277344,
    "critic_loss": 9.438480377197266,
    "ent_coef": 0.08001641929149628,
    "learning_rate": 0.001
  },
  {
    "episode": 10428,
    "reward": 88.431659,
    "length": 65,
    "time": 153750.836077,
    "actor_loss": -62.12736129760742,
    "critic_loss": 4.674266338348389,
    "ent_coef": 0.08123317360877991,
    "learning_rate": 0.001
  },
  {
    "episode": 10429,
    "reward": 81.013782,
    "length": 78,
    "time": 153764.898709,
    "actor_loss": -66.85458374023438,
    "critic_loss": 3.6578149795532227,
    "ent_coef": 0.07755651324987411,
    "learning_rate": 0.001
  },
  {
    "episode": 10430,
    "reward": 88.898859,
    "length": 65,
    "time": 153777.399057,
    "actor_loss": -58.4173583984375,
    "critic_loss": 40.97693634033203,
    "ent_coef": 0.07819131761789322,
    "learning_rate": 0.001
  },
  {
    "episode": 10431,
    "reward": 89.694788,
    "length": 64,
    "time": 153789.458554,
    "actor_loss": -61.370452880859375,
    "critic_loss": 35.217063903808594,
    "ent_coef": 0.08195330947637558,
    "learning_rate": 0.001
  },
  {
    "episode": 10432,
    "reward": 88.594209,
    "length": 70,
    "time": 153804.979307,
    "actor_loss": -59.76914978027344,
    "critic_loss": 16.40283203125,
    "ent_coef": 0.09333925694227219,
    "learning_rate": 0.001
  },
  {
    "episode": 10433,
    "reward": 85.378112,
    "length": 71,
    "time": 153818.07048,
    "actor_loss": -65.96951293945312,
    "critic_loss": 4.618215560913086,
    "ent_coef": 0.08941078186035156,
    "learning_rate": 0.001
  },
  {
    "episode": 10434,
    "reward": 84.553036,
    "length": 74,
    "time": 153831.914384,
    "actor_loss": -63.178466796875,
    "critic_loss": 24.727245330810547,
    "ent_coef": 0.08549191802740097,
    "learning_rate": 0.001
  },
  {
    "episode": 10435,
    "reward": 87.087176,
    "length": 68,
    "time": 153847.608401,
    "actor_loss": -65.47992706298828,
    "critic_loss": 12.3365478515625,
    "ent_coef": 0.0857529491186142,
    "learning_rate": 0.001
  },
  {
    "episode": 10436,
    "reward": 88.310947,
    "length": 67,
    "time": 153859.2588,
    "actor_loss": -67.44830322265625,
    "critic_loss": 7.21573543548584,
    "ent_coef": 0.08639593422412872,
    "learning_rate": 0.001
  },
  {
    "episode": 10437,
    "reward": 89.779283,
    "length": 62,
    "time": 153872.25002,
    "actor_loss": -64.4988784790039,
    "critic_loss": 52.38343811035156,
    "ent_coef": 0.08656483888626099,
    "learning_rate": 0.001
  },
  {
    "episode": 10438,
    "reward": 88.00977,
    "length": 66,
    "time": 153883.785399,
    "actor_loss": -63.08022689819336,
    "critic_loss": 6.7090044021606445,
    "ent_coef": 0.08546402305364609,
    "learning_rate": 0.001
  },
  {
    "episode": 10439,
    "reward": 89.912982,
    "length": 62,
    "time": 153895.970617,
    "actor_loss": -63.4174919128418,
    "critic_loss": 11.024459838867188,
    "ent_coef": 0.09469542652368546,
    "learning_rate": 0.001
  },
  {
    "episode": 10440,
    "reward": 86.903402,
    "length": 68,
    "time": 153910.727695,
    "actor_loss": -64.27362823486328,
    "critic_loss": 14.492185592651367,
    "ent_coef": 0.09737728536128998,
    "learning_rate": 0.001
  },
  {
    "episode": 10441,
    "reward": 84.146415,
    "length": 77,
    "time": 153927.09747,
    "actor_loss": -65.98359680175781,
    "critic_loss": 14.459077835083008,
    "ent_coef": 0.0959598571062088,
    "learning_rate": 0.001
  },
  {
    "episode": 10442,
    "reward": 88.125308,
    "length": 67,
    "time": 153939.910305,
    "actor_loss": -63.518959045410156,
    "critic_loss": 3.8237955570220947,
    "ent_coef": 0.09152851998806,
    "learning_rate": 0.001
  },
  {
    "episode": 10443,
    "reward": 87.733955,
    "length": 67,
    "time": 153952.727359,
    "actor_loss": -58.717063903808594,
    "critic_loss": 19.26831817626953,
    "ent_coef": 0.08788742870092392,
    "learning_rate": 0.001
  },
  {
    "episode": 10444,
    "reward": 88.160842,
    "length": 68,
    "time": 153964.630103,
    "actor_loss": -55.298702239990234,
    "critic_loss": 14.145482063293457,
    "ent_coef": 0.0877825915813446,
    "learning_rate": 0.001
  },
  {
    "episode": 10445,
    "reward": 86.735606,
    "length": 69,
    "time": 153978.068051,
    "actor_loss": -66.123291015625,
    "critic_loss": 10.043359756469727,
    "ent_coef": 0.08286694437265396,
    "learning_rate": 0.001
  },
  {
    "episode": 10446,
    "reward": 79.545445,
    "length": 77,
    "time": 153992.233413,
    "actor_loss": -66.11775970458984,
    "critic_loss": 13.31857967376709,
    "ent_coef": 0.07974638044834137,
    "learning_rate": 0.001
  },
  {
    "episode": 10447,
    "reward": 84.36371,
    "length": 72,
    "time": 154005.531803,
    "actor_loss": -65.55651092529297,
    "critic_loss": 137.88731384277344,
    "ent_coef": 0.07549631595611572,
    "learning_rate": 0.001
  },
  {
    "episode": 10448,
    "reward": 88.987521,
    "length": 65,
    "time": 154017.048699,
    "actor_loss": -66.61801147460938,
    "critic_loss": 2.0237042903900146,
    "ent_coef": 0.07855979353189468,
    "learning_rate": 0.001
  },
  {
    "episode": 10449,
    "reward": 88.662753,
    "length": 65,
    "time": 154029.553421,
    "actor_loss": -66.1063232421875,
    "critic_loss": 3.9372923374176025,
    "ent_coef": 0.07998981326818466,
    "learning_rate": 0.001
  },
  {
    "episode": 10450,
    "reward": 88.619955,
    "length": 65,
    "time": 154042.413514,
    "actor_loss": -61.81511688232422,
    "critic_loss": 7.831269264221191,
    "ent_coef": 0.0833713710308075,
    "learning_rate": 0.001
  },
  {
    "episode": 10451,
    "reward": 85.849952,
    "length": 69,
    "time": 154058.24039,
    "actor_loss": -61.90795135498047,
    "critic_loss": 31.67515754699707,
    "ent_coef": 0.08151654899120331,
    "learning_rate": 0.001
  },
  {
    "episode": 10452,
    "reward": 88.261905,
    "length": 66,
    "time": 154072.457964,
    "actor_loss": -63.271018981933594,
    "critic_loss": 8.435258865356445,
    "ent_coef": 0.08086679875850677,
    "learning_rate": 0.001
  },
  {
    "episode": 10453,
    "reward": 88.971754,
    "length": 65,
    "time": 154085.794056,
    "actor_loss": -65.11918640136719,
    "critic_loss": 6.14460563659668,
    "ent_coef": 0.08122986555099487,
    "learning_rate": 0.001
  },
  {
    "episode": 10454,
    "reward": 88.057521,
    "length": 68,
    "time": 154097.970695,
    "actor_loss": -68.05376434326172,
    "critic_loss": 17.372194290161133,
    "ent_coef": 0.08174630254507065,
    "learning_rate": 0.001
  },
  {
    "episode": 10455,
    "reward": 87.831652,
    "length": 66,
    "time": 154110.607593,
    "actor_loss": -60.21959686279297,
    "critic_loss": 8.101985931396484,
    "ent_coef": 0.08361783623695374,
    "learning_rate": 0.001
  },
  {
    "episode": 10456,
    "reward": 89.981962,
    "length": 63,
    "time": 154123.178774,
    "actor_loss": -68.34156799316406,
    "critic_loss": 3.297621965408325,
    "ent_coef": 0.08759595453739166,
    "learning_rate": 0.001
  },
  {
    "episode": 10457,
    "reward": 87.358508,
    "length": 68,
    "time": 154135.081266,
    "actor_loss": -56.6199951171875,
    "critic_loss": 10.2388334274292,
    "ent_coef": 0.08905177563428879,
    "learning_rate": 0.001
  },
  {
    "episode": 10458,
    "reward": -153.072658,
    "length": 131,
    "time": 154155.778011,
    "actor_loss": -57.934974670410156,
    "critic_loss": 3.4868979454040527,
    "ent_coef": 0.10664582997560501,
    "learning_rate": 0.001
  },
  {
    "episode": 10459,
    "reward": 90.780907,
    "length": 61,
    "time": 154169.108267,
    "actor_loss": -65.54275512695312,
    "critic_loss": 10.418203353881836,
    "ent_coef": 0.10979421436786652,
    "learning_rate": 0.001
  },
  {
    "episode": 10460,
    "reward": 89.102113,
    "length": 65,
    "time": 154181.87959,
    "actor_loss": -63.801639556884766,
    "critic_loss": 6.114805698394775,
    "ent_coef": 0.11228696256875992,
    "learning_rate": 0.001
  },
  {
    "episode": 10461,
    "reward": 90.064843,
    "length": 62,
    "time": 154193.514021,
    "actor_loss": -62.55168533325195,
    "critic_loss": 96.42273712158203,
    "ent_coef": 0.11086054146289825,
    "learning_rate": 0.001
  },
  {
    "episode": 10462,
    "reward": 85.914664,
    "length": 71,
    "time": 154208.096231,
    "actor_loss": -64.6546859741211,
    "critic_loss": 4.181321620941162,
    "ent_coef": 0.10476979613304138,
    "learning_rate": 0.001
  },
  {
    "episode": 10463,
    "reward": 84.32455,
    "length": 74,
    "time": 154221.813418,
    "actor_loss": -69.0506362915039,
    "critic_loss": 38.66645812988281,
    "ent_coef": 0.10102921724319458,
    "learning_rate": 0.001
  },
  {
    "episode": 10464,
    "reward": 88.509977,
    "length": 67,
    "time": 154233.391274,
    "actor_loss": -60.84300994873047,
    "critic_loss": 15.068216323852539,
    "ent_coef": 0.09902089089155197,
    "learning_rate": 0.001
  },
  {
    "episode": 10465,
    "reward": 87.844888,
    "length": 67,
    "time": 154246.685291,
    "actor_loss": -60.40892791748047,
    "critic_loss": 25.444683074951172,
    "ent_coef": 0.09506143629550934,
    "learning_rate": 0.001
  },
  {
    "episode": 10466,
    "reward": 88.69404,
    "length": 67,
    "time": 154258.596493,
    "actor_loss": -67.29780578613281,
    "critic_loss": 19.642765045166016,
    "ent_coef": 0.09586922824382782,
    "learning_rate": 0.001
  },
  {
    "episode": 10467,
    "reward": 84.674666,
    "length": 73,
    "time": 154271.34944,
    "actor_loss": -65.00751495361328,
    "critic_loss": 17.567331314086914,
    "ent_coef": 0.09281719475984573,
    "learning_rate": 0.001
  },
  {
    "episode": 10468,
    "reward": 87.118335,
    "length": 69,
    "time": 154283.772151,
    "actor_loss": -66.41585540771484,
    "critic_loss": 545.500732421875,
    "ent_coef": 0.0878310352563858,
    "learning_rate": 0.001
  },
  {
    "episode": 10469,
    "reward": 86.657935,
    "length": 70,
    "time": 154296.920155,
    "actor_loss": -52.47386169433594,
    "critic_loss": 20.894245147705078,
    "ent_coef": 0.08444449305534363,
    "learning_rate": 0.001
  },
  {
    "episode": 10470,
    "reward": 85.144258,
    "length": 70,
    "time": 154312.953394,
    "actor_loss": -62.36711502075195,
    "critic_loss": 34.845550537109375,
    "ent_coef": 0.08637231588363647,
    "learning_rate": 0.001
  },
  {
    "episode": 10471,
    "reward": 89.22423,
    "length": 64,
    "time": 154324.467462,
    "actor_loss": -66.05451965332031,
    "critic_loss": 7.102907180786133,
    "ent_coef": 0.09080468118190765,
    "learning_rate": 0.001
  },
  {
    "episode": 10472,
    "reward": 89.403511,
    "length": 64,
    "time": 154336.258643,
    "actor_loss": -65.27703857421875,
    "critic_loss": 50.24340057373047,
    "ent_coef": 0.09268968552350998,
    "learning_rate": 0.001
  },
  {
    "episode": 10473,
    "reward": 88.567602,
    "length": 66,
    "time": 154348.438046,
    "actor_loss": -64.86446380615234,
    "critic_loss": 13.309591293334961,
    "ent_coef": 0.09257206320762634,
    "learning_rate": 0.001
  },
  {
    "episode": 10474,
    "reward": 88.385849,
    "length": 65,
    "time": 154361.708521,
    "actor_loss": -64.48892211914062,
    "critic_loss": 26.618820190429688,
    "ent_coef": 0.09457682073116302,
    "learning_rate": 0.001
  },
  {
    "episode": 10475,
    "reward": 87.127774,
    "length": 69,
    "time": 154375.838763,
    "actor_loss": -62.6185302734375,
    "critic_loss": 5.045307159423828,
    "ent_coef": 0.09063097089529037,
    "learning_rate": 0.001
  },
  {
    "episode": 10476,
    "reward": 86.483359,
    "length": 70,
    "time": 154387.647893,
    "actor_loss": -66.96160125732422,
    "critic_loss": 18.141921997070312,
    "ent_coef": 0.0876486599445343,
    "learning_rate": 0.001
  },
  {
    "episode": 10477,
    "reward": 85.234827,
    "length": 72,
    "time": 154399.907699,
    "actor_loss": -65.72652435302734,
    "critic_loss": 7.122414588928223,
    "ent_coef": 0.08773195743560791,
    "learning_rate": 0.001
  },
  {
    "episode": 10478,
    "reward": 81.520081,
    "length": 84,
    "time": 154413.852209,
    "actor_loss": -64.04116821289062,
    "critic_loss": 95.62713623046875,
    "ent_coef": 0.08107884228229523,
    "learning_rate": 0.001
  },
  {
    "episode": 10479,
    "reward": 86.539084,
    "length": 69,
    "time": 154428.170026,
    "actor_loss": -61.94293212890625,
    "critic_loss": 20.272382736206055,
    "ent_coef": 0.07864879071712494,
    "learning_rate": 0.001
  },
  {
    "episode": 10480,
    "reward": 87.147343,
    "length": 68,
    "time": 154440.035543,
    "actor_loss": -66.13516235351562,
    "critic_loss": 14.251558303833008,
    "ent_coef": 0.07623837888240814,
    "learning_rate": 0.001
  },
  {
    "episode": 10481,
    "reward": 88.672996,
    "length": 65,
    "time": 154451.954801,
    "actor_loss": -59.945526123046875,
    "critic_loss": 18.079090118408203,
    "ent_coef": 0.0796453133225441,
    "learning_rate": 0.001
  },
  {
    "episode": 10482,
    "reward": 88.593541,
    "length": 66,
    "time": 154463.768089,
    "actor_loss": -62.78303527832031,
    "critic_loss": 24.405601501464844,
    "ent_coef": 0.08350996673107147,
    "learning_rate": 0.001
  },
  {
    "episode": 10483,
    "reward": 87.600335,
    "length": 67,
    "time": 154477.529207,
    "actor_loss": -66.26414489746094,
    "critic_loss": 19.16277313232422,
    "ent_coef": 0.08439343422651291,
    "learning_rate": 0.001
  },
  {
    "episode": 10484,
    "reward": 88.145503,
    "length": 67,
    "time": 154491.418601,
    "actor_loss": -60.56306076049805,
    "critic_loss": 4.885478496551514,
    "ent_coef": 0.08481114357709885,
    "learning_rate": 0.001
  },
  {
    "episode": 10485,
    "reward": 88.297447,
    "length": 66,
    "time": 154503.447041,
    "actor_loss": -61.029991149902344,
    "critic_loss": 69.17611694335938,
    "ent_coef": 0.08381222933530807,
    "learning_rate": 0.001
  },
  {
    "episode": 10486,
    "reward": 88.315476,
    "length": 66,
    "time": 154519.411019,
    "actor_loss": -60.97850799560547,
    "critic_loss": 56.943519592285156,
    "ent_coef": 0.08586346358060837,
    "learning_rate": 0.001
  },
  {
    "episode": 10487,
    "reward": 89.008909,
    "length": 64,
    "time": 154531.072903,
    "actor_loss": -68.9271240234375,
    "critic_loss": 10.318304061889648,
    "ent_coef": 0.09288343042135239,
    "learning_rate": 0.001
  },
  {
    "episode": 10488,
    "reward": 89.696134,
    "length": 66,
    "time": 154543.383373,
    "actor_loss": -65.97270965576172,
    "critic_loss": 28.104244232177734,
    "ent_coef": 0.09827980399131775,
    "learning_rate": 0.001
  },
  {
    "episode": 10489,
    "reward": 88.729552,
    "length": 66,
    "time": 154558.499764,
    "actor_loss": -61.77320861816406,
    "critic_loss": 22.478763580322266,
    "ent_coef": 0.10014110058546066,
    "learning_rate": 0.001
  },
  {
    "episode": 10490,
    "reward": 89.264585,
    "length": 64,
    "time": 154569.996736,
    "actor_loss": -65.39410400390625,
    "critic_loss": 15.375672340393066,
    "ent_coef": 0.09979335963726044,
    "learning_rate": 0.001
  },
  {
    "episode": 10491,
    "reward": 87.676681,
    "length": 69,
    "time": 154586.118047,
    "actor_loss": -64.46927642822266,
    "critic_loss": 10.487802505493164,
    "ent_coef": 0.09976471960544586,
    "learning_rate": 0.001
  },
  {
    "episode": 10492,
    "reward": 87.923531,
    "length": 67,
    "time": 154597.919816,
    "actor_loss": -64.99136352539062,
    "critic_loss": 4.8975067138671875,
    "ent_coef": 0.09920946508646011,
    "learning_rate": 0.001
  },
  {
    "episode": 10493,
    "reward": 85.543262,
    "length": 72,
    "time": 154610.563572,
    "actor_loss": -66.52044677734375,
    "critic_loss": 8.627494812011719,
    "ent_coef": 0.09616357833147049,
    "learning_rate": 0.001
  },
  {
    "episode": 10494,
    "reward": 89.734209,
    "length": 62,
    "time": 154621.754818,
    "actor_loss": -62.50318908691406,
    "critic_loss": 5.126486301422119,
    "ent_coef": 0.09904872626066208,
    "learning_rate": 0.001
  },
  {
    "episode": 10495,
    "reward": 86.211303,
    "length": 69,
    "time": 154633.786726,
    "actor_loss": -60.3086051940918,
    "critic_loss": 6.1230268478393555,
    "ent_coef": 0.09446551650762558,
    "learning_rate": 0.001
  },
  {
    "episode": 10496,
    "reward": 82.756447,
    "length": 76,
    "time": 154648.224919,
    "actor_loss": -65.48915100097656,
    "critic_loss": 6.822769641876221,
    "ent_coef": 0.08668902516365051,
    "learning_rate": 0.001
  },
  {
    "episode": 10497,
    "reward": 86.731334,
    "length": 69,
    "time": 154660.65106,
    "actor_loss": -64.15093231201172,
    "critic_loss": 16.286033630371094,
    "ent_coef": 0.08441151678562164,
    "learning_rate": 0.001
  },
  {
    "episode": 10498,
    "reward": 88.537743,
    "length": 66,
    "time": 154673.592541,
    "actor_loss": -62.43961715698242,
    "critic_loss": 6.803229808807373,
    "ent_coef": 0.08197689801454544,
    "learning_rate": 0.001
  },
  {
    "episode": 10499,
    "reward": 85.795374,
    "length": 73,
    "time": 154686.607249,
    "actor_loss": -67.12812042236328,
    "critic_loss": 10.967168807983398,
    "ent_coef": 0.08135652542114258,
    "learning_rate": 0.001
  },
  {
    "episode": 10500,
    "reward": 87.069671,
    "length": 69,
    "time": 154698.694239,
    "actor_loss": -64.79379272460938,
    "critic_loss": 28.485435485839844,
    "ent_coef": 0.0790872797369957,
    "learning_rate": 0.001
  },
  {
    "episode": 10501,
    "reward": 90.109864,
    "length": 63,
    "time": 154710.607331,
    "actor_loss": -67.25714111328125,
    "critic_loss": 5.234410285949707,
    "ent_coef": 0.07915659993886948,
    "learning_rate": 0.001
  },
  {
    "episode": 10502,
    "reward": 87.139864,
    "length": 69,
    "time": 154725.110897,
    "actor_loss": -60.28083419799805,
    "critic_loss": 23.977481842041016,
    "ent_coef": 0.07724941521883011,
    "learning_rate": 0.001
  },
  {
    "episode": 10503,
    "reward": 87.602373,
    "length": 69,
    "time": 154737.083308,
    "actor_loss": -63.336273193359375,
    "critic_loss": 16.389846801757812,
    "ent_coef": 0.07739938795566559,
    "learning_rate": 0.001
  },
  {
    "episode": 10504,
    "reward": 89.663685,
    "length": 64,
    "time": 154750.312801,
    "actor_loss": -66.7384033203125,
    "critic_loss": 56.51315689086914,
    "ent_coef": 0.0826040580868721,
    "learning_rate": 0.001
  },
  {
    "episode": 10505,
    "reward": 89.940445,
    "length": 63,
    "time": 154761.385993,
    "actor_loss": -64.21611022949219,
    "critic_loss": 17.136314392089844,
    "ent_coef": 0.08712446689605713,
    "learning_rate": 0.001
  },
  {
    "episode": 10506,
    "reward": 89.94235,
    "length": 63,
    "time": 154772.593117,
    "actor_loss": -63.105838775634766,
    "critic_loss": 10.954994201660156,
    "ent_coef": 0.09282974153757095,
    "learning_rate": 0.001
  },
  {
    "episode": 10507,
    "reward": 90.185489,
    "length": 62,
    "time": 154785.895056,
    "actor_loss": -64.93864440917969,
    "critic_loss": 14.896018981933594,
    "ent_coef": 0.10382042080163956,
    "learning_rate": 0.001
  },
  {
    "episode": 10508,
    "reward": 90.243447,
    "length": 63,
    "time": 154801.256705,
    "actor_loss": -63.480445861816406,
    "critic_loss": 13.865795135498047,
    "ent_coef": 0.11001214385032654,
    "learning_rate": 0.001
  },
  {
    "episode": 10509,
    "reward": 85.428174,
    "length": 71,
    "time": 154815.576017,
    "actor_loss": -64.94032287597656,
    "critic_loss": 56.29083251953125,
    "ent_coef": 0.11046162247657776,
    "learning_rate": 0.001
  },
  {
    "episode": 10510,
    "reward": 86.093119,
    "length": 71,
    "time": 154828.34668,
    "actor_loss": -66.44730377197266,
    "critic_loss": 4.2059125900268555,
    "ent_coef": 0.10795705765485764,
    "learning_rate": 0.001
  },
  {
    "episode": 10511,
    "reward": 89.213018,
    "length": 64,
    "time": 154840.775153,
    "actor_loss": -66.17100524902344,
    "critic_loss": 22.234424591064453,
    "ent_coef": 0.10701245069503784,
    "learning_rate": 0.001
  },
  {
    "episode": 10512,
    "reward": 87.759365,
    "length": 68,
    "time": 154855.726539,
    "actor_loss": -59.65536880493164,
    "critic_loss": 4.609922885894775,
    "ent_coef": 0.10204493999481201,
    "learning_rate": 0.001
  },
  {
    "episode": 10513,
    "reward": 86.187802,
    "length": 71,
    "time": 154867.945676,
    "actor_loss": -60.90949630737305,
    "critic_loss": 3.7041988372802734,
    "ent_coef": 0.10182642936706543,
    "learning_rate": 0.001
  },
  {
    "episode": 10514,
    "reward": 89.996641,
    "length": 63,
    "time": 154880.627258,
    "actor_loss": -58.81124496459961,
    "critic_loss": 5.247480392456055,
    "ent_coef": 0.10555385798215866,
    "learning_rate": 0.001
  },
  {
    "episode": 10515,
    "reward": 88.365241,
    "length": 66,
    "time": 154892.37303,
    "actor_loss": -59.30820083618164,
    "critic_loss": 18.31281280517578,
    "ent_coef": 0.10593520104885101,
    "learning_rate": 0.001
  },
  {
    "episode": 10516,
    "reward": 89.858175,
    "length": 63,
    "time": 154903.674509,
    "actor_loss": -68.00904083251953,
    "critic_loss": 6.952615737915039,
    "ent_coef": 0.10466385632753372,
    "learning_rate": 0.001
  },
  {
    "episode": 10517,
    "reward": 89.231671,
    "length": 64,
    "time": 154915.121814,
    "actor_loss": -66.6644515991211,
    "critic_loss": 29.508556365966797,
    "ent_coef": 0.10539336502552032,
    "learning_rate": 0.001
  },
  {
    "episode": 10518,
    "reward": 87.785482,
    "length": 68,
    "time": 154929.252146,
    "actor_loss": -62.03270721435547,
    "critic_loss": 5.030051231384277,
    "ent_coef": 0.10265954583883286,
    "learning_rate": 0.001
  },
  {
    "episode": 10519,
    "reward": 87.94878,
    "length": 68,
    "time": 154943.987052,
    "actor_loss": -66.6482925415039,
    "critic_loss": 186.68557739257812,
    "ent_coef": 0.10113899409770966,
    "learning_rate": 0.001
  },
  {
    "episode": 10520,
    "reward": 83.294461,
    "length": 86,
    "time": 154958.337985,
    "actor_loss": -64.45255279541016,
    "critic_loss": 29.79363250732422,
    "ent_coef": 0.10213921219110489,
    "learning_rate": 0.001
  },
  {
    "episode": 10521,
    "reward": 86.292274,
    "length": 70,
    "time": 154970.684884,
    "actor_loss": -60.18402099609375,
    "critic_loss": 2.915167808532715,
    "ent_coef": 0.09753521531820297,
    "learning_rate": 0.001
  },
  {
    "episode": 10522,
    "reward": 88.813528,
    "length": 65,
    "time": 154983.023911,
    "actor_loss": -63.35404968261719,
    "critic_loss": 16.147762298583984,
    "ent_coef": 0.09459090977907181,
    "learning_rate": 0.001
  },
  {
    "episode": 10523,
    "reward": 89.286698,
    "length": 65,
    "time": 154994.84847,
    "actor_loss": -64.83441162109375,
    "critic_loss": 8.244526863098145,
    "ent_coef": 0.09138540923595428,
    "learning_rate": 0.001
  },
  {
    "episode": 10524,
    "reward": 87.248112,
    "length": 68,
    "time": 155006.97878,
    "actor_loss": -64.30465698242188,
    "critic_loss": 6.0159783363342285,
    "ent_coef": 0.0893121138215065,
    "learning_rate": 0.001
  },
  {
    "episode": 10525,
    "reward": 90.461053,
    "length": 61,
    "time": 155018.773637,
    "actor_loss": -61.22300720214844,
    "critic_loss": 39.47309112548828,
    "ent_coef": 0.09617368876934052,
    "learning_rate": 0.001
  },
  {
    "episode": 10526,
    "reward": 88.646066,
    "length": 66,
    "time": 155030.509043,
    "actor_loss": -62.33611297607422,
    "critic_loss": 23.56133270263672,
    "ent_coef": 0.10181523859500885,
    "learning_rate": 0.001
  },
  {
    "episode": 10527,
    "reward": 88.496295,
    "length": 66,
    "time": 155044.579272,
    "actor_loss": -60.824825286865234,
    "critic_loss": 10.149017333984375,
    "ent_coef": 0.10233570635318756,
    "learning_rate": 0.001
  },
  {
    "episode": 10528,
    "reward": 88.897326,
    "length": 65,
    "time": 155056.432523,
    "actor_loss": -69.95997619628906,
    "critic_loss": 11.035245895385742,
    "ent_coef": 0.10722695291042328,
    "learning_rate": 0.001
  },
  {
    "episode": 10529,
    "reward": 82.073947,
    "length": 80,
    "time": 155071.609702,
    "actor_loss": -64.64862823486328,
    "critic_loss": 4.36053466796875,
    "ent_coef": 0.10355708748102188,
    "learning_rate": 0.001
  },
  {
    "episode": 10530,
    "reward": 80.172468,
    "length": 89,
    "time": 155087.873226,
    "actor_loss": -65.45744323730469,
    "critic_loss": 3.798859119415283,
    "ent_coef": 0.10122857242822647,
    "learning_rate": 0.001
  },
  {
    "episode": 10531,
    "reward": 90.634916,
    "length": 61,
    "time": 155099.867644,
    "actor_loss": -61.95054626464844,
    "critic_loss": 4.77188777923584,
    "ent_coef": 0.10457435995340347,
    "learning_rate": 0.001
  },
  {
    "episode": 10532,
    "reward": 89.671795,
    "length": 64,
    "time": 155112.122258,
    "actor_loss": -62.749366760253906,
    "critic_loss": 28.43051528930664,
    "ent_coef": 0.10551752150058746,
    "learning_rate": 0.001
  },
  {
    "episode": 10533,
    "reward": 88.931577,
    "length": 65,
    "time": 155125.503129,
    "actor_loss": -63.224952697753906,
    "critic_loss": 9.905917167663574,
    "ent_coef": 0.10490389168262482,
    "learning_rate": 0.001
  },
  {
    "episode": 10534,
    "reward": 86.987863,
    "length": 68,
    "time": 155139.155494,
    "actor_loss": -63.60026931762695,
    "critic_loss": 81.50593566894531,
    "ent_coef": 0.10510309040546417,
    "learning_rate": 0.001
  },
  {
    "episode": 10535,
    "reward": 85.684271,
    "length": 72,
    "time": 155153.09656,
    "actor_loss": -64.04313659667969,
    "critic_loss": 22.84157371520996,
    "ent_coef": 0.09947473555803299,
    "learning_rate": 0.001
  },
  {
    "episode": 10536,
    "reward": 81.99911,
    "length": 76,
    "time": 155167.463491,
    "actor_loss": -62.13469696044922,
    "critic_loss": 29.689661026000977,
    "ent_coef": 0.09742274880409241,
    "learning_rate": 0.001
  },
  {
    "episode": 10537,
    "reward": 88.675883,
    "length": 65,
    "time": 155179.093574,
    "actor_loss": -65.22200012207031,
    "critic_loss": 7.997533798217773,
    "ent_coef": 0.09368392825126648,
    "learning_rate": 0.001
  },
  {
    "episode": 10538,
    "reward": 88.912799,
    "length": 64,
    "time": 155194.221382,
    "actor_loss": -63.545616149902344,
    "critic_loss": 17.441909790039062,
    "ent_coef": 0.09490121901035309,
    "learning_rate": 0.001
  },
  {
    "episode": 10539,
    "reward": 88.37801,
    "length": 66,
    "time": 155206.448035,
    "actor_loss": -63.713829040527344,
    "critic_loss": 3.86407208442688,
    "ent_coef": 0.09542153030633926,
    "learning_rate": 0.001
  },
  {
    "episode": 10540,
    "reward": 86.826885,
    "length": 68,
    "time": 155218.416799,
    "actor_loss": -62.5754280090332,
    "critic_loss": 4.947126865386963,
    "ent_coef": 0.09468366950750351,
    "learning_rate": 0.001
  },
  {
    "episode": 10541,
    "reward": 86.697672,
    "length": 69,
    "time": 155230.996892,
    "actor_loss": -63.083953857421875,
    "critic_loss": 7.590337753295898,
    "ent_coef": 0.09527026861906052,
    "learning_rate": 0.001
  },
  {
    "episode": 10542,
    "reward": 84.224023,
    "length": 75,
    "time": 155243.681629,
    "actor_loss": -66.64532470703125,
    "critic_loss": 18.5567626953125,
    "ent_coef": 0.09326115250587463,
    "learning_rate": 0.001
  },
  {
    "episode": 10543,
    "reward": 85.440159,
    "length": 71,
    "time": 155258.166793,
    "actor_loss": -71.41133117675781,
    "critic_loss": 8.861394882202148,
    "ent_coef": 0.09112326055765152,
    "learning_rate": 0.001
  },
  {
    "episode": 10544,
    "reward": 83.600706,
    "length": 74,
    "time": 155270.841507,
    "actor_loss": -64.0789566040039,
    "critic_loss": 9.878105163574219,
    "ent_coef": 0.0899866595864296,
    "learning_rate": 0.001
  },
  {
    "episode": 10545,
    "reward": 87.207568,
    "length": 70,
    "time": 155283.38297,
    "actor_loss": -56.8856201171875,
    "critic_loss": 6.143243789672852,
    "ent_coef": 0.08796410262584686,
    "learning_rate": 0.001
  },
  {
    "episode": 10546,
    "reward": 89.095615,
    "length": 64,
    "time": 155299.413375,
    "actor_loss": -59.129478454589844,
    "critic_loss": 5.0251617431640625,
    "ent_coef": 0.08884511142969131,
    "learning_rate": 0.001
  },
  {
    "episode": 10547,
    "reward": 88.904536,
    "length": 65,
    "time": 155312.995623,
    "actor_loss": -63.70464324951172,
    "critic_loss": 13.323173522949219,
    "ent_coef": 0.08857341855764389,
    "learning_rate": 0.001
  },
  {
    "episode": 10548,
    "reward": 88.949739,
    "length": 65,
    "time": 155325.714625,
    "actor_loss": -54.95457458496094,
    "critic_loss": 62.02867126464844,
    "ent_coef": 0.08876251429319382,
    "learning_rate": 0.001
  },
  {
    "episode": 10549,
    "reward": 88.110878,
    "length": 65,
    "time": 155341.655018,
    "actor_loss": -62.55366516113281,
    "critic_loss": 23.097936630249023,
    "ent_coef": 0.08835099637508392,
    "learning_rate": 0.001
  },
  {
    "episode": 10550,
    "reward": 89.667839,
    "length": 64,
    "time": 155353.214555,
    "actor_loss": -66.45558166503906,
    "critic_loss": 570.00439453125,
    "ent_coef": 0.09133748710155487,
    "learning_rate": 0.001
  },
  {
    "episode": 10551,
    "reward": 89.385433,
    "length": 63,
    "time": 155368.359763,
    "actor_loss": -64.30633544921875,
    "critic_loss": 5.151505947113037,
    "ent_coef": 0.09761539101600647,
    "learning_rate": 0.001
  },
  {
    "episode": 10552,
    "reward": 89.713426,
    "length": 64,
    "time": 155379.696272,
    "actor_loss": -62.820045471191406,
    "critic_loss": 16.486011505126953,
    "ent_coef": 0.0999484434723854,
    "learning_rate": 0.001
  },
  {
    "episode": 10553,
    "reward": 86.2165,
    "length": 71,
    "time": 155392.268492,
    "actor_loss": -60.991756439208984,
    "critic_loss": 6.189603805541992,
    "ent_coef": 0.10000798106193542,
    "learning_rate": 0.001
  },
  {
    "episode": 10554,
    "reward": 86.991672,
    "length": 68,
    "time": 155407.74753,
    "actor_loss": -60.201438903808594,
    "critic_loss": 8.203327178955078,
    "ent_coef": 0.09961435943841934,
    "learning_rate": 0.001
  },
  {
    "episode": 10555,
    "reward": 86.943878,
    "length": 68,
    "time": 155422.810225,
    "actor_loss": -62.548912048339844,
    "critic_loss": 8.076786994934082,
    "ent_coef": 0.09792731702327728,
    "learning_rate": 0.001
  },
  {
    "episode": 10556,
    "reward": 88.313788,
    "length": 66,
    "time": 155436.541404,
    "actor_loss": -66.28729248046875,
    "critic_loss": 3.721526622772217,
    "ent_coef": 0.09507539123296738,
    "learning_rate": 0.001
  },
  {
    "episode": 10557,
    "reward": 89.565395,
    "length": 63,
    "time": 155448.651244,
    "actor_loss": -61.92073440551758,
    "critic_loss": 28.66793441772461,
    "ent_coef": 0.0986572876572609,
    "learning_rate": 0.001
  },
  {
    "episode": 10558,
    "reward": 86.375276,
    "length": 70,
    "time": 155465.000649,
    "actor_loss": -67.63420104980469,
    "critic_loss": 4.406694412231445,
    "ent_coef": 0.1026776060461998,
    "learning_rate": 0.001
  },
  {
    "episode": 10559,
    "reward": 88.158466,
    "length": 68,
    "time": 155478.064212,
    "actor_loss": -57.88133239746094,
    "critic_loss": 60.863346099853516,
    "ent_coef": 0.09878214448690414,
    "learning_rate": 0.001
  },
  {
    "episode": 10560,
    "reward": 87.160537,
    "length": 68,
    "time": 155492.225127,
    "actor_loss": -60.72425842285156,
    "critic_loss": 8.509952545166016,
    "ent_coef": 0.09206307679414749,
    "learning_rate": 0.001
  },
  {
    "episode": 10561,
    "reward": 87.054575,
    "length": 68,
    "time": 155504.471108,
    "actor_loss": -69.6254653930664,
    "critic_loss": 5.8769378662109375,
    "ent_coef": 0.0872127041220665,
    "learning_rate": 0.001
  },
  {
    "episode": 10562,
    "reward": 87.06743,
    "length": 67,
    "time": 155516.408365,
    "actor_loss": -64.03369140625,
    "critic_loss": 3.4472808837890625,
    "ent_coef": 0.08100096136331558,
    "learning_rate": 0.001
  },
  {
    "episode": 10563,
    "reward": 80.460229,
    "length": 78,
    "time": 155530.469659,
    "actor_loss": -55.489349365234375,
    "critic_loss": 8.802717208862305,
    "ent_coef": 0.07687706500291824,
    "learning_rate": 0.001
  },
  {
    "episode": 10564,
    "reward": 82.956546,
    "length": 75,
    "time": 155544.971112,
    "actor_loss": -67.05178833007812,
    "critic_loss": 4.548300743103027,
    "ent_coef": 0.07449238747358322,
    "learning_rate": 0.001
  },
  {
    "episode": 10565,
    "reward": 86.474369,
    "length": 67,
    "time": 155556.997541,
    "actor_loss": -66.7432632446289,
    "critic_loss": 803.7249755859375,
    "ent_coef": 0.0763460099697113,
    "learning_rate": 0.001
  },
  {
    "episode": 10566,
    "reward": 89.439246,
    "length": 63,
    "time": 155570.42675,
    "actor_loss": -63.47979736328125,
    "critic_loss": 13.98122787475586,
    "ent_coef": 0.07940462231636047,
    "learning_rate": 0.001
  },
  {
    "episode": 10567,
    "reward": 83.197579,
    "length": 70,
    "time": 155583.59949,
    "actor_loss": -60.03097152709961,
    "critic_loss": 34.25625228881836,
    "ent_coef": 0.08275274932384491,
    "learning_rate": 0.001
  },
  {
    "episode": 10568,
    "reward": 86.765906,
    "length": 68,
    "time": 155599.7429,
    "actor_loss": -58.492427825927734,
    "critic_loss": 4.813617706298828,
    "ent_coef": 0.08567511290311813,
    "learning_rate": 0.001
  },
  {
    "episode": 10569,
    "reward": 89.141276,
    "length": 64,
    "time": 155612.68771,
    "actor_loss": -63.49017333984375,
    "critic_loss": 28.56774139404297,
    "ent_coef": 0.08709143847227097,
    "learning_rate": 0.001
  },
  {
    "episode": 10570,
    "reward": 85.376116,
    "length": 71,
    "time": 155625.020698,
    "actor_loss": -63.979331970214844,
    "critic_loss": 3.5476155281066895,
    "ent_coef": 0.0882984921336174,
    "learning_rate": 0.001
  },
  {
    "episode": 10571,
    "reward": 88.289981,
    "length": 66,
    "time": 155644.872866,
    "actor_loss": -65.70538330078125,
    "critic_loss": 5.367714881896973,
    "ent_coef": 0.08888773620128632,
    "learning_rate": 0.001
  },
  {
    "episode": 10572,
    "reward": 89.862739,
    "length": 63,
    "time": 155656.206618,
    "actor_loss": -67.23307037353516,
    "critic_loss": 35.76277160644531,
    "ent_coef": 0.09201326966285706,
    "learning_rate": 0.001
  },
  {
    "episode": 10573,
    "reward": 87.550453,
    "length": 69,
    "time": 155668.177407,
    "actor_loss": -66.63541412353516,
    "critic_loss": 4.281990051269531,
    "ent_coef": 0.09066099673509598,
    "learning_rate": 0.001
  },
  {
    "episode": 10574,
    "reward": 88.330894,
    "length": 66,
    "time": 155681.956686,
    "actor_loss": -66.72407531738281,
    "critic_loss": 7.702009201049805,
    "ent_coef": 0.08968488872051239,
    "learning_rate": 0.001
  },
  {
    "episode": 10575,
    "reward": 88.392387,
    "length": 65,
    "time": 155695.415678,
    "actor_loss": -71.68515014648438,
    "critic_loss": 40.016754150390625,
    "ent_coef": 0.09429009258747101,
    "learning_rate": 0.001
  },
  {
    "episode": 10576,
    "reward": 89.509291,
    "length": 64,
    "time": 155706.596576,
    "actor_loss": -64.58431243896484,
    "critic_loss": 3.0051159858703613,
    "ent_coef": 0.09845318645238876,
    "learning_rate": 0.001
  },
  {
    "episode": 10577,
    "reward": 89.042402,
    "length": 63,
    "time": 155717.673209,
    "actor_loss": -65.27618408203125,
    "critic_loss": 21.669435501098633,
    "ent_coef": 0.10165377706289291,
    "learning_rate": 0.001
  },
  {
    "episode": 10578,
    "reward": 85.179035,
    "length": 82,
    "time": 155731.841744,
    "actor_loss": -63.92116928100586,
    "critic_loss": 24.003406524658203,
    "ent_coef": 0.11074483394622803,
    "learning_rate": 0.001
  },
  {
    "episode": 10579,
    "reward": 89.210246,
    "length": 64,
    "time": 155743.07565,
    "actor_loss": -64.4208984375,
    "critic_loss": 8.581071853637695,
    "ent_coef": 0.10615314543247223,
    "learning_rate": 0.001
  },
  {
    "episode": 10580,
    "reward": 87.417548,
    "length": 66,
    "time": 155758.478147,
    "actor_loss": -62.416664123535156,
    "critic_loss": 6.336491584777832,
    "ent_coef": 0.10008691251277924,
    "learning_rate": 0.001
  },
  {
    "episode": 10581,
    "reward": 87.124379,
    "length": 67,
    "time": 155773.974138,
    "actor_loss": -66.00396728515625,
    "critic_loss": 630.8714599609375,
    "ent_coef": 0.09523827582597733,
    "learning_rate": 0.001
  },
  {
    "episode": 10582,
    "reward": 88.325452,
    "length": 66,
    "time": 155788.665868,
    "actor_loss": -65.60970306396484,
    "critic_loss": 52.38214111328125,
    "ent_coef": 0.09161932021379471,
    "learning_rate": 0.001
  },
  {
    "episode": 10583,
    "reward": 86.513921,
    "length": 69,
    "time": 155803.861263,
    "actor_loss": -62.04570007324219,
    "critic_loss": 11.774486541748047,
    "ent_coef": 0.08651499450206757,
    "learning_rate": 0.001
  },
  {
    "episode": 10584,
    "reward": 89.602657,
    "length": 64,
    "time": 155815.506402,
    "actor_loss": -66.20641326904297,
    "critic_loss": 515.7447509765625,
    "ent_coef": 0.08410326391458511,
    "learning_rate": 0.001
  },
  {
    "episode": 10585,
    "reward": 83.304118,
    "length": 85,
    "time": 155829.667921,
    "actor_loss": -58.517662048339844,
    "critic_loss": 8.447940826416016,
    "ent_coef": 0.086082324385643,
    "learning_rate": 0.001
  },
  {
    "episode": 10586,
    "reward": 90.469147,
    "length": 62,
    "time": 155841.686761,
    "actor_loss": -66.93853759765625,
    "critic_loss": 5.790581703186035,
    "ent_coef": 0.08821377903223038,
    "learning_rate": 0.001
  },
  {
    "episode": 10587,
    "reward": 89.029948,
    "length": 66,
    "time": 155853.429645,
    "actor_loss": -64.16251373291016,
    "critic_loss": 4.897828102111816,
    "ent_coef": 0.09081143140792847,
    "learning_rate": 0.001
  },
  {
    "episode": 10588,
    "reward": 87.686643,
    "length": 67,
    "time": 155866.594447,
    "actor_loss": -69.82864379882812,
    "critic_loss": 36.00775146484375,
    "ent_coef": 0.09095797687768936,
    "learning_rate": 0.001
  },
  {
    "episode": 10589,
    "reward": 84.60422,
    "length": 68,
    "time": 155878.524458,
    "actor_loss": -62.74891662597656,
    "critic_loss": 475.59686279296875,
    "ent_coef": 0.09367459267377853,
    "learning_rate": 0.001
  },
  {
    "episode": 10590,
    "reward": 89.621059,
    "length": 64,
    "time": 155889.870935,
    "actor_loss": -66.0948486328125,
    "critic_loss": 5.377009868621826,
    "ent_coef": 0.09149697422981262,
    "learning_rate": 0.001
  },
  {
    "episode": 10591,
    "reward": 88.091114,
    "length": 66,
    "time": 155902.009161,
    "actor_loss": -71.9946060180664,
    "critic_loss": 27.963367462158203,
    "ent_coef": 0.08752544224262238,
    "learning_rate": 0.001
  },
  {
    "episode": 10592,
    "reward": 88.496158,
    "length": 68,
    "time": 155915.414785,
    "actor_loss": -66.03356170654297,
    "critic_loss": 2.27951979637146,
    "ent_coef": 0.08924238383769989,
    "learning_rate": 0.001
  },
  {
    "episode": 10593,
    "reward": 87.708327,
    "length": 67,
    "time": 155927.966825,
    "actor_loss": -59.80314636230469,
    "critic_loss": 24.140811920166016,
    "ent_coef": 0.08553783595561981,
    "learning_rate": 0.001
  },
  {
    "episode": 10594,
    "reward": 81.181167,
    "length": 75,
    "time": 155942.860935,
    "actor_loss": -60.93169403076172,
    "critic_loss": 24.77114486694336,
    "ent_coef": 0.07989144325256348,
    "learning_rate": 0.001
  },
  {
    "episode": 10595,
    "reward": 82.024165,
    "length": 75,
    "time": 155955.556918,
    "actor_loss": -60.33978271484375,
    "critic_loss": 4.509129047393799,
    "ent_coef": 0.07974111288785934,
    "learning_rate": 0.001
  },
  {
    "episode": 10596,
    "reward": 85.803977,
    "length": 70,
    "time": 155968.922124,
    "actor_loss": -61.029815673828125,
    "critic_loss": 3.7460851669311523,
    "ent_coef": 0.0808304101228714,
    "learning_rate": 0.001
  },
  {
    "episode": 10597,
    "reward": 87.846069,
    "length": 67,
    "time": 155980.62065,
    "actor_loss": -61.35517120361328,
    "critic_loss": 53.89399337768555,
    "ent_coef": 0.07953108102083206,
    "learning_rate": 0.001
  },
  {
    "episode": 10598,
    "reward": 85.190696,
    "length": 71,
    "time": 155993.090823,
    "actor_loss": -66.21333312988281,
    "critic_loss": 30.704965591430664,
    "ent_coef": 0.078514464199543,
    "learning_rate": 0.001
  },
  {
    "episode": 10599,
    "reward": 87.605766,
    "length": 67,
    "time": 156006.051404,
    "actor_loss": -65.40531158447266,
    "critic_loss": 669.7471313476562,
    "ent_coef": 0.07822531461715698,
    "learning_rate": 0.001
  },
  {
    "episode": 10600,
    "reward": 87.018914,
    "length": 67,
    "time": 156017.855042,
    "actor_loss": -66.01986694335938,
    "critic_loss": 20.216564178466797,
    "ent_coef": 0.07788646221160889,
    "learning_rate": 0.001
  },
  {
    "episode": 10601,
    "reward": 88.2335,
    "length": 67,
    "time": 156032.061424,
    "actor_loss": -63.85437774658203,
    "critic_loss": 12.802626609802246,
    "ent_coef": 0.08090222626924515,
    "learning_rate": 0.001
  },
  {
    "episode": 10602,
    "reward": 87.64214,
    "length": 68,
    "time": 156045.178264,
    "actor_loss": -61.31932067871094,
    "critic_loss": 4.923016548156738,
    "ent_coef": 0.08032859861850739,
    "learning_rate": 0.001
  },
  {
    "episode": 10603,
    "reward": 84.502264,
    "length": 71,
    "time": 156060.516688,
    "actor_loss": -71.43765258789062,
    "critic_loss": 3.2027411460876465,
    "ent_coef": 0.07505147904157639,
    "learning_rate": 0.001
  },
  {
    "episode": 10604,
    "reward": 86.600312,
    "length": 70,
    "time": 156072.632825,
    "actor_loss": -59.90424346923828,
    "critic_loss": 8.642875671386719,
    "ent_coef": 0.07138101756572723,
    "learning_rate": 0.001
  },
  {
    "episode": 10605,
    "reward": 84.327547,
    "length": 71,
    "time": 156084.917662,
    "actor_loss": -58.53013610839844,
    "critic_loss": 33.80342102050781,
    "ent_coef": 0.07205536216497421,
    "learning_rate": 0.001
  },
  {
    "episode": 10606,
    "reward": 83.825486,
    "length": 83,
    "time": 156098.622196,
    "actor_loss": -71.52771759033203,
    "critic_loss": 11.14588737487793,
    "ent_coef": 0.07950487732887268,
    "learning_rate": 0.001
  },
  {
    "episode": 10607,
    "reward": 90.056146,
    "length": 64,
    "time": 156112.504127,
    "actor_loss": -65.9728775024414,
    "critic_loss": 6.540393829345703,
    "ent_coef": 0.08446007966995239,
    "learning_rate": 0.001
  },
  {
    "episode": 10608,
    "reward": 87.987603,
    "length": 65,
    "time": 156124.161715,
    "actor_loss": -58.6625862121582,
    "critic_loss": 272.0702209472656,
    "ent_coef": 0.08835063129663467,
    "learning_rate": 0.001
  },
  {
    "episode": 10609,
    "reward": 88.010325,
    "length": 65,
    "time": 156136.28046,
    "actor_loss": -66.04501342773438,
    "critic_loss": 11.631292343139648,
    "ent_coef": 0.0896313488483429,
    "learning_rate": 0.001
  },
  {
    "episode": 10610,
    "reward": 87.830305,
    "length": 66,
    "time": 156147.872653,
    "actor_loss": -62.11471939086914,
    "critic_loss": 41.489105224609375,
    "ent_coef": 0.09232226759195328,
    "learning_rate": 0.001
  },
  {
    "episode": 10611,
    "reward": 88.437307,
    "length": 65,
    "time": 156160.822767,
    "actor_loss": -63.238243103027344,
    "critic_loss": 22.500661849975586,
    "ent_coef": 0.09253520518541336,
    "learning_rate": 0.001
  },
  {
    "episode": 10612,
    "reward": 89.916395,
    "length": 63,
    "time": 156172.612422,
    "actor_loss": -60.45991516113281,
    "critic_loss": 4.29604434967041,
    "ent_coef": 0.09710271656513214,
    "learning_rate": 0.001
  },
  {
    "episode": 10613,
    "reward": 88.148299,
    "length": 68,
    "time": 156184.343421,
    "actor_loss": -67.68902587890625,
    "critic_loss": 4.586889743804932,
    "ent_coef": 0.0994558185338974,
    "learning_rate": 0.001
  },
  {
    "episode": 10614,
    "reward": 88.505795,
    "length": 64,
    "time": 156195.917604,
    "actor_loss": -65.01324462890625,
    "critic_loss": 5.986469745635986,
    "ent_coef": 0.10052270442247391,
    "learning_rate": 0.001
  },
  {
    "episode": 10615,
    "reward": 88.444968,
    "length": 66,
    "time": 156207.478564,
    "actor_loss": -64.63479614257812,
    "critic_loss": 8.302921295166016,
    "ent_coef": 0.09892704337835312,
    "learning_rate": 0.001
  },
  {
    "episode": 10616,
    "reward": 88.087888,
    "length": 66,
    "time": 156219.490898,
    "actor_loss": -67.28800201416016,
    "critic_loss": 37.18751907348633,
    "ent_coef": 0.10079329460859299,
    "learning_rate": 0.001
  },
  {
    "episode": 10617,
    "reward": 90.169822,
    "length": 62,
    "time": 156233.279911,
    "actor_loss": -64.42998504638672,
    "critic_loss": 14.408502578735352,
    "ent_coef": 0.10449343174695969,
    "learning_rate": 0.001
  },
  {
    "episode": 10618,
    "reward": 89.400814,
    "length": 64,
    "time": 156244.650849,
    "actor_loss": -61.89130401611328,
    "critic_loss": 45.139617919921875,
    "ent_coef": 0.11037112027406693,
    "learning_rate": 0.001
  },
  {
    "episode": 10619,
    "reward": 87.69061,
    "length": 67,
    "time": 156256.726369,
    "actor_loss": -68.1002197265625,
    "critic_loss": 45.413509368896484,
    "ent_coef": 0.11252468079328537,
    "learning_rate": 0.001
  },
  {
    "episode": 10620,
    "reward": 73.3688,
    "length": 83,
    "time": 156273.623021,
    "actor_loss": -57.3785400390625,
    "critic_loss": 4.253384590148926,
    "ent_coef": 0.1118292286992073,
    "learning_rate": 0.001
  },
  {
    "episode": 10621,
    "reward": 88.004657,
    "length": 68,
    "time": 156287.301615,
    "actor_loss": -57.36951446533203,
    "critic_loss": 23.19066619873047,
    "ent_coef": 0.1060330718755722,
    "learning_rate": 0.001
  },
  {
    "episode": 10622,
    "reward": 85.973983,
    "length": 71,
    "time": 156300.592733,
    "actor_loss": -68.24605560302734,
    "critic_loss": 3.6594948768615723,
    "ent_coef": 0.10324432700872421,
    "learning_rate": 0.001
  },
  {
    "episode": 10623,
    "reward": 87.329249,
    "length": 69,
    "time": 156312.693733,
    "actor_loss": -66.110595703125,
    "critic_loss": 64.82356262207031,
    "ent_coef": 0.09465861320495605,
    "learning_rate": 0.001
  },
  {
    "episode": 10624,
    "reward": 87.181556,
    "length": 67,
    "time": 156325.674189,
    "actor_loss": -66.59202575683594,
    "critic_loss": 3.057163953781128,
    "ent_coef": 0.08986890316009521,
    "learning_rate": 0.001
  },
  {
    "episode": 10625,
    "reward": 88.195172,
    "length": 66,
    "time": 156337.865499,
    "actor_loss": -63.32135772705078,
    "critic_loss": 11.710882186889648,
    "ent_coef": 0.09006798267364502,
    "learning_rate": 0.001
  },
  {
    "episode": 10626,
    "reward": 85.135079,
    "length": 71,
    "time": 156350.560386,
    "actor_loss": -59.68878936767578,
    "critic_loss": 28.34359359741211,
    "ent_coef": 0.08570755273103714,
    "learning_rate": 0.001
  },
  {
    "episode": 10627,
    "reward": 85.161157,
    "length": 72,
    "time": 156365.363994,
    "actor_loss": -67.23869323730469,
    "critic_loss": 4.614439010620117,
    "ent_coef": 0.07889286428689957,
    "learning_rate": 0.001
  },
  {
    "episode": 10628,
    "reward": 84.223273,
    "length": 72,
    "time": 156378.283825,
    "actor_loss": -65.791748046875,
    "critic_loss": 14.553642272949219,
    "ent_coef": 0.07429884374141693,
    "learning_rate": 0.001
  },
  {
    "episode": 10629,
    "reward": 83.287412,
    "length": 72,
    "time": 156390.870644,
    "actor_loss": -67.27069091796875,
    "critic_loss": 12.183359146118164,
    "ent_coef": 0.07326623797416687,
    "learning_rate": 0.001
  },
  {
    "episode": 10630,
    "reward": 87.210651,
    "length": 66,
    "time": 156403.284084,
    "actor_loss": -63.10942459106445,
    "critic_loss": 29.641643524169922,
    "ent_coef": 0.07756173610687256,
    "learning_rate": 0.001
  },
  {
    "episode": 10631,
    "reward": 88.567027,
    "length": 65,
    "time": 156417.482275,
    "actor_loss": -61.455543518066406,
    "critic_loss": 4.038303852081299,
    "ent_coef": 0.08071491867303848,
    "learning_rate": 0.001
  },
  {
    "episode": 10632,
    "reward": 89.613369,
    "length": 64,
    "time": 156433.186439,
    "actor_loss": -74.50176239013672,
    "critic_loss": 44.70600891113281,
    "ent_coef": 0.08560609817504883,
    "learning_rate": 0.001
  },
  {
    "episode": 10633,
    "reward": 89.920604,
    "length": 62,
    "time": 156446.569507,
    "actor_loss": -66.90676879882812,
    "critic_loss": 15.312356948852539,
    "ent_coef": 0.08961065858602524,
    "learning_rate": 0.001
  },
  {
    "episode": 10634,
    "reward": 86.652156,
    "length": 72,
    "time": 156459.010505,
    "actor_loss": -64.32046508789062,
    "critic_loss": 611.308837890625,
    "ent_coef": 0.09008750319480896,
    "learning_rate": 0.001
  },
  {
    "episode": 10635,
    "reward": 84.054665,
    "length": 72,
    "time": 156471.688677,
    "actor_loss": -60.22352600097656,
    "critic_loss": 16.05780029296875,
    "ent_coef": 0.08818136900663376,
    "learning_rate": 0.001
  },
  {
    "episode": 10636,
    "reward": 86.875313,
    "length": 68,
    "time": 156483.588961,
    "actor_loss": -65.59507751464844,
    "critic_loss": 31.634170532226562,
    "ent_coef": 0.08569466322660446,
    "learning_rate": 0.001
  },
  {
    "episode": 10637,
    "reward": 85.745706,
    "length": 70,
    "time": 156496.76388,
    "actor_loss": -64.25074768066406,
    "critic_loss": 19.951908111572266,
    "ent_coef": 0.08564010262489319,
    "learning_rate": 0.001
  },
  {
    "episode": 10638,
    "reward": 86.774651,
    "length": 68,
    "time": 156509.882585,
    "actor_loss": -65.66633605957031,
    "critic_loss": 41.78949737548828,
    "ent_coef": 0.08482341468334198,
    "learning_rate": 0.001
  },
  {
    "episode": 10639,
    "reward": 86.629682,
    "length": 68,
    "time": 156523.879748,
    "actor_loss": -63.957855224609375,
    "critic_loss": 5.36688232421875,
    "ent_coef": 0.08639898151159286,
    "learning_rate": 0.001
  },
  {
    "episode": 10640,
    "reward": 87.079154,
    "length": 68,
    "time": 156535.826865,
    "actor_loss": -63.5787353515625,
    "critic_loss": 8.965171813964844,
    "ent_coef": 0.08463975042104721,
    "learning_rate": 0.001
  },
  {
    "episode": 10641,
    "reward": 74.021036,
    "length": 86,
    "time": 156553.288183,
    "actor_loss": -56.610084533691406,
    "critic_loss": 38.050254821777344,
    "ent_coef": 0.08335274457931519,
    "learning_rate": 0.001
  },
  {
    "episode": 10642,
    "reward": 85.477574,
    "length": 71,
    "time": 156568.854085,
    "actor_loss": -66.11761474609375,
    "critic_loss": 12.475247383117676,
    "ent_coef": 0.08163301646709442,
    "learning_rate": 0.001
  },
  {
    "episode": 10643,
    "reward": 85.765054,
    "length": 70,
    "time": 156581.905708,
    "actor_loss": -63.99843215942383,
    "critic_loss": 3.1981687545776367,
    "ent_coef": 0.08182007074356079,
    "learning_rate": 0.001
  },
  {
    "episode": 10644,
    "reward": 87.889686,
    "length": 68,
    "time": 156593.972035,
    "actor_loss": -59.1828498840332,
    "critic_loss": 10.305012702941895,
    "ent_coef": 0.08275394886732101,
    "learning_rate": 0.001
  },
  {
    "episode": 10645,
    "reward": 89.411623,
    "length": 63,
    "time": 156605.571612,
    "actor_loss": -61.325313568115234,
    "critic_loss": 33.73798370361328,
    "ent_coef": 0.08397234976291656,
    "learning_rate": 0.001
  },
  {
    "episode": 10646,
    "reward": 88.169816,
    "length": 66,
    "time": 156617.332185,
    "actor_loss": -70.69631958007812,
    "critic_loss": 7.683189392089844,
    "ent_coef": 0.08460542559623718,
    "learning_rate": 0.001
  },
  {
    "episode": 10647,
    "reward": 87.38335,
    "length": 70,
    "time": 156630.570054,
    "actor_loss": -66.48200225830078,
    "critic_loss": 18.292495727539062,
    "ent_coef": 0.08573735505342484,
    "learning_rate": 0.001
  },
  {
    "episode": 10648,
    "reward": 89.614869,
    "length": 64,
    "time": 156644.755115,
    "actor_loss": -72.07386779785156,
    "critic_loss": 58.30989074707031,
    "ent_coef": 0.0879005640745163,
    "learning_rate": 0.001
  },
  {
    "episode": 10649,
    "reward": 87.011024,
    "length": 76,
    "time": 156657.788429,
    "actor_loss": -65.14535522460938,
    "critic_loss": 38.32048034667969,
    "ent_coef": 0.09354808926582336,
    "learning_rate": 0.001
  },
  {
    "episode": 10650,
    "reward": 88.928034,
    "length": 65,
    "time": 156670.348724,
    "actor_loss": -63.151615142822266,
    "critic_loss": 3.366292953491211,
    "ent_coef": 0.09229788184165955,
    "learning_rate": 0.001
  },
  {
    "episode": 10651,
    "reward": 88.078363,
    "length": 66,
    "time": 156682.385731,
    "actor_loss": -67.9253158569336,
    "critic_loss": 10.361109733581543,
    "ent_coef": 0.08818215131759644,
    "learning_rate": 0.001
  },
  {
    "episode": 10652,
    "reward": 88.781081,
    "length": 66,
    "time": 156700.598088,
    "actor_loss": -63.675498962402344,
    "critic_loss": 27.75271224975586,
    "ent_coef": 0.09037929028272629,
    "learning_rate": 0.001
  },
  {
    "episode": 10653,
    "reward": 89.181836,
    "length": 64,
    "time": 156712.831309,
    "actor_loss": -66.23674011230469,
    "critic_loss": 19.724912643432617,
    "ent_coef": 0.09249556809663773,
    "learning_rate": 0.001
  },
  {
    "episode": 10654,
    "reward": 89.899065,
    "length": 63,
    "time": 156723.96259,
    "actor_loss": -65.90229034423828,
    "critic_loss": 3.3257811069488525,
    "ent_coef": 0.09845452755689621,
    "learning_rate": 0.001
  },
  {
    "episode": 10655,
    "reward": 87.959469,
    "length": 67,
    "time": 156736.654979,
    "actor_loss": -62.404258728027344,
    "critic_loss": 9.147550582885742,
    "ent_coef": 0.09804071485996246,
    "learning_rate": 0.001
  },
  {
    "episode": 10656,
    "reward": 87.787968,
    "length": 67,
    "time": 156748.677213,
    "actor_loss": -64.14917755126953,
    "critic_loss": 2.7034928798675537,
    "ent_coef": 0.09346994757652283,
    "learning_rate": 0.001
  },
  {
    "episode": 10657,
    "reward": 88.231434,
    "length": 67,
    "time": 156760.696625,
    "actor_loss": -67.90000915527344,
    "critic_loss": 104.58905029296875,
    "ent_coef": 0.09365389496088028,
    "learning_rate": 0.001
  },
  {
    "episode": 10658,
    "reward": 88.251552,
    "length": 66,
    "time": 156773.406402,
    "actor_loss": -68.06623077392578,
    "critic_loss": 20.516674041748047,
    "ent_coef": 0.09356214106082916,
    "learning_rate": 0.001
  },
  {
    "episode": 10659,
    "reward": 87.388804,
    "length": 68,
    "time": 156786.669955,
    "actor_loss": -65.99632263183594,
    "critic_loss": 10.314051628112793,
    "ent_coef": 0.08919632434844971,
    "learning_rate": 0.001
  },
  {
    "episode": 10660,
    "reward": 82.898298,
    "length": 80,
    "time": 156801.035182,
    "actor_loss": -64.59085845947266,
    "critic_loss": 2.368562936782837,
    "ent_coef": 0.08393813669681549,
    "learning_rate": 0.001
  },
  {
    "episode": 10661,
    "reward": 87.533421,
    "length": 68,
    "time": 156815.212804,
    "actor_loss": -70.33006286621094,
    "critic_loss": 90.25624084472656,
    "ent_coef": 0.08423886448144913,
    "learning_rate": 0.001
  },
  {
    "episode": 10662,
    "reward": 90.60683,
    "length": 62,
    "time": 156826.678114,
    "actor_loss": -68.10355377197266,
    "critic_loss": 20.380016326904297,
    "ent_coef": 0.09198936074972153,
    "learning_rate": 0.001
  },
  {
    "episode": 10663,
    "reward": 85.924936,
    "length": 80,
    "time": 156839.96647,
    "actor_loss": -64.57953643798828,
    "critic_loss": 3.5452966690063477,
    "ent_coef": 0.0931616798043251,
    "learning_rate": 0.001
  },
  {
    "episode": 10664,
    "reward": 91.089817,
    "length": 60,
    "time": 156850.905488,
    "actor_loss": -64.32450103759766,
    "critic_loss": 8.948617935180664,
    "ent_coef": 0.09494741261005402,
    "learning_rate": 0.001
  },
  {
    "episode": 10665,
    "reward": 85.009499,
    "length": 77,
    "time": 156864.058486,
    "actor_loss": -64.06910705566406,
    "critic_loss": 8.01823616027832,
    "ent_coef": 0.09444486349821091,
    "learning_rate": 0.001
  },
  {
    "episode": 10666,
    "reward": -161.973937,
    "length": 164,
    "time": 156888.600774,
    "actor_loss": -67.95924377441406,
    "critic_loss": 46.224578857421875,
    "ent_coef": 0.08598478138446808,
    "learning_rate": 0.001
  },
  {
    "episode": 10667,
    "reward": 88.613073,
    "length": 64,
    "time": 156901.38904,
    "actor_loss": -61.567176818847656,
    "critic_loss": 16.110509872436523,
    "ent_coef": 0.0900837630033493,
    "learning_rate": 0.001
  },
  {
    "episode": 10668,
    "reward": 83.785876,
    "length": 84,
    "time": 156915.861521,
    "actor_loss": -58.145896911621094,
    "critic_loss": 22.29861068725586,
    "ent_coef": 0.0883525013923645,
    "learning_rate": 0.001
  },
  {
    "episode": 10669,
    "reward": 90.405367,
    "length": 62,
    "time": 156926.944587,
    "actor_loss": -67.33528137207031,
    "critic_loss": 5.223752975463867,
    "ent_coef": 0.09063177555799484,
    "learning_rate": 0.001
  },
  {
    "episode": 10670,
    "reward": 88.353133,
    "length": 67,
    "time": 156939.092112,
    "actor_loss": -62.9437255859375,
    "critic_loss": 15.460955619812012,
    "ent_coef": 0.08859235793352127,
    "learning_rate": 0.001
  },
  {
    "episode": 10671,
    "reward": 88.393143,
    "length": 65,
    "time": 156951.286652,
    "actor_loss": -68.65965270996094,
    "critic_loss": 69.95421600341797,
    "ent_coef": 0.09200230240821838,
    "learning_rate": 0.001
  },
  {
    "episode": 10672,
    "reward": 87.312746,
    "length": 72,
    "time": 156964.607095,
    "actor_loss": -62.20171356201172,
    "critic_loss": 3.1839375495910645,
    "ent_coef": 0.09821442514657974,
    "learning_rate": 0.001
  },
  {
    "episode": 10673,
    "reward": 89.206493,
    "length": 64,
    "time": 156978.62946,
    "actor_loss": -66.13536071777344,
    "critic_loss": 46.10319519042969,
    "ent_coef": 0.1023573949933052,
    "learning_rate": 0.001
  },
  {
    "episode": 10674,
    "reward": 87.79695,
    "length": 68,
    "time": 156993.236106,
    "actor_loss": -59.600948333740234,
    "critic_loss": 17.274612426757812,
    "ent_coef": 0.10071856528520584,
    "learning_rate": 0.001
  },
  {
    "episode": 10675,
    "reward": 84.871912,
    "length": 71,
    "time": 157005.752644,
    "actor_loss": -63.8221435546875,
    "critic_loss": 13.02166748046875,
    "ent_coef": 0.09564996510744095,
    "learning_rate": 0.001
  },
  {
    "episode": 10676,
    "reward": 86.665035,
    "length": 70,
    "time": 157017.767353,
    "actor_loss": -62.74379348754883,
    "critic_loss": 10.167990684509277,
    "ent_coef": 0.09082853049039841,
    "learning_rate": 0.001
  },
  {
    "episode": 10677,
    "reward": 85.006082,
    "length": 74,
    "time": 157032.974933,
    "actor_loss": -66.20283508300781,
    "critic_loss": 35.39933395385742,
    "ent_coef": 0.08913327753543854,
    "learning_rate": 0.001
  },
  {
    "episode": 10678,
    "reward": 87.057746,
    "length": 65,
    "time": 157045.296293,
    "actor_loss": -62.70974349975586,
    "critic_loss": 11.771483421325684,
    "ent_coef": 0.09372244030237198,
    "learning_rate": 0.001
  },
  {
    "episode": 10679,
    "reward": 89.726984,
    "length": 64,
    "time": 157062.392908,
    "actor_loss": -67.2750244140625,
    "critic_loss": 92.75516510009766,
    "ent_coef": 0.09186261147260666,
    "learning_rate": 0.001
  },
  {
    "episode": 10680,
    "reward": 89.613363,
    "length": 63,
    "time": 157073.960938,
    "actor_loss": -60.11331558227539,
    "critic_loss": 14.19875431060791,
    "ent_coef": 0.09229594469070435,
    "learning_rate": 0.001
  },
  {
    "episode": 10681,
    "reward": 88.669557,
    "length": 65,
    "time": 157086.49442,
    "actor_loss": -66.0245132446289,
    "critic_loss": 5.374323844909668,
    "ent_coef": 0.0940556675195694,
    "learning_rate": 0.001
  },
  {
    "episode": 10682,
    "reward": 88.75197,
    "length": 65,
    "time": 157099.461854,
    "actor_loss": -67.78289794921875,
    "critic_loss": 7.456064224243164,
    "ent_coef": 0.09587012231349945,
    "learning_rate": 0.001
  },
  {
    "episode": 10683,
    "reward": 90.205066,
    "length": 62,
    "time": 157110.502167,
    "actor_loss": -64.65950012207031,
    "critic_loss": 132.55743408203125,
    "ent_coef": 0.09689193964004517,
    "learning_rate": 0.001
  },
  {
    "episode": 10684,
    "reward": 85.270879,
    "length": 62,
    "time": 157121.683923,
    "actor_loss": -67.40562438964844,
    "critic_loss": 4.60919189453125,
    "ent_coef": 0.10541342198848724,
    "learning_rate": 0.001
  },
  {
    "episode": 10685,
    "reward": 89.232851,
    "length": 64,
    "time": 157132.88554,
    "actor_loss": -62.35597610473633,
    "critic_loss": 48.74125671386719,
    "ent_coef": 0.1085064560174942,
    "learning_rate": 0.001
  },
  {
    "episode": 10686,
    "reward": 89.079339,
    "length": 64,
    "time": 157144.259023,
    "actor_loss": -63.485042572021484,
    "critic_loss": 22.700502395629883,
    "ent_coef": 0.1082884669303894,
    "learning_rate": 0.001
  },
  {
    "episode": 10687,
    "reward": 85.203303,
    "length": 71,
    "time": 157158.550902,
    "actor_loss": -71.20193481445312,
    "critic_loss": 5.915648460388184,
    "ent_coef": 0.10289573669433594,
    "learning_rate": 0.001
  },
  {
    "episode": 10688,
    "reward": 85.886984,
    "length": 70,
    "time": 157173.773721,
    "actor_loss": -66.37017059326172,
    "critic_loss": 2.5191197395324707,
    "ent_coef": 0.09828502684831619,
    "learning_rate": 0.001
  },
  {
    "episode": 10689,
    "reward": 85.845943,
    "length": 83,
    "time": 157188.315071,
    "actor_loss": -63.955894470214844,
    "critic_loss": 23.992948532104492,
    "ent_coef": 0.10186372697353363,
    "learning_rate": 0.001
  },
  {
    "episode": 10690,
    "reward": 89.501298,
    "length": 63,
    "time": 157201.163485,
    "actor_loss": -58.59813690185547,
    "critic_loss": 6.104639053344727,
    "ent_coef": 0.09954354166984558,
    "learning_rate": 0.001
  },
  {
    "episode": 10691,
    "reward": 89.966858,
    "length": 63,
    "time": 157216.609743,
    "actor_loss": -64.37802124023438,
    "critic_loss": 32.5819091796875,
    "ent_coef": 0.10134931653738022,
    "learning_rate": 0.001
  },
  {
    "episode": 10692,
    "reward": 87.58491,
    "length": 68,
    "time": 157228.791965,
    "actor_loss": -63.92245101928711,
    "critic_loss": 29.28939437866211,
    "ent_coef": 0.09920984506607056,
    "learning_rate": 0.001
  },
  {
    "episode": 10693,
    "reward": 82.821684,
    "length": 87,
    "time": 157243.182897,
    "actor_loss": -64.1869125366211,
    "critic_loss": 2.502781391143799,
    "ent_coef": 0.09525148570537567,
    "learning_rate": 0.001
  },
  {
    "episode": 10694,
    "reward": 87.44726,
    "length": 68,
    "time": 157254.880763,
    "actor_loss": -60.85528564453125,
    "critic_loss": 64.05220031738281,
    "ent_coef": 0.08958739042282104,
    "learning_rate": 0.001
  },
  {
    "episode": 10695,
    "reward": 86.365314,
    "length": 70,
    "time": 157267.263968,
    "actor_loss": -63.15435028076172,
    "critic_loss": 15.709085464477539,
    "ent_coef": 0.08641079068183899,
    "learning_rate": 0.001
  },
  {
    "episode": 10696,
    "reward": 88.707142,
    "length": 65,
    "time": 157279.351931,
    "actor_loss": -64.97808074951172,
    "critic_loss": 48.330604553222656,
    "ent_coef": 0.0822182223200798,
    "learning_rate": 0.001
  },
  {
    "episode": 10697,
    "reward": 89.188158,
    "length": 64,
    "time": 157290.736029,
    "actor_loss": -65.49413299560547,
    "critic_loss": 48.00993347167969,
    "ent_coef": 0.0801687240600586,
    "learning_rate": 0.001
  },
  {
    "episode": 10698,
    "reward": 88.939542,
    "length": 64,
    "time": 157303.262667,
    "actor_loss": -61.348045349121094,
    "critic_loss": 4.295909881591797,
    "ent_coef": 0.08224253356456757,
    "learning_rate": 0.001
  },
  {
    "episode": 10699,
    "reward": 89.595332,
    "length": 63,
    "time": 157315.001529,
    "actor_loss": -68.05509948730469,
    "critic_loss": 34.36648941040039,
    "ent_coef": 0.0853082463145256,
    "learning_rate": 0.001
  },
  {
    "episode": 10700,
    "reward": 89.687063,
    "length": 63,
    "time": 157326.158776,
    "actor_loss": -64.41546630859375,
    "critic_loss": 48.52290725708008,
    "ent_coef": 0.08673862367868423,
    "learning_rate": 0.001
  },
  {
    "episode": 10701,
    "reward": 88.258188,
    "length": 66,
    "time": 157338.603367,
    "actor_loss": -66.94422912597656,
    "critic_loss": 44.288116455078125,
    "ent_coef": 0.08386250585317612,
    "learning_rate": 0.001
  },
  {
    "episode": 10702,
    "reward": 88.799027,
    "length": 64,
    "time": 157351.148428,
    "actor_loss": -68.94740295410156,
    "critic_loss": 160.5618896484375,
    "ent_coef": 0.08683735132217407,
    "learning_rate": 0.001
  },
  {
    "episode": 10703,
    "reward": 88.797991,
    "length": 66,
    "time": 157363.930588,
    "actor_loss": -63.234397888183594,
    "critic_loss": 33.06242752075195,
    "ent_coef": 0.08911634236574173,
    "learning_rate": 0.001
  },
  {
    "episode": 10704,
    "reward": 87.953877,
    "length": 67,
    "time": 157378.717387,
    "actor_loss": -60.69415283203125,
    "critic_loss": 78.75812530517578,
    "ent_coef": 0.08807837218046188,
    "learning_rate": 0.001
  },
  {
    "episode": 10705,
    "reward": 86.390108,
    "length": 70,
    "time": 157392.659243,
    "actor_loss": -67.51017761230469,
    "critic_loss": 5.029717922210693,
    "ent_coef": 0.0881204903125763,
    "learning_rate": 0.001
  },
  {
    "episode": 10706,
    "reward": 88.040115,
    "length": 68,
    "time": 157405.2621,
    "actor_loss": -69.3503189086914,
    "critic_loss": 5.413248062133789,
    "ent_coef": 0.0865485817193985,
    "learning_rate": 0.001
  },
  {
    "episode": 10707,
    "reward": 80.574517,
    "length": 87,
    "time": 157420.360479,
    "actor_loss": -63.795501708984375,
    "critic_loss": 13.609548568725586,
    "ent_coef": 0.08505906909704208,
    "learning_rate": 0.001
  },
  {
    "episode": 10708,
    "reward": 81.758736,
    "length": 76,
    "time": 157434.265928,
    "actor_loss": -57.52092361450195,
    "critic_loss": 8.532546997070312,
    "ent_coef": 0.08072672039270401,
    "learning_rate": 0.001
  },
  {
    "episode": 10709,
    "reward": 86.586296,
    "length": 70,
    "time": 157448.299199,
    "actor_loss": -63.338462829589844,
    "critic_loss": 25.298357009887695,
    "ent_coef": 0.07993163168430328,
    "learning_rate": 0.001
  },
  {
    "episode": 10710,
    "reward": 88.592349,
    "length": 65,
    "time": 157461.810677,
    "actor_loss": -63.227752685546875,
    "critic_loss": 8.67519474029541,
    "ent_coef": 0.08070927858352661,
    "learning_rate": 0.001
  },
  {
    "episode": 10711,
    "reward": 87.796687,
    "length": 67,
    "time": 157474.010507,
    "actor_loss": -64.30313110351562,
    "critic_loss": 6.221569061279297,
    "ent_coef": 0.08503870666027069,
    "learning_rate": 0.001
  },
  {
    "episode": 10712,
    "reward": 89.401669,
    "length": 64,
    "time": 157485.80409,
    "actor_loss": -64.75663757324219,
    "critic_loss": 3.5751962661743164,
    "ent_coef": 0.0849880501627922,
    "learning_rate": 0.001
  },
  {
    "episode": 10713,
    "reward": 89.441396,
    "length": 63,
    "time": 157497.119023,
    "actor_loss": -65.55052185058594,
    "critic_loss": 30.436357498168945,
    "ent_coef": 0.08697856217622757,
    "learning_rate": 0.001
  },
  {
    "episode": 10714,
    "reward": 89.097341,
    "length": 63,
    "time": 157508.442721,
    "actor_loss": -66.78948974609375,
    "critic_loss": 8.090898513793945,
    "ent_coef": 0.0878748744726181,
    "learning_rate": 0.001
  },
  {
    "episode": 10715,
    "reward": 89.609158,
    "length": 63,
    "time": 157519.74664,
    "actor_loss": -63.744834899902344,
    "critic_loss": 78.68968963623047,
    "ent_coef": 0.09152398258447647,
    "learning_rate": 0.001
  },
  {
    "episode": 10716,
    "reward": 89.11909,
    "length": 65,
    "time": 157531.445631,
    "actor_loss": -64.27942657470703,
    "critic_loss": 11.732783317565918,
    "ent_coef": 0.09352491796016693,
    "learning_rate": 0.001
  },
  {
    "episode": 10717,
    "reward": 88.88192,
    "length": 64,
    "time": 157544.23042,
    "actor_loss": -63.379608154296875,
    "critic_loss": 21.70941162109375,
    "ent_coef": 0.09509479999542236,
    "learning_rate": 0.001
  },
  {
    "episode": 10718,
    "reward": 87.898135,
    "length": 66,
    "time": 157555.696703,
    "actor_loss": -65.81771850585938,
    "critic_loss": 14.548842430114746,
    "ent_coef": 0.09276967495679855,
    "learning_rate": 0.001
  },
  {
    "episode": 10719,
    "reward": 88.900075,
    "length": 64,
    "time": 157567.885228,
    "actor_loss": -67.57646179199219,
    "critic_loss": 4.1399407386779785,
    "ent_coef": 0.09550480544567108,
    "learning_rate": 0.001
  },
  {
    "episode": 10720,
    "reward": 89.086019,
    "length": 65,
    "time": 157579.766509,
    "actor_loss": -66.22338104248047,
    "critic_loss": 132.64080810546875,
    "ent_coef": 0.09502866864204407,
    "learning_rate": 0.001
  },
  {
    "episode": 10721,
    "reward": 86.96403,
    "length": 69,
    "time": 157591.990426,
    "actor_loss": -71.30872344970703,
    "critic_loss": 4.823457717895508,
    "ent_coef": 0.08909324556589127,
    "learning_rate": 0.001
  },
  {
    "episode": 10722,
    "reward": 85.32027,
    "length": 71,
    "time": 157604.699607,
    "actor_loss": -69.87199401855469,
    "critic_loss": 6.223409652709961,
    "ent_coef": 0.08630108833312988,
    "learning_rate": 0.001
  },
  {
    "episode": 10723,
    "reward": 87.202374,
    "length": 67,
    "time": 157616.299723,
    "actor_loss": -54.595970153808594,
    "critic_loss": 16.71592903137207,
    "ent_coef": 0.0846571996808052,
    "learning_rate": 0.001
  },
  {
    "episode": 10724,
    "reward": 87.961607,
    "length": 66,
    "time": 157628.32806,
    "actor_loss": -63.158729553222656,
    "critic_loss": 87.28224182128906,
    "ent_coef": 0.07986199110746384,
    "learning_rate": 0.001
  },
  {
    "episode": 10725,
    "reward": 87.51871,
    "length": 68,
    "time": 157640.035957,
    "actor_loss": -61.91107177734375,
    "critic_loss": 4.510274887084961,
    "ent_coef": 0.07640253007411957,
    "learning_rate": 0.001
  },
  {
    "episode": 10726,
    "reward": 90.231028,
    "length": 62,
    "time": 157651.223188,
    "actor_loss": -65.19680786132812,
    "critic_loss": 711.2308959960938,
    "ent_coef": 0.07705727964639664,
    "learning_rate": 0.001
  },
  {
    "episode": 10727,
    "reward": 89.086306,
    "length": 64,
    "time": 157662.608777,
    "actor_loss": -62.60441207885742,
    "critic_loss": 31.116329193115234,
    "ent_coef": 0.07972922921180725,
    "learning_rate": 0.001
  },
  {
    "episode": 10728,
    "reward": 88.892046,
    "length": 66,
    "time": 157675.881907,
    "actor_loss": -62.67620849609375,
    "critic_loss": 5.3535356521606445,
    "ent_coef": 0.08304180204868317,
    "learning_rate": 0.001
  },
  {
    "episode": 10729,
    "reward": 87.985873,
    "length": 67,
    "time": 157687.820655,
    "actor_loss": -60.66728210449219,
    "critic_loss": 3.071152925491333,
    "ent_coef": 0.08287187665700912,
    "learning_rate": 0.001
  },
  {
    "episode": 10730,
    "reward": 88.650247,
    "length": 65,
    "time": 157699.323093,
    "actor_loss": -59.704689025878906,
    "critic_loss": 4.2235941886901855,
    "ent_coef": 0.08186818659305573,
    "learning_rate": 0.001
  },
  {
    "episode": 10731,
    "reward": 89.257031,
    "length": 64,
    "time": 157711.065943,
    "actor_loss": -63.04943084716797,
    "critic_loss": 69.12139892578125,
    "ent_coef": 0.08452895283699036,
    "learning_rate": 0.001
  },
  {
    "episode": 10732,
    "reward": 87.924963,
    "length": 68,
    "time": 157725.367705,
    "actor_loss": -69.50498962402344,
    "critic_loss": 44.63678741455078,
    "ent_coef": 0.08965963870286942,
    "learning_rate": 0.001
  },
  {
    "episode": 10733,
    "reward": 87.546587,
    "length": 68,
    "time": 157738.953937,
    "actor_loss": -62.51435470581055,
    "critic_loss": 3.677192211151123,
    "ent_coef": 0.08644410967826843,
    "learning_rate": 0.001
  },
  {
    "episode": 10734,
    "reward": 88.999749,
    "length": 65,
    "time": 157751.609181,
    "actor_loss": -68.38706970214844,
    "critic_loss": 4.134008407592773,
    "ent_coef": 0.08778074383735657,
    "learning_rate": 0.001
  },
  {
    "episode": 10735,
    "reward": 87.809997,
    "length": 67,
    "time": 157764.363827,
    "actor_loss": -65.17060852050781,
    "critic_loss": 43.61931228637695,
    "ent_coef": 0.09359724074602127,
    "learning_rate": 0.001
  },
  {
    "episode": 10736,
    "reward": 86.859289,
    "length": 69,
    "time": 157777.693313,
    "actor_loss": -60.559967041015625,
    "critic_loss": 27.286766052246094,
    "ent_coef": 0.09220559895038605,
    "learning_rate": 0.001
  },
  {
    "episode": 10737,
    "reward": 89.183591,
    "length": 64,
    "time": 157789.467757,
    "actor_loss": -69.32070922851562,
    "critic_loss": 22.017160415649414,
    "ent_coef": 0.08896370977163315,
    "learning_rate": 0.001
  },
  {
    "episode": 10738,
    "reward": 89.282241,
    "length": 64,
    "time": 157802.730328,
    "actor_loss": -70.23955535888672,
    "critic_loss": 9.903132438659668,
    "ent_coef": 0.08951357007026672,
    "learning_rate": 0.001
  },
  {
    "episode": 10739,
    "reward": 90.232278,
    "length": 62,
    "time": 157814.434834,
    "actor_loss": -66.21757507324219,
    "critic_loss": 16.5488338470459,
    "ent_coef": 0.09223101288080215,
    "learning_rate": 0.001
  },
  {
    "episode": 10740,
    "reward": 88.504693,
    "length": 66,
    "time": 157827.075133,
    "actor_loss": -66.82148742675781,
    "critic_loss": 82.52745819091797,
    "ent_coef": 0.0935298278927803,
    "learning_rate": 0.001
  },
  {
    "episode": 10741,
    "reward": 90.059726,
    "length": 62,
    "time": 157840.276871,
    "actor_loss": -60.50566482543945,
    "critic_loss": 36.49974822998047,
    "ent_coef": 0.0935608297586441,
    "learning_rate": 0.001
  },
  {
    "episode": 10742,
    "reward": 89.335875,
    "length": 63,
    "time": 157854.766146,
    "actor_loss": -66.12799072265625,
    "critic_loss": 12.111912727355957,
    "ent_coef": 0.09115033596754074,
    "learning_rate": 0.001
  },
  {
    "episode": 10743,
    "reward": 88.618242,
    "length": 65,
    "time": 157868.351758,
    "actor_loss": -58.98231506347656,
    "critic_loss": 18.61425018310547,
    "ent_coef": 0.0969163253903389,
    "learning_rate": 0.001
  },
  {
    "episode": 10744,
    "reward": 90.380451,
    "length": 61,
    "time": 157879.298837,
    "actor_loss": -60.52865982055664,
    "critic_loss": 13.52566909790039,
    "ent_coef": 0.09723537415266037,
    "learning_rate": 0.001
  },
  {
    "episode": 10745,
    "reward": 89.753051,
    "length": 64,
    "time": 157893.928727,
    "actor_loss": -61.719871520996094,
    "critic_loss": 652.02001953125,
    "ent_coef": 0.10069432854652405,
    "learning_rate": 0.001
  },
  {
    "episode": 10746,
    "reward": 89.955895,
    "length": 63,
    "time": 157907.738297,
    "actor_loss": -69.65194702148438,
    "critic_loss": 20.346847534179688,
    "ent_coef": 0.10046935081481934,
    "learning_rate": 0.001
  },
  {
    "episode": 10747,
    "reward": 87.920983,
    "length": 66,
    "time": 157920.417694,
    "actor_loss": -65.80614471435547,
    "critic_loss": 5.294081211090088,
    "ent_coef": 0.09756004810333252,
    "learning_rate": 0.001
  },
  {
    "episode": 10748,
    "reward": 86.697547,
    "length": 68,
    "time": 157932.421862,
    "actor_loss": -66.37882995605469,
    "critic_loss": 4.998525619506836,
    "ent_coef": 0.09794945269823074,
    "learning_rate": 0.001
  },
  {
    "episode": 10749,
    "reward": 90.828014,
    "length": 62,
    "time": 157945.208913,
    "actor_loss": -60.89402770996094,
    "critic_loss": 3.3018574714660645,
    "ent_coef": 0.09524160623550415,
    "learning_rate": 0.001
  },
  {
    "episode": 10750,
    "reward": 82.940859,
    "length": 75,
    "time": 157958.835931,
    "actor_loss": -62.81009292602539,
    "critic_loss": 7.501863479614258,
    "ent_coef": 0.08556950837373734,
    "learning_rate": 0.001
  },
  {
    "episode": 10751,
    "reward": 87.1347,
    "length": 69,
    "time": 157973.437767,
    "actor_loss": -62.329803466796875,
    "critic_loss": 14.381489753723145,
    "ent_coef": 0.08201564848423004,
    "learning_rate": 0.001
  },
  {
    "episode": 10752,
    "reward": 86.944255,
    "length": 70,
    "time": 157989.470586,
    "actor_loss": -68.13383483886719,
    "critic_loss": 43.30473327636719,
    "ent_coef": 0.07664857059717178,
    "learning_rate": 0.001
  },
  {
    "episode": 10753,
    "reward": 85.315142,
    "length": 71,
    "time": 158004.44998,
    "actor_loss": -65.48356628417969,
    "critic_loss": 16.10371971130371,
    "ent_coef": 0.07209108769893646,
    "learning_rate": 0.001
  },
  {
    "episode": 10754,
    "reward": 85.207604,
    "length": 71,
    "time": 158016.738463,
    "actor_loss": -58.520652770996094,
    "critic_loss": 90.49488830566406,
    "ent_coef": 0.06739891320466995,
    "learning_rate": 0.001
  },
  {
    "episode": 10755,
    "reward": 87.377611,
    "length": 72,
    "time": 158030.040516,
    "actor_loss": -66.12020874023438,
    "critic_loss": 26.385343551635742,
    "ent_coef": 0.06804830580949783,
    "learning_rate": 0.001
  },
  {
    "episode": 10756,
    "reward": 88.244526,
    "length": 65,
    "time": 158044.637281,
    "actor_loss": -70.14945220947266,
    "critic_loss": 14.817422866821289,
    "ent_coef": 0.06756395101547241,
    "learning_rate": 0.001
  },
  {
    "episode": 10757,
    "reward": 87.901231,
    "length": 67,
    "time": 158059.694646,
    "actor_loss": -68.07472229003906,
    "critic_loss": 16.627620697021484,
    "ent_coef": 0.06548426300287247,
    "learning_rate": 0.001
  },
  {
    "episode": 10758,
    "reward": 85.111085,
    "length": 73,
    "time": 158072.245009,
    "actor_loss": -66.61700439453125,
    "critic_loss": 5.043094158172607,
    "ent_coef": 0.0606980100274086,
    "learning_rate": 0.001
  },
  {
    "episode": 10759,
    "reward": 80.83171,
    "length": 78,
    "time": 158085.702362,
    "actor_loss": -62.95720672607422,
    "critic_loss": 32.64950942993164,
    "ent_coef": 0.057146135717630386,
    "learning_rate": 0.001
  },
  {
    "episode": 10760,
    "reward": 90.94935,
    "length": 61,
    "time": 158099.603005,
    "actor_loss": -63.67985534667969,
    "critic_loss": 38.66156768798828,
    "ent_coef": 0.061692461371421814,
    "learning_rate": 0.001
  },
  {
    "episode": 10761,
    "reward": 89.2516,
    "length": 64,
    "time": 158111.32114,
    "actor_loss": -65.6974868774414,
    "critic_loss": 4.380622386932373,
    "ent_coef": 0.06652459502220154,
    "learning_rate": 0.001
  },
  {
    "episode": 10762,
    "reward": 88.390984,
    "length": 66,
    "time": 158124.095873,
    "actor_loss": -64.16519927978516,
    "critic_loss": 11.228572845458984,
    "ent_coef": 0.06614511460065842,
    "learning_rate": 0.001
  },
  {
    "episode": 10763,
    "reward": 89.324482,
    "length": 65,
    "time": 158136.047603,
    "actor_loss": -61.69218444824219,
    "critic_loss": 11.270021438598633,
    "ent_coef": 0.06772463023662567,
    "learning_rate": 0.001
  },
  {
    "episode": 10764,
    "reward": 89.274339,
    "length": 64,
    "time": 158149.34328,
    "actor_loss": -72.5313949584961,
    "critic_loss": 10.580657958984375,
    "ent_coef": 0.06859742105007172,
    "learning_rate": 0.001
  },
  {
    "episode": 10765,
    "reward": 90.868376,
    "length": 62,
    "time": 158162.388772,
    "actor_loss": -67.96401977539062,
    "critic_loss": 54.12321472167969,
    "ent_coef": 0.07065445929765701,
    "learning_rate": 0.001
  },
  {
    "episode": 10766,
    "reward": 89.677118,
    "length": 63,
    "time": 158174.444696,
    "actor_loss": -64.43303680419922,
    "critic_loss": 14.30698013305664,
    "ent_coef": 0.07512611150741577,
    "learning_rate": 0.001
  },
  {
    "episode": 10767,
    "reward": 91.626393,
    "length": 60,
    "time": 158186.113974,
    "actor_loss": -71.7007064819336,
    "critic_loss": 7.218426704406738,
    "ent_coef": 0.08309956640005112,
    "learning_rate": 0.001
  },
  {
    "episode": 10768,
    "reward": 91.05458,
    "length": 62,
    "time": 158197.171453,
    "actor_loss": -67.74785614013672,
    "critic_loss": 16.838253021240234,
    "ent_coef": 0.0877637192606926,
    "learning_rate": 0.001
  },
  {
    "episode": 10769,
    "reward": 90.624641,
    "length": 62,
    "time": 158208.65433,
    "actor_loss": -60.08877944946289,
    "critic_loss": 3.6625912189483643,
    "ent_coef": 0.08786377310752869,
    "learning_rate": 0.001
  },
  {
    "episode": 10770,
    "reward": 90.419217,
    "length": 62,
    "time": 158225.624842,
    "actor_loss": -62.2062873840332,
    "critic_loss": 43.661590576171875,
    "ent_coef": 0.09047999233007431,
    "learning_rate": 0.001
  },
  {
    "episode": 10771,
    "reward": 89.047287,
    "length": 65,
    "time": 158239.899987,
    "actor_loss": -63.42826843261719,
    "critic_loss": 2.428964376449585,
    "ent_coef": 0.0896638035774231,
    "learning_rate": 0.001
  },
  {
    "episode": 10772,
    "reward": 89.406828,
    "length": 68,
    "time": 158252.09515,
    "actor_loss": -61.40742492675781,
    "critic_loss": 18.0709228515625,
    "ent_coef": 0.08637510985136032,
    "learning_rate": 0.001
  },
  {
    "episode": 10773,
    "reward": 87.238236,
    "length": 68,
    "time": 158263.952676,
    "actor_loss": -62.32054138183594,
    "critic_loss": 51.387611389160156,
    "ent_coef": 0.08159427344799042,
    "learning_rate": 0.001
  },
  {
    "episode": 10774,
    "reward": 87.034998,
    "length": 69,
    "time": 158279.137655,
    "actor_loss": -63.42407989501953,
    "critic_loss": 326.1982116699219,
    "ent_coef": 0.07616854459047318,
    "learning_rate": 0.001
  },
  {
    "episode": 10775,
    "reward": 84.826806,
    "length": 72,
    "time": 158291.407098,
    "actor_loss": -65.042724609375,
    "critic_loss": 69.32966613769531,
    "ent_coef": 0.07228634506464005,
    "learning_rate": 0.001
  },
  {
    "episode": 10776,
    "reward": 90.316087,
    "length": 63,
    "time": 158302.462957,
    "actor_loss": -65.57582092285156,
    "critic_loss": 9.234598159790039,
    "ent_coef": 0.07342787086963654,
    "learning_rate": 0.001
  },
  {
    "episode": 10777,
    "reward": 91.206799,
    "length": 61,
    "time": 158314.058772,
    "actor_loss": -57.242164611816406,
    "critic_loss": 77.29901123046875,
    "ent_coef": 0.07784560322761536,
    "learning_rate": 0.001
  },
  {
    "episode": 10778,
    "reward": 91.365416,
    "length": 62,
    "time": 158327.833719,
    "actor_loss": -63.177757263183594,
    "critic_loss": 4.042418479919434,
    "ent_coef": 0.08012705296278,
    "learning_rate": 0.001
  },
  {
    "episode": 10779,
    "reward": 90.155204,
    "length": 62,
    "time": 158338.913855,
    "actor_loss": -64.32491302490234,
    "critic_loss": 85.37104797363281,
    "ent_coef": 0.08394060283899307,
    "learning_rate": 0.001
  },
  {
    "episode": 10780,
    "reward": 91.559674,
    "length": 60,
    "time": 158351.307459,
    "actor_loss": -60.77537536621094,
    "critic_loss": 18.70408058166504,
    "ent_coef": 0.09522686898708344,
    "learning_rate": 0.001
  },
  {
    "episode": 10781,
    "reward": 92.083625,
    "length": 59,
    "time": 158363.438082,
    "actor_loss": -68.67506408691406,
    "critic_loss": 36.35340881347656,
    "ent_coef": 0.0988459661602974,
    "learning_rate": 0.001
  },
  {
    "episode": 10782,
    "reward": 91.168987,
    "length": 61,
    "time": 158374.31418,
    "actor_loss": -63.45671844482422,
    "critic_loss": 5.06953239440918,
    "ent_coef": 0.10168470442295074,
    "learning_rate": 0.001
  },
  {
    "episode": 10783,
    "reward": 85.998287,
    "length": 67,
    "time": 158387.924092,
    "actor_loss": -63.731056213378906,
    "critic_loss": 6.108954429626465,
    "ent_coef": 0.1029440313577652,
    "learning_rate": 0.001
  },
  {
    "episode": 10784,
    "reward": 86.085318,
    "length": 68,
    "time": 158399.63001,
    "actor_loss": -64.5517578125,
    "critic_loss": 19.66683006286621,
    "ent_coef": 0.10574968159198761,
    "learning_rate": 0.001
  },
  {
    "episode": 10785,
    "reward": 89.736661,
    "length": 64,
    "time": 158411.564934,
    "actor_loss": -65.0095443725586,
    "critic_loss": 49.57054138183594,
    "ent_coef": 0.10273373872041702,
    "learning_rate": 0.001
  },
  {
    "episode": 10786,
    "reward": 80.243762,
    "length": 78,
    "time": 158425.549316,
    "actor_loss": -63.4185676574707,
    "critic_loss": 5.228335380554199,
    "ent_coef": 0.09799233824014664,
    "learning_rate": 0.001
  },
  {
    "episode": 10787,
    "reward": 89.496599,
    "length": 65,
    "time": 158440.541241,
    "actor_loss": -69.00688934326172,
    "critic_loss": 19.13536834716797,
    "ent_coef": 0.09417064487934113,
    "learning_rate": 0.001
  },
  {
    "episode": 10788,
    "reward": 91.169449,
    "length": 61,
    "time": 158451.457172,
    "actor_loss": -64.2038345336914,
    "critic_loss": 7.972873687744141,
    "ent_coef": 0.09182550013065338,
    "learning_rate": 0.001
  },
  {
    "episode": 10789,
    "reward": 88.863985,
    "length": 67,
    "time": 158467.078456,
    "actor_loss": -65.52765655517578,
    "critic_loss": 2.9065568447113037,
    "ent_coef": 0.0918135866522789,
    "learning_rate": 0.001
  },
  {
    "episode": 10790,
    "reward": 91.128502,
    "length": 62,
    "time": 158478.153956,
    "actor_loss": -66.33876037597656,
    "critic_loss": 5.60292387008667,
    "ent_coef": 0.09179594367742538,
    "learning_rate": 0.001
  },
  {
    "episode": 10791,
    "reward": 90.320507,
    "length": 63,
    "time": 158490.523154,
    "actor_loss": -69.20260620117188,
    "critic_loss": 161.3190460205078,
    "ent_coef": 0.08974278718233109,
    "learning_rate": 0.001
  },
  {
    "episode": 10792,
    "reward": 90.360403,
    "length": 62,
    "time": 158502.009424,
    "actor_loss": -65.1633071899414,
    "critic_loss": 10.129852294921875,
    "ent_coef": 0.08706820756196976,
    "learning_rate": 0.001
  },
  {
    "episode": 10793,
    "reward": 91.38522,
    "length": 60,
    "time": 158514.938426,
    "actor_loss": -58.404109954833984,
    "critic_loss": 7.901262283325195,
    "ent_coef": 0.09009870141744614,
    "learning_rate": 0.001
  },
  {
    "episode": 10794,
    "reward": 87.937705,
    "length": 66,
    "time": 158530.636446,
    "actor_loss": -74.69099426269531,
    "critic_loss": 8.11241340637207,
    "ent_coef": 0.09040864557027817,
    "learning_rate": 0.001
  },
  {
    "episode": 10795,
    "reward": 90.857295,
    "length": 62,
    "time": 158545.174801,
    "actor_loss": -63.51984786987305,
    "critic_loss": 6.703226566314697,
    "ent_coef": 0.09051781892776489,
    "learning_rate": 0.001
  },
  {
    "episode": 10796,
    "reward": 90.831553,
    "length": 61,
    "time": 158556.705566,
    "actor_loss": -62.39975357055664,
    "critic_loss": 53.20545959472656,
    "ent_coef": 0.08972898870706558,
    "learning_rate": 0.001
  },
  {
    "episode": 10797,
    "reward": 90.9724,
    "length": 61,
    "time": 158567.688917,
    "actor_loss": -62.46782684326172,
    "critic_loss": 8.699930191040039,
    "ent_coef": 0.09210948646068573,
    "learning_rate": 0.001
  },
  {
    "episode": 10798,
    "reward": 91.344697,
    "length": 61,
    "time": 158578.853565,
    "actor_loss": -64.0215835571289,
    "critic_loss": 6.282880783081055,
    "ent_coef": 0.09323498606681824,
    "learning_rate": 0.001
  },
  {
    "episode": 10799,
    "reward": 90.575331,
    "length": 63,
    "time": 158591.051097,
    "actor_loss": -67.38569641113281,
    "critic_loss": 13.770143508911133,
    "ent_coef": 0.09348268061876297,
    "learning_rate": 0.001
  },
  {
    "episode": 10800,
    "reward": 90.541252,
    "length": 64,
    "time": 158602.419462,
    "actor_loss": -59.88207244873047,
    "critic_loss": 5.625836372375488,
    "ent_coef": 0.09205908328294754,
    "learning_rate": 0.001
  },
  {
    "episode": 10801,
    "reward": 90.662851,
    "length": 61,
    "time": 158613.967994,
    "actor_loss": -63.0628776550293,
    "critic_loss": 27.63105010986328,
    "ent_coef": 0.09306655079126358,
    "learning_rate": 0.001
  },
  {
    "episode": 10802,
    "reward": 90.335872,
    "length": 64,
    "time": 158625.190098,
    "actor_loss": -62.728145599365234,
    "critic_loss": 59.05866241455078,
    "ent_coef": 0.0935593768954277,
    "learning_rate": 0.001
  },
  {
    "episode": 10803,
    "reward": 82.777617,
    "length": 68,
    "time": 158637.3674,
    "actor_loss": -67.57012176513672,
    "critic_loss": 2.4424545764923096,
    "ent_coef": 0.09223730117082596,
    "learning_rate": 0.001
  },
  {
    "episode": 10804,
    "reward": 90.157876,
    "length": 63,
    "time": 158653.317105,
    "actor_loss": -70.02203369140625,
    "critic_loss": 28.537763595581055,
    "ent_coef": 0.08911918848752975,
    "learning_rate": 0.001
  },
  {
    "episode": 10805,
    "reward": 86.937556,
    "length": 67,
    "time": 158668.767294,
    "actor_loss": -64.35751342773438,
    "critic_loss": 49.5030517578125,
    "ent_coef": 0.08230740576982498,
    "learning_rate": 0.001
  },
  {
    "episode": 10806,
    "reward": 90.950808,
    "length": 62,
    "time": 158681.513404,
    "actor_loss": -65.0797119140625,
    "critic_loss": 8.152616500854492,
    "ent_coef": 0.07956066727638245,
    "learning_rate": 0.001
  },
  {
    "episode": 10807,
    "reward": 91.081012,
    "length": 62,
    "time": 158694.499989,
    "actor_loss": -64.80264282226562,
    "critic_loss": 3.003314971923828,
    "ent_coef": 0.07628733664751053,
    "learning_rate": 0.001
  },
  {
    "episode": 10808,
    "reward": 90.137265,
    "length": 61,
    "time": 158705.793507,
    "actor_loss": -67.62316131591797,
    "critic_loss": 2.7439887523651123,
    "ent_coef": 0.07526702433824539,
    "learning_rate": 0.001
  },
  {
    "episode": 10809,
    "reward": 89.798167,
    "length": 64,
    "time": 158719.338362,
    "actor_loss": -65.45524597167969,
    "critic_loss": 3.296203136444092,
    "ent_coef": 0.07290665805339813,
    "learning_rate": 0.001
  },
  {
    "episode": 10810,
    "reward": 90.793681,
    "length": 62,
    "time": 158731.558619,
    "actor_loss": -65.44200134277344,
    "critic_loss": 6.2556939125061035,
    "ent_coef": 0.07349658757448196,
    "learning_rate": 0.001
  },
  {
    "episode": 10811,
    "reward": 86.051562,
    "length": 70,
    "time": 158744.445059,
    "actor_loss": -63.00648880004883,
    "critic_loss": 22.119733810424805,
    "ent_coef": 0.07308075577020645,
    "learning_rate": 0.001
  },
  {
    "episode": 10812,
    "reward": 88.089419,
    "length": 67,
    "time": 158758.813391,
    "actor_loss": -65.41146850585938,
    "critic_loss": 110.46609497070312,
    "ent_coef": 0.07204803079366684,
    "learning_rate": 0.001
  },
  {
    "episode": 10813,
    "reward": 91.177747,
    "length": 60,
    "time": 158771.620664,
    "actor_loss": -73.56539916992188,
    "critic_loss": 35.025230407714844,
    "ent_coef": 0.07389737665653229,
    "learning_rate": 0.001
  },
  {
    "episode": 10814,
    "reward": -158.331915,
    "length": 149,
    "time": 158794.407162,
    "actor_loss": -68.79920959472656,
    "critic_loss": 155.86123657226562,
    "ent_coef": 0.07537849992513657,
    "learning_rate": 0.001
  },
  {
    "episode": 10815,
    "reward": 88.726967,
    "length": 64,
    "time": 158809.36184,
    "actor_loss": -65.794677734375,
    "critic_loss": 14.569880485534668,
    "ent_coef": 0.07665770500898361,
    "learning_rate": 0.001
  },
  {
    "episode": 10816,
    "reward": 91.317316,
    "length": 61,
    "time": 158821.436105,
    "actor_loss": -69.76699829101562,
    "critic_loss": 48.508026123046875,
    "ent_coef": 0.07926394790410995,
    "learning_rate": 0.001
  },
  {
    "episode": 10817,
    "reward": 91.553916,
    "length": 60,
    "time": 158836.146265,
    "actor_loss": -60.459693908691406,
    "critic_loss": 8.751577377319336,
    "ent_coef": 0.08229033648967743,
    "learning_rate": 0.001
  },
  {
    "episode": 10818,
    "reward": 91.600957,
    "length": 59,
    "time": 158846.84112,
    "actor_loss": -69.64556884765625,
    "critic_loss": 3.208733081817627,
    "ent_coef": 0.08575762808322906,
    "learning_rate": 0.001
  },
  {
    "episode": 10819,
    "reward": 91.563188,
    "length": 61,
    "time": 158858.202282,
    "actor_loss": -67.7413330078125,
    "critic_loss": 18.149978637695312,
    "ent_coef": 0.08730803430080414,
    "learning_rate": 0.001
  },
  {
    "episode": 10820,
    "reward": 89.084947,
    "length": 66,
    "time": 158869.654181,
    "actor_loss": -64.87628173828125,
    "critic_loss": 10.757466316223145,
    "ent_coef": 0.08898738026618958,
    "learning_rate": 0.001
  },
  {
    "episode": 10821,
    "reward": 90.409939,
    "length": 63,
    "time": 158882.839291,
    "actor_loss": -69.31135559082031,
    "critic_loss": 25.777347564697266,
    "ent_coef": 0.08538103103637695,
    "learning_rate": 0.001
  },
  {
    "episode": 10822,
    "reward": 90.869988,
    "length": 60,
    "time": 158894.031262,
    "actor_loss": -70.77226257324219,
    "critic_loss": 24.923439025878906,
    "ent_coef": 0.09100869297981262,
    "learning_rate": 0.001
  },
  {
    "episode": 10823,
    "reward": 90.61323,
    "length": 62,
    "time": 158905.101721,
    "actor_loss": -68.21236419677734,
    "critic_loss": 40.0023193359375,
    "ent_coef": 0.09312009066343307,
    "learning_rate": 0.001
  },
  {
    "episode": 10824,
    "reward": 89.195001,
    "length": 64,
    "time": 158916.417545,
    "actor_loss": -71.81900787353516,
    "critic_loss": 9.034038543701172,
    "ent_coef": 0.09101804345846176,
    "learning_rate": 0.001
  },
  {
    "episode": 10825,
    "reward": 91.010809,
    "length": 62,
    "time": 158927.831391,
    "actor_loss": -66.83341979980469,
    "critic_loss": 5.014041900634766,
    "ent_coef": 0.09071443974971771,
    "learning_rate": 0.001
  },
  {
    "episode": 10826,
    "reward": 90.959861,
    "length": 60,
    "time": 158941.039572,
    "actor_loss": -66.77584838867188,
    "critic_loss": 3.1588199138641357,
    "ent_coef": 0.09027937799692154,
    "learning_rate": 0.001
  },
  {
    "episode": 10827,
    "reward": 89.189831,
    "length": 68,
    "time": 158953.756289,
    "actor_loss": -63.66114044189453,
    "critic_loss": 97.86087799072266,
    "ent_coef": 0.09243272244930267,
    "learning_rate": 0.001
  },
  {
    "episode": 10828,
    "reward": 87.738942,
    "length": 70,
    "time": 158966.01292,
    "actor_loss": -64.85922241210938,
    "critic_loss": 8.116096496582031,
    "ent_coef": 0.09063633531332016,
    "learning_rate": 0.001
  },
  {
    "episode": 10829,
    "reward": 89.920451,
    "length": 65,
    "time": 158978.868763,
    "actor_loss": -64.8936767578125,
    "critic_loss": 271.3249816894531,
    "ent_coef": 0.08456912636756897,
    "learning_rate": 0.001
  },
  {
    "episode": 10830,
    "reward": 87.022537,
    "length": 69,
    "time": 158990.978089,
    "actor_loss": -61.399497985839844,
    "critic_loss": 9.321237564086914,
    "ent_coef": 0.07893871515989304,
    "learning_rate": 0.001
  },
  {
    "episode": 10831,
    "reward": 91.050393,
    "length": 61,
    "time": 159002.308478,
    "actor_loss": -67.02347564697266,
    "critic_loss": 17.506309509277344,
    "ent_coef": 0.07645083963871002,
    "learning_rate": 0.001
  },
  {
    "episode": 10832,
    "reward": 89.565251,
    "length": 63,
    "time": 159013.525548,
    "actor_loss": -63.87657165527344,
    "critic_loss": 58.312950134277344,
    "ent_coef": 0.07772142440080643,
    "learning_rate": 0.001
  },
  {
    "episode": 10833,
    "reward": 89.672105,
    "length": 62,
    "time": 159026.367715,
    "actor_loss": -69.32715606689453,
    "critic_loss": 2.913933038711548,
    "ent_coef": 0.08093006163835526,
    "learning_rate": 0.001
  },
  {
    "episode": 10834,
    "reward": 91.266815,
    "length": 60,
    "time": 159038.350788,
    "actor_loss": -69.57345581054688,
    "critic_loss": 4.2750115394592285,
    "ent_coef": 0.08294907212257385,
    "learning_rate": 0.001
  },
  {
    "episode": 10835,
    "reward": 90.540747,
    "length": 64,
    "time": 159051.964752,
    "actor_loss": -69.20094299316406,
    "critic_loss": 53.093505859375,
    "ent_coef": 0.08255179226398468,
    "learning_rate": 0.001
  },
  {
    "episode": 10836,
    "reward": 88.190676,
    "length": 66,
    "time": 159067.659337,
    "actor_loss": -62.47016143798828,
    "critic_loss": 648.9324951171875,
    "ent_coef": 0.08065924793481827,
    "learning_rate": 0.001
  },
  {
    "episode": 10837,
    "reward": 88.922584,
    "length": 65,
    "time": 159080.958953,
    "actor_loss": -64.4510498046875,
    "critic_loss": 26.508953094482422,
    "ent_coef": 0.07817372679710388,
    "learning_rate": 0.001
  },
  {
    "episode": 10838,
    "reward": 83.148291,
    "length": 88,
    "time": 159095.450989,
    "actor_loss": -61.85598373413086,
    "critic_loss": 3.4940690994262695,
    "ent_coef": 0.0727703645825386,
    "learning_rate": 0.001
  },
  {
    "episode": 10839,
    "reward": 83.326263,
    "length": 77,
    "time": 159109.470577,
    "actor_loss": -63.04694747924805,
    "critic_loss": 28.3775691986084,
    "ent_coef": 0.06740494072437286,
    "learning_rate": 0.001
  },
  {
    "episode": 10840,
    "reward": 84.361325,
    "length": 72,
    "time": 159122.327377,
    "actor_loss": -61.76641845703125,
    "critic_loss": 4.469176292419434,
    "ent_coef": 0.06202087923884392,
    "learning_rate": 0.001
  },
  {
    "episode": 10841,
    "reward": 88.737155,
    "length": 65,
    "time": 159134.030949,
    "actor_loss": -64.81564331054688,
    "critic_loss": 27.86456298828125,
    "ent_coef": 0.06225594878196716,
    "learning_rate": 0.001
  },
  {
    "episode": 10842,
    "reward": 88.096462,
    "length": 66,
    "time": 159148.769389,
    "actor_loss": -67.36219787597656,
    "critic_loss": 8.661776542663574,
    "ent_coef": 0.06409775465726852,
    "learning_rate": 0.001
  },
  {
    "episode": 10843,
    "reward": 86.12173,
    "length": 69,
    "time": 159163.868361,
    "actor_loss": -73.39736938476562,
    "critic_loss": 7.6641082763671875,
    "ent_coef": 0.06455507129430771,
    "learning_rate": 0.001
  },
  {
    "episode": 10844,
    "reward": 86.935693,
    "length": 67,
    "time": 159176.073254,
    "actor_loss": -62.867828369140625,
    "critic_loss": 20.078445434570312,
    "ent_coef": 0.06929589062929153,
    "learning_rate": 0.001
  },
  {
    "episode": 10845,
    "reward": 82.746567,
    "length": 73,
    "time": 159189.995486,
    "actor_loss": -64.94203186035156,
    "critic_loss": 44.41876220703125,
    "ent_coef": 0.06889312714338303,
    "learning_rate": 0.001
  },
  {
    "episode": 10846,
    "reward": 89.72161,
    "length": 64,
    "time": 159204.762015,
    "actor_loss": -62.396392822265625,
    "critic_loss": 4.040737152099609,
    "ent_coef": 0.06760533154010773,
    "learning_rate": 0.001
  },
  {
    "episode": 10847,
    "reward": 87.24673,
    "length": 68,
    "time": 159216.717593,
    "actor_loss": -63.35709762573242,
    "critic_loss": 3.919200897216797,
    "ent_coef": 0.07004374265670776,
    "learning_rate": 0.001
  },
  {
    "episode": 10848,
    "reward": 87.93097,
    "length": 66,
    "time": 159231.217805,
    "actor_loss": -64.22510528564453,
    "critic_loss": 4.238994598388672,
    "ent_coef": 0.07507073879241943,
    "learning_rate": 0.001
  },
  {
    "episode": 10849,
    "reward": 89.525204,
    "length": 63,
    "time": 159242.362628,
    "actor_loss": -56.03791809082031,
    "critic_loss": 68.9122543334961,
    "ent_coef": 0.07825577259063721,
    "learning_rate": 0.001
  },
  {
    "episode": 10850,
    "reward": 89.732882,
    "length": 63,
    "time": 159256.286686,
    "actor_loss": -67.83895874023438,
    "critic_loss": 26.976459503173828,
    "ent_coef": 0.07971934229135513,
    "learning_rate": 0.001
  },
  {
    "episode": 10851,
    "reward": 91.578062,
    "length": 60,
    "time": 159269.632748,
    "actor_loss": -65.33089447021484,
    "critic_loss": 109.35552215576172,
    "ent_coef": 0.08587249368429184,
    "learning_rate": 0.001
  },
  {
    "episode": 10852,
    "reward": 83.157088,
    "length": 89,
    "time": 159284.071339,
    "actor_loss": -65.97029113769531,
    "critic_loss": 12.955986022949219,
    "ent_coef": 0.08988823741674423,
    "learning_rate": 0.001
  },
  {
    "episode": 10853,
    "reward": 90.861103,
    "length": 62,
    "time": 159296.600971,
    "actor_loss": -67.5610580444336,
    "critic_loss": 15.163262367248535,
    "ent_coef": 0.09302417933940887,
    "learning_rate": 0.001
  },
  {
    "episode": 10854,
    "reward": 90.303044,
    "length": 62,
    "time": 159308.516998,
    "actor_loss": -72.28396606445312,
    "critic_loss": 116.72067260742188,
    "ent_coef": 0.0954521968960762,
    "learning_rate": 0.001
  },
  {
    "episode": 10855,
    "reward": 69.394526,
    "length": 96,
    "time": 159324.007647,
    "actor_loss": -66.3228759765625,
    "critic_loss": 13.931949615478516,
    "ent_coef": 0.09111437946557999,
    "learning_rate": 0.001
  },
  {
    "episode": 10856,
    "reward": 87.321249,
    "length": 67,
    "time": 159337.758911,
    "actor_loss": -59.48454284667969,
    "critic_loss": 6.796233654022217,
    "ent_coef": 0.09283968061208725,
    "learning_rate": 0.001
  },
  {
    "episode": 10857,
    "reward": 89.357684,
    "length": 66,
    "time": 159349.673069,
    "actor_loss": -62.77329635620117,
    "critic_loss": 26.189373016357422,
    "ent_coef": 0.09693890064954758,
    "learning_rate": 0.001
  },
  {
    "episode": 10858,
    "reward": 91.331714,
    "length": 61,
    "time": 159361.049926,
    "actor_loss": -63.61613464355469,
    "critic_loss": 65.13833618164062,
    "ent_coef": 0.10162331163883209,
    "learning_rate": 0.001
  },
  {
    "episode": 10859,
    "reward": 87.269401,
    "length": 63,
    "time": 159373.158666,
    "actor_loss": -64.84654235839844,
    "critic_loss": 2.847553014755249,
    "ent_coef": 0.10277026146650314,
    "learning_rate": 0.001
  },
  {
    "episode": 10860,
    "reward": 81.010178,
    "length": 85,
    "time": 159387.983141,
    "actor_loss": -63.29542541503906,
    "critic_loss": 28.927419662475586,
    "ent_coef": 0.10168863087892532,
    "learning_rate": 0.001
  },
  {
    "episode": 10861,
    "reward": 90.450421,
    "length": 63,
    "time": 159399.606649,
    "actor_loss": -63.98579406738281,
    "critic_loss": 31.558135986328125,
    "ent_coef": 0.09684357792139053,
    "learning_rate": 0.001
  },
  {
    "episode": 10862,
    "reward": 90.063831,
    "length": 67,
    "time": 159413.072304,
    "actor_loss": -59.109619140625,
    "critic_loss": 42.186119079589844,
    "ent_coef": 0.09786228835582733,
    "learning_rate": 0.001
  },
  {
    "episode": 10863,
    "reward": 89.608971,
    "length": 64,
    "time": 159424.558147,
    "actor_loss": -63.50433349609375,
    "critic_loss": 7.673315525054932,
    "ent_coef": 0.09283772855997086,
    "learning_rate": 0.001
  },
  {
    "episode": 10864,
    "reward": 89.722247,
    "length": 65,
    "time": 159437.938147,
    "actor_loss": -65.38763427734375,
    "critic_loss": 87.65711975097656,
    "ent_coef": 0.08791347593069077,
    "learning_rate": 0.001
  },
  {
    "episode": 10865,
    "reward": 89.894323,
    "length": 64,
    "time": 159449.756333,
    "actor_loss": -64.14654541015625,
    "critic_loss": 605.85595703125,
    "ent_coef": 0.08451057970523834,
    "learning_rate": 0.001
  },
  {
    "episode": 10866,
    "reward": 90.907421,
    "length": 61,
    "time": 159463.093003,
    "actor_loss": -63.852012634277344,
    "critic_loss": 17.152324676513672,
    "ent_coef": 0.08781116455793381,
    "learning_rate": 0.001
  },
  {
    "episode": 10867,
    "reward": 91.648019,
    "length": 61,
    "time": 159474.403417,
    "actor_loss": -57.867645263671875,
    "critic_loss": 48.08451461791992,
    "ent_coef": 0.09129733592271805,
    "learning_rate": 0.001
  },
  {
    "episode": 10868,
    "reward": 90.828469,
    "length": 61,
    "time": 159487.131582,
    "actor_loss": -66.90843200683594,
    "critic_loss": 10.215581893920898,
    "ent_coef": 0.09439360350370407,
    "learning_rate": 0.001
  },
  {
    "episode": 10869,
    "reward": 90.850737,
    "length": 63,
    "time": 159498.311655,
    "actor_loss": -65.0919189453125,
    "critic_loss": 3.27154541015625,
    "ent_coef": 0.09500764310359955,
    "learning_rate": 0.001
  },
  {
    "episode": 10870,
    "reward": 89.914926,
    "length": 62,
    "time": 159510.604945,
    "actor_loss": -66.38511657714844,
    "critic_loss": 8.59591007232666,
    "ent_coef": 0.097260020673275,
    "learning_rate": 0.001
  },
  {
    "episode": 10871,
    "reward": 90.937294,
    "length": 61,
    "time": 159522.567153,
    "actor_loss": -62.78859329223633,
    "critic_loss": 6.257819175720215,
    "ent_coef": 0.09834215044975281,
    "learning_rate": 0.001
  },
  {
    "episode": 10872,
    "reward": 88.095019,
    "length": 67,
    "time": 159536.100575,
    "actor_loss": -61.826900482177734,
    "critic_loss": 62.49518585205078,
    "ent_coef": 0.09413813799619675,
    "learning_rate": 0.001
  },
  {
    "episode": 10873,
    "reward": 83.124265,
    "length": 74,
    "time": 159551.759458,
    "actor_loss": -72.33860778808594,
    "critic_loss": 4.6028642654418945,
    "ent_coef": 0.09293021261692047,
    "learning_rate": 0.001
  },
  {
    "episode": 10874,
    "reward": 90.578862,
    "length": 62,
    "time": 159563.0618,
    "actor_loss": -67.75518035888672,
    "critic_loss": 13.515484809875488,
    "ent_coef": 0.09495282173156738,
    "learning_rate": 0.001
  },
  {
    "episode": 10875,
    "reward": 89.687087,
    "length": 64,
    "time": 159574.447483,
    "actor_loss": -62.01287078857422,
    "critic_loss": 32.02546691894531,
    "ent_coef": 0.09844373166561127,
    "learning_rate": 0.001
  },
  {
    "episode": 10876,
    "reward": 90.166959,
    "length": 62,
    "time": 159586.261175,
    "actor_loss": -67.23895263671875,
    "critic_loss": 124.10690307617188,
    "ent_coef": 0.0978589728474617,
    "learning_rate": 0.001
  },
  {
    "episode": 10877,
    "reward": 89.484111,
    "length": 64,
    "time": 159601.443248,
    "actor_loss": -63.68806457519531,
    "critic_loss": 18.838359832763672,
    "ent_coef": 0.09550678730010986,
    "learning_rate": 0.001
  },
  {
    "episode": 10878,
    "reward": 82.916724,
    "length": 76,
    "time": 159614.949445,
    "actor_loss": -69.85113525390625,
    "critic_loss": 4.90351676940918,
    "ent_coef": 0.08707989752292633,
    "learning_rate": 0.001
  },
  {
    "episode": 10879,
    "reward": 87.695818,
    "length": 67,
    "time": 159626.921757,
    "actor_loss": -65.75299072265625,
    "critic_loss": 7.227450370788574,
    "ent_coef": 0.08567836135625839,
    "learning_rate": 0.001
  },
  {
    "episode": 10880,
    "reward": 89.306694,
    "length": 64,
    "time": 159640.372991,
    "actor_loss": -63.16935729980469,
    "critic_loss": 41.11626434326172,
    "ent_coef": 0.08818015456199646,
    "learning_rate": 0.001
  },
  {
    "episode": 10881,
    "reward": 90.272806,
    "length": 62,
    "time": 159651.956664,
    "actor_loss": -70.04220581054688,
    "critic_loss": 15.008034706115723,
    "ent_coef": 0.08800196647644043,
    "learning_rate": 0.001
  },
  {
    "episode": 10882,
    "reward": 90.659249,
    "length": 61,
    "time": 159664.094989,
    "actor_loss": -64.04452514648438,
    "critic_loss": 7.265307903289795,
    "ent_coef": 0.08925242722034454,
    "learning_rate": 0.001
  },
  {
    "episode": 10883,
    "reward": 89.709078,
    "length": 64,
    "time": 159679.379635,
    "actor_loss": -66.87208557128906,
    "critic_loss": 7.325299263000488,
    "ent_coef": 0.08772001415491104,
    "learning_rate": 0.001
  },
  {
    "episode": 10884,
    "reward": 90.319594,
    "length": 63,
    "time": 159694.360702,
    "actor_loss": -70.95562744140625,
    "critic_loss": 29.59117317199707,
    "ent_coef": 0.09011828899383545,
    "learning_rate": 0.001
  },
  {
    "episode": 10885,
    "reward": 89.78992,
    "length": 63,
    "time": 159709.316828,
    "actor_loss": -71.2075424194336,
    "critic_loss": 11.732210159301758,
    "ent_coef": 0.09287089854478836,
    "learning_rate": 0.001
  },
  {
    "episode": 10886,
    "reward": 90.704948,
    "length": 62,
    "time": 159721.187205,
    "actor_loss": -65.56343078613281,
    "critic_loss": 16.386693954467773,
    "ent_coef": 0.09060381352901459,
    "learning_rate": 0.001
  },
  {
    "episode": 10887,
    "reward": 91.332692,
    "length": 61,
    "time": 159732.21376,
    "actor_loss": -67.59833526611328,
    "critic_loss": 31.412193298339844,
    "ent_coef": 0.08964743465185165,
    "learning_rate": 0.001
  },
  {
    "episode": 10888,
    "reward": 89.681895,
    "length": 64,
    "time": 159743.721065,
    "actor_loss": -63.31424331665039,
    "critic_loss": 4.492406368255615,
    "ent_coef": 0.0852411538362503,
    "learning_rate": 0.001
  },
  {
    "episode": 10889,
    "reward": 70.240417,
    "length": 94,
    "time": 159759.700829,
    "actor_loss": -63.051918029785156,
    "critic_loss": 28.51073455810547,
    "ent_coef": 0.07876662164926529,
    "learning_rate": 0.001
  },
  {
    "episode": 10890,
    "reward": 89.910773,
    "length": 63,
    "time": 159771.041308,
    "actor_loss": -60.58375549316406,
    "critic_loss": 18.780168533325195,
    "ent_coef": 0.07812267541885376,
    "learning_rate": 0.001
  },
  {
    "episode": 10891,
    "reward": 91.077164,
    "length": 61,
    "time": 159782.95269,
    "actor_loss": -69.53568267822266,
    "critic_loss": 11.391586303710938,
    "ent_coef": 0.07773042470216751,
    "learning_rate": 0.001
  },
  {
    "episode": 10892,
    "reward": 91.263735,
    "length": 61,
    "time": 159796.122625,
    "actor_loss": -67.68765258789062,
    "critic_loss": 16.60749626159668,
    "ent_coef": 0.08023610711097717,
    "learning_rate": 0.001
  },
  {
    "episode": 10893,
    "reward": 88.200084,
    "length": 67,
    "time": 159811.805292,
    "actor_loss": -67.49440002441406,
    "critic_loss": 5.490281581878662,
    "ent_coef": 0.08279797434806824,
    "learning_rate": 0.001
  },
  {
    "episode": 10894,
    "reward": 90.694554,
    "length": 62,
    "time": 159823.411875,
    "actor_loss": -71.29035949707031,
    "critic_loss": 23.895122528076172,
    "ent_coef": 0.08601777255535126,
    "learning_rate": 0.001
  },
  {
    "episode": 10895,
    "reward": 90.455813,
    "length": 61,
    "time": 159834.78325,
    "actor_loss": -59.02378463745117,
    "critic_loss": 102.41268920898438,
    "ent_coef": 0.08850061148405075,
    "learning_rate": 0.001
  },
  {
    "episode": 10896,
    "reward": 91.181623,
    "length": 61,
    "time": 159847.211415,
    "actor_loss": -60.33160400390625,
    "critic_loss": 5.992226600646973,
    "ent_coef": 0.09025159478187561,
    "learning_rate": 0.001
  },
  {
    "episode": 10897,
    "reward": 90.2994,
    "length": 62,
    "time": 159858.489974,
    "actor_loss": -64.94284057617188,
    "critic_loss": 19.163694381713867,
    "ent_coef": 0.09369932115077972,
    "learning_rate": 0.001
  },
  {
    "episode": 10898,
    "reward": 88.43767,
    "length": 67,
    "time": 159874.720338,
    "actor_loss": -69.6506118774414,
    "critic_loss": 3.323514223098755,
    "ent_coef": 0.09239255636930466,
    "learning_rate": 0.001
  },
  {
    "episode": 10899,
    "reward": 82.403182,
    "length": 75,
    "time": 159890.993495,
    "actor_loss": -61.89181137084961,
    "critic_loss": 264.1216125488281,
    "ent_coef": 0.08936913311481476,
    "learning_rate": 0.001
  },
  {
    "episode": 10900,
    "reward": 83.987552,
    "length": 74,
    "time": 159903.730776,
    "actor_loss": -62.756935119628906,
    "critic_loss": 116.2685317993164,
    "ent_coef": 0.08415637910366058,
    "learning_rate": 0.001
  },
  {
    "episode": 10901,
    "reward": 88.687245,
    "length": 65,
    "time": 159916.859324,
    "actor_loss": -62.88578796386719,
    "critic_loss": 11.66312313079834,
    "ent_coef": 0.08074481040239334,
    "learning_rate": 0.001
  },
  {
    "episode": 10902,
    "reward": 91.422787,
    "length": 60,
    "time": 159928.181085,
    "actor_loss": -66.67180633544922,
    "critic_loss": 8.353119850158691,
    "ent_coef": 0.08081470429897308,
    "learning_rate": 0.001
  },
  {
    "episode": 10903,
    "reward": 91.610619,
    "length": 60,
    "time": 159939.51272,
    "actor_loss": -75.69232177734375,
    "critic_loss": 8.676807403564453,
    "ent_coef": 0.08564674109220505,
    "learning_rate": 0.001
  },
  {
    "episode": 10904,
    "reward": 89.958978,
    "length": 63,
    "time": 159950.694941,
    "actor_loss": -59.752357482910156,
    "critic_loss": 13.74998664855957,
    "ent_coef": 0.09063786268234253,
    "learning_rate": 0.001
  },
  {
    "episode": 10905,
    "reward": 91.240209,
    "length": 60,
    "time": 159962.506083,
    "actor_loss": -60.88528823852539,
    "critic_loss": 3.639434814453125,
    "ent_coef": 0.09277841448783875,
    "learning_rate": 0.001
  },
  {
    "episode": 10906,
    "reward": 90.825239,
    "length": 62,
    "time": 159976.094723,
    "actor_loss": -63.014617919921875,
    "critic_loss": 19.02679443359375,
    "ent_coef": 0.09374432265758514,
    "learning_rate": 0.001
  },
  {
    "episode": 10907,
    "reward": 89.453378,
    "length": 63,
    "time": 159988.168754,
    "actor_loss": -65.4972915649414,
    "critic_loss": 4.422482967376709,
    "ent_coef": 0.09880419820547104,
    "learning_rate": 0.001
  },
  {
    "episode": 10908,
    "reward": 87.205899,
    "length": 65,
    "time": 160000.343287,
    "actor_loss": -64.15225219726562,
    "critic_loss": 37.819580078125,
    "ent_coef": 0.1001332476735115,
    "learning_rate": 0.001
  },
  {
    "episode": 10909,
    "reward": 89.707592,
    "length": 63,
    "time": 160012.386693,
    "actor_loss": -70.66166687011719,
    "critic_loss": 7.534835338592529,
    "ent_coef": 0.09844363480806351,
    "learning_rate": 0.001
  },
  {
    "episode": 10910,
    "reward": 88.293865,
    "length": 66,
    "time": 160024.661701,
    "actor_loss": -68.1142578125,
    "critic_loss": 4.1445231437683105,
    "ent_coef": 0.09401125460863113,
    "learning_rate": 0.001
  },
  {
    "episode": 10911,
    "reward": 71.810915,
    "length": 93,
    "time": 160041.568237,
    "actor_loss": -59.48960876464844,
    "critic_loss": 3.418095350265503,
    "ent_coef": 0.0898752212524414,
    "learning_rate": 0.001
  },
  {
    "episode": 10912,
    "reward": 85.799043,
    "length": 69,
    "time": 160053.600018,
    "actor_loss": -68.02489471435547,
    "critic_loss": 18.89853286743164,
    "ent_coef": 0.0901457890868187,
    "learning_rate": 0.001
  },
  {
    "episode": 10913,
    "reward": 83.370196,
    "length": 76,
    "time": 160066.614839,
    "actor_loss": -60.32102584838867,
    "critic_loss": 21.21608543395996,
    "ent_coef": 0.08706393837928772,
    "learning_rate": 0.001
  },
  {
    "episode": 10914,
    "reward": 79.528207,
    "length": 78,
    "time": 160080.730879,
    "actor_loss": -64.75621032714844,
    "critic_loss": 21.77066421508789,
    "ent_coef": 0.0853092148900032,
    "learning_rate": 0.001
  },
  {
    "episode": 10915,
    "reward": 77.556041,
    "length": 81,
    "time": 160098.747675,
    "actor_loss": -67.39976501464844,
    "critic_loss": 7.140741348266602,
    "ent_coef": 0.08410799503326416,
    "learning_rate": 0.001
  },
  {
    "episode": 10916,
    "reward": 90.016001,
    "length": 63,
    "time": 160114.306918,
    "actor_loss": -65.58740997314453,
    "critic_loss": 37.06230163574219,
    "ent_coef": 0.09111195057630539,
    "learning_rate": 0.001
  },
  {
    "episode": 10917,
    "reward": 90.012356,
    "length": 63,
    "time": 160125.475089,
    "actor_loss": -63.3934211730957,
    "critic_loss": 661.8017578125,
    "ent_coef": 0.09449218213558197,
    "learning_rate": 0.001
  },
  {
    "episode": 10918,
    "reward": 90.64298,
    "length": 62,
    "time": 160140.43698,
    "actor_loss": -61.753135681152344,
    "critic_loss": 4.884223937988281,
    "ent_coef": 0.10062668472528458,
    "learning_rate": 0.001
  },
  {
    "episode": 10919,
    "reward": 91.051364,
    "length": 61,
    "time": 160152.260861,
    "actor_loss": -67.05319213867188,
    "critic_loss": 2.479710578918457,
    "ent_coef": 0.10647190362215042,
    "learning_rate": 0.001
  },
  {
    "episode": 10920,
    "reward": 89.138747,
    "length": 65,
    "time": 160165.59514,
    "actor_loss": -64.05410766601562,
    "critic_loss": 4.110121726989746,
    "ent_coef": 0.10403639078140259,
    "learning_rate": 0.001
  },
  {
    "episode": 10921,
    "reward": 89.427192,
    "length": 64,
    "time": 160179.205515,
    "actor_loss": -69.26507568359375,
    "critic_loss": 8.424373626708984,
    "ent_coef": 0.1037515327334404,
    "learning_rate": 0.001
  },
  {
    "episode": 10922,
    "reward": 89.643825,
    "length": 63,
    "time": 160190.524021,
    "actor_loss": -62.658233642578125,
    "critic_loss": 5.422359943389893,
    "ent_coef": 0.10588102042675018,
    "learning_rate": 0.001
  },
  {
    "episode": 10923,
    "reward": 88.960067,
    "length": 64,
    "time": 160201.837577,
    "actor_loss": -67.95426940917969,
    "critic_loss": 100.09049987792969,
    "ent_coef": 0.10498100519180298,
    "learning_rate": 0.001
  },
  {
    "episode": 10924,
    "reward": 86.538011,
    "length": 69,
    "time": 160213.998175,
    "actor_loss": -70.00127410888672,
    "critic_loss": 5.136338233947754,
    "ent_coef": 0.10037906467914581,
    "learning_rate": 0.001
  },
  {
    "episode": 10925,
    "reward": 87.458442,
    "length": 67,
    "time": 160225.735997,
    "actor_loss": -64.47976684570312,
    "critic_loss": 4.542612075805664,
    "ent_coef": 0.0992908701300621,
    "learning_rate": 0.001
  },
  {
    "episode": 10926,
    "reward": 88.945457,
    "length": 64,
    "time": 160237.202863,
    "actor_loss": -67.13200378417969,
    "critic_loss": 15.799572944641113,
    "ent_coef": 0.09886996448040009,
    "learning_rate": 0.001
  },
  {
    "episode": 10927,
    "reward": 90.68548,
    "length": 61,
    "time": 160248.282862,
    "actor_loss": -65.08723449707031,
    "critic_loss": 12.154535293579102,
    "ent_coef": 0.09689543396234512,
    "learning_rate": 0.001
  },
  {
    "episode": 10928,
    "reward": 88.913129,
    "length": 65,
    "time": 160261.568639,
    "actor_loss": -63.98387908935547,
    "critic_loss": 6.415021896362305,
    "ent_coef": 0.09243102371692657,
    "learning_rate": 0.001
  },
  {
    "episode": 10929,
    "reward": 85.033502,
    "length": 71,
    "time": 160274.01013,
    "actor_loss": -68.01638793945312,
    "critic_loss": 3.229534149169922,
    "ent_coef": 0.08649162948131561,
    "learning_rate": 0.001
  },
  {
    "episode": 10930,
    "reward": 89.939452,
    "length": 63,
    "time": 160288.386972,
    "actor_loss": -63.60582733154297,
    "critic_loss": 49.46120834350586,
    "ent_coef": 0.08281499147415161,
    "learning_rate": 0.001
  },
  {
    "episode": 10931,
    "reward": 73.64768,
    "length": 87,
    "time": 160303.799244,
    "actor_loss": -62.907066345214844,
    "critic_loss": 23.53750228881836,
    "ent_coef": 0.07766073942184448,
    "learning_rate": 0.001
  },
  {
    "episode": 10932,
    "reward": 87.671443,
    "length": 67,
    "time": 160317.19282,
    "actor_loss": -64.73442077636719,
    "critic_loss": 12.886639595031738,
    "ent_coef": 0.07467839866876602,
    "learning_rate": 0.001
  },
  {
    "episode": 10933,
    "reward": -536.447501,
    "length": 383,
    "time": 160369.942418,
    "actor_loss": -65.11642456054688,
    "critic_loss": 2.7316246032714844,
    "ent_coef": 0.0765891745686531,
    "learning_rate": 0.001
  },
  {
    "episode": 10934,
    "reward": 118.081444,
    "length": 63,
    "time": 160382.796755,
    "actor_loss": -65.79193115234375,
    "critic_loss": 28.254175186157227,
    "ent_coef": 0.08514757454395294,
    "learning_rate": 0.001
  },
  {
    "episode": 10935,
    "reward": 90.916379,
    "length": 63,
    "time": 160394.686058,
    "actor_loss": -39.355255126953125,
    "critic_loss": 2827.94970703125,
    "ent_coef": 0.08783465623855591,
    "learning_rate": 0.001
  },
  {
    "episode": 10936,
    "reward": 89.091071,
    "length": 67,
    "time": 160406.586886,
    "actor_loss": -66.52005004882812,
    "critic_loss": 9.603672981262207,
    "ent_coef": 0.08752850443124771,
    "learning_rate": 0.001
  },
  {
    "episode": 10937,
    "reward": -144.267235,
    "length": 80,
    "time": 160419.935138,
    "actor_loss": -60.54598617553711,
    "critic_loss": 71.46481323242188,
    "ent_coef": 0.09783032536506653,
    "learning_rate": 0.001
  },
  {
    "episode": 10938,
    "reward": 98.640737,
    "length": 63,
    "time": 160431.472069,
    "actor_loss": -64.24724578857422,
    "critic_loss": 25.561880111694336,
    "ent_coef": 0.10295374691486359,
    "learning_rate": 0.001
  },
  {
    "episode": 10939,
    "reward": 88.280012,
    "length": 67,
    "time": 160444.519947,
    "actor_loss": -57.022125244140625,
    "critic_loss": 18.36944580078125,
    "ent_coef": 0.1023985743522644,
    "learning_rate": 0.001
  },
  {
    "episode": 10940,
    "reward": 88.823753,
    "length": 67,
    "time": 160456.172697,
    "actor_loss": -64.31804656982422,
    "critic_loss": 6.616726398468018,
    "ent_coef": 0.10191063582897186,
    "learning_rate": 0.001
  },
  {
    "episode": 10941,
    "reward": 88.599027,
    "length": 66,
    "time": 160470.401723,
    "actor_loss": -62.50325393676758,
    "critic_loss": 23.022550582885742,
    "ent_coef": 0.10191663354635239,
    "learning_rate": 0.001
  },
  {
    "episode": 10942,
    "reward": 89.427175,
    "length": 66,
    "time": 160482.454732,
    "actor_loss": -60.075050354003906,
    "critic_loss": 27.913440704345703,
    "ent_coef": 0.10691548138856888,
    "learning_rate": 0.001
  },
  {
    "episode": 10943,
    "reward": 88.296181,
    "length": 68,
    "time": 160494.316289,
    "actor_loss": -62.89649963378906,
    "critic_loss": 17.046812057495117,
    "ent_coef": 0.11587410420179367,
    "learning_rate": 0.001
  },
  {
    "episode": 10944,
    "reward": 91.624005,
    "length": 60,
    "time": 160505.312466,
    "actor_loss": -60.91756820678711,
    "critic_loss": 16.468795776367188,
    "ent_coef": 0.11840202659368515,
    "learning_rate": 0.001
  },
  {
    "episode": 10945,
    "reward": 90.487323,
    "length": 64,
    "time": 160516.756648,
    "actor_loss": -68.46176147460938,
    "critic_loss": 4.237447261810303,
    "ent_coef": 0.11883316934108734,
    "learning_rate": 0.001
  },
  {
    "episode": 10946,
    "reward": 89.246669,
    "length": 65,
    "time": 160531.691049,
    "actor_loss": -55.86366271972656,
    "critic_loss": 212.88552856445312,
    "ent_coef": 0.11647650599479675,
    "learning_rate": 0.001
  },
  {
    "episode": 10947,
    "reward": 89.550763,
    "length": 65,
    "time": 160543.179317,
    "actor_loss": -61.054359436035156,
    "critic_loss": 15.303770065307617,
    "ent_coef": 0.11573825776576996,
    "learning_rate": 0.001
  },
  {
    "episode": 10948,
    "reward": 90.070591,
    "length": 63,
    "time": 160554.501677,
    "actor_loss": -61.73005294799805,
    "critic_loss": 30.684932708740234,
    "ent_coef": 0.11691688001155853,
    "learning_rate": 0.001
  },
  {
    "episode": 10949,
    "reward": 88.971532,
    "length": 67,
    "time": 160566.45164,
    "actor_loss": -60.26702117919922,
    "critic_loss": 17.07065200805664,
    "ent_coef": 0.11387578397989273,
    "learning_rate": 0.001
  },
  {
    "episode": 10950,
    "reward": 88.188901,
    "length": 68,
    "time": 160579.915436,
    "actor_loss": -64.88212585449219,
    "critic_loss": 6.895112991333008,
    "ent_coef": 0.10714438557624817,
    "learning_rate": 0.001
  },
  {
    "episode": 10951,
    "reward": 89.919481,
    "length": 64,
    "time": 160592.250229,
    "actor_loss": -71.4089126586914,
    "critic_loss": 18.889989852905273,
    "ent_coef": 0.10423227399587631,
    "learning_rate": 0.001
  },
  {
    "episode": 10952,
    "reward": 90.263938,
    "length": 63,
    "time": 160605.01124,
    "actor_loss": -54.747291564941406,
    "critic_loss": 31.245466232299805,
    "ent_coef": 0.10498666018247604,
    "learning_rate": 0.001
  },
  {
    "episode": 10953,
    "reward": 89.269601,
    "length": 64,
    "time": 160617.271312,
    "actor_loss": -66.89692687988281,
    "critic_loss": 23.59814453125,
    "ent_coef": 0.10294925421476364,
    "learning_rate": 0.001
  },
  {
    "episode": 10954,
    "reward": 88.569149,
    "length": 67,
    "time": 160630.722678,
    "actor_loss": -66.190673828125,
    "critic_loss": 44.93933868408203,
    "ent_coef": 0.10120486468076706,
    "learning_rate": 0.001
  },
  {
    "episode": 10955,
    "reward": 90.187724,
    "length": 65,
    "time": 160642.582797,
    "actor_loss": -67.90306854248047,
    "critic_loss": 16.670061111450195,
    "ent_coef": 0.10158232599496841,
    "learning_rate": 0.001
  },
  {
    "episode": 10956,
    "reward": 87.63938,
    "length": 68,
    "time": 160654.796551,
    "actor_loss": -62.0102424621582,
    "critic_loss": 28.685367584228516,
    "ent_coef": 0.09816509485244751,
    "learning_rate": 0.001
  },
  {
    "episode": 10957,
    "reward": 90.487906,
    "length": 63,
    "time": 160667.118077,
    "actor_loss": -50.15550231933594,
    "critic_loss": 14.358016014099121,
    "ent_coef": 0.09503304213285446,
    "learning_rate": 0.001
  },
  {
    "episode": 10958,
    "reward": 89.591894,
    "length": 65,
    "time": 160679.60085,
    "actor_loss": -60.340660095214844,
    "critic_loss": 8.977334976196289,
    "ent_coef": 0.092368945479393,
    "learning_rate": 0.001
  },
  {
    "episode": 10959,
    "reward": 89.799082,
    "length": 64,
    "time": 160693.39377,
    "actor_loss": -68.27813720703125,
    "critic_loss": 4.799305438995361,
    "ent_coef": 0.0905144140124321,
    "learning_rate": 0.001
  },
  {
    "episode": 10960,
    "reward": 90.480048,
    "length": 63,
    "time": 160705.2663,
    "actor_loss": -72.03008270263672,
    "critic_loss": 8.827104568481445,
    "ent_coef": 0.09443115442991257,
    "learning_rate": 0.001
  },
  {
    "episode": 10961,
    "reward": 88.257514,
    "length": 70,
    "time": 160717.658612,
    "actor_loss": -67.61192321777344,
    "critic_loss": 4.800334453582764,
    "ent_coef": 0.10070249438285828,
    "learning_rate": 0.001
  },
  {
    "episode": 10962,
    "reward": 88.445103,
    "length": 66,
    "time": 160729.52204,
    "actor_loss": -64.65620422363281,
    "critic_loss": 4.1237874031066895,
    "ent_coef": 0.10364721715450287,
    "learning_rate": 0.001
  },
  {
    "episode": 10963,
    "reward": 90.503313,
    "length": 62,
    "time": 160741.320976,
    "actor_loss": -74.55469512939453,
    "critic_loss": 16.262941360473633,
    "ent_coef": 0.10438728332519531,
    "learning_rate": 0.001
  },
  {
    "episode": 10964,
    "reward": 90.287953,
    "length": 64,
    "time": 160752.841286,
    "actor_loss": -68.89232635498047,
    "critic_loss": 10.708757400512695,
    "ent_coef": 0.10413026064634323,
    "learning_rate": 0.001
  },
  {
    "episode": 10965,
    "reward": 88.839802,
    "length": 66,
    "time": 160764.842834,
    "actor_loss": -62.32080078125,
    "critic_loss": 132.01028442382812,
    "ent_coef": 0.10175149142742157,
    "learning_rate": 0.001
  },
  {
    "episode": 10966,
    "reward": 91.357099,
    "length": 61,
    "time": 160775.820507,
    "actor_loss": -63.40333557128906,
    "critic_loss": 17.30240249633789,
    "ent_coef": 0.1033807024359703,
    "learning_rate": 0.001
  },
  {
    "episode": 10967,
    "reward": 89.937565,
    "length": 64,
    "time": 160787.181489,
    "actor_loss": -60.245872497558594,
    "critic_loss": 6.229766368865967,
    "ent_coef": 0.10677672922611237,
    "learning_rate": 0.001
  },
  {
    "episode": 10968,
    "reward": 90.561122,
    "length": 62,
    "time": 160801.258237,
    "actor_loss": -62.77778625488281,
    "critic_loss": 39.96458435058594,
    "ent_coef": 0.11197882145643234,
    "learning_rate": 0.001
  },
  {
    "episode": 10969,
    "reward": 90.469111,
    "length": 62,
    "time": 160812.430463,
    "actor_loss": -61.174964904785156,
    "critic_loss": 5.313719749450684,
    "ent_coef": 0.11669423431158066,
    "learning_rate": 0.001
  },
  {
    "episode": 10970,
    "reward": 89.729137,
    "length": 65,
    "time": 160827.829583,
    "actor_loss": -63.93354415893555,
    "critic_loss": 2.58339524269104,
    "ent_coef": 0.11857135593891144,
    "learning_rate": 0.001
  },
  {
    "episode": 10971,
    "reward": 88.761392,
    "length": 66,
    "time": 160839.767885,
    "actor_loss": -63.83477020263672,
    "critic_loss": 28.849273681640625,
    "ent_coef": 0.11798843741416931,
    "learning_rate": 0.001
  },
  {
    "episode": 10972,
    "reward": 88.691989,
    "length": 66,
    "time": 160852.926772,
    "actor_loss": -60.920562744140625,
    "critic_loss": 4.587535858154297,
    "ent_coef": 0.11716677993535995,
    "learning_rate": 0.001
  },
  {
    "episode": 10973,
    "reward": 89.66151,
    "length": 64,
    "time": 160865.921489,
    "actor_loss": -65.4066162109375,
    "critic_loss": 105.18370819091797,
    "ent_coef": 0.11780156940221786,
    "learning_rate": 0.001
  },
  {
    "episode": 10974,
    "reward": 88.52542,
    "length": 67,
    "time": 160879.055306,
    "actor_loss": -61.806453704833984,
    "critic_loss": 18.25288963317871,
    "ent_coef": 0.11312545090913773,
    "learning_rate": 0.001
  },
  {
    "episode": 10975,
    "reward": 90.492354,
    "length": 62,
    "time": 160892.492937,
    "actor_loss": -69.59371948242188,
    "critic_loss": 48.12706756591797,
    "ent_coef": 0.1083076223731041,
    "learning_rate": 0.001
  },
  {
    "episode": 10976,
    "reward": 86.264358,
    "length": 70,
    "time": 160905.430246,
    "actor_loss": -63.617767333984375,
    "critic_loss": 16.220590591430664,
    "ent_coef": 0.10536441951990128,
    "learning_rate": 0.001
  },
  {
    "episode": 10977,
    "reward": 88.867284,
    "length": 65,
    "time": 160918.764784,
    "actor_loss": -63.30516052246094,
    "critic_loss": 6.849486351013184,
    "ent_coef": 0.10402855277061462,
    "learning_rate": 0.001
  },
  {
    "episode": 10978,
    "reward": 89.375031,
    "length": 65,
    "time": 160930.578833,
    "actor_loss": -68.89747619628906,
    "critic_loss": 15.261490821838379,
    "ent_coef": 0.10407494008541107,
    "learning_rate": 0.001
  },
  {
    "episode": 10979,
    "reward": 88.486949,
    "length": 67,
    "time": 160942.25171,
    "actor_loss": -31.80896759033203,
    "critic_loss": 28.54059410095215,
    "ent_coef": 0.10310963541269302,
    "learning_rate": 0.001
  },
  {
    "episode": 10980,
    "reward": 88.718844,
    "length": 66,
    "time": 160953.963152,
    "actor_loss": -59.55573654174805,
    "critic_loss": 14.75699234008789,
    "ent_coef": 0.10310095548629761,
    "learning_rate": 0.001
  },
  {
    "episode": 10981,
    "reward": 87.777947,
    "length": 68,
    "time": 160967.345963,
    "actor_loss": -59.578407287597656,
    "critic_loss": 14.56458568572998,
    "ent_coef": 0.09916923940181732,
    "learning_rate": 0.001
  },
  {
    "episode": 10982,
    "reward": 84.128105,
    "length": 74,
    "time": 160979.901586,
    "actor_loss": -62.80036926269531,
    "critic_loss": 21.359973907470703,
    "ent_coef": 0.09478313475847244,
    "learning_rate": 0.001
  },
  {
    "episode": 10983,
    "reward": 88.821534,
    "length": 65,
    "time": 160991.60387,
    "actor_loss": -64.73351287841797,
    "critic_loss": 13.150590896606445,
    "ent_coef": 0.09374050050973892,
    "learning_rate": 0.001
  },
  {
    "episode": 10984,
    "reward": 89.166377,
    "length": 64,
    "time": 161003.364188,
    "actor_loss": -62.703712463378906,
    "critic_loss": 7.686734199523926,
    "ent_coef": 0.09846494346857071,
    "learning_rate": 0.001
  },
  {
    "episode": 10985,
    "reward": 87.872695,
    "length": 67,
    "time": 161016.036885,
    "actor_loss": -69.2656478881836,
    "critic_loss": 13.857648849487305,
    "ent_coef": 0.10397551208734512,
    "learning_rate": 0.001
  },
  {
    "episode": 10986,
    "reward": 89.622769,
    "length": 64,
    "time": 161028.587273,
    "actor_loss": -67.47156524658203,
    "critic_loss": 831.501953125,
    "ent_coef": 0.10819527506828308,
    "learning_rate": 0.001
  },
  {
    "episode": 10987,
    "reward": 85.597629,
    "length": 73,
    "time": 161041.118897,
    "actor_loss": -53.7877197265625,
    "critic_loss": 42.06781768798828,
    "ent_coef": 0.10443871468305588,
    "learning_rate": 0.001
  },
  {
    "episode": 10988,
    "reward": 90.925811,
    "length": 62,
    "time": 161052.457177,
    "actor_loss": -53.501068115234375,
    "critic_loss": 306.4530029296875,
    "ent_coef": 0.10575535148382187,
    "learning_rate": 0.001
  },
  {
    "episode": 10989,
    "reward": 83.717317,
    "length": 74,
    "time": 161065.11358,
    "actor_loss": -58.06623458862305,
    "critic_loss": 11.55899429321289,
    "ent_coef": 0.10255205631256104,
    "learning_rate": 0.001
  },
  {
    "episode": 10990,
    "reward": 89.892979,
    "length": 64,
    "time": 161078.924961,
    "actor_loss": -68.87979888916016,
    "critic_loss": 8.858094215393066,
    "ent_coef": 0.10636600106954575,
    "learning_rate": 0.001
  },
  {
    "episode": 10991,
    "reward": 90.145128,
    "length": 64,
    "time": 161091.096597,
    "actor_loss": -69.39271545410156,
    "critic_loss": 93.6506576538086,
    "ent_coef": 0.10962649434804916,
    "learning_rate": 0.001
  },
  {
    "episode": 10992,
    "reward": 89.338289,
    "length": 66,
    "time": 161104.71497,
    "actor_loss": -68.32971954345703,
    "critic_loss": 8.026469230651855,
    "ent_coef": 0.10919369012117386,
    "learning_rate": 0.001
  },
  {
    "episode": 10993,
    "reward": 89.795019,
    "length": 65,
    "time": 161117.257586,
    "actor_loss": -56.91542053222656,
    "critic_loss": 92.66459655761719,
    "ent_coef": 0.11082173138856888,
    "learning_rate": 0.001
  },
  {
    "episode": 10994,
    "reward": 89.104555,
    "length": 66,
    "time": 161128.776269,
    "actor_loss": -61.085845947265625,
    "critic_loss": 6.069513320922852,
    "ent_coef": 0.11359508335590363,
    "learning_rate": 0.001
  },
  {
    "episode": 10995,
    "reward": 90.436424,
    "length": 64,
    "time": 161140.303474,
    "actor_loss": -61.44020462036133,
    "critic_loss": 754.78662109375,
    "ent_coef": 0.11248031258583069,
    "learning_rate": 0.001
  },
  {
    "episode": 10996,
    "reward": 88.220416,
    "length": 67,
    "time": 161152.944845,
    "actor_loss": -61.92755126953125,
    "critic_loss": 15.907669067382812,
    "ent_coef": 0.11032473295927048,
    "learning_rate": 0.001
  },
  {
    "episode": 10997,
    "reward": 89.551073,
    "length": 65,
    "time": 161164.847829,
    "actor_loss": -64.07921600341797,
    "critic_loss": 297.26263427734375,
    "ent_coef": 0.11196883767843246,
    "learning_rate": 0.001
  },
  {
    "episode": 10998,
    "reward": 88.68206,
    "length": 68,
    "time": 161176.631544,
    "actor_loss": -46.8922004699707,
    "critic_loss": 68.20118713378906,
    "ent_coef": 0.11113187670707703,
    "learning_rate": 0.001
  },
  {
    "episode": 10999,
    "reward": 87.408738,
    "length": 70,
    "time": 161191.031811,
    "actor_loss": -52.30023956298828,
    "critic_loss": 44.959686279296875,
    "ent_coef": 0.1046452522277832,
    "learning_rate": 0.001
  },
  {
    "episode": 11000,
    "reward": 88.124568,
    "length": 68,
    "time": 161202.972285,
    "actor_loss": -63.10029220581055,
    "critic_loss": 5.340248107910156,
    "ent_coef": 0.09993287920951843,
    "learning_rate": 0.001
  },
  {
    "episode": 11001,
    "reward": 90.670046,
    "length": 62,
    "time": 161217.141582,
    "actor_loss": -65.570068359375,
    "critic_loss": 30.96092987060547,
    "ent_coef": 0.09997351467609406,
    "learning_rate": 0.001
  },
  {
    "episode": 11002,
    "reward": 91.500837,
    "length": 61,
    "time": 161229.282161,
    "actor_loss": -60.85590362548828,
    "critic_loss": 63.84463119506836,
    "ent_coef": 0.10471530258655548,
    "learning_rate": 0.001
  },
  {
    "episode": 11003,
    "reward": 90.545334,
    "length": 64,
    "time": 161240.811281,
    "actor_loss": -63.637672424316406,
    "critic_loss": 22.772085189819336,
    "ent_coef": 0.11191266775131226,
    "learning_rate": 0.001
  },
  {
    "episode": 11004,
    "reward": 89.871039,
    "length": 63,
    "time": 161252.607869,
    "actor_loss": -66.44316864013672,
    "critic_loss": 4.4478440284729,
    "ent_coef": 0.1130852997303009,
    "learning_rate": 0.001
  },
  {
    "episode": 11005,
    "reward": 89.358725,
    "length": 64,
    "time": 161266.476228,
    "actor_loss": -57.18427658081055,
    "critic_loss": 71.29833984375,
    "ent_coef": 0.11619927734136581,
    "learning_rate": 0.001
  },
  {
    "episode": 11006,
    "reward": 90.78357,
    "length": 62,
    "time": 161279.669762,
    "actor_loss": -69.02716064453125,
    "critic_loss": 3.9096927642822266,
    "ent_coef": 0.1216764822602272,
    "learning_rate": 0.001
  },
  {
    "episode": 11007,
    "reward": 88.980618,
    "length": 65,
    "time": 161292.122368,
    "actor_loss": -67.5252685546875,
    "critic_loss": 5.7348456382751465,
    "ent_coef": 0.12424883246421814,
    "learning_rate": 0.001
  },
  {
    "episode": 11008,
    "reward": 89.278642,
    "length": 65,
    "time": 161303.849678,
    "actor_loss": -57.490997314453125,
    "critic_loss": 29.912019729614258,
    "ent_coef": 0.12403081357479095,
    "learning_rate": 0.001
  },
  {
    "episode": 11009,
    "reward": 87.16745,
    "length": 68,
    "time": 161316.112244,
    "actor_loss": -57.053062438964844,
    "critic_loss": 33.46891784667969,
    "ent_coef": 0.1199437603354454,
    "learning_rate": 0.001
  },
  {
    "episode": 11010,
    "reward": 90.309876,
    "length": 63,
    "time": 161328.392203,
    "actor_loss": -61.871055603027344,
    "critic_loss": 357.82061767578125,
    "ent_coef": 0.11691707372665405,
    "learning_rate": 0.001
  },
  {
    "episode": 11011,
    "reward": 88.734641,
    "length": 65,
    "time": 161344.941161,
    "actor_loss": -48.44371795654297,
    "critic_loss": 403.8401794433594,
    "ent_coef": 0.11513680219650269,
    "learning_rate": 0.001
  },
  {
    "episode": 11012,
    "reward": 90.249056,
    "length": 63,
    "time": 161357.590669,
    "actor_loss": -64.83456420898438,
    "critic_loss": 48.81786346435547,
    "ent_coef": 0.11610395461320877,
    "learning_rate": 0.001
  },
  {
    "episode": 11013,
    "reward": 90.388014,
    "length": 63,
    "time": 161368.614733,
    "actor_loss": -68.6668472290039,
    "critic_loss": 99.47102355957031,
    "ent_coef": 0.1175290048122406,
    "learning_rate": 0.001
  },
  {
    "episode": 11014,
    "reward": 91.075021,
    "length": 61,
    "time": 161379.687485,
    "actor_loss": -63.53483581542969,
    "critic_loss": 7.209161758422852,
    "ent_coef": 0.11849439889192581,
    "learning_rate": 0.001
  },
  {
    "episode": 11015,
    "reward": 90.530494,
    "length": 62,
    "time": 161390.838232,
    "actor_loss": -59.445255279541016,
    "critic_loss": 21.612558364868164,
    "ent_coef": 0.11841688305139542,
    "learning_rate": 0.001
  },
  {
    "episode": 11016,
    "reward": 88.896665,
    "length": 65,
    "time": 161402.438029,
    "actor_loss": -63.7947883605957,
    "critic_loss": 5.621390342712402,
    "ent_coef": 0.11261861771345139,
    "learning_rate": 0.001
  },
  {
    "episode": 11017,
    "reward": 87.813844,
    "length": 67,
    "time": 161416.240382,
    "actor_loss": -58.911251068115234,
    "critic_loss": 11.738601684570312,
    "ent_coef": 0.10645241290330887,
    "learning_rate": 0.001
  },
  {
    "episode": 11018,
    "reward": 85.749927,
    "length": 72,
    "time": 161431.32358,
    "actor_loss": -70.77156066894531,
    "critic_loss": 132.10134887695312,
    "ent_coef": 0.10056916624307632,
    "learning_rate": 0.001
  },
  {
    "episode": 11019,
    "reward": 88.935359,
    "length": 66,
    "time": 161443.071681,
    "actor_loss": -61.57626724243164,
    "critic_loss": 43.59532928466797,
    "ent_coef": 0.09742282330989838,
    "learning_rate": 0.001
  },
  {
    "episode": 11020,
    "reward": 86.835727,
    "length": 70,
    "time": 161456.336957,
    "actor_loss": -66.53985595703125,
    "critic_loss": 11.970708847045898,
    "ent_coef": 0.09089020639657974,
    "learning_rate": 0.001
  },
  {
    "episode": 11021,
    "reward": 87.422404,
    "length": 68,
    "time": 161468.990125,
    "actor_loss": -64.5135269165039,
    "critic_loss": 104.3961181640625,
    "ent_coef": 0.08265738934278488,
    "learning_rate": 0.001
  },
  {
    "episode": 11022,
    "reward": -162.510313,
    "length": 174,
    "time": 161495.522621,
    "actor_loss": -62.651092529296875,
    "critic_loss": 13.199623107910156,
    "ent_coef": 0.08341817557811737,
    "learning_rate": 0.001
  },
  {
    "episode": 11023,
    "reward": 89.781718,
    "length": 64,
    "time": 161509.455336,
    "actor_loss": -66.61651611328125,
    "critic_loss": 21.435237884521484,
    "ent_coef": 0.08435504883527756,
    "learning_rate": 0.001
  },
  {
    "episode": 11024,
    "reward": 87.612919,
    "length": 67,
    "time": 161521.870901,
    "actor_loss": -60.203216552734375,
    "critic_loss": 6.839286804199219,
    "ent_coef": 0.08618935197591782,
    "learning_rate": 0.001
  },
  {
    "episode": 11025,
    "reward": 85.800916,
    "length": 71,
    "time": 161537.608404,
    "actor_loss": -64.9931640625,
    "critic_loss": 55.92310333251953,
    "ent_coef": 0.08818987011909485,
    "learning_rate": 0.001
  },
  {
    "episode": 11026,
    "reward": 79.559868,
    "length": 81,
    "time": 161553.621112,
    "actor_loss": -59.05765914916992,
    "critic_loss": 13.189404487609863,
    "ent_coef": 0.08354441821575165,
    "learning_rate": 0.001
  },
  {
    "episode": 11027,
    "reward": 85.796677,
    "length": 69,
    "time": 161565.520963,
    "actor_loss": -62.57783126831055,
    "critic_loss": 30.311010360717773,
    "ent_coef": 0.0819537416100502,
    "learning_rate": 0.001
  },
  {
    "episode": 11028,
    "reward": 83.285689,
    "length": 75,
    "time": 161578.315892,
    "actor_loss": -57.55762481689453,
    "critic_loss": 11.128019332885742,
    "ent_coef": 0.08064386248588562,
    "learning_rate": 0.001
  },
  {
    "episode": 11029,
    "reward": 38.844428,
    "length": 144,
    "time": 161600.105251,
    "actor_loss": -62.28108215332031,
    "critic_loss": 108.43712615966797,
    "ent_coef": 0.07813567668199539,
    "learning_rate": 0.001
  },
  {
    "episode": 11030,
    "reward": 84.9441,
    "length": 70,
    "time": 161613.73829,
    "actor_loss": -68.76875305175781,
    "critic_loss": 38.137664794921875,
    "ent_coef": 0.07822714000940323,
    "learning_rate": 0.001
  },
  {
    "episode": 11031,
    "reward": 85.768965,
    "length": 69,
    "time": 161627.477316,
    "actor_loss": -64.1607666015625,
    "critic_loss": 7.175148010253906,
    "ent_coef": 0.07886318862438202,
    "learning_rate": 0.001
  },
  {
    "episode": 11032,
    "reward": 83.302329,
    "length": 74,
    "time": 161640.120163,
    "actor_loss": -66.92823028564453,
    "critic_loss": 3.944033622741699,
    "ent_coef": 0.07974991947412491,
    "learning_rate": 0.001
  },
  {
    "episode": 11033,
    "reward": 85.789064,
    "length": 69,
    "time": 161653.370677,
    "actor_loss": -51.119041442871094,
    "critic_loss": 6003.2490234375,
    "ent_coef": 0.08246193081140518,
    "learning_rate": 0.001
  },
  {
    "episode": 11034,
    "reward": 90.547396,
    "length": 61,
    "time": 161664.577168,
    "actor_loss": -64.72547149658203,
    "critic_loss": 29.925949096679688,
    "ent_coef": 0.0857769176363945,
    "learning_rate": 0.001
  },
  {
    "episode": 11035,
    "reward": 88.796226,
    "length": 65,
    "time": 161676.548904,
    "actor_loss": -63.40168762207031,
    "critic_loss": 4.604742050170898,
    "ent_coef": 0.09015075862407684,
    "learning_rate": 0.001
  },
  {
    "episode": 11036,
    "reward": 89.055365,
    "length": 65,
    "time": 161688.752271,
    "actor_loss": -65.29257202148438,
    "critic_loss": 98.05309295654297,
    "ent_coef": 0.0965893566608429,
    "learning_rate": 0.001
  },
  {
    "episode": 11037,
    "reward": 86.824289,
    "length": 68,
    "time": 161703.503304,
    "actor_loss": -52.55921173095703,
    "critic_loss": 373.03961181640625,
    "ent_coef": 0.1045527532696724,
    "learning_rate": 0.001
  },
  {
    "episode": 11038,
    "reward": 88.895603,
    "length": 69,
    "time": 161715.622789,
    "actor_loss": -64.69173431396484,
    "critic_loss": 13.521678924560547,
    "ent_coef": 0.11265712231397629,
    "learning_rate": 0.001
  },
  {
    "episode": 11039,
    "reward": 83.646706,
    "length": 73,
    "time": 161728.037157,
    "actor_loss": -62.87953186035156,
    "critic_loss": 41.539485931396484,
    "ent_coef": 0.11349810659885406,
    "learning_rate": 0.001
  },
  {
    "episode": 11040,
    "reward": 85.113683,
    "length": 70,
    "time": 161741.319213,
    "actor_loss": -68.66629028320312,
    "critic_loss": 12.166709899902344,
    "ent_coef": 0.11352068185806274,
    "learning_rate": 0.001
  },
  {
    "episode": 11041,
    "reward": 82.216705,
    "length": 74,
    "time": 161755.616102,
    "actor_loss": -58.344234466552734,
    "critic_loss": 7.345480442047119,
    "ent_coef": 0.11339954286813736,
    "learning_rate": 0.001
  },
  {
    "episode": 11042,
    "reward": 81.066793,
    "length": 77,
    "time": 161770.490066,
    "actor_loss": -59.67742919921875,
    "critic_loss": 4.246951103210449,
    "ent_coef": 0.11187242716550827,
    "learning_rate": 0.001
  },
  {
    "episode": 11043,
    "reward": 83.868165,
    "length": 73,
    "time": 161783.602834,
    "actor_loss": -67.52499389648438,
    "critic_loss": 7.876094818115234,
    "ent_coef": 0.10964147746562958,
    "learning_rate": 0.001
  },
  {
    "episode": 11044,
    "reward": 83.277175,
    "length": 73,
    "time": 161796.062436,
    "actor_loss": -55.46599197387695,
    "critic_loss": 11.967875480651855,
    "ent_coef": 0.11024593561887741,
    "learning_rate": 0.001
  },
  {
    "episode": 11045,
    "reward": 90.349877,
    "length": 62,
    "time": 161807.433739,
    "actor_loss": -62.34048843383789,
    "critic_loss": 15.554689407348633,
    "ent_coef": 0.11328267306089401,
    "learning_rate": 0.001
  },
  {
    "episode": 11046,
    "reward": 89.516475,
    "length": 63,
    "time": 161818.740181,
    "actor_loss": -64.66390991210938,
    "critic_loss": 6.263510704040527,
    "ent_coef": 0.11752701550722122,
    "learning_rate": 0.001
  },
  {
    "episode": 11047,
    "reward": 88.796732,
    "length": 65,
    "time": 161830.183818,
    "actor_loss": -67.03843688964844,
    "critic_loss": 23.837890625,
    "ent_coef": 0.11843559890985489,
    "learning_rate": 0.001
  },
  {
    "episode": 11048,
    "reward": 84.575937,
    "length": 70,
    "time": 161842.686532,
    "actor_loss": -68.09854888916016,
    "critic_loss": 75.582275390625,
    "ent_coef": 0.11993615329265594,
    "learning_rate": 0.001
  },
  {
    "episode": 11049,
    "reward": 86.758547,
    "length": 68,
    "time": 161854.543256,
    "actor_loss": -59.4012451171875,
    "critic_loss": 5.905412197113037,
    "ent_coef": 0.11772041022777557,
    "learning_rate": 0.001
  },
  {
    "episode": 11050,
    "reward": 86.348143,
    "length": 68,
    "time": 161868.294577,
    "actor_loss": -62.79928207397461,
    "critic_loss": 51.40381622314453,
    "ent_coef": 0.11620639264583588,
    "learning_rate": 0.001
  },
  {
    "episode": 11051,
    "reward": 87.469973,
    "length": 67,
    "time": 161880.407432,
    "actor_loss": -59.59751510620117,
    "critic_loss": 2.849010467529297,
    "ent_coef": 0.10756417363882065,
    "learning_rate": 0.001
  },
  {
    "episode": 11052,
    "reward": 80.504103,
    "length": 79,
    "time": 161893.638328,
    "actor_loss": -64.9967041015625,
    "critic_loss": 7.319247245788574,
    "ent_coef": 0.10673773288726807,
    "learning_rate": 0.001
  },
  {
    "episode": 11053,
    "reward": 78.247147,
    "length": 81,
    "time": 161910.627575,
    "actor_loss": -61.41039276123047,
    "critic_loss": 6.589638710021973,
    "ent_coef": 0.10305681824684143,
    "learning_rate": 0.001
  },
  {
    "episode": 11054,
    "reward": 86.980555,
    "length": 68,
    "time": 161923.004663,
    "actor_loss": -62.5612678527832,
    "critic_loss": 7.042591094970703,
    "ent_coef": 0.09916628152132034,
    "learning_rate": 0.001
  },
  {
    "episode": 11055,
    "reward": 83.912468,
    "length": 73,
    "time": 161936.823376,
    "actor_loss": -65.97254943847656,
    "critic_loss": 5.445295810699463,
    "ent_coef": 0.0933980867266655,
    "learning_rate": 0.001
  },
  {
    "episode": 11056,
    "reward": 76.040433,
    "length": 83,
    "time": 161950.603721,
    "actor_loss": -70.16384887695312,
    "critic_loss": 17.09526252746582,
    "ent_coef": 0.09245645999908447,
    "learning_rate": 0.001
  },
  {
    "episode": 11057,
    "reward": 72.695133,
    "length": 89,
    "time": 161968.781407,
    "actor_loss": -58.93635940551758,
    "critic_loss": 11.056589126586914,
    "ent_coef": 0.08791472762823105,
    "learning_rate": 0.001
  },
  {
    "episode": 11058,
    "reward": 58.292868,
    "length": 111,
    "time": 161989.19324,
    "actor_loss": -49.19237518310547,
    "critic_loss": 41.53364562988281,
    "ent_coef": 0.08236348628997803,
    "learning_rate": 0.001
  },
  {
    "episode": 11059,
    "reward": 82.15812,
    "length": 76,
    "time": 162002.275831,
    "actor_loss": -67.54447937011719,
    "critic_loss": 2.976104497909546,
    "ent_coef": 0.08004558086395264,
    "learning_rate": 0.001
  },
  {
    "episode": 11060,
    "reward": 7.71631,
    "length": 185,
    "time": 162030.861829,
    "actor_loss": -68.90377807617188,
    "critic_loss": 26.458526611328125,
    "ent_coef": 0.07769685983657837,
    "learning_rate": 0.001
  },
  {
    "episode": 11061,
    "reward": 30.527762,
    "length": 151,
    "time": 162059.570116,
    "actor_loss": -64.53666687011719,
    "critic_loss": 14.4459228515625,
    "ent_coef": 0.08432549238204956,
    "learning_rate": 0.001
  },
  {
    "episode": 11062,
    "reward": 2.805395,
    "length": 187,
    "time": 162087.551056,
    "actor_loss": -64.26646423339844,
    "critic_loss": 80.79086303710938,
    "ent_coef": 0.07960466295480728,
    "learning_rate": 0.001
  },
  {
    "episode": 11063,
    "reward": 55.936746,
    "length": 116,
    "time": 162105.722824,
    "actor_loss": -59.824832916259766,
    "critic_loss": 9.571532249450684,
    "ent_coef": 0.0782477855682373,
    "learning_rate": 0.001
  },
  {
    "episode": 11064,
    "reward": 5.321594,
    "length": 191,
    "time": 162133.596806,
    "actor_loss": -62.574981689453125,
    "critic_loss": 9.774978637695312,
    "ent_coef": 0.08773141354322433,
    "learning_rate": 0.001
  },
  {
    "episode": 11065,
    "reward": -35.315458,
    "length": 244,
    "time": 162169.268853,
    "actor_loss": -69.7081069946289,
    "critic_loss": 10.984511375427246,
    "ent_coef": 0.09265760332345963,
    "learning_rate": 0.001
  },
  {
    "episode": 11066,
    "reward": 82.441803,
    "length": 75,
    "time": 162182.374845,
    "actor_loss": -58.00194549560547,
    "critic_loss": 8.017232894897461,
    "ent_coef": 0.09041375666856766,
    "learning_rate": 0.001
  },
  {
    "episode": 11067,
    "reward": 83.586481,
    "length": 73,
    "time": 162195.880715,
    "actor_loss": -63.32782745361328,
    "critic_loss": 16.14881134033203,
    "ent_coef": 0.08897555619478226,
    "learning_rate": 0.001
  },
  {
    "episode": 11068,
    "reward": 15.995075,
    "length": 172,
    "time": 162222.57692,
    "actor_loss": -64.14764404296875,
    "critic_loss": 2.8774185180664062,
    "ent_coef": 0.08554056286811829,
    "learning_rate": 0.001
  },
  {
    "episode": 11069,
    "reward": 65.916031,
    "length": 99,
    "time": 162238.394387,
    "actor_loss": -46.802703857421875,
    "critic_loss": 20.856067657470703,
    "ent_coef": 0.08063501864671707,
    "learning_rate": 0.001
  },
  {
    "episode": 11070,
    "reward": 67.585425,
    "length": 97,
    "time": 162254.965407,
    "actor_loss": -62.98435974121094,
    "critic_loss": 7.612985610961914,
    "ent_coef": 0.0777074471116066,
    "learning_rate": 0.001
  },
  {
    "episode": 11071,
    "reward": 64.707165,
    "length": 100,
    "time": 162273.655676,
    "actor_loss": -62.90333557128906,
    "critic_loss": 8.1593656539917,
    "ent_coef": 0.07944052666425705,
    "learning_rate": 0.001
  },
  {
    "episode": 11072,
    "reward": 77.779497,
    "length": 81,
    "time": 162288.777051,
    "actor_loss": -68.61555480957031,
    "critic_loss": 9.496811866760254,
    "ent_coef": 0.07867170870304108,
    "learning_rate": 0.001
  },
  {
    "episode": 11073,
    "reward": 84.332681,
    "length": 70,
    "time": 162301.682407,
    "actor_loss": -63.51280212402344,
    "critic_loss": 7.2854790687561035,
    "ent_coef": 0.0797399953007698,
    "learning_rate": 0.001
  },
  {
    "episode": 11074,
    "reward": 54.068909,
    "length": 117,
    "time": 162323.574074,
    "actor_loss": -70.25227355957031,
    "critic_loss": 28.834579467773438,
    "ent_coef": 0.08237578719854355,
    "learning_rate": 0.001
  },
  {
    "episode": 11075,
    "reward": -40.225574,
    "length": 247,
    "time": 162359.24628,
    "actor_loss": -65.1473617553711,
    "critic_loss": 9.41642951965332,
    "ent_coef": 0.09688851982355118,
    "learning_rate": 0.001
  },
  {
    "episode": 11076,
    "reward": -147.179725,
    "length": 404,
    "time": 162417.302913,
    "actor_loss": -49.92999267578125,
    "critic_loss": 16.817012786865234,
    "ent_coef": 0.08663369715213776,
    "learning_rate": 0.001
  },
  {
    "episode": 11077,
    "reward": 81.365517,
    "length": 76,
    "time": 162432.091361,
    "actor_loss": -62.044921875,
    "critic_loss": 24.86200714111328,
    "ent_coef": 0.08217333257198334,
    "learning_rate": 0.001
  },
  {
    "episode": 11078,
    "reward": 86.289235,
    "length": 69,
    "time": 162445.288326,
    "actor_loss": -57.378746032714844,
    "critic_loss": 30.367855072021484,
    "ent_coef": 0.08386458456516266,
    "learning_rate": 0.001
  },
  {
    "episode": 11079,
    "reward": 5.925799,
    "length": 182,
    "time": 162475.700798,
    "actor_loss": -62.05070495605469,
    "critic_loss": 9.21806526184082,
    "ent_coef": 0.0776541456580162,
    "learning_rate": 0.001
  },
  {
    "episode": 11080,
    "reward": 25.92848,
    "length": 151,
    "time": 162498.277682,
    "actor_loss": -59.735511779785156,
    "critic_loss": 13.198173522949219,
    "ent_coef": 0.08032551407814026,
    "learning_rate": 0.001
  },
  {
    "episode": 11081,
    "reward": 82.884956,
    "length": 75,
    "time": 162511.388883,
    "actor_loss": -64.81278228759766,
    "critic_loss": 35.21415710449219,
    "ent_coef": 0.08224267512559891,
    "learning_rate": 0.001
  },
  {
    "episode": 11082,
    "reward": 65.631093,
    "length": 127,
    "time": 162531.983271,
    "actor_loss": -63.09722137451172,
    "critic_loss": 41.333595275878906,
    "ent_coef": 0.08118477463722229,
    "learning_rate": 0.001
  },
  {
    "episode": 11083,
    "reward": -143.668219,
    "length": 388,
    "time": 162585.028056,
    "actor_loss": -63.394657135009766,
    "critic_loss": 8.471475601196289,
    "ent_coef": 0.09232271462678909,
    "learning_rate": 0.001
  },
  {
    "episode": 11084,
    "reward": 73.039416,
    "length": 87,
    "time": 162601.49823,
    "actor_loss": -61.31035232543945,
    "critic_loss": 13.328086853027344,
    "ent_coef": 0.09422135353088379,
    "learning_rate": 0.001
  },
  {
    "episode": 11085,
    "reward": -111.88732,
    "length": 345,
    "time": 162652.761331,
    "actor_loss": -62.92535400390625,
    "critic_loss": 8.649572372436523,
    "ent_coef": 0.10587380081415176,
    "learning_rate": 0.001
  },
  {
    "episode": 11086,
    "reward": 70.153003,
    "length": 93,
    "time": 162668.655171,
    "actor_loss": -60.7987174987793,
    "critic_loss": 33.07866668701172,
    "ent_coef": 0.11106337606906891,
    "learning_rate": 0.001
  },
  {
    "episode": 11087,
    "reward": -159.969812,
    "length": 113,
    "time": 162687.663148,
    "actor_loss": -65.42767333984375,
    "critic_loss": 6.117792129516602,
    "ent_coef": 0.10286002606153488,
    "learning_rate": 0.001
  },
  {
    "episode": 11088,
    "reward": 78.187789,
    "length": 84,
    "time": 162705.677,
    "actor_loss": -59.93057632446289,
    "critic_loss": 15.286274909973145,
    "ent_coef": 0.09229631721973419,
    "learning_rate": 0.001
  },
  {
    "episode": 11089,
    "reward": 85.796215,
    "length": 70,
    "time": 162722.792057,
    "actor_loss": -68.47579193115234,
    "critic_loss": 9.461559295654297,
    "ent_coef": 0.0866876021027565,
    "learning_rate": 0.001
  },
  {
    "episode": 11090,
    "reward": 85.61881,
    "length": 70,
    "time": 162736.330333,
    "actor_loss": -60.208595275878906,
    "critic_loss": 63.47515106201172,
    "ent_coef": 0.08277910947799683,
    "learning_rate": 0.001
  },
  {
    "episode": 11091,
    "reward": 68.704217,
    "length": 96,
    "time": 162752.82057,
    "actor_loss": -68.31996154785156,
    "critic_loss": 4.5265278816223145,
    "ent_coef": 0.0828135758638382,
    "learning_rate": 0.001
  },
  {
    "episode": 11092,
    "reward": 85.384191,
    "length": 70,
    "time": 162766.312427,
    "actor_loss": -63.86334991455078,
    "critic_loss": 5.696412086486816,
    "ent_coef": 0.0835433229804039,
    "learning_rate": 0.001
  },
  {
    "episode": 11093,
    "reward": 87.79191,
    "length": 66,
    "time": 162780.214186,
    "actor_loss": -55.86189270019531,
    "critic_loss": 14.881359100341797,
    "ent_coef": 0.08250781148672104,
    "learning_rate": 0.001
  },
  {
    "episode": 11094,
    "reward": 89.803603,
    "length": 63,
    "time": 162793.405681,
    "actor_loss": -63.0604248046875,
    "critic_loss": 16.511367797851562,
    "ent_coef": 0.08323018252849579,
    "learning_rate": 0.001
  },
  {
    "episode": 11095,
    "reward": 87.362867,
    "length": 67,
    "time": 162805.216655,
    "actor_loss": -65.72887420654297,
    "critic_loss": 7.027242183685303,
    "ent_coef": 0.08322855085134506,
    "learning_rate": 0.001
  },
  {
    "episode": 11096,
    "reward": 82.302987,
    "length": 74,
    "time": 162820.141317,
    "actor_loss": -65.4202880859375,
    "critic_loss": 10.028696060180664,
    "ent_coef": 0.0833800882101059,
    "learning_rate": 0.001
  },
  {
    "episode": 11097,
    "reward": -2.086686,
    "length": 198,
    "time": 162851.203293,
    "actor_loss": -66.6420669555664,
    "critic_loss": 3.571995735168457,
    "ent_coef": 0.08505401760339737,
    "learning_rate": 0.001
  },
  {
    "episode": 11098,
    "reward": 88.379756,
    "length": 67,
    "time": 162862.955405,
    "actor_loss": -61.187591552734375,
    "critic_loss": 5.037470817565918,
    "ent_coef": 0.08353820443153381,
    "learning_rate": 0.001
  },
  {
    "episode": 11099,
    "reward": 81.235596,
    "length": 78,
    "time": 162879.574033,
    "actor_loss": -62.12437057495117,
    "critic_loss": 255.18124389648438,
    "ent_coef": 0.08521237969398499,
    "learning_rate": 0.001
  },
  {
    "episode": 11100,
    "reward": 89.699494,
    "length": 64,
    "time": 162891.948019,
    "actor_loss": -65.35096740722656,
    "critic_loss": 5.715008735656738,
    "ent_coef": 0.08678974211215973,
    "learning_rate": 0.001
  },
  {
    "episode": 11101,
    "reward": 73.092476,
    "length": 90,
    "time": 162909.368766,
    "actor_loss": -71.5866470336914,
    "critic_loss": 99.20843505859375,
    "ent_coef": 0.09651029109954834,
    "learning_rate": 0.001
  },
  {
    "episode": 11102,
    "reward": 88.864019,
    "length": 65,
    "time": 162922.932289,
    "actor_loss": -61.569583892822266,
    "critic_loss": 9.713140487670898,
    "ent_coef": 0.09594082832336426,
    "learning_rate": 0.001
  },
  {
    "episode": 11103,
    "reward": 75.432982,
    "length": 86,
    "time": 162940.385384,
    "actor_loss": -56.68098831176758,
    "critic_loss": 8.934148788452148,
    "ent_coef": 0.0940568745136261,
    "learning_rate": 0.001
  },
  {
    "episode": 11104,
    "reward": 89.997493,
    "length": 63,
    "time": 162951.775585,
    "actor_loss": -64.61031341552734,
    "critic_loss": 15.503887176513672,
    "ent_coef": 0.09235857427120209,
    "learning_rate": 0.001
  },
  {
    "episode": 11105,
    "reward": 84.218784,
    "length": 73,
    "time": 162964.351583,
    "actor_loss": -59.50908660888672,
    "critic_loss": 81.96947479248047,
    "ent_coef": 0.08914972096681595,
    "learning_rate": 0.001
  },
  {
    "episode": 11106,
    "reward": 89.013665,
    "length": 65,
    "time": 162975.754135,
    "actor_loss": -60.010009765625,
    "critic_loss": 107.900146484375,
    "ent_coef": 0.08750501275062561,
    "learning_rate": 0.001
  },
  {
    "episode": 11107,
    "reward": 86.859513,
    "length": 68,
    "time": 162990.475399,
    "actor_loss": -64.11966705322266,
    "critic_loss": 53.898860931396484,
    "ent_coef": 0.08499914407730103,
    "learning_rate": 0.001
  },
  {
    "episode": 11108,
    "reward": -1.909288,
    "length": 200,
    "time": 163019.800064,
    "actor_loss": -56.82707214355469,
    "critic_loss": 8.132777214050293,
    "ent_coef": 0.08754419535398483,
    "learning_rate": 0.001
  },
  {
    "episode": 11109,
    "reward": 91.796116,
    "length": 59,
    "time": 163031.666664,
    "actor_loss": -67.16984558105469,
    "critic_loss": 8.555513381958008,
    "ent_coef": 0.09540817886590958,
    "learning_rate": 0.001
  },
  {
    "episode": 11110,
    "reward": 88.861542,
    "length": 66,
    "time": 163045.833498,
    "actor_loss": -66.62271118164062,
    "critic_loss": 6.07462739944458,
    "ent_coef": 0.09930419921875,
    "learning_rate": 0.001
  },
  {
    "episode": 11111,
    "reward": 74.678322,
    "length": 89,
    "time": 163062.435752,
    "actor_loss": -64.06224060058594,
    "critic_loss": 5.783707618713379,
    "ent_coef": 0.10109977424144745,
    "learning_rate": 0.001
  },
  {
    "episode": 11112,
    "reward": 85.170439,
    "length": 73,
    "time": 163076.045316,
    "actor_loss": -65.87683868408203,
    "critic_loss": 7.550546646118164,
    "ent_coef": 0.09791524708271027,
    "learning_rate": 0.001
  },
  {
    "episode": 11113,
    "reward": 88.356219,
    "length": 65,
    "time": 163088.97119,
    "actor_loss": -55.59855651855469,
    "critic_loss": 26.61316680908203,
    "ent_coef": 0.09466996788978577,
    "learning_rate": 0.001
  },
  {
    "episode": 11114,
    "reward": 87.299061,
    "length": 68,
    "time": 163101.287952,
    "actor_loss": -66.47709655761719,
    "critic_loss": 64.94779968261719,
    "ent_coef": 0.09210821986198425,
    "learning_rate": 0.001
  },
  {
    "episode": 11115,
    "reward": 88.174308,
    "length": 68,
    "time": 163113.1181,
    "actor_loss": -58.517433166503906,
    "critic_loss": 58.25743103027344,
    "ent_coef": 0.09002730250358582,
    "learning_rate": 0.001
  },
  {
    "episode": 11116,
    "reward": 87.532344,
    "length": 67,
    "time": 163126.031584,
    "actor_loss": -65.33746337890625,
    "critic_loss": 55.77648162841797,
    "ent_coef": 0.08861877024173737,
    "learning_rate": 0.001
  },
  {
    "episode": 11117,
    "reward": 85.857474,
    "length": 70,
    "time": 163138.487007,
    "actor_loss": -64.12307739257812,
    "critic_loss": 26.380199432373047,
    "ent_coef": 0.08598218113183975,
    "learning_rate": 0.001
  },
  {
    "episode": 11118,
    "reward": 87.690288,
    "length": 67,
    "time": 163150.74221,
    "actor_loss": -65.40809631347656,
    "critic_loss": 8.888216972351074,
    "ent_coef": 0.08471310883760452,
    "learning_rate": 0.001
  },
  {
    "episode": 11119,
    "reward": 82.105524,
    "length": 76,
    "time": 163165.173633,
    "actor_loss": -58.293724060058594,
    "critic_loss": 34.11952209472656,
    "ent_coef": 0.08753103017807007,
    "learning_rate": 0.001
  },
  {
    "episode": 11120,
    "reward": 81.616693,
    "length": 78,
    "time": 163179.384907,
    "actor_loss": -63.25590896606445,
    "critic_loss": 175.73265075683594,
    "ent_coef": 0.08813431113958359,
    "learning_rate": 0.001
  },
  {
    "episode": 11121,
    "reward": 89.880477,
    "length": 64,
    "time": 163191.198582,
    "actor_loss": -65.24339294433594,
    "critic_loss": 9.01974868774414,
    "ent_coef": 0.09151609987020493,
    "learning_rate": 0.001
  },
  {
    "episode": 11122,
    "reward": 88.568527,
    "length": 66,
    "time": 163203.21362,
    "actor_loss": -63.759578704833984,
    "critic_loss": 4.918278694152832,
    "ent_coef": 0.09269391000270844,
    "learning_rate": 0.001
  },
  {
    "episode": 11123,
    "reward": 88.849078,
    "length": 65,
    "time": 163215.778508,
    "actor_loss": -47.72577667236328,
    "critic_loss": 9.033543586730957,
    "ent_coef": 0.09660444408655167,
    "learning_rate": 0.001
  },
  {
    "episode": 11124,
    "reward": 86.058985,
    "length": 71,
    "time": 163232.545734,
    "actor_loss": -60.689517974853516,
    "critic_loss": 71.44380187988281,
    "ent_coef": 0.09487228095531464,
    "learning_rate": 0.001
  },
  {
    "episode": 11125,
    "reward": 86.853701,
    "length": 68,
    "time": 163245.277478,
    "actor_loss": -61.007568359375,
    "critic_loss": 21.59949493408203,
    "ent_coef": 0.09541326761245728,
    "learning_rate": 0.001
  },
  {
    "episode": 11126,
    "reward": 90.035877,
    "length": 64,
    "time": 163257.095039,
    "actor_loss": -63.489742279052734,
    "critic_loss": 13.746156692504883,
    "ent_coef": 0.09863602370023727,
    "learning_rate": 0.001
  },
  {
    "episode": 11127,
    "reward": 87.58654,
    "length": 69,
    "time": 163268.947528,
    "actor_loss": -64.11092376708984,
    "critic_loss": 8.049089431762695,
    "ent_coef": 0.1001134067773819,
    "learning_rate": 0.001
  },
  {
    "episode": 11128,
    "reward": 89.095348,
    "length": 65,
    "time": 163281.413158,
    "actor_loss": -62.58521270751953,
    "critic_loss": 4.766983985900879,
    "ent_coef": 0.0995575413107872,
    "learning_rate": 0.001
  },
  {
    "episode": 11129,
    "reward": 88.026193,
    "length": 67,
    "time": 163294.795079,
    "actor_loss": -65.80681610107422,
    "critic_loss": 17.189796447753906,
    "ent_coef": 0.09834941476583481,
    "learning_rate": 0.001
  },
  {
    "episode": 11130,
    "reward": 88.201285,
    "length": 67,
    "time": 163307.430149,
    "actor_loss": -56.48990249633789,
    "critic_loss": 31.141544342041016,
    "ent_coef": 0.09594450891017914,
    "learning_rate": 0.001
  },
  {
    "episode": 11131,
    "reward": 86.517868,
    "length": 69,
    "time": 163320.888828,
    "actor_loss": -64.40679931640625,
    "critic_loss": 5.88163948059082,
    "ent_coef": 0.09541583806276321,
    "learning_rate": 0.001
  },
  {
    "episode": 11132,
    "reward": 90.526282,
    "length": 62,
    "time": 163333.070033,
    "actor_loss": -59.39973831176758,
    "critic_loss": 10.818869590759277,
    "ent_coef": 0.09646555781364441,
    "learning_rate": 0.001
  },
  {
    "episode": 11133,
    "reward": 84.903205,
    "length": 72,
    "time": 163345.486795,
    "actor_loss": -59.57196807861328,
    "critic_loss": 14.583728790283203,
    "ent_coef": 0.094657301902771,
    "learning_rate": 0.001
  },
  {
    "episode": 11134,
    "reward": 88.714597,
    "length": 65,
    "time": 163359.567463,
    "actor_loss": -55.391788482666016,
    "critic_loss": 6.024325847625732,
    "ent_coef": 0.09589730948209763,
    "learning_rate": 0.001
  },
  {
    "episode": 11135,
    "reward": 90.390037,
    "length": 63,
    "time": 163371.036511,
    "actor_loss": -69.48345184326172,
    "critic_loss": 7.039800643920898,
    "ent_coef": 0.09684194624423981,
    "learning_rate": 0.001
  },
  {
    "episode": 11136,
    "reward": 88.190752,
    "length": 68,
    "time": 163383.97876,
    "actor_loss": -65.32084655761719,
    "critic_loss": 3.6147375106811523,
    "ent_coef": 0.09810931235551834,
    "learning_rate": 0.001
  },
  {
    "episode": 11137,
    "reward": 90.54655,
    "length": 63,
    "time": 163399.478086,
    "actor_loss": -66.3780517578125,
    "critic_loss": 5.480947971343994,
    "ent_coef": 0.1001661941409111,
    "learning_rate": 0.001
  },
  {
    "episode": 11138,
    "reward": 91.632417,
    "length": 61,
    "time": 163410.860033,
    "actor_loss": -51.21197509765625,
    "critic_loss": 4.582250118255615,
    "ent_coef": 0.10631407797336578,
    "learning_rate": 0.001
  },
  {
    "episode": 11139,
    "reward": 89.469825,
    "length": 64,
    "time": 163423.398665,
    "actor_loss": -64.95916748046875,
    "critic_loss": 22.16476058959961,
    "ent_coef": 0.10738682746887207,
    "learning_rate": 0.001
  },
  {
    "episode": 11140,
    "reward": 90.693259,
    "length": 62,
    "time": 163438.396788,
    "actor_loss": -63.686500549316406,
    "critic_loss": 7.7516303062438965,
    "ent_coef": 0.10744887590408325,
    "learning_rate": 0.001
  },
  {
    "episode": 11141,
    "reward": 89.585084,
    "length": 65,
    "time": 163454.126173,
    "actor_loss": -59.8916015625,
    "critic_loss": 41.337406158447266,
    "ent_coef": 0.10595725476741791,
    "learning_rate": 0.001
  },
  {
    "episode": 11142,
    "reward": 88.990802,
    "length": 65,
    "time": 163465.727334,
    "actor_loss": -67.672607421875,
    "critic_loss": 2.5016355514526367,
    "ent_coef": 0.10610449314117432,
    "learning_rate": 0.001
  },
  {
    "episode": 11143,
    "reward": 89.4318,
    "length": 65,
    "time": 163477.645341,
    "actor_loss": -59.211753845214844,
    "critic_loss": 7.898423194885254,
    "ent_coef": 0.10505962371826172,
    "learning_rate": 0.001
  },
  {
    "episode": 11144,
    "reward": 88.703086,
    "length": 65,
    "time": 163489.133545,
    "actor_loss": -60.8140869140625,
    "critic_loss": 17.935564041137695,
    "ent_coef": 0.10403641313314438,
    "learning_rate": 0.001
  },
  {
    "episode": 11145,
    "reward": 87.981755,
    "length": 67,
    "time": 163507.056265,
    "actor_loss": -62.08109664916992,
    "critic_loss": 26.600528717041016,
    "ent_coef": 0.10414493083953857,
    "learning_rate": 0.001
  },
  {
    "episode": 11146,
    "reward": 88.712402,
    "length": 66,
    "time": 163521.143545,
    "actor_loss": -59.0111083984375,
    "critic_loss": 9.701805114746094,
    "ent_coef": 0.1046530082821846,
    "learning_rate": 0.001
  },
  {
    "episode": 11147,
    "reward": 87.540165,
    "length": 67,
    "time": 163533.210556,
    "actor_loss": -54.26539611816406,
    "critic_loss": 18.999107360839844,
    "ent_coef": 0.10068485140800476,
    "learning_rate": 0.001
  },
  {
    "episode": 11148,
    "reward": 76.244072,
    "length": 84,
    "time": 163549.09433,
    "actor_loss": -62.09430694580078,
    "critic_loss": 37.95869445800781,
    "ent_coef": 0.09815318137407303,
    "learning_rate": 0.001
  },
  {
    "episode": 11149,
    "reward": 89.634707,
    "length": 63,
    "time": 163560.233939,
    "actor_loss": -54.447174072265625,
    "critic_loss": 28.910480499267578,
    "ent_coef": 0.0989556610584259,
    "learning_rate": 0.001
  },
  {
    "episode": 11150,
    "reward": 86.514143,
    "length": 68,
    "time": 163573.160728,
    "actor_loss": -65.84375,
    "critic_loss": 8.887965202331543,
    "ent_coef": 0.09791155159473419,
    "learning_rate": 0.001
  },
  {
    "episode": 11151,
    "reward": 88.996218,
    "length": 65,
    "time": 163585.466178,
    "actor_loss": -61.66075897216797,
    "critic_loss": 6.633157253265381,
    "ent_coef": 0.10111929476261139,
    "learning_rate": 0.001
  },
  {
    "episode": 11152,
    "reward": 88.984373,
    "length": 66,
    "time": 163597.453982,
    "actor_loss": -66.6281509399414,
    "critic_loss": 5.807092666625977,
    "ent_coef": 0.10673646628856659,
    "learning_rate": 0.001
  },
  {
    "episode": 11153,
    "reward": 90.362181,
    "length": 62,
    "time": 163608.593921,
    "actor_loss": -66.4359130859375,
    "critic_loss": 4.870506286621094,
    "ent_coef": 0.10637987405061722,
    "learning_rate": 0.001
  },
  {
    "episode": 11154,
    "reward": 88.887589,
    "length": 66,
    "time": 163621.404868,
    "actor_loss": -64.32203674316406,
    "critic_loss": 15.222412109375,
    "ent_coef": 0.105401910841465,
    "learning_rate": 0.001
  },
  {
    "episode": 11155,
    "reward": 89.103367,
    "length": 65,
    "time": 163633.037259,
    "actor_loss": -70.09246826171875,
    "critic_loss": 5.128212928771973,
    "ent_coef": 0.10008114576339722,
    "learning_rate": 0.001
  },
  {
    "episode": 11156,
    "reward": 87.814193,
    "length": 66,
    "time": 163645.889405,
    "actor_loss": -65.4892349243164,
    "critic_loss": 516.974609375,
    "ent_coef": 0.10059954971075058,
    "learning_rate": 0.001
  },
  {
    "episode": 11157,
    "reward": 88.557536,
    "length": 66,
    "time": 163659.000823,
    "actor_loss": -62.888790130615234,
    "critic_loss": 5.940036773681641,
    "ent_coef": 0.10321084409952164,
    "learning_rate": 0.001
  },
  {
    "episode": 11158,
    "reward": 90.285375,
    "length": 63,
    "time": 163676.217983,
    "actor_loss": -62.09209060668945,
    "critic_loss": 9.176206588745117,
    "ent_coef": 0.10472576320171356,
    "learning_rate": 0.001
  },
  {
    "episode": 11159,
    "reward": 91.08379,
    "length": 62,
    "time": 163687.410612,
    "actor_loss": -59.20145034790039,
    "critic_loss": 6.979497909545898,
    "ent_coef": 0.10179142653942108,
    "learning_rate": 0.001
  },
  {
    "episode": 11160,
    "reward": 89.235986,
    "length": 64,
    "time": 163698.87526,
    "actor_loss": -63.69621276855469,
    "critic_loss": 4.486854076385498,
    "ent_coef": 0.10233072191476822,
    "learning_rate": 0.001
  },
  {
    "episode": 11161,
    "reward": 89.702928,
    "length": 65,
    "time": 163714.0592,
    "actor_loss": -67.13221740722656,
    "critic_loss": 7.512486457824707,
    "ent_coef": 0.10643137246370316,
    "learning_rate": 0.001
  },
  {
    "episode": 11162,
    "reward": 88.752114,
    "length": 66,
    "time": 163729.56226,
    "actor_loss": -68.17481231689453,
    "critic_loss": 17.34177017211914,
    "ent_coef": 0.10061176121234894,
    "learning_rate": 0.001
  },
  {
    "episode": 11163,
    "reward": 86.933354,
    "length": 70,
    "time": 163741.636121,
    "actor_loss": -67.89830780029297,
    "critic_loss": 17.372631072998047,
    "ent_coef": 0.09630277007818222,
    "learning_rate": 0.001
  },
  {
    "episode": 11164,
    "reward": 90.324046,
    "length": 63,
    "time": 163752.700474,
    "actor_loss": -66.43402862548828,
    "critic_loss": 17.27783203125,
    "ent_coef": 0.1003299355506897,
    "learning_rate": 0.001
  },
  {
    "episode": 11165,
    "reward": 90.257442,
    "length": 64,
    "time": 163764.895339,
    "actor_loss": -66.03121185302734,
    "critic_loss": 58.198089599609375,
    "ent_coef": 0.10330639779567719,
    "learning_rate": 0.001
  },
  {
    "episode": 11166,
    "reward": 90.283574,
    "length": 63,
    "time": 163777.541329,
    "actor_loss": -65.07039642333984,
    "critic_loss": 49.06925582885742,
    "ent_coef": 0.10063858330249786,
    "learning_rate": 0.001
  },
  {
    "episode": 11167,
    "reward": 87.858822,
    "length": 67,
    "time": 163790.420065,
    "actor_loss": -66.6682357788086,
    "critic_loss": 16.184368133544922,
    "ent_coef": 0.098305344581604,
    "learning_rate": 0.001
  },
  {
    "episode": 11168,
    "reward": 82.082867,
    "length": 75,
    "time": 163803.21343,
    "actor_loss": -62.0941276550293,
    "critic_loss": 8.027061462402344,
    "ent_coef": 0.09239593148231506,
    "learning_rate": 0.001
  },
  {
    "episode": 11169,
    "reward": 87.232799,
    "length": 68,
    "time": 163815.234677,
    "actor_loss": -55.37427520751953,
    "critic_loss": 20.411075592041016,
    "ent_coef": 0.09694254398345947,
    "learning_rate": 0.001
  },
  {
    "episode": 11170,
    "reward": 87.662985,
    "length": 67,
    "time": 163827.505405,
    "actor_loss": -59.269081115722656,
    "critic_loss": 4.811821460723877,
    "ent_coef": 0.09983333200216293,
    "learning_rate": 0.001
  },
  {
    "episode": 11171,
    "reward": 88.538922,
    "length": 67,
    "time": 163839.537328,
    "actor_loss": -61.377960205078125,
    "critic_loss": 4.7061567306518555,
    "ent_coef": 0.10262897610664368,
    "learning_rate": 0.001
  },
  {
    "episode": 11172,
    "reward": 88.299011,
    "length": 65,
    "time": 163851.784518,
    "actor_loss": -59.024147033691406,
    "critic_loss": 12.430519104003906,
    "ent_coef": 0.11047284305095673,
    "learning_rate": 0.001
  },
  {
    "episode": 11173,
    "reward": 88.625732,
    "length": 66,
    "time": 163863.387451,
    "actor_loss": -66.79295349121094,
    "critic_loss": 28.562856674194336,
    "ent_coef": 0.11157215386629105,
    "learning_rate": 0.001
  },
  {
    "episode": 11174,
    "reward": 86.945391,
    "length": 69,
    "time": 163877.248648,
    "actor_loss": -62.518707275390625,
    "critic_loss": 3.4088499546051025,
    "ent_coef": 0.10911145061254501,
    "learning_rate": 0.001
  },
  {
    "episode": 11175,
    "reward": 86.53448,
    "length": 70,
    "time": 163892.375979,
    "actor_loss": -63.00489807128906,
    "critic_loss": 5.090911388397217,
    "ent_coef": 0.10821934044361115,
    "learning_rate": 0.001
  },
  {
    "episode": 11176,
    "reward": 79.554788,
    "length": 80,
    "time": 163909.052195,
    "actor_loss": -54.033817291259766,
    "critic_loss": 52.36531066894531,
    "ent_coef": 0.10105549544095993,
    "learning_rate": 0.001
  },
  {
    "episode": 11177,
    "reward": 83.451942,
    "length": 75,
    "time": 163921.604883,
    "actor_loss": -58.03564453125,
    "critic_loss": 9.505759239196777,
    "ent_coef": 0.09649243205785751,
    "learning_rate": 0.001
  },
  {
    "episode": 11178,
    "reward": 87.103495,
    "length": 69,
    "time": 163933.498381,
    "actor_loss": -63.189720153808594,
    "critic_loss": 10.649721145629883,
    "ent_coef": 0.09604399651288986,
    "learning_rate": 0.001
  },
  {
    "episode": 11179,
    "reward": 87.28381,
    "length": 69,
    "time": 163948.641698,
    "actor_loss": -59.688453674316406,
    "critic_loss": 9.133556365966797,
    "ent_coef": 0.09611042588949203,
    "learning_rate": 0.001
  },
  {
    "episode": 11180,
    "reward": 84.918171,
    "length": 73,
    "time": 163961.184258,
    "actor_loss": -60.963218688964844,
    "critic_loss": 24.47545623779297,
    "ent_coef": 0.09788735210895538,
    "learning_rate": 0.001
  },
  {
    "episode": 11181,
    "reward": 86.638999,
    "length": 70,
    "time": 163973.755241,
    "actor_loss": -64.18635559082031,
    "critic_loss": 10.314297676086426,
    "ent_coef": 0.09708299487829208,
    "learning_rate": 0.001
  },
  {
    "episode": 11182,
    "reward": 87.358353,
    "length": 68,
    "time": 163986.848756,
    "actor_loss": -60.90584182739258,
    "critic_loss": 46.362953186035156,
    "ent_coef": 0.09756609052419662,
    "learning_rate": 0.001
  },
  {
    "episode": 11183,
    "reward": 83.235477,
    "length": 74,
    "time": 164000.931633,
    "actor_loss": -59.84564971923828,
    "critic_loss": 31.042064666748047,
    "ent_coef": 0.09441125392913818,
    "learning_rate": 0.001
  },
  {
    "episode": 11184,
    "reward": 84.412849,
    "length": 73,
    "time": 164014.013866,
    "actor_loss": -61.57722473144531,
    "critic_loss": 17.66314697265625,
    "ent_coef": 0.09495605528354645,
    "learning_rate": 0.001
  },
  {
    "episode": 11185,
    "reward": 87.386942,
    "length": 68,
    "time": 164026.262932,
    "actor_loss": -57.19447326660156,
    "critic_loss": 17.11688232421875,
    "ent_coef": 0.09611696004867554,
    "learning_rate": 0.001
  },
  {
    "episode": 11186,
    "reward": 86.630897,
    "length": 68,
    "time": 164039.12905,
    "actor_loss": -56.474815368652344,
    "critic_loss": 28.489486694335938,
    "ent_coef": 0.0950169786810875,
    "learning_rate": 0.001
  },
  {
    "episode": 11187,
    "reward": 87.01592,
    "length": 68,
    "time": 164050.918285,
    "actor_loss": -64.36531829833984,
    "critic_loss": 5.165485382080078,
    "ent_coef": 0.09523919969797134,
    "learning_rate": 0.001
  },
  {
    "episode": 11188,
    "reward": 86.810859,
    "length": 70,
    "time": 164062.98207,
    "actor_loss": -66.7645034790039,
    "critic_loss": 25.040943145751953,
    "ent_coef": 0.0969165712594986,
    "learning_rate": 0.001
  },
  {
    "episode": 11189,
    "reward": 88.165137,
    "length": 66,
    "time": 164076.450437,
    "actor_loss": -61.952598571777344,
    "critic_loss": 10.569450378417969,
    "ent_coef": 0.09580228477716446,
    "learning_rate": 0.001
  },
  {
    "episode": 11190,
    "reward": 87.523622,
    "length": 67,
    "time": 164089.367568,
    "actor_loss": -67.01020812988281,
    "critic_loss": 12.43402099609375,
    "ent_coef": 0.09353774040937424,
    "learning_rate": 0.001
  },
  {
    "episode": 11191,
    "reward": 84.984543,
    "length": 83,
    "time": 164107.35207,
    "actor_loss": -64.44292449951172,
    "critic_loss": 44.268089294433594,
    "ent_coef": 0.09351406246423721,
    "learning_rate": 0.001
  },
  {
    "episode": 11192,
    "reward": 89.474544,
    "length": 62,
    "time": 164119.562004,
    "actor_loss": -62.09333801269531,
    "critic_loss": 10.88187313079834,
    "ent_coef": 0.09334341436624527,
    "learning_rate": 0.001
  },
  {
    "episode": 11193,
    "reward": 87.006279,
    "length": 69,
    "time": 164133.780158,
    "actor_loss": -69.66127014160156,
    "critic_loss": 18.714523315429688,
    "ent_coef": 0.09451685845851898,
    "learning_rate": 0.001
  },
  {
    "episode": 11194,
    "reward": 86.70643,
    "length": 71,
    "time": 164146.070827,
    "actor_loss": -65.03836059570312,
    "critic_loss": 32.51498031616211,
    "ent_coef": 0.09405414015054703,
    "learning_rate": 0.001
  },
  {
    "episode": 11195,
    "reward": 87.348157,
    "length": 68,
    "time": 164158.241789,
    "actor_loss": -69.86790466308594,
    "critic_loss": 3.9309475421905518,
    "ent_coef": 0.0942586287856102,
    "learning_rate": 0.001
  },
  {
    "episode": 11196,
    "reward": 86.841167,
    "length": 70,
    "time": 164171.464186,
    "actor_loss": -67.28419494628906,
    "critic_loss": 5.551609992980957,
    "ent_coef": 0.09691687673330307,
    "learning_rate": 0.001
  },
  {
    "episode": 11197,
    "reward": 87.311484,
    "length": 68,
    "time": 164186.112303,
    "actor_loss": -62.95252990722656,
    "critic_loss": 46.527198791503906,
    "ent_coef": 0.10206212103366852,
    "learning_rate": 0.001
  },
  {
    "episode": 11198,
    "reward": 86.875298,
    "length": 68,
    "time": 164198.484827,
    "actor_loss": -61.6409797668457,
    "critic_loss": 5.316228866577148,
    "ent_coef": 0.10159961879253387,
    "learning_rate": 0.001
  },
  {
    "episode": 11199,
    "reward": 86.26694,
    "length": 70,
    "time": 164212.835386,
    "actor_loss": -63.56890106201172,
    "critic_loss": 10.070119857788086,
    "ent_coef": 0.0968206524848938,
    "learning_rate": 0.001
  },
  {
    "episode": 11200,
    "reward": 87.176556,
    "length": 69,
    "time": 164225.332497,
    "actor_loss": -62.98698425292969,
    "critic_loss": 16.257713317871094,
    "ent_coef": 0.09507421404123306,
    "learning_rate": 0.001
  },
  {
    "episode": 11201,
    "reward": 86.201843,
    "length": 72,
    "time": 164238.490477,
    "actor_loss": -64.74055480957031,
    "critic_loss": 3.3600597381591797,
    "ent_coef": 0.09404360502958298,
    "learning_rate": 0.001
  },
  {
    "episode": 11202,
    "reward": 84.48182,
    "length": 73,
    "time": 164251.158115,
    "actor_loss": -59.298362731933594,
    "critic_loss": 22.86278533935547,
    "ent_coef": 0.08837848156690598,
    "learning_rate": 0.001
  },
  {
    "episode": 11203,
    "reward": 84.377064,
    "length": 73,
    "time": 164263.570777,
    "actor_loss": -62.94302749633789,
    "critic_loss": 37.367454528808594,
    "ent_coef": 0.09138952195644379,
    "learning_rate": 0.001
  },
  {
    "episode": 11204,
    "reward": 85.196926,
    "length": 77,
    "time": 164277.536955,
    "actor_loss": -59.668853759765625,
    "critic_loss": 38.18586730957031,
    "ent_coef": 0.0974893793463707,
    "learning_rate": 0.001
  },
  {
    "episode": 11205,
    "reward": 87.44117,
    "length": 69,
    "time": 164289.543773,
    "actor_loss": -63.85316467285156,
    "critic_loss": 6.151180267333984,
    "ent_coef": 0.10036204755306244,
    "learning_rate": 0.001
  },
  {
    "episode": 11206,
    "reward": 85.432217,
    "length": 73,
    "time": 164303.685006,
    "actor_loss": -61.843170166015625,
    "critic_loss": 7.586297988891602,
    "ent_coef": 0.10141852498054504,
    "learning_rate": 0.001
  },
  {
    "episode": 11207,
    "reward": 84.055872,
    "length": 73,
    "time": 164318.866995,
    "actor_loss": -64.04176330566406,
    "critic_loss": 6.337458610534668,
    "ent_coef": 0.0991365909576416,
    "learning_rate": 0.001
  },
  {
    "episode": 11208,
    "reward": 86.752805,
    "length": 69,
    "time": 164333.27091,
    "actor_loss": -59.10353088378906,
    "critic_loss": 44.76463317871094,
    "ent_coef": 0.09734879434108734,
    "learning_rate": 0.001
  },
  {
    "episode": 11209,
    "reward": 87.118393,
    "length": 69,
    "time": 164348.361522,
    "actor_loss": -58.52459716796875,
    "critic_loss": 10.609567642211914,
    "ent_coef": 0.0954783707857132,
    "learning_rate": 0.001
  },
  {
    "episode": 11210,
    "reward": 86.389077,
    "length": 69,
    "time": 164363.337325,
    "actor_loss": -69.03411102294922,
    "critic_loss": 6.5979413986206055,
    "ent_coef": 0.09560538828372955,
    "learning_rate": 0.001
  },
  {
    "episode": 11211,
    "reward": 85.04429,
    "length": 71,
    "time": 164377.209663,
    "actor_loss": -65.80564880371094,
    "critic_loss": 55.64209747314453,
    "ent_coef": 0.09775695949792862,
    "learning_rate": 0.001
  },
  {
    "episode": 11212,
    "reward": 87.924939,
    "length": 67,
    "time": 164391.45258,
    "actor_loss": -65.79127502441406,
    "critic_loss": 4.2996673583984375,
    "ent_coef": 0.09501564502716064,
    "learning_rate": 0.001
  },
  {
    "episode": 11213,
    "reward": 86.238067,
    "length": 70,
    "time": 164403.505473,
    "actor_loss": -60.78594970703125,
    "critic_loss": 36.24538803100586,
    "ent_coef": 0.09524912387132645,
    "learning_rate": 0.001
  },
  {
    "episode": 11214,
    "reward": 87.230024,
    "length": 67,
    "time": 164415.583228,
    "actor_loss": -60.58097839355469,
    "critic_loss": 4.919924259185791,
    "ent_coef": 0.09355232864618301,
    "learning_rate": 0.001
  },
  {
    "episode": 11215,
    "reward": 87.155734,
    "length": 67,
    "time": 164429.182898,
    "actor_loss": -69.35941314697266,
    "critic_loss": 6.248329162597656,
    "ent_coef": 0.09407263994216919,
    "learning_rate": 0.001
  },
  {
    "episode": 11216,
    "reward": 87.902193,
    "length": 66,
    "time": 164442.216565,
    "actor_loss": -69.51185607910156,
    "critic_loss": 22.022756576538086,
    "ent_coef": 0.10074935108423233,
    "learning_rate": 0.001
  },
  {
    "episode": 11217,
    "reward": 85.080622,
    "length": 71,
    "time": 164454.458389,
    "actor_loss": -63.62103271484375,
    "critic_loss": 19.170442581176758,
    "ent_coef": 0.10271468013525009,
    "learning_rate": 0.001
  },
  {
    "episode": 11218,
    "reward": 85.73222,
    "length": 70,
    "time": 164466.846712,
    "actor_loss": -62.16554260253906,
    "critic_loss": 25.8405818939209,
    "ent_coef": 0.1024932935833931,
    "learning_rate": 0.001
  },
  {
    "episode": 11219,
    "reward": 87.051655,
    "length": 69,
    "time": 164478.740649,
    "actor_loss": -60.356910705566406,
    "critic_loss": 14.580602645874023,
    "ent_coef": 0.09889299422502518,
    "learning_rate": 0.001
  },
  {
    "episode": 11220,
    "reward": 85.266665,
    "length": 73,
    "time": 164492.870224,
    "actor_loss": -64.11389923095703,
    "critic_loss": 32.59563446044922,
    "ent_coef": 0.09302149713039398,
    "learning_rate": 0.001
  },
  {
    "episode": 11221,
    "reward": 85.13452,
    "length": 72,
    "time": 164507.971198,
    "actor_loss": -60.69530487060547,
    "critic_loss": 4.936046600341797,
    "ent_coef": 0.09032002836465836,
    "learning_rate": 0.001
  },
  {
    "episode": 11222,
    "reward": 86.204098,
    "length": 69,
    "time": 164522.399587,
    "actor_loss": -62.170040130615234,
    "critic_loss": 8.07444953918457,
    "ent_coef": 0.0889195129275322,
    "learning_rate": 0.001
  },
  {
    "episode": 11223,
    "reward": 88.789278,
    "length": 64,
    "time": 164533.709213,
    "actor_loss": -62.329532623291016,
    "critic_loss": 5.655332088470459,
    "ent_coef": 0.0940103828907013,
    "learning_rate": 0.001
  },
  {
    "episode": 11224,
    "reward": 85.507096,
    "length": 72,
    "time": 164545.98745,
    "actor_loss": -61.212196350097656,
    "critic_loss": 4.351747512817383,
    "ent_coef": 0.09674997627735138,
    "learning_rate": 0.001
  },
  {
    "episode": 11225,
    "reward": 88.41122,
    "length": 65,
    "time": 164558.527239,
    "actor_loss": -64.5262451171875,
    "critic_loss": 10.422869682312012,
    "ent_coef": 0.09898246824741364,
    "learning_rate": 0.001
  },
  {
    "episode": 11226,
    "reward": 86.440332,
    "length": 68,
    "time": 164573.22799,
    "actor_loss": -68.56428527832031,
    "critic_loss": 7.361598968505859,
    "ent_coef": 0.10071968287229538,
    "learning_rate": 0.001
  },
  {
    "episode": 11227,
    "reward": 87.746353,
    "length": 68,
    "time": 164588.117723,
    "actor_loss": -59.13825607299805,
    "critic_loss": 19.021617889404297,
    "ent_coef": 0.10084272921085358,
    "learning_rate": 0.001
  },
  {
    "episode": 11228,
    "reward": 86.760433,
    "length": 68,
    "time": 164599.809459,
    "actor_loss": -69.24945068359375,
    "critic_loss": 17.268783569335938,
    "ent_coef": 0.09671621024608612,
    "learning_rate": 0.001
  },
  {
    "episode": 11229,
    "reward": 85.174455,
    "length": 71,
    "time": 164615.428755,
    "actor_loss": -68.2618637084961,
    "critic_loss": 19.026348114013672,
    "ent_coef": 0.09022900462150574,
    "learning_rate": 0.001
  },
  {
    "episode": 11230,
    "reward": 88.735265,
    "length": 65,
    "time": 164629.746745,
    "actor_loss": -59.53933334350586,
    "critic_loss": 5.418166637420654,
    "ent_coef": 0.09177478402853012,
    "learning_rate": 0.001
  },
  {
    "episode": 11231,
    "reward": 87.615222,
    "length": 67,
    "time": 164643.634628,
    "actor_loss": -70.84947204589844,
    "critic_loss": 13.129581451416016,
    "ent_coef": 0.09153105318546295,
    "learning_rate": 0.001
  },
  {
    "episode": 11232,
    "reward": 88.426124,
    "length": 65,
    "time": 164655.60804,
    "actor_loss": -59.4571647644043,
    "critic_loss": 8.687455177307129,
    "ent_coef": 0.0902915820479393,
    "learning_rate": 0.001
  },
  {
    "episode": 11233,
    "reward": 85.904387,
    "length": 72,
    "time": 164667.912847,
    "actor_loss": -63.605552673339844,
    "critic_loss": 3.1397151947021484,
    "ent_coef": 0.09364768862724304,
    "learning_rate": 0.001
  },
  {
    "episode": 11234,
    "reward": 87.048406,
    "length": 68,
    "time": 164679.838277,
    "actor_loss": -64.25221252441406,
    "critic_loss": 10.263839721679688,
    "ent_coef": 0.09197304397821426,
    "learning_rate": 0.001
  },
  {
    "episode": 11235,
    "reward": 88.980002,
    "length": 65,
    "time": 164691.46733,
    "actor_loss": -63.20551300048828,
    "critic_loss": 4.893483638763428,
    "ent_coef": 0.09143806248903275,
    "learning_rate": 0.001
  },
  {
    "episode": 11236,
    "reward": 84.674958,
    "length": 72,
    "time": 164705.803921,
    "actor_loss": -61.29057312011719,
    "critic_loss": 14.965911865234375,
    "ent_coef": 0.08972633630037308,
    "learning_rate": 0.001
  },
  {
    "episode": 11237,
    "reward": 89.097765,
    "length": 65,
    "time": 164718.208855,
    "actor_loss": -65.06098937988281,
    "critic_loss": 189.4720001220703,
    "ent_coef": 0.09147631376981735,
    "learning_rate": 0.001
  },
  {
    "episode": 11238,
    "reward": 88.600241,
    "length": 64,
    "time": 164729.815968,
    "actor_loss": -66.84664916992188,
    "critic_loss": 8.480253219604492,
    "ent_coef": 0.08932844549417496,
    "learning_rate": 0.001
  },
  {
    "episode": 11239,
    "reward": 88.042218,
    "length": 67,
    "time": 164744.121226,
    "actor_loss": -65.79623413085938,
    "critic_loss": 6.204825401306152,
    "ent_coef": 0.09104612469673157,
    "learning_rate": 0.001
  },
  {
    "episode": 11240,
    "reward": 88.769464,
    "length": 65,
    "time": 164758.856616,
    "actor_loss": -60.04161834716797,
    "critic_loss": 25.01355743408203,
    "ent_coef": 0.09499827027320862,
    "learning_rate": 0.001
  },
  {
    "episode": 11241,
    "reward": 89.762012,
    "length": 64,
    "time": 164770.785494,
    "actor_loss": -60.939453125,
    "critic_loss": 5.008548736572266,
    "ent_coef": 0.10216629505157471,
    "learning_rate": 0.001
  },
  {
    "episode": 11242,
    "reward": 88.003768,
    "length": 65,
    "time": 164784.118294,
    "actor_loss": -59.315425872802734,
    "critic_loss": 16.85450553894043,
    "ent_coef": 0.10141634196043015,
    "learning_rate": 0.001
  },
  {
    "episode": 11243,
    "reward": 87.315299,
    "length": 67,
    "time": 164796.450524,
    "actor_loss": -59.94429397583008,
    "critic_loss": 5.748635292053223,
    "ent_coef": 0.10197997838258743,
    "learning_rate": 0.001
  },
  {
    "episode": 11244,
    "reward": 87.192985,
    "length": 68,
    "time": 164810.132909,
    "actor_loss": -65.81138610839844,
    "critic_loss": 16.829025268554688,
    "ent_coef": 0.10065921396017075,
    "learning_rate": 0.001
  },
  {
    "episode": 11245,
    "reward": 88.045054,
    "length": 65,
    "time": 164823.303704,
    "actor_loss": -67.91931915283203,
    "critic_loss": 4.59246826171875,
    "ent_coef": 0.09904936701059341,
    "learning_rate": 0.001
  },
  {
    "episode": 11246,
    "reward": 86.915026,
    "length": 68,
    "time": 164837.227075,
    "actor_loss": -63.839073181152344,
    "critic_loss": 12.724254608154297,
    "ent_coef": 0.10062252730131149,
    "learning_rate": 0.001
  },
  {
    "episode": 11247,
    "reward": 81.064283,
    "length": 74,
    "time": 164850.14446,
    "actor_loss": -61.64743423461914,
    "critic_loss": 24.251239776611328,
    "ent_coef": 0.10127849131822586,
    "learning_rate": 0.001
  },
  {
    "episode": 11248,
    "reward": 89.111146,
    "length": 64,
    "time": 164861.431581,
    "actor_loss": -63.331809997558594,
    "critic_loss": 7.170346260070801,
    "ent_coef": 0.10418303310871124,
    "learning_rate": 0.001
  },
  {
    "episode": 11249,
    "reward": 88.58863,
    "length": 65,
    "time": 164873.028406,
    "actor_loss": -60.353660583496094,
    "critic_loss": 24.049915313720703,
    "ent_coef": 0.10734487324953079,
    "learning_rate": 0.001
  },
  {
    "episode": 11250,
    "reward": 88.911781,
    "length": 65,
    "time": 164884.820504,
    "actor_loss": -66.81626892089844,
    "critic_loss": 12.51063346862793,
    "ent_coef": 0.10728911310434341,
    "learning_rate": 0.001
  },
  {
    "episode": 11251,
    "reward": 87.421566,
    "length": 68,
    "time": 164898.724504,
    "actor_loss": -56.097900390625,
    "critic_loss": 14.714032173156738,
    "ent_coef": 0.10201411694288254,
    "learning_rate": 0.001
  },
  {
    "episode": 11252,
    "reward": 88.568852,
    "length": 65,
    "time": 164910.524514,
    "actor_loss": -70.06957244873047,
    "critic_loss": 12.168008804321289,
    "ent_coef": 0.09642801433801651,
    "learning_rate": 0.001
  },
  {
    "episode": 11253,
    "reward": 89.653686,
    "length": 63,
    "time": 164922.169413,
    "actor_loss": -62.75333023071289,
    "critic_loss": 15.172001838684082,
    "ent_coef": 0.09256672114133835,
    "learning_rate": 0.001
  },
  {
    "episode": 11254,
    "reward": 88.277915,
    "length": 66,
    "time": 164933.750009,
    "actor_loss": -67.41040802001953,
    "critic_loss": 4.156989574432373,
    "ent_coef": 0.0902840718626976,
    "learning_rate": 0.001
  },
  {
    "episode": 11255,
    "reward": 87.58924,
    "length": 67,
    "time": 164948.159651,
    "actor_loss": -67.41293334960938,
    "critic_loss": 9.797996520996094,
    "ent_coef": 0.09005728363990784,
    "learning_rate": 0.001
  },
  {
    "episode": 11256,
    "reward": 89.365441,
    "length": 64,
    "time": 164959.502367,
    "actor_loss": -63.35139083862305,
    "critic_loss": 5.241189479827881,
    "ent_coef": 0.09118500351905823,
    "learning_rate": 0.001
  },
  {
    "episode": 11257,
    "reward": 90.1217,
    "length": 62,
    "time": 164973.167308,
    "actor_loss": -64.91041564941406,
    "critic_loss": 4.952175617218018,
    "ent_coef": 0.0987137034535408,
    "learning_rate": 0.001
  },
  {
    "episode": 11258,
    "reward": 88.986223,
    "length": 65,
    "time": 164984.68389,
    "actor_loss": -67.18243408203125,
    "critic_loss": 28.27403450012207,
    "ent_coef": 0.09863308817148209,
    "learning_rate": 0.001
  },
  {
    "episode": 11259,
    "reward": 89.388665,
    "length": 64,
    "time": 164996.033594,
    "actor_loss": -60.01109313964844,
    "critic_loss": 6.037786483764648,
    "ent_coef": 0.09919454157352448,
    "learning_rate": 0.001
  },
  {
    "episode": 11260,
    "reward": 88.094799,
    "length": 67,
    "time": 165008.550881,
    "actor_loss": -68.50970458984375,
    "critic_loss": 10.27616024017334,
    "ent_coef": 0.09692385047674179,
    "learning_rate": 0.001
  },
  {
    "episode": 11261,
    "reward": 86.945172,
    "length": 68,
    "time": 165023.564639,
    "actor_loss": -69.24589538574219,
    "critic_loss": 65.97151947021484,
    "ent_coef": 0.09570236504077911,
    "learning_rate": 0.001
  },
  {
    "episode": 11262,
    "reward": 85.639827,
    "length": 71,
    "time": 165036.994799,
    "actor_loss": -62.93318557739258,
    "critic_loss": 18.1903133392334,
    "ent_coef": 0.09381980448961258,
    "learning_rate": 0.001
  },
  {
    "episode": 11263,
    "reward": 89.778304,
    "length": 64,
    "time": 165053.052541,
    "actor_loss": -60.58715057373047,
    "critic_loss": 23.646255493164062,
    "ent_coef": 0.09154380857944489,
    "learning_rate": 0.001
  },
  {
    "episode": 11264,
    "reward": 86.821451,
    "length": 69,
    "time": 165065.05096,
    "actor_loss": -66.17906188964844,
    "critic_loss": 5.435354232788086,
    "ent_coef": 0.0875479131937027,
    "learning_rate": 0.001
  },
  {
    "episode": 11265,
    "reward": 87.169603,
    "length": 67,
    "time": 165077.858631,
    "actor_loss": -69.70686340332031,
    "critic_loss": 7.403939723968506,
    "ent_coef": 0.0883212685585022,
    "learning_rate": 0.001
  },
  {
    "episode": 11266,
    "reward": 90.180471,
    "length": 64,
    "time": 165091.640045,
    "actor_loss": -66.781005859375,
    "critic_loss": 7.226507186889648,
    "ent_coef": 0.08707057684659958,
    "learning_rate": 0.001
  },
  {
    "episode": 11267,
    "reward": 86.363974,
    "length": 71,
    "time": 165104.611253,
    "actor_loss": -67.0622787475586,
    "critic_loss": 4.807663917541504,
    "ent_coef": 0.08299762010574341,
    "learning_rate": 0.001
  },
  {
    "episode": 11268,
    "reward": 89.846979,
    "length": 64,
    "time": 165116.365859,
    "actor_loss": -61.90779113769531,
    "critic_loss": 23.693500518798828,
    "ent_coef": 0.08319966495037079,
    "learning_rate": 0.001
  },
  {
    "episode": 11269,
    "reward": 90.252902,
    "length": 63,
    "time": 165130.009036,
    "actor_loss": -64.39393615722656,
    "critic_loss": 15.327362060546875,
    "ent_coef": 0.08385452628135681,
    "learning_rate": 0.001
  },
  {
    "episode": 11270,
    "reward": 90.883632,
    "length": 62,
    "time": 165141.305938,
    "actor_loss": -63.20423126220703,
    "critic_loss": 25.51934814453125,
    "ent_coef": 0.08548435568809509,
    "learning_rate": 0.001
  },
  {
    "episode": 11271,
    "reward": 90.01735,
    "length": 63,
    "time": 165154.770451,
    "actor_loss": -64.69973754882812,
    "critic_loss": 5.078531265258789,
    "ent_coef": 0.08898907154798508,
    "learning_rate": 0.001
  },
  {
    "episode": 11272,
    "reward": 87.564529,
    "length": 68,
    "time": 165167.474275,
    "actor_loss": -61.96062469482422,
    "critic_loss": 5.972020149230957,
    "ent_coef": 0.08378101140260696,
    "learning_rate": 0.001
  },
  {
    "episode": 11273,
    "reward": 90.716193,
    "length": 63,
    "time": 165181.409067,
    "actor_loss": -63.89329147338867,
    "critic_loss": 6.473992824554443,
    "ent_coef": 0.08594473451375961,
    "learning_rate": 0.001
  },
  {
    "episode": 11274,
    "reward": 84.445251,
    "length": 79,
    "time": 165195.586943,
    "actor_loss": -65.84595489501953,
    "critic_loss": 6.142830848693848,
    "ent_coef": 0.08371168375015259,
    "learning_rate": 0.001
  },
  {
    "episode": 11275,
    "reward": 89.253667,
    "length": 65,
    "time": 165208.84786,
    "actor_loss": -69.31446075439453,
    "critic_loss": 18.437936782836914,
    "ent_coef": 0.07678049057722092,
    "learning_rate": 0.001
  },
  {
    "episode": 11276,
    "reward": 90.099514,
    "length": 63,
    "time": 165220.440635,
    "actor_loss": -66.46190643310547,
    "critic_loss": 20.07858657836914,
    "ent_coef": 0.07424253225326538,
    "learning_rate": 0.001
  },
  {
    "episode": 11277,
    "reward": 89.194651,
    "length": 66,
    "time": 165232.178516,
    "actor_loss": -67.01933288574219,
    "critic_loss": 44.07745361328125,
    "ent_coef": 0.07096235454082489,
    "learning_rate": 0.001
  },
  {
    "episode": 11278,
    "reward": 90.796012,
    "length": 61,
    "time": 165244.222884,
    "actor_loss": -64.15167236328125,
    "critic_loss": 24.24350357055664,
    "ent_coef": 0.07415411621332169,
    "learning_rate": 0.001
  },
  {
    "episode": 11279,
    "reward": 87.46902,
    "length": 70,
    "time": 165258.698892,
    "actor_loss": -63.89300537109375,
    "critic_loss": 7.055761337280273,
    "ent_coef": 0.07266810536384583,
    "learning_rate": 0.001
  },
  {
    "episode": 11280,
    "reward": 88.646478,
    "length": 67,
    "time": 165272.137225,
    "actor_loss": -71.42945861816406,
    "critic_loss": 15.489487648010254,
    "ent_coef": 0.071031853556633,
    "learning_rate": 0.001
  },
  {
    "episode": 11281,
    "reward": 88.433807,
    "length": 67,
    "time": 165284.266509,
    "actor_loss": -66.75651550292969,
    "critic_loss": 6.847774505615234,
    "ent_coef": 0.06956245005130768,
    "learning_rate": 0.001
  },
  {
    "episode": 11282,
    "reward": 88.462821,
    "length": 67,
    "time": 165296.254096,
    "actor_loss": -58.12446975708008,
    "critic_loss": 27.928617477416992,
    "ent_coef": 0.06735440343618393,
    "learning_rate": 0.001
  },
  {
    "episode": 11283,
    "reward": 89.482951,
    "length": 64,
    "time": 165307.714786,
    "actor_loss": -63.4979248046875,
    "critic_loss": 16.663637161254883,
    "ent_coef": 0.06760301440954208,
    "learning_rate": 0.001
  },
  {
    "episode": 11284,
    "reward": 89.432474,
    "length": 65,
    "time": 165320.461695,
    "actor_loss": -70.05630493164062,
    "critic_loss": 55.20820236206055,
    "ent_coef": 0.06610126793384552,
    "learning_rate": 0.001
  },
  {
    "episode": 11285,
    "reward": 90.615295,
    "length": 62,
    "time": 165331.407104,
    "actor_loss": -69.14214324951172,
    "critic_loss": 12.328751564025879,
    "ent_coef": 0.06816655397415161,
    "learning_rate": 0.001
  },
  {
    "episode": 11286,
    "reward": 90.036496,
    "length": 65,
    "time": 165346.739243,
    "actor_loss": -69.52462768554688,
    "critic_loss": 17.89169692993164,
    "ent_coef": 0.06971567869186401,
    "learning_rate": 0.001
  },
  {
    "episode": 11287,
    "reward": 92.250909,
    "length": 58,
    "time": 165358.213479,
    "actor_loss": -70.13058471679688,
    "critic_loss": 51.802345275878906,
    "ent_coef": 0.07376058399677277,
    "learning_rate": 0.001
  },
  {
    "episode": 11288,
    "reward": 90.989835,
    "length": 62,
    "time": 165369.376369,
    "actor_loss": -59.987857818603516,
    "critic_loss": 16.827709197998047,
    "ent_coef": 0.07722744345664978,
    "learning_rate": 0.001
  },
  {
    "episode": 11289,
    "reward": 90.228937,
    "length": 64,
    "time": 165381.703498,
    "actor_loss": -63.06843185424805,
    "critic_loss": 4.1861162185668945,
    "ent_coef": 0.0767507404088974,
    "learning_rate": 0.001
  },
  {
    "episode": 11290,
    "reward": 86.69584,
    "length": 71,
    "time": 165397.256608,
    "actor_loss": -72.1767349243164,
    "critic_loss": 48.599517822265625,
    "ent_coef": 0.07687647640705109,
    "learning_rate": 0.001
  },
  {
    "episode": 11291,
    "reward": 87.220266,
    "length": 70,
    "time": 165411.069094,
    "actor_loss": -67.3775634765625,
    "critic_loss": 14.761434555053711,
    "ent_coef": 0.0803888589143753,
    "learning_rate": 0.001
  },
  {
    "episode": 11292,
    "reward": 90.817664,
    "length": 61,
    "time": 165423.706328,
    "actor_loss": -63.13165283203125,
    "critic_loss": 7.864307880401611,
    "ent_coef": 0.08146238327026367,
    "learning_rate": 0.001
  },
  {
    "episode": 11293,
    "reward": 89.205129,
    "length": 65,
    "time": 165435.370339,
    "actor_loss": -65.13660430908203,
    "critic_loss": 3.0361430644989014,
    "ent_coef": 0.08033474534749985,
    "learning_rate": 0.001
  },
  {
    "episode": 11294,
    "reward": 89.675924,
    "length": 65,
    "time": 165447.320781,
    "actor_loss": -68.81597137451172,
    "critic_loss": 21.263160705566406,
    "ent_coef": 0.0809229239821434,
    "learning_rate": 0.001
  },
  {
    "episode": 11295,
    "reward": 89.165669,
    "length": 66,
    "time": 165459.35165,
    "actor_loss": -57.38997268676758,
    "critic_loss": 75.03050231933594,
    "ent_coef": 0.08132175356149673,
    "learning_rate": 0.001
  },
  {
    "episode": 11296,
    "reward": 88.869369,
    "length": 66,
    "time": 165471.222254,
    "actor_loss": -64.53646850585938,
    "critic_loss": 38.687950134277344,
    "ent_coef": 0.08435694128274918,
    "learning_rate": 0.001
  },
  {
    "episode": 11297,
    "reward": 90.54598,
    "length": 63,
    "time": 165483.488206,
    "actor_loss": -56.41107940673828,
    "critic_loss": 6.282767295837402,
    "ent_coef": 0.0877423882484436,
    "learning_rate": 0.001
  },
  {
    "episode": 11298,
    "reward": 90.08659,
    "length": 64,
    "time": 165495.781544,
    "actor_loss": -58.876670837402344,
    "critic_loss": 5.0995073318481445,
    "ent_coef": 0.08835046738386154,
    "learning_rate": 0.001
  },
  {
    "episode": 11299,
    "reward": 88.141596,
    "length": 65,
    "time": 165508.227477,
    "actor_loss": -65.7318115234375,
    "critic_loss": 4.058289527893066,
    "ent_coef": 0.08857375383377075,
    "learning_rate": 0.001
  },
  {
    "episode": 11300,
    "reward": 90.60284,
    "length": 62,
    "time": 165521.976873,
    "actor_loss": -63.654640197753906,
    "critic_loss": 6.362878322601318,
    "ent_coef": 0.09150977432727814,
    "learning_rate": 0.001
  },
  {
    "episode": 11301,
    "reward": 89.338804,
    "length": 65,
    "time": 165536.071826,
    "actor_loss": -58.836002349853516,
    "critic_loss": 11.999900817871094,
    "ent_coef": 0.08836141973733902,
    "learning_rate": 0.001
  },
  {
    "episode": 11302,
    "reward": 89.296758,
    "length": 65,
    "time": 165548.567471,
    "actor_loss": -68.25113677978516,
    "critic_loss": 4.028270244598389,
    "ent_coef": 0.08664233237504959,
    "learning_rate": 0.001
  },
  {
    "episode": 11303,
    "reward": 89.631904,
    "length": 64,
    "time": 165561.119172,
    "actor_loss": -65.75985717773438,
    "critic_loss": 34.459327697753906,
    "ent_coef": 0.08612444251775742,
    "learning_rate": 0.001
  },
  {
    "episode": 11304,
    "reward": 89.606845,
    "length": 64,
    "time": 165572.354571,
    "actor_loss": -59.246482849121094,
    "critic_loss": 341.5146484375,
    "ent_coef": 0.08009026944637299,
    "learning_rate": 0.001
  },
  {
    "episode": 11305,
    "reward": 90.20124,
    "length": 63,
    "time": 165583.432058,
    "actor_loss": -59.90135192871094,
    "critic_loss": 9.540111541748047,
    "ent_coef": 0.0765652284026146,
    "learning_rate": 0.001
  },
  {
    "episode": 11306,
    "reward": 87.419208,
    "length": 70,
    "time": 165595.62079,
    "actor_loss": -62.847145080566406,
    "critic_loss": 21.323720932006836,
    "ent_coef": 0.07507626712322235,
    "learning_rate": 0.001
  },
  {
    "episode": 11307,
    "reward": 87.820662,
    "length": 68,
    "time": 165607.766204,
    "actor_loss": -55.47748565673828,
    "critic_loss": 37.7424201965332,
    "ent_coef": 0.07454094290733337,
    "learning_rate": 0.001
  },
  {
    "episode": 11308,
    "reward": 89.558386,
    "length": 64,
    "time": 165619.485865,
    "actor_loss": -65.0533447265625,
    "critic_loss": 8.29594612121582,
    "ent_coef": 0.07560228556394577,
    "learning_rate": 0.001
  },
  {
    "episode": 11309,
    "reward": 90.453238,
    "length": 63,
    "time": 165630.623141,
    "actor_loss": -68.61990356445312,
    "critic_loss": 10.649904251098633,
    "ent_coef": 0.07532371580600739,
    "learning_rate": 0.001
  },
  {
    "episode": 11310,
    "reward": 89.489557,
    "length": 65,
    "time": 165644.093825,
    "actor_loss": -64.16043853759766,
    "critic_loss": 15.37183952331543,
    "ent_coef": 0.07389513403177261,
    "learning_rate": 0.001
  },
  {
    "episode": 11311,
    "reward": 88.627345,
    "length": 67,
    "time": 165657.492567,
    "actor_loss": -65.70075225830078,
    "critic_loss": 5.510629177093506,
    "ent_coef": 0.07369878143072128,
    "learning_rate": 0.001
  },
  {
    "episode": 11312,
    "reward": 84.872574,
    "length": 72,
    "time": 165670.226739,
    "actor_loss": -67.11112213134766,
    "critic_loss": 49.00999450683594,
    "ent_coef": 0.07734604179859161,
    "learning_rate": 0.001
  },
  {
    "episode": 11313,
    "reward": 89.799175,
    "length": 63,
    "time": 165684.201689,
    "actor_loss": -68.83795928955078,
    "critic_loss": 11.110062599182129,
    "ent_coef": 0.08028984069824219,
    "learning_rate": 0.001
  },
  {
    "episode": 11314,
    "reward": 91.405026,
    "length": 61,
    "time": 165697.323436,
    "actor_loss": -58.51312255859375,
    "critic_loss": 3.2192649841308594,
    "ent_coef": 0.08481737226247787,
    "learning_rate": 0.001
  },
  {
    "episode": 11315,
    "reward": 90.958031,
    "length": 61,
    "time": 165709.161892,
    "actor_loss": -62.12516403198242,
    "critic_loss": 17.648433685302734,
    "ent_coef": 0.08848404884338379,
    "learning_rate": 0.001
  },
  {
    "episode": 11316,
    "reward": 90.540436,
    "length": 62,
    "time": 165721.662201,
    "actor_loss": -67.26725769042969,
    "critic_loss": 6.667109966278076,
    "ent_coef": 0.09283972531557083,
    "learning_rate": 0.001
  },
  {
    "episode": 11317,
    "reward": 86.714657,
    "length": 69,
    "time": 165733.704193,
    "actor_loss": -71.96177673339844,
    "critic_loss": 4.503444671630859,
    "ent_coef": 0.08867418766021729,
    "learning_rate": 0.001
  },
  {
    "episode": 11318,
    "reward": 88.910734,
    "length": 65,
    "time": 165747.098487,
    "actor_loss": -64.831298828125,
    "critic_loss": 14.27175521850586,
    "ent_coef": 0.08584649860858917,
    "learning_rate": 0.001
  },
  {
    "episode": 11319,
    "reward": 89.98114,
    "length": 63,
    "time": 165760.680221,
    "actor_loss": -64.31531524658203,
    "critic_loss": 44.529903411865234,
    "ent_coef": 0.08463536202907562,
    "learning_rate": 0.001
  },
  {
    "episode": 11320,
    "reward": 89.52871,
    "length": 64,
    "time": 165774.260986,
    "actor_loss": -66.33519744873047,
    "critic_loss": 10.63781452178955,
    "ent_coef": 0.08845733106136322,
    "learning_rate": 0.001
  },
  {
    "episode": 11321,
    "reward": 86.935708,
    "length": 71,
    "time": 165787.425281,
    "actor_loss": -69.12907409667969,
    "critic_loss": 13.05813980102539,
    "ent_coef": 0.09405302256345749,
    "learning_rate": 0.001
  },
  {
    "episode": 11322,
    "reward": 90.416663,
    "length": 62,
    "time": 165799.517104,
    "actor_loss": -70.57325744628906,
    "critic_loss": 7.645814895629883,
    "ent_coef": 0.0943499505519867,
    "learning_rate": 0.001
  },
  {
    "episode": 11323,
    "reward": 87.939071,
    "length": 69,
    "time": 165812.746244,
    "actor_loss": -57.58934783935547,
    "critic_loss": 25.699228286743164,
    "ent_coef": 0.0907149612903595,
    "learning_rate": 0.001
  },
  {
    "episode": 11324,
    "reward": 87.403485,
    "length": 68,
    "time": 165825.909998,
    "actor_loss": -62.1630859375,
    "critic_loss": 36.345375061035156,
    "ent_coef": 0.08886940777301788,
    "learning_rate": 0.001
  },
  {
    "episode": 11325,
    "reward": 90.031213,
    "length": 61,
    "time": 165839.647089,
    "actor_loss": -62.411659240722656,
    "critic_loss": 3.9883434772491455,
    "ent_coef": 0.09064039587974548,
    "learning_rate": 0.001
  },
  {
    "episode": 11326,
    "reward": 91.105127,
    "length": 62,
    "time": 165852.646927,
    "actor_loss": -72.89657592773438,
    "critic_loss": 9.453211784362793,
    "ent_coef": 0.08927682042121887,
    "learning_rate": 0.001
  },
  {
    "episode": 11327,
    "reward": 90.898172,
    "length": 61,
    "time": 165864.917791,
    "actor_loss": -70.24989318847656,
    "critic_loss": 8.61796760559082,
    "ent_coef": 0.08774308860301971,
    "learning_rate": 0.001
  },
  {
    "episode": 11328,
    "reward": 90.646804,
    "length": 63,
    "time": 165879.878502,
    "actor_loss": -62.57590103149414,
    "critic_loss": 8.489776611328125,
    "ent_coef": 0.08851715922355652,
    "learning_rate": 0.001
  },
  {
    "episode": 11329,
    "reward": 90.883167,
    "length": 62,
    "time": 165891.051388,
    "actor_loss": -63.73958206176758,
    "critic_loss": 5.805902004241943,
    "ent_coef": 0.09077649563550949,
    "learning_rate": 0.001
  },
  {
    "episode": 11330,
    "reward": 90.845835,
    "length": 61,
    "time": 165903.680721,
    "actor_loss": -65.11030578613281,
    "critic_loss": 6.225005149841309,
    "ent_coef": 0.09209750592708588,
    "learning_rate": 0.001
  },
  {
    "episode": 11331,
    "reward": 90.082982,
    "length": 64,
    "time": 165917.032026,
    "actor_loss": -60.19248962402344,
    "critic_loss": 5.935768127441406,
    "ent_coef": 0.09143037348985672,
    "learning_rate": 0.001
  },
  {
    "episode": 11332,
    "reward": 88.706701,
    "length": 67,
    "time": 165930.327521,
    "actor_loss": -65.8680419921875,
    "critic_loss": 4.8855390548706055,
    "ent_coef": 0.08873727172613144,
    "learning_rate": 0.001
  },
  {
    "episode": 11333,
    "reward": 86.999432,
    "length": 67,
    "time": 165942.755085,
    "actor_loss": -63.158164978027344,
    "critic_loss": 12.288576126098633,
    "ent_coef": 0.08541122078895569,
    "learning_rate": 0.001
  },
  {
    "episode": 11334,
    "reward": 90.407308,
    "length": 63,
    "time": 165955.61779,
    "actor_loss": -68.19918060302734,
    "critic_loss": 3.2641801834106445,
    "ent_coef": 0.08411893248558044,
    "learning_rate": 0.001
  },
  {
    "episode": 11335,
    "reward": 88.548551,
    "length": 66,
    "time": 165967.493008,
    "actor_loss": -58.502899169921875,
    "critic_loss": 4.154587268829346,
    "ent_coef": 0.08058441430330276,
    "learning_rate": 0.001
  },
  {
    "episode": 11336,
    "reward": 87.84713,
    "length": 68,
    "time": 165979.742544,
    "actor_loss": -65.8490982055664,
    "critic_loss": 12.031024932861328,
    "ent_coef": 0.07708585262298584,
    "learning_rate": 0.001
  },
  {
    "episode": 11337,
    "reward": 90.024317,
    "length": 64,
    "time": 165993.151325,
    "actor_loss": -70.21329498291016,
    "critic_loss": 14.59980297088623,
    "ent_coef": 0.07544068992137909,
    "learning_rate": 0.001
  },
  {
    "episode": 11338,
    "reward": 91.597091,
    "length": 60,
    "time": 166005.30257,
    "actor_loss": -66.38533020019531,
    "critic_loss": 7.371997356414795,
    "ent_coef": 0.07882523536682129,
    "learning_rate": 0.001
  },
  {
    "episode": 11339,
    "reward": 90.997342,
    "length": 61,
    "time": 166017.995729,
    "actor_loss": -63.17734146118164,
    "critic_loss": 16.435577392578125,
    "ent_coef": 0.08390926569700241,
    "learning_rate": 0.001
  },
  {
    "episode": 11340,
    "reward": 91.118288,
    "length": 61,
    "time": 166030.130761,
    "actor_loss": -63.560142517089844,
    "critic_loss": 30.162668228149414,
    "ent_coef": 0.08631498366594315,
    "learning_rate": 0.001
  },
  {
    "episode": 11341,
    "reward": -156.371845,
    "length": 143,
    "time": 166053.734638,
    "actor_loss": -69.7687759399414,
    "critic_loss": 5.143915176391602,
    "ent_coef": 0.08894962817430496,
    "learning_rate": 0.001
  },
  {
    "episode": 11342,
    "reward": 88.581337,
    "length": 64,
    "time": 166066.351763,
    "actor_loss": -63.67945861816406,
    "critic_loss": 42.061912536621094,
    "ent_coef": 0.08610085397958755,
    "learning_rate": 0.001
  },
  {
    "episode": 11343,
    "reward": 86.370593,
    "length": 73,
    "time": 166080.040518,
    "actor_loss": -67.46977996826172,
    "critic_loss": 19.56085968017578,
    "ent_coef": 0.08457685261964798,
    "learning_rate": 0.001
  },
  {
    "episode": 11344,
    "reward": 89.349704,
    "length": 67,
    "time": 166091.667697,
    "actor_loss": -65.91435241699219,
    "critic_loss": 16.077205657958984,
    "ent_coef": 0.0839010626077652,
    "learning_rate": 0.001
  },
  {
    "episode": 11345,
    "reward": 91.642403,
    "length": 60,
    "time": 166103.694877,
    "actor_loss": -64.7298355102539,
    "critic_loss": 4.411304473876953,
    "ent_coef": 0.0863143801689148,
    "learning_rate": 0.001
  },
  {
    "episode": 11346,
    "reward": 89.870526,
    "length": 63,
    "time": 166115.975211,
    "actor_loss": -64.36769104003906,
    "critic_loss": 10.856351852416992,
    "ent_coef": 0.08601698279380798,
    "learning_rate": 0.001
  },
  {
    "episode": 11347,
    "reward": 90.065545,
    "length": 63,
    "time": 166135.53708,
    "actor_loss": -54.18287658691406,
    "critic_loss": 26.67788314819336,
    "ent_coef": 0.0846661627292633,
    "learning_rate": 0.001
  },
  {
    "episode": 11348,
    "reward": 88.278821,
    "length": 68,
    "time": 166147.491588,
    "actor_loss": -67.08393859863281,
    "critic_loss": 2.342782497406006,
    "ent_coef": 0.08045930415391922,
    "learning_rate": 0.001
  },
  {
    "episode": 11349,
    "reward": 89.052352,
    "length": 63,
    "time": 166162.316909,
    "actor_loss": -64.18177795410156,
    "critic_loss": 11.32297134399414,
    "ent_coef": 0.08043321222066879,
    "learning_rate": 0.001
  },
  {
    "episode": 11350,
    "reward": 90.317367,
    "length": 63,
    "time": 166174.785223,
    "actor_loss": -63.451927185058594,
    "critic_loss": 15.315160751342773,
    "ent_coef": 0.07824919372797012,
    "learning_rate": 0.001
  },
  {
    "episode": 11351,
    "reward": 90.848773,
    "length": 62,
    "time": 166186.106695,
    "actor_loss": -66.76927185058594,
    "critic_loss": 10.378591537475586,
    "ent_coef": 0.08139321208000183,
    "learning_rate": 0.001
  },
  {
    "episode": 11352,
    "reward": 88.420232,
    "length": 65,
    "time": 166197.491925,
    "actor_loss": -67.67036437988281,
    "critic_loss": 7.185637950897217,
    "ent_coef": 0.08046940714120865,
    "learning_rate": 0.001
  },
  {
    "episode": 11353,
    "reward": 90.220787,
    "length": 62,
    "time": 166209.550596,
    "actor_loss": -62.730369567871094,
    "critic_loss": 6.914262294769287,
    "ent_coef": 0.08157489448785782,
    "learning_rate": 0.001
  },
  {
    "episode": 11354,
    "reward": 87.893201,
    "length": 67,
    "time": 166221.458549,
    "actor_loss": -73.11567687988281,
    "critic_loss": 5.320688247680664,
    "ent_coef": 0.07827770709991455,
    "learning_rate": 0.001
  },
  {
    "episode": 11355,
    "reward": 86.491047,
    "length": 77,
    "time": 166234.985205,
    "actor_loss": -64.39593505859375,
    "critic_loss": 39.609989166259766,
    "ent_coef": 0.0815761461853981,
    "learning_rate": 0.001
  },
  {
    "episode": 11356,
    "reward": 90.402931,
    "length": 63,
    "time": 166249.618263,
    "actor_loss": -62.563934326171875,
    "critic_loss": 4.974731922149658,
    "ent_coef": 0.08233880996704102,
    "learning_rate": 0.001
  },
  {
    "episode": 11357,
    "reward": 90.306219,
    "length": 62,
    "time": 166262.610159,
    "actor_loss": -69.32914733886719,
    "critic_loss": 7.414396286010742,
    "ent_coef": 0.08369721472263336,
    "learning_rate": 0.001
  },
  {
    "episode": 11358,
    "reward": 86.115222,
    "length": 77,
    "time": 166276.010608,
    "actor_loss": -61.676239013671875,
    "critic_loss": 9.451983451843262,
    "ent_coef": 0.08367794007062912,
    "learning_rate": 0.001
  },
  {
    "episode": 11359,
    "reward": 87.089916,
    "length": 79,
    "time": 166293.636294,
    "actor_loss": -62.36255645751953,
    "critic_loss": 4.20023775100708,
    "ent_coef": 0.08833727985620499,
    "learning_rate": 0.001
  },
  {
    "episode": 11360,
    "reward": 82.757799,
    "length": 71,
    "time": 166307.513077,
    "actor_loss": -68.1864013671875,
    "critic_loss": 11.280050277709961,
    "ent_coef": 0.0880904495716095,
    "learning_rate": 0.001
  },
  {
    "episode": 11361,
    "reward": 86.996744,
    "length": 70,
    "time": 166323.207116,
    "actor_loss": -64.04536437988281,
    "critic_loss": 13.728187561035156,
    "ent_coef": 0.08040269464254379,
    "learning_rate": 0.001
  },
  {
    "episode": 11362,
    "reward": 88.51623,
    "length": 66,
    "time": 166336.881652,
    "actor_loss": -63.331573486328125,
    "critic_loss": 69.3619384765625,
    "ent_coef": 0.07776404172182083,
    "learning_rate": 0.001
  },
  {
    "episode": 11363,
    "reward": 89.52603,
    "length": 64,
    "time": 166348.330601,
    "actor_loss": -62.74353790283203,
    "critic_loss": 4.9864373207092285,
    "ent_coef": 0.07841725647449493,
    "learning_rate": 0.001
  },
  {
    "episode": 11364,
    "reward": 83.718607,
    "length": 96,
    "time": 166364.59739,
    "actor_loss": -65.92185974121094,
    "critic_loss": 4.731498718261719,
    "ent_coef": 0.07878139615058899,
    "learning_rate": 0.001
  },
  {
    "episode": 11365,
    "reward": 88.79343,
    "length": 66,
    "time": 166377.260245,
    "actor_loss": -57.95552444458008,
    "critic_loss": 5.528531074523926,
    "ent_coef": 0.0763484314084053,
    "learning_rate": 0.001
  },
  {
    "episode": 11366,
    "reward": 78.939309,
    "length": 94,
    "time": 166392.77396,
    "actor_loss": -72.3519287109375,
    "critic_loss": 23.191308975219727,
    "ent_coef": 0.0760461762547493,
    "learning_rate": 0.001
  },
  {
    "episode": 11367,
    "reward": 88.713317,
    "length": 64,
    "time": 166406.951781,
    "actor_loss": -65.78987121582031,
    "critic_loss": 6.107702255249023,
    "ent_coef": 0.0765467956662178,
    "learning_rate": 0.001
  },
  {
    "episode": 11368,
    "reward": 90.697086,
    "length": 62,
    "time": 166420.379479,
    "actor_loss": -69.49301147460938,
    "critic_loss": 4.279725551605225,
    "ent_coef": 0.07913729548454285,
    "learning_rate": 0.001
  },
  {
    "episode": 11369,
    "reward": 89.002378,
    "length": 64,
    "time": 166431.833617,
    "actor_loss": -61.77476501464844,
    "critic_loss": 3.0379796028137207,
    "ent_coef": 0.08099532872438431,
    "learning_rate": 0.001
  },
  {
    "episode": 11370,
    "reward": 89.880964,
    "length": 65,
    "time": 166443.254514,
    "actor_loss": -59.827880859375,
    "critic_loss": 8.917706489562988,
    "ent_coef": 0.0807654932141304,
    "learning_rate": 0.001
  },
  {
    "episode": 11371,
    "reward": 90.922793,
    "length": 61,
    "time": 166456.727031,
    "actor_loss": -65.04320526123047,
    "critic_loss": 2.4834094047546387,
    "ent_coef": 0.08424068987369537,
    "learning_rate": 0.001
  },
  {
    "episode": 11372,
    "reward": 90.633605,
    "length": 62,
    "time": 166467.752617,
    "actor_loss": -69.62106323242188,
    "critic_loss": 19.600814819335938,
    "ent_coef": 0.08336789160966873,
    "learning_rate": 0.001
  },
  {
    "episode": 11373,
    "reward": 89.859298,
    "length": 64,
    "time": 166479.874372,
    "actor_loss": -65.62844848632812,
    "critic_loss": 4.80101203918457,
    "ent_coef": 0.08370453864336014,
    "learning_rate": 0.001
  },
  {
    "episode": 11374,
    "reward": 87.2828,
    "length": 70,
    "time": 166491.898274,
    "actor_loss": -62.03156280517578,
    "critic_loss": 28.300901412963867,
    "ent_coef": 0.08473729342222214,
    "learning_rate": 0.001
  },
  {
    "episode": 11375,
    "reward": 88.457146,
    "length": 65,
    "time": 166506.097208,
    "actor_loss": -71.07749938964844,
    "critic_loss": 31.222801208496094,
    "ent_coef": 0.08307047188282013,
    "learning_rate": 0.001
  },
  {
    "episode": 11376,
    "reward": 91.227955,
    "length": 61,
    "time": 166519.571435,
    "actor_loss": -57.96063232421875,
    "critic_loss": 7.487582683563232,
    "ent_coef": 0.08227664232254028,
    "learning_rate": 0.001
  },
  {
    "episode": 11377,
    "reward": 91.531886,
    "length": 60,
    "time": 166530.326825,
    "actor_loss": -69.26139831542969,
    "critic_loss": 15.25786018371582,
    "ent_coef": 0.08527365326881409,
    "learning_rate": 0.001
  },
  {
    "episode": 11378,
    "reward": 89.358368,
    "length": 67,
    "time": 166543.013755,
    "actor_loss": -58.870689392089844,
    "critic_loss": 7.780374526977539,
    "ent_coef": 0.08736175298690796,
    "learning_rate": 0.001
  },
  {
    "episode": 11379,
    "reward": 91.324508,
    "length": 61,
    "time": 166553.932285,
    "actor_loss": -62.685638427734375,
    "critic_loss": 4.608229160308838,
    "ent_coef": 0.0899755209684372,
    "learning_rate": 0.001
  },
  {
    "episode": 11380,
    "reward": 91.284784,
    "length": 61,
    "time": 166566.951143,
    "actor_loss": -70.60188293457031,
    "critic_loss": 20.010150909423828,
    "ent_coef": 0.09197953343391418,
    "learning_rate": 0.001
  },
  {
    "episode": 11381,
    "reward": 85.23282,
    "length": 78,
    "time": 166581.722216,
    "actor_loss": -62.158809661865234,
    "critic_loss": 14.15779972076416,
    "ent_coef": 0.09206246584653854,
    "learning_rate": 0.001
  },
  {
    "episode": 11382,
    "reward": 90.512857,
    "length": 62,
    "time": 166594.305025,
    "actor_loss": -74.19725036621094,
    "critic_loss": 103.52703094482422,
    "ent_coef": 0.09557157009840012,
    "learning_rate": 0.001
  },
  {
    "episode": 11383,
    "reward": 85.635566,
    "length": 74,
    "time": 166608.316201,
    "actor_loss": -66.0760498046875,
    "critic_loss": 9.51884651184082,
    "ent_coef": 0.09348706901073456,
    "learning_rate": 0.001
  },
  {
    "episode": 11384,
    "reward": 87.107023,
    "length": 67,
    "time": 166619.937113,
    "actor_loss": -65.76860046386719,
    "critic_loss": 349.7636413574219,
    "ent_coef": 0.08894746005535126,
    "learning_rate": 0.001
  },
  {
    "episode": 11385,
    "reward": 88.927805,
    "length": 64,
    "time": 166631.074098,
    "actor_loss": -65.06431579589844,
    "critic_loss": 4.957761287689209,
    "ent_coef": 0.0850665494799614,
    "learning_rate": 0.001
  },
  {
    "episode": 11386,
    "reward": 89.557577,
    "length": 64,
    "time": 166642.622091,
    "actor_loss": -62.615135192871094,
    "critic_loss": 7.057224273681641,
    "ent_coef": 0.08543291687965393,
    "learning_rate": 0.001
  },
  {
    "episode": 11387,
    "reward": 89.788675,
    "length": 63,
    "time": 166656.687029,
    "actor_loss": -65.73457336425781,
    "critic_loss": 2.4164204597473145,
    "ent_coef": 0.08470113575458527,
    "learning_rate": 0.001
  },
  {
    "episode": 11388,
    "reward": 90.519002,
    "length": 63,
    "time": 166668.833373,
    "actor_loss": -65.31583404541016,
    "critic_loss": 11.426204681396484,
    "ent_coef": 0.08370613306760788,
    "learning_rate": 0.001
  },
  {
    "episode": 11389,
    "reward": 85.964646,
    "length": 86,
    "time": 166687.46397,
    "actor_loss": -64.09165954589844,
    "critic_loss": 4.022190093994141,
    "ent_coef": 0.08495049923658371,
    "learning_rate": 0.001
  },
  {
    "episode": 11390,
    "reward": 89.133534,
    "length": 64,
    "time": 166700.631924,
    "actor_loss": -64.66130828857422,
    "critic_loss": 15.488985061645508,
    "ent_coef": 0.08515220135450363,
    "learning_rate": 0.001
  },
  {
    "episode": 11391,
    "reward": 88.049419,
    "length": 69,
    "time": 166713.902593,
    "actor_loss": -65.50707244873047,
    "critic_loss": 34.392295837402344,
    "ent_coef": 0.08155000954866409,
    "learning_rate": 0.001
  },
  {
    "episode": 11392,
    "reward": 92.130573,
    "length": 59,
    "time": 166724.563095,
    "actor_loss": -66.77340698242188,
    "critic_loss": 8.197588920593262,
    "ent_coef": 0.08821169286966324,
    "learning_rate": 0.001
  },
  {
    "episode": 11393,
    "reward": 90.920027,
    "length": 61,
    "time": 166736.595758,
    "actor_loss": -64.34822845458984,
    "critic_loss": 17.410598754882812,
    "ent_coef": 0.09232152253389359,
    "learning_rate": 0.001
  },
  {
    "episode": 11394,
    "reward": 91.071469,
    "length": 61,
    "time": 166747.858554,
    "actor_loss": -64.24072265625,
    "critic_loss": 9.970499992370605,
    "ent_coef": 0.09451966732740402,
    "learning_rate": 0.001
  },
  {
    "episode": 11395,
    "reward": 91.599415,
    "length": 60,
    "time": 166760.542593,
    "actor_loss": -65.75031280517578,
    "critic_loss": 5.849319934844971,
    "ent_coef": 0.10429392009973526,
    "learning_rate": 0.001
  },
  {
    "episode": 11396,
    "reward": 90.147148,
    "length": 63,
    "time": 166772.587852,
    "actor_loss": -62.028560638427734,
    "critic_loss": 18.713685989379883,
    "ent_coef": 0.10211223363876343,
    "learning_rate": 0.001
  },
  {
    "episode": 11397,
    "reward": 88.254219,
    "length": 70,
    "time": 166787.371309,
    "actor_loss": -74.35324096679688,
    "critic_loss": 2.24414324760437,
    "ent_coef": 0.09916919469833374,
    "learning_rate": 0.001
  },
  {
    "episode": 11398,
    "reward": 89.035675,
    "length": 64,
    "time": 166798.538722,
    "actor_loss": -65.51435852050781,
    "critic_loss": 34.170719146728516,
    "ent_coef": 0.09663233906030655,
    "learning_rate": 0.001
  },
  {
    "episode": 11399,
    "reward": 90.073257,
    "length": 63,
    "time": 166809.63506,
    "actor_loss": -61.155696868896484,
    "critic_loss": 13.861213684082031,
    "ent_coef": 0.09286622703075409,
    "learning_rate": 0.001
  },
  {
    "episode": 11400,
    "reward": 89.19455,
    "length": 65,
    "time": 166822.792807,
    "actor_loss": -67.92610168457031,
    "critic_loss": 32.9776496887207,
    "ent_coef": 0.09066062420606613,
    "learning_rate": 0.001
  },
  {
    "episode": 11401,
    "reward": 90.729719,
    "length": 61,
    "time": 166836.057808,
    "actor_loss": -66.39462280273438,
    "critic_loss": 9.190386772155762,
    "ent_coef": 0.090904600918293,
    "learning_rate": 0.001
  },
  {
    "episode": 11402,
    "reward": 91.16834,
    "length": 61,
    "time": 166848.561863,
    "actor_loss": -67.20153045654297,
    "critic_loss": 7.748459339141846,
    "ent_coef": 0.08984296023845673,
    "learning_rate": 0.001
  },
  {
    "episode": 11403,
    "reward": 90.132313,
    "length": 63,
    "time": 166860.481796,
    "actor_loss": -69.41423034667969,
    "critic_loss": 10.708559036254883,
    "ent_coef": 0.08783268928527832,
    "learning_rate": 0.001
  },
  {
    "episode": 11404,
    "reward": 90.560612,
    "length": 63,
    "time": 166871.615068,
    "actor_loss": -64.90394592285156,
    "critic_loss": 4.634596347808838,
    "ent_coef": 0.08731484413146973,
    "learning_rate": 0.001
  },
  {
    "episode": 11405,
    "reward": 90.899148,
    "length": 61,
    "time": 166882.848687,
    "actor_loss": -67.99696350097656,
    "critic_loss": 25.7958984375,
    "ent_coef": 0.08994347602128983,
    "learning_rate": 0.001
  },
  {
    "episode": 11406,
    "reward": 91.438762,
    "length": 61,
    "time": 166895.651833,
    "actor_loss": -71.13317108154297,
    "critic_loss": 2.809438705444336,
    "ent_coef": 0.09001577645540237,
    "learning_rate": 0.001
  },
  {
    "episode": 11407,
    "reward": 89.125917,
    "length": 64,
    "time": 166907.847584,
    "actor_loss": -58.86748504638672,
    "critic_loss": 9.565349578857422,
    "ent_coef": 0.08864805847406387,
    "learning_rate": 0.001
  },
  {
    "episode": 11408,
    "reward": 88.115339,
    "length": 67,
    "time": 166920.536153,
    "actor_loss": -66.17218780517578,
    "critic_loss": 3.846681594848633,
    "ent_coef": 0.0889635756611824,
    "learning_rate": 0.001
  },
  {
    "episode": 11409,
    "reward": 87.360912,
    "length": 68,
    "time": 166934.320949,
    "actor_loss": -64.38041687011719,
    "critic_loss": 8.769279479980469,
    "ent_coef": 0.08586607128381729,
    "learning_rate": 0.001
  },
  {
    "episode": 11410,
    "reward": 86.836426,
    "length": 68,
    "time": 166945.954827,
    "actor_loss": -64.91254425048828,
    "critic_loss": 7.060445785522461,
    "ent_coef": 0.08092933148145676,
    "learning_rate": 0.001
  },
  {
    "episode": 11411,
    "reward": 88.883565,
    "length": 64,
    "time": 166957.847087,
    "actor_loss": -66.10214233398438,
    "critic_loss": 4.054685592651367,
    "ent_coef": 0.0843224748969078,
    "learning_rate": 0.001
  },
  {
    "episode": 11412,
    "reward": 89.217029,
    "length": 65,
    "time": 166969.842516,
    "actor_loss": -68.57583618164062,
    "critic_loss": 7.388141632080078,
    "ent_coef": 0.08179251104593277,
    "learning_rate": 0.001
  },
  {
    "episode": 11413,
    "reward": 85.221569,
    "length": 71,
    "time": 166984.937798,
    "actor_loss": -65.85101318359375,
    "critic_loss": 144.286865234375,
    "ent_coef": 0.07428295910358429,
    "learning_rate": 0.001
  },
  {
    "episode": 11414,
    "reward": 85.776492,
    "length": 71,
    "time": 166997.044406,
    "actor_loss": -67.4909896850586,
    "critic_loss": 2.6867752075195312,
    "ent_coef": 0.06954639405012131,
    "learning_rate": 0.001
  },
  {
    "episode": 11415,
    "reward": 85.85606,
    "length": 69,
    "time": 167010.476866,
    "actor_loss": -67.74979400634766,
    "critic_loss": 96.65849304199219,
    "ent_coef": 0.06747111678123474,
    "learning_rate": 0.001
  },
  {
    "episode": 11416,
    "reward": 84.882936,
    "length": 71,
    "time": 167022.646641,
    "actor_loss": -72.3403091430664,
    "critic_loss": 9.01519775390625,
    "ent_coef": 0.06413624435663223,
    "learning_rate": 0.001
  },
  {
    "episode": 11417,
    "reward": 78.609938,
    "length": 76,
    "time": 167035.414266,
    "actor_loss": -65.65478515625,
    "critic_loss": 3.0929641723632812,
    "ent_coef": 0.06466960906982422,
    "learning_rate": 0.001
  },
  {
    "episode": 11418,
    "reward": 89.367699,
    "length": 63,
    "time": 167047.810078,
    "actor_loss": -67.40652465820312,
    "critic_loss": 23.080854415893555,
    "ent_coef": 0.0667966678738594,
    "learning_rate": 0.001
  },
  {
    "episode": 11419,
    "reward": 88.61895,
    "length": 66,
    "time": 167059.415602,
    "actor_loss": -75.07850646972656,
    "critic_loss": 3.1279807090759277,
    "ent_coef": 0.06748341023921967,
    "learning_rate": 0.001
  },
  {
    "episode": 11420,
    "reward": 87.880364,
    "length": 65,
    "time": 167071.739477,
    "actor_loss": -65.32738494873047,
    "critic_loss": 22.888856887817383,
    "ent_coef": 0.06878067553043365,
    "learning_rate": 0.001
  },
  {
    "episode": 11421,
    "reward": 88.354471,
    "length": 65,
    "time": 167084.315175,
    "actor_loss": -66.04312896728516,
    "critic_loss": 34.517494201660156,
    "ent_coef": 0.06786839663982391,
    "learning_rate": 0.001
  },
  {
    "episode": 11422,
    "reward": 80.690793,
    "length": 98,
    "time": 167099.828968,
    "actor_loss": -71.6007080078125,
    "critic_loss": 22.05478286743164,
    "ent_coef": 0.06722953170537949,
    "learning_rate": 0.001
  },
  {
    "episode": 11423,
    "reward": 89.559625,
    "length": 66,
    "time": 167111.62961,
    "actor_loss": -69.49995422363281,
    "critic_loss": 2.7454307079315186,
    "ent_coef": 0.06993968039751053,
    "learning_rate": 0.001
  },
  {
    "episode": 11424,
    "reward": 90.160738,
    "length": 63,
    "time": 167124.260823,
    "actor_loss": -69.9627456665039,
    "critic_loss": 11.864774703979492,
    "ent_coef": 0.07089923322200775,
    "learning_rate": 0.001
  },
  {
    "episode": 11425,
    "reward": 89.442953,
    "length": 63,
    "time": 167137.521468,
    "actor_loss": -67.45843505859375,
    "critic_loss": 5.438508987426758,
    "ent_coef": 0.07138870656490326,
    "learning_rate": 0.001
  },
  {
    "episode": 11426,
    "reward": 90.183689,
    "length": 63,
    "time": 167149.692864,
    "actor_loss": -72.71949768066406,
    "critic_loss": 3.6515541076660156,
    "ent_coef": 0.07335612177848816,
    "learning_rate": 0.001
  },
  {
    "episode": 11427,
    "reward": 88.77453,
    "length": 65,
    "time": 167161.379199,
    "actor_loss": -62.65911102294922,
    "critic_loss": 16.213577270507812,
    "ent_coef": 0.07430573552846909,
    "learning_rate": 0.001
  },
  {
    "episode": 11428,
    "reward": 86.442397,
    "length": 68,
    "time": 167174.187508,
    "actor_loss": -68.02885437011719,
    "critic_loss": 4.366657257080078,
    "ent_coef": 0.07364412397146225,
    "learning_rate": 0.001
  },
  {
    "episode": 11429,
    "reward": 89.402798,
    "length": 63,
    "time": 167187.03431,
    "actor_loss": -65.41812896728516,
    "critic_loss": 6.327326774597168,
    "ent_coef": 0.07763662189245224,
    "learning_rate": 0.001
  },
  {
    "episode": 11430,
    "reward": 90.095466,
    "length": 63,
    "time": 167198.859257,
    "actor_loss": -65.9339599609375,
    "critic_loss": 3.974540948867798,
    "ent_coef": 0.08376502990722656,
    "learning_rate": 0.001
  },
  {
    "episode": 11431,
    "reward": 91.746654,
    "length": 61,
    "time": 167210.258527,
    "actor_loss": -66.655517578125,
    "critic_loss": 14.058666229248047,
    "ent_coef": 0.08504290133714676,
    "learning_rate": 0.001
  },
  {
    "episode": 11432,
    "reward": 90.390368,
    "length": 62,
    "time": 167224.565275,
    "actor_loss": -77.5609130859375,
    "critic_loss": 8.9263916015625,
    "ent_coef": 0.08604705333709717,
    "learning_rate": 0.001
  },
  {
    "episode": 11433,
    "reward": 88.682392,
    "length": 65,
    "time": 167235.81192,
    "actor_loss": -67.98613739013672,
    "critic_loss": 5.690446376800537,
    "ent_coef": 0.08312372863292694,
    "learning_rate": 0.001
  },
  {
    "episode": 11434,
    "reward": 88.388287,
    "length": 68,
    "time": 167248.603231,
    "actor_loss": -66.00358581542969,
    "critic_loss": 50.64209747314453,
    "ent_coef": 0.0761924684047699,
    "learning_rate": 0.001
  },
  {
    "episode": 11435,
    "reward": 89.571247,
    "length": 63,
    "time": 167259.816314,
    "actor_loss": -60.00367736816406,
    "critic_loss": 168.93096923828125,
    "ent_coef": 0.07725308835506439,
    "learning_rate": 0.001
  },
  {
    "episode": 11436,
    "reward": 90.317039,
    "length": 63,
    "time": 167271.889211,
    "actor_loss": -66.08470153808594,
    "critic_loss": 6.2136945724487305,
    "ent_coef": 0.07907059043645859,
    "learning_rate": 0.001
  },
  {
    "episode": 11437,
    "reward": 90.464611,
    "length": 62,
    "time": 167282.970914,
    "actor_loss": -67.74212646484375,
    "critic_loss": 6.226890563964844,
    "ent_coef": 0.07876799255609512,
    "learning_rate": 0.001
  },
  {
    "episode": 11438,
    "reward": 91.230621,
    "length": 61,
    "time": 167296.344577,
    "actor_loss": -69.14064025878906,
    "critic_loss": 41.315223693847656,
    "ent_coef": 0.08001163601875305,
    "learning_rate": 0.001
  },
  {
    "episode": 11439,
    "reward": 90.090516,
    "length": 63,
    "time": 167308.707537,
    "actor_loss": -69.19747161865234,
    "critic_loss": 4.1511735916137695,
    "ent_coef": 0.07986971735954285,
    "learning_rate": 0.001
  },
  {
    "episode": 11440,
    "reward": 88.672674,
    "length": 65,
    "time": 167320.078168,
    "actor_loss": -67.61422729492188,
    "critic_loss": 2.834841728210449,
    "ent_coef": 0.07999240607023239,
    "learning_rate": 0.001
  },
  {
    "episode": 11441,
    "reward": 88.947589,
    "length": 65,
    "time": 167331.759434,
    "actor_loss": -65.68289184570312,
    "critic_loss": 9.35760498046875,
    "ent_coef": 0.07735913246870041,
    "learning_rate": 0.001
  },
  {
    "episode": 11442,
    "reward": 87.800578,
    "length": 66,
    "time": 167348.212702,
    "actor_loss": -65.50791931152344,
    "critic_loss": 2.9317851066589355,
    "ent_coef": 0.07391728460788727,
    "learning_rate": 0.001
  },
  {
    "episode": 11443,
    "reward": 89.426736,
    "length": 64,
    "time": 167360.852302,
    "actor_loss": -71.06172180175781,
    "critic_loss": 3.5018465518951416,
    "ent_coef": 0.07324124872684479,
    "learning_rate": 0.001
  },
  {
    "episode": 11444,
    "reward": 90.109259,
    "length": 62,
    "time": 167371.992289,
    "actor_loss": -65.82122802734375,
    "critic_loss": 35.459686279296875,
    "ent_coef": 0.07318175584077835,
    "learning_rate": 0.001
  },
  {
    "episode": 11445,
    "reward": 91.513295,
    "length": 60,
    "time": 167383.095279,
    "actor_loss": -61.375396728515625,
    "critic_loss": 6.740971565246582,
    "ent_coef": 0.08029868453741074,
    "learning_rate": 0.001
  },
  {
    "episode": 11446,
    "reward": 90.698736,
    "length": 61,
    "time": 167394.033416,
    "actor_loss": -65.85350036621094,
    "critic_loss": 4.617220401763916,
    "ent_coef": 0.0853111669421196,
    "learning_rate": 0.001
  },
  {
    "episode": 11447,
    "reward": 91.089307,
    "length": 61,
    "time": 167405.056565,
    "actor_loss": -71.35293579101562,
    "critic_loss": 37.158538818359375,
    "ent_coef": 0.08492255210876465,
    "learning_rate": 0.001
  },
  {
    "episode": 11448,
    "reward": 90.10647,
    "length": 62,
    "time": 167416.153764,
    "actor_loss": -67.72442626953125,
    "critic_loss": 5.069973945617676,
    "ent_coef": 0.08512602001428604,
    "learning_rate": 0.001
  },
  {
    "episode": 11449,
    "reward": 90.316405,
    "length": 63,
    "time": 167428.925765,
    "actor_loss": -61.153221130371094,
    "critic_loss": 4.049448490142822,
    "ent_coef": 0.08613529056310654,
    "learning_rate": 0.001
  },
  {
    "episode": 11450,
    "reward": 89.039626,
    "length": 64,
    "time": 167441.35847,
    "actor_loss": -68.08338928222656,
    "critic_loss": 6.068384647369385,
    "ent_coef": 0.08783526718616486,
    "learning_rate": 0.001
  },
  {
    "episode": 11451,
    "reward": 90.242771,
    "length": 63,
    "time": 167452.884929,
    "actor_loss": -70.0726318359375,
    "critic_loss": 13.018260955810547,
    "ent_coef": 0.08615832775831223,
    "learning_rate": 0.001
  },
  {
    "episode": 11452,
    "reward": 90.511395,
    "length": 63,
    "time": 167464.536796,
    "actor_loss": -63.32574462890625,
    "critic_loss": 5.621143817901611,
    "ent_coef": 0.08637510985136032,
    "learning_rate": 0.001
  },
  {
    "episode": 11453,
    "reward": 90.649155,
    "length": 62,
    "time": 167475.809838,
    "actor_loss": -63.165306091308594,
    "critic_loss": 10.506270408630371,
    "ent_coef": 0.08831733465194702,
    "learning_rate": 0.001
  },
  {
    "episode": 11454,
    "reward": 89.859481,
    "length": 64,
    "time": 167490.373816,
    "actor_loss": -67.62400817871094,
    "critic_loss": 6.460064888000488,
    "ent_coef": 0.08611281961202621,
    "learning_rate": 0.001
  },
  {
    "episode": 11455,
    "reward": 90.479969,
    "length": 62,
    "time": 167503.369326,
    "actor_loss": -65.19243621826172,
    "critic_loss": 16.693941116333008,
    "ent_coef": 0.08574096858501434,
    "learning_rate": 0.001
  },
  {
    "episode": 11456,
    "reward": 90.127857,
    "length": 63,
    "time": 167517.065755,
    "actor_loss": -62.33880615234375,
    "critic_loss": 5.9031476974487305,
    "ent_coef": 0.08677788823843002,
    "learning_rate": 0.001
  },
  {
    "episode": 11457,
    "reward": 89.228957,
    "length": 66,
    "time": 167529.240931,
    "actor_loss": -62.15380096435547,
    "critic_loss": 13.35528564453125,
    "ent_coef": 0.0825028121471405,
    "learning_rate": 0.001
  },
  {
    "episode": 11458,
    "reward": 90.215598,
    "length": 64,
    "time": 167540.876944,
    "actor_loss": -64.57937622070312,
    "critic_loss": 6.353754997253418,
    "ent_coef": 0.07738186419010162,
    "learning_rate": 0.001
  },
  {
    "episode": 11459,
    "reward": 89.619197,
    "length": 64,
    "time": 167552.186177,
    "actor_loss": -61.55760192871094,
    "critic_loss": 22.045677185058594,
    "ent_coef": 0.07493459433317184,
    "learning_rate": 0.001
  },
  {
    "episode": 11460,
    "reward": 89.721795,
    "length": 65,
    "time": 167563.746171,
    "actor_loss": -68.1881103515625,
    "critic_loss": 3.717750072479248,
    "ent_coef": 0.07326763868331909,
    "learning_rate": 0.001
  },
  {
    "episode": 11461,
    "reward": 88.147599,
    "length": 67,
    "time": 167576.58495,
    "actor_loss": -71.432861328125,
    "critic_loss": 9.666409492492676,
    "ent_coef": 0.0682806596159935,
    "learning_rate": 0.001
  },
  {
    "episode": 11462,
    "reward": 83.674942,
    "length": 84,
    "time": 167591.620093,
    "actor_loss": -61.24818420410156,
    "critic_loss": 10.864744186401367,
    "ent_coef": 0.0671161413192749,
    "learning_rate": 0.001
  },
  {
    "episode": 11463,
    "reward": 89.18803,
    "length": 65,
    "time": 167603.010537,
    "actor_loss": -66.97213745117188,
    "critic_loss": 7.713379859924316,
    "ent_coef": 0.06602642685174942,
    "learning_rate": 0.001
  },
  {
    "episode": 11464,
    "reward": 89.229851,
    "length": 66,
    "time": 167616.503531,
    "actor_loss": -68.59574890136719,
    "critic_loss": 22.7894287109375,
    "ent_coef": 0.06273548305034637,
    "learning_rate": 0.001
  },
  {
    "episode": 11465,
    "reward": 89.257857,
    "length": 66,
    "time": 167630.137776,
    "actor_loss": -57.11823272705078,
    "critic_loss": 3.9451427459716797,
    "ent_coef": 0.06343989819288254,
    "learning_rate": 0.001
  },
  {
    "episode": 11466,
    "reward": 87.106254,
    "length": 68,
    "time": 167643.515847,
    "actor_loss": -63.236351013183594,
    "critic_loss": 4.385839462280273,
    "ent_coef": 0.06098611280322075,
    "learning_rate": 0.001
  },
  {
    "episode": 11467,
    "reward": 91.447974,
    "length": 61,
    "time": 167656.37625,
    "actor_loss": -64.49942016601562,
    "critic_loss": 5.526965141296387,
    "ent_coef": 0.061289794743061066,
    "learning_rate": 0.001
  },
  {
    "episode": 11468,
    "reward": 91.282646,
    "length": 60,
    "time": 167668.185223,
    "actor_loss": -65.81610870361328,
    "critic_loss": 5.919610977172852,
    "ent_coef": 0.0627271756529808,
    "learning_rate": 0.001
  },
  {
    "episode": 11469,
    "reward": -157.321196,
    "length": 151,
    "time": 167694.920314,
    "actor_loss": -63.04368591308594,
    "critic_loss": 3.0149500370025635,
    "ent_coef": 0.06728023290634155,
    "learning_rate": 0.001
  },
  {
    "episode": 11470,
    "reward": 89.238463,
    "length": 64,
    "time": 167706.966242,
    "actor_loss": -67.01316833496094,
    "critic_loss": 13.63299560546875,
    "ent_coef": 0.0692480057477951,
    "learning_rate": 0.001
  },
  {
    "episode": 11471,
    "reward": 91.204757,
    "length": 61,
    "time": 167718.296463,
    "actor_loss": -65.94277954101562,
    "critic_loss": 29.72711944580078,
    "ent_coef": 0.07037346810102463,
    "learning_rate": 0.001
  },
  {
    "episode": 11472,
    "reward": 90.604104,
    "length": 62,
    "time": 167729.358196,
    "actor_loss": -66.85462188720703,
    "critic_loss": 4.181313991546631,
    "ent_coef": 0.07194546610116959,
    "learning_rate": 0.001
  },
  {
    "episode": 11473,
    "reward": 89.755891,
    "length": 64,
    "time": 167741.937937,
    "actor_loss": -72.67741394042969,
    "critic_loss": 64.13432312011719,
    "ent_coef": 0.07320702821016312,
    "learning_rate": 0.001
  },
  {
    "episode": 11474,
    "reward": 90.566598,
    "length": 64,
    "time": 167754.530758,
    "actor_loss": -64.07069396972656,
    "critic_loss": 2.7726995944976807,
    "ent_coef": 0.07131003588438034,
    "learning_rate": 0.001
  },
  {
    "episode": 11475,
    "reward": 89.379024,
    "length": 64,
    "time": 167766.857177,
    "actor_loss": -62.03520202636719,
    "critic_loss": 5.332889556884766,
    "ent_coef": 0.0727127343416214,
    "learning_rate": 0.001
  },
  {
    "episode": 11476,
    "reward": 91.905429,
    "length": 60,
    "time": 167779.478106,
    "actor_loss": -67.01307678222656,
    "critic_loss": 36.01746368408203,
    "ent_coef": 0.07471923530101776,
    "learning_rate": 0.001
  },
  {
    "episode": 11477,
    "reward": 89.563741,
    "length": 63,
    "time": 167792.271009,
    "actor_loss": -70.74687957763672,
    "critic_loss": 3.298285722732544,
    "ent_coef": 0.07620523869991302,
    "learning_rate": 0.001
  },
  {
    "episode": 11478,
    "reward": 88.681656,
    "length": 65,
    "time": 167804.158838,
    "actor_loss": -64.28147888183594,
    "critic_loss": 55.32668685913086,
    "ent_coef": 0.0744934007525444,
    "learning_rate": 0.001
  },
  {
    "episode": 11479,
    "reward": 87.537662,
    "length": 67,
    "time": 167822.091918,
    "actor_loss": -64.121826171875,
    "critic_loss": 58.35652160644531,
    "ent_coef": 0.07449805736541748,
    "learning_rate": 0.001
  },
  {
    "episode": 11480,
    "reward": 90.004395,
    "length": 63,
    "time": 167833.613597,
    "actor_loss": -69.41804504394531,
    "critic_loss": 10.496305465698242,
    "ent_coef": 0.07898276299238205,
    "learning_rate": 0.001
  },
  {
    "episode": 11481,
    "reward": 87.550018,
    "length": 66,
    "time": 167848.034726,
    "actor_loss": -66.04246520996094,
    "critic_loss": 100.18116760253906,
    "ent_coef": 0.07918321341276169,
    "learning_rate": 0.001
  },
  {
    "episode": 11482,
    "reward": 90.729653,
    "length": 61,
    "time": 167861.713123,
    "actor_loss": -65.93316650390625,
    "critic_loss": 41.42626190185547,
    "ent_coef": 0.08008046448230743,
    "learning_rate": 0.001
  },
  {
    "episode": 11483,
    "reward": 88.174545,
    "length": 66,
    "time": 167873.306756,
    "actor_loss": -59.57098388671875,
    "critic_loss": 8.406426429748535,
    "ent_coef": 0.07904065400362015,
    "learning_rate": 0.001
  },
  {
    "episode": 11484,
    "reward": 88.034353,
    "length": 66,
    "time": 167885.806127,
    "actor_loss": -67.34033203125,
    "critic_loss": 3.8084888458251953,
    "ent_coef": 0.07444576174020767,
    "learning_rate": 0.001
  },
  {
    "episode": 11485,
    "reward": 88.692499,
    "length": 65,
    "time": 167898.103007,
    "actor_loss": -63.8835563659668,
    "critic_loss": 3.9419476985931396,
    "ent_coef": 0.07061203569173813,
    "learning_rate": 0.001
  },
  {
    "episode": 11486,
    "reward": 87.148541,
    "length": 68,
    "time": 167910.839519,
    "actor_loss": -69.45968627929688,
    "critic_loss": 9.39065933227539,
    "ent_coef": 0.06782114505767822,
    "learning_rate": 0.001
  },
  {
    "episode": 11487,
    "reward": 88.565026,
    "length": 65,
    "time": 167926.654581,
    "actor_loss": -70.79964447021484,
    "critic_loss": 17.948204040527344,
    "ent_coef": 0.06583680212497711,
    "learning_rate": 0.001
  },
  {
    "episode": 11488,
    "reward": 89.85929,
    "length": 63,
    "time": 167938.325898,
    "actor_loss": -57.61498260498047,
    "critic_loss": 3.217604637145996,
    "ent_coef": 0.06845859438180923,
    "learning_rate": 0.001
  },
  {
    "episode": 11489,
    "reward": 84.806437,
    "length": 75,
    "time": 167952.180584,
    "actor_loss": -67.0499496459961,
    "critic_loss": 4.236590385437012,
    "ent_coef": 0.07352039963006973,
    "learning_rate": 0.001
  },
  {
    "episode": 11490,
    "reward": 85.281391,
    "length": 81,
    "time": 167966.076197,
    "actor_loss": -69.53660583496094,
    "critic_loss": 3.2412710189819336,
    "ent_coef": 0.0758291706442833,
    "learning_rate": 0.001
  },
  {
    "episode": 11491,
    "reward": 89.257253,
    "length": 64,
    "time": 167979.495053,
    "actor_loss": -67.29724884033203,
    "critic_loss": 4.436075210571289,
    "ent_coef": 0.07370183616876602,
    "learning_rate": 0.001
  },
  {
    "episode": 11492,
    "reward": 90.487888,
    "length": 63,
    "time": 167990.824766,
    "actor_loss": -70.31553649902344,
    "critic_loss": 9.161458969116211,
    "ent_coef": 0.07020111382007599,
    "learning_rate": 0.001
  },
  {
    "episode": 11493,
    "reward": 88.6302,
    "length": 67,
    "time": 168003.40605,
    "actor_loss": -66.88660430908203,
    "critic_loss": 3.167222023010254,
    "ent_coef": 0.06638649851083755,
    "learning_rate": 0.001
  },
  {
    "episode": 11494,
    "reward": 90.526767,
    "length": 62,
    "time": 168014.806235,
    "actor_loss": -66.28021240234375,
    "critic_loss": 166.76876831054688,
    "ent_coef": 0.06517040729522705,
    "learning_rate": 0.001
  },
  {
    "episode": 11495,
    "reward": 90.64904,
    "length": 62,
    "time": 168028.639269,
    "actor_loss": -63.331993103027344,
    "critic_loss": 5.77229642868042,
    "ent_coef": 0.06604870408773422,
    "learning_rate": 0.001
  },
  {
    "episode": 11496,
    "reward": 89.268252,
    "length": 66,
    "time": 168040.594237,
    "actor_loss": -60.89303207397461,
    "critic_loss": 5.9951019287109375,
    "ent_coef": 0.06565509736537933,
    "learning_rate": 0.001
  },
  {
    "episode": 11497,
    "reward": 88.831009,
    "length": 66,
    "time": 168052.093182,
    "actor_loss": -70.83556365966797,
    "critic_loss": 3.432173728942871,
    "ent_coef": 0.06358473747968674,
    "learning_rate": 0.001
  },
  {
    "episode": 11498,
    "reward": 90.409602,
    "length": 62,
    "time": 168063.360043,
    "actor_loss": -64.33773803710938,
    "critic_loss": 20.721954345703125,
    "ent_coef": 0.06255006790161133,
    "learning_rate": 0.001
  },
  {
    "episode": 11499,
    "reward": 90.505536,
    "length": 62,
    "time": 168076.388019,
    "actor_loss": -65.13372039794922,
    "critic_loss": 8.237842559814453,
    "ent_coef": 0.06549593806266785,
    "learning_rate": 0.001
  },
  {
    "episode": 11500,
    "reward": 90.89461,
    "length": 61,
    "time": 168089.550592,
    "actor_loss": -62.19744873046875,
    "critic_loss": 5.763111591339111,
    "ent_coef": 0.06662751734256744,
    "learning_rate": 0.001
  },
  {
    "episode": 11501,
    "reward": -157.058455,
    "length": 148,
    "time": 168116.119104,
    "actor_loss": -64.17434692382812,
    "critic_loss": 8.109665870666504,
    "ent_coef": 0.0668814405798912,
    "learning_rate": 0.001
  },
  {
    "episode": 11502,
    "reward": 89.861962,
    "length": 63,
    "time": 168128.509022,
    "actor_loss": -68.61601257324219,
    "critic_loss": 32.169273376464844,
    "ent_coef": 0.06477460265159607,
    "learning_rate": 0.001
  },
  {
    "episode": 11503,
    "reward": 87.176504,
    "length": 79,
    "time": 168142.157109,
    "actor_loss": -66.42432403564453,
    "critic_loss": 5.668581008911133,
    "ent_coef": 0.06912104785442352,
    "learning_rate": 0.001
  },
  {
    "episode": 11504,
    "reward": 91.431741,
    "length": 60,
    "time": 168156.032599,
    "actor_loss": -65.8798599243164,
    "critic_loss": 4.852424621582031,
    "ent_coef": 0.07250048965215683,
    "learning_rate": 0.001
  },
  {
    "episode": 11505,
    "reward": 90.700726,
    "length": 62,
    "time": 168167.402159,
    "actor_loss": -72.31645965576172,
    "critic_loss": 8.272907257080078,
    "ent_coef": 0.07087255269289017,
    "learning_rate": 0.001
  },
  {
    "episode": 11506,
    "reward": 89.793509,
    "length": 64,
    "time": 168179.948356,
    "actor_loss": -68.89009094238281,
    "critic_loss": 3.900211811065674,
    "ent_coef": 0.06904038041830063,
    "learning_rate": 0.001
  },
  {
    "episode": 11507,
    "reward": 89.640381,
    "length": 64,
    "time": 168191.184703,
    "actor_loss": -69.86894226074219,
    "critic_loss": 16.011966705322266,
    "ent_coef": 0.06974393874406815,
    "learning_rate": 0.001
  },
  {
    "episode": 11508,
    "reward": 89.685856,
    "length": 64,
    "time": 168205.60117,
    "actor_loss": -62.022705078125,
    "critic_loss": 3.7950987815856934,
    "ent_coef": 0.06775347888469696,
    "learning_rate": 0.001
  },
  {
    "episode": 11509,
    "reward": 88.161783,
    "length": 68,
    "time": 168218.319134,
    "actor_loss": -68.57344055175781,
    "critic_loss": 3.3579134941101074,
    "ent_coef": 0.06526169180870056,
    "learning_rate": 0.001
  },
  {
    "episode": 11510,
    "reward": 89.992771,
    "length": 63,
    "time": 168229.594049,
    "actor_loss": -70.4361572265625,
    "critic_loss": 5.457498550415039,
    "ent_coef": 0.06535151600837708,
    "learning_rate": 0.001
  },
  {
    "episode": 11511,
    "reward": 89.854192,
    "length": 64,
    "time": 168241.455974,
    "actor_loss": -70.31669616699219,
    "critic_loss": 19.28790283203125,
    "ent_coef": 0.0646921917796135,
    "learning_rate": 0.001
  },
  {
    "episode": 11512,
    "reward": 88.81923,
    "length": 65,
    "time": 168255.119658,
    "actor_loss": -59.039085388183594,
    "critic_loss": 6.1277360916137695,
    "ent_coef": 0.06220240518450737,
    "learning_rate": 0.001
  },
  {
    "episode": 11513,
    "reward": 90.816938,
    "length": 62,
    "time": 168266.164193,
    "actor_loss": -65.697998046875,
    "critic_loss": 4.936217308044434,
    "ent_coef": 0.06122859939932823,
    "learning_rate": 0.001
  },
  {
    "episode": 11514,
    "reward": 91.385255,
    "length": 61,
    "time": 168278.607116,
    "actor_loss": -66.2806396484375,
    "critic_loss": 43.89906311035156,
    "ent_coef": 0.06443308293819427,
    "learning_rate": 0.001
  },
  {
    "episode": 11515,
    "reward": 90.226049,
    "length": 65,
    "time": 168290.066482,
    "actor_loss": -66.47036743164062,
    "critic_loss": 4.962003707885742,
    "ent_coef": 0.0656038373708725,
    "learning_rate": 0.001
  },
  {
    "episode": 11516,
    "reward": 87.967491,
    "length": 67,
    "time": 168302.268094,
    "actor_loss": -61.41868591308594,
    "critic_loss": 2.092841148376465,
    "ent_coef": 0.06408542394638062,
    "learning_rate": 0.001
  },
  {
    "episode": 11517,
    "reward": 89.970622,
    "length": 64,
    "time": 168316.67071,
    "actor_loss": -64.96049499511719,
    "critic_loss": 3.585635185241699,
    "ent_coef": 0.06624741852283478,
    "learning_rate": 0.001
  },
  {
    "episode": 11518,
    "reward": 89.497544,
    "length": 69,
    "time": 168332.371041,
    "actor_loss": -65.9815673828125,
    "critic_loss": 2.692392587661743,
    "ent_coef": 0.06932269036769867,
    "learning_rate": 0.001
  },
  {
    "episode": 11519,
    "reward": 91.091887,
    "length": 62,
    "time": 168343.209332,
    "actor_loss": -64.73383331298828,
    "critic_loss": 29.220252990722656,
    "ent_coef": 0.0699751153588295,
    "learning_rate": 0.001
  },
  {
    "episode": 11520,
    "reward": 89.799904,
    "length": 64,
    "time": 168356.922915,
    "actor_loss": -66.6673583984375,
    "critic_loss": 4.167520523071289,
    "ent_coef": 0.06830476969480515,
    "learning_rate": 0.001
  },
  {
    "episode": 11521,
    "reward": 89.476664,
    "length": 64,
    "time": 168369.707227,
    "actor_loss": -66.29391479492188,
    "critic_loss": 5.619725227355957,
    "ent_coef": 0.06666555255651474,
    "learning_rate": 0.001
  },
  {
    "episode": 11522,
    "reward": 90.741757,
    "length": 62,
    "time": 168380.939622,
    "actor_loss": -69.02509307861328,
    "critic_loss": 3.526247024536133,
    "ent_coef": 0.06950189918279648,
    "learning_rate": 0.001
  },
  {
    "episode": 11523,
    "reward": 87.05116,
    "length": 80,
    "time": 168396.188601,
    "actor_loss": -67.62623596191406,
    "critic_loss": 22.363250732421875,
    "ent_coef": 0.07290402799844742,
    "learning_rate": 0.001
  },
  {
    "episode": 11524,
    "reward": 85.66331,
    "length": 78,
    "time": 168412.916256,
    "actor_loss": -69.32622528076172,
    "critic_loss": 6.131330490112305,
    "ent_coef": 0.07298848778009415,
    "learning_rate": 0.001
  },
  {
    "episode": 11525,
    "reward": 89.192978,
    "length": 65,
    "time": 168425.031173,
    "actor_loss": -59.62897491455078,
    "critic_loss": 6.602883338928223,
    "ent_coef": 0.07009203732013702,
    "learning_rate": 0.001
  },
  {
    "episode": 11526,
    "reward": 86.806329,
    "length": 78,
    "time": 168439.259313,
    "actor_loss": -67.08472442626953,
    "critic_loss": 13.469043731689453,
    "ent_coef": 0.06776168942451477,
    "learning_rate": 0.001
  },
  {
    "episode": 11527,
    "reward": 89.876269,
    "length": 64,
    "time": 168450.621801,
    "actor_loss": -69.56593322753906,
    "critic_loss": 13.845083236694336,
    "ent_coef": 0.06467466801404953,
    "learning_rate": 0.001
  },
  {
    "episode": 11528,
    "reward": 91.13215,
    "length": 60,
    "time": 168461.333863,
    "actor_loss": -64.33653259277344,
    "critic_loss": 7.969599723815918,
    "ent_coef": 0.06392940133810043,
    "learning_rate": 0.001
  },
  {
    "episode": 11529,
    "reward": 90.564866,
    "length": 62,
    "time": 168475.502885,
    "actor_loss": -68.03099060058594,
    "critic_loss": 13.25571346282959,
    "ent_coef": 0.06642433255910873,
    "learning_rate": 0.001
  },
  {
    "episode": 11530,
    "reward": 88.139598,
    "length": 67,
    "time": 168488.038159,
    "actor_loss": -66.37986755371094,
    "critic_loss": 8.997156143188477,
    "ent_coef": 0.06683719158172607,
    "learning_rate": 0.001
  },
  {
    "episode": 11531,
    "reward": 90.259001,
    "length": 64,
    "time": 168499.778448,
    "actor_loss": -67.40038299560547,
    "critic_loss": 4.746423721313477,
    "ent_coef": 0.06483078002929688,
    "learning_rate": 0.001
  },
  {
    "episode": 11532,
    "reward": 91.203505,
    "length": 61,
    "time": 168510.619836,
    "actor_loss": -63.37213134765625,
    "critic_loss": 14.014328002929688,
    "ent_coef": 0.06536680459976196,
    "learning_rate": 0.001
  },
  {
    "episode": 11533,
    "reward": 85.38197,
    "length": 83,
    "time": 168526.135291,
    "actor_loss": -63.867191314697266,
    "critic_loss": 15.532089233398438,
    "ent_coef": 0.06563199311494827,
    "learning_rate": 0.001
  },
  {
    "episode": 11534,
    "reward": 90.011283,
    "length": 63,
    "time": 168540.266573,
    "actor_loss": -65.87664794921875,
    "critic_loss": 4.283560276031494,
    "ent_coef": 0.06326207518577576,
    "learning_rate": 0.001
  },
  {
    "episode": 11535,
    "reward": 90.526933,
    "length": 63,
    "time": 168553.773795,
    "actor_loss": -65.96469116210938,
    "critic_loss": 20.026987075805664,
    "ent_coef": 0.06282907724380493,
    "learning_rate": 0.001
  },
  {
    "episode": 11536,
    "reward": 78.679336,
    "length": 106,
    "time": 168571.729454,
    "actor_loss": -68.21431732177734,
    "critic_loss": 7.0934062004089355,
    "ent_coef": 0.05746261030435562,
    "learning_rate": 0.001
  },
  {
    "episode": 11537,
    "reward": 91.391194,
    "length": 60,
    "time": 168584.606372,
    "actor_loss": -58.731502532958984,
    "critic_loss": 31.243976593017578,
    "ent_coef": 0.05673699826002121,
    "learning_rate": 0.001
  },
  {
    "episode": 11538,
    "reward": 86.913542,
    "length": 77,
    "time": 168600.482017,
    "actor_loss": -67.43516540527344,
    "critic_loss": 63.778709411621094,
    "ent_coef": 0.055863793939352036,
    "learning_rate": 0.001
  },
  {
    "episode": 11539,
    "reward": 89.787117,
    "length": 65,
    "time": 168614.146223,
    "actor_loss": -61.499263763427734,
    "critic_loss": 75.57831573486328,
    "ent_coef": 0.05525388568639755,
    "learning_rate": 0.001
  },
  {
    "episode": 11540,
    "reward": 87.198734,
    "length": 78,
    "time": 168629.614455,
    "actor_loss": -68.0740737915039,
    "critic_loss": 17.362285614013672,
    "ent_coef": 0.057855308055877686,
    "learning_rate": 0.001
  },
  {
    "episode": 11541,
    "reward": 90.515288,
    "length": 62,
    "time": 168643.70051,
    "actor_loss": -67.34822845458984,
    "critic_loss": 3.3051440715789795,
    "ent_coef": 0.05878598242998123,
    "learning_rate": 0.001
  },
  {
    "episode": 11542,
    "reward": 90.931501,
    "length": 62,
    "time": 168655.355828,
    "actor_loss": -70.85242462158203,
    "critic_loss": 15.2503023147583,
    "ent_coef": 0.060262713581323624,
    "learning_rate": 0.001
  },
  {
    "episode": 11543,
    "reward": 91.417946,
    "length": 60,
    "time": 168668.538563,
    "actor_loss": -66.71957397460938,
    "critic_loss": 15.902115821838379,
    "ent_coef": 0.0637093335390091,
    "learning_rate": 0.001
  },
  {
    "episode": 11544,
    "reward": 90.759949,
    "length": 62,
    "time": 168682.451752,
    "actor_loss": -62.08561325073242,
    "critic_loss": 11.705425262451172,
    "ent_coef": 0.06514866650104523,
    "learning_rate": 0.001
  },
  {
    "episode": 11545,
    "reward": 87.750797,
    "length": 77,
    "time": 168696.326653,
    "actor_loss": -65.33706665039062,
    "critic_loss": 9.716654777526855,
    "ent_coef": 0.06736623495817184,
    "learning_rate": 0.001
  },
  {
    "episode": 11546,
    "reward": 88.629395,
    "length": 66,
    "time": 168709.944976,
    "actor_loss": -67.36297607421875,
    "critic_loss": 41.48875045776367,
    "ent_coef": 0.06786543130874634,
    "learning_rate": 0.001
  },
  {
    "episode": 11547,
    "reward": 91.481522,
    "length": 61,
    "time": 168720.825103,
    "actor_loss": -60.147342681884766,
    "critic_loss": 12.633243560791016,
    "ent_coef": 0.07071982324123383,
    "learning_rate": 0.001
  },
  {
    "episode": 11548,
    "reward": 91.100835,
    "length": 62,
    "time": 168733.060312,
    "actor_loss": -64.729736328125,
    "critic_loss": 7.67609977722168,
    "ent_coef": 0.0720619410276413,
    "learning_rate": 0.001
  },
  {
    "episode": 11549,
    "reward": 89.549923,
    "length": 65,
    "time": 168744.263082,
    "actor_loss": -60.66887664794922,
    "critic_loss": 3.790651321411133,
    "ent_coef": 0.07035534828901291,
    "learning_rate": 0.001
  },
  {
    "episode": 11550,
    "reward": 90.643541,
    "length": 63,
    "time": 168755.375154,
    "actor_loss": -65.47361755371094,
    "critic_loss": 3.3714346885681152,
    "ent_coef": 0.06879668682813644,
    "learning_rate": 0.001
  },
  {
    "episode": 11551,
    "reward": 91.494536,
    "length": 60,
    "time": 168766.397092,
    "actor_loss": -62.19104766845703,
    "critic_loss": 5.235980987548828,
    "ent_coef": 0.06884326040744781,
    "learning_rate": 0.001
  },
  {
    "episode": 11552,
    "reward": 91.350618,
    "length": 61,
    "time": 168779.7288,
    "actor_loss": -68.64149475097656,
    "critic_loss": 4.364727020263672,
    "ent_coef": 0.07112516462802887,
    "learning_rate": 0.001
  },
  {
    "episode": 11553,
    "reward": 90.577105,
    "length": 63,
    "time": 168790.839121,
    "actor_loss": -64.73249053955078,
    "critic_loss": 3.64561128616333,
    "ent_coef": 0.06967651098966599,
    "learning_rate": 0.001
  },
  {
    "episode": 11554,
    "reward": 91.469076,
    "length": 61,
    "time": 168801.819584,
    "actor_loss": -64.16683959960938,
    "critic_loss": 9.545034408569336,
    "ent_coef": 0.07400698959827423,
    "learning_rate": 0.001
  },
  {
    "episode": 11555,
    "reward": 90.749795,
    "length": 63,
    "time": 168813.836169,
    "actor_loss": -64.33755493164062,
    "critic_loss": 5.663514614105225,
    "ent_coef": 0.07380375266075134,
    "learning_rate": 0.001
  },
  {
    "episode": 11556,
    "reward": 89.797581,
    "length": 65,
    "time": 168830.086841,
    "actor_loss": -66.97417449951172,
    "critic_loss": 10.215726852416992,
    "ent_coef": 0.07280439883470535,
    "learning_rate": 0.001
  },
  {
    "episode": 11557,
    "reward": 88.947495,
    "length": 65,
    "time": 168841.353002,
    "actor_loss": -67.02685546875,
    "critic_loss": 27.84654998779297,
    "ent_coef": 0.07099245488643646,
    "learning_rate": 0.001
  },
  {
    "episode": 11558,
    "reward": 91.240945,
    "length": 61,
    "time": 168852.129859,
    "actor_loss": -68.92379760742188,
    "critic_loss": 2.8821136951446533,
    "ent_coef": 0.07246140390634537,
    "learning_rate": 0.001
  },
  {
    "episode": 11559,
    "reward": 90.312317,
    "length": 64,
    "time": 168866.151364,
    "actor_loss": -63.22759246826172,
    "critic_loss": 11.534576416015625,
    "ent_coef": 0.07193326950073242,
    "learning_rate": 0.001
  },
  {
    "episode": 11560,
    "reward": 89.032533,
    "length": 67,
    "time": 168877.826889,
    "actor_loss": -72.27525329589844,
    "critic_loss": 6.614768028259277,
    "ent_coef": 0.0694488137960434,
    "learning_rate": 0.001
  },
  {
    "episode": 11561,
    "reward": 91.19978,
    "length": 61,
    "time": 168892.208491,
    "actor_loss": -67.27081298828125,
    "critic_loss": 70.86137390136719,
    "ent_coef": 0.06803596019744873,
    "learning_rate": 0.001
  },
  {
    "episode": 11562,
    "reward": -161.442459,
    "length": 192,
    "time": 168920.328002,
    "actor_loss": -78.4886245727539,
    "critic_loss": 2.633340358734131,
    "ent_coef": 0.06770514696836472,
    "learning_rate": 0.001
  },
  {
    "episode": 11563,
    "reward": 88.972117,
    "length": 63,
    "time": 168932.332306,
    "actor_loss": -69.66511535644531,
    "critic_loss": 6.260481834411621,
    "ent_coef": 0.06849949061870575,
    "learning_rate": 0.001
  },
  {
    "episode": 11564,
    "reward": 90.594323,
    "length": 61,
    "time": 168943.266938,
    "actor_loss": -60.112274169921875,
    "critic_loss": 22.55905532836914,
    "ent_coef": 0.06773010641336441,
    "learning_rate": 0.001
  },
  {
    "episode": 11565,
    "reward": 90.578627,
    "length": 63,
    "time": 168958.003108,
    "actor_loss": -56.919517517089844,
    "critic_loss": 7.697193145751953,
    "ent_coef": 0.06636705994606018,
    "learning_rate": 0.001
  },
  {
    "episode": 11566,
    "reward": 90.386716,
    "length": 63,
    "time": 168971.704719,
    "actor_loss": -72.8821029663086,
    "critic_loss": 34.94139099121094,
    "ent_coef": 0.06358728557825089,
    "learning_rate": 0.001
  },
  {
    "episode": 11567,
    "reward": 88.754322,
    "length": 67,
    "time": 168984.631804,
    "actor_loss": -67.94058227539062,
    "critic_loss": 4.341902732849121,
    "ent_coef": 0.060144826769828796,
    "learning_rate": 0.001
  },
  {
    "episode": 11568,
    "reward": 91.555266,
    "length": 61,
    "time": 168996.822507,
    "actor_loss": -68.87269592285156,
    "critic_loss": 4.117401599884033,
    "ent_coef": 0.06079689785838127,
    "learning_rate": 0.001
  },
  {
    "episode": 11569,
    "reward": 89.627138,
    "length": 64,
    "time": 169008.301105,
    "actor_loss": -68.41754150390625,
    "critic_loss": 95.4593734741211,
    "ent_coef": 0.061363544315099716,
    "learning_rate": 0.001
  },
  {
    "episode": 11570,
    "reward": 90.989145,
    "length": 62,
    "time": 169020.289231,
    "actor_loss": -68.97721862792969,
    "critic_loss": 2.3803658485412598,
    "ent_coef": 0.061812322586774826,
    "learning_rate": 0.001
  },
  {
    "episode": 11571,
    "reward": 92.110849,
    "length": 59,
    "time": 169033.484607,
    "actor_loss": -62.61025619506836,
    "critic_loss": 6.3050150871276855,
    "ent_coef": 0.06538994610309601,
    "learning_rate": 0.001
  },
  {
    "episode": 11572,
    "reward": 90.499146,
    "length": 62,
    "time": 169045.470155,
    "actor_loss": -72.91395568847656,
    "critic_loss": 15.339990615844727,
    "ent_coef": 0.06508064270019531,
    "learning_rate": 0.001
  },
  {
    "episode": 11573,
    "reward": 86.064628,
    "length": 81,
    "time": 169062.950691,
    "actor_loss": -64.53142547607422,
    "critic_loss": 7.058289527893066,
    "ent_coef": 0.06897880882024765,
    "learning_rate": 0.001
  },
  {
    "episode": 11574,
    "reward": 88.075816,
    "length": 66,
    "time": 169077.271041,
    "actor_loss": -66.76753234863281,
    "critic_loss": 27.02393341064453,
    "ent_coef": 0.06309960782527924,
    "learning_rate": 0.001
  },
  {
    "episode": 11575,
    "reward": 90.824099,
    "length": 62,
    "time": 169089.219243,
    "actor_loss": -71.87016296386719,
    "critic_loss": 3.36596941947937,
    "ent_coef": 0.061327580362558365,
    "learning_rate": 0.001
  },
  {
    "episode": 11576,
    "reward": 86.495762,
    "length": 67,
    "time": 169101.8538,
    "actor_loss": -65.13677215576172,
    "critic_loss": 2.614861011505127,
    "ent_coef": 0.06369122117757797,
    "learning_rate": 0.001
  },
  {
    "episode": 11577,
    "reward": 91.064391,
    "length": 61,
    "time": 169114.330711,
    "actor_loss": -70.11924743652344,
    "critic_loss": 4.920177936553955,
    "ent_coef": 0.06658504903316498,
    "learning_rate": 0.001
  },
  {
    "episode": 11578,
    "reward": 91.176242,
    "length": 61,
    "time": 169125.227266,
    "actor_loss": -62.519500732421875,
    "critic_loss": 3.2343907356262207,
    "ent_coef": 0.06934092193841934,
    "learning_rate": 0.001
  },
  {
    "episode": 11579,
    "reward": 90.960528,
    "length": 61,
    "time": 169138.304737,
    "actor_loss": -68.18280029296875,
    "critic_loss": 3.248101234436035,
    "ent_coef": 0.06996592879295349,
    "learning_rate": 0.001
  },
  {
    "episode": 11580,
    "reward": 91.15122,
    "length": 61,
    "time": 169150.34817,
    "actor_loss": -69.67108154296875,
    "critic_loss": 6.32625675201416,
    "ent_coef": 0.06868486106395721,
    "learning_rate": 0.001
  },
  {
    "episode": 11581,
    "reward": 90.668228,
    "length": 63,
    "time": 169165.823614,
    "actor_loss": -65.17894744873047,
    "critic_loss": 11.343061447143555,
    "ent_coef": 0.06761620193719864,
    "learning_rate": 0.001
  },
  {
    "episode": 11582,
    "reward": 91.300765,
    "length": 61,
    "time": 169178.671885,
    "actor_loss": -69.76722717285156,
    "critic_loss": 4.545619010925293,
    "ent_coef": 0.06607075035572052,
    "learning_rate": 0.001
  },
  {
    "episode": 11583,
    "reward": 91.344272,
    "length": 62,
    "time": 169189.777802,
    "actor_loss": -70.57656860351562,
    "critic_loss": 56.89146041870117,
    "ent_coef": 0.0644877478480339,
    "learning_rate": 0.001
  },
  {
    "episode": 11584,
    "reward": 91.37974,
    "length": 60,
    "time": 169204.360691,
    "actor_loss": -67.98192596435547,
    "critic_loss": 3.3116297721862793,
    "ent_coef": 0.0652497261762619,
    "learning_rate": 0.001
  },
  {
    "episode": 11585,
    "reward": 91.340238,
    "length": 61,
    "time": 169215.41423,
    "actor_loss": -66.3128433227539,
    "critic_loss": 6.575536251068115,
    "ent_coef": 0.06708221137523651,
    "learning_rate": 0.001
  },
  {
    "episode": 11586,
    "reward": 91.686597,
    "length": 60,
    "time": 169226.396011,
    "actor_loss": -67.22000885009766,
    "critic_loss": 2.358867645263672,
    "ent_coef": 0.07295478880405426,
    "learning_rate": 0.001
  },
  {
    "episode": 11587,
    "reward": 91.222611,
    "length": 61,
    "time": 169237.368318,
    "actor_loss": -67.11866760253906,
    "critic_loss": 7.430023193359375,
    "ent_coef": 0.07480225712060928,
    "learning_rate": 0.001
  },
  {
    "episode": 11588,
    "reward": 88.534112,
    "length": 67,
    "time": 169249.262091,
    "actor_loss": -64.81166076660156,
    "critic_loss": 5.0933051109313965,
    "ent_coef": 0.07290993630886078,
    "learning_rate": 0.001
  },
  {
    "episode": 11589,
    "reward": 90.527998,
    "length": 62,
    "time": 169264.883722,
    "actor_loss": -67.49835968017578,
    "critic_loss": 7.885873794555664,
    "ent_coef": 0.07534703612327576,
    "learning_rate": 0.001
  },
  {
    "episode": 11590,
    "reward": 91.522025,
    "length": 61,
    "time": 169275.68488,
    "actor_loss": -67.363525390625,
    "critic_loss": 3.641608476638794,
    "ent_coef": 0.07749191671609879,
    "learning_rate": 0.001
  },
  {
    "episode": 11591,
    "reward": 90.309442,
    "length": 63,
    "time": 169289.258688,
    "actor_loss": -63.48622512817383,
    "critic_loss": 3.7612998485565186,
    "ent_coef": 0.07637018710374832,
    "learning_rate": 0.001
  },
  {
    "episode": 11592,
    "reward": 89.359907,
    "length": 65,
    "time": 169301.688388,
    "actor_loss": -65.92646789550781,
    "critic_loss": 4.218621253967285,
    "ent_coef": 0.07234209030866623,
    "learning_rate": 0.001
  },
  {
    "episode": 11593,
    "reward": 76.875555,
    "length": 162,
    "time": 169326.996208,
    "actor_loss": -63.337337493896484,
    "critic_loss": 87.65689086914062,
    "ent_coef": 0.06609104573726654,
    "learning_rate": 0.001
  },
  {
    "episode": 11594,
    "reward": 91.048067,
    "length": 61,
    "time": 169340.287606,
    "actor_loss": -62.56510543823242,
    "critic_loss": 32.25056076049805,
    "ent_coef": 0.06764537841081619,
    "learning_rate": 0.001
  },
  {
    "episode": 11595,
    "reward": 90.931914,
    "length": 62,
    "time": 169352.957581,
    "actor_loss": -65.04356384277344,
    "critic_loss": 34.454471588134766,
    "ent_coef": 0.06815658509731293,
    "learning_rate": 0.001
  },
  {
    "episode": 11596,
    "reward": 88.054725,
    "length": 68,
    "time": 169364.72633,
    "actor_loss": -71.70343017578125,
    "critic_loss": 42.043636322021484,
    "ent_coef": 0.06532598286867142,
    "learning_rate": 0.001
  },
  {
    "episode": 11597,
    "reward": 89.337403,
    "length": 65,
    "time": 169379.021322,
    "actor_loss": -62.594940185546875,
    "critic_loss": 3.459664821624756,
    "ent_coef": 0.06324681639671326,
    "learning_rate": 0.001
  },
  {
    "episode": 11598,
    "reward": 90.347484,
    "length": 63,
    "time": 169389.995777,
    "actor_loss": -64.8350830078125,
    "critic_loss": 34.11640167236328,
    "ent_coef": 0.06390724331140518,
    "learning_rate": 0.001
  },
  {
    "episode": 11599,
    "reward": 89.38985,
    "length": 64,
    "time": 169403.298906,
    "actor_loss": -69.981689453125,
    "critic_loss": 84.96350860595703,
    "ent_coef": 0.06335588544607162,
    "learning_rate": 0.001
  },
  {
    "episode": 11600,
    "reward": 90.798286,
    "length": 61,
    "time": 169415.702066,
    "actor_loss": -59.95271301269531,
    "critic_loss": 7.787579536437988,
    "ent_coef": 0.06647756695747375,
    "learning_rate": 0.001
  },
  {
    "episode": 11601,
    "reward": 90.669873,
    "length": 62,
    "time": 169427.397332,
    "actor_loss": -66.7347412109375,
    "critic_loss": 4.029134273529053,
    "ent_coef": 0.0680408626794815,
    "learning_rate": 0.001
  },
  {
    "episode": 11602,
    "reward": 90.96127,
    "length": 62,
    "time": 169440.616559,
    "actor_loss": -72.14530944824219,
    "critic_loss": 20.456912994384766,
    "ent_coef": 0.06997085362672806,
    "learning_rate": 0.001
  },
  {
    "episode": 11603,
    "reward": 90.165294,
    "length": 63,
    "time": 169452.66491,
    "actor_loss": -66.15838623046875,
    "critic_loss": 41.04520797729492,
    "ent_coef": 0.07235150784254074,
    "learning_rate": 0.001
  },
  {
    "episode": 11604,
    "reward": 91.546552,
    "length": 61,
    "time": 169463.892556,
    "actor_loss": -63.50258255004883,
    "critic_loss": 28.322872161865234,
    "ent_coef": 0.07245848327875137,
    "learning_rate": 0.001
  },
  {
    "episode": 11605,
    "reward": 91.414561,
    "length": 60,
    "time": 169477.16431,
    "actor_loss": -65.08556365966797,
    "critic_loss": 11.368165969848633,
    "ent_coef": 0.07376853376626968,
    "learning_rate": 0.001
  },
  {
    "episode": 11606,
    "reward": 91.077063,
    "length": 62,
    "time": 169492.521808,
    "actor_loss": -67.84532928466797,
    "critic_loss": 3.9764411449432373,
    "ent_coef": 0.07441465556621552,
    "learning_rate": 0.001
  },
  {
    "episode": 11607,
    "reward": 90.342435,
    "length": 63,
    "time": 169504.602726,
    "actor_loss": -66.52434539794922,
    "critic_loss": 3.790015459060669,
    "ent_coef": 0.07570356130599976,
    "learning_rate": 0.001
  },
  {
    "episode": 11608,
    "reward": 90.613082,
    "length": 63,
    "time": 169515.63651,
    "actor_loss": -70.62615966796875,
    "critic_loss": 137.09707641601562,
    "ent_coef": 0.07548253238201141,
    "learning_rate": 0.001
  },
  {
    "episode": 11609,
    "reward": 91.111645,
    "length": 62,
    "time": 169526.95366,
    "actor_loss": -65.70344543457031,
    "critic_loss": 8.064532279968262,
    "ent_coef": 0.07626140117645264,
    "learning_rate": 0.001
  },
  {
    "episode": 11610,
    "reward": 91.828091,
    "length": 59,
    "time": 169539.405337,
    "actor_loss": -69.98434448242188,
    "critic_loss": 5.599266052246094,
    "ent_coef": 0.08020887523889542,
    "learning_rate": 0.001
  },
  {
    "episode": 11611,
    "reward": 90.590411,
    "length": 62,
    "time": 169552.063387,
    "actor_loss": -68.00125885009766,
    "critic_loss": 2.432753562927246,
    "ent_coef": 0.08120843023061752,
    "learning_rate": 0.001
  },
  {
    "episode": 11612,
    "reward": 91.199095,
    "length": 62,
    "time": 169564.225183,
    "actor_loss": -64.59957885742188,
    "critic_loss": 4.345171928405762,
    "ent_coef": 0.08167976140975952,
    "learning_rate": 0.001
  },
  {
    "episode": 11613,
    "reward": 87.810997,
    "length": 69,
    "time": 169580.335178,
    "actor_loss": -67.33039855957031,
    "critic_loss": 5.246738433837891,
    "ent_coef": 0.07595859467983246,
    "learning_rate": 0.001
  },
  {
    "episode": 11614,
    "reward": 88.666418,
    "length": 71,
    "time": 169592.590294,
    "actor_loss": -64.04702758789062,
    "critic_loss": 3.2456607818603516,
    "ent_coef": 0.06993954628705978,
    "learning_rate": 0.001
  },
  {
    "episode": 11615,
    "reward": 89.212778,
    "length": 66,
    "time": 169604.132984,
    "actor_loss": -66.55987548828125,
    "critic_loss": 3.9223735332489014,
    "ent_coef": 0.0680580735206604,
    "learning_rate": 0.001
  },
  {
    "episode": 11616,
    "reward": 90.231938,
    "length": 63,
    "time": 169615.736758,
    "actor_loss": -66.49827575683594,
    "critic_loss": 3.814908027648926,
    "ent_coef": 0.0662708505988121,
    "learning_rate": 0.001
  },
  {
    "episode": 11617,
    "reward": 90.031921,
    "length": 65,
    "time": 169628.454177,
    "actor_loss": -65.82614135742188,
    "critic_loss": 13.022446632385254,
    "ent_coef": 0.06076807528734207,
    "learning_rate": 0.001
  },
  {
    "episode": 11618,
    "reward": 90.213211,
    "length": 64,
    "time": 169639.585459,
    "actor_loss": -64.90399169921875,
    "critic_loss": 5.296816825866699,
    "ent_coef": 0.060390204191207886,
    "learning_rate": 0.001
  },
  {
    "episode": 11619,
    "reward": 90.803284,
    "length": 63,
    "time": 169654.598233,
    "actor_loss": -68.26416778564453,
    "critic_loss": 4.561916828155518,
    "ent_coef": 0.0608460009098053,
    "learning_rate": 0.001
  },
  {
    "episode": 11620,
    "reward": 90.717764,
    "length": 62,
    "time": 169665.912907,
    "actor_loss": -68.4537353515625,
    "critic_loss": 9.301795959472656,
    "ent_coef": 0.06053004041314125,
    "learning_rate": 0.001
  },
  {
    "episode": 11621,
    "reward": 89.925423,
    "length": 64,
    "time": 169677.536541,
    "actor_loss": -66.9371337890625,
    "critic_loss": 3.723694324493408,
    "ent_coef": 0.06121886521577835,
    "learning_rate": 0.001
  },
  {
    "episode": 11622,
    "reward": 91.021095,
    "length": 62,
    "time": 169688.357795,
    "actor_loss": -66.00247192382812,
    "critic_loss": 26.410419464111328,
    "ent_coef": 0.06227336451411247,
    "learning_rate": 0.001
  },
  {
    "episode": 11623,
    "reward": 91.077562,
    "length": 61,
    "time": 169700.158699,
    "actor_loss": -71.300048828125,
    "critic_loss": 3.063171625137329,
    "ent_coef": 0.06129651516675949,
    "learning_rate": 0.001
  },
  {
    "episode": 11624,
    "reward": 90.841999,
    "length": 62,
    "time": 169714.676111,
    "actor_loss": -67.96835327148438,
    "critic_loss": 32.961341857910156,
    "ent_coef": 0.061131760478019714,
    "learning_rate": 0.001
  },
  {
    "episode": 11625,
    "reward": 91.5433,
    "length": 60,
    "time": 169725.850623,
    "actor_loss": -65.44367980957031,
    "critic_loss": 4.0644731521606445,
    "ent_coef": 0.06251909583806992,
    "learning_rate": 0.001
  },
  {
    "episode": 11626,
    "reward": 90.883945,
    "length": 62,
    "time": 169738.279844,
    "actor_loss": -59.59748840332031,
    "critic_loss": 6.538278579711914,
    "ent_coef": 0.06270340830087662,
    "learning_rate": 0.001
  },
  {
    "episode": 11627,
    "reward": 89.658654,
    "length": 64,
    "time": 169750.053561,
    "actor_loss": -67.96511840820312,
    "critic_loss": 4.7762250900268555,
    "ent_coef": 0.06297100335359573,
    "learning_rate": 0.001
  },
  {
    "episode": 11628,
    "reward": 89.686389,
    "length": 64,
    "time": 169762.320497,
    "actor_loss": -63.82906723022461,
    "critic_loss": 17.9813232421875,
    "ent_coef": 0.06113104522228241,
    "learning_rate": 0.001
  },
  {
    "episode": 11629,
    "reward": 91.431361,
    "length": 60,
    "time": 169773.097962,
    "actor_loss": -70.76797485351562,
    "critic_loss": 5.33564567565918,
    "ent_coef": 0.06147829443216324,
    "learning_rate": 0.001
  },
  {
    "episode": 11630,
    "reward": 90.958736,
    "length": 62,
    "time": 169783.87166,
    "actor_loss": -67.8736801147461,
    "critic_loss": 2.531076669692993,
    "ent_coef": 0.06268615275621414,
    "learning_rate": 0.001
  },
  {
    "episode": 11631,
    "reward": 90.011293,
    "length": 64,
    "time": 169796.580688,
    "actor_loss": -68.02952575683594,
    "critic_loss": 92.52238464355469,
    "ent_coef": 0.0621592178940773,
    "learning_rate": 0.001
  },
  {
    "episode": 11632,
    "reward": 89.630299,
    "length": 63,
    "time": 169810.135864,
    "actor_loss": -68.091796875,
    "critic_loss": 6.739211082458496,
    "ent_coef": 0.06343211978673935,
    "learning_rate": 0.001
  },
  {
    "episode": 11633,
    "reward": 91.181374,
    "length": 60,
    "time": 169820.844669,
    "actor_loss": -75.50089263916016,
    "critic_loss": 3.725253105163574,
    "ent_coef": 0.0650118961930275,
    "learning_rate": 0.001
  },
  {
    "episode": 11634,
    "reward": 90.677127,
    "length": 63,
    "time": 169832.171402,
    "actor_loss": -69.92512512207031,
    "critic_loss": 3.354586124420166,
    "ent_coef": 0.06441397219896317,
    "learning_rate": 0.001
  },
  {
    "episode": 11635,
    "reward": 89.071553,
    "length": 64,
    "time": 169843.732433,
    "actor_loss": -67.75762176513672,
    "critic_loss": 17.361427307128906,
    "ent_coef": 0.06120870262384415,
    "learning_rate": 0.001
  },
  {
    "episode": 11636,
    "reward": 90.748397,
    "length": 62,
    "time": 169854.766201,
    "actor_loss": -62.81050109863281,
    "critic_loss": 71.99312591552734,
    "ent_coef": 0.06099185720086098,
    "learning_rate": 0.001
  },
  {
    "episode": 11637,
    "reward": 89.97364,
    "length": 64,
    "time": 169866.084563,
    "actor_loss": -68.60664367675781,
    "critic_loss": 2.8930540084838867,
    "ent_coef": 0.06026957929134369,
    "learning_rate": 0.001
  },
  {
    "episode": 11638,
    "reward": 91.354795,
    "length": 61,
    "time": 169877.123766,
    "actor_loss": -67.66532897949219,
    "critic_loss": 4.497127532958984,
    "ent_coef": 0.06072044372558594,
    "learning_rate": 0.001
  },
  {
    "episode": 11639,
    "reward": 91.134862,
    "length": 62,
    "time": 169889.717796,
    "actor_loss": -70.28323364257812,
    "critic_loss": 3.8903822898864746,
    "ent_coef": 0.06180857867002487,
    "learning_rate": 0.001
  },
  {
    "episode": 11640,
    "reward": 91.14053,
    "length": 62,
    "time": 169903.444076,
    "actor_loss": -73.20954132080078,
    "critic_loss": 3.5954267978668213,
    "ent_coef": 0.0641566812992096,
    "learning_rate": 0.001
  },
  {
    "episode": 11641,
    "reward": 89.76916,
    "length": 65,
    "time": 169916.563861,
    "actor_loss": -75.14643859863281,
    "critic_loss": 9.522452354431152,
    "ent_coef": 0.0666186660528183,
    "learning_rate": 0.001
  },
  {
    "episode": 11642,
    "reward": 90.665414,
    "length": 63,
    "time": 169927.806454,
    "actor_loss": -63.40162658691406,
    "critic_loss": 6.7162675857543945,
    "ent_coef": 0.06441084295511246,
    "learning_rate": 0.001
  },
  {
    "episode": 11643,
    "reward": 87.049931,
    "length": 77,
    "time": 169940.63502,
    "actor_loss": -68.35963439941406,
    "critic_loss": 2.663381338119507,
    "ent_coef": 0.06467698514461517,
    "learning_rate": 0.001
  },
  {
    "episode": 11644,
    "reward": 90.955258,
    "length": 62,
    "time": 169952.848664,
    "actor_loss": -65.21929931640625,
    "critic_loss": 7.968245983123779,
    "ent_coef": 0.06451628357172012,
    "learning_rate": 0.001
  },
  {
    "episode": 11645,
    "reward": 91.388304,
    "length": 61,
    "time": 169963.746803,
    "actor_loss": -67.54833984375,
    "critic_loss": 5.161171913146973,
    "ent_coef": 0.06396307796239853,
    "learning_rate": 0.001
  },
  {
    "episode": 11646,
    "reward": 91.745754,
    "length": 60,
    "time": 169974.525074,
    "actor_loss": -62.123687744140625,
    "critic_loss": 8.222834587097168,
    "ent_coef": 0.06631363183259964,
    "learning_rate": 0.001
  },
  {
    "episode": 11647,
    "reward": 91.324698,
    "length": 61,
    "time": 169986.636934,
    "actor_loss": -72.71072387695312,
    "critic_loss": 5.401604652404785,
    "ent_coef": 0.06784272193908691,
    "learning_rate": 0.001
  },
  {
    "episode": 11648,
    "reward": 90.29946,
    "length": 63,
    "time": 169999.651976,
    "actor_loss": -70.02354431152344,
    "critic_loss": 2.7187490463256836,
    "ent_coef": 0.06719743460416794,
    "learning_rate": 0.001
  },
  {
    "episode": 11649,
    "reward": 91.05269,
    "length": 62,
    "time": 170010.947171,
    "actor_loss": -70.10901641845703,
    "critic_loss": 6.256750106811523,
    "ent_coef": 0.06671040505170822,
    "learning_rate": 0.001
  },
  {
    "episode": 11650,
    "reward": 91.955897,
    "length": 59,
    "time": 170023.186297,
    "actor_loss": -65.10636901855469,
    "critic_loss": 7.432845592498779,
    "ent_coef": 0.0690966472029686,
    "learning_rate": 0.001
  },
  {
    "episode": 11651,
    "reward": 89.687902,
    "length": 64,
    "time": 170036.177019,
    "actor_loss": -69.05795288085938,
    "critic_loss": 9.578397750854492,
    "ent_coef": 0.06592602282762527,
    "learning_rate": 0.001
  },
  {
    "episode": 11652,
    "reward": 90.750962,
    "length": 62,
    "time": 170048.914588,
    "actor_loss": -64.02867889404297,
    "critic_loss": 4.437772750854492,
    "ent_coef": 0.0647183209657669,
    "learning_rate": 0.001
  },
  {
    "episode": 11653,
    "reward": 89.16648,
    "length": 65,
    "time": 170062.872586,
    "actor_loss": -68.38809967041016,
    "critic_loss": 2.5961251258850098,
    "ent_coef": 0.06349904835224152,
    "learning_rate": 0.001
  },
  {
    "episode": 11654,
    "reward": 91.242236,
    "length": 61,
    "time": 170075.736186,
    "actor_loss": -67.20841979980469,
    "critic_loss": 5.439841270446777,
    "ent_coef": 0.06468759477138519,
    "learning_rate": 0.001
  },
  {
    "episode": 11655,
    "reward": 91.093482,
    "length": 61,
    "time": 170089.245338,
    "actor_loss": -68.82906341552734,
    "critic_loss": 4.565779209136963,
    "ent_coef": 0.06629426777362823,
    "learning_rate": 0.001
  },
  {
    "episode": 11656,
    "reward": 91.000191,
    "length": 62,
    "time": 170101.455726,
    "actor_loss": -68.0619888305664,
    "critic_loss": 2.28695011138916,
    "ent_coef": 0.06633545458316803,
    "learning_rate": 0.001
  },
  {
    "episode": 11657,
    "reward": 91.481124,
    "length": 60,
    "time": 170116.298051,
    "actor_loss": -63.62199783325195,
    "critic_loss": 6.418432235717773,
    "ent_coef": 0.0675177201628685,
    "learning_rate": 0.001
  },
  {
    "episode": 11658,
    "reward": 91.569977,
    "length": 60,
    "time": 170127.82133,
    "actor_loss": -70.89042663574219,
    "critic_loss": 5.541309833526611,
    "ent_coef": 0.06940890848636627,
    "learning_rate": 0.001
  },
  {
    "episode": 11659,
    "reward": 90.822321,
    "length": 62,
    "time": 170139.194438,
    "actor_loss": -67.803955078125,
    "critic_loss": 4.5217084884643555,
    "ent_coef": 0.07050005346536636,
    "learning_rate": 0.001
  },
  {
    "episode": 11660,
    "reward": 91.716224,
    "length": 60,
    "time": 170152.361137,
    "actor_loss": -63.89377975463867,
    "critic_loss": 4.322495460510254,
    "ent_coef": 0.07070064544677734,
    "learning_rate": 0.001
  },
  {
    "episode": 11661,
    "reward": 90.068588,
    "length": 64,
    "time": 170164.991378,
    "actor_loss": -72.1134033203125,
    "critic_loss": 26.501426696777344,
    "ent_coef": 0.07038586586713791,
    "learning_rate": 0.001
  },
  {
    "episode": 11662,
    "reward": 90.90741,
    "length": 62,
    "time": 170176.136457,
    "actor_loss": -64.12202453613281,
    "critic_loss": 8.29951286315918,
    "ent_coef": 0.07045873254537582,
    "learning_rate": 0.001
  },
  {
    "episode": 11663,
    "reward": 88.204026,
    "length": 68,
    "time": 170189.73846,
    "actor_loss": -68.13288116455078,
    "critic_loss": 9.632745742797852,
    "ent_coef": 0.06673773378133774,
    "learning_rate": 0.001
  },
  {
    "episode": 11664,
    "reward": 90.537331,
    "length": 62,
    "time": 170200.890422,
    "actor_loss": -68.19127655029297,
    "critic_loss": 10.617158889770508,
    "ent_coef": 0.06634023040533066,
    "learning_rate": 0.001
  },
  {
    "episode": 11665,
    "reward": 90.373601,
    "length": 63,
    "time": 170214.03037,
    "actor_loss": -68.35901641845703,
    "critic_loss": 5.749566078186035,
    "ent_coef": 0.06250818073749542,
    "learning_rate": 0.001
  },
  {
    "episode": 11666,
    "reward": 89.338141,
    "length": 65,
    "time": 170225.515616,
    "actor_loss": -67.57742309570312,
    "critic_loss": 35.40721893310547,
    "ent_coef": 0.058387767523527145,
    "learning_rate": 0.001
  },
  {
    "episode": 11667,
    "reward": 90.309036,
    "length": 64,
    "time": 170238.383269,
    "actor_loss": -67.81727600097656,
    "critic_loss": 3.317671298980713,
    "ent_coef": 0.058628421276807785,
    "learning_rate": 0.001
  },
  {
    "episode": 11668,
    "reward": 91.277972,
    "length": 61,
    "time": 170249.253481,
    "actor_loss": -72.39863586425781,
    "critic_loss": 21.520675659179688,
    "ent_coef": 0.062362123280763626,
    "learning_rate": 0.001
  },
  {
    "episode": 11669,
    "reward": 90.621141,
    "length": 64,
    "time": 170260.463014,
    "actor_loss": -68.52008056640625,
    "critic_loss": 4.120854377746582,
    "ent_coef": 0.06696850061416626,
    "learning_rate": 0.001
  },
  {
    "episode": 11670,
    "reward": 91.728115,
    "length": 60,
    "time": 170271.364366,
    "actor_loss": -63.03582000732422,
    "critic_loss": 9.083433151245117,
    "ent_coef": 0.07305613905191422,
    "learning_rate": 0.001
  },
  {
    "episode": 11671,
    "reward": 89.754392,
    "length": 68,
    "time": 170283.722699,
    "actor_loss": -69.28080749511719,
    "critic_loss": 2.8691492080688477,
    "ent_coef": 0.07231982797384262,
    "learning_rate": 0.001
  },
  {
    "episode": 11672,
    "reward": 92.05307,
    "length": 59,
    "time": 170295.78255,
    "actor_loss": -72.65327453613281,
    "critic_loss": 3.4528093338012695,
    "ent_coef": 0.07319071143865585,
    "learning_rate": 0.001
  },
  {
    "episode": 11673,
    "reward": 89.238428,
    "length": 65,
    "time": 170307.550723,
    "actor_loss": -67.71416473388672,
    "critic_loss": 26.857337951660156,
    "ent_coef": 0.07468320429325104,
    "learning_rate": 0.001
  },
  {
    "episode": 11674,
    "reward": 91.308936,
    "length": 61,
    "time": 170318.920865,
    "actor_loss": -64.91162109375,
    "critic_loss": 3.2029013633728027,
    "ent_coef": 0.07371705770492554,
    "learning_rate": 0.001
  },
  {
    "episode": 11675,
    "reward": 91.640255,
    "length": 60,
    "time": 170331.217647,
    "actor_loss": -63.14039611816406,
    "critic_loss": 38.654747009277344,
    "ent_coef": 0.07072163373231888,
    "learning_rate": 0.001
  },
  {
    "episode": 11676,
    "reward": 91.165218,
    "length": 61,
    "time": 170342.361874,
    "actor_loss": -70.25857543945312,
    "critic_loss": 19.66318130493164,
    "ent_coef": 0.0690273642539978,
    "learning_rate": 0.001
  },
  {
    "episode": 11677,
    "reward": 91.119445,
    "length": 61,
    "time": 170353.19933,
    "actor_loss": -70.5367431640625,
    "critic_loss": 11.623753547668457,
    "ent_coef": 0.07187069952487946,
    "learning_rate": 0.001
  },
  {
    "episode": 11678,
    "reward": 91.74419,
    "length": 60,
    "time": 170365.222749,
    "actor_loss": -65.25430297851562,
    "critic_loss": 17.34079933166504,
    "ent_coef": 0.07383230328559875,
    "learning_rate": 0.001
  },
  {
    "episode": 11679,
    "reward": 91.178475,
    "length": 61,
    "time": 170377.773001,
    "actor_loss": -61.96330642700195,
    "critic_loss": 66.55526733398438,
    "ent_coef": 0.07358507812023163,
    "learning_rate": 0.001
  },
  {
    "episode": 11680,
    "reward": 91.008849,
    "length": 62,
    "time": 170388.895462,
    "actor_loss": -66.70491027832031,
    "critic_loss": 11.640142440795898,
    "ent_coef": 0.07391959428787231,
    "learning_rate": 0.001
  },
  {
    "episode": 11681,
    "reward": 90.870687,
    "length": 62,
    "time": 170400.243695,
    "actor_loss": -63.81175994873047,
    "critic_loss": 4.0066657066345215,
    "ent_coef": 0.07384418696165085,
    "learning_rate": 0.001
  },
  {
    "episode": 11682,
    "reward": 89.217645,
    "length": 67,
    "time": 170412.023507,
    "actor_loss": -67.99003601074219,
    "critic_loss": 81.30833435058594,
    "ent_coef": 0.07115273922681808,
    "learning_rate": 0.001
  },
  {
    "episode": 11683,
    "reward": 89.930112,
    "length": 64,
    "time": 170424.937899,
    "actor_loss": -67.08389282226562,
    "critic_loss": 4.139681816101074,
    "ent_coef": 0.06935033202171326,
    "learning_rate": 0.001
  },
  {
    "episode": 11684,
    "reward": 89.558788,
    "length": 65,
    "time": 170436.290315,
    "actor_loss": -68.76634216308594,
    "critic_loss": 9.753140449523926,
    "ent_coef": 0.06964533776044846,
    "learning_rate": 0.001
  },
  {
    "episode": 11685,
    "reward": 90.923963,
    "length": 62,
    "time": 170447.171701,
    "actor_loss": -71.66368103027344,
    "critic_loss": 6.196747779846191,
    "ent_coef": 0.07004188746213913,
    "learning_rate": 0.001
  },
  {
    "episode": 11686,
    "reward": 91.245934,
    "length": 60,
    "time": 170458.050026,
    "actor_loss": -66.93038177490234,
    "critic_loss": 7.114006042480469,
    "ent_coef": 0.07152865827083588,
    "learning_rate": 0.001
  },
  {
    "episode": 11687,
    "reward": 92.177689,
    "length": 59,
    "time": 170469.088102,
    "actor_loss": -66.39144897460938,
    "critic_loss": 6.313172817230225,
    "ent_coef": 0.0723164975643158,
    "learning_rate": 0.001
  },
  {
    "episode": 11688,
    "reward": 89.054957,
    "length": 65,
    "time": 170481.268202,
    "actor_loss": -69.171875,
    "critic_loss": 4.370572090148926,
    "ent_coef": 0.07017974555492401,
    "learning_rate": 0.001
  },
  {
    "episode": 11689,
    "reward": 89.344692,
    "length": 64,
    "time": 170493.12929,
    "actor_loss": -69.24020385742188,
    "critic_loss": 5.33247184753418,
    "ent_coef": 0.06765242666006088,
    "learning_rate": 0.001
  },
  {
    "episode": 11690,
    "reward": 88.156986,
    "length": 66,
    "time": 170506.270269,
    "actor_loss": -68.32542419433594,
    "critic_loss": 4.130241394042969,
    "ent_coef": 0.06328611075878143,
    "learning_rate": 0.001
  },
  {
    "episode": 11691,
    "reward": 85.889694,
    "length": 71,
    "time": 170518.605779,
    "actor_loss": -68.37249755859375,
    "critic_loss": 11.694616317749023,
    "ent_coef": 0.05938570946455002,
    "learning_rate": 0.001
  },
  {
    "episode": 11692,
    "reward": 90.664213,
    "length": 62,
    "time": 170529.736959,
    "actor_loss": -66.49427795410156,
    "critic_loss": 3.4032702445983887,
    "ent_coef": 0.0579923540353775,
    "learning_rate": 0.001
  },
  {
    "episode": 11693,
    "reward": 89.902396,
    "length": 64,
    "time": 170542.797726,
    "actor_loss": -63.87751388549805,
    "critic_loss": 5.758749485015869,
    "ent_coef": 0.05560627952218056,
    "learning_rate": 0.001
  },
  {
    "episode": 11694,
    "reward": 87.491931,
    "length": 69,
    "time": 170558.444096,
    "actor_loss": -67.29268646240234,
    "critic_loss": 16.522546768188477,
    "ent_coef": 0.05408220365643501,
    "learning_rate": 0.001
  },
  {
    "episode": 11695,
    "reward": 91.443959,
    "length": 61,
    "time": 170569.189227,
    "actor_loss": -62.5961799621582,
    "critic_loss": 2.639920711517334,
    "ent_coef": 0.05606706067919731,
    "learning_rate": 0.001
  },
  {
    "episode": 11696,
    "reward": 91.404478,
    "length": 61,
    "time": 170583.012132,
    "actor_loss": -69.67986297607422,
    "critic_loss": 4.6659746170043945,
    "ent_coef": 0.05740048736333847,
    "learning_rate": 0.001
  },
  {
    "episode": 11697,
    "reward": 90.476706,
    "length": 62,
    "time": 170593.967707,
    "actor_loss": -64.87284851074219,
    "critic_loss": 5.391546726226807,
    "ent_coef": 0.060366854071617126,
    "learning_rate": 0.001
  },
  {
    "episode": 11698,
    "reward": 89.361057,
    "length": 66,
    "time": 170607.205312,
    "actor_loss": -66.09144592285156,
    "critic_loss": 3.4383087158203125,
    "ent_coef": 0.0597345270216465,
    "learning_rate": 0.001
  },
  {
    "episode": 11699,
    "reward": 87.801346,
    "length": 69,
    "time": 170619.100241,
    "actor_loss": -64.9709701538086,
    "critic_loss": 8.563070297241211,
    "ent_coef": 0.05705788731575012,
    "learning_rate": 0.001
  },
  {
    "episode": 11700,
    "reward": 90.225693,
    "length": 63,
    "time": 170630.162259,
    "actor_loss": -78.38703155517578,
    "critic_loss": 28.14369773864746,
    "ent_coef": 0.05586813762784004,
    "learning_rate": 0.001
  },
  {
    "episode": 11701,
    "reward": 92.197632,
    "length": 59,
    "time": 170641.488089,
    "actor_loss": -70.6769027709961,
    "critic_loss": 3.72739315032959,
    "ent_coef": 0.0565919429063797,
    "learning_rate": 0.001
  },
  {
    "episode": 11702,
    "reward": 89.862901,
    "length": 64,
    "time": 170654.97046,
    "actor_loss": -66.54373931884766,
    "critic_loss": 31.331222534179688,
    "ent_coef": 0.05674890801310539,
    "learning_rate": 0.001
  },
  {
    "episode": 11703,
    "reward": 91.032063,
    "length": 62,
    "time": 170666.8697,
    "actor_loss": -67.1068115234375,
    "critic_loss": 2.350081443786621,
    "ent_coef": 0.05917892977595329,
    "learning_rate": 0.001
  },
  {
    "episode": 11704,
    "reward": 89.672732,
    "length": 65,
    "time": 170678.322518,
    "actor_loss": -64.34950256347656,
    "critic_loss": 12.976103782653809,
    "ent_coef": 0.059724029153585434,
    "learning_rate": 0.001
  },
  {
    "episode": 11705,
    "reward": 90.891112,
    "length": 63,
    "time": 170692.751126,
    "actor_loss": -68.52926635742188,
    "critic_loss": 3.5052268505096436,
    "ent_coef": 0.06172800809144974,
    "learning_rate": 0.001
  },
  {
    "episode": 11706,
    "reward": 90.716657,
    "length": 62,
    "time": 170705.955746,
    "actor_loss": -72.87307739257812,
    "critic_loss": 79.03611755371094,
    "ent_coef": 0.06176465004682541,
    "learning_rate": 0.001
  },
  {
    "episode": 11707,
    "reward": 90.309148,
    "length": 63,
    "time": 170717.458979,
    "actor_loss": -64.83977508544922,
    "critic_loss": 4.802456378936768,
    "ent_coef": 0.06581272929906845,
    "learning_rate": 0.001
  },
  {
    "episode": 11708,
    "reward": 91.636532,
    "length": 61,
    "time": 170731.324848,
    "actor_loss": -68.11846923828125,
    "critic_loss": 4.843406677246094,
    "ent_coef": 0.07208239287137985,
    "learning_rate": 0.001
  },
  {
    "episode": 11709,
    "reward": 90.887792,
    "length": 62,
    "time": 170746.615205,
    "actor_loss": -66.2386703491211,
    "critic_loss": 2.851512908935547,
    "ent_coef": 0.0710773915052414,
    "learning_rate": 0.001
  },
  {
    "episode": 11710,
    "reward": 88.058001,
    "length": 66,
    "time": 170759.034841,
    "actor_loss": -63.5782470703125,
    "critic_loss": 9.039474487304688,
    "ent_coef": 0.06915421038866043,
    "learning_rate": 0.001
  },
  {
    "episode": 11711,
    "reward": 88.078144,
    "length": 67,
    "time": 170771.324152,
    "actor_loss": -67.4473648071289,
    "critic_loss": 35.65715789794922,
    "ent_coef": 0.06884697079658508,
    "learning_rate": 0.001
  },
  {
    "episode": 11712,
    "reward": 88.917729,
    "length": 64,
    "time": 170785.094124,
    "actor_loss": -71.37030029296875,
    "critic_loss": 78.87928009033203,
    "ent_coef": 0.06839673221111298,
    "learning_rate": 0.001
  },
  {
    "episode": 11713,
    "reward": 90.500637,
    "length": 62,
    "time": 170800.550223,
    "actor_loss": -66.12757873535156,
    "critic_loss": 3.2224769592285156,
    "ent_coef": 0.06787948310375214,
    "learning_rate": 0.001
  },
  {
    "episode": 11714,
    "reward": 88.646774,
    "length": 67,
    "time": 170814.924959,
    "actor_loss": -68.84559631347656,
    "critic_loss": 315.777099609375,
    "ent_coef": 0.0637691393494606,
    "learning_rate": 0.001
  },
  {
    "episode": 11715,
    "reward": 89.427132,
    "length": 65,
    "time": 170826.508432,
    "actor_loss": -67.66767883300781,
    "critic_loss": 7.722847938537598,
    "ent_coef": 0.06259448081254959,
    "learning_rate": 0.001
  },
  {
    "episode": 11716,
    "reward": 91.092334,
    "length": 61,
    "time": 170837.772724,
    "actor_loss": -67.08193969726562,
    "critic_loss": 3.176800489425659,
    "ent_coef": 0.0633828267455101,
    "learning_rate": 0.001
  },
  {
    "episode": 11717,
    "reward": 91.875998,
    "length": 59,
    "time": 170849.078293,
    "actor_loss": -63.15037536621094,
    "critic_loss": 8.766433715820312,
    "ent_coef": 0.06475856155157089,
    "learning_rate": 0.001
  },
  {
    "episode": 11718,
    "reward": 91.090751,
    "length": 60,
    "time": 170861.033481,
    "actor_loss": -66.74827575683594,
    "critic_loss": 4.279190540313721,
    "ent_coef": 0.06677109003067017,
    "learning_rate": 0.001
  },
  {
    "episode": 11719,
    "reward": 88.6004,
    "length": 67,
    "time": 170874.091386,
    "actor_loss": -67.41580200195312,
    "critic_loss": 3.1217880249023438,
    "ent_coef": 0.06527762860059738,
    "learning_rate": 0.001
  },
  {
    "episode": 11720,
    "reward": 89.718938,
    "length": 65,
    "time": 170886.971161,
    "actor_loss": -66.4555435180664,
    "critic_loss": 4.582075119018555,
    "ent_coef": 0.06482784450054169,
    "learning_rate": 0.001
  },
  {
    "episode": 11721,
    "reward": 91.387711,
    "length": 61,
    "time": 170898.389565,
    "actor_loss": -69.12771606445312,
    "critic_loss": 6.127821922302246,
    "ent_coef": 0.06664028018712997,
    "learning_rate": 0.001
  },
  {
    "episode": 11722,
    "reward": 87.810556,
    "length": 68,
    "time": 170912.653093,
    "actor_loss": -61.9280891418457,
    "critic_loss": 4.842763900756836,
    "ent_coef": 0.06493369489908218,
    "learning_rate": 0.001
  },
  {
    "episode": 11723,
    "reward": 88.654184,
    "length": 67,
    "time": 170927.24813,
    "actor_loss": -65.46160888671875,
    "critic_loss": 3.5303900241851807,
    "ent_coef": 0.06120489537715912,
    "learning_rate": 0.001
  },
  {
    "episode": 11724,
    "reward": 88.87254,
    "length": 66,
    "time": 170939.125531,
    "actor_loss": -75.55265045166016,
    "critic_loss": 25.694442749023438,
    "ent_coef": 0.0601080022752285,
    "learning_rate": 0.001
  },
  {
    "episode": 11725,
    "reward": 89.400461,
    "length": 65,
    "time": 170952.185054,
    "actor_loss": -70.38056945800781,
    "critic_loss": 3.8703999519348145,
    "ent_coef": 0.06053592637181282,
    "learning_rate": 0.001
  },
  {
    "episode": 11726,
    "reward": 82.520859,
    "length": 76,
    "time": 170964.917268,
    "actor_loss": -67.45526123046875,
    "critic_loss": 152.8412322998047,
    "ent_coef": 0.06481196731328964,
    "learning_rate": 0.001
  },
  {
    "episode": 11727,
    "reward": 88.7225,
    "length": 65,
    "time": 170978.039561,
    "actor_loss": -67.1996841430664,
    "critic_loss": 11.769231796264648,
    "ent_coef": 0.06461235135793686,
    "learning_rate": 0.001
  },
  {
    "episode": 11728,
    "reward": 86.227925,
    "length": 70,
    "time": 170993.648851,
    "actor_loss": -66.0425033569336,
    "critic_loss": 2.6412196159362793,
    "ent_coef": 0.06000032275915146,
    "learning_rate": 0.001
  },
  {
    "episode": 11729,
    "reward": 88.846314,
    "length": 65,
    "time": 171005.317118,
    "actor_loss": -69.2916030883789,
    "critic_loss": 6.754281044006348,
    "ent_coef": 0.05839322507381439,
    "learning_rate": 0.001
  },
  {
    "episode": 11730,
    "reward": 85.399918,
    "length": 71,
    "time": 171017.794457,
    "actor_loss": -73.79444122314453,
    "critic_loss": 2.767608404159546,
    "ent_coef": 0.055200088769197464,
    "learning_rate": 0.001
  },
  {
    "episode": 11731,
    "reward": 90.617663,
    "length": 62,
    "time": 171029.191808,
    "actor_loss": -67.76123046875,
    "critic_loss": 17.445531845092773,
    "ent_coef": 0.05835028737783432,
    "learning_rate": 0.001
  },
  {
    "episode": 11732,
    "reward": 89.73943,
    "length": 64,
    "time": 171041.534539,
    "actor_loss": -70.69898223876953,
    "critic_loss": 1.9441481828689575,
    "ent_coef": 0.05883529782295227,
    "learning_rate": 0.001
  },
  {
    "episode": 11733,
    "reward": 85.959998,
    "length": 71,
    "time": 171055.01192,
    "actor_loss": -64.33040618896484,
    "critic_loss": 2.810096263885498,
    "ent_coef": 0.0547143816947937,
    "learning_rate": 0.001
  },
  {
    "episode": 11734,
    "reward": 87.151983,
    "length": 69,
    "time": 171068.238228,
    "actor_loss": -63.071720123291016,
    "critic_loss": 33.60171890258789,
    "ent_coef": 0.0513109527528286,
    "learning_rate": 0.001
  },
  {
    "episode": 11735,
    "reward": 77.418481,
    "length": 92,
    "time": 171084.304322,
    "actor_loss": -63.984554290771484,
    "critic_loss": 10.476123809814453,
    "ent_coef": 0.048242922872304916,
    "learning_rate": 0.001
  },
  {
    "episode": 11736,
    "reward": 83.770481,
    "length": 77,
    "time": 171097.338402,
    "actor_loss": -71.46395874023438,
    "critic_loss": 5.955348014831543,
    "ent_coef": 0.04894254356622696,
    "learning_rate": 0.001
  },
  {
    "episode": 11737,
    "reward": 90.541507,
    "length": 62,
    "time": 171111.887166,
    "actor_loss": -68.51849365234375,
    "critic_loss": 5.144620895385742,
    "ent_coef": 0.05275961756706238,
    "learning_rate": 0.001
  },
  {
    "episode": 11738,
    "reward": 90.815175,
    "length": 62,
    "time": 171123.917787,
    "actor_loss": -66.9259033203125,
    "critic_loss": 8.067750930786133,
    "ent_coef": 0.05170292407274246,
    "learning_rate": 0.001
  },
  {
    "episode": 11739,
    "reward": 88.43599,
    "length": 64,
    "time": 171140.722054,
    "actor_loss": -67.0289306640625,
    "critic_loss": 4.673861980438232,
    "ent_coef": 0.05005022510886192,
    "learning_rate": 0.001
  },
  {
    "episode": 11740,
    "reward": 85.993175,
    "length": 72,
    "time": 171154.20597,
    "actor_loss": -68.18426513671875,
    "critic_loss": 9.77521800994873,
    "ent_coef": 0.053682804107666016,
    "learning_rate": 0.001
  },
  {
    "episode": 11741,
    "reward": 87.027343,
    "length": 71,
    "time": 171166.967686,
    "actor_loss": -66.72413635253906,
    "critic_loss": 3.6766552925109863,
    "ent_coef": 0.05436411499977112,
    "learning_rate": 0.001
  },
  {
    "episode": 11742,
    "reward": 83.79557,
    "length": 76,
    "time": 171182.117397,
    "actor_loss": -69.72921752929688,
    "critic_loss": 3.9527885913848877,
    "ent_coef": 0.05396679416298866,
    "learning_rate": 0.001
  },
  {
    "episode": 11743,
    "reward": 88.91653,
    "length": 65,
    "time": 171193.491183,
    "actor_loss": -70.02687072753906,
    "critic_loss": 2.994938373565674,
    "ent_coef": 0.055464815348386765,
    "learning_rate": 0.001
  },
  {
    "episode": 11744,
    "reward": 87.198364,
    "length": 68,
    "time": 171208.173426,
    "actor_loss": -67.56084442138672,
    "critic_loss": 6.415115833282471,
    "ent_coef": 0.05495856702327728,
    "learning_rate": 0.001
  },
  {
    "episode": 11745,
    "reward": 84.405128,
    "length": 72,
    "time": 171224.994326,
    "actor_loss": -68.05406188964844,
    "critic_loss": 3.6481752395629883,
    "ent_coef": 0.05428173020482063,
    "learning_rate": 0.001
  },
  {
    "episode": 11746,
    "reward": 88.971747,
    "length": 72,
    "time": 171239.803207,
    "actor_loss": -65.07418823242188,
    "critic_loss": 2.971050262451172,
    "ent_coef": 0.057899851351976395,
    "learning_rate": 0.001
  },
  {
    "episode": 11747,
    "reward": 85.052015,
    "length": 73,
    "time": 171252.585901,
    "actor_loss": -70.7906265258789,
    "critic_loss": 36.64771270751953,
    "ent_coef": 0.056766241788864136,
    "learning_rate": 0.001
  },
  {
    "episode": 11748,
    "reward": 87.279927,
    "length": 67,
    "time": 171266.307267,
    "actor_loss": -68.52352142333984,
    "critic_loss": 25.661287307739258,
    "ent_coef": 0.05820083245635033,
    "learning_rate": 0.001
  },
  {
    "episode": 11749,
    "reward": 90.086734,
    "length": 62,
    "time": 171278.141849,
    "actor_loss": -66.98998260498047,
    "critic_loss": 5.711841583251953,
    "ent_coef": 0.06087518110871315,
    "learning_rate": 0.001
  },
  {
    "episode": 11750,
    "reward": 88.672277,
    "length": 69,
    "time": 171290.77641,
    "actor_loss": -63.72895050048828,
    "critic_loss": 4.929043292999268,
    "ent_coef": 0.06205503270030022,
    "learning_rate": 0.001
  },
  {
    "episode": 11751,
    "reward": 87.987453,
    "length": 67,
    "time": 171305.685079,
    "actor_loss": -64.85359191894531,
    "critic_loss": 4.657041549682617,
    "ent_coef": 0.058328479528427124,
    "learning_rate": 0.001
  },
  {
    "episode": 11752,
    "reward": 85.30229,
    "length": 73,
    "time": 171325.412446,
    "actor_loss": -68.583740234375,
    "critic_loss": 5.438797950744629,
    "ent_coef": 0.05791912600398064,
    "learning_rate": 0.001
  },
  {
    "episode": 11753,
    "reward": 88.92994,
    "length": 65,
    "time": 171338.324195,
    "actor_loss": -67.84088134765625,
    "critic_loss": 15.053472518920898,
    "ent_coef": 0.05662654712796211,
    "learning_rate": 0.001
  },
  {
    "episode": 11754,
    "reward": 74.448928,
    "length": 95,
    "time": 171353.700459,
    "actor_loss": -74.09089660644531,
    "critic_loss": 3.7740018367767334,
    "ent_coef": 0.055364008992910385,
    "learning_rate": 0.001
  },
  {
    "episode": 11755,
    "reward": 88.724747,
    "length": 67,
    "time": 171366.584934,
    "actor_loss": -67.02659606933594,
    "critic_loss": 10.670822143554688,
    "ent_coef": 0.05645168945193291,
    "learning_rate": 0.001
  },
  {
    "episode": 11756,
    "reward": 89.02555,
    "length": 65,
    "time": 171378.309553,
    "actor_loss": -67.05105590820312,
    "critic_loss": 12.74322509765625,
    "ent_coef": 0.05575491115450859,
    "learning_rate": 0.001
  },
  {
    "episode": 11757,
    "reward": 86.875244,
    "length": 69,
    "time": 171390.405407,
    "actor_loss": -68.95999908447266,
    "critic_loss": 4.537951469421387,
    "ent_coef": 0.05483468249440193,
    "learning_rate": 0.001
  },
  {
    "episode": 11758,
    "reward": 85.731896,
    "length": 70,
    "time": 171403.62438,
    "actor_loss": -64.76609802246094,
    "critic_loss": 13.433294296264648,
    "ent_coef": 0.0546615906059742,
    "learning_rate": 0.001
  },
  {
    "episode": 11759,
    "reward": 81.104329,
    "length": 81,
    "time": 171417.37371,
    "actor_loss": -67.24994659423828,
    "critic_loss": 3.461165428161621,
    "ent_coef": 0.05107640102505684,
    "learning_rate": 0.001
  },
  {
    "episode": 11760,
    "reward": 82.507268,
    "length": 77,
    "time": 171431.934319,
    "actor_loss": -74.30592346191406,
    "critic_loss": 2.5052428245544434,
    "ent_coef": 0.050058577209711075,
    "learning_rate": 0.001
  },
  {
    "episode": 11761,
    "reward": 67.735129,
    "length": 108,
    "time": 171452.052979,
    "actor_loss": -70.34452819824219,
    "critic_loss": 42.32264709472656,
    "ent_coef": 0.04931078106164932,
    "learning_rate": 0.001
  },
  {
    "episode": 11762,
    "reward": 92.779327,
    "length": 57,
    "time": 171462.765424,
    "actor_loss": -68.27839660644531,
    "critic_loss": 2.9339966773986816,
    "ent_coef": 0.05283346772193909,
    "learning_rate": 0.001
  },
  {
    "episode": 11763,
    "reward": 90.61899,
    "length": 62,
    "time": 171475.580709,
    "actor_loss": -68.05211639404297,
    "critic_loss": 32.98219680786133,
    "ent_coef": 0.05469883605837822,
    "learning_rate": 0.001
  },
  {
    "episode": 11764,
    "reward": 91.144527,
    "length": 62,
    "time": 171489.418413,
    "actor_loss": -69.91841888427734,
    "critic_loss": 9.556270599365234,
    "ent_coef": 0.05571814253926277,
    "learning_rate": 0.001
  },
  {
    "episode": 11765,
    "reward": 88.783438,
    "length": 66,
    "time": 171502.160306,
    "actor_loss": -65.12676239013672,
    "critic_loss": 4.949132919311523,
    "ent_coef": 0.05692277476191521,
    "learning_rate": 0.001
  },
  {
    "episode": 11766,
    "reward": 86.616494,
    "length": 69,
    "time": 171515.448483,
    "actor_loss": -71.2059555053711,
    "critic_loss": 3.603419780731201,
    "ent_coef": 0.056274883449077606,
    "learning_rate": 0.001
  },
  {
    "episode": 11767,
    "reward": 84.456268,
    "length": 72,
    "time": 171527.79155,
    "actor_loss": -68.04786682128906,
    "critic_loss": 3.077258586883545,
    "ent_coef": 0.05371122062206268,
    "learning_rate": 0.001
  },
  {
    "episode": 11768,
    "reward": 81.530525,
    "length": 79,
    "time": 171544.032236,
    "actor_loss": -70.46971130371094,
    "critic_loss": 4.391368865966797,
    "ent_coef": 0.051964495331048965,
    "learning_rate": 0.001
  },
  {
    "episode": 11769,
    "reward": 79.650229,
    "length": 82,
    "time": 171559.241543,
    "actor_loss": -69.24325561523438,
    "critic_loss": 3.5367884635925293,
    "ent_coef": 0.05005313456058502,
    "learning_rate": 0.001
  },
  {
    "episode": 11770,
    "reward": 79.115601,
    "length": 81,
    "time": 171573.039459,
    "actor_loss": -73.94786834716797,
    "critic_loss": 14.844935417175293,
    "ent_coef": 0.048916518688201904,
    "learning_rate": 0.001
  },
  {
    "episode": 11771,
    "reward": 86.689259,
    "length": 68,
    "time": 171587.866232,
    "actor_loss": -70.5694580078125,
    "critic_loss": 7.4360175132751465,
    "ent_coef": 0.051015354692935944,
    "learning_rate": 0.001
  },
  {
    "episode": 11772,
    "reward": 85.765563,
    "length": 70,
    "time": 171600.150592,
    "actor_loss": -65.8902587890625,
    "critic_loss": 26.834997177124023,
    "ent_coef": 0.051241014152765274,
    "learning_rate": 0.001
  },
  {
    "episode": 11773,
    "reward": 91.189337,
    "length": 61,
    "time": 171613.685474,
    "actor_loss": -67.6828384399414,
    "critic_loss": 4.245718955993652,
    "ent_coef": 0.052237387746572495,
    "learning_rate": 0.001
  },
  {
    "episode": 11774,
    "reward": 85.282636,
    "length": 72,
    "time": 171626.813789,
    "actor_loss": -69.48099517822266,
    "critic_loss": 8.060403823852539,
    "ent_coef": 0.05168332904577255,
    "learning_rate": 0.001
  },
  {
    "episode": 11775,
    "reward": 89.527145,
    "length": 62,
    "time": 171640.745551,
    "actor_loss": -72.72425842285156,
    "critic_loss": 4.735597610473633,
    "ent_coef": 0.053482793271541595,
    "learning_rate": 0.001
  },
  {
    "episode": 11776,
    "reward": 81.708129,
    "length": 76,
    "time": 171653.813019,
    "actor_loss": -74.01522064208984,
    "critic_loss": 22.322986602783203,
    "ent_coef": 0.055722858756780624,
    "learning_rate": 0.001
  },
  {
    "episode": 11777,
    "reward": 85.025655,
    "length": 71,
    "time": 171667.330404,
    "actor_loss": -68.49253845214844,
    "critic_loss": 13.159282684326172,
    "ent_coef": 0.055939000099897385,
    "learning_rate": 0.001
  },
  {
    "episode": 11778,
    "reward": 80.912951,
    "length": 80,
    "time": 171680.771812,
    "actor_loss": -69.37623596191406,
    "critic_loss": 5.187774658203125,
    "ent_coef": 0.05504244938492775,
    "learning_rate": 0.001
  },
  {
    "episode": 11779,
    "reward": 83.355209,
    "length": 73,
    "time": 171696.146758,
    "actor_loss": -66.0535888671875,
    "critic_loss": 3.3624582290649414,
    "ent_coef": 0.05648467317223549,
    "learning_rate": 0.001
  },
  {
    "episode": 11780,
    "reward": 89.288748,
    "length": 63,
    "time": 171707.531467,
    "actor_loss": -67.33137512207031,
    "critic_loss": 5.131472587585449,
    "ent_coef": 0.05785202234983444,
    "learning_rate": 0.001
  },
  {
    "episode": 11781,
    "reward": 90.595363,
    "length": 62,
    "time": 171721.077544,
    "actor_loss": -67.94564819335938,
    "critic_loss": 7.9651970863342285,
    "ent_coef": 0.06002061441540718,
    "learning_rate": 0.001
  },
  {
    "episode": 11782,
    "reward": 89.25859,
    "length": 64,
    "time": 171732.596334,
    "actor_loss": -66.2552490234375,
    "critic_loss": 8.769231796264648,
    "ent_coef": 0.06265883892774582,
    "learning_rate": 0.001
  },
  {
    "episode": 11783,
    "reward": 83.820912,
    "length": 72,
    "time": 171747.303668,
    "actor_loss": -66.89106750488281,
    "critic_loss": 12.000883102416992,
    "ent_coef": 0.06173064559698105,
    "learning_rate": 0.001
  },
  {
    "episode": 11784,
    "reward": 91.948489,
    "length": 59,
    "time": 171758.006135,
    "actor_loss": -71.44573974609375,
    "critic_loss": 89.65154266357422,
    "ent_coef": 0.06277255713939667,
    "learning_rate": 0.001
  },
  {
    "episode": 11785,
    "reward": 89.962317,
    "length": 62,
    "time": 171772.713804,
    "actor_loss": -69.20565795898438,
    "critic_loss": 27.300933837890625,
    "ent_coef": 0.06314213573932648,
    "learning_rate": 0.001
  },
  {
    "episode": 11786,
    "reward": 84.349659,
    "length": 73,
    "time": 171789.029699,
    "actor_loss": -71.32186889648438,
    "critic_loss": 7.322422504425049,
    "ent_coef": 0.06221044436097145,
    "learning_rate": 0.001
  },
  {
    "episode": 11787,
    "reward": 88.638622,
    "length": 67,
    "time": 171801.830912,
    "actor_loss": -73.1556625366211,
    "critic_loss": 61.533592224121094,
    "ent_coef": 0.059097155928611755,
    "learning_rate": 0.001
  },
  {
    "episode": 11788,
    "reward": 83.536345,
    "length": 74,
    "time": 171814.746749,
    "actor_loss": -64.68206024169922,
    "critic_loss": 5.185332775115967,
    "ent_coef": 0.056052789092063904,
    "learning_rate": 0.001
  },
  {
    "episode": 11789,
    "reward": 85.056422,
    "length": 71,
    "time": 171827.411133,
    "actor_loss": -68.72853088378906,
    "critic_loss": 3.7632546424865723,
    "ent_coef": 0.05461689084768295,
    "learning_rate": 0.001
  },
  {
    "episode": 11790,
    "reward": 90.67526,
    "length": 62,
    "time": 171839.241902,
    "actor_loss": -71.38233947753906,
    "critic_loss": 2.668172836303711,
    "ent_coef": 0.05626295879483223,
    "learning_rate": 0.001
  },
  {
    "episode": 11791,
    "reward": 89.11716,
    "length": 63,
    "time": 171852.696398,
    "actor_loss": -67.7730712890625,
    "critic_loss": 5.57941198348999,
    "ent_coef": 0.05977202206850052,
    "learning_rate": 0.001
  },
  {
    "episode": 11792,
    "reward": 92.064284,
    "length": 59,
    "time": 171864.372738,
    "actor_loss": -67.17286682128906,
    "critic_loss": 4.523984909057617,
    "ent_coef": 0.06306140869855881,
    "learning_rate": 0.001
  },
  {
    "episode": 11793,
    "reward": 90.414363,
    "length": 62,
    "time": 171875.522207,
    "actor_loss": -67.11906433105469,
    "critic_loss": 7.1371073722839355,
    "ent_coef": 0.06352559477090836,
    "learning_rate": 0.001
  },
  {
    "episode": 11794,
    "reward": 88.944619,
    "length": 64,
    "time": 171888.55766,
    "actor_loss": -69.66641235351562,
    "critic_loss": 10.948698043823242,
    "ent_coef": 0.06207418069243431,
    "learning_rate": 0.001
  },
  {
    "episode": 11795,
    "reward": 87.892054,
    "length": 66,
    "time": 171900.896646,
    "actor_loss": -69.39244842529297,
    "critic_loss": 6.202060699462891,
    "ent_coef": 0.0606515146791935,
    "learning_rate": 0.001
  },
  {
    "episode": 11796,
    "reward": 90.688169,
    "length": 62,
    "time": 171912.437177,
    "actor_loss": -66.3505630493164,
    "critic_loss": 4.0508575439453125,
    "ent_coef": 0.06357108056545258,
    "learning_rate": 0.001
  },
  {
    "episode": 11797,
    "reward": 91.409407,
    "length": 60,
    "time": 171924.265092,
    "actor_loss": -73.7212905883789,
    "critic_loss": 9.386432647705078,
    "ent_coef": 0.06596625596284866,
    "learning_rate": 0.001
  },
  {
    "episode": 11798,
    "reward": 84.320412,
    "length": 73,
    "time": 171945.030224,
    "actor_loss": -67.1987075805664,
    "critic_loss": 11.973291397094727,
    "ent_coef": 0.06325549632310867,
    "learning_rate": 0.001
  },
  {
    "episode": 11799,
    "reward": 84.950496,
    "length": 70,
    "time": 171959.871555,
    "actor_loss": -72.69635009765625,
    "critic_loss": 5.581778526306152,
    "ent_coef": 0.06373748928308487,
    "learning_rate": 0.001
  },
  {
    "episode": 11800,
    "reward": 87.370209,
    "length": 68,
    "time": 171974.551091,
    "actor_loss": -68.58549499511719,
    "critic_loss": 4.622110366821289,
    "ent_coef": 0.060370467603206635,
    "learning_rate": 0.001
  },
  {
    "episode": 11801,
    "reward": 89.334133,
    "length": 64,
    "time": 171987.693426,
    "actor_loss": -70.16250610351562,
    "critic_loss": 5.1429877281188965,
    "ent_coef": 0.05854102596640587,
    "learning_rate": 0.001
  },
  {
    "episode": 11802,
    "reward": 91.115024,
    "length": 61,
    "time": 172000.572176,
    "actor_loss": -61.99126434326172,
    "critic_loss": 39.073883056640625,
    "ent_coef": 0.05876240134239197,
    "learning_rate": 0.001
  },
  {
    "episode": 11803,
    "reward": 86.843067,
    "length": 71,
    "time": 172013.800064,
    "actor_loss": -64.94087219238281,
    "critic_loss": 4.566165924072266,
    "ent_coef": 0.056023892015218735,
    "learning_rate": 0.001
  },
  {
    "episode": 11804,
    "reward": 90.034158,
    "length": 67,
    "time": 172031.515135,
    "actor_loss": -66.106201171875,
    "critic_loss": 4.649599075317383,
    "ent_coef": 0.05909733846783638,
    "learning_rate": 0.001
  },
  {
    "episode": 11805,
    "reward": 90.861317,
    "length": 63,
    "time": 172044.06723,
    "actor_loss": -72.63717651367188,
    "critic_loss": 3.02846622467041,
    "ent_coef": 0.06011216714978218,
    "learning_rate": 0.001
  },
  {
    "episode": 11806,
    "reward": 86.110497,
    "length": 75,
    "time": 172058.151429,
    "actor_loss": -69.00208282470703,
    "critic_loss": 8.213845252990723,
    "ent_coef": 0.05891924351453781,
    "learning_rate": 0.001
  },
  {
    "episode": 11807,
    "reward": 0.55878,
    "length": 182,
    "time": 172088.09871,
    "actor_loss": -64.4538345336914,
    "critic_loss": 13.759308815002441,
    "ent_coef": 0.06155120208859444,
    "learning_rate": 0.001
  },
  {
    "episode": 11808,
    "reward": 89.995832,
    "length": 67,
    "time": 172103.401972,
    "actor_loss": -67.87938690185547,
    "critic_loss": 5.195328712463379,
    "ent_coef": 0.06156346946954727,
    "learning_rate": 0.001
  },
  {
    "episode": 11809,
    "reward": 88.267105,
    "length": 72,
    "time": 172117.383274,
    "actor_loss": -66.673828125,
    "critic_loss": 2.9034509658813477,
    "ent_coef": 0.05940988287329674,
    "learning_rate": 0.001
  },
  {
    "episode": 11810,
    "reward": 87.830131,
    "length": 68,
    "time": 172130.479671,
    "actor_loss": -65.84616088867188,
    "critic_loss": 15.000110626220703,
    "ent_coef": 0.05837390199303627,
    "learning_rate": 0.001
  },
  {
    "episode": 11811,
    "reward": 85.838196,
    "length": 76,
    "time": 172146.963576,
    "actor_loss": -71.09568786621094,
    "critic_loss": 3.628669261932373,
    "ent_coef": 0.05697061866521835,
    "learning_rate": 0.001
  },
  {
    "episode": 11812,
    "reward": 91.489734,
    "length": 60,
    "time": 172158.681305,
    "actor_loss": -74.29022216796875,
    "critic_loss": 9.037453651428223,
    "ent_coef": 0.05656271055340767,
    "learning_rate": 0.001
  },
  {
    "episode": 11813,
    "reward": 89.837902,
    "length": 68,
    "time": 172170.625643,
    "actor_loss": -67.06233215332031,
    "critic_loss": 8.474554061889648,
    "ent_coef": 0.05850512161850929,
    "learning_rate": 0.001
  },
  {
    "episode": 11814,
    "reward": 89.928199,
    "length": 67,
    "time": 172183.553559,
    "actor_loss": -71.58692932128906,
    "critic_loss": 4.44003963470459,
    "ent_coef": 0.06039245054125786,
    "learning_rate": 0.001
  },
  {
    "episode": 11815,
    "reward": 91.08683,
    "length": 61,
    "time": 172195.641441,
    "actor_loss": -67.67781066894531,
    "critic_loss": 5.209385395050049,
    "ent_coef": 0.061538904905319214,
    "learning_rate": 0.001
  },
  {
    "episode": 11816,
    "reward": 90.290528,
    "length": 66,
    "time": 172207.275516,
    "actor_loss": -69.25700378417969,
    "critic_loss": 1.9911788702011108,
    "ent_coef": 0.06264220178127289,
    "learning_rate": 0.001
  },
  {
    "episode": 11817,
    "reward": 90.483476,
    "length": 62,
    "time": 172222.811123,
    "actor_loss": -64.08734130859375,
    "critic_loss": 7.591304302215576,
    "ent_coef": 0.06325490027666092,
    "learning_rate": 0.001
  },
  {
    "episode": 11818,
    "reward": 91.946151,
    "length": 60,
    "time": 172237.416459,
    "actor_loss": -70.65782165527344,
    "critic_loss": 4.748467445373535,
    "ent_coef": 0.06378199905157089,
    "learning_rate": 0.001
  },
  {
    "episode": 11819,
    "reward": 86.530813,
    "length": 69,
    "time": 172250.460862,
    "actor_loss": -71.15985107421875,
    "critic_loss": 2.9445157051086426,
    "ent_coef": 0.05910427123308182,
    "learning_rate": 0.001
  },
  {
    "episode": 11820,
    "reward": 88.94554,
    "length": 65,
    "time": 172262.327463,
    "actor_loss": -64.5900650024414,
    "critic_loss": 5.606778621673584,
    "ent_coef": 0.057524457573890686,
    "learning_rate": 0.001
  },
  {
    "episode": 11821,
    "reward": 88.072485,
    "length": 70,
    "time": 172278.227293,
    "actor_loss": -71.3712158203125,
    "critic_loss": 2.7105371952056885,
    "ent_coef": 0.05785409361124039,
    "learning_rate": 0.001
  },
  {
    "episode": 11822,
    "reward": 91.104518,
    "length": 61,
    "time": 172289.390551,
    "actor_loss": -66.72801208496094,
    "critic_loss": 3.707700729370117,
    "ent_coef": 0.0582856647670269,
    "learning_rate": 0.001
  },
  {
    "episode": 11823,
    "reward": 87.010073,
    "length": 76,
    "time": 172302.373765,
    "actor_loss": -66.85546875,
    "critic_loss": 3.4885482788085938,
    "ent_coef": 0.05664041265845299,
    "learning_rate": 0.001
  },
  {
    "episode": 11824,
    "reward": 89.676943,
    "length": 64,
    "time": 172316.066228,
    "actor_loss": -73.83783721923828,
    "critic_loss": 4.78416633605957,
    "ent_coef": 0.05426977202296257,
    "learning_rate": 0.001
  },
  {
    "episode": 11825,
    "reward": 88.519201,
    "length": 70,
    "time": 172328.140788,
    "actor_loss": -65.37628173828125,
    "critic_loss": 8.125819206237793,
    "ent_coef": 0.05391500145196915,
    "learning_rate": 0.001
  },
  {
    "episode": 11826,
    "reward": 90.317208,
    "length": 66,
    "time": 172340.076972,
    "actor_loss": -67.89168548583984,
    "critic_loss": 13.735780715942383,
    "ent_coef": 0.05724964290857315,
    "learning_rate": 0.001
  },
  {
    "episode": 11827,
    "reward": 89.621763,
    "length": 68,
    "time": 172352.042167,
    "actor_loss": -63.00777816772461,
    "critic_loss": 2.2617907524108887,
    "ent_coef": 0.05695074051618576,
    "learning_rate": 0.001
  },
  {
    "episode": 11828,
    "reward": 91.707888,
    "length": 60,
    "time": 172363.134241,
    "actor_loss": -73.45439147949219,
    "critic_loss": 5.906602382659912,
    "ent_coef": 0.058377910405397415,
    "learning_rate": 0.001
  },
  {
    "episode": 11829,
    "reward": 88.274542,
    "length": 72,
    "time": 172377.012232,
    "actor_loss": -71.73186492919922,
    "critic_loss": 20.03618621826172,
    "ent_coef": 0.05893838033080101,
    "learning_rate": 0.001
  },
  {
    "episode": 11830,
    "reward": 90.089784,
    "length": 68,
    "time": 172388.893455,
    "actor_loss": -70.41441345214844,
    "critic_loss": 3.154761791229248,
    "ent_coef": 0.0613875575363636,
    "learning_rate": 0.001
  },
  {
    "episode": 11831,
    "reward": 88.797676,
    "length": 72,
    "time": 172404.27012,
    "actor_loss": -62.78601837158203,
    "critic_loss": 3.8236660957336426,
    "ent_coef": 0.06255842000246048,
    "learning_rate": 0.001
  },
  {
    "episode": 11832,
    "reward": 90.200234,
    "length": 63,
    "time": 172415.493977,
    "actor_loss": -69.9272232055664,
    "critic_loss": 2.88352632522583,
    "ent_coef": 0.06343068927526474,
    "learning_rate": 0.001
  },
  {
    "episode": 11833,
    "reward": 87.659237,
    "length": 71,
    "time": 172430.897024,
    "actor_loss": -67.00568389892578,
    "critic_loss": 3.5240681171417236,
    "ent_coef": 0.0661737322807312,
    "learning_rate": 0.001
  },
  {
    "episode": 11834,
    "reward": 88.469577,
    "length": 71,
    "time": 172444.245947,
    "actor_loss": -74.96324920654297,
    "critic_loss": 4.940404891967773,
    "ent_coef": 0.06559783220291138,
    "learning_rate": 0.001
  },
  {
    "episode": 11835,
    "reward": 89.379323,
    "length": 69,
    "time": 172456.335908,
    "actor_loss": -69.97735595703125,
    "critic_loss": 4.455862998962402,
    "ent_coef": 0.06535463035106659,
    "learning_rate": 0.001
  },
  {
    "episode": 11836,
    "reward": 90.199386,
    "length": 62,
    "time": 172468.689862,
    "actor_loss": -74.45622253417969,
    "critic_loss": 41.75559997558594,
    "ent_coef": 0.06318832188844681,
    "learning_rate": 0.001
  },
  {
    "episode": 11837,
    "reward": 90.836062,
    "length": 62,
    "time": 172482.545259,
    "actor_loss": -70.7175064086914,
    "critic_loss": 36.953887939453125,
    "ent_coef": 0.060896724462509155,
    "learning_rate": 0.001
  },
  {
    "episode": 11838,
    "reward": 89.004937,
    "length": 70,
    "time": 172495.945521,
    "actor_loss": -67.57209777832031,
    "critic_loss": 7.921065330505371,
    "ent_coef": 0.05844888091087341,
    "learning_rate": 0.001
  },
  {
    "episode": 11839,
    "reward": 89.569224,
    "length": 64,
    "time": 172507.503962,
    "actor_loss": -70.36270904541016,
    "critic_loss": 9.40969467163086,
    "ent_coef": 0.05869099497795105,
    "learning_rate": 0.001
  },
  {
    "episode": 11840,
    "reward": 82.616074,
    "length": 73,
    "time": 172520.126324,
    "actor_loss": -66.60585021972656,
    "critic_loss": 17.89568328857422,
    "ent_coef": 0.05898749455809593,
    "learning_rate": 0.001
  },
  {
    "episode": 11841,
    "reward": 89.935766,
    "length": 63,
    "time": 172532.610607,
    "actor_loss": -67.73677825927734,
    "critic_loss": 11.411676406860352,
    "ent_coef": 0.057543277740478516,
    "learning_rate": 0.001
  },
  {
    "episode": 11842,
    "reward": 90.926757,
    "length": 62,
    "time": 172544.150735,
    "actor_loss": -66.44139099121094,
    "critic_loss": 2.2285470962524414,
    "ent_coef": 0.05497012287378311,
    "learning_rate": 0.001
  },
  {
    "episode": 11843,
    "reward": 89.464213,
    "length": 69,
    "time": 172556.264055,
    "actor_loss": -66.57557678222656,
    "critic_loss": 24.84527587890625,
    "ent_coef": 0.053330276161432266,
    "learning_rate": 0.001
  },
  {
    "episode": 11844,
    "reward": 89.328697,
    "length": 65,
    "time": 172568.241879,
    "actor_loss": -71.75245666503906,
    "critic_loss": 4.0073347091674805,
    "ent_coef": 0.05270576849579811,
    "learning_rate": 0.001
  },
  {
    "episode": 11845,
    "reward": 91.646546,
    "length": 61,
    "time": 172579.201849,
    "actor_loss": -68.61073303222656,
    "critic_loss": 13.579290390014648,
    "ent_coef": 0.05408946052193642,
    "learning_rate": 0.001
  },
  {
    "episode": 11846,
    "reward": 89.279721,
    "length": 68,
    "time": 172591.288329,
    "actor_loss": -69.10196685791016,
    "critic_loss": 13.788532257080078,
    "ent_coef": 0.05507264286279678,
    "learning_rate": 0.001
  },
  {
    "episode": 11847,
    "reward": 88.202483,
    "length": 71,
    "time": 172603.719064,
    "actor_loss": -68.82774353027344,
    "critic_loss": 5.73012638092041,
    "ent_coef": 0.0547155924141407,
    "learning_rate": 0.001
  },
  {
    "episode": 11848,
    "reward": 89.241506,
    "length": 70,
    "time": 172615.90147,
    "actor_loss": -68.01338958740234,
    "critic_loss": 9.25666618347168,
    "ent_coef": 0.05407378077507019,
    "learning_rate": 0.001
  },
  {
    "episode": 11849,
    "reward": 90.226223,
    "length": 66,
    "time": 172628.227728,
    "actor_loss": -73.23617553710938,
    "critic_loss": 3.9049243927001953,
    "ent_coef": 0.05448026955127716,
    "learning_rate": 0.001
  },
  {
    "episode": 11850,
    "reward": 90.520189,
    "length": 63,
    "time": 172641.337101,
    "actor_loss": -71.56623840332031,
    "critic_loss": 5.431453704833984,
    "ent_coef": 0.05505763739347458,
    "learning_rate": 0.001
  },
  {
    "episode": 11851,
    "reward": 83.320427,
    "length": 79,
    "time": 172655.772532,
    "actor_loss": -66.82135009765625,
    "critic_loss": 50.18336486816406,
    "ent_coef": 0.0515647754073143,
    "learning_rate": 0.001
  },
  {
    "episode": 11852,
    "reward": 86.660357,
    "length": 73,
    "time": 172668.900906,
    "actor_loss": -72.77276611328125,
    "critic_loss": 2.224775791168213,
    "ent_coef": 0.05472817271947861,
    "learning_rate": 0.001
  },
  {
    "episode": 11853,
    "reward": 90.10352,
    "length": 64,
    "time": 172681.454866,
    "actor_loss": -71.09768676757812,
    "critic_loss": 17.424837112426758,
    "ent_coef": 0.05356249585747719,
    "learning_rate": 0.001
  },
  {
    "episode": 11854,
    "reward": 91.813774,
    "length": 60,
    "time": 172692.755667,
    "actor_loss": -65.45045471191406,
    "critic_loss": 7.072274208068848,
    "ent_coef": 0.05616153031587601,
    "learning_rate": 0.001
  },
  {
    "episode": 11855,
    "reward": 89.452755,
    "length": 67,
    "time": 172706.449232,
    "actor_loss": -69.57806396484375,
    "critic_loss": 5.173712730407715,
    "ent_coef": 0.06020371988415718,
    "learning_rate": 0.001
  },
  {
    "episode": 11856,
    "reward": 90.439172,
    "length": 63,
    "time": 172721.063608,
    "actor_loss": -72.34833526611328,
    "critic_loss": 44.32869338989258,
    "ent_coef": 0.06137843802571297,
    "learning_rate": 0.001
  },
  {
    "episode": 11857,
    "reward": 90.600235,
    "length": 63,
    "time": 172734.988317,
    "actor_loss": -73.02699279785156,
    "critic_loss": 4.126561164855957,
    "ent_coef": 0.0623701810836792,
    "learning_rate": 0.001
  },
  {
    "episode": 11858,
    "reward": 88.05124,
    "length": 67,
    "time": 172750.021013,
    "actor_loss": -68.94929504394531,
    "critic_loss": 4.767356872558594,
    "ent_coef": 0.06146867945790291,
    "learning_rate": 0.001
  },
  {
    "episode": 11859,
    "reward": 90.599801,
    "length": 60,
    "time": 172766.47075,
    "actor_loss": -75.01717376708984,
    "critic_loss": 4.212193012237549,
    "ent_coef": 0.06011798977851868,
    "learning_rate": 0.001
  },
  {
    "episode": 11860,
    "reward": 87.829719,
    "length": 69,
    "time": 172782.791692,
    "actor_loss": -76.34686279296875,
    "critic_loss": 7.5506391525268555,
    "ent_coef": 0.0599496066570282,
    "learning_rate": 0.001
  },
  {
    "episode": 11861,
    "reward": 83.782035,
    "length": 90,
    "time": 172802.086249,
    "actor_loss": -69.03194427490234,
    "critic_loss": 4.950762748718262,
    "ent_coef": 0.05802961438894272,
    "learning_rate": 0.001
  },
  {
    "episode": 11862,
    "reward": 71.416247,
    "length": 93,
    "time": 172819.911672,
    "actor_loss": -65.96542358398438,
    "critic_loss": 3.9066972732543945,
    "ent_coef": 0.057077210396528244,
    "learning_rate": 0.001
  },
  {
    "episode": 11863,
    "reward": 85.928439,
    "length": 73,
    "time": 172834.961264,
    "actor_loss": -72.10787963867188,
    "critic_loss": 53.79774475097656,
    "ent_coef": 0.05928425118327141,
    "learning_rate": 0.001
  },
  {
    "episode": 11864,
    "reward": 87.948463,
    "length": 69,
    "time": 172849.252804,
    "actor_loss": -71.02978515625,
    "critic_loss": 6.967389106750488,
    "ent_coef": 0.05996517464518547,
    "learning_rate": 0.001
  },
  {
    "episode": 11865,
    "reward": 77.740555,
    "length": 100,
    "time": 172868.284607,
    "actor_loss": -69.85808563232422,
    "critic_loss": 4.587281227111816,
    "ent_coef": 0.05690787732601166,
    "learning_rate": 0.001
  },
  {
    "episode": 11866,
    "reward": 87.415605,
    "length": 72,
    "time": 172883.690261,
    "actor_loss": -68.61247253417969,
    "critic_loss": 5.9886980056762695,
    "ent_coef": 0.05873291566967964,
    "learning_rate": 0.001
  },
  {
    "episode": 11867,
    "reward": 90.981584,
    "length": 62,
    "time": 172895.125049,
    "actor_loss": -70.61688995361328,
    "critic_loss": 3.8079373836517334,
    "ent_coef": 0.06085928902029991,
    "learning_rate": 0.001
  },
  {
    "episode": 11868,
    "reward": 88.751326,
    "length": 66,
    "time": 172906.987246,
    "actor_loss": -64.25293731689453,
    "critic_loss": 5.621140480041504,
    "ent_coef": 0.06147182732820511,
    "learning_rate": 0.001
  },
  {
    "episode": 11869,
    "reward": 89.893113,
    "length": 65,
    "time": 172922.377872,
    "actor_loss": -67.9803237915039,
    "critic_loss": 15.186570167541504,
    "ent_coef": 0.06017730012536049,
    "learning_rate": 0.001
  },
  {
    "episode": 11870,
    "reward": 89.588772,
    "length": 65,
    "time": 172934.561415,
    "actor_loss": -63.795616149902344,
    "critic_loss": 71.00524139404297,
    "ent_coef": 0.059438444674015045,
    "learning_rate": 0.001
  },
  {
    "episode": 11871,
    "reward": 89.037949,
    "length": 67,
    "time": 172947.337886,
    "actor_loss": -74.34120178222656,
    "critic_loss": 2.3968143463134766,
    "ent_coef": 0.05722922459244728,
    "learning_rate": 0.001
  },
  {
    "episode": 11872,
    "reward": 88.879443,
    "length": 67,
    "time": 172960.923744,
    "actor_loss": -70.21946716308594,
    "critic_loss": 2.3091278076171875,
    "ent_coef": 0.05631447955965996,
    "learning_rate": 0.001
  },
  {
    "episode": 11873,
    "reward": 91.593602,
    "length": 61,
    "time": 172975.237942,
    "actor_loss": -62.308109283447266,
    "critic_loss": 5.9904985427856445,
    "ent_coef": 0.059158969670534134,
    "learning_rate": 0.001
  },
  {
    "episode": 11874,
    "reward": 90.409298,
    "length": 64,
    "time": 172987.033465,
    "actor_loss": -68.79192352294922,
    "critic_loss": 334.9991149902344,
    "ent_coef": 0.058907948434352875,
    "learning_rate": 0.001
  },
  {
    "episode": 11875,
    "reward": 87.621792,
    "length": 77,
    "time": 173000.800959,
    "actor_loss": -67.11418151855469,
    "critic_loss": 7.9609503746032715,
    "ent_coef": 0.059001944959163666,
    "learning_rate": 0.001
  },
  {
    "episode": 11876,
    "reward": 88.457222,
    "length": 67,
    "time": 173012.877947,
    "actor_loss": -72.40022277832031,
    "critic_loss": 6.059002876281738,
    "ent_coef": 0.057885851711034775,
    "learning_rate": 0.001
  },
  {
    "episode": 11877,
    "reward": 89.099751,
    "length": 65,
    "time": 173026.228514,
    "actor_loss": -70.41304016113281,
    "critic_loss": 4.3121747970581055,
    "ent_coef": 0.057225678116083145,
    "learning_rate": 0.001
  },
  {
    "episode": 11878,
    "reward": 85.662826,
    "length": 79,
    "time": 173043.126695,
    "actor_loss": -67.88582611083984,
    "critic_loss": 4.054467678070068,
    "ent_coef": 0.05448879301548004,
    "learning_rate": 0.001
  },
  {
    "episode": 11879,
    "reward": 88.604159,
    "length": 68,
    "time": 173056.409029,
    "actor_loss": -71.73486328125,
    "critic_loss": 25.274948120117188,
    "ent_coef": 0.05370936542749405,
    "learning_rate": 0.001
  },
  {
    "episode": 11880,
    "reward": 90.084435,
    "length": 65,
    "time": 173069.039953,
    "actor_loss": -67.8219985961914,
    "critic_loss": 5.683820724487305,
    "ent_coef": 0.053582001477479935,
    "learning_rate": 0.001
  },
  {
    "episode": 11881,
    "reward": 85.471512,
    "length": 73,
    "time": 173083.087384,
    "actor_loss": -71.40973663330078,
    "critic_loss": 3.224091053009033,
    "ent_coef": 0.05056669935584068,
    "learning_rate": 0.001
  },
  {
    "episode": 11882,
    "reward": 87.821187,
    "length": 68,
    "time": 173100.45787,
    "actor_loss": -67.47706604003906,
    "critic_loss": 13.912425994873047,
    "ent_coef": 0.04980570822954178,
    "learning_rate": 0.001
  },
  {
    "episode": 11883,
    "reward": 88.988814,
    "length": 66,
    "time": 173113.557429,
    "actor_loss": -70.45654296875,
    "critic_loss": 3.1873490810394287,
    "ent_coef": 0.05131036788225174,
    "learning_rate": 0.001
  },
  {
    "episode": 11884,
    "reward": 88.412972,
    "length": 74,
    "time": 173131.172601,
    "actor_loss": -68.98445129394531,
    "critic_loss": 3.2179646492004395,
    "ent_coef": 0.05294674634933472,
    "learning_rate": 0.001
  },
  {
    "episode": 11885,
    "reward": 85.399661,
    "length": 81,
    "time": 173149.441438,
    "actor_loss": -69.11943054199219,
    "critic_loss": 21.838178634643555,
    "ent_coef": 0.05348219722509384,
    "learning_rate": 0.001
  },
  {
    "episode": 11886,
    "reward": 85.305019,
    "length": 83,
    "time": 173165.072395,
    "actor_loss": -68.0714111328125,
    "critic_loss": 2.408322334289551,
    "ent_coef": 0.050603125244379044,
    "learning_rate": 0.001
  },
  {
    "episode": 11887,
    "reward": 84.185853,
    "length": 76,
    "time": 173178.801019,
    "actor_loss": -70.9910888671875,
    "critic_loss": 30.595848083496094,
    "ent_coef": 0.04834524169564247,
    "learning_rate": 0.001
  },
  {
    "episode": 11888,
    "reward": 82.152081,
    "length": 86,
    "time": 173193.8476,
    "actor_loss": -72.36334228515625,
    "critic_loss": 520.6803588867188,
    "ent_coef": 0.04620349034667015,
    "learning_rate": 0.001
  },
  {
    "episode": 11889,
    "reward": 86.375252,
    "length": 77,
    "time": 173208.65065,
    "actor_loss": -68.40432739257812,
    "critic_loss": 6.385505199432373,
    "ent_coef": 0.047241341322660446,
    "learning_rate": 0.001
  },
  {
    "episode": 11890,
    "reward": 88.681222,
    "length": 67,
    "time": 173221.070666,
    "actor_loss": -71.32377624511719,
    "critic_loss": 5.8976898193359375,
    "ent_coef": 0.04757234826683998,
    "learning_rate": 0.001
  },
  {
    "episode": 11891,
    "reward": 85.999984,
    "length": 75,
    "time": 173235.792196,
    "actor_loss": -71.39497375488281,
    "critic_loss": 4.151908874511719,
    "ent_coef": 0.05184045433998108,
    "learning_rate": 0.001
  },
  {
    "episode": 11892,
    "reward": 91.171577,
    "length": 61,
    "time": 173250.302459,
    "actor_loss": -72.5618667602539,
    "critic_loss": 91.42559051513672,
    "ent_coef": 0.05359410122036934,
    "learning_rate": 0.001
  },
  {
    "episode": 11893,
    "reward": 87.8005,
    "length": 75,
    "time": 173264.402253,
    "actor_loss": -66.8018798828125,
    "critic_loss": 2.54909086227417,
    "ent_coef": 0.054414909332990646,
    "learning_rate": 0.001
  },
  {
    "episode": 11894,
    "reward": 85.469003,
    "length": 79,
    "time": 173281.47476,
    "actor_loss": -68.4789810180664,
    "critic_loss": 4.390772819519043,
    "ent_coef": 0.054185155779123306,
    "learning_rate": 0.001
  },
  {
    "episode": 11895,
    "reward": 88.972587,
    "length": 69,
    "time": 173298.358528,
    "actor_loss": -66.73075866699219,
    "critic_loss": 3.258493423461914,
    "ent_coef": 0.05574706941843033,
    "learning_rate": 0.001
  },
  {
    "episode": 11896,
    "reward": 86.60359,
    "length": 77,
    "time": 173313.294208,
    "actor_loss": -68.28532409667969,
    "critic_loss": 41.19550323486328,
    "ent_coef": 0.05664088577032089,
    "learning_rate": 0.001
  },
  {
    "episode": 11897,
    "reward": 90.49195,
    "length": 63,
    "time": 173326.33114,
    "actor_loss": -70.89077758789062,
    "critic_loss": 5.905486583709717,
    "ent_coef": 0.05937926843762398,
    "learning_rate": 0.001
  },
  {
    "episode": 11898,
    "reward": 89.706059,
    "length": 70,
    "time": 173340.738763,
    "actor_loss": -70.66295623779297,
    "critic_loss": 6.972153186798096,
    "ent_coef": 0.06445835530757904,
    "learning_rate": 0.001
  },
  {
    "episode": 11899,
    "reward": 89.844721,
    "length": 63,
    "time": 173356.2636,
    "actor_loss": -64.41567993164062,
    "critic_loss": 13.950061798095703,
    "ent_coef": 0.06449469178915024,
    "learning_rate": 0.001
  },
  {
    "episode": 11900,
    "reward": 88.596674,
    "length": 72,
    "time": 173369.370624,
    "actor_loss": -77.63343048095703,
    "critic_loss": 21.529151916503906,
    "ent_coef": 0.06612516939640045,
    "learning_rate": 0.001
  },
  {
    "episode": 11901,
    "reward": 83.999595,
    "length": 80,
    "time": 173386.864382,
    "actor_loss": -70.73046875,
    "critic_loss": 4.240015983581543,
    "ent_coef": 0.06290574371814728,
    "learning_rate": 0.001
  },
  {
    "episode": 11902,
    "reward": 86.290541,
    "length": 78,
    "time": 173403.679673,
    "actor_loss": -72.14642333984375,
    "critic_loss": 8.324212074279785,
    "ent_coef": 0.060894761234521866,
    "learning_rate": 0.001
  },
  {
    "episode": 11903,
    "reward": 87.585218,
    "length": 75,
    "time": 173417.439836,
    "actor_loss": -73.14656066894531,
    "critic_loss": 26.180524826049805,
    "ent_coef": 0.06127731874585152,
    "learning_rate": 0.001
  },
  {
    "episode": 11904,
    "reward": 87.796689,
    "length": 71,
    "time": 173433.510705,
    "actor_loss": -65.07740783691406,
    "critic_loss": 5.134950637817383,
    "ent_coef": 0.06237248331308365,
    "learning_rate": 0.001
  },
  {
    "episode": 11905,
    "reward": 89.415005,
    "length": 68,
    "time": 173448.601354,
    "actor_loss": -66.97335815429688,
    "critic_loss": 6.360889911651611,
    "ent_coef": 0.06714747101068497,
    "learning_rate": 0.001
  },
  {
    "episode": 11906,
    "reward": 86.473188,
    "length": 77,
    "time": 173464.245043,
    "actor_loss": -67.28570556640625,
    "critic_loss": 3.6828436851501465,
    "ent_coef": 0.06447882950305939,
    "learning_rate": 0.001
  },
  {
    "episode": 11907,
    "reward": 87.962721,
    "length": 68,
    "time": 173477.003606,
    "actor_loss": -70.8685302734375,
    "critic_loss": 60.169490814208984,
    "ent_coef": 0.062269844114780426,
    "learning_rate": 0.001
  },
  {
    "episode": 11908,
    "reward": 86.129663,
    "length": 69,
    "time": 173489.753542,
    "actor_loss": -70.64462280273438,
    "critic_loss": 8.573485374450684,
    "ent_coef": 0.06053924933075905,
    "learning_rate": 0.001
  },
  {
    "episode": 11909,
    "reward": 88.616003,
    "length": 70,
    "time": 173503.85362,
    "actor_loss": -69.26179504394531,
    "critic_loss": 3.3366036415100098,
    "ent_coef": 0.06056959554553032,
    "learning_rate": 0.001
  },
  {
    "episode": 11910,
    "reward": 79.590569,
    "length": 87,
    "time": 173519.474829,
    "actor_loss": -71.68536376953125,
    "critic_loss": 3.5924434661865234,
    "ent_coef": 0.05835501849651337,
    "learning_rate": 0.001
  },
  {
    "episode": 11911,
    "reward": 83.238024,
    "length": 84,
    "time": 173535.423959,
    "actor_loss": -72.09886169433594,
    "critic_loss": 3.3227949142456055,
    "ent_coef": 0.05558124557137489,
    "learning_rate": 0.001
  },
  {
    "episode": 11912,
    "reward": 84.543087,
    "length": 76,
    "time": 173549.970977,
    "actor_loss": -66.05500793457031,
    "critic_loss": 4.74586296081543,
    "ent_coef": 0.054907120764255524,
    "learning_rate": 0.001
  },
  {
    "episode": 11913,
    "reward": 81.460675,
    "length": 85,
    "time": 173565.604669,
    "actor_loss": -78.62359619140625,
    "critic_loss": 3.815347194671631,
    "ent_coef": 0.053992584347724915,
    "learning_rate": 0.001
  },
  {
    "episode": 11914,
    "reward": 87.544103,
    "length": 74,
    "time": 173579.52642,
    "actor_loss": -77.15921020507812,
    "critic_loss": 58.495574951171875,
    "ent_coef": 0.05485105514526367,
    "learning_rate": 0.001
  },
  {
    "episode": 11915,
    "reward": 87.194834,
    "length": 76,
    "time": 173596.317975,
    "actor_loss": -75.12417602539062,
    "critic_loss": 3.1813242435455322,
    "ent_coef": 0.056036967784166336,
    "learning_rate": 0.001
  },
  {
    "episode": 11916,
    "reward": 88.161223,
    "length": 69,
    "time": 173609.977332,
    "actor_loss": -73.00775146484375,
    "critic_loss": 8.085734367370605,
    "ent_coef": 0.05737339332699776,
    "learning_rate": 0.001
  },
  {
    "episode": 11917,
    "reward": 85.616616,
    "length": 72,
    "time": 173625.904494,
    "actor_loss": -70.72762298583984,
    "critic_loss": 4.9762282371521,
    "ent_coef": 0.057100676000118256,
    "learning_rate": 0.001
  },
  {
    "episode": 11918,
    "reward": 87.217282,
    "length": 76,
    "time": 173639.149599,
    "actor_loss": -73.98065185546875,
    "critic_loss": 29.73897933959961,
    "ent_coef": 0.059171028435230255,
    "learning_rate": 0.001
  },
  {
    "episode": 11919,
    "reward": 89.012365,
    "length": 66,
    "time": 173651.530689,
    "actor_loss": -68.66503143310547,
    "critic_loss": 4.181270599365234,
    "ent_coef": 0.06584320962429047,
    "learning_rate": 0.001
  },
  {
    "episode": 11920,
    "reward": 90.268713,
    "length": 69,
    "time": 173664.161253,
    "actor_loss": -67.94507598876953,
    "critic_loss": 24.201587677001953,
    "ent_coef": 0.07093335688114166,
    "learning_rate": 0.001
  },
  {
    "episode": 11921,
    "reward": 90.005095,
    "length": 64,
    "time": 173676.46927,
    "actor_loss": -70.41918182373047,
    "critic_loss": 28.00262451171875,
    "ent_coef": 0.07095616310834885,
    "learning_rate": 0.001
  },
  {
    "episode": 11922,
    "reward": 87.237183,
    "length": 76,
    "time": 173692.322984,
    "actor_loss": -69.81884765625,
    "critic_loss": 4.896196365356445,
    "ent_coef": 0.06912802159786224,
    "learning_rate": 0.001
  },
  {
    "episode": 11923,
    "reward": 89.745939,
    "length": 65,
    "time": 173706.150432,
    "actor_loss": -69.16106414794922,
    "critic_loss": 4.748549461364746,
    "ent_coef": 0.07077745348215103,
    "learning_rate": 0.001
  },
  {
    "episode": 11924,
    "reward": 87.253208,
    "length": 73,
    "time": 173720.754916,
    "actor_loss": -63.856590270996094,
    "critic_loss": 18.632240295410156,
    "ent_coef": 0.07000984996557236,
    "learning_rate": 0.001
  },
  {
    "episode": 11925,
    "reward": 83.37799,
    "length": 82,
    "time": 173737.968983,
    "actor_loss": -66.96771240234375,
    "critic_loss": 5.649313926696777,
    "ent_coef": 0.06774847209453583,
    "learning_rate": 0.001
  },
  {
    "episode": 11926,
    "reward": 90.640371,
    "length": 65,
    "time": 173751.789686,
    "actor_loss": -68.01023864746094,
    "critic_loss": 12.045016288757324,
    "ent_coef": 0.0684887021780014,
    "learning_rate": 0.001
  },
  {
    "episode": 11927,
    "reward": 86.586153,
    "length": 64,
    "time": 173768.735303,
    "actor_loss": -67.3748779296875,
    "critic_loss": 5.194406032562256,
    "ent_coef": 0.06850950419902802,
    "learning_rate": 0.001
  },
  {
    "episode": 11928,
    "reward": 90.766723,
    "length": 62,
    "time": 173782.1351,
    "actor_loss": -70.25437927246094,
    "critic_loss": 8.6054048538208,
    "ent_coef": 0.06702566891908646,
    "learning_rate": 0.001
  },
  {
    "episode": 11929,
    "reward": 90.39778,
    "length": 63,
    "time": 173795.546665,
    "actor_loss": -72.98860168457031,
    "critic_loss": 57.780670166015625,
    "ent_coef": 0.0671156495809555,
    "learning_rate": 0.001
  },
  {
    "episode": 11930,
    "reward": 88.852272,
    "length": 72,
    "time": 173809.263022,
    "actor_loss": -69.66876220703125,
    "critic_loss": 3.094846248626709,
    "ent_coef": 0.06487071514129639,
    "learning_rate": 0.001
  },
  {
    "episode": 11931,
    "reward": -160.375331,
    "length": 156,
    "time": 173834.863395,
    "actor_loss": -69.4690933227539,
    "critic_loss": 8.044586181640625,
    "ent_coef": 0.06771931797266006,
    "learning_rate": 0.001
  },
  {
    "episode": 11932,
    "reward": 86.818692,
    "length": 75,
    "time": 173849.280862,
    "actor_loss": -73.47095489501953,
    "critic_loss": 3.473966598510742,
    "ent_coef": 0.06564177572727203,
    "learning_rate": 0.001
  },
  {
    "episode": 11933,
    "reward": 87.853532,
    "length": 75,
    "time": 173863.58476,
    "actor_loss": -72.95307922363281,
    "critic_loss": 16.912147521972656,
    "ent_coef": 0.06366857886314392,
    "learning_rate": 0.001
  },
  {
    "episode": 11934,
    "reward": 86.844921,
    "length": 74,
    "time": 173877.479906,
    "actor_loss": -66.18257904052734,
    "critic_loss": 4.342095375061035,
    "ent_coef": 0.06061890348792076,
    "learning_rate": 0.001
  },
  {
    "episode": 11935,
    "reward": 87.263416,
    "length": 69,
    "time": 173893.017504,
    "actor_loss": -73.534423828125,
    "critic_loss": 5.380797863006592,
    "ent_coef": 0.05835842713713646,
    "learning_rate": 0.001
  },
  {
    "episode": 11936,
    "reward": 87.718285,
    "length": 70,
    "time": 173907.505447,
    "actor_loss": -74.6217041015625,
    "critic_loss": 1.6134397983551025,
    "ent_coef": 0.05615775287151337,
    "learning_rate": 0.001
  },
  {
    "episode": 11937,
    "reward": 86.564046,
    "length": 72,
    "time": 173921.382133,
    "actor_loss": -75.03241729736328,
    "critic_loss": 6.013306140899658,
    "ent_coef": 0.052699409425258636,
    "learning_rate": 0.001
  },
  {
    "episode": 11938,
    "reward": 86.899642,
    "length": 75,
    "time": 173938.024865,
    "actor_loss": -64.80987548828125,
    "critic_loss": 4.060850143432617,
    "ent_coef": 0.053475894033908844,
    "learning_rate": 0.001
  },
  {
    "episode": 11939,
    "reward": 85.717873,
    "length": 76,
    "time": 173957.178512,
    "actor_loss": -68.85595703125,
    "critic_loss": 14.53514289855957,
    "ent_coef": 0.051703307777643204,
    "learning_rate": 0.001
  },
  {
    "episode": 11940,
    "reward": 88.318451,
    "length": 67,
    "time": 173970.488041,
    "actor_loss": -72.2129135131836,
    "critic_loss": 5.619058609008789,
    "ent_coef": 0.05044671520590782,
    "learning_rate": 0.001
  },
  {
    "episode": 11941,
    "reward": -162.499503,
    "length": 143,
    "time": 173994.945326,
    "actor_loss": -70.642333984375,
    "critic_loss": 3.8146581649780273,
    "ent_coef": 0.054212212562561035,
    "learning_rate": 0.001
  },
  {
    "episode": 11942,
    "reward": 86.171981,
    "length": 76,
    "time": 174011.899554,
    "actor_loss": -75.44104766845703,
    "critic_loss": 3.559429883956909,
    "ent_coef": 0.056207798421382904,
    "learning_rate": 0.001
  },
  {
    "episode": 11943,
    "reward": 88.117241,
    "length": 73,
    "time": 174025.786524,
    "actor_loss": -74.1160659790039,
    "critic_loss": 2.63421893119812,
    "ent_coef": 0.0575626939535141,
    "learning_rate": 0.001
  },
  {
    "episode": 11944,
    "reward": 87.32293,
    "length": 76,
    "time": 174041.950606,
    "actor_loss": -71.9087905883789,
    "critic_loss": 4.197139739990234,
    "ent_coef": 0.05748892202973366,
    "learning_rate": 0.001
  },
  {
    "episode": 11945,
    "reward": 86.120185,
    "length": 62,
    "time": 174053.755944,
    "actor_loss": -66.59831237792969,
    "critic_loss": 3.9668962955474854,
    "ent_coef": 0.05862002074718475,
    "learning_rate": 0.001
  },
  {
    "episode": 11946,
    "reward": 87.946367,
    "length": 69,
    "time": 174066.114794,
    "actor_loss": -66.02714538574219,
    "critic_loss": 11.21474838256836,
    "ent_coef": 0.061197295784950256,
    "learning_rate": 0.001
  },
  {
    "episode": 11947,
    "reward": 87.769836,
    "length": 67,
    "time": 174080.819833,
    "actor_loss": -70.69650268554688,
    "critic_loss": 5.160798072814941,
    "ent_coef": 0.06382177770137787,
    "learning_rate": 0.001
  },
  {
    "episode": 11948,
    "reward": 90.486794,
    "length": 66,
    "time": 174093.170424,
    "actor_loss": -67.18426513671875,
    "critic_loss": 7.568179130554199,
    "ent_coef": 0.0690658763051033,
    "learning_rate": 0.001
  },
  {
    "episode": 11949,
    "reward": 88.253751,
    "length": 71,
    "time": 174106.766069,
    "actor_loss": -68.666015625,
    "critic_loss": 4.789680480957031,
    "ent_coef": 0.06798240542411804,
    "learning_rate": 0.001
  },
  {
    "episode": 11950,
    "reward": 86.691511,
    "length": 76,
    "time": 174124.170783,
    "actor_loss": -74.28533935546875,
    "critic_loss": 3.6144421100616455,
    "ent_coef": 0.06568162143230438,
    "learning_rate": 0.001
  },
  {
    "episode": 11951,
    "reward": 87.681131,
    "length": 73,
    "time": 174140.461632,
    "actor_loss": -64.70018005371094,
    "critic_loss": 6.912872314453125,
    "ent_coef": 0.061611250042915344,
    "learning_rate": 0.001
  },
  {
    "episode": 11952,
    "reward": 88.104038,
    "length": 68,
    "time": 174152.928685,
    "actor_loss": -72.24703216552734,
    "critic_loss": 6.286273956298828,
    "ent_coef": 0.06005926802754402,
    "learning_rate": 0.001
  },
  {
    "episode": 11953,
    "reward": 84.709326,
    "length": 65,
    "time": 174165.891062,
    "actor_loss": -69.64509582519531,
    "critic_loss": 2.79252290725708,
    "ent_coef": 0.061055537313222885,
    "learning_rate": 0.001
  },
  {
    "episode": 11954,
    "reward": 86.793533,
    "length": 76,
    "time": 174182.44458,
    "actor_loss": -74.22055053710938,
    "critic_loss": 8.882431030273438,
    "ent_coef": 0.0613241009414196,
    "learning_rate": 0.001
  },
  {
    "episode": 11955,
    "reward": 84.576145,
    "length": 81,
    "time": 174196.911732,
    "actor_loss": -66.08676147460938,
    "critic_loss": 7.85245418548584,
    "ent_coef": 0.06173813343048096,
    "learning_rate": 0.001
  },
  {
    "episode": 11956,
    "reward": 86.434019,
    "length": 82,
    "time": 174212.292245,
    "actor_loss": -74.00849151611328,
    "critic_loss": 10.901815414428711,
    "ent_coef": 0.06048298254609108,
    "learning_rate": 0.001
  },
  {
    "episode": 11957,
    "reward": 87.652834,
    "length": 72,
    "time": 174225.50172,
    "actor_loss": -68.6561050415039,
    "critic_loss": 1.7153644561767578,
    "ent_coef": 0.05878908187150955,
    "learning_rate": 0.001
  },
  {
    "episode": 11958,
    "reward": 90.092077,
    "length": 68,
    "time": 174238.117001,
    "actor_loss": -74.39057159423828,
    "critic_loss": 6.21425724029541,
    "ent_coef": 0.05893572047352791,
    "learning_rate": 0.001
  },
  {
    "episode": 11959,
    "reward": -154.711891,
    "length": 135,
    "time": 174260.991654,
    "actor_loss": -73.0615463256836,
    "critic_loss": 2.78410005569458,
    "ent_coef": 0.056906409561634064,
    "learning_rate": 0.001
  },
  {
    "episode": 11960,
    "reward": 89.279375,
    "length": 65,
    "time": 174273.99351,
    "actor_loss": -69.18501281738281,
    "critic_loss": 3.7712936401367188,
    "ent_coef": 0.05557479336857796,
    "learning_rate": 0.001
  },
  {
    "episode": 11961,
    "reward": 86.361044,
    "length": 66,
    "time": 174288.509005,
    "actor_loss": -69.57000732421875,
    "critic_loss": 21.261764526367188,
    "ent_coef": 0.056036219000816345,
    "learning_rate": 0.001
  },
  {
    "episode": 11962,
    "reward": 87.889019,
    "length": 65,
    "time": 174302.849422,
    "actor_loss": -69.11038970947266,
    "critic_loss": 3.7598228454589844,
    "ent_coef": 0.05835124850273132,
    "learning_rate": 0.001
  },
  {
    "episode": 11963,
    "reward": 88.905197,
    "length": 66,
    "time": 174318.542987,
    "actor_loss": -69.60308837890625,
    "critic_loss": 6.820313453674316,
    "ent_coef": 0.058292292058467865,
    "learning_rate": 0.001
  },
  {
    "episode": 11964,
    "reward": 87.041477,
    "length": 69,
    "time": 174333.842531,
    "actor_loss": -69.29988098144531,
    "critic_loss": 3.101008892059326,
    "ent_coef": 0.05673057585954666,
    "learning_rate": 0.001
  },
  {
    "episode": 11965,
    "reward": 83.782236,
    "length": 80,
    "time": 174354.053468,
    "actor_loss": -72.78321838378906,
    "critic_loss": 5.914570331573486,
    "ent_coef": 0.05698545649647713,
    "learning_rate": 0.001
  },
  {
    "episode": 11966,
    "reward": 85.831686,
    "length": 66,
    "time": 174368.741257,
    "actor_loss": -72.99403381347656,
    "critic_loss": 3.0327208042144775,
    "ent_coef": 0.0558263435959816,
    "learning_rate": 0.001
  },
  {
    "episode": 11967,
    "reward": 84.401351,
    "length": 68,
    "time": 174383.915574,
    "actor_loss": -68.44953155517578,
    "critic_loss": 4.3273797035217285,
    "ent_coef": 0.059013351798057556,
    "learning_rate": 0.001
  },
  {
    "episode": 11968,
    "reward": -152.750291,
    "length": 123,
    "time": 174407.181329,
    "actor_loss": -73.2811279296875,
    "critic_loss": 8.88886547088623,
    "ent_coef": 0.06250669062137604,
    "learning_rate": 0.001
  },
  {
    "episode": 11969,
    "reward": 87.303379,
    "length": 75,
    "time": 174422.696201,
    "actor_loss": -69.62332153320312,
    "critic_loss": 8.179304122924805,
    "ent_coef": 0.06733563542366028,
    "learning_rate": 0.001
  },
  {
    "episode": 11970,
    "reward": 90.255299,
    "length": 63,
    "time": 174436.556915,
    "actor_loss": -65.80496978759766,
    "critic_loss": 3.925349235534668,
    "ent_coef": 0.0687330886721611,
    "learning_rate": 0.001
  },
  {
    "episode": 11971,
    "reward": 89.669586,
    "length": 62,
    "time": 174450.209554,
    "actor_loss": -77.16493225097656,
    "critic_loss": 5.369930267333984,
    "ent_coef": 0.06792892515659332,
    "learning_rate": 0.001
  },
  {
    "episode": 11972,
    "reward": 88.220572,
    "length": 72,
    "time": 174465.926687,
    "actor_loss": -72.86944580078125,
    "critic_loss": 4.669947624206543,
    "ent_coef": 0.06696661561727524,
    "learning_rate": 0.001
  },
  {
    "episode": 11973,
    "reward": 90.637814,
    "length": 67,
    "time": 174483.597897,
    "actor_loss": -66.1216049194336,
    "critic_loss": 2.7469091415405273,
    "ent_coef": 0.06968363374471664,
    "learning_rate": 0.001
  },
  {
    "episode": 11974,
    "reward": 87.811399,
    "length": 70,
    "time": 174498.446203,
    "actor_loss": -73.12992858886719,
    "critic_loss": 2.7537927627563477,
    "ent_coef": 0.06689907610416412,
    "learning_rate": 0.001
  },
  {
    "episode": 11975,
    "reward": 83.889694,
    "length": 81,
    "time": 174515.075983,
    "actor_loss": -72.70930480957031,
    "critic_loss": 9.392579078674316,
    "ent_coef": 0.06268398463726044,
    "learning_rate": 0.001
  },
  {
    "episode": 11976,
    "reward": 86.199824,
    "length": 86,
    "time": 174532.137382,
    "actor_loss": -68.89958190917969,
    "critic_loss": 11.993279457092285,
    "ent_coef": 0.05965232476592064,
    "learning_rate": 0.001
  },
  {
    "episode": 11977,
    "reward": 85.903248,
    "length": 79,
    "time": 174551.56449,
    "actor_loss": -71.16431427001953,
    "critic_loss": 4.080634117126465,
    "ent_coef": 0.05745484307408333,
    "learning_rate": 0.001
  },
  {
    "episode": 11978,
    "reward": 87.696183,
    "length": 71,
    "time": 174567.041558,
    "actor_loss": -70.54203796386719,
    "critic_loss": 20.34332275390625,
    "ent_coef": 0.055576141923666,
    "learning_rate": 0.001
  },
  {
    "episode": 11979,
    "reward": 88.828609,
    "length": 69,
    "time": 174582.775689,
    "actor_loss": -71.10261535644531,
    "critic_loss": 8.410223007202148,
    "ent_coef": 0.05637567117810249,
    "learning_rate": 0.001
  },
  {
    "episode": 11980,
    "reward": 87.094587,
    "length": 75,
    "time": 174600.370625,
    "actor_loss": -64.08854675292969,
    "critic_loss": 6.872222900390625,
    "ent_coef": 0.05652869865298271,
    "learning_rate": 0.001
  },
  {
    "episode": 11981,
    "reward": 85.506784,
    "length": 78,
    "time": 174616.101666,
    "actor_loss": -69.73678588867188,
    "critic_loss": 9.126270294189453,
    "ent_coef": 0.05582733824849129,
    "learning_rate": 0.001
  },
  {
    "episode": 11982,
    "reward": 85.052032,
    "length": 78,
    "time": 174631.573035,
    "actor_loss": -65.8168716430664,
    "critic_loss": 4.266018867492676,
    "ent_coef": 0.05587751418352127,
    "learning_rate": 0.001
  },
  {
    "episode": 11983,
    "reward": 89.526059,
    "length": 70,
    "time": 174645.164603,
    "actor_loss": -69.5170669555664,
    "critic_loss": 4.534162521362305,
    "ent_coef": 0.0573820136487484,
    "learning_rate": 0.001
  },
  {
    "episode": 11984,
    "reward": 84.548457,
    "length": 79,
    "time": 174660.136982,
    "actor_loss": -72.76760864257812,
    "critic_loss": 8.553821563720703,
    "ent_coef": 0.058621279895305634,
    "learning_rate": 0.001
  },
  {
    "episode": 11985,
    "reward": 85.341284,
    "length": 78,
    "time": 174675.659018,
    "actor_loss": -72.30928039550781,
    "critic_loss": 7.1342620849609375,
    "ent_coef": 0.057999394834041595,
    "learning_rate": 0.001
  },
  {
    "episode": 11986,
    "reward": 89.636256,
    "length": 64,
    "time": 174688.429364,
    "actor_loss": -68.47673034667969,
    "critic_loss": 76.99168395996094,
    "ent_coef": 0.05871214345097542,
    "learning_rate": 0.001
  },
  {
    "episode": 11987,
    "reward": 89.852515,
    "length": 65,
    "time": 174705.076499,
    "actor_loss": -66.75482177734375,
    "critic_loss": 299.9259338378906,
    "ent_coef": 0.06177978962659836,
    "learning_rate": 0.001
  },
  {
    "episode": 11988,
    "reward": 92.114648,
    "length": 59,
    "time": 174717.140827,
    "actor_loss": -63.45041275024414,
    "critic_loss": 4.508400917053223,
    "ent_coef": 0.06378120929002762,
    "learning_rate": 0.001
  },
  {
    "episode": 11989,
    "reward": 91.659776,
    "length": 60,
    "time": 174731.222878,
    "actor_loss": -73.53182220458984,
    "critic_loss": 6.210638999938965,
    "ent_coef": 0.06630909442901611,
    "learning_rate": 0.001
  },
  {
    "episode": 11990,
    "reward": 90.827473,
    "length": 63,
    "time": 174745.564796,
    "actor_loss": -74.60798645019531,
    "critic_loss": 1.535295009613037,
    "ent_coef": 0.0661771222949028,
    "learning_rate": 0.001
  },
  {
    "episode": 11991,
    "reward": 88.048286,
    "length": 73,
    "time": 174762.670155,
    "actor_loss": -69.14614868164062,
    "critic_loss": 6.6763200759887695,
    "ent_coef": 0.063993901014328,
    "learning_rate": 0.001
  },
  {
    "episode": 11992,
    "reward": 89.237965,
    "length": 67,
    "time": 174776.762738,
    "actor_loss": -72.19482421875,
    "critic_loss": 30.918746948242188,
    "ent_coef": 0.06225146725773811,
    "learning_rate": 0.001
  },
  {
    "episode": 11993,
    "reward": 89.977755,
    "length": 64,
    "time": 174791.859298,
    "actor_loss": -65.2982406616211,
    "critic_loss": 2.309450626373291,
    "ent_coef": 0.05977471545338631,
    "learning_rate": 0.001
  },
  {
    "episode": 11994,
    "reward": 88.233129,
    "length": 67,
    "time": 174805.971092,
    "actor_loss": -71.03182983398438,
    "critic_loss": 5.554034233093262,
    "ent_coef": 0.056886591017246246,
    "learning_rate": 0.001
  },
  {
    "episode": 11995,
    "reward": 87.469218,
    "length": 68,
    "time": 174821.160958,
    "actor_loss": -73.26274108886719,
    "critic_loss": 8.163297653198242,
    "ent_coef": 0.05924353003501892,
    "learning_rate": 0.001
  },
  {
    "episode": 11996,
    "reward": 88.144663,
    "length": 67,
    "time": 174834.376091,
    "actor_loss": -70.14453887939453,
    "critic_loss": 9.286736488342285,
    "ent_coef": 0.05944335088133812,
    "learning_rate": 0.001
  },
  {
    "episode": 11997,
    "reward": 87.948746,
    "length": 71,
    "time": 174848.29158,
    "actor_loss": -70.39413452148438,
    "critic_loss": 15.659184455871582,
    "ent_coef": 0.059333037585020065,
    "learning_rate": 0.001
  },
  {
    "episode": 11998,
    "reward": 86.601032,
    "length": 76,
    "time": 174864.037618,
    "actor_loss": -64.2523193359375,
    "critic_loss": 26.192140579223633,
    "ent_coef": 0.06200186535716057,
    "learning_rate": 0.001
  },
  {
    "episode": 11999,
    "reward": 91.495007,
    "length": 59,
    "time": 174878.198467,
    "actor_loss": -69.71343994140625,
    "critic_loss": 11.413394927978516,
    "ent_coef": 0.06280197948217392,
    "learning_rate": 0.001
  },
  {
    "episode": 12000,
    "reward": 90.662624,
    "length": 62,
    "time": 174893.576681,
    "actor_loss": -69.26846313476562,
    "critic_loss": 8.046846389770508,
    "ent_coef": 0.06161467730998993,
    "learning_rate": 0.001
  },
  {
    "episode": 12001,
    "reward": 89.443977,
    "length": 66,
    "time": 174911.295378,
    "actor_loss": -72.034912109375,
    "critic_loss": 6.082210063934326,
    "ent_coef": 0.06266102194786072,
    "learning_rate": 0.001
  },
  {
    "episode": 12002,
    "reward": 89.905881,
    "length": 63,
    "time": 174927.0838,
    "actor_loss": -68.32354736328125,
    "critic_loss": 5.942941665649414,
    "ent_coef": 0.06472582370042801,
    "learning_rate": 0.001
  },
  {
    "episode": 12003,
    "reward": 88.915894,
    "length": 67,
    "time": 174940.92781,
    "actor_loss": -70.17489624023438,
    "critic_loss": 17.48952293395996,
    "ent_coef": 0.06827864050865173,
    "learning_rate": 0.001
  },
  {
    "episode": 12004,
    "reward": 89.558013,
    "length": 68,
    "time": 174956.322247,
    "actor_loss": -71.11615753173828,
    "critic_loss": 3.906554698944092,
    "ent_coef": 0.07192620635032654,
    "learning_rate": 0.001
  },
  {
    "episode": 12005,
    "reward": 88.716675,
    "length": 66,
    "time": 174971.506879,
    "actor_loss": -70.37517547607422,
    "critic_loss": 30.864009857177734,
    "ent_coef": 0.07028571516275406,
    "learning_rate": 0.001
  },
  {
    "episode": 12006,
    "reward": 88.231421,
    "length": 67,
    "time": 174987.735012,
    "actor_loss": -68.93043518066406,
    "critic_loss": 2.972060203552246,
    "ent_coef": 0.07023580372333527,
    "learning_rate": 0.001
  },
  {
    "episode": 12007,
    "reward": 90.353395,
    "length": 63,
    "time": 175003.775004,
    "actor_loss": -68.36776733398438,
    "critic_loss": 21.638469696044922,
    "ent_coef": 0.07340496778488159,
    "learning_rate": 0.001
  },
  {
    "episode": 12008,
    "reward": 87.864762,
    "length": 70,
    "time": 175020.916659,
    "actor_loss": -67.30770111083984,
    "critic_loss": 7.60771369934082,
    "ent_coef": 0.0762443095445633,
    "learning_rate": 0.001
  },
  {
    "episode": 12009,
    "reward": 88.886834,
    "length": 72,
    "time": 175037.125262,
    "actor_loss": -67.93745422363281,
    "critic_loss": 8.235200881958008,
    "ent_coef": 0.07496839016675949,
    "learning_rate": 0.001
  },
  {
    "episode": 12010,
    "reward": 91.735092,
    "length": 60,
    "time": 175049.994998,
    "actor_loss": -64.95501708984375,
    "critic_loss": 8.373802185058594,
    "ent_coef": 0.07504960149526596,
    "learning_rate": 0.001
  },
  {
    "episode": 12011,
    "reward": 88.15087,
    "length": 69,
    "time": 175064.826458,
    "actor_loss": -65.60372924804688,
    "critic_loss": 11.966623306274414,
    "ent_coef": 0.07388731837272644,
    "learning_rate": 0.001
  },
  {
    "episode": 12012,
    "reward": 88.444094,
    "length": 66,
    "time": 175079.162147,
    "actor_loss": -67.12633514404297,
    "critic_loss": 9.29041862487793,
    "ent_coef": 0.06977427005767822,
    "learning_rate": 0.001
  },
  {
    "episode": 12013,
    "reward": 82.621871,
    "length": 75,
    "time": 175093.305591,
    "actor_loss": -64.33253479003906,
    "critic_loss": 4.288418769836426,
    "ent_coef": 0.06806255131959915,
    "learning_rate": 0.001
  },
  {
    "episode": 12014,
    "reward": 86.229822,
    "length": 70,
    "time": 175107.081131,
    "actor_loss": -68.18515014648438,
    "critic_loss": 5.002167701721191,
    "ent_coef": 0.06506005674600601,
    "learning_rate": 0.001
  },
  {
    "episode": 12015,
    "reward": 83.894012,
    "length": 75,
    "time": 175122.102123,
    "actor_loss": -68.40756225585938,
    "critic_loss": 6.579004764556885,
    "ent_coef": 0.06342227756977081,
    "learning_rate": 0.001
  },
  {
    "episode": 12016,
    "reward": 85.019404,
    "length": 72,
    "time": 175135.787678,
    "actor_loss": -69.05583190917969,
    "critic_loss": 7.698747634887695,
    "ent_coef": 0.06091391667723656,
    "learning_rate": 0.001
  },
  {
    "episode": 12017,
    "reward": 86.171807,
    "length": 68,
    "time": 175149.656942,
    "actor_loss": -64.46340942382812,
    "critic_loss": 58.781349182128906,
    "ent_coef": 0.05971924960613251,
    "learning_rate": 0.001
  },
  {
    "episode": 12018,
    "reward": 86.726291,
    "length": 69,
    "time": 175164.455765,
    "actor_loss": -66.8240737915039,
    "critic_loss": 11.789670944213867,
    "ent_coef": 0.059100620448589325,
    "learning_rate": 0.001
  },
  {
    "episode": 12019,
    "reward": 85.672434,
    "length": 71,
    "time": 175179.35309,
    "actor_loss": -69.36317443847656,
    "critic_loss": 8.31259822845459,
    "ent_coef": 0.059043046087026596,
    "learning_rate": 0.001
  },
  {
    "episode": 12020,
    "reward": 88.963222,
    "length": 65,
    "time": 175193.170773,
    "actor_loss": -63.163352966308594,
    "critic_loss": 9.030305862426758,
    "ent_coef": 0.06016458943486214,
    "learning_rate": 0.001
  },
  {
    "episode": 12021,
    "reward": 89.645565,
    "length": 62,
    "time": 175206.536281,
    "actor_loss": -67.15956115722656,
    "critic_loss": 30.526073455810547,
    "ent_coef": 0.06146088242530823,
    "learning_rate": 0.001
  },
  {
    "episode": 12022,
    "reward": 87.167074,
    "length": 72,
    "time": 175220.431834,
    "actor_loss": -65.77850341796875,
    "critic_loss": 8.662559509277344,
    "ent_coef": 0.06335306167602539,
    "learning_rate": 0.001
  },
  {
    "episode": 12023,
    "reward": 80.705495,
    "length": 87,
    "time": 175236.695292,
    "actor_loss": -68.8697509765625,
    "critic_loss": 5.157020568847656,
    "ent_coef": 0.06204714626073837,
    "learning_rate": 0.001
  },
  {
    "episode": 12024,
    "reward": 89.61638,
    "length": 65,
    "time": 175250.932526,
    "actor_loss": -72.65210723876953,
    "critic_loss": 17.173887252807617,
    "ent_coef": 0.06432899087667465,
    "learning_rate": 0.001
  },
  {
    "episode": 12025,
    "reward": 89.112738,
    "length": 63,
    "time": 175264.027255,
    "actor_loss": -68.70556640625,
    "critic_loss": 10.189201354980469,
    "ent_coef": 0.06584159284830093,
    "learning_rate": 0.001
  },
  {
    "episode": 12026,
    "reward": 83.241259,
    "length": 81,
    "time": 175280.137669,
    "actor_loss": -71.55458068847656,
    "critic_loss": 3.9955317974090576,
    "ent_coef": 0.06693646311759949,
    "learning_rate": 0.001
  },
  {
    "episode": 12027,
    "reward": 84.347397,
    "length": 76,
    "time": 175295.081511,
    "actor_loss": -64.35993194580078,
    "critic_loss": 4.1377081871032715,
    "ent_coef": 0.06866918504238129,
    "learning_rate": 0.001
  },
  {
    "episode": 12028,
    "reward": 81.306722,
    "length": 76,
    "time": 175310.22824,
    "actor_loss": -71.05911254882812,
    "critic_loss": 4.409286022186279,
    "ent_coef": 0.06941800564527512,
    "learning_rate": 0.001
  },
  {
    "episode": 12029,
    "reward": 82.398976,
    "length": 78,
    "time": 175325.030541,
    "actor_loss": -66.65237426757812,
    "critic_loss": 36.160057067871094,
    "ent_coef": 0.07309549301862717,
    "learning_rate": 0.001
  },
  {
    "episode": 12030,
    "reward": 89.929637,
    "length": 64,
    "time": 175338.328563,
    "actor_loss": -67.31694030761719,
    "critic_loss": 13.68155574798584,
    "ent_coef": 0.07281366735696793,
    "learning_rate": 0.001
  },
  {
    "episode": 12031,
    "reward": 86.160995,
    "length": 71,
    "time": 175352.995274,
    "actor_loss": -67.72197723388672,
    "critic_loss": 5.970253944396973,
    "ent_coef": 0.07253562659025192,
    "learning_rate": 0.001
  },
  {
    "episode": 12032,
    "reward": 87.229335,
    "length": 66,
    "time": 175366.820297,
    "actor_loss": -69.26818084716797,
    "critic_loss": 117.16961669921875,
    "ent_coef": 0.07064712792634964,
    "learning_rate": 0.001
  },
  {
    "episode": 12033,
    "reward": 89.197102,
    "length": 70,
    "time": 175384.401435,
    "actor_loss": -64.49008178710938,
    "critic_loss": 12.52115249633789,
    "ent_coef": 0.06888876110315323,
    "learning_rate": 0.001
  },
  {
    "episode": 12034,
    "reward": 89.13761,
    "length": 62,
    "time": 175398.920066,
    "actor_loss": -68.52361297607422,
    "critic_loss": 15.870160102844238,
    "ent_coef": 0.06894087791442871,
    "learning_rate": 0.001
  },
  {
    "episode": 12035,
    "reward": 86.11437,
    "length": 83,
    "time": 175417.798135,
    "actor_loss": -63.95679473876953,
    "critic_loss": 4.752854347229004,
    "ent_coef": 0.06883131712675095,
    "learning_rate": 0.001
  },
  {
    "episode": 12036,
    "reward": 86.872042,
    "length": 67,
    "time": 175433.247273,
    "actor_loss": -73.38137817382812,
    "critic_loss": 26.369340896606445,
    "ent_coef": 0.06783610582351685,
    "learning_rate": 0.001
  },
  {
    "episode": 12037,
    "reward": 86.015689,
    "length": 75,
    "time": 175450.204831,
    "actor_loss": -67.54822540283203,
    "critic_loss": 5.462881088256836,
    "ent_coef": 0.06673544645309448,
    "learning_rate": 0.001
  },
  {
    "episode": 12038,
    "reward": 88.229837,
    "length": 69,
    "time": 175464.394448,
    "actor_loss": -66.9249038696289,
    "critic_loss": 7.1558003425598145,
    "ent_coef": 0.06405965238809586,
    "learning_rate": 0.001
  },
  {
    "episode": 12039,
    "reward": 86.328586,
    "length": 73,
    "time": 175478.139505,
    "actor_loss": -70.10649108886719,
    "critic_loss": 1.931020975112915,
    "ent_coef": 0.06669022142887115,
    "learning_rate": 0.001
  },
  {
    "episode": 12040,
    "reward": 89.169812,
    "length": 70,
    "time": 175491.487577,
    "actor_loss": -63.84650421142578,
    "critic_loss": 6.935882091522217,
    "ent_coef": 0.06844581663608551,
    "learning_rate": 0.001
  },
  {
    "episode": 12041,
    "reward": 87.472437,
    "length": 73,
    "time": 175506.269396,
    "actor_loss": -68.68695068359375,
    "critic_loss": 3.9739463329315186,
    "ent_coef": 0.06730906665325165,
    "learning_rate": 0.001
  },
  {
    "episode": 12042,
    "reward": 89.37155,
    "length": 66,
    "time": 175520.954468,
    "actor_loss": -72.72764587402344,
    "critic_loss": 14.288726806640625,
    "ent_coef": 0.06628455966711044,
    "learning_rate": 0.001
  },
  {
    "episode": 12043,
    "reward": 88.059427,
    "length": 65,
    "time": 175533.625266,
    "actor_loss": -63.06200408935547,
    "critic_loss": 3.915532112121582,
    "ent_coef": 0.066621333360672,
    "learning_rate": 0.001
  },
  {
    "episode": 12044,
    "reward": 87.596465,
    "length": 68,
    "time": 175546.802542,
    "actor_loss": -69.89292907714844,
    "critic_loss": 2.9198436737060547,
    "ent_coef": 0.06798803061246872,
    "learning_rate": 0.001
  },
  {
    "episode": 12045,
    "reward": 89.95176,
    "length": 63,
    "time": 175561.697447,
    "actor_loss": -61.76173782348633,
    "critic_loss": 19.113136291503906,
    "ent_coef": 0.06851231306791306,
    "learning_rate": 0.001
  },
  {
    "episode": 12046,
    "reward": 88.905551,
    "length": 67,
    "time": 175576.273163,
    "actor_loss": -71.70355224609375,
    "critic_loss": 2.781048059463501,
    "ent_coef": 0.07242555171251297,
    "learning_rate": 0.001
  },
  {
    "episode": 12047,
    "reward": 90.978244,
    "length": 61,
    "time": 175590.957108,
    "actor_loss": -65.59095001220703,
    "critic_loss": 5.113343238830566,
    "ent_coef": 0.07543868571519852,
    "learning_rate": 0.001
  },
  {
    "episode": 12048,
    "reward": 88.64824,
    "length": 67,
    "time": 175605.541397,
    "actor_loss": -71.15325927734375,
    "critic_loss": 5.554878234863281,
    "ent_coef": 0.08145135641098022,
    "learning_rate": 0.001
  },
  {
    "episode": 12049,
    "reward": 91.82102,
    "length": 59,
    "time": 175617.793357,
    "actor_loss": -70.38746643066406,
    "critic_loss": 1.6728546619415283,
    "ent_coef": 0.08132421970367432,
    "learning_rate": 0.001
  },
  {
    "episode": 12050,
    "reward": 90.268856,
    "length": 63,
    "time": 175631.107126,
    "actor_loss": -71.33261108398438,
    "critic_loss": 209.811767578125,
    "ent_coef": 0.07838669419288635,
    "learning_rate": 0.001
  },
  {
    "episode": 12051,
    "reward": 89.605885,
    "length": 63,
    "time": 175644.579261,
    "actor_loss": -69.33087158203125,
    "critic_loss": 45.63282775878906,
    "ent_coef": 0.07797839492559433,
    "learning_rate": 0.001
  },
  {
    "episode": 12052,
    "reward": 84.119281,
    "length": 75,
    "time": 175658.402631,
    "actor_loss": -69.21800231933594,
    "critic_loss": 25.01557159423828,
    "ent_coef": 0.07430674135684967,
    "learning_rate": 0.001
  },
  {
    "episode": 12053,
    "reward": 88.64022,
    "length": 66,
    "time": 175670.750101,
    "actor_loss": -70.75726318359375,
    "critic_loss": 3.9749555587768555,
    "ent_coef": 0.07366350293159485,
    "learning_rate": 0.001
  },
  {
    "episode": 12054,
    "reward": 88.041603,
    "length": 68,
    "time": 175684.499402,
    "actor_loss": -65.97142028808594,
    "critic_loss": 117.97402954101562,
    "ent_coef": 0.07472603768110275,
    "learning_rate": 0.001
  },
  {
    "episode": 12055,
    "reward": 90.010698,
    "length": 63,
    "time": 175696.327137,
    "actor_loss": -74.63919067382812,
    "critic_loss": 5.622006416320801,
    "ent_coef": 0.07444159686565399,
    "learning_rate": 0.001
  },
  {
    "episode": 12056,
    "reward": 88.211892,
    "length": 66,
    "time": 175709.183928,
    "actor_loss": -69.4368896484375,
    "critic_loss": 7.2224202156066895,
    "ent_coef": 0.07421064376831055,
    "learning_rate": 0.001
  },
  {
    "episode": 12057,
    "reward": 92.293809,
    "length": 59,
    "time": 175723.938603,
    "actor_loss": -66.65336608886719,
    "critic_loss": 3.672769784927368,
    "ent_coef": 0.07837959378957748,
    "learning_rate": 0.001
  },
  {
    "episode": 12058,
    "reward": 90.377459,
    "length": 62,
    "time": 175736.357282,
    "actor_loss": -70.40390014648438,
    "critic_loss": 4.368332862854004,
    "ent_coef": 0.07842525839805603,
    "learning_rate": 0.001
  },
  {
    "episode": 12059,
    "reward": 90.381742,
    "length": 61,
    "time": 175748.517029,
    "actor_loss": -63.64630126953125,
    "critic_loss": 12.971964836120605,
    "ent_coef": 0.07652559131383896,
    "learning_rate": 0.001
  },
  {
    "episode": 12060,
    "reward": 90.980602,
    "length": 61,
    "time": 175762.023952,
    "actor_loss": -69.45730590820312,
    "critic_loss": 23.105464935302734,
    "ent_coef": 0.07575541734695435,
    "learning_rate": 0.001
  },
  {
    "episode": 12061,
    "reward": 90.350345,
    "length": 62,
    "time": 175775.542168,
    "actor_loss": -69.02224731445312,
    "critic_loss": 9.099712371826172,
    "ent_coef": 0.07424486428499222,
    "learning_rate": 0.001
  },
  {
    "episode": 12062,
    "reward": 89.35069,
    "length": 65,
    "time": 175790.640069,
    "actor_loss": -71.56912994384766,
    "critic_loss": 5.120442867279053,
    "ent_coef": 0.07186053693294525,
    "learning_rate": 0.001
  },
  {
    "episode": 12063,
    "reward": 90.372094,
    "length": 62,
    "time": 175805.18707,
    "actor_loss": -70.15632629394531,
    "critic_loss": 16.724790573120117,
    "ent_coef": 0.07181555032730103,
    "learning_rate": 0.001
  },
  {
    "episode": 12064,
    "reward": 90.820431,
    "length": 60,
    "time": 175818.467577,
    "actor_loss": -71.55943298339844,
    "critic_loss": 5.851712226867676,
    "ent_coef": 0.07127082347869873,
    "learning_rate": 0.001
  },
  {
    "episode": 12065,
    "reward": 91.390635,
    "length": 60,
    "time": 175830.09673,
    "actor_loss": -67.52506256103516,
    "critic_loss": 3.793109178543091,
    "ent_coef": 0.07386940717697144,
    "learning_rate": 0.001
  },
  {
    "episode": 12066,
    "reward": 87.39266,
    "length": 73,
    "time": 175844.078357,
    "actor_loss": -62.637611389160156,
    "critic_loss": 11.333282470703125,
    "ent_coef": 0.07411471754312515,
    "learning_rate": 0.001
  },
  {
    "episode": 12067,
    "reward": 90.425708,
    "length": 63,
    "time": 175856.017275,
    "actor_loss": -70.2266845703125,
    "critic_loss": 5.662907600402832,
    "ent_coef": 0.07348822802305222,
    "learning_rate": 0.001
  },
  {
    "episode": 12068,
    "reward": 91.736784,
    "length": 60,
    "time": 175867.509623,
    "actor_loss": -70.26008605957031,
    "critic_loss": 11.26250171661377,
    "ent_coef": 0.07466995716094971,
    "learning_rate": 0.001
  },
  {
    "episode": 12069,
    "reward": 91.671312,
    "length": 60,
    "time": 175878.961637,
    "actor_loss": -72.39063262939453,
    "critic_loss": 7.5419464111328125,
    "ent_coef": 0.08040963113307953,
    "learning_rate": 0.001
  },
  {
    "episode": 12070,
    "reward": 88.625561,
    "length": 65,
    "time": 175892.573501,
    "actor_loss": -67.63973999023438,
    "critic_loss": 7.905406475067139,
    "ent_coef": 0.08155445754528046,
    "learning_rate": 0.001
  },
  {
    "episode": 12071,
    "reward": 90.855336,
    "length": 61,
    "time": 175906.093077,
    "actor_loss": -72.77738189697266,
    "critic_loss": 13.378433227539062,
    "ent_coef": 0.0854516476392746,
    "learning_rate": 0.001
  },
  {
    "episode": 12072,
    "reward": 88.864101,
    "length": 64,
    "time": 175919.805709,
    "actor_loss": -72.35039520263672,
    "critic_loss": 5.640064239501953,
    "ent_coef": 0.0842948779463768,
    "learning_rate": 0.001
  },
  {
    "episode": 12073,
    "reward": 90.062397,
    "length": 63,
    "time": 175934.262309,
    "actor_loss": -72.362060546875,
    "critic_loss": 5.99275016784668,
    "ent_coef": 0.0812116414308548,
    "learning_rate": 0.001
  },
  {
    "episode": 12074,
    "reward": 90.868148,
    "length": 61,
    "time": 175949.652493,
    "actor_loss": -70.207763671875,
    "critic_loss": 8.939685821533203,
    "ent_coef": 0.07995381206274033,
    "learning_rate": 0.001
  },
  {
    "episode": 12075,
    "reward": 90.839095,
    "length": 62,
    "time": 175962.787009,
    "actor_loss": -66.93505859375,
    "critic_loss": 4.610258102416992,
    "ent_coef": 0.08074218779802322,
    "learning_rate": 0.001
  },
  {
    "episode": 12076,
    "reward": 89.53316,
    "length": 69,
    "time": 175976.215134,
    "actor_loss": -72.59587860107422,
    "critic_loss": 5.385306358337402,
    "ent_coef": 0.08051696419715881,
    "learning_rate": 0.001
  },
  {
    "episode": 12077,
    "reward": 87.722145,
    "length": 67,
    "time": 175990.39617,
    "actor_loss": -71.16156005859375,
    "critic_loss": 64.18109893798828,
    "ent_coef": 0.07466283440589905,
    "learning_rate": 0.001
  },
  {
    "episode": 12078,
    "reward": 89.839107,
    "length": 64,
    "time": 176002.18539,
    "actor_loss": -67.36109924316406,
    "critic_loss": 13.815380096435547,
    "ent_coef": 0.07187457382678986,
    "learning_rate": 0.001
  },
  {
    "episode": 12079,
    "reward": 90.044656,
    "length": 63,
    "time": 176016.437783,
    "actor_loss": -64.1244888305664,
    "critic_loss": 11.10805606842041,
    "ent_coef": 0.07252176851034164,
    "learning_rate": 0.001
  },
  {
    "episode": 12080,
    "reward": 87.368731,
    "length": 68,
    "time": 176029.685786,
    "actor_loss": -68.50226593017578,
    "critic_loss": 12.458911895751953,
    "ent_coef": 0.06878992915153503,
    "learning_rate": 0.001
  },
  {
    "episode": 12081,
    "reward": 90.646923,
    "length": 63,
    "time": 176042.629522,
    "actor_loss": -74.8648681640625,
    "critic_loss": 3.641552448272705,
    "ent_coef": 0.06929650157690048,
    "learning_rate": 0.001
  },
  {
    "episode": 12082,
    "reward": 88.409955,
    "length": 66,
    "time": 176055.294183,
    "actor_loss": -67.29077911376953,
    "critic_loss": 266.3214111328125,
    "ent_coef": 0.06787633895874023,
    "learning_rate": 0.001
  },
  {
    "episode": 12083,
    "reward": 88.64254,
    "length": 67,
    "time": 176068.197863,
    "actor_loss": -73.9507064819336,
    "critic_loss": 5.109831809997559,
    "ent_coef": 0.06399741768836975,
    "learning_rate": 0.001
  },
  {
    "episode": 12084,
    "reward": 90.086961,
    "length": 63,
    "time": 176081.307198,
    "actor_loss": -69.32177734375,
    "critic_loss": 7.964025974273682,
    "ent_coef": 0.061682477593421936,
    "learning_rate": 0.001
  },
  {
    "episode": 12085,
    "reward": 87.964576,
    "length": 70,
    "time": 176093.863017,
    "actor_loss": -70.2052230834961,
    "critic_loss": 4.982883930206299,
    "ent_coef": 0.0579838789999485,
    "learning_rate": 0.001
  },
  {
    "episode": 12086,
    "reward": 89.802597,
    "length": 64,
    "time": 176105.971503,
    "actor_loss": -65.30604553222656,
    "critic_loss": 16.151752471923828,
    "ent_coef": 0.05816305801272392,
    "learning_rate": 0.001
  },
  {
    "episode": 12087,
    "reward": 88.321293,
    "length": 71,
    "time": 176119.820027,
    "actor_loss": -64.85700988769531,
    "critic_loss": 4.811430931091309,
    "ent_coef": 0.05805037543177605,
    "learning_rate": 0.001
  },
  {
    "episode": 12088,
    "reward": 91.80358,
    "length": 61,
    "time": 176135.029527,
    "actor_loss": -66.72563934326172,
    "critic_loss": 6.175384521484375,
    "ent_coef": 0.061678461730480194,
    "learning_rate": 0.001
  },
  {
    "episode": 12089,
    "reward": 90.649379,
    "length": 62,
    "time": 176146.553208,
    "actor_loss": -65.48281860351562,
    "critic_loss": 5.5995073318481445,
    "ent_coef": 0.0635821595788002,
    "learning_rate": 0.001
  },
  {
    "episode": 12090,
    "reward": 91.069954,
    "length": 61,
    "time": 176157.949626,
    "actor_loss": -69.83146667480469,
    "critic_loss": 7.121341705322266,
    "ent_coef": 0.06474634259939194,
    "learning_rate": 0.001
  },
  {
    "episode": 12091,
    "reward": 87.719486,
    "length": 69,
    "time": 176170.655509,
    "actor_loss": -71.04989624023438,
    "critic_loss": 3.4354472160339355,
    "ent_coef": 0.06406588852405548,
    "learning_rate": 0.001
  },
  {
    "episode": 12092,
    "reward": 90.617172,
    "length": 67,
    "time": 176182.998317,
    "actor_loss": -70.57283020019531,
    "critic_loss": 5.4594831466674805,
    "ent_coef": 0.06437082588672638,
    "learning_rate": 0.001
  },
  {
    "episode": 12093,
    "reward": 89.082164,
    "length": 66,
    "time": 176196.184221,
    "actor_loss": -69.2632064819336,
    "critic_loss": 16.739295959472656,
    "ent_coef": 0.06352954357862473,
    "learning_rate": 0.001
  },
  {
    "episode": 12094,
    "reward": 90.454651,
    "length": 62,
    "time": 176207.693443,
    "actor_loss": -66.46359252929688,
    "critic_loss": 2.334944486618042,
    "ent_coef": 0.06384885311126709,
    "learning_rate": 0.001
  },
  {
    "episode": 12095,
    "reward": 90.739208,
    "length": 62,
    "time": 176222.614845,
    "actor_loss": -72.69627380371094,
    "critic_loss": 9.818954467773438,
    "ent_coef": 0.06556665152311325,
    "learning_rate": 0.001
  },
  {
    "episode": 12096,
    "reward": 89.590526,
    "length": 64,
    "time": 176237.685961,
    "actor_loss": -68.23294067382812,
    "critic_loss": 2.9314327239990234,
    "ent_coef": 0.06508920341730118,
    "learning_rate": 0.001
  },
  {
    "episode": 12097,
    "reward": 89.817829,
    "length": 63,
    "time": 176251.377624,
    "actor_loss": -67.47252655029297,
    "critic_loss": 9.300363540649414,
    "ent_coef": 0.06535377353429794,
    "learning_rate": 0.001
  },
  {
    "episode": 12098,
    "reward": 88.476793,
    "length": 65,
    "time": 176263.869853,
    "actor_loss": -71.08412170410156,
    "critic_loss": 6.098105430603027,
    "ent_coef": 0.06704606115818024,
    "learning_rate": 0.001
  },
  {
    "episode": 12099,
    "reward": 91.107348,
    "length": 63,
    "time": 176276.143992,
    "actor_loss": -71.00470733642578,
    "critic_loss": 10.747198104858398,
    "ent_coef": 0.06693941354751587,
    "learning_rate": 0.001
  },
  {
    "episode": 12100,
    "reward": 91.722311,
    "length": 60,
    "time": 176289.515735,
    "actor_loss": -66.81171417236328,
    "critic_loss": 7.119801998138428,
    "ent_coef": 0.06960111856460571,
    "learning_rate": 0.001
  },
  {
    "episode": 12101,
    "reward": 90.959672,
    "length": 62,
    "time": 176302.080081,
    "actor_loss": -67.45050048828125,
    "critic_loss": 7.301816940307617,
    "ent_coef": 0.07034379243850708,
    "learning_rate": 0.001
  },
  {
    "episode": 12102,
    "reward": 89.171046,
    "length": 66,
    "time": 176318.69845,
    "actor_loss": -66.3994369506836,
    "critic_loss": 4.165423393249512,
    "ent_coef": 0.06617431342601776,
    "learning_rate": 0.001
  },
  {
    "episode": 12103,
    "reward": 90.786395,
    "length": 63,
    "time": 176332.92654,
    "actor_loss": -70.30900573730469,
    "critic_loss": 108.18228149414062,
    "ent_coef": 0.0651383250951767,
    "learning_rate": 0.001
  },
  {
    "episode": 12104,
    "reward": 89.156967,
    "length": 66,
    "time": 176347.08485,
    "actor_loss": -63.983985900878906,
    "critic_loss": 5.298785209655762,
    "ent_coef": 0.0660465732216835,
    "learning_rate": 0.001
  },
  {
    "episode": 12105,
    "reward": 87.892398,
    "length": 71,
    "time": 176363.758388,
    "actor_loss": -70.44215393066406,
    "critic_loss": 109.56925964355469,
    "ent_coef": 0.06799720972776413,
    "learning_rate": 0.001
  },
  {
    "episode": 12106,
    "reward": 90.57836,
    "length": 64,
    "time": 176375.291135,
    "actor_loss": -64.47543334960938,
    "critic_loss": 3.7234601974487305,
    "ent_coef": 0.06715228408575058,
    "learning_rate": 0.001
  },
  {
    "episode": 12107,
    "reward": 81.822784,
    "length": 79,
    "time": 176389.149109,
    "actor_loss": -67.89036560058594,
    "critic_loss": 63.599571228027344,
    "ent_coef": 0.06743995100259781,
    "learning_rate": 0.001
  },
  {
    "episode": 12108,
    "reward": 88.726615,
    "length": 67,
    "time": 176404.330286,
    "actor_loss": -71.25619506835938,
    "critic_loss": 86.55348205566406,
    "ent_coef": 0.0665213093161583,
    "learning_rate": 0.001
  },
  {
    "episode": 12109,
    "reward": 91.608955,
    "length": 60,
    "time": 176416.946574,
    "actor_loss": -65.07796478271484,
    "critic_loss": 40.222808837890625,
    "ent_coef": 0.0684126764535904,
    "learning_rate": 0.001
  },
  {
    "episode": 12110,
    "reward": 90.028862,
    "length": 64,
    "time": 176435.30358,
    "actor_loss": -72.41807556152344,
    "critic_loss": 22.274547576904297,
    "ent_coef": 0.07047926634550095,
    "learning_rate": 0.001
  },
  {
    "episode": 12111,
    "reward": 89.652227,
    "length": 67,
    "time": 176449.38247,
    "actor_loss": -65.04458618164062,
    "critic_loss": 5.862191200256348,
    "ent_coef": 0.07072702795267105,
    "learning_rate": 0.001
  },
  {
    "episode": 12112,
    "reward": 90.259696,
    "length": 62,
    "time": 176461.185416,
    "actor_loss": -72.14581298828125,
    "critic_loss": 21.03251075744629,
    "ent_coef": 0.06859398633241653,
    "learning_rate": 0.001
  },
  {
    "episode": 12113,
    "reward": 88.261499,
    "length": 67,
    "time": 176473.848766,
    "actor_loss": -70.565673828125,
    "critic_loss": 3.471011161804199,
    "ent_coef": 0.06271544098854065,
    "learning_rate": 0.001
  },
  {
    "episode": 12114,
    "reward": 89.876695,
    "length": 64,
    "time": 176487.722098,
    "actor_loss": -67.9134292602539,
    "critic_loss": 2.9196903705596924,
    "ent_coef": 0.060047898441553116,
    "learning_rate": 0.001
  },
  {
    "episode": 12115,
    "reward": 88.963733,
    "length": 67,
    "time": 176500.855575,
    "actor_loss": -68.13533020019531,
    "critic_loss": 72.37214660644531,
    "ent_coef": 0.06168815493583679,
    "learning_rate": 0.001
  },
  {
    "episode": 12116,
    "reward": 90.08821,
    "length": 64,
    "time": 176515.403805,
    "actor_loss": -70.28146362304688,
    "critic_loss": 14.254081726074219,
    "ent_coef": 0.06086358800530434,
    "learning_rate": 0.001
  },
  {
    "episode": 12117,
    "reward": 89.107965,
    "length": 66,
    "time": 176528.848369,
    "actor_loss": -69.63397979736328,
    "critic_loss": 7.005571365356445,
    "ent_coef": 0.05971691384911537,
    "learning_rate": 0.001
  },
  {
    "episode": 12118,
    "reward": 86.929641,
    "length": 69,
    "time": 176544.412851,
    "actor_loss": -72.95909118652344,
    "critic_loss": 27.550405502319336,
    "ent_coef": 0.056369420140981674,
    "learning_rate": 0.001
  },
  {
    "episode": 12119,
    "reward": 87.98674,
    "length": 66,
    "time": 176558.963896,
    "actor_loss": -66.62898254394531,
    "critic_loss": 4.734591007232666,
    "ent_coef": 0.05719122290611267,
    "learning_rate": 0.001
  },
  {
    "episode": 12120,
    "reward": 90.349935,
    "length": 64,
    "time": 176573.553403,
    "actor_loss": -69.73088836669922,
    "critic_loss": 10.681373596191406,
    "ent_coef": 0.05729984864592552,
    "learning_rate": 0.001
  },
  {
    "episode": 12121,
    "reward": 90.301541,
    "length": 61,
    "time": 176586.187433,
    "actor_loss": -67.80529022216797,
    "critic_loss": 4.868265151977539,
    "ent_coef": 0.05683332681655884,
    "learning_rate": 0.001
  },
  {
    "episode": 12122,
    "reward": 88.643627,
    "length": 70,
    "time": 176599.180587,
    "actor_loss": -70.05155944824219,
    "critic_loss": 6.9855852127075195,
    "ent_coef": 0.0549418069422245,
    "learning_rate": 0.001
  },
  {
    "episode": 12123,
    "reward": 90.252167,
    "length": 62,
    "time": 176611.343056,
    "actor_loss": -64.5177230834961,
    "critic_loss": 8.438119888305664,
    "ent_coef": 0.055192362517118454,
    "learning_rate": 0.001
  },
  {
    "episode": 12124,
    "reward": 81.948363,
    "length": 83,
    "time": 176626.401087,
    "actor_loss": -68.48983764648438,
    "critic_loss": 111.98076629638672,
    "ent_coef": 0.053879447281360626,
    "learning_rate": 0.001
  },
  {
    "episode": 12125,
    "reward": 89.60403,
    "length": 64,
    "time": 176640.007065,
    "actor_loss": -62.26380920410156,
    "critic_loss": 64.15825653076172,
    "ent_coef": 0.05306569114327431,
    "learning_rate": 0.001
  },
  {
    "episode": 12126,
    "reward": 90.153473,
    "length": 63,
    "time": 176654.205884,
    "actor_loss": -68.26017761230469,
    "critic_loss": 3.3876874446868896,
    "ent_coef": 0.05484085530042648,
    "learning_rate": 0.001
  },
  {
    "episode": 12127,
    "reward": 90.664342,
    "length": 62,
    "time": 176665.654503,
    "actor_loss": -71.5428466796875,
    "critic_loss": 12.062517166137695,
    "ent_coef": 0.056202396750450134,
    "learning_rate": 0.001
  },
  {
    "episode": 12128,
    "reward": 87.024711,
    "length": 69,
    "time": 176678.377849,
    "actor_loss": -67.32691955566406,
    "critic_loss": 4.6371612548828125,
    "ent_coef": 0.05640735477209091,
    "learning_rate": 0.001
  },
  {
    "episode": 12129,
    "reward": 88.924824,
    "length": 66,
    "time": 176690.667927,
    "actor_loss": -65.203369140625,
    "critic_loss": 33.679622650146484,
    "ent_coef": 0.058550264686346054,
    "learning_rate": 0.001
  },
  {
    "episode": 12130,
    "reward": 90.490172,
    "length": 63,
    "time": 176705.108676,
    "actor_loss": -71.2510986328125,
    "critic_loss": 4.42075777053833,
    "ent_coef": 0.06322401762008667,
    "learning_rate": 0.001
  },
  {
    "episode": 12131,
    "reward": 88.070215,
    "length": 67,
    "time": 176721.141466,
    "actor_loss": -67.04713439941406,
    "critic_loss": 17.143218994140625,
    "ent_coef": 0.06177664175629616,
    "learning_rate": 0.001
  },
  {
    "episode": 12132,
    "reward": 90.143653,
    "length": 63,
    "time": 176733.906815,
    "actor_loss": -65.78935241699219,
    "critic_loss": 5.245992660522461,
    "ent_coef": 0.06150126829743385,
    "learning_rate": 0.001
  },
  {
    "episode": 12133,
    "reward": 87.135103,
    "length": 67,
    "time": 176746.415214,
    "actor_loss": -67.53355407714844,
    "critic_loss": 5.206247329711914,
    "ent_coef": 0.06066511198878288,
    "learning_rate": 0.001
  },
  {
    "episode": 12134,
    "reward": 81.771596,
    "length": 80,
    "time": 176761.41495,
    "actor_loss": -67.9930191040039,
    "critic_loss": 6.032430648803711,
    "ent_coef": 0.05657019838690758,
    "learning_rate": 0.001
  },
  {
    "episode": 12135,
    "reward": 88.555182,
    "length": 71,
    "time": 176776.630554,
    "actor_loss": -66.88648986816406,
    "critic_loss": 6.754610061645508,
    "ent_coef": 0.055943526327610016,
    "learning_rate": 0.001
  },
  {
    "episode": 12136,
    "reward": 86.067471,
    "length": 71,
    "time": 176789.164604,
    "actor_loss": -69.43424224853516,
    "critic_loss": 44.097755432128906,
    "ent_coef": 0.053095340728759766,
    "learning_rate": 0.001
  },
  {
    "episode": 12137,
    "reward": 89.466761,
    "length": 64,
    "time": 176800.686004,
    "actor_loss": -70.78849029541016,
    "critic_loss": 3.3224802017211914,
    "ent_coef": 0.05375814065337181,
    "learning_rate": 0.001
  },
  {
    "episode": 12138,
    "reward": 85.167201,
    "length": 77,
    "time": 176814.131378,
    "actor_loss": -68.96823120117188,
    "critic_loss": 4.871991157531738,
    "ent_coef": 0.05235908925533295,
    "learning_rate": 0.001
  },
  {
    "episode": 12139,
    "reward": 89.337642,
    "length": 68,
    "time": 176829.053761,
    "actor_loss": -64.14112854003906,
    "critic_loss": 34.46772384643555,
    "ent_coef": 0.056283097714185715,
    "learning_rate": 0.001
  },
  {
    "episode": 12140,
    "reward": 89.258026,
    "length": 68,
    "time": 176842.215071,
    "actor_loss": -71.70852661132812,
    "critic_loss": 7.019777774810791,
    "ent_coef": 0.056706398725509644,
    "learning_rate": 0.001
  },
  {
    "episode": 12141,
    "reward": 87.11459,
    "length": 70,
    "time": 176856.52539,
    "actor_loss": -65.71539306640625,
    "critic_loss": 4.834190368652344,
    "ent_coef": 0.056192509829998016,
    "learning_rate": 0.001
  },
  {
    "episode": 12142,
    "reward": 89.362275,
    "length": 65,
    "time": 176869.027314,
    "actor_loss": -68.52195739746094,
    "critic_loss": 4.7287774085998535,
    "ent_coef": 0.05551626905798912,
    "learning_rate": 0.001
  },
  {
    "episode": 12143,
    "reward": 88.179405,
    "length": 72,
    "time": 176883.4077,
    "actor_loss": -72.20115661621094,
    "critic_loss": 2.6676254272460938,
    "ent_coef": 0.057103194296360016,
    "learning_rate": 0.001
  },
  {
    "episode": 12144,
    "reward": 90.632982,
    "length": 64,
    "time": 176897.516539,
    "actor_loss": -65.89349365234375,
    "critic_loss": 20.265811920166016,
    "ent_coef": 0.05715705081820488,
    "learning_rate": 0.001
  },
  {
    "episode": 12145,
    "reward": 87.120378,
    "length": 69,
    "time": 176909.760838,
    "actor_loss": -69.0208740234375,
    "critic_loss": 6.661975860595703,
    "ent_coef": 0.05888728052377701,
    "learning_rate": 0.001
  },
  {
    "episode": 12146,
    "reward": 90.099748,
    "length": 64,
    "time": 176921.531446,
    "actor_loss": -70.37818908691406,
    "critic_loss": 8.461557388305664,
    "ent_coef": 0.059897564351558685,
    "learning_rate": 0.001
  },
  {
    "episode": 12147,
    "reward": 87.303268,
    "length": 71,
    "time": 176937.249698,
    "actor_loss": -62.56945037841797,
    "critic_loss": 4.819998741149902,
    "ent_coef": 0.058900874108076096,
    "learning_rate": 0.001
  },
  {
    "episode": 12148,
    "reward": 86.805904,
    "length": 68,
    "time": 176949.210035,
    "actor_loss": -68.8797607421875,
    "critic_loss": 8.532644271850586,
    "ent_coef": 0.05908168479800224,
    "learning_rate": 0.001
  },
  {
    "episode": 12149,
    "reward": 90.285618,
    "length": 62,
    "time": 176961.56148,
    "actor_loss": -60.735076904296875,
    "critic_loss": 9.53921127319336,
    "ent_coef": 0.06272689253091812,
    "learning_rate": 0.001
  },
  {
    "episode": 12150,
    "reward": 87.550937,
    "length": 69,
    "time": 176973.969118,
    "actor_loss": -65.552978515625,
    "critic_loss": 10.757323265075684,
    "ent_coef": 0.06434962898492813,
    "learning_rate": 0.001
  },
  {
    "episode": 12151,
    "reward": 89.15295,
    "length": 64,
    "time": 176986.411282,
    "actor_loss": -68.36885833740234,
    "critic_loss": 17.871315002441406,
    "ent_coef": 0.06669238954782486,
    "learning_rate": 0.001
  },
  {
    "episode": 12152,
    "reward": 90.90566,
    "length": 61,
    "time": 176997.529701,
    "actor_loss": -68.56939697265625,
    "critic_loss": 2.8874146938323975,
    "ent_coef": 0.06698724627494812,
    "learning_rate": 0.001
  },
  {
    "episode": 12153,
    "reward": 92.593275,
    "length": 58,
    "time": 177008.594955,
    "actor_loss": -63.47892379760742,
    "critic_loss": 6.133467674255371,
    "ent_coef": 0.06939081847667694,
    "learning_rate": 0.001
  },
  {
    "episode": 12154,
    "reward": 91.144905,
    "length": 61,
    "time": 177021.22512,
    "actor_loss": -70.57650756835938,
    "critic_loss": 12.038370132446289,
    "ent_coef": 0.07031363993883133,
    "learning_rate": 0.001
  },
  {
    "episode": 12155,
    "reward": 86.82225,
    "length": 69,
    "time": 177035.102867,
    "actor_loss": -66.92881774902344,
    "critic_loss": 105.0790023803711,
    "ent_coef": 0.06888367235660553,
    "learning_rate": 0.001
  },
  {
    "episode": 12156,
    "reward": 93.059123,
    "length": 56,
    "time": 177049.222848,
    "actor_loss": -69.04193878173828,
    "critic_loss": 12.600797653198242,
    "ent_coef": 0.07129403948783875,
    "learning_rate": 0.001
  },
  {
    "episode": 12157,
    "reward": 92.33872,
    "length": 59,
    "time": 177061.646441,
    "actor_loss": -71.22135162353516,
    "critic_loss": 3.220916748046875,
    "ent_coef": 0.0765211209654808,
    "learning_rate": 0.001
  },
  {
    "episode": 12158,
    "reward": 90.802899,
    "length": 65,
    "time": 177077.719167,
    "actor_loss": -70.23495483398438,
    "critic_loss": 2.7599008083343506,
    "ent_coef": 0.07908295840024948,
    "learning_rate": 0.001
  },
  {
    "episode": 12159,
    "reward": 90.41384,
    "length": 67,
    "time": 177091.901863,
    "actor_loss": -70.35124206542969,
    "critic_loss": 4.858919143676758,
    "ent_coef": 0.0752946138381958,
    "learning_rate": 0.001
  },
  {
    "episode": 12160,
    "reward": 91.237963,
    "length": 62,
    "time": 177104.412021,
    "actor_loss": -66.61019134521484,
    "critic_loss": 5.017755031585693,
    "ent_coef": 0.07442612200975418,
    "learning_rate": 0.001
  },
  {
    "episode": 12161,
    "reward": 86.961387,
    "length": 72,
    "time": 177118.5764,
    "actor_loss": -66.12055969238281,
    "critic_loss": 11.962974548339844,
    "ent_coef": 0.0723767951130867,
    "learning_rate": 0.001
  },
  {
    "episode": 12162,
    "reward": 90.117779,
    "length": 63,
    "time": 177130.926619,
    "actor_loss": -62.40447235107422,
    "critic_loss": 2.012204170227051,
    "ent_coef": 0.06814078241586685,
    "learning_rate": 0.001
  },
  {
    "episode": 12163,
    "reward": 89.613226,
    "length": 69,
    "time": 177145.166494,
    "actor_loss": -66.56309509277344,
    "critic_loss": 5.189101219177246,
    "ent_coef": 0.0695091113448143,
    "learning_rate": 0.001
  },
  {
    "episode": 12164,
    "reward": 91.906344,
    "length": 59,
    "time": 177159.359733,
    "actor_loss": -72.52339935302734,
    "critic_loss": 129.57763671875,
    "ent_coef": 0.07127518951892853,
    "learning_rate": 0.001
  },
  {
    "episode": 12165,
    "reward": 88.366701,
    "length": 66,
    "time": 177171.650182,
    "actor_loss": -64.2496337890625,
    "critic_loss": 7.288548469543457,
    "ent_coef": 0.07118695229291916,
    "learning_rate": 0.001
  },
  {
    "episode": 12166,
    "reward": 87.854425,
    "length": 69,
    "time": 177184.335407,
    "actor_loss": -68.9381103515625,
    "critic_loss": 15.672250747680664,
    "ent_coef": 0.06851086020469666,
    "learning_rate": 0.001
  },
  {
    "episode": 12167,
    "reward": 86.468212,
    "length": 70,
    "time": 177199.66049,
    "actor_loss": -70.72299194335938,
    "critic_loss": 7.052348613739014,
    "ent_coef": 0.06478865444660187,
    "learning_rate": 0.001
  },
  {
    "episode": 12168,
    "reward": 88.86311,
    "length": 64,
    "time": 177212.012007,
    "actor_loss": -66.15983581542969,
    "critic_loss": 5.693724632263184,
    "ent_coef": 0.06582192331552505,
    "learning_rate": 0.001
  },
  {
    "episode": 12169,
    "reward": 87.672654,
    "length": 67,
    "time": 177224.988453,
    "actor_loss": -67.54283142089844,
    "critic_loss": 23.085636138916016,
    "ent_coef": 0.06568824499845505,
    "learning_rate": 0.001
  },
  {
    "episode": 12170,
    "reward": 87.661995,
    "length": 68,
    "time": 177239.791905,
    "actor_loss": -67.957275390625,
    "critic_loss": 4.654305458068848,
    "ent_coef": 0.06532062590122223,
    "learning_rate": 0.001
  },
  {
    "episode": 12171,
    "reward": 88.408341,
    "length": 66,
    "time": 177251.896906,
    "actor_loss": -72.35792541503906,
    "critic_loss": 4.284919738769531,
    "ent_coef": 0.06283921748399734,
    "learning_rate": 0.001
  },
  {
    "episode": 12172,
    "reward": 86.702229,
    "length": 71,
    "time": 177264.226124,
    "actor_loss": -66.81932067871094,
    "critic_loss": 37.830108642578125,
    "ent_coef": 0.05883312597870827,
    "learning_rate": 0.001
  },
  {
    "episode": 12173,
    "reward": 90.087531,
    "length": 63,
    "time": 177278.14974,
    "actor_loss": -72.52091217041016,
    "critic_loss": 65.70235443115234,
    "ent_coef": 0.05699041485786438,
    "learning_rate": 0.001
  },
  {
    "episode": 12174,
    "reward": 83.229385,
    "length": 81,
    "time": 177292.908547,
    "actor_loss": -61.75297164916992,
    "critic_loss": 14.027444839477539,
    "ent_coef": 0.05408775806427002,
    "learning_rate": 0.001
  },
  {
    "episode": 12175,
    "reward": 88.328592,
    "length": 67,
    "time": 177304.656226,
    "actor_loss": -70.07715606689453,
    "critic_loss": 6.627695560455322,
    "ent_coef": 0.051968660205602646,
    "learning_rate": 0.001
  },
  {
    "episode": 12176,
    "reward": 87.181343,
    "length": 68,
    "time": 177316.935625,
    "actor_loss": -68.20008850097656,
    "critic_loss": 3.6421141624450684,
    "ent_coef": 0.050240833312273026,
    "learning_rate": 0.001
  },
  {
    "episode": 12177,
    "reward": 88.567475,
    "length": 66,
    "time": 177328.788706,
    "actor_loss": -68.17129516601562,
    "critic_loss": 4.718315601348877,
    "ent_coef": 0.051603592932224274,
    "learning_rate": 0.001
  },
  {
    "episode": 12178,
    "reward": 87.644667,
    "length": 73,
    "time": 177341.354305,
    "actor_loss": -71.1102294921875,
    "critic_loss": 117.39338684082031,
    "ent_coef": 0.052430640906095505,
    "learning_rate": 0.001
  },
  {
    "episode": 12179,
    "reward": 89.267523,
    "length": 68,
    "time": 177355.239923,
    "actor_loss": -71.30096435546875,
    "critic_loss": 7.10665225982666,
    "ent_coef": 0.056326765567064285,
    "learning_rate": 0.001
  },
  {
    "episode": 12180,
    "reward": 84.171244,
    "length": 65,
    "time": 177366.771168,
    "actor_loss": -64.3367691040039,
    "critic_loss": 7.618077754974365,
    "ent_coef": 0.05892065912485123,
    "learning_rate": 0.001
  },
  {
    "episode": 12181,
    "reward": 92.08983,
    "length": 59,
    "time": 177379.05221,
    "actor_loss": -66.48654174804688,
    "critic_loss": 2.9766266345977783,
    "ent_coef": 0.06289715319871902,
    "learning_rate": 0.001
  },
  {
    "episode": 12182,
    "reward": 91.36201,
    "length": 61,
    "time": 177390.057096,
    "actor_loss": -65.85529327392578,
    "critic_loss": 2.546415328979492,
    "ent_coef": 0.06699839234352112,
    "learning_rate": 0.001
  },
  {
    "episode": 12183,
    "reward": 89.487545,
    "length": 65,
    "time": 177401.705468,
    "actor_loss": -69.96080017089844,
    "critic_loss": 4.517014980316162,
    "ent_coef": 0.07555831968784332,
    "learning_rate": 0.001
  },
  {
    "episode": 12184,
    "reward": 88.046986,
    "length": 71,
    "time": 177414.418396,
    "actor_loss": -69.43931579589844,
    "critic_loss": 7.308450698852539,
    "ent_coef": 0.07817462086677551,
    "learning_rate": 0.001
  },
  {
    "episode": 12185,
    "reward": 88.252522,
    "length": 67,
    "time": 177428.966438,
    "actor_loss": -64.0284423828125,
    "critic_loss": 118.8692398071289,
    "ent_coef": 0.07774607837200165,
    "learning_rate": 0.001
  },
  {
    "episode": 12186,
    "reward": 86.759002,
    "length": 69,
    "time": 177442.120572,
    "actor_loss": -66.64972686767578,
    "critic_loss": 5.999334335327148,
    "ent_coef": 0.07837338745594025,
    "learning_rate": 0.001
  },
  {
    "episode": 12187,
    "reward": 86.016541,
    "length": 70,
    "time": 177454.292446,
    "actor_loss": -70.35064697265625,
    "critic_loss": 4.417285919189453,
    "ent_coef": 0.0777330994606018,
    "learning_rate": 0.001
  },
  {
    "episode": 12188,
    "reward": 87.546273,
    "length": 67,
    "time": 177466.994621,
    "actor_loss": -63.925331115722656,
    "critic_loss": 7.442536354064941,
    "ent_coef": 0.07709251344203949,
    "learning_rate": 0.001
  },
  {
    "episode": 12189,
    "reward": 86.889631,
    "length": 68,
    "time": 177479.011954,
    "actor_loss": -69.70792388916016,
    "critic_loss": 54.25835037231445,
    "ent_coef": 0.07402723282575607,
    "learning_rate": 0.001
  },
  {
    "episode": 12190,
    "reward": 86.634636,
    "length": 70,
    "time": 177491.994071,
    "actor_loss": -69.79086303710938,
    "critic_loss": 6.588666915893555,
    "ent_coef": 0.07322213053703308,
    "learning_rate": 0.001
  },
  {
    "episode": 12191,
    "reward": 81.171639,
    "length": 79,
    "time": 177507.461882,
    "actor_loss": -66.91729736328125,
    "critic_loss": 8.54922866821289,
    "ent_coef": 0.06873659789562225,
    "learning_rate": 0.001
  },
  {
    "episode": 12192,
    "reward": 83.797971,
    "length": 72,
    "time": 177522.220217,
    "actor_loss": -72.49613952636719,
    "critic_loss": 1.9863075017929077,
    "ent_coef": 0.06868579238653183,
    "learning_rate": 0.001
  },
  {
    "episode": 12193,
    "reward": 85.989036,
    "length": 68,
    "time": 177534.081618,
    "actor_loss": -67.81287384033203,
    "critic_loss": 13.359960556030273,
    "ent_coef": 0.07002329081296921,
    "learning_rate": 0.001
  },
  {
    "episode": 12194,
    "reward": 82.879246,
    "length": 74,
    "time": 177547.060618,
    "actor_loss": -68.29490661621094,
    "critic_loss": 5.090028762817383,
    "ent_coef": 0.0705224797129631,
    "learning_rate": 0.001
  },
  {
    "episode": 12195,
    "reward": 86.318469,
    "length": 69,
    "time": 177560.204869,
    "actor_loss": -67.53387451171875,
    "critic_loss": 50.97468566894531,
    "ent_coef": 0.07083671540021896,
    "learning_rate": 0.001
  },
  {
    "episode": 12196,
    "reward": 90.873033,
    "length": 61,
    "time": 177573.299694,
    "actor_loss": -70.06106567382812,
    "critic_loss": 55.573829650878906,
    "ent_coef": 0.07070387899875641,
    "learning_rate": 0.001
  },
  {
    "episode": 12197,
    "reward": 86.855513,
    "length": 69,
    "time": 177586.181161,
    "actor_loss": -68.97608947753906,
    "critic_loss": 12.43665885925293,
    "ent_coef": 0.06834595650434494,
    "learning_rate": 0.001
  },
  {
    "episode": 12198,
    "reward": 85.822301,
    "length": 71,
    "time": 177598.345862,
    "actor_loss": -74.95906066894531,
    "critic_loss": 31.41770362854004,
    "ent_coef": 0.06711798906326294,
    "learning_rate": 0.001
  },
  {
    "episode": 12199,
    "reward": 88.54411,
    "length": 65,
    "time": 177612.037745,
    "actor_loss": -67.80078125,
    "critic_loss": 4.59515905380249,
    "ent_coef": 0.06826156377792358,
    "learning_rate": 0.001
  },
  {
    "episode": 12200,
    "reward": 90.136352,
    "length": 62,
    "time": 177623.145576,
    "actor_loss": -69.31681823730469,
    "critic_loss": 8.087757110595703,
    "ent_coef": 0.06902994215488434,
    "learning_rate": 0.001
  },
  {
    "episode": 12201,
    "reward": 87.441511,
    "length": 67,
    "time": 177635.316959,
    "actor_loss": -63.533416748046875,
    "critic_loss": 57.01921844482422,
    "ent_coef": 0.06903927773237228,
    "learning_rate": 0.001
  },
  {
    "episode": 12202,
    "reward": 88.677846,
    "length": 67,
    "time": 177647.327547,
    "actor_loss": -61.65852355957031,
    "critic_loss": 17.13703155517578,
    "ent_coef": 0.06926846504211426,
    "learning_rate": 0.001
  },
  {
    "episode": 12203,
    "reward": 86.870745,
    "length": 72,
    "time": 177659.886804,
    "actor_loss": -71.17472839355469,
    "critic_loss": 34.19438934326172,
    "ent_coef": 0.07123026996850967,
    "learning_rate": 0.001
  },
  {
    "episode": 12204,
    "reward": 90.167188,
    "length": 62,
    "time": 177671.251325,
    "actor_loss": -62.74163055419922,
    "critic_loss": 4.20352029800415,
    "ent_coef": 0.07543878257274628,
    "learning_rate": 0.001
  },
  {
    "episode": 12205,
    "reward": 88.464722,
    "length": 70,
    "time": 177683.446084,
    "actor_loss": -69.8529052734375,
    "critic_loss": 2.603940725326538,
    "ent_coef": 0.07599946111440659,
    "learning_rate": 0.001
  },
  {
    "episode": 12206,
    "reward": 87.335428,
    "length": 73,
    "time": 177696.071101,
    "actor_loss": -68.11265563964844,
    "critic_loss": 2.6736409664154053,
    "ent_coef": 0.07388386875391006,
    "learning_rate": 0.001
  },
  {
    "episode": 12207,
    "reward": 88.802017,
    "length": 67,
    "time": 177710.028802,
    "actor_loss": -73.44752502441406,
    "critic_loss": 6.36424446105957,
    "ent_coef": 0.07187316566705704,
    "learning_rate": 0.001
  },
  {
    "episode": 12208,
    "reward": 88.505864,
    "length": 66,
    "time": 177722.694441,
    "actor_loss": -65.27790069580078,
    "critic_loss": 5.33314323425293,
    "ent_coef": 0.0708218440413475,
    "learning_rate": 0.001
  },
  {
    "episode": 12209,
    "reward": 86.121112,
    "length": 72,
    "time": 177736.082891,
    "actor_loss": -69.02560424804688,
    "critic_loss": 21.171518325805664,
    "ent_coef": 0.06774277240037918,
    "learning_rate": 0.001
  },
  {
    "episode": 12210,
    "reward": 86.193707,
    "length": 72,
    "time": 177749.245196,
    "actor_loss": -68.45184326171875,
    "critic_loss": 15.402255058288574,
    "ent_coef": 0.06410545855760574,
    "learning_rate": 0.001
  },
  {
    "episode": 12211,
    "reward": 91.047704,
    "length": 61,
    "time": 177760.680386,
    "actor_loss": -70.07786560058594,
    "critic_loss": 6.175992965698242,
    "ent_coef": 0.06516875326633453,
    "learning_rate": 0.001
  },
  {
    "episode": 12212,
    "reward": 88.700667,
    "length": 65,
    "time": 177772.152496,
    "actor_loss": -66.39556884765625,
    "critic_loss": 7.788938522338867,
    "ent_coef": 0.06347499787807465,
    "learning_rate": 0.001
  },
  {
    "episode": 12213,
    "reward": 88.17019,
    "length": 70,
    "time": 177784.20651,
    "actor_loss": -73.18069458007812,
    "critic_loss": 5.034427642822266,
    "ent_coef": 0.061754170805215836,
    "learning_rate": 0.001
  },
  {
    "episode": 12214,
    "reward": 89.582593,
    "length": 65,
    "time": 177795.98652,
    "actor_loss": -70.876708984375,
    "critic_loss": 107.8548583984375,
    "ent_coef": 0.059588100761175156,
    "learning_rate": 0.001
  },
  {
    "episode": 12215,
    "reward": 89.568186,
    "length": 64,
    "time": 177807.534184,
    "actor_loss": -62.892024993896484,
    "critic_loss": 20.552513122558594,
    "ent_coef": 0.059543367475271225,
    "learning_rate": 0.001
  },
  {
    "episode": 12216,
    "reward": 83.625099,
    "length": 75,
    "time": 177820.529677,
    "actor_loss": -60.70477294921875,
    "critic_loss": 19.963733673095703,
    "ent_coef": 0.057600490748882294,
    "learning_rate": 0.001
  },
  {
    "episode": 12217,
    "reward": 73.336756,
    "length": 97,
    "time": 177836.248148,
    "actor_loss": -70.04681396484375,
    "critic_loss": 5.881139278411865,
    "ent_coef": 0.055696986615657806,
    "learning_rate": 0.001
  },
  {
    "episode": 12218,
    "reward": 85.880909,
    "length": 75,
    "time": 177852.800877,
    "actor_loss": -62.4217529296875,
    "critic_loss": 14.317012786865234,
    "ent_coef": 0.0568019300699234,
    "learning_rate": 0.001
  },
  {
    "episode": 12219,
    "reward": 88.598951,
    "length": 69,
    "time": 177864.636602,
    "actor_loss": -66.86138153076172,
    "critic_loss": 15.675873756408691,
    "ent_coef": 0.056416355073451996,
    "learning_rate": 0.001
  },
  {
    "episode": 12220,
    "reward": 85.161928,
    "length": 74,
    "time": 177879.169373,
    "actor_loss": -64.61763000488281,
    "critic_loss": 5.92796516418457,
    "ent_coef": 0.057508017867803574,
    "learning_rate": 0.001
  },
  {
    "episode": 12221,
    "reward": 84.610872,
    "length": 77,
    "time": 177895.293534,
    "actor_loss": -64.0291748046875,
    "critic_loss": 24.487911224365234,
    "ent_coef": 0.05460115522146225,
    "learning_rate": 0.001
  },
  {
    "episode": 12222,
    "reward": 88.655613,
    "length": 71,
    "time": 177907.434238,
    "actor_loss": -72.05474853515625,
    "critic_loss": 12.202064514160156,
    "ent_coef": 0.05260192230343819,
    "learning_rate": 0.001
  },
  {
    "episode": 12223,
    "reward": 81.029301,
    "length": 80,
    "time": 177922.20648,
    "actor_loss": -77.84645080566406,
    "critic_loss": 2.2924258708953857,
    "ent_coef": 0.05048678070306778,
    "learning_rate": 0.001
  },
  {
    "episode": 12224,
    "reward": 84.373815,
    "length": 71,
    "time": 177935.435315,
    "actor_loss": -66.07897186279297,
    "critic_loss": 11.960148811340332,
    "ent_coef": 0.0491289347410202,
    "learning_rate": 0.001
  },
  {
    "episode": 12225,
    "reward": 86.373608,
    "length": 67,
    "time": 177947.269353,
    "actor_loss": -67.52128601074219,
    "critic_loss": 21.27191734313965,
    "ent_coef": 0.05222460255026817,
    "learning_rate": 0.001
  },
  {
    "episode": 12226,
    "reward": 90.135356,
    "length": 62,
    "time": 177958.340572,
    "actor_loss": -68.70245361328125,
    "critic_loss": 28.821578979492188,
    "ent_coef": 0.05471033975481987,
    "learning_rate": 0.001
  },
  {
    "episode": 12227,
    "reward": 87.7096,
    "length": 71,
    "time": 177971.67578,
    "actor_loss": -71.03337097167969,
    "critic_loss": 3.675191640853882,
    "ent_coef": 0.05490115284919739,
    "learning_rate": 0.001
  },
  {
    "episode": 12228,
    "reward": 85.768128,
    "length": 74,
    "time": 177985.685328,
    "actor_loss": -64.95611572265625,
    "critic_loss": 28.522720336914062,
    "ent_coef": 0.05532573163509369,
    "learning_rate": 0.001
  },
  {
    "episode": 12229,
    "reward": 85.147592,
    "length": 74,
    "time": 178002.420319,
    "actor_loss": -70.52108001708984,
    "critic_loss": 20.66461181640625,
    "ent_coef": 0.06118130683898926,
    "learning_rate": 0.001
  },
  {
    "episode": 12230,
    "reward": 88.168788,
    "length": 65,
    "time": 178014.436698,
    "actor_loss": -65.3386459350586,
    "critic_loss": 10.272026062011719,
    "ent_coef": 0.0647028237581253,
    "learning_rate": 0.001
  },
  {
    "episode": 12231,
    "reward": 84.935131,
    "length": 71,
    "time": 178027.349818,
    "actor_loss": -64.73799133300781,
    "critic_loss": 30.524999618530273,
    "ent_coef": 0.06493169814348221,
    "learning_rate": 0.001
  },
  {
    "episode": 12232,
    "reward": 86.562074,
    "length": 67,
    "time": 178039.225619,
    "actor_loss": -65.47305297851562,
    "critic_loss": 7.015553951263428,
    "ent_coef": 0.06435157358646393,
    "learning_rate": 0.001
  },
  {
    "episode": 12233,
    "reward": 88.446883,
    "length": 64,
    "time": 178052.258085,
    "actor_loss": -73.60134887695312,
    "critic_loss": 23.39263916015625,
    "ent_coef": 0.06733737885951996,
    "learning_rate": 0.001
  },
  {
    "episode": 12234,
    "reward": 86.150051,
    "length": 67,
    "time": 178064.810984,
    "actor_loss": -67.31969451904297,
    "critic_loss": 27.199939727783203,
    "ent_coef": 0.0708414688706398,
    "learning_rate": 0.001
  },
  {
    "episode": 12235,
    "reward": 85.985283,
    "length": 69,
    "time": 178077.111964,
    "actor_loss": -70.41776275634766,
    "critic_loss": 3.890747547149658,
    "ent_coef": 0.06999605894088745,
    "learning_rate": 0.001
  },
  {
    "episode": 12236,
    "reward": 87.085453,
    "length": 67,
    "time": 178089.737743,
    "actor_loss": -65.47429656982422,
    "critic_loss": 17.81342124938965,
    "ent_coef": 0.06938638538122177,
    "learning_rate": 0.001
  },
  {
    "episode": 12237,
    "reward": 87.98562,
    "length": 65,
    "time": 178103.515091,
    "actor_loss": -73.07736206054688,
    "critic_loss": 320.015380859375,
    "ent_coef": 0.07285381108522415,
    "learning_rate": 0.001
  },
  {
    "episode": 12238,
    "reward": 89.302544,
    "length": 65,
    "time": 178115.199748,
    "actor_loss": -68.34477233886719,
    "critic_loss": 7.892212867736816,
    "ent_coef": 0.07355915755033493,
    "learning_rate": 0.001
  },
  {
    "episode": 12239,
    "reward": 84.349482,
    "length": 73,
    "time": 178127.791247,
    "actor_loss": -67.68466186523438,
    "critic_loss": 6.452962875366211,
    "ent_coef": 0.06979314237833023,
    "learning_rate": 0.001
  },
  {
    "episode": 12240,
    "reward": 84.886608,
    "length": 71,
    "time": 178140.345945,
    "actor_loss": -67.02115631103516,
    "critic_loss": 16.351520538330078,
    "ent_coef": 0.06855972856283188,
    "learning_rate": 0.001
  },
  {
    "episode": 12241,
    "reward": 78.675922,
    "length": 82,
    "time": 178154.499424,
    "actor_loss": -71.25911712646484,
    "critic_loss": 14.076635360717773,
    "ent_coef": 0.06487241387367249,
    "learning_rate": 0.001
  },
  {
    "episode": 12242,
    "reward": 87.042858,
    "length": 66,
    "time": 178167.083309,
    "actor_loss": -69.98159790039062,
    "critic_loss": 53.723365783691406,
    "ent_coef": 0.0637517124414444,
    "learning_rate": 0.001
  },
  {
    "episode": 12243,
    "reward": 82.661887,
    "length": 80,
    "time": 178181.407098,
    "actor_loss": -68.74921417236328,
    "critic_loss": 13.986807823181152,
    "ent_coef": 0.06175926327705383,
    "learning_rate": 0.001
  },
  {
    "episode": 12244,
    "reward": 88.249078,
    "length": 66,
    "time": 178194.170421,
    "actor_loss": -68.27218627929688,
    "critic_loss": 10.827264785766602,
    "ent_coef": 0.06465102732181549,
    "learning_rate": 0.001
  },
  {
    "episode": 12245,
    "reward": 88.662368,
    "length": 64,
    "time": 178208.363815,
    "actor_loss": -65.89900970458984,
    "critic_loss": 9.832655906677246,
    "ent_coef": 0.06690311431884766,
    "learning_rate": 0.001
  },
  {
    "episode": 12246,
    "reward": 88.561224,
    "length": 65,
    "time": 178220.091083,
    "actor_loss": -69.98564147949219,
    "critic_loss": 7.841352462768555,
    "ent_coef": 0.06693590432405472,
    "learning_rate": 0.001
  },
  {
    "episode": 12247,
    "reward": 91.445483,
    "length": 60,
    "time": 178231.233671,
    "actor_loss": -71.78689575195312,
    "critic_loss": 32.494754791259766,
    "ent_coef": 0.06722617149353027,
    "learning_rate": 0.001
  },
  {
    "episode": 12248,
    "reward": 91.801546,
    "length": 59,
    "time": 178244.103315,
    "actor_loss": -69.60209655761719,
    "critic_loss": 4.426072120666504,
    "ent_coef": 0.0699710100889206,
    "learning_rate": 0.001
  },
  {
    "episode": 12249,
    "reward": 89.326238,
    "length": 63,
    "time": 178255.626121,
    "actor_loss": -68.09125518798828,
    "critic_loss": 4.735708236694336,
    "ent_coef": 0.07255689799785614,
    "learning_rate": 0.001
  },
  {
    "episode": 12250,
    "reward": 91.118208,
    "length": 62,
    "time": 178270.309752,
    "actor_loss": -74.05906677246094,
    "critic_loss": 164.57177734375,
    "ent_coef": 0.07566076517105103,
    "learning_rate": 0.001
  },
  {
    "episode": 12251,
    "reward": 92.094078,
    "length": 59,
    "time": 178281.64444,
    "actor_loss": -70.7438735961914,
    "critic_loss": 10.453474044799805,
    "ent_coef": 0.07999961823225021,
    "learning_rate": 0.001
  },
  {
    "episode": 12252,
    "reward": 87.537266,
    "length": 66,
    "time": 178293.574674,
    "actor_loss": -64.45405578613281,
    "critic_loss": 16.660541534423828,
    "ent_coef": 0.07928790897130966,
    "learning_rate": 0.001
  },
  {
    "episode": 12253,
    "reward": 87.708522,
    "length": 67,
    "time": 178306.385817,
    "actor_loss": -69.55682373046875,
    "critic_loss": 22.276729583740234,
    "ent_coef": 0.07619907706975937,
    "learning_rate": 0.001
  },
  {
    "episode": 12254,
    "reward": 85.022989,
    "length": 71,
    "time": 178319.993106,
    "actor_loss": -63.38520050048828,
    "critic_loss": 7.219511985778809,
    "ent_coef": 0.07315190136432648,
    "learning_rate": 0.001
  },
  {
    "episode": 12255,
    "reward": 87.443514,
    "length": 66,
    "time": 178334.679006,
    "actor_loss": -73.2406005859375,
    "critic_loss": 41.258026123046875,
    "ent_coef": 0.07223878055810928,
    "learning_rate": 0.001
  },
  {
    "episode": 12256,
    "reward": 89.798197,
    "length": 63,
    "time": 178347.500488,
    "actor_loss": -66.68028259277344,
    "critic_loss": 6.237733840942383,
    "ent_coef": 0.07130491733551025,
    "learning_rate": 0.001
  },
  {
    "episode": 12257,
    "reward": 88.525083,
    "length": 66,
    "time": 178359.133282,
    "actor_loss": -68.48617553710938,
    "critic_loss": 3.2585668563842773,
    "ent_coef": 0.06931072473526001,
    "learning_rate": 0.001
  },
  {
    "episode": 12258,
    "reward": 87.458097,
    "length": 68,
    "time": 178373.973237,
    "actor_loss": -71.74861907958984,
    "critic_loss": 3.6213788986206055,
    "ent_coef": 0.06587795913219452,
    "learning_rate": 0.001
  },
  {
    "episode": 12259,
    "reward": 87.154297,
    "length": 68,
    "time": 178388.772711,
    "actor_loss": -68.01021575927734,
    "critic_loss": 4.131847858428955,
    "ent_coef": 0.06537400186061859,
    "learning_rate": 0.001
  },
  {
    "episode": 12260,
    "reward": 85.661886,
    "length": 67,
    "time": 178403.910969,
    "actor_loss": -65.2914810180664,
    "critic_loss": 16.516712188720703,
    "ent_coef": 0.06414788216352463,
    "learning_rate": 0.001
  },
  {
    "episode": 12261,
    "reward": 86.835298,
    "length": 67,
    "time": 178418.619763,
    "actor_loss": -70.57283020019531,
    "critic_loss": 5.860046863555908,
    "ent_coef": 0.06200962886214256,
    "learning_rate": 0.001
  },
  {
    "episode": 12262,
    "reward": 87.671746,
    "length": 68,
    "time": 178432.602158,
    "actor_loss": -69.63992309570312,
    "critic_loss": 18.900541305541992,
    "ent_coef": 0.06162232905626297,
    "learning_rate": 0.001
  },
  {
    "episode": 12263,
    "reward": 85.830309,
    "length": 68,
    "time": 178445.589829,
    "actor_loss": -68.09235382080078,
    "critic_loss": 37.446964263916016,
    "ent_coef": 0.061001524329185486,
    "learning_rate": 0.001
  },
  {
    "episode": 12264,
    "reward": 90.336499,
    "length": 62,
    "time": 178458.85121,
    "actor_loss": -70.38880157470703,
    "critic_loss": 11.420947074890137,
    "ent_coef": 0.06393112242221832,
    "learning_rate": 0.001
  },
  {
    "episode": 12265,
    "reward": 88.771079,
    "length": 65,
    "time": 178473.086029,
    "actor_loss": -66.5516357421875,
    "critic_loss": 85.91436767578125,
    "ent_coef": 0.06374747306108475,
    "learning_rate": 0.001
  },
  {
    "episode": 12266,
    "reward": 90.180642,
    "length": 61,
    "time": 178487.223763,
    "actor_loss": -65.26573944091797,
    "critic_loss": 3.6644132137298584,
    "ent_coef": 0.06614907830953598,
    "learning_rate": 0.001
  },
  {
    "episode": 12267,
    "reward": 89.288773,
    "length": 62,
    "time": 178500.019311,
    "actor_loss": -65.37417602539062,
    "critic_loss": 25.234235763549805,
    "ent_coef": 0.07102013379335403,
    "learning_rate": 0.001
  },
  {
    "episode": 12268,
    "reward": 87.895044,
    "length": 65,
    "time": 178513.250567,
    "actor_loss": -70.45883178710938,
    "critic_loss": 9.25780200958252,
    "ent_coef": 0.07048673182725906,
    "learning_rate": 0.001
  },
  {
    "episode": 12269,
    "reward": 89.599074,
    "length": 62,
    "time": 178525.285416,
    "actor_loss": -69.703369140625,
    "critic_loss": 483.9964599609375,
    "ent_coef": 0.06979808211326599,
    "learning_rate": 0.001
  },
  {
    "episode": 12270,
    "reward": 91.052921,
    "length": 60,
    "time": 178538.009979,
    "actor_loss": -71.39747619628906,
    "critic_loss": 34.50459289550781,
    "ent_coef": 0.07161547988653183,
    "learning_rate": 0.001
  },
  {
    "episode": 12271,
    "reward": 89.43268,
    "length": 62,
    "time": 178550.29788,
    "actor_loss": -72.71759033203125,
    "critic_loss": 37.19855499267578,
    "ent_coef": 0.07155978679656982,
    "learning_rate": 0.001
  },
  {
    "episode": 12272,
    "reward": 88.116776,
    "length": 65,
    "time": 178562.266339,
    "actor_loss": -67.35061645507812,
    "critic_loss": 30.414325714111328,
    "ent_coef": 0.07157133519649506,
    "learning_rate": 0.001
  },
  {
    "episode": 12273,
    "reward": 90.192124,
    "length": 64,
    "time": 178573.600273,
    "actor_loss": -70.12666320800781,
    "critic_loss": 2.8874809741973877,
    "ent_coef": 0.07405327260494232,
    "learning_rate": 0.001
  },
  {
    "episode": 12274,
    "reward": 88.996259,
    "length": 68,
    "time": 178585.747443,
    "actor_loss": -69.90425872802734,
    "critic_loss": 24.42024040222168,
    "ent_coef": 0.0758160650730133,
    "learning_rate": 0.001
  },
  {
    "episode": 12275,
    "reward": 91.463032,
    "length": 61,
    "time": 178599.090999,
    "actor_loss": -66.37217712402344,
    "critic_loss": 57.95649719238281,
    "ent_coef": 0.07516888529062271,
    "learning_rate": 0.001
  },
  {
    "episode": 12276,
    "reward": 90.593885,
    "length": 63,
    "time": 178611.562381,
    "actor_loss": -61.82822799682617,
    "critic_loss": 6.327293872833252,
    "ent_coef": 0.07445934414863586,
    "learning_rate": 0.001
  },
  {
    "episode": 12277,
    "reward": 91.292162,
    "length": 61,
    "time": 178623.532932,
    "actor_loss": -71.6728744506836,
    "critic_loss": 14.8280668258667,
    "ent_coef": 0.0750279352068901,
    "learning_rate": 0.001
  },
  {
    "episode": 12278,
    "reward": 89.679741,
    "length": 63,
    "time": 178635.504295,
    "actor_loss": -70.05767822265625,
    "critic_loss": 5.638650894165039,
    "ent_coef": 0.07482931762933731,
    "learning_rate": 0.001
  },
  {
    "episode": 12279,
    "reward": 87.827454,
    "length": 67,
    "time": 178648.184903,
    "actor_loss": -68.34388732910156,
    "critic_loss": 9.264337539672852,
    "ent_coef": 0.07432329654693604,
    "learning_rate": 0.001
  },
  {
    "episode": 12280,
    "reward": 90.495133,
    "length": 62,
    "time": 178661.232708,
    "actor_loss": -65.54219055175781,
    "critic_loss": 6.794475555419922,
    "ent_coef": 0.07381440699100494,
    "learning_rate": 0.001
  },
  {
    "episode": 12281,
    "reward": 86.404481,
    "length": 74,
    "time": 178675.140049,
    "actor_loss": -72.36785888671875,
    "critic_loss": 3.5029778480529785,
    "ent_coef": 0.06930401921272278,
    "learning_rate": 0.001
  },
  {
    "episode": 12282,
    "reward": 90.43477,
    "length": 63,
    "time": 178686.457092,
    "actor_loss": -67.5470199584961,
    "critic_loss": 32.890106201171875,
    "ent_coef": 0.06719934195280075,
    "learning_rate": 0.001
  },
  {
    "episode": 12283,
    "reward": 87.072833,
    "length": 73,
    "time": 178699.314002,
    "actor_loss": -59.434242248535156,
    "critic_loss": 3.2545337677001953,
    "ent_coef": 0.06646130234003067,
    "learning_rate": 0.001
  },
  {
    "episode": 12284,
    "reward": 89.987123,
    "length": 62,
    "time": 178712.509646,
    "actor_loss": -67.85577392578125,
    "critic_loss": 10.859942436218262,
    "ent_coef": 0.06838136911392212,
    "learning_rate": 0.001
  },
  {
    "episode": 12285,
    "reward": 88.532328,
    "length": 66,
    "time": 178726.166391,
    "actor_loss": -69.11509704589844,
    "critic_loss": 13.292997360229492,
    "ent_coef": 0.06699202209711075,
    "learning_rate": 0.001
  },
  {
    "episode": 12286,
    "reward": 87.628513,
    "length": 67,
    "time": 178738.500356,
    "actor_loss": -63.29203414916992,
    "critic_loss": 5.310900688171387,
    "ent_coef": 0.0666629746556282,
    "learning_rate": 0.001
  },
  {
    "episode": 12287,
    "reward": 87.556456,
    "length": 68,
    "time": 178750.972746,
    "actor_loss": -65.9067611694336,
    "critic_loss": 5.578169345855713,
    "ent_coef": 0.06403378397226334,
    "learning_rate": 0.001
  },
  {
    "episode": 12288,
    "reward": 89.82818,
    "length": 68,
    "time": 178763.421251,
    "actor_loss": -69.53842163085938,
    "critic_loss": 5.8049798011779785,
    "ent_coef": 0.06209477037191391,
    "learning_rate": 0.001
  },
  {
    "episode": 12289,
    "reward": 88.426313,
    "length": 65,
    "time": 178775.458252,
    "actor_loss": -67.49027252197266,
    "critic_loss": 4.800820350646973,
    "ent_coef": 0.05984056368470192,
    "learning_rate": 0.001
  },
  {
    "episode": 12290,
    "reward": 89.539176,
    "length": 68,
    "time": 178787.45932,
    "actor_loss": -64.89502716064453,
    "critic_loss": 21.045108795166016,
    "ent_coef": 0.060912273824214935,
    "learning_rate": 0.001
  },
  {
    "episode": 12291,
    "reward": 91.236908,
    "length": 61,
    "time": 178802.969989,
    "actor_loss": -66.61482238769531,
    "critic_loss": 6.0279035568237305,
    "ent_coef": 0.06138922646641731,
    "learning_rate": 0.001
  },
  {
    "episode": 12292,
    "reward": 90.272198,
    "length": 63,
    "time": 178814.578465,
    "actor_loss": -63.50870895385742,
    "critic_loss": 7.824341773986816,
    "ent_coef": 0.06164941191673279,
    "learning_rate": 0.001
  },
  {
    "episode": 12293,
    "reward": 89.643779,
    "length": 63,
    "time": 178828.975009,
    "actor_loss": -67.56585693359375,
    "critic_loss": 61.83516311645508,
    "ent_coef": 0.06391651928424835,
    "learning_rate": 0.001
  },
  {
    "episode": 12294,
    "reward": 89.277287,
    "length": 67,
    "time": 178841.613903,
    "actor_loss": -68.00096130371094,
    "critic_loss": 4.542941570281982,
    "ent_coef": 0.06304867565631866,
    "learning_rate": 0.001
  },
  {
    "episode": 12295,
    "reward": 87.510107,
    "length": 68,
    "time": 178855.585528,
    "actor_loss": -73.3244400024414,
    "critic_loss": 27.355205535888672,
    "ent_coef": 0.06343862414360046,
    "learning_rate": 0.001
  },
  {
    "episode": 12296,
    "reward": 90.879219,
    "length": 60,
    "time": 178868.14372,
    "actor_loss": -68.56047821044922,
    "critic_loss": 6.948810577392578,
    "ent_coef": 0.0656495988368988,
    "learning_rate": 0.001
  },
  {
    "episode": 12297,
    "reward": 92.760979,
    "length": 56,
    "time": 178879.837632,
    "actor_loss": -68.23800659179688,
    "critic_loss": 12.773229598999023,
    "ent_coef": 0.0690956562757492,
    "learning_rate": 0.001
  },
  {
    "episode": 12298,
    "reward": 90.691867,
    "length": 66,
    "time": 178892.435268,
    "actor_loss": -65.45477294921875,
    "critic_loss": 3.6913299560546875,
    "ent_coef": 0.06979688256978989,
    "learning_rate": 0.001
  },
  {
    "episode": 12299,
    "reward": 88.874065,
    "length": 65,
    "time": 178905.402832,
    "actor_loss": -73.59664916992188,
    "critic_loss": 4.447402477264404,
    "ent_coef": 0.0654754564166069,
    "learning_rate": 0.001
  },
  {
    "episode": 12300,
    "reward": 89.241699,
    "length": 67,
    "time": 178920.172432,
    "actor_loss": -67.32057189941406,
    "critic_loss": 4.033100605010986,
    "ent_coef": 0.06226865574717522,
    "learning_rate": 0.001
  },
  {
    "episode": 12301,
    "reward": 85.443301,
    "length": 71,
    "time": 178933.606614,
    "actor_loss": -66.67947387695312,
    "critic_loss": 9.708353996276855,
    "ent_coef": 0.05793005973100662,
    "learning_rate": 0.001
  },
  {
    "episode": 12302,
    "reward": 89.356388,
    "length": 65,
    "time": 178946.026981,
    "actor_loss": -68.11245727539062,
    "critic_loss": 10.273040771484375,
    "ent_coef": 0.057216864079236984,
    "learning_rate": 0.001
  },
  {
    "episode": 12303,
    "reward": 89.510114,
    "length": 69,
    "time": 178961.393411,
    "actor_loss": -69.60843658447266,
    "critic_loss": 44.38074493408203,
    "ent_coef": 0.05672673135995865,
    "learning_rate": 0.001
  },
  {
    "episode": 12304,
    "reward": 88.658042,
    "length": 65,
    "time": 178976.784763,
    "actor_loss": -69.2662582397461,
    "critic_loss": 12.108196258544922,
    "ent_coef": 0.058960922062397,
    "learning_rate": 0.001
  },
  {
    "episode": 12305,
    "reward": 90.491642,
    "length": 61,
    "time": 178989.566229,
    "actor_loss": -68.56278228759766,
    "critic_loss": 9.596062660217285,
    "ent_coef": 0.06193458288908005,
    "learning_rate": 0.001
  },
  {
    "episode": 12306,
    "reward": 87.47669,
    "length": 70,
    "time": 179001.815724,
    "actor_loss": -69.6430435180664,
    "critic_loss": 6.114033222198486,
    "ent_coef": 0.06488072872161865,
    "learning_rate": 0.001
  },
  {
    "episode": 12307,
    "reward": 89.39747,
    "length": 65,
    "time": 179013.598941,
    "actor_loss": -72.52084350585938,
    "critic_loss": 59.9603271484375,
    "ent_coef": 0.06481032818555832,
    "learning_rate": 0.001
  },
  {
    "episode": 12308,
    "reward": 89.393112,
    "length": 65,
    "time": 179026.26332,
    "actor_loss": -67.89392852783203,
    "critic_loss": 3.142759323120117,
    "ent_coef": 0.06563854962587357,
    "learning_rate": 0.001
  },
  {
    "episode": 12309,
    "reward": 86.959547,
    "length": 74,
    "time": 179038.923258,
    "actor_loss": -69.52656555175781,
    "critic_loss": 9.674860954284668,
    "ent_coef": 0.06656522303819656,
    "learning_rate": 0.001
  },
  {
    "episode": 12310,
    "reward": 89.329328,
    "length": 65,
    "time": 179056.554785,
    "actor_loss": -67.71296691894531,
    "critic_loss": 34.43688201904297,
    "ent_coef": 0.06780365109443665,
    "learning_rate": 0.001
  },
  {
    "episode": 12311,
    "reward": 89.099454,
    "length": 65,
    "time": 179068.935852,
    "actor_loss": -73.11744689941406,
    "critic_loss": 3.3125810623168945,
    "ent_coef": 0.06674132496118546,
    "learning_rate": 0.001
  },
  {
    "episode": 12312,
    "reward": 82.513501,
    "length": 77,
    "time": 179081.981198,
    "actor_loss": -61.891136169433594,
    "critic_loss": 11.54963493347168,
    "ent_coef": 0.06401094049215317,
    "learning_rate": 0.001
  },
  {
    "episode": 12313,
    "reward": 88.636218,
    "length": 64,
    "time": 179093.746748,
    "actor_loss": -71.12312316894531,
    "critic_loss": 4.913088798522949,
    "ent_coef": 0.0657823383808136,
    "learning_rate": 0.001
  },
  {
    "episode": 12314,
    "reward": 88.689447,
    "length": 64,
    "time": 179106.804656,
    "actor_loss": -61.021568298339844,
    "critic_loss": 22.865123748779297,
    "ent_coef": 0.06666956841945648,
    "learning_rate": 0.001
  },
  {
    "episode": 12315,
    "reward": 89.53652,
    "length": 63,
    "time": 179119.299755,
    "actor_loss": -70.40487670898438,
    "critic_loss": 25.714691162109375,
    "ent_coef": 0.06539107114076614,
    "learning_rate": 0.001
  },
  {
    "episode": 12316,
    "reward": 90.001645,
    "length": 63,
    "time": 179130.858269,
    "actor_loss": -61.17585372924805,
    "critic_loss": 2.7729315757751465,
    "ent_coef": 0.06481347233057022,
    "learning_rate": 0.001
  },
  {
    "episode": 12317,
    "reward": 88.877286,
    "length": 69,
    "time": 179144.293873,
    "actor_loss": -65.46115112304688,
    "critic_loss": 5.727457523345947,
    "ent_coef": 0.06549548357725143,
    "learning_rate": 0.001
  },
  {
    "episode": 12318,
    "reward": 91.70583,
    "length": 60,
    "time": 179156.122125,
    "actor_loss": -66.86859130859375,
    "critic_loss": 101.01814270019531,
    "ent_coef": 0.06740730255842209,
    "learning_rate": 0.001
  },
  {
    "episode": 12319,
    "reward": 89.754031,
    "length": 65,
    "time": 179170.74799,
    "actor_loss": -62.0484504699707,
    "critic_loss": 119.5010986328125,
    "ent_coef": 0.06372439116239548,
    "learning_rate": 0.001
  },
  {
    "episode": 12320,
    "reward": 88.129023,
    "length": 68,
    "time": 179184.030998,
    "actor_loss": -69.7225570678711,
    "critic_loss": 6.442039966583252,
    "ent_coef": 0.06172880530357361,
    "learning_rate": 0.001
  },
  {
    "episode": 12321,
    "reward": 87.802205,
    "length": 68,
    "time": 179197.703105,
    "actor_loss": -72.32847595214844,
    "critic_loss": 3.7610411643981934,
    "ent_coef": 0.060324471443891525,
    "learning_rate": 0.001
  },
  {
    "episode": 12322,
    "reward": 61.656905,
    "length": 95,
    "time": 179216.309637,
    "actor_loss": -66.0441665649414,
    "critic_loss": 22.501461029052734,
    "ent_coef": 0.05725804716348648,
    "learning_rate": 0.001
  },
  {
    "episode": 12323,
    "reward": 88.581673,
    "length": 62,
    "time": 179230.979881,
    "actor_loss": -70.02099609375,
    "critic_loss": 4.971927642822266,
    "ent_coef": 0.05849149450659752,
    "learning_rate": 0.001
  },
  {
    "episode": 12324,
    "reward": 86.929918,
    "length": 67,
    "time": 179246.699166,
    "actor_loss": -71.05248260498047,
    "critic_loss": 15.44488525390625,
    "ent_coef": 0.05873667076230049,
    "learning_rate": 0.001
  },
  {
    "episode": 12325,
    "reward": 68.485185,
    "length": 90,
    "time": 179266.579869,
    "actor_loss": -68.72962951660156,
    "critic_loss": 67.73579406738281,
    "ent_coef": 0.06072390452027321,
    "learning_rate": 0.001
  },
  {
    "episode": 12326,
    "reward": 86.823806,
    "length": 73,
    "time": 179282.998498,
    "actor_loss": -67.26799011230469,
    "critic_loss": 12.490493774414062,
    "ent_coef": 0.06147336959838867,
    "learning_rate": 0.001
  },
  {
    "episode": 12327,
    "reward": 89.319072,
    "length": 63,
    "time": 179296.127333,
    "actor_loss": -68.82020568847656,
    "critic_loss": 3.1781601905822754,
    "ent_coef": 0.060383234173059464,
    "learning_rate": 0.001
  },
  {
    "episode": 12328,
    "reward": 88.887278,
    "length": 70,
    "time": 179310.816168,
    "actor_loss": -67.47459411621094,
    "critic_loss": 2.2867143154144287,
    "ent_coef": 0.060931552201509476,
    "learning_rate": 0.001
  },
  {
    "episode": 12329,
    "reward": -149.264252,
    "length": 93,
    "time": 179328.240478,
    "actor_loss": -72.5558853149414,
    "critic_loss": 4.742348670959473,
    "ent_coef": 0.059928059577941895,
    "learning_rate": 0.001
  },
  {
    "episode": 12330,
    "reward": 94.407418,
    "length": 61,
    "time": 179340.889796,
    "actor_loss": -69.81233978271484,
    "critic_loss": 781.10302734375,
    "ent_coef": 0.06029651314020157,
    "learning_rate": 0.001
  },
  {
    "episode": 12331,
    "reward": 91.647328,
    "length": 60,
    "time": 179354.747766,
    "actor_loss": -67.11988830566406,
    "critic_loss": 53.32722473144531,
    "ent_coef": 0.0625624805688858,
    "learning_rate": 0.001
  },
  {
    "episode": 12332,
    "reward": 91.953754,
    "length": 58,
    "time": 179366.921308,
    "actor_loss": -67.66859436035156,
    "critic_loss": 4.590127468109131,
    "ent_coef": 0.06551571190357208,
    "learning_rate": 0.001
  },
  {
    "episode": 12333,
    "reward": 90.230941,
    "length": 63,
    "time": 179380.48533,
    "actor_loss": -72.14637756347656,
    "critic_loss": 3.0456337928771973,
    "ent_coef": 0.0668037012219429,
    "learning_rate": 0.001
  },
  {
    "episode": 12334,
    "reward": 90.609935,
    "length": 62,
    "time": 179393.254917,
    "actor_loss": -72.89441680908203,
    "critic_loss": 5.335183143615723,
    "ent_coef": 0.06597542762756348,
    "learning_rate": 0.001
  },
  {
    "episode": 12335,
    "reward": 88.710031,
    "length": 65,
    "time": 179408.235855,
    "actor_loss": -64.90788269042969,
    "critic_loss": 75.72991943359375,
    "ent_coef": 0.06546637415885925,
    "learning_rate": 0.001
  },
  {
    "episode": 12336,
    "reward": 90.172523,
    "length": 64,
    "time": 179420.449579,
    "actor_loss": -65.05707550048828,
    "critic_loss": 4.202314376831055,
    "ent_coef": 0.06451405584812164,
    "learning_rate": 0.001
  },
  {
    "episode": 12337,
    "reward": 89.196149,
    "length": 64,
    "time": 179433.499248,
    "actor_loss": -68.15605926513672,
    "critic_loss": 5.396130084991455,
    "ent_coef": 0.06359557807445526,
    "learning_rate": 0.001
  },
  {
    "episode": 12338,
    "reward": 88.78636,
    "length": 65,
    "time": 179447.891669,
    "actor_loss": -72.11143493652344,
    "critic_loss": 1.9224927425384521,
    "ent_coef": 0.06172231584787369,
    "learning_rate": 0.001
  },
  {
    "episode": 12339,
    "reward": 89.497103,
    "length": 63,
    "time": 179460.278594,
    "actor_loss": -65.86726379394531,
    "critic_loss": 6.534233093261719,
    "ent_coef": 0.06124589964747429,
    "learning_rate": 0.001
  },
  {
    "episode": 12340,
    "reward": 90.147129,
    "length": 62,
    "time": 179474.036438,
    "actor_loss": -63.21963882446289,
    "critic_loss": 10.850933074951172,
    "ent_coef": 0.05933671444654465,
    "learning_rate": 0.001
  },
  {
    "episode": 12341,
    "reward": 89.765263,
    "length": 65,
    "time": 179487.361255,
    "actor_loss": -65.74574279785156,
    "critic_loss": 5.774990558624268,
    "ent_coef": 0.059502407908439636,
    "learning_rate": 0.001
  },
  {
    "episode": 12342,
    "reward": 91.890007,
    "length": 59,
    "time": 179499.382823,
    "actor_loss": -68.60311889648438,
    "critic_loss": 4.562146186828613,
    "ent_coef": 0.059476256370544434,
    "learning_rate": 0.001
  },
  {
    "episode": 12343,
    "reward": 89.158309,
    "length": 64,
    "time": 179511.815144,
    "actor_loss": -69.4739990234375,
    "critic_loss": 5.331485271453857,
    "ent_coef": 0.057432547211647034,
    "learning_rate": 0.001
  },
  {
    "episode": 12344,
    "reward": 90.523225,
    "length": 61,
    "time": 179524.233421,
    "actor_loss": -65.32444763183594,
    "critic_loss": 5.281374931335449,
    "ent_coef": 0.056817181408405304,
    "learning_rate": 0.001
  },
  {
    "episode": 12345,
    "reward": 90.451041,
    "length": 61,
    "time": 179537.239564,
    "actor_loss": -71.53780364990234,
    "critic_loss": 5.3957319259643555,
    "ent_coef": 0.05672739818692207,
    "learning_rate": 0.001
  },
  {
    "episode": 12346,
    "reward": 90.280093,
    "length": 61,
    "time": 179549.029599,
    "actor_loss": -63.381248474121094,
    "critic_loss": 5.051448822021484,
    "ent_coef": 0.056555431336164474,
    "learning_rate": 0.001
  },
  {
    "episode": 12347,
    "reward": 89.976244,
    "length": 65,
    "time": 179561.673694,
    "actor_loss": -69.18276977539062,
    "critic_loss": 4.099068641662598,
    "ent_coef": 0.05607588589191437,
    "learning_rate": 0.001
  },
  {
    "episode": 12348,
    "reward": 90.709734,
    "length": 60,
    "time": 179574.999958,
    "actor_loss": -72.92106628417969,
    "critic_loss": 7.682277202606201,
    "ent_coef": 0.05833829939365387,
    "learning_rate": 0.001
  },
  {
    "episode": 12349,
    "reward": 89.682474,
    "length": 63,
    "time": 179588.364255,
    "actor_loss": -71.45077514648438,
    "critic_loss": 3.024326801300049,
    "ent_coef": 0.05922456458210945,
    "learning_rate": 0.001
  },
  {
    "episode": 12350,
    "reward": 89.324117,
    "length": 62,
    "time": 179600.684593,
    "actor_loss": -66.47266387939453,
    "critic_loss": 5.460390567779541,
    "ent_coef": 0.05791279673576355,
    "learning_rate": 0.001
  },
  {
    "episode": 12351,
    "reward": 90.24067,
    "length": 62,
    "time": 179615.655326,
    "actor_loss": -68.07563781738281,
    "critic_loss": 18.398422241210938,
    "ent_coef": 0.05607754364609718,
    "learning_rate": 0.001
  },
  {
    "episode": 12352,
    "reward": 89.405946,
    "length": 64,
    "time": 179628.337635,
    "actor_loss": -71.44990539550781,
    "critic_loss": 38.622493743896484,
    "ent_coef": 0.05609171837568283,
    "learning_rate": 0.001
  },
  {
    "episode": 12353,
    "reward": 89.174873,
    "length": 64,
    "time": 179642.879477,
    "actor_loss": -68.30781555175781,
    "critic_loss": 9.688692092895508,
    "ent_coef": 0.0555114671587944,
    "learning_rate": 0.001
  },
  {
    "episode": 12354,
    "reward": 90.437574,
    "length": 63,
    "time": 179657.819951,
    "actor_loss": -73.54507446289062,
    "critic_loss": 2.1796231269836426,
    "ent_coef": 0.056122325360774994,
    "learning_rate": 0.001
  },
  {
    "episode": 12355,
    "reward": 86.486542,
    "length": 69,
    "time": 179671.18039,
    "actor_loss": -68.20642852783203,
    "critic_loss": 8.773435592651367,
    "ent_coef": 0.05315515026450157,
    "learning_rate": 0.001
  },
  {
    "episode": 12356,
    "reward": 88.221896,
    "length": 66,
    "time": 179688.247924,
    "actor_loss": -66.56175231933594,
    "critic_loss": 5.146849632263184,
    "ent_coef": 0.050661440938711166,
    "learning_rate": 0.001
  },
  {
    "episode": 12357,
    "reward": 90.660507,
    "length": 60,
    "time": 179700.258797,
    "actor_loss": -67.183349609375,
    "critic_loss": 3.121182918548584,
    "ent_coef": 0.05266280099749565,
    "learning_rate": 0.001
  },
  {
    "episode": 12358,
    "reward": 90.406878,
    "length": 60,
    "time": 179711.967749,
    "actor_loss": -71.10977172851562,
    "critic_loss": 3.451441764831543,
    "ent_coef": 0.05342816933989525,
    "learning_rate": 0.001
  },
  {
    "episode": 12359,
    "reward": 93.081599,
    "length": 57,
    "time": 179723.723401,
    "actor_loss": -66.84933471679688,
    "critic_loss": 3.091712474822998,
    "ent_coef": 0.05403231084346771,
    "learning_rate": 0.001
  },
  {
    "episode": 12360,
    "reward": 90.63347,
    "length": 62,
    "time": 179736.080004,
    "actor_loss": -62.953697204589844,
    "critic_loss": 94.437744140625,
    "ent_coef": 0.05516974627971649,
    "learning_rate": 0.001
  },
  {
    "episode": 12361,
    "reward": 91.831894,
    "length": 60,
    "time": 179750.833602,
    "actor_loss": -73.23234558105469,
    "critic_loss": 2.2916111946105957,
    "ent_coef": 0.05610842630267143,
    "learning_rate": 0.001
  },
  {
    "episode": 12362,
    "reward": 91.570221,
    "length": 60,
    "time": 179762.408713,
    "actor_loss": -72.932861328125,
    "critic_loss": 10.18182373046875,
    "ent_coef": 0.05817345902323723,
    "learning_rate": 0.001
  },
  {
    "episode": 12363,
    "reward": 90.46621,
    "length": 62,
    "time": 179775.593542,
    "actor_loss": -70.2205810546875,
    "critic_loss": 4.0202155113220215,
    "ent_coef": 0.05657448619604111,
    "learning_rate": 0.001
  },
  {
    "episode": 12364,
    "reward": 87.862329,
    "length": 67,
    "time": 179790.069739,
    "actor_loss": -67.66678619384766,
    "critic_loss": 7.5152435302734375,
    "ent_coef": 0.052533358335494995,
    "learning_rate": 0.001
  },
  {
    "episode": 12365,
    "reward": 87.484176,
    "length": 68,
    "time": 179803.779374,
    "actor_loss": -66.80149841308594,
    "critic_loss": 9.529156684875488,
    "ent_coef": 0.051701825112104416,
    "learning_rate": 0.001
  },
  {
    "episode": 12366,
    "reward": 89.009911,
    "length": 68,
    "time": 179816.41892,
    "actor_loss": -65.09774017333984,
    "critic_loss": 4.296196937561035,
    "ent_coef": 0.05160188302397728,
    "learning_rate": 0.001
  },
  {
    "episode": 12367,
    "reward": 86.639198,
    "length": 68,
    "time": 179828.923535,
    "actor_loss": -66.89657592773438,
    "critic_loss": 4.425928592681885,
    "ent_coef": 0.04991740733385086,
    "learning_rate": 0.001
  },
  {
    "episode": 12368,
    "reward": 90.309665,
    "length": 65,
    "time": 179842.282317,
    "actor_loss": -67.68632507324219,
    "critic_loss": 7.327862739562988,
    "ent_coef": 0.05030674487352371,
    "learning_rate": 0.001
  },
  {
    "episode": 12369,
    "reward": 90.435589,
    "length": 61,
    "time": 179855.167213,
    "actor_loss": -74.1990737915039,
    "critic_loss": 48.64311981201172,
    "ent_coef": 0.05386687070131302,
    "learning_rate": 0.001
  },
  {
    "episode": 12370,
    "reward": 88.979644,
    "length": 65,
    "time": 179867.365446,
    "actor_loss": -64.31047821044922,
    "critic_loss": 5.753159523010254,
    "ent_coef": 0.054145511239767075,
    "learning_rate": 0.001
  },
  {
    "episode": 12371,
    "reward": 87.808715,
    "length": 67,
    "time": 179882.850037,
    "actor_loss": -68.47345733642578,
    "critic_loss": 38.53377151489258,
    "ent_coef": 0.05263159051537514,
    "learning_rate": 0.001
  },
  {
    "episode": 12372,
    "reward": 90.498237,
    "length": 62,
    "time": 179895.083915,
    "actor_loss": -64.3797607421875,
    "critic_loss": 3.285602569580078,
    "ent_coef": 0.05427161231637001,
    "learning_rate": 0.001
  },
  {
    "episode": 12373,
    "reward": 89.735816,
    "length": 64,
    "time": 179907.284943,
    "actor_loss": -62.641563415527344,
    "critic_loss": 39.12078094482422,
    "ent_coef": 0.05330006033182144,
    "learning_rate": 0.001
  },
  {
    "episode": 12374,
    "reward": 91.906839,
    "length": 61,
    "time": 179919.640634,
    "actor_loss": -71.80351257324219,
    "critic_loss": 16.048864364624023,
    "ent_coef": 0.05263504385948181,
    "learning_rate": 0.001
  },
  {
    "episode": 12375,
    "reward": 90.633024,
    "length": 64,
    "time": 179932.652838,
    "actor_loss": -64.26117706298828,
    "critic_loss": 5.056002616882324,
    "ent_coef": 0.05150717496871948,
    "learning_rate": 0.001
  },
  {
    "episode": 12376,
    "reward": 89.271263,
    "length": 65,
    "time": 179944.802714,
    "actor_loss": -65.89968872070312,
    "critic_loss": 8.908454895019531,
    "ent_coef": 0.051977913826704025,
    "learning_rate": 0.001
  },
  {
    "episode": 12377,
    "reward": 92.376747,
    "length": 59,
    "time": 179956.861011,
    "actor_loss": -68.35514068603516,
    "critic_loss": 4.633737564086914,
    "ent_coef": 0.05405465513467789,
    "learning_rate": 0.001
  },
  {
    "episode": 12378,
    "reward": 90.652773,
    "length": 62,
    "time": 179970.884041,
    "actor_loss": -68.63414001464844,
    "critic_loss": 44.63838195800781,
    "ent_coef": 0.05279700085520744,
    "learning_rate": 0.001
  },
  {
    "episode": 12379,
    "reward": 89.719521,
    "length": 63,
    "time": 179983.884377,
    "actor_loss": -68.34622192382812,
    "critic_loss": 8.918586730957031,
    "ent_coef": 0.052348215132951736,
    "learning_rate": 0.001
  },
  {
    "episode": 12380,
    "reward": 92.019793,
    "length": 60,
    "time": 179996.556767,
    "actor_loss": -67.3323745727539,
    "critic_loss": 4.015563011169434,
    "ent_coef": 0.054859671741724014,
    "learning_rate": 0.001
  },
  {
    "episode": 12381,
    "reward": 91.736715,
    "length": 61,
    "time": 180009.13383,
    "actor_loss": -70.26229858398438,
    "critic_loss": 21.04474639892578,
    "ent_coef": 0.05435052514076233,
    "learning_rate": 0.001
  },
  {
    "episode": 12382,
    "reward": 89.213967,
    "length": 65,
    "time": 180022.339749,
    "actor_loss": -74.41847229003906,
    "critic_loss": 24.425277709960938,
    "ent_coef": 0.053996846079826355,
    "learning_rate": 0.001
  },
  {
    "episode": 12383,
    "reward": 91.094668,
    "length": 61,
    "time": 180035.286536,
    "actor_loss": -72.53800964355469,
    "critic_loss": 8.817113876342773,
    "ent_coef": 0.05470520257949829,
    "learning_rate": 0.001
  },
  {
    "episode": 12384,
    "reward": 91.555582,
    "length": 60,
    "time": 180046.945018,
    "actor_loss": -72.79670715332031,
    "critic_loss": 19.637630462646484,
    "ent_coef": 0.05780966579914093,
    "learning_rate": 0.001
  },
  {
    "episode": 12385,
    "reward": 90.66687,
    "length": 60,
    "time": 180059.814126,
    "actor_loss": -68.47474670410156,
    "critic_loss": 6.905634880065918,
    "ent_coef": 0.06053004041314125,
    "learning_rate": 0.001
  },
  {
    "episode": 12386,
    "reward": 82.93122,
    "length": 77,
    "time": 180076.382611,
    "actor_loss": -65.48133850097656,
    "critic_loss": 2.7252626419067383,
    "ent_coef": 0.05728224292397499,
    "learning_rate": 0.001
  },
  {
    "episode": 12387,
    "reward": 86.973307,
    "length": 69,
    "time": 180089.54649,
    "actor_loss": -65.4109878540039,
    "critic_loss": 6.84689998626709,
    "ent_coef": 0.054127130657434464,
    "learning_rate": 0.001
  },
  {
    "episode": 12388,
    "reward": 91.379572,
    "length": 61,
    "time": 180102.919665,
    "actor_loss": -73.99071502685547,
    "critic_loss": 11.615355491638184,
    "ent_coef": 0.053866807371377945,
    "learning_rate": 0.001
  },
  {
    "episode": 12389,
    "reward": 88.384434,
    "length": 65,
    "time": 180115.243932,
    "actor_loss": -66.90994262695312,
    "critic_loss": 108.50244903564453,
    "ent_coef": 0.05236878991127014,
    "learning_rate": 0.001
  },
  {
    "episode": 12390,
    "reward": 90.177719,
    "length": 62,
    "time": 180127.490569,
    "actor_loss": -67.75923919677734,
    "critic_loss": 7.776511192321777,
    "ent_coef": 0.054618287831544876,
    "learning_rate": 0.001
  },
  {
    "episode": 12391,
    "reward": 88.704901,
    "length": 67,
    "time": 180142.084857,
    "actor_loss": -59.90861129760742,
    "critic_loss": 13.8639497756958,
    "ent_coef": 0.0530216284096241,
    "learning_rate": 0.001
  },
  {
    "episode": 12392,
    "reward": 89.003708,
    "length": 65,
    "time": 180155.511294,
    "actor_loss": -70.33683013916016,
    "critic_loss": 2.214592933654785,
    "ent_coef": 0.05162006616592407,
    "learning_rate": 0.001
  },
  {
    "episode": 12393,
    "reward": 91.009346,
    "length": 60,
    "time": 180169.135369,
    "actor_loss": -70.85246276855469,
    "critic_loss": 10.389852523803711,
    "ent_coef": 0.051308177411556244,
    "learning_rate": 0.001
  },
  {
    "episode": 12394,
    "reward": 91.785789,
    "length": 60,
    "time": 180180.895617,
    "actor_loss": -70.50820922851562,
    "critic_loss": 7.451910018920898,
    "ent_coef": 0.05247344821691513,
    "learning_rate": 0.001
  },
  {
    "episode": 12395,
    "reward": 88.398498,
    "length": 67,
    "time": 180193.838692,
    "actor_loss": -67.75120544433594,
    "critic_loss": 10.42008113861084,
    "ent_coef": 0.050810687243938446,
    "learning_rate": 0.001
  },
  {
    "episode": 12396,
    "reward": 90.566893,
    "length": 63,
    "time": 180206.867226,
    "actor_loss": -69.28739166259766,
    "critic_loss": 4.328621864318848,
    "ent_coef": 0.049282222986221313,
    "learning_rate": 0.001
  },
  {
    "episode": 12397,
    "reward": 89.868547,
    "length": 63,
    "time": 180220.909029,
    "actor_loss": -67.10840606689453,
    "critic_loss": 26.311723709106445,
    "ent_coef": 0.048209112137556076,
    "learning_rate": 0.001
  },
  {
    "episode": 12398,
    "reward": 90.463816,
    "length": 64,
    "time": 180233.931422,
    "actor_loss": -65.93974304199219,
    "critic_loss": 4.44956111907959,
    "ent_coef": 0.046182818710803986,
    "learning_rate": 0.001
  },
  {
    "episode": 12399,
    "reward": 90.55655,
    "length": 63,
    "time": 180247.305478,
    "actor_loss": -67.45729064941406,
    "critic_loss": 11.048149108886719,
    "ent_coef": 0.04614490270614624,
    "learning_rate": 0.001
  },
  {
    "episode": 12400,
    "reward": 91.460207,
    "length": 61,
    "time": 180258.666032,
    "actor_loss": -69.45892333984375,
    "critic_loss": 5.956465244293213,
    "ent_coef": 0.046991508454084396,
    "learning_rate": 0.001
  },
  {
    "episode": 12401,
    "reward": 91.341572,
    "length": 60,
    "time": 180271.152846,
    "actor_loss": -69.35993957519531,
    "critic_loss": 32.632530212402344,
    "ent_coef": 0.04937330633401871,
    "learning_rate": 0.001
  },
  {
    "episode": 12402,
    "reward": 89.238304,
    "length": 64,
    "time": 180284.067837,
    "actor_loss": -65.5396728515625,
    "critic_loss": 4.269415855407715,
    "ent_coef": 0.04946601018309593,
    "learning_rate": 0.001
  },
  {
    "episode": 12403,
    "reward": 91.572284,
    "length": 61,
    "time": 180296.347023,
    "actor_loss": -70.39884948730469,
    "critic_loss": 5.796172142028809,
    "ent_coef": 0.04866481572389603,
    "learning_rate": 0.001
  },
  {
    "episode": 12404,
    "reward": 88.188623,
    "length": 70,
    "time": 180312.446845,
    "actor_loss": -69.77678680419922,
    "critic_loss": 16.199871063232422,
    "ent_coef": 0.051159944385290146,
    "learning_rate": 0.001
  },
  {
    "episode": 12405,
    "reward": 90.966044,
    "length": 62,
    "time": 180325.055784,
    "actor_loss": -70.88610076904297,
    "critic_loss": 4.488134384155273,
    "ent_coef": 0.05335923656821251,
    "learning_rate": 0.001
  },
  {
    "episode": 12406,
    "reward": 89.685305,
    "length": 65,
    "time": 180339.038258,
    "actor_loss": -72.95787048339844,
    "critic_loss": 16.715648651123047,
    "ent_coef": 0.05274174362421036,
    "learning_rate": 0.001
  },
  {
    "episode": 12407,
    "reward": 90.980347,
    "length": 61,
    "time": 180351.733357,
    "actor_loss": -66.3428955078125,
    "critic_loss": 8.383556365966797,
    "ent_coef": 0.053682841360569,
    "learning_rate": 0.001
  },
  {
    "episode": 12408,
    "reward": 89.657391,
    "length": 63,
    "time": 180364.062625,
    "actor_loss": -68.287841796875,
    "critic_loss": 8.811868667602539,
    "ent_coef": 0.055384259670972824,
    "learning_rate": 0.001
  },
  {
    "episode": 12409,
    "reward": 90.700727,
    "length": 63,
    "time": 180375.270906,
    "actor_loss": -69.8097915649414,
    "critic_loss": 6.343719482421875,
    "ent_coef": 0.05517204850912094,
    "learning_rate": 0.001
  },
  {
    "episode": 12410,
    "reward": 91.375723,
    "length": 61,
    "time": 180387.291312,
    "actor_loss": -72.89178466796875,
    "critic_loss": 101.16909790039062,
    "ent_coef": 0.055806715041399,
    "learning_rate": 0.001
  },
  {
    "episode": 12411,
    "reward": 89.706486,
    "length": 64,
    "time": 180399.699196,
    "actor_loss": -69.4074478149414,
    "critic_loss": 4.665326118469238,
    "ent_coef": 0.05466708913445473,
    "learning_rate": 0.001
  },
  {
    "episode": 12412,
    "reward": 88.531912,
    "length": 65,
    "time": 180412.164149,
    "actor_loss": -64.80699157714844,
    "critic_loss": 5.305678367614746,
    "ent_coef": 0.05581224709749222,
    "learning_rate": 0.001
  },
  {
    "episode": 12413,
    "reward": 91.436768,
    "length": 61,
    "time": 180424.238517,
    "actor_loss": -75.43094635009766,
    "critic_loss": 22.31317138671875,
    "ent_coef": 0.06165951117873192,
    "learning_rate": 0.001
  },
  {
    "episode": 12414,
    "reward": 85.982301,
    "length": 70,
    "time": 180436.174942,
    "actor_loss": -71.96347045898438,
    "critic_loss": 34.49415969848633,
    "ent_coef": 0.059087011963129044,
    "learning_rate": 0.001
  },
  {
    "episode": 12415,
    "reward": 85.285065,
    "length": 72,
    "time": 180448.963833,
    "actor_loss": -69.4791488647461,
    "critic_loss": 3.588885545730591,
    "ent_coef": 0.056305576115846634,
    "learning_rate": 0.001
  },
  {
    "episode": 12416,
    "reward": 88.294756,
    "length": 68,
    "time": 180460.666674,
    "actor_loss": -70.47857666015625,
    "critic_loss": 17.671249389648438,
    "ent_coef": 0.055250030010938644,
    "learning_rate": 0.001
  },
  {
    "episode": 12417,
    "reward": 88.897566,
    "length": 65,
    "time": 180477.233697,
    "actor_loss": -67.78803253173828,
    "critic_loss": 7.270456790924072,
    "ent_coef": 0.05491796135902405,
    "learning_rate": 0.001
  },
  {
    "episode": 12418,
    "reward": 91.982938,
    "length": 59,
    "time": 180491.248113,
    "actor_loss": -73.07743072509766,
    "critic_loss": 4.024966716766357,
    "ent_coef": 0.05552949383854866,
    "learning_rate": 0.001
  },
  {
    "episode": 12419,
    "reward": 88.836583,
    "length": 66,
    "time": 180505.121941,
    "actor_loss": -68.953857421875,
    "critic_loss": 89.19378662109375,
    "ent_coef": 0.05438295379281044,
    "learning_rate": 0.001
  },
  {
    "episode": 12420,
    "reward": 89.323543,
    "length": 65,
    "time": 180518.564841,
    "actor_loss": -67.7066650390625,
    "critic_loss": 4.8471293449401855,
    "ent_coef": 0.05226651579141617,
    "learning_rate": 0.001
  },
  {
    "episode": 12421,
    "reward": 87.942523,
    "length": 67,
    "time": 180534.239911,
    "actor_loss": -67.00040435791016,
    "critic_loss": 32.482933044433594,
    "ent_coef": 0.050047777593135834,
    "learning_rate": 0.001
  },
  {
    "episode": 12422,
    "reward": 89.283214,
    "length": 66,
    "time": 180546.298023,
    "actor_loss": -68.95712280273438,
    "critic_loss": 5.203869819641113,
    "ent_coef": 0.04670698195695877,
    "learning_rate": 0.001
  },
  {
    "episode": 12423,
    "reward": 87.570457,
    "length": 67,
    "time": 180560.854968,
    "actor_loss": -69.14098358154297,
    "critic_loss": 15.032998085021973,
    "ent_coef": 0.04514734074473381,
    "learning_rate": 0.001
  },
  {
    "episode": 12424,
    "reward": 87.875236,
    "length": 68,
    "time": 180573.141893,
    "actor_loss": -71.49858093261719,
    "critic_loss": 6.944531440734863,
    "ent_coef": 0.04655640199780464,
    "learning_rate": 0.001
  },
  {
    "episode": 12425,
    "reward": 92.593953,
    "length": 57,
    "time": 180585.100375,
    "actor_loss": -72.9410400390625,
    "critic_loss": 10.19931411743164,
    "ent_coef": 0.051450248807668686,
    "learning_rate": 0.001
  },
  {
    "episode": 12426,
    "reward": 90.372095,
    "length": 62,
    "time": 180597.573442,
    "actor_loss": -67.71985626220703,
    "critic_loss": 2.9323978424072266,
    "ent_coef": 0.054664041846990585,
    "learning_rate": 0.001
  },
  {
    "episode": 12427,
    "reward": 90.935321,
    "length": 61,
    "time": 180608.475582,
    "actor_loss": -66.2498779296875,
    "critic_loss": 6.345582008361816,
    "ent_coef": 0.056489359587430954,
    "learning_rate": 0.001
  },
  {
    "episode": 12428,
    "reward": 89.975969,
    "length": 63,
    "time": 180620.010238,
    "actor_loss": -74.61054992675781,
    "critic_loss": 7.840915679931641,
    "ent_coef": 0.055625561624765396,
    "learning_rate": 0.001
  },
  {
    "episode": 12429,
    "reward": 90.008682,
    "length": 64,
    "time": 180633.620688,
    "actor_loss": -72.21539306640625,
    "critic_loss": 15.188610076904297,
    "ent_coef": 0.056868623942136765,
    "learning_rate": 0.001
  },
  {
    "episode": 12430,
    "reward": 90.585026,
    "length": 62,
    "time": 180645.423058,
    "actor_loss": -71.07089233398438,
    "critic_loss": 4.110074996948242,
    "ent_coef": 0.0571967177093029,
    "learning_rate": 0.001
  },
  {
    "episode": 12431,
    "reward": 89.568708,
    "length": 65,
    "time": 180657.312938,
    "actor_loss": -66.16167449951172,
    "critic_loss": 6.126473903656006,
    "ent_coef": 0.05716387555003166,
    "learning_rate": 0.001
  },
  {
    "episode": 12432,
    "reward": 89.317747,
    "length": 64,
    "time": 180669.996522,
    "actor_loss": -73.53172302246094,
    "critic_loss": 2.541041851043701,
    "ent_coef": 0.056975048035383224,
    "learning_rate": 0.001
  },
  {
    "episode": 12433,
    "reward": 91.893053,
    "length": 60,
    "time": 180682.536705,
    "actor_loss": -68.42082214355469,
    "critic_loss": 7.265133857727051,
    "ent_coef": 0.058262959122657776,
    "learning_rate": 0.001
  },
  {
    "episode": 12434,
    "reward": 89.92243,
    "length": 63,
    "time": 180694.241952,
    "actor_loss": -72.43394470214844,
    "critic_loss": 29.757137298583984,
    "ent_coef": 0.05822208151221275,
    "learning_rate": 0.001
  },
  {
    "episode": 12435,
    "reward": 91.445502,
    "length": 60,
    "time": 180705.579292,
    "actor_loss": -73.296630859375,
    "critic_loss": 11.736398696899414,
    "ent_coef": 0.05814293026924133,
    "learning_rate": 0.001
  },
  {
    "episode": 12436,
    "reward": 89.831848,
    "length": 63,
    "time": 180719.479741,
    "actor_loss": -69.75608825683594,
    "critic_loss": 2.6821248531341553,
    "ent_coef": 0.05952975153923035,
    "learning_rate": 0.001
  },
  {
    "episode": 12437,
    "reward": 88.84332,
    "length": 65,
    "time": 180731.197673,
    "actor_loss": -71.8817138671875,
    "critic_loss": 8.052594184875488,
    "ent_coef": 0.05982552841305733,
    "learning_rate": 0.001
  },
  {
    "episode": 12438,
    "reward": 90.532477,
    "length": 63,
    "time": 180745.148916,
    "actor_loss": -70.04011535644531,
    "critic_loss": 5.852651596069336,
    "ent_coef": 0.05894438177347183,
    "learning_rate": 0.001
  },
  {
    "episode": 12439,
    "reward": 88.781585,
    "length": 65,
    "time": 180757.92545,
    "actor_loss": -69.23603820800781,
    "critic_loss": 2.391023635864258,
    "ent_coef": 0.05861261487007141,
    "learning_rate": 0.001
  },
  {
    "episode": 12440,
    "reward": 90.202698,
    "length": 63,
    "time": 180770.256232,
    "actor_loss": -70.33914184570312,
    "critic_loss": 4.050313472747803,
    "ent_coef": 0.058202456682920456,
    "learning_rate": 0.001
  },
  {
    "episode": 12441,
    "reward": 91.210602,
    "length": 62,
    "time": 180788.352245,
    "actor_loss": -74.64812469482422,
    "critic_loss": 17.896221160888672,
    "ent_coef": 0.05746674910187721,
    "learning_rate": 0.001
  },
  {
    "episode": 12442,
    "reward": 90.257783,
    "length": 63,
    "time": 180800.168514,
    "actor_loss": -71.96926879882812,
    "critic_loss": 27.572368621826172,
    "ent_coef": 0.05730847269296646,
    "learning_rate": 0.001
  },
  {
    "episode": 12443,
    "reward": 91.931554,
    "length": 59,
    "time": 180811.44219,
    "actor_loss": -70.244140625,
    "critic_loss": 2.8537888526916504,
    "ent_coef": 0.05916585400700569,
    "learning_rate": 0.001
  },
  {
    "episode": 12444,
    "reward": 90.356224,
    "length": 62,
    "time": 180823.234093,
    "actor_loss": -69.97144317626953,
    "critic_loss": 2.579102039337158,
    "ent_coef": 0.06099933013319969,
    "learning_rate": 0.001
  },
  {
    "episode": 12445,
    "reward": 90.898087,
    "length": 61,
    "time": 180835.367043,
    "actor_loss": -65.2900161743164,
    "critic_loss": 8.453174591064453,
    "ent_coef": 0.06476648151874542,
    "learning_rate": 0.001
  },
  {
    "episode": 12446,
    "reward": 91.825373,
    "length": 60,
    "time": 180851.301841,
    "actor_loss": -66.8314437866211,
    "critic_loss": 20.118484497070312,
    "ent_coef": 0.06580759584903717,
    "learning_rate": 0.001
  },
  {
    "episode": 12447,
    "reward": 91.538439,
    "length": 59,
    "time": 180863.708291,
    "actor_loss": -75.10528564453125,
    "critic_loss": 3.1731619834899902,
    "ent_coef": 0.06738326698541641,
    "learning_rate": 0.001
  },
  {
    "episode": 12448,
    "reward": 92.690868,
    "length": 58,
    "time": 180876.534077,
    "actor_loss": -78.28170013427734,
    "critic_loss": 13.828775405883789,
    "ent_coef": 0.0689629539847374,
    "learning_rate": 0.001
  },
  {
    "episode": 12449,
    "reward": 91.201737,
    "length": 61,
    "time": 180888.439505,
    "actor_loss": -72.44319915771484,
    "critic_loss": 5.894455909729004,
    "ent_coef": 0.07035414129495621,
    "learning_rate": 0.001
  },
  {
    "episode": 12450,
    "reward": 91.544815,
    "length": 59,
    "time": 180900.597466,
    "actor_loss": -65.4000244140625,
    "critic_loss": 3.257936954498291,
    "ent_coef": 0.0732724592089653,
    "learning_rate": 0.001
  },
  {
    "episode": 12451,
    "reward": 89.696912,
    "length": 63,
    "time": 180914.834286,
    "actor_loss": -65.56291961669922,
    "critic_loss": 57.10407257080078,
    "ent_coef": 0.07213284820318222,
    "learning_rate": 0.001
  },
  {
    "episode": 12452,
    "reward": 90.80049,
    "length": 61,
    "time": 180926.013665,
    "actor_loss": -68.21469116210938,
    "critic_loss": 5.462830543518066,
    "ent_coef": 0.07065299153327942,
    "learning_rate": 0.001
  },
  {
    "episode": 12453,
    "reward": 91.099773,
    "length": 60,
    "time": 180937.079901,
    "actor_loss": -69.51853942871094,
    "critic_loss": 9.598539352416992,
    "ent_coef": 0.06875419616699219,
    "learning_rate": 0.001
  },
  {
    "episode": 12454,
    "reward": 90.28566,
    "length": 62,
    "time": 180950.212614,
    "actor_loss": -71.49250793457031,
    "critic_loss": 5.22968053817749,
    "ent_coef": 0.06835053116083145,
    "learning_rate": 0.001
  },
  {
    "episode": 12455,
    "reward": 90.386827,
    "length": 63,
    "time": 180961.426305,
    "actor_loss": -76.44673156738281,
    "critic_loss": 12.21021842956543,
    "ent_coef": 0.06550808995962143,
    "learning_rate": 0.001
  },
  {
    "episode": 12456,
    "reward": 90.294521,
    "length": 62,
    "time": 180976.008951,
    "actor_loss": -76.657958984375,
    "critic_loss": 3.1708154678344727,
    "ent_coef": 0.06265289336442947,
    "learning_rate": 0.001
  },
  {
    "episode": 12457,
    "reward": 89.477233,
    "length": 65,
    "time": 180988.927383,
    "actor_loss": -70.70793914794922,
    "critic_loss": 3.7663679122924805,
    "ent_coef": 0.05960093066096306,
    "learning_rate": 0.001
  },
  {
    "episode": 12458,
    "reward": 91.122753,
    "length": 61,
    "time": 181004.163806,
    "actor_loss": -68.977783203125,
    "critic_loss": 8.653911590576172,
    "ent_coef": 0.05908355861902237,
    "learning_rate": 0.001
  },
  {
    "episode": 12459,
    "reward": 88.282988,
    "length": 67,
    "time": 181018.667833,
    "actor_loss": -71.05250549316406,
    "critic_loss": 5.44576358795166,
    "ent_coef": 0.05765525624155998,
    "learning_rate": 0.001
  },
  {
    "episode": 12460,
    "reward": 89.934985,
    "length": 63,
    "time": 181030.880396,
    "actor_loss": -69.61882019042969,
    "critic_loss": 4.43796443939209,
    "ent_coef": 0.05492740124464035,
    "learning_rate": 0.001
  },
  {
    "episode": 12461,
    "reward": 90.878271,
    "length": 61,
    "time": 181044.977297,
    "actor_loss": -65.15025329589844,
    "critic_loss": 8.736727714538574,
    "ent_coef": 0.054600007832050323,
    "learning_rate": 0.001
  },
  {
    "episode": 12462,
    "reward": 88.314773,
    "length": 66,
    "time": 181057.482939,
    "actor_loss": -72.89634704589844,
    "critic_loss": 54.67621612548828,
    "ent_coef": 0.05254651978611946,
    "learning_rate": 0.001
  },
  {
    "episode": 12463,
    "reward": 90.508683,
    "length": 62,
    "time": 181068.849411,
    "actor_loss": -68.91903686523438,
    "critic_loss": 32.16197204589844,
    "ent_coef": 0.05214843153953552,
    "learning_rate": 0.001
  },
  {
    "episode": 12464,
    "reward": 90.704694,
    "length": 61,
    "time": 181082.151274,
    "actor_loss": -66.49271392822266,
    "critic_loss": 5.071755886077881,
    "ent_coef": 0.05339740216732025,
    "learning_rate": 0.001
  },
  {
    "episode": 12465,
    "reward": 90.315565,
    "length": 62,
    "time": 181096.392121,
    "actor_loss": -72.21207427978516,
    "critic_loss": 30.79387855529785,
    "ent_coef": 0.05433504283428192,
    "learning_rate": 0.001
  },
  {
    "episode": 12466,
    "reward": 90.0722,
    "length": 62,
    "time": 181107.573105,
    "actor_loss": -70.35311889648438,
    "critic_loss": 3.719083547592163,
    "ent_coef": 0.055665891617536545,
    "learning_rate": 0.001
  },
  {
    "episode": 12467,
    "reward": 89.862712,
    "length": 63,
    "time": 181118.714678,
    "actor_loss": -71.19197082519531,
    "critic_loss": 28.529335021972656,
    "ent_coef": 0.05974524840712547,
    "learning_rate": 0.001
  },
  {
    "episode": 12468,
    "reward": 90.627401,
    "length": 63,
    "time": 181133.512899,
    "actor_loss": -73.926025390625,
    "critic_loss": 4.028912544250488,
    "ent_coef": 0.06017546355724335,
    "learning_rate": 0.001
  },
  {
    "episode": 12469,
    "reward": 87.964725,
    "length": 71,
    "time": 181146.818116,
    "actor_loss": -71.9072265625,
    "critic_loss": 25.260475158691406,
    "ent_coef": 0.061918240040540695,
    "learning_rate": 0.001
  },
  {
    "episode": 12470,
    "reward": 90.537099,
    "length": 62,
    "time": 181159.109846,
    "actor_loss": -73.0421142578125,
    "critic_loss": 10.59111499786377,
    "ent_coef": 0.06300350278615952,
    "learning_rate": 0.001
  },
  {
    "episode": 12471,
    "reward": 91.830261,
    "length": 60,
    "time": 181171.373652,
    "actor_loss": -67.69349670410156,
    "critic_loss": 7.681748390197754,
    "ent_coef": 0.06305345147848129,
    "learning_rate": 0.001
  },
  {
    "episode": 12472,
    "reward": 94.050549,
    "length": 54,
    "time": 181188.334811,
    "actor_loss": -69.10803985595703,
    "critic_loss": 2.5084714889526367,
    "ent_coef": 0.06387848407030106,
    "learning_rate": 0.001
  },
  {
    "episode": 12473,
    "reward": 94.313792,
    "length": 55,
    "time": 181202.529399,
    "actor_loss": -66.72598266601562,
    "critic_loss": 24.406219482421875,
    "ent_coef": 0.06404288858175278,
    "learning_rate": 0.001
  },
  {
    "episode": 12474,
    "reward": 93.623513,
    "length": 55,
    "time": 181214.240145,
    "actor_loss": -68.21759796142578,
    "critic_loss": 6.711944580078125,
    "ent_coef": 0.06569847464561462,
    "learning_rate": 0.001
  },
  {
    "episode": 12475,
    "reward": 93.680482,
    "length": 56,
    "time": 181229.788315,
    "actor_loss": -71.38648986816406,
    "critic_loss": 4.726531505584717,
    "ent_coef": 0.0660928413271904,
    "learning_rate": 0.001
  },
  {
    "episode": 12476,
    "reward": 90.966672,
    "length": 60,
    "time": 181242.445882,
    "actor_loss": -71.90625,
    "critic_loss": 4.503507614135742,
    "ent_coef": 0.06512944400310516,
    "learning_rate": 0.001
  },
  {
    "episode": 12477,
    "reward": 92.894557,
    "length": 56,
    "time": 181255.448963,
    "actor_loss": -65.1355209350586,
    "critic_loss": 70.08554077148438,
    "ent_coef": 0.06270188093185425,
    "learning_rate": 0.001
  },
  {
    "episode": 12478,
    "reward": 94.22162,
    "length": 54,
    "time": 181267.35443,
    "actor_loss": -75.86514282226562,
    "critic_loss": 10.669833183288574,
    "ent_coef": 0.06651882082223892,
    "learning_rate": 0.001
  },
  {
    "episode": 12479,
    "reward": 94.594894,
    "length": 54,
    "time": 181279.520798,
    "actor_loss": -65.5341567993164,
    "critic_loss": 13.377389907836914,
    "ent_coef": 0.06712355464696884,
    "learning_rate": 0.001
  },
  {
    "episode": 12480,
    "reward": 94.486477,
    "length": 53,
    "time": 181292.183222,
    "actor_loss": -66.36585998535156,
    "critic_loss": 5.7059102058410645,
    "ent_coef": 0.06900917738676071,
    "learning_rate": 0.001
  },
  {
    "episode": 12481,
    "reward": 93.145244,
    "length": 57,
    "time": 181305.208907,
    "actor_loss": -63.38337326049805,
    "critic_loss": 6.30271053314209,
    "ent_coef": 0.06916026771068573,
    "learning_rate": 0.001
  },
  {
    "episode": 12482,
    "reward": 93.740091,
    "length": 56,
    "time": 181318.148916,
    "actor_loss": -72.01457214355469,
    "critic_loss": 6.502945899963379,
    "ent_coef": 0.06702766567468643,
    "learning_rate": 0.001
  },
  {
    "episode": 12483,
    "reward": 94.624017,
    "length": 54,
    "time": 181330.171415,
    "actor_loss": -69.07537841796875,
    "critic_loss": 6.42530632019043,
    "ent_coef": 0.06479264795780182,
    "learning_rate": 0.001
  },
  {
    "episode": 12484,
    "reward": 93.502732,
    "length": 55,
    "time": 181342.35915,
    "actor_loss": -73.11900329589844,
    "critic_loss": 3.6338937282562256,
    "ent_coef": 0.06403625011444092,
    "learning_rate": 0.001
  },
  {
    "episode": 12485,
    "reward": 91.969925,
    "length": 63,
    "time": 181355.571196,
    "actor_loss": -74.12590026855469,
    "critic_loss": 9.614317893981934,
    "ent_coef": 0.06127284839749336,
    "learning_rate": 0.001
  },
  {
    "episode": 12486,
    "reward": 92.86411,
    "length": 58,
    "time": 181368.947357,
    "actor_loss": -66.85537719726562,
    "critic_loss": 8.416142463684082,
    "ent_coef": 0.05903555825352669,
    "learning_rate": 0.001
  },
  {
    "episode": 12487,
    "reward": 90.210993,
    "length": 63,
    "time": 181383.036788,
    "actor_loss": -67.45512390136719,
    "critic_loss": 4.407157897949219,
    "ent_coef": 0.05429888516664505,
    "learning_rate": 0.001
  },
  {
    "episode": 12488,
    "reward": 91.22209,
    "length": 61,
    "time": 181396.288867,
    "actor_loss": -70.40791320800781,
    "critic_loss": 6.429485321044922,
    "ent_coef": 0.05203431844711304,
    "learning_rate": 0.001
  },
  {
    "episode": 12489,
    "reward": 93.054788,
    "length": 57,
    "time": 181409.917604,
    "actor_loss": -75.58246612548828,
    "critic_loss": 5.713796615600586,
    "ent_coef": 0.0533846877515316,
    "learning_rate": 0.001
  },
  {
    "episode": 12490,
    "reward": 93.848646,
    "length": 55,
    "time": 181424.5845,
    "actor_loss": -66.5890884399414,
    "critic_loss": 2.82893705368042,
    "ent_coef": 0.0532916896045208,
    "learning_rate": 0.001
  },
  {
    "episode": 12491,
    "reward": 93.413317,
    "length": 56,
    "time": 181440.087262,
    "actor_loss": -71.873779296875,
    "critic_loss": 3.4426732063293457,
    "ent_coef": 0.05378276854753494,
    "learning_rate": 0.001
  },
  {
    "episode": 12492,
    "reward": 93.347288,
    "length": 55,
    "time": 181454.514288,
    "actor_loss": -70.44273376464844,
    "critic_loss": 27.91509246826172,
    "ent_coef": 0.05403515696525574,
    "learning_rate": 0.001
  },
  {
    "episode": 12493,
    "reward": 93.608342,
    "length": 57,
    "time": 181469.078898,
    "actor_loss": -70.11354064941406,
    "critic_loss": 3.60235857963562,
    "ent_coef": 0.054016780108213425,
    "learning_rate": 0.001
  },
  {
    "episode": 12494,
    "reward": 94.172799,
    "length": 55,
    "time": 181480.893759,
    "actor_loss": -75.62254333496094,
    "critic_loss": 19.50648307800293,
    "ent_coef": 0.054337866604328156,
    "learning_rate": 0.001
  },
  {
    "episode": 12495,
    "reward": 93.665832,
    "length": 57,
    "time": 181495.351627,
    "actor_loss": -65.12510681152344,
    "critic_loss": 11.458845138549805,
    "ent_coef": 0.0544176883995533,
    "learning_rate": 0.001
  },
  {
    "episode": 12496,
    "reward": 94.230333,
    "length": 55,
    "time": 181507.959068,
    "actor_loss": -70.51274871826172,
    "critic_loss": 5.244680881500244,
    "ent_coef": 0.0552448108792305,
    "learning_rate": 0.001
  },
  {
    "episode": 12497,
    "reward": 92.952323,
    "length": 57,
    "time": 181520.539467,
    "actor_loss": -67.94364929199219,
    "critic_loss": 3.552471160888672,
    "ent_coef": 0.05422166734933853,
    "learning_rate": 0.001
  },
  {
    "episode": 12498,
    "reward": 93.896885,
    "length": 58,
    "time": 181533.078184,
    "actor_loss": -68.1676025390625,
    "critic_loss": 4.435641288757324,
    "ent_coef": 0.053339406847953796,
    "learning_rate": 0.001
  },
  {
    "episode": 12499,
    "reward": 94.38753,
    "length": 55,
    "time": 181545.979092,
    "actor_loss": -66.36994934082031,
    "critic_loss": 4.230281829833984,
    "ent_coef": 0.05422326549887657,
    "learning_rate": 0.001
  },
  {
    "episode": 12500,
    "reward": 94.219067,
    "length": 56,
    "time": 181559.270544,
    "actor_loss": -63.4969367980957,
    "critic_loss": 3.7733707427978516,
    "ent_coef": 0.05420076474547386,
    "learning_rate": 0.001
  },
  {
    "episode": 12501,
    "reward": 93.553064,
    "length": 58,
    "time": 181572.969382,
    "actor_loss": -68.16593933105469,
    "critic_loss": 28.79082489013672,
    "ent_coef": 0.05347887799143791,
    "learning_rate": 0.001
  },
  {
    "episode": 12502,
    "reward": 90.894462,
    "length": 61,
    "time": 181585.229543,
    "actor_loss": -65.2490005493164,
    "critic_loss": 7.225947380065918,
    "ent_coef": 0.053902678191661835,
    "learning_rate": 0.001
  },
  {
    "episode": 12503,
    "reward": 92.22622,
    "length": 60,
    "time": 181597.151699,
    "actor_loss": -65.54570007324219,
    "critic_loss": 77.63002014160156,
    "ent_coef": 0.05700930580496788,
    "learning_rate": 0.001
  },
  {
    "episode": 12504,
    "reward": 91.258383,
    "length": 62,
    "time": 181608.82228,
    "actor_loss": -69.65291595458984,
    "critic_loss": 4.801261901855469,
    "ent_coef": 0.06005203351378441,
    "learning_rate": 0.001
  },
  {
    "episode": 12505,
    "reward": 89.724326,
    "length": 68,
    "time": 181621.050856,
    "actor_loss": -70.86744689941406,
    "critic_loss": 26.284271240234375,
    "ent_coef": 0.05958514288067818,
    "learning_rate": 0.001
  },
  {
    "episode": 12506,
    "reward": 90.168328,
    "length": 63,
    "time": 181634.645129,
    "actor_loss": -77.62411499023438,
    "critic_loss": 33.321800231933594,
    "ent_coef": 0.058720819652080536,
    "learning_rate": 0.001
  },
  {
    "episode": 12507,
    "reward": 90.024678,
    "length": 65,
    "time": 181647.089813,
    "actor_loss": -67.4878158569336,
    "critic_loss": 11.25804615020752,
    "ent_coef": 0.05420239642262459,
    "learning_rate": 0.001
  },
  {
    "episode": 12508,
    "reward": 88.703618,
    "length": 67,
    "time": 181659.780049,
    "actor_loss": -70.87861633300781,
    "critic_loss": 3.599773406982422,
    "ent_coef": 0.04983293265104294,
    "learning_rate": 0.001
  },
  {
    "episode": 12509,
    "reward": 90.985494,
    "length": 63,
    "time": 181671.199008,
    "actor_loss": -71.00355529785156,
    "critic_loss": 6.6497483253479,
    "ent_coef": 0.04924003407359123,
    "learning_rate": 0.001
  },
  {
    "episode": 12510,
    "reward": 91.316567,
    "length": 62,
    "time": 181682.818987,
    "actor_loss": -71.33222961425781,
    "critic_loss": 2.705742835998535,
    "ent_coef": 0.048011548817157745,
    "learning_rate": 0.001
  },
  {
    "episode": 12511,
    "reward": 91.589558,
    "length": 60,
    "time": 181695.402495,
    "actor_loss": -66.31828308105469,
    "critic_loss": 4.814963340759277,
    "ent_coef": 0.04914163425564766,
    "learning_rate": 0.001
  },
  {
    "episode": 12512,
    "reward": 90.786299,
    "length": 64,
    "time": 181707.726944,
    "actor_loss": -73.265625,
    "critic_loss": 4.427992820739746,
    "ent_coef": 0.048783477395772934,
    "learning_rate": 0.001
  },
  {
    "episode": 12513,
    "reward": 89.99538,
    "length": 65,
    "time": 181720.221083,
    "actor_loss": -74.87332153320312,
    "critic_loss": 82.79916381835938,
    "ent_coef": 0.0473150908946991,
    "learning_rate": 0.001
  },
  {
    "episode": 12514,
    "reward": 91.375949,
    "length": 61,
    "time": 181731.732641,
    "actor_loss": -76.01792907714844,
    "critic_loss": 3.497173547744751,
    "ent_coef": 0.04748493432998657,
    "learning_rate": 0.001
  },
  {
    "episode": 12515,
    "reward": 90.982506,
    "length": 63,
    "time": 181743.143744,
    "actor_loss": -66.24005889892578,
    "critic_loss": 10.217937469482422,
    "ent_coef": 0.047729842364788055,
    "learning_rate": 0.001
  },
  {
    "episode": 12516,
    "reward": 89.200381,
    "length": 71,
    "time": 181756.608543,
    "actor_loss": -66.83267211914062,
    "critic_loss": 4.780182838439941,
    "ent_coef": 0.048261966556310654,
    "learning_rate": 0.001
  },
  {
    "episode": 12517,
    "reward": 89.039776,
    "length": 69,
    "time": 181769.184539,
    "actor_loss": -67.69719696044922,
    "critic_loss": 2.98321270942688,
    "ent_coef": 0.05180048570036888,
    "learning_rate": 0.001
  },
  {
    "episode": 12518,
    "reward": 89.923116,
    "length": 64,
    "time": 181781.885911,
    "actor_loss": -71.87666320800781,
    "critic_loss": 8.103961944580078,
    "ent_coef": 0.05373941361904144,
    "learning_rate": 0.001
  },
  {
    "episode": 12519,
    "reward": 90.065459,
    "length": 67,
    "time": 181794.614876,
    "actor_loss": -76.68948364257812,
    "critic_loss": 40.2474479675293,
    "ent_coef": 0.05534147098660469,
    "learning_rate": 0.001
  },
  {
    "episode": 12520,
    "reward": 86.037823,
    "length": 78,
    "time": 181808.658141,
    "actor_loss": -74.14010620117188,
    "critic_loss": 45.94615936279297,
    "ent_coef": 0.058200374245643616,
    "learning_rate": 0.001
  },
  {
    "episode": 12521,
    "reward": 87.405166,
    "length": 70,
    "time": 181821.876663,
    "actor_loss": -68.7717514038086,
    "critic_loss": 12.284884452819824,
    "ent_coef": 0.05825040489435196,
    "learning_rate": 0.001
  },
  {
    "episode": 12522,
    "reward": 87.693956,
    "length": 72,
    "time": 181834.770294,
    "actor_loss": -68.3520736694336,
    "critic_loss": 8.177892684936523,
    "ent_coef": 0.058011483401060104,
    "learning_rate": 0.001
  },
  {
    "episode": 12523,
    "reward": 91.200215,
    "length": 62,
    "time": 181848.971074,
    "actor_loss": -67.49685668945312,
    "critic_loss": 16.572343826293945,
    "ent_coef": 0.05939798802137375,
    "learning_rate": 0.001
  },
  {
    "episode": 12524,
    "reward": 89.303207,
    "length": 63,
    "time": 181862.588571,
    "actor_loss": -76.01176452636719,
    "critic_loss": 11.107634544372559,
    "ent_coef": 0.057905275374650955,
    "learning_rate": 0.001
  },
  {
    "episode": 12525,
    "reward": 89.746067,
    "length": 64,
    "time": 181875.475421,
    "actor_loss": -67.37867736816406,
    "critic_loss": 10.282554626464844,
    "ent_coef": 0.05819584056735039,
    "learning_rate": 0.001
  },
  {
    "episode": 12526,
    "reward": 90.61896,
    "length": 66,
    "time": 181889.385395,
    "actor_loss": -71.50588989257812,
    "critic_loss": 3.256960868835449,
    "ent_coef": 0.05826082080602646,
    "learning_rate": 0.001
  },
  {
    "episode": 12527,
    "reward": 91.17889,
    "length": 62,
    "time": 181901.336429,
    "actor_loss": -70.00747680664062,
    "critic_loss": 7.062769889831543,
    "ent_coef": 0.06084240600466728,
    "learning_rate": 0.001
  },
  {
    "episode": 12528,
    "reward": 92.492727,
    "length": 58,
    "time": 181913.171818,
    "actor_loss": -73.40768432617188,
    "critic_loss": 24.517749786376953,
    "ent_coef": 0.06496109068393707,
    "learning_rate": 0.001
  },
  {
    "episode": 12529,
    "reward": 91.844761,
    "length": 61,
    "time": 181927.498065,
    "actor_loss": -71.19269561767578,
    "critic_loss": 118.11920166015625,
    "ent_coef": 0.06618611514568329,
    "learning_rate": 0.001
  },
  {
    "episode": 12530,
    "reward": 89.99157,
    "length": 63,
    "time": 181940.516106,
    "actor_loss": -70.28062438964844,
    "critic_loss": 8.048168182373047,
    "ent_coef": 0.06549263000488281,
    "learning_rate": 0.001
  },
  {
    "episode": 12531,
    "reward": 85.595595,
    "length": 70,
    "time": 181954.723903,
    "actor_loss": -73.71809387207031,
    "critic_loss": 4.999575614929199,
    "ent_coef": 0.06318093836307526,
    "learning_rate": 0.001
  },
  {
    "episode": 12532,
    "reward": 87.581084,
    "length": 67,
    "time": 181967.463688,
    "actor_loss": -67.61817932128906,
    "critic_loss": 4.172208309173584,
    "ent_coef": 0.05968858674168587,
    "learning_rate": 0.001
  },
  {
    "episode": 12533,
    "reward": 90.351811,
    "length": 66,
    "time": 181983.113924,
    "actor_loss": -74.328125,
    "critic_loss": 23.034578323364258,
    "ent_coef": 0.057327959686517715,
    "learning_rate": 0.001
  },
  {
    "episode": 12534,
    "reward": 91.038436,
    "length": 62,
    "time": 181997.669514,
    "actor_loss": -71.557861328125,
    "critic_loss": 12.779953002929688,
    "ent_coef": 0.05553116276860237,
    "learning_rate": 0.001
  },
  {
    "episode": 12535,
    "reward": 88.889443,
    "length": 65,
    "time": 182009.985563,
    "actor_loss": -67.79388427734375,
    "critic_loss": 146.84005737304688,
    "ent_coef": 0.05461754649877548,
    "learning_rate": 0.001
  },
  {
    "episode": 12536,
    "reward": 90.322116,
    "length": 62,
    "time": 182022.912933,
    "actor_loss": -73.3912353515625,
    "critic_loss": 30.059093475341797,
    "ent_coef": 0.05224629491567612,
    "learning_rate": 0.001
  },
  {
    "episode": 12537,
    "reward": 90.846317,
    "length": 62,
    "time": 182035.15325,
    "actor_loss": -70.14981842041016,
    "critic_loss": 6.33577823638916,
    "ent_coef": 0.050201330333948135,
    "learning_rate": 0.001
  },
  {
    "episode": 12538,
    "reward": 91.12295,
    "length": 62,
    "time": 182048.506005,
    "actor_loss": -73.7251968383789,
    "critic_loss": 2.569103717803955,
    "ent_coef": 0.04763443022966385,
    "learning_rate": 0.001
  },
  {
    "episode": 12539,
    "reward": 90.226903,
    "length": 63,
    "time": 182062.33523,
    "actor_loss": -68.926513671875,
    "critic_loss": 5.165748119354248,
    "ent_coef": 0.045737773180007935,
    "learning_rate": 0.001
  },
  {
    "episode": 12540,
    "reward": 89.885191,
    "length": 65,
    "time": 182075.488697,
    "actor_loss": -73.71980285644531,
    "critic_loss": 6.7315754890441895,
    "ent_coef": 0.04597105458378792,
    "learning_rate": 0.001
  },
  {
    "episode": 12541,
    "reward": 89.624349,
    "length": 65,
    "time": 182089.41085,
    "actor_loss": -73.25413513183594,
    "critic_loss": 4.801122665405273,
    "ent_coef": 0.04404356703162193,
    "learning_rate": 0.001
  },
  {
    "episode": 12542,
    "reward": 91.442361,
    "length": 61,
    "time": 182102.362626,
    "actor_loss": -70.0440444946289,
    "critic_loss": 3.3155272006988525,
    "ent_coef": 0.044657718390226364,
    "learning_rate": 0.001
  },
  {
    "episode": 12543,
    "reward": 90.761692,
    "length": 62,
    "time": 182115.374921,
    "actor_loss": -68.12950897216797,
    "critic_loss": 13.400494575500488,
    "ent_coef": 0.04618093743920326,
    "learning_rate": 0.001
  },
  {
    "episode": 12544,
    "reward": 92.122797,
    "length": 60,
    "time": 182128.112951,
    "actor_loss": -70.43525695800781,
    "critic_loss": 9.628645896911621,
    "ent_coef": 0.0462690070271492,
    "learning_rate": 0.001
  },
  {
    "episode": 12545,
    "reward": 92.849372,
    "length": 58,
    "time": 182140.483401,
    "actor_loss": -72.2818603515625,
    "critic_loss": 8.745025634765625,
    "ent_coef": 0.04876059666275978,
    "learning_rate": 0.001
  },
  {
    "episode": 12546,
    "reward": 91.563694,
    "length": 61,
    "time": 182158.244822,
    "actor_loss": -67.50322723388672,
    "critic_loss": 44.51633071899414,
    "ent_coef": 0.05066824331879616,
    "learning_rate": 0.001
  },
  {
    "episode": 12547,
    "reward": 91.184182,
    "length": 61,
    "time": 182170.937698,
    "actor_loss": -67.84476470947266,
    "critic_loss": 37.41248321533203,
    "ent_coef": 0.05243662744760513,
    "learning_rate": 0.001
  },
  {
    "episode": 12548,
    "reward": 90.558607,
    "length": 66,
    "time": 182184.272622,
    "actor_loss": -70.91940307617188,
    "critic_loss": 4.63715934753418,
    "ent_coef": 0.05508998781442642,
    "learning_rate": 0.001
  },
  {
    "episode": 12549,
    "reward": 91.246393,
    "length": 62,
    "time": 182197.277116,
    "actor_loss": -70.8890380859375,
    "critic_loss": 12.108150482177734,
    "ent_coef": 0.054621413350105286,
    "learning_rate": 0.001
  },
  {
    "episode": 12550,
    "reward": 92.522774,
    "length": 59,
    "time": 182210.664755,
    "actor_loss": -68.3315200805664,
    "critic_loss": 12.489801406860352,
    "ent_coef": 0.05406489968299866,
    "learning_rate": 0.001
  },
  {
    "episode": 12551,
    "reward": 91.657437,
    "length": 59,
    "time": 182225.861289,
    "actor_loss": -73.17129516601562,
    "critic_loss": 24.420307159423828,
    "ent_coef": 0.055128064006567,
    "learning_rate": 0.001
  },
  {
    "episode": 12552,
    "reward": 89.279692,
    "length": 64,
    "time": 182238.054661,
    "actor_loss": -72.09896850585938,
    "critic_loss": 7.89759635925293,
    "ent_coef": 0.0564708448946476,
    "learning_rate": 0.001
  },
  {
    "episode": 12553,
    "reward": 91.274334,
    "length": 60,
    "time": 182251.063478,
    "actor_loss": -66.17403411865234,
    "critic_loss": 3.036500930786133,
    "ent_coef": 0.05757332965731621,
    "learning_rate": 0.001
  },
  {
    "episode": 12554,
    "reward": 91.912511,
    "length": 60,
    "time": 182264.320364,
    "actor_loss": -70.20953369140625,
    "critic_loss": 13.53843879699707,
    "ent_coef": 0.058120738714933395,
    "learning_rate": 0.001
  },
  {
    "episode": 12555,
    "reward": 91.386765,
    "length": 61,
    "time": 182276.149017,
    "actor_loss": -68.27812194824219,
    "critic_loss": 3.279973268508911,
    "ent_coef": 0.056463032960891724,
    "learning_rate": 0.001
  },
  {
    "episode": 12556,
    "reward": 90.585396,
    "length": 62,
    "time": 182288.199514,
    "actor_loss": -69.63047790527344,
    "critic_loss": 12.585150718688965,
    "ent_coef": 0.052749957889318466,
    "learning_rate": 0.001
  },
  {
    "episode": 12557,
    "reward": 88.205857,
    "length": 67,
    "time": 182301.727902,
    "actor_loss": -70.07887268066406,
    "critic_loss": 8.571023941040039,
    "ent_coef": 0.050989001989364624,
    "learning_rate": 0.001
  },
  {
    "episode": 12558,
    "reward": 91.153178,
    "length": 62,
    "time": 182313.909209,
    "actor_loss": -69.4377212524414,
    "critic_loss": 32.71070861816406,
    "ent_coef": 0.05021483451128006,
    "learning_rate": 0.001
  },
  {
    "episode": 12559,
    "reward": 91.463985,
    "length": 62,
    "time": 182326.291771,
    "actor_loss": -66.51875305175781,
    "critic_loss": 33.06456756591797,
    "ent_coef": 0.04998835548758507,
    "learning_rate": 0.001
  },
  {
    "episode": 12560,
    "reward": 91.502305,
    "length": 61,
    "time": 182341.059859,
    "actor_loss": -65.56514739990234,
    "critic_loss": 12.742152214050293,
    "ent_coef": 0.04911523312330246,
    "learning_rate": 0.001
  },
  {
    "episode": 12561,
    "reward": 90.150551,
    "length": 63,
    "time": 182353.933508,
    "actor_loss": -69.3240966796875,
    "critic_loss": 22.536163330078125,
    "ent_coef": 0.04930678382515907,
    "learning_rate": 0.001
  },
  {
    "episode": 12562,
    "reward": 91.801926,
    "length": 59,
    "time": 182365.579741,
    "actor_loss": -68.320068359375,
    "critic_loss": 6.884478569030762,
    "ent_coef": 0.05130940303206444,
    "learning_rate": 0.001
  },
  {
    "episode": 12563,
    "reward": 91.419044,
    "length": 60,
    "time": 182384.407607,
    "actor_loss": -72.20435333251953,
    "critic_loss": 8.694757461547852,
    "ent_coef": 0.05411630496382713,
    "learning_rate": 0.001
  },
  {
    "episode": 12564,
    "reward": 92.777928,
    "length": 58,
    "time": 182396.02062,
    "actor_loss": -76.01411437988281,
    "critic_loss": 2.341754913330078,
    "ent_coef": 0.055441971868276596,
    "learning_rate": 0.001
  },
  {
    "episode": 12565,
    "reward": 89.421273,
    "length": 66,
    "time": 182408.492213,
    "actor_loss": -68.64579772949219,
    "critic_loss": 5.438657760620117,
    "ent_coef": 0.05429017171263695,
    "learning_rate": 0.001
  },
  {
    "episode": 12566,
    "reward": 88.597786,
    "length": 67,
    "time": 182423.864116,
    "actor_loss": -68.33578491210938,
    "critic_loss": 7.463505268096924,
    "ent_coef": 0.0511944405734539,
    "learning_rate": 0.001
  },
  {
    "episode": 12567,
    "reward": 91.362219,
    "length": 61,
    "time": 182438.48782,
    "actor_loss": -72.26005554199219,
    "critic_loss": 3.0641541481018066,
    "ent_coef": 0.048503320664167404,
    "learning_rate": 0.001
  },
  {
    "episode": 12568,
    "reward": 90.26861,
    "length": 68,
    "time": 182452.198816,
    "actor_loss": -75.13921356201172,
    "critic_loss": 3.6584789752960205,
    "ent_coef": 0.04892240837216377,
    "learning_rate": 0.001
  },
  {
    "episode": 12569,
    "reward": 89.529112,
    "length": 64,
    "time": 182464.716554,
    "actor_loss": -72.99072265625,
    "critic_loss": 4.641205310821533,
    "ent_coef": 0.04763396456837654,
    "learning_rate": 0.001
  },
  {
    "episode": 12570,
    "reward": 92.473623,
    "length": 58,
    "time": 182477.870325,
    "actor_loss": -68.00173950195312,
    "critic_loss": 4.465950012207031,
    "ent_coef": 0.049003809690475464,
    "learning_rate": 0.001
  },
  {
    "episode": 12571,
    "reward": 92.506348,
    "length": 59,
    "time": 182490.910838,
    "actor_loss": -65.88639831542969,
    "critic_loss": 2.725843667984009,
    "ent_coef": 0.051575757563114166,
    "learning_rate": 0.001
  },
  {
    "episode": 12572,
    "reward": 91.606476,
    "length": 59,
    "time": 182504.264848,
    "actor_loss": -77.10517120361328,
    "critic_loss": 17.99944496154785,
    "ent_coef": 0.05277107656002045,
    "learning_rate": 0.001
  },
  {
    "episode": 12573,
    "reward": 91.9577,
    "length": 59,
    "time": 182516.278133,
    "actor_loss": -66.84400177001953,
    "critic_loss": 9.78231430053711,
    "ent_coef": 0.05217580497264862,
    "learning_rate": 0.001
  },
  {
    "episode": 12574,
    "reward": 92.365298,
    "length": 58,
    "time": 182527.703966,
    "actor_loss": -70.13975524902344,
    "critic_loss": 5.062055587768555,
    "ent_coef": 0.052111443132162094,
    "learning_rate": 0.001
  },
  {
    "episode": 12575,
    "reward": 90.991618,
    "length": 61,
    "time": 182539.677772,
    "actor_loss": -72.87974548339844,
    "critic_loss": 1.720892071723938,
    "ent_coef": 0.05130971968173981,
    "learning_rate": 0.001
  },
  {
    "episode": 12576,
    "reward": 91.262054,
    "length": 61,
    "time": 182551.525149,
    "actor_loss": -68.40577697753906,
    "critic_loss": 12.060997009277344,
    "ent_coef": 0.049155570566654205,
    "learning_rate": 0.001
  },
  {
    "episode": 12577,
    "reward": 91.310991,
    "length": 61,
    "time": 182564.972974,
    "actor_loss": -74.36376190185547,
    "critic_loss": 2.391620635986328,
    "ent_coef": 0.04897932708263397,
    "learning_rate": 0.001
  },
  {
    "episode": 12578,
    "reward": 91.651283,
    "length": 60,
    "time": 182579.501504,
    "actor_loss": -74.01765441894531,
    "critic_loss": 3.3746676445007324,
    "ent_coef": 0.05292261391878128,
    "learning_rate": 0.001
  },
  {
    "episode": 12579,
    "reward": 92.472344,
    "length": 58,
    "time": 182591.070896,
    "actor_loss": -72.37995910644531,
    "critic_loss": 15.629423141479492,
    "ent_coef": 0.0571865476667881,
    "learning_rate": 0.001
  },
  {
    "episode": 12580,
    "reward": 91.969285,
    "length": 59,
    "time": 182603.251474,
    "actor_loss": -67.65492248535156,
    "critic_loss": 5.739775657653809,
    "ent_coef": 0.05853496491909027,
    "learning_rate": 0.001
  },
  {
    "episode": 12581,
    "reward": 92.410269,
    "length": 59,
    "time": 182616.035435,
    "actor_loss": -73.93623352050781,
    "critic_loss": 6.23987340927124,
    "ent_coef": 0.060110535472631454,
    "learning_rate": 0.001
  },
  {
    "episode": 12582,
    "reward": 90.52684,
    "length": 63,
    "time": 182629.281865,
    "actor_loss": -74.54222106933594,
    "critic_loss": 21.740127563476562,
    "ent_coef": 0.05793829634785652,
    "learning_rate": 0.001
  },
  {
    "episode": 12583,
    "reward": 92.547538,
    "length": 58,
    "time": 182641.964079,
    "actor_loss": -72.47773742675781,
    "critic_loss": 5.782571315765381,
    "ent_coef": 0.0567234605550766,
    "learning_rate": 0.001
  },
  {
    "episode": 12584,
    "reward": 91.385254,
    "length": 60,
    "time": 182655.327089,
    "actor_loss": -72.79950714111328,
    "critic_loss": 3.0957112312316895,
    "ent_coef": 0.056342411786317825,
    "learning_rate": 0.001
  },
  {
    "episode": 12585,
    "reward": 88.824132,
    "length": 65,
    "time": 182670.095969,
    "actor_loss": -67.40290832519531,
    "critic_loss": 14.537605285644531,
    "ent_coef": 0.052898306399583817,
    "learning_rate": 0.001
  },
  {
    "episode": 12586,
    "reward": 87.537283,
    "length": 69,
    "time": 182685.61779,
    "actor_loss": -70.69679260253906,
    "critic_loss": 2.5609073638916016,
    "ent_coef": 0.04903417080640793,
    "learning_rate": 0.001
  },
  {
    "episode": 12587,
    "reward": 88.767312,
    "length": 69,
    "time": 182700.743679,
    "actor_loss": -68.59964752197266,
    "critic_loss": 7.027198791503906,
    "ent_coef": 0.04567689821124077,
    "learning_rate": 0.001
  },
  {
    "episode": 12588,
    "reward": 88.026679,
    "length": 68,
    "time": 182714.734196,
    "actor_loss": -69.45130157470703,
    "critic_loss": 2.684476375579834,
    "ent_coef": 0.0427873469889164,
    "learning_rate": 0.001
  },
  {
    "episode": 12589,
    "reward": 92.526793,
    "length": 59,
    "time": 182727.212892,
    "actor_loss": -74.80021667480469,
    "critic_loss": 3.6000173091888428,
    "ent_coef": 0.04400056600570679,
    "learning_rate": 0.001
  },
  {
    "episode": 12590,
    "reward": 91.355829,
    "length": 60,
    "time": 182740.825596,
    "actor_loss": -72.25224304199219,
    "critic_loss": 2.260897636413574,
    "ent_coef": 0.04489791393280029,
    "learning_rate": 0.001
  },
  {
    "episode": 12591,
    "reward": 90.903741,
    "length": 62,
    "time": 182753.292193,
    "actor_loss": -75.69036865234375,
    "critic_loss": 17.11873435974121,
    "ent_coef": 0.04405592754483223,
    "learning_rate": 0.001
  },
  {
    "episode": 12592,
    "reward": 90.956548,
    "length": 60,
    "time": 182768.351266,
    "actor_loss": -74.89045715332031,
    "critic_loss": 4.041465759277344,
    "ent_coef": 0.04424203559756279,
    "learning_rate": 0.001
  },
  {
    "episode": 12593,
    "reward": 88.394499,
    "length": 66,
    "time": 182784.166686,
    "actor_loss": -70.1500244140625,
    "critic_loss": 11.616016387939453,
    "ent_coef": 0.0423041470348835,
    "learning_rate": 0.001
  },
  {
    "episode": 12594,
    "reward": 86.339027,
    "length": 71,
    "time": 182797.471809,
    "actor_loss": -72.65789794921875,
    "critic_loss": 10.475399017333984,
    "ent_coef": 0.039873577654361725,
    "learning_rate": 0.001
  },
  {
    "episode": 12595,
    "reward": 83.36092,
    "length": 77,
    "time": 182812.634485,
    "actor_loss": -68.61924743652344,
    "critic_loss": 3.1185214519500732,
    "ent_coef": 0.03825704753398895,
    "learning_rate": 0.001
  },
  {
    "episode": 12596,
    "reward": 88.4862,
    "length": 67,
    "time": 182826.319889,
    "actor_loss": -68.1425552368164,
    "critic_loss": 20.722549438476562,
    "ent_coef": 0.03749808669090271,
    "learning_rate": 0.001
  },
  {
    "episode": 12597,
    "reward": 92.59283,
    "length": 58,
    "time": 182837.768265,
    "actor_loss": -69.34403991699219,
    "critic_loss": 2.791578531265259,
    "ent_coef": 0.0391550250351429,
    "learning_rate": 0.001
  },
  {
    "episode": 12598,
    "reward": 91.340819,
    "length": 60,
    "time": 182855.328294,
    "actor_loss": -74.75042724609375,
    "critic_loss": 4.278042316436768,
    "ent_coef": 0.03958248347043991,
    "learning_rate": 0.001
  },
  {
    "episode": 12599,
    "reward": 88.763311,
    "length": 65,
    "time": 182868.695382,
    "actor_loss": -75.7415771484375,
    "critic_loss": 2.428036689758301,
    "ent_coef": 0.03852647542953491,
    "learning_rate": 0.001
  },
  {
    "episode": 12600,
    "reward": 88.126141,
    "length": 66,
    "time": 182883.356572,
    "actor_loss": -73.65140533447266,
    "critic_loss": 10.192873001098633,
    "ent_coef": 0.03910471126437187,
    "learning_rate": 0.001
  },
  {
    "episode": 12601,
    "reward": 91.538303,
    "length": 60,
    "time": 182896.8088,
    "actor_loss": -76.70091247558594,
    "critic_loss": 17.5831298828125,
    "ent_coef": 0.03973229601979256,
    "learning_rate": 0.001
  },
  {
    "episode": 12602,
    "reward": 91.247105,
    "length": 60,
    "time": 182911.796751,
    "actor_loss": -72.3639907836914,
    "critic_loss": 61.598548889160156,
    "ent_coef": 0.041512537747621536,
    "learning_rate": 0.001
  },
  {
    "episode": 12603,
    "reward": 91.001005,
    "length": 61,
    "time": 182924.636817,
    "actor_loss": -75.32661437988281,
    "critic_loss": 5.819678783416748,
    "ent_coef": 0.04209541901946068,
    "learning_rate": 0.001
  },
  {
    "episode": 12604,
    "reward": 91.016653,
    "length": 61,
    "time": 182937.338022,
    "actor_loss": -72.88725280761719,
    "critic_loss": 18.53314208984375,
    "ent_coef": 0.04196431487798691,
    "learning_rate": 0.001
  },
  {
    "episode": 12605,
    "reward": 86.161787,
    "length": 73,
    "time": 182951.578783,
    "actor_loss": -68.9111328125,
    "critic_loss": 18.617658615112305,
    "ent_coef": 0.03886807709932327,
    "learning_rate": 0.001
  },
  {
    "episode": 12606,
    "reward": 86.907753,
    "length": 70,
    "time": 182965.733208,
    "actor_loss": -69.81781005859375,
    "critic_loss": 6.25941276550293,
    "ent_coef": 0.03732308745384216,
    "learning_rate": 0.001
  },
  {
    "episode": 12607,
    "reward": 90.319251,
    "length": 63,
    "time": 182977.073131,
    "actor_loss": -72.89321899414062,
    "critic_loss": 4.800860404968262,
    "ent_coef": 0.036659132689237595,
    "learning_rate": 0.001
  },
  {
    "episode": 12608,
    "reward": 86.486578,
    "length": 69,
    "time": 182990.014006,
    "actor_loss": -70.53738403320312,
    "critic_loss": 73.06770324707031,
    "ent_coef": 0.03666752949357033,
    "learning_rate": 0.001
  },
  {
    "episode": 12609,
    "reward": 91.188586,
    "length": 61,
    "time": 183003.495473,
    "actor_loss": -77.617919921875,
    "critic_loss": 4.456395149230957,
    "ent_coef": 0.039939988404512405,
    "learning_rate": 0.001
  },
  {
    "episode": 12610,
    "reward": 89.860811,
    "length": 63,
    "time": 183016.330917,
    "actor_loss": -73.02128601074219,
    "critic_loss": 27.115650177001953,
    "ent_coef": 0.041411299258470535,
    "learning_rate": 0.001
  },
  {
    "episode": 12611,
    "reward": 75.072207,
    "length": 99,
    "time": 183034.502887,
    "actor_loss": -72.57389831542969,
    "critic_loss": 2.3402366638183594,
    "ent_coef": 0.03750883415341377,
    "learning_rate": 0.001
  },
  {
    "episode": 12612,
    "reward": 77.605535,
    "length": 91,
    "time": 183049.486936,
    "actor_loss": -71.64228820800781,
    "critic_loss": 9.739715576171875,
    "ent_coef": 0.03427096828818321,
    "learning_rate": 0.001
  },
  {
    "episode": 12613,
    "reward": 83.238351,
    "length": 76,
    "time": 183062.344235,
    "actor_loss": -68.4356460571289,
    "critic_loss": 4.4519805908203125,
    "ent_coef": 0.03334110602736473,
    "learning_rate": 0.001
  },
  {
    "episode": 12614,
    "reward": 88.246149,
    "length": 65,
    "time": 183076.272093,
    "actor_loss": -70.74545288085938,
    "critic_loss": 3.6272735595703125,
    "ent_coef": 0.03614327684044838,
    "learning_rate": 0.001
  },
  {
    "episode": 12615,
    "reward": 89.537629,
    "length": 64,
    "time": 183088.212625,
    "actor_loss": -73.30695343017578,
    "critic_loss": 14.862442970275879,
    "ent_coef": 0.03865423426032066,
    "learning_rate": 0.001
  },
  {
    "episode": 12616,
    "reward": 87.08297,
    "length": 69,
    "time": 183100.571666,
    "actor_loss": -76.06608581542969,
    "critic_loss": 8.107172012329102,
    "ent_coef": 0.038437385112047195,
    "learning_rate": 0.001
  },
  {
    "episode": 12617,
    "reward": 80.03983,
    "length": 83,
    "time": 183115.009198,
    "actor_loss": -73.43382263183594,
    "critic_loss": 5.279674530029297,
    "ent_coef": 0.03569279611110687,
    "learning_rate": 0.001
  },
  {
    "episode": 12618,
    "reward": 85.511956,
    "length": 72,
    "time": 183129.569683,
    "actor_loss": -75.33585357666016,
    "critic_loss": 4.558736801147461,
    "ent_coef": 0.034525152295827866,
    "learning_rate": 0.001
  },
  {
    "episode": 12619,
    "reward": 87.153964,
    "length": 70,
    "time": 183142.830676,
    "actor_loss": -67.13774108886719,
    "critic_loss": 9.303366661071777,
    "ent_coef": 0.03363258019089699,
    "learning_rate": 0.001
  },
  {
    "episode": 12620,
    "reward": 89.801492,
    "length": 64,
    "time": 183154.228501,
    "actor_loss": -71.42332458496094,
    "critic_loss": 4.060299873352051,
    "ent_coef": 0.03385862708091736,
    "learning_rate": 0.001
  },
  {
    "episode": 12621,
    "reward": 90.237722,
    "length": 63,
    "time": 183167.491717,
    "actor_loss": -75.32099151611328,
    "critic_loss": 6.963982582092285,
    "ent_coef": 0.03302913159132004,
    "learning_rate": 0.001
  },
  {
    "episode": 12622,
    "reward": 90.250535,
    "length": 64,
    "time": 183181.248958,
    "actor_loss": -70.5604476928711,
    "critic_loss": 3.480733871459961,
    "ent_coef": 0.032420821487903595,
    "learning_rate": 0.001
  },
  {
    "episode": 12623,
    "reward": 88.422573,
    "length": 65,
    "time": 183195.184379,
    "actor_loss": -68.8376693725586,
    "critic_loss": 6.61759090423584,
    "ent_coef": 0.03237411379814148,
    "learning_rate": 0.001
  },
  {
    "episode": 12624,
    "reward": 93.58358,
    "length": 55,
    "time": 183211.937701,
    "actor_loss": -70.10761260986328,
    "critic_loss": 6.637897968292236,
    "ent_coef": 0.03461143374443054,
    "learning_rate": 0.001
  },
  {
    "episode": 12625,
    "reward": 92.949365,
    "length": 57,
    "time": 183224.903105,
    "actor_loss": -77.76362609863281,
    "critic_loss": 6.511892318725586,
    "ent_coef": 0.03780123591423035,
    "learning_rate": 0.001
  },
  {
    "episode": 12626,
    "reward": 92.631983,
    "length": 57,
    "time": 183237.558404,
    "actor_loss": -71.73112487792969,
    "critic_loss": 7.902466297149658,
    "ent_coef": 0.038685183972120285,
    "learning_rate": 0.001
  },
  {
    "episode": 12627,
    "reward": 93.826772,
    "length": 55,
    "time": 183250.325666,
    "actor_loss": -70.77317810058594,
    "critic_loss": 2.396979808807373,
    "ent_coef": 0.040770456194877625,
    "learning_rate": 0.001
  },
  {
    "episode": 12628,
    "reward": 93.154074,
    "length": 56,
    "time": 183266.510868,
    "actor_loss": -66.14414978027344,
    "critic_loss": 32.43903732299805,
    "ent_coef": 0.04221922531723976,
    "learning_rate": 0.001
  },
  {
    "episode": 12629,
    "reward": 93.480279,
    "length": 56,
    "time": 183281.171442,
    "actor_loss": -68.71109008789062,
    "critic_loss": 55.50365447998047,
    "ent_coef": 0.04426327720284462,
    "learning_rate": 0.001
  },
  {
    "episode": 12630,
    "reward": 93.639375,
    "length": 56,
    "time": 183293.065858,
    "actor_loss": -70.84526062011719,
    "critic_loss": 3.806706190109253,
    "ent_coef": 0.04603622853755951,
    "learning_rate": 0.001
  },
  {
    "episode": 12631,
    "reward": 92.570664,
    "length": 57,
    "time": 183306.104325,
    "actor_loss": -70.02902221679688,
    "critic_loss": 15.635690689086914,
    "ent_coef": 0.045899778604507446,
    "learning_rate": 0.001
  },
  {
    "episode": 12632,
    "reward": 92.389992,
    "length": 58,
    "time": 183319.121566,
    "actor_loss": -70.42171478271484,
    "critic_loss": 4.429800510406494,
    "ent_coef": 0.046418383717536926,
    "learning_rate": 0.001
  },
  {
    "episode": 12633,
    "reward": 91.704065,
    "length": 59,
    "time": 183331.922003,
    "actor_loss": -74.2235107421875,
    "critic_loss": 5.924803256988525,
    "ent_coef": 0.04808313027024269,
    "learning_rate": 0.001
  },
  {
    "episode": 12634,
    "reward": 91.64749,
    "length": 58,
    "time": 183344.969962,
    "actor_loss": -74.30146789550781,
    "critic_loss": 9.006954193115234,
    "ent_coef": 0.04907210171222687,
    "learning_rate": 0.001
  },
  {
    "episode": 12635,
    "reward": 91.015574,
    "length": 62,
    "time": 183358.641975,
    "actor_loss": -73.69134521484375,
    "critic_loss": 7.567066192626953,
    "ent_coef": 0.04909737780690193,
    "learning_rate": 0.001
  },
  {
    "episode": 12636,
    "reward": 90.946459,
    "length": 59,
    "time": 183372.318871,
    "actor_loss": -75.40950775146484,
    "critic_loss": 6.708735942840576,
    "ent_coef": 0.04912593588232994,
    "learning_rate": 0.001
  },
  {
    "episode": 12637,
    "reward": 92.131702,
    "length": 56,
    "time": 183385.455642,
    "actor_loss": -70.84219360351562,
    "critic_loss": 6.041720390319824,
    "ent_coef": 0.04961559176445007,
    "learning_rate": 0.001
  },
  {
    "episode": 12638,
    "reward": 92.158428,
    "length": 58,
    "time": 183399.448117,
    "actor_loss": -70.62020111083984,
    "critic_loss": 10.868486404418945,
    "ent_coef": 0.050626762211322784,
    "learning_rate": 0.001
  },
  {
    "episode": 12639,
    "reward": 91.905776,
    "length": 59,
    "time": 183412.052823,
    "actor_loss": -69.09368896484375,
    "critic_loss": 5.3936309814453125,
    "ent_coef": 0.04897373169660568,
    "learning_rate": 0.001
  },
  {
    "episode": 12640,
    "reward": 79.078633,
    "length": 173,
    "time": 183441.275594,
    "actor_loss": -79.87327575683594,
    "critic_loss": 8.754928588867188,
    "ent_coef": 0.04254469648003578,
    "learning_rate": 0.001
  },
  {
    "episode": 12641,
    "reward": 92.679548,
    "length": 58,
    "time": 183454.34248,
    "actor_loss": -78.85661315917969,
    "critic_loss": 179.0447235107422,
    "ent_coef": 0.04246027022600174,
    "learning_rate": 0.001
  },
  {
    "episode": 12642,
    "reward": 89.842757,
    "length": 62,
    "time": 183467.390573,
    "actor_loss": -72.104248046875,
    "critic_loss": 15.981023788452148,
    "ent_coef": 0.04183860123157501,
    "learning_rate": 0.001
  },
  {
    "episode": 12643,
    "reward": 93.259693,
    "length": 56,
    "time": 183479.989371,
    "actor_loss": -73.53643798828125,
    "critic_loss": 5.0332512855529785,
    "ent_coef": 0.043249744921922684,
    "learning_rate": 0.001
  },
  {
    "episode": 12644,
    "reward": 90.50213,
    "length": 61,
    "time": 183493.395774,
    "actor_loss": -74.96687316894531,
    "critic_loss": 4.763754844665527,
    "ent_coef": 0.043330639600753784,
    "learning_rate": 0.001
  },
  {
    "episode": 12645,
    "reward": 92.695009,
    "length": 57,
    "time": 183505.360043,
    "actor_loss": -74.27764892578125,
    "critic_loss": 5.55427360534668,
    "ent_coef": 0.04364157095551491,
    "learning_rate": 0.001
  },
  {
    "episode": 12646,
    "reward": 92.931112,
    "length": 57,
    "time": 183518.321018,
    "actor_loss": -74.25614929199219,
    "critic_loss": 17.272491455078125,
    "ent_coef": 0.044638652354478836,
    "learning_rate": 0.001
  },
  {
    "episode": 12647,
    "reward": 91.676713,
    "length": 58,
    "time": 183531.484522,
    "actor_loss": -76.198486328125,
    "critic_loss": 4.413763999938965,
    "ent_coef": 0.044200897216796875,
    "learning_rate": 0.001
  },
  {
    "episode": 12648,
    "reward": 91.907888,
    "length": 58,
    "time": 183544.416166,
    "actor_loss": -73.00135040283203,
    "critic_loss": 2.5925419330596924,
    "ent_coef": 0.04453397914767265,
    "learning_rate": 0.001
  },
  {
    "episode": 12649,
    "reward": 92.187103,
    "length": 58,
    "time": 183557.333709,
    "actor_loss": -71.55609893798828,
    "critic_loss": 4.120465278625488,
    "ent_coef": 0.046204760670661926,
    "learning_rate": 0.001
  },
  {
    "episode": 12650,
    "reward": 93.224449,
    "length": 56,
    "time": 183570.551472,
    "actor_loss": -74.4612045288086,
    "critic_loss": 9.387146949768066,
    "ent_coef": 0.04688766226172447,
    "learning_rate": 0.001
  },
  {
    "episode": 12651,
    "reward": 92.618051,
    "length": 57,
    "time": 183585.133146,
    "actor_loss": -75.33811950683594,
    "critic_loss": 9.99870491027832,
    "ent_coef": 0.04918748140335083,
    "learning_rate": 0.001
  },
  {
    "episode": 12652,
    "reward": 93.107345,
    "length": 56,
    "time": 183599.348888,
    "actor_loss": -78.1259536743164,
    "critic_loss": 7.156737327575684,
    "ent_coef": 0.050162170082330704,
    "learning_rate": 0.001
  },
  {
    "episode": 12653,
    "reward": 93.643916,
    "length": 53,
    "time": 183612.292869,
    "actor_loss": -70.11972045898438,
    "critic_loss": 6.252184867858887,
    "ent_coef": 0.051785554736852646,
    "learning_rate": 0.001
  },
  {
    "episode": 12654,
    "reward": 90.024799,
    "length": 64,
    "time": 183625.434951,
    "actor_loss": -72.15849304199219,
    "critic_loss": 52.747215270996094,
    "ent_coef": 0.053998079150915146,
    "learning_rate": 0.001
  },
  {
    "episode": 12655,
    "reward": 89.876567,
    "length": 62,
    "time": 183637.301661,
    "actor_loss": -77.27404022216797,
    "critic_loss": 14.01280403137207,
    "ent_coef": 0.056259628385305405,
    "learning_rate": 0.001
  },
  {
    "episode": 12656,
    "reward": 90.860177,
    "length": 62,
    "time": 183649.056943,
    "actor_loss": -71.21049499511719,
    "critic_loss": 16.186296463012695,
    "ent_coef": 0.05885059013962746,
    "learning_rate": 0.001
  },
  {
    "episode": 12657,
    "reward": 89.670003,
    "length": 62,
    "time": 183661.445589,
    "actor_loss": -75.93339538574219,
    "critic_loss": 6.984177589416504,
    "ent_coef": 0.061565615236759186,
    "learning_rate": 0.001
  },
  {
    "episode": 12658,
    "reward": 90.077489,
    "length": 62,
    "time": 183674.540528,
    "actor_loss": -74.73043823242188,
    "critic_loss": 4.473780632019043,
    "ent_coef": 0.06219670921564102,
    "learning_rate": 0.001
  },
  {
    "episode": 12659,
    "reward": 88.929594,
    "length": 64,
    "time": 183687.888176,
    "actor_loss": -73.9815673828125,
    "critic_loss": 2.7081172466278076,
    "ent_coef": 0.06283340603113174,
    "learning_rate": 0.001
  },
  {
    "episode": 12660,
    "reward": 86.455097,
    "length": 68,
    "time": 183702.392137,
    "actor_loss": -82.15021514892578,
    "critic_loss": 3.4304826259613037,
    "ent_coef": 0.06007172539830208,
    "learning_rate": 0.001
  },
  {
    "episode": 12661,
    "reward": 88.93822,
    "length": 65,
    "time": 183716.837962,
    "actor_loss": -75.00530242919922,
    "critic_loss": 4.690328598022461,
    "ent_coef": 0.056673116981983185,
    "learning_rate": 0.001
  },
  {
    "episode": 12662,
    "reward": 90.185258,
    "length": 62,
    "time": 183729.984796,
    "actor_loss": -72.71499633789062,
    "critic_loss": 33.16918182373047,
    "ent_coef": 0.05447963625192642,
    "learning_rate": 0.001
  },
  {
    "episode": 12663,
    "reward": 86.262364,
    "length": 69,
    "time": 183745.119224,
    "actor_loss": -72.48131561279297,
    "critic_loss": 6.963798999786377,
    "ent_coef": 0.0522320382297039,
    "learning_rate": 0.001
  },
  {
    "episode": 12664,
    "reward": 89.749306,
    "length": 63,
    "time": 183758.157073,
    "actor_loss": -74.74752807617188,
    "critic_loss": 7.727240085601807,
    "ent_coef": 0.051866814494132996,
    "learning_rate": 0.001
  },
  {
    "episode": 12665,
    "reward": -155.840136,
    "length": 175,
    "time": 183787.927947,
    "actor_loss": -72.79441833496094,
    "critic_loss": 1.9299988746643066,
    "ent_coef": 0.047104328870773315,
    "learning_rate": 0.001
  },
  {
    "episode": 12666,
    "reward": 90.965432,
    "length": 61,
    "time": 183802.051457,
    "actor_loss": -76.25967407226562,
    "critic_loss": 6.485721588134766,
    "ent_coef": 0.044201191514730453,
    "learning_rate": 0.001
  },
  {
    "episode": 12667,
    "reward": 79.254972,
    "length": 87,
    "time": 183819.43221,
    "actor_loss": -70.1958999633789,
    "critic_loss": 2.781301259994507,
    "ent_coef": 0.04326610267162323,
    "learning_rate": 0.001
  },
  {
    "episode": 12668,
    "reward": 92.131604,
    "length": 55,
    "time": 183832.793137,
    "actor_loss": -68.10311889648438,
    "critic_loss": 4.572928428649902,
    "ent_coef": 0.044459715485572815,
    "learning_rate": 0.001
  },
  {
    "episode": 12669,
    "reward": 94.047199,
    "length": 53,
    "time": 183845.341355,
    "actor_loss": -70.87715148925781,
    "critic_loss": 48.78108215332031,
    "ent_coef": 0.04751833155751228,
    "learning_rate": 0.001
  },
  {
    "episode": 12670,
    "reward": 93.03051,
    "length": 57,
    "time": 183858.190279,
    "actor_loss": -72.36150360107422,
    "critic_loss": 8.596923828125,
    "ent_coef": 0.04939337074756622,
    "learning_rate": 0.001
  },
  {
    "episode": 12671,
    "reward": 87.467371,
    "length": 67,
    "time": 183871.785543,
    "actor_loss": -72.64669799804688,
    "critic_loss": 6.986995220184326,
    "ent_coef": 0.04868081957101822,
    "learning_rate": 0.001
  },
  {
    "episode": 12672,
    "reward": 88.378436,
    "length": 66,
    "time": 183884.47358,
    "actor_loss": -69.97036743164062,
    "critic_loss": 8.73765754699707,
    "ent_coef": 0.04753576219081879,
    "learning_rate": 0.001
  },
  {
    "episode": 12673,
    "reward": 90.474636,
    "length": 63,
    "time": 183896.857844,
    "actor_loss": -78.06900024414062,
    "critic_loss": 3.3252570629119873,
    "ent_coef": 0.04770267754793167,
    "learning_rate": 0.001
  },
  {
    "episode": 12674,
    "reward": 89.266711,
    "length": 65,
    "time": 183908.51992,
    "actor_loss": -77.02894592285156,
    "critic_loss": 21.80884552001953,
    "ent_coef": 0.04680235683917999,
    "learning_rate": 0.001
  },
  {
    "episode": 12675,
    "reward": 81.969846,
    "length": 78,
    "time": 183921.859132,
    "actor_loss": -74.62399291992188,
    "critic_loss": 4.987872123718262,
    "ent_coef": 0.042869072407484055,
    "learning_rate": 0.001
  },
  {
    "episode": 12676,
    "reward": 86.962995,
    "length": 69,
    "time": 183935.061515,
    "actor_loss": -70.605712890625,
    "critic_loss": 5.740027904510498,
    "ent_coef": 0.041436146944761276,
    "learning_rate": 0.001
  },
  {
    "episode": 12677,
    "reward": 80.214007,
    "length": 83,
    "time": 183951.07943,
    "actor_loss": -73.7523193359375,
    "critic_loss": 6.858894348144531,
    "ent_coef": 0.03841598331928253,
    "learning_rate": 0.001
  },
  {
    "episode": 12678,
    "reward": 86.661104,
    "length": 71,
    "time": 183964.32787,
    "actor_loss": -73.38906860351562,
    "critic_loss": 37.78434371948242,
    "ent_coef": 0.036718033254146576,
    "learning_rate": 0.001
  },
  {
    "episode": 12679,
    "reward": 89.740559,
    "length": 65,
    "time": 183977.708913,
    "actor_loss": -73.4586181640625,
    "critic_loss": 6.848389625549316,
    "ent_coef": 0.03642373904585838,
    "learning_rate": 0.001
  },
  {
    "episode": 12680,
    "reward": 89.465287,
    "length": 65,
    "time": 183991.983706,
    "actor_loss": -71.96382141113281,
    "critic_loss": 31.090099334716797,
    "ent_coef": 0.036282408982515335,
    "learning_rate": 0.001
  },
  {
    "episode": 12681,
    "reward": 90.898033,
    "length": 63,
    "time": 184003.865908,
    "actor_loss": -72.86038970947266,
    "critic_loss": 6.336334228515625,
    "ent_coef": 0.03663947805762291,
    "learning_rate": 0.001
  },
  {
    "episode": 12682,
    "reward": 89.854707,
    "length": 63,
    "time": 184016.334657,
    "actor_loss": -76.32664489746094,
    "critic_loss": 106.33535766601562,
    "ent_coef": 0.037108276039361954,
    "learning_rate": 0.001
  },
  {
    "episode": 12683,
    "reward": 89.340009,
    "length": 65,
    "time": 184027.842277,
    "actor_loss": -80.3365478515625,
    "critic_loss": 18.32974624633789,
    "ent_coef": 0.036514025181531906,
    "learning_rate": 0.001
  },
  {
    "episode": 12684,
    "reward": 91.690725,
    "length": 61,
    "time": 184043.173517,
    "actor_loss": -71.478515625,
    "critic_loss": 1.9894111156463623,
    "ent_coef": 0.03717992082238197,
    "learning_rate": 0.001
  },
  {
    "episode": 12685,
    "reward": 89.534521,
    "length": 66,
    "time": 184055.834184,
    "actor_loss": -71.92749786376953,
    "critic_loss": 1.9014644622802734,
    "ent_coef": 0.03695254400372505,
    "learning_rate": 0.001
  },
  {
    "episode": 12686,
    "reward": 89.039926,
    "length": 66,
    "time": 184067.37959,
    "actor_loss": -74.62417602539062,
    "critic_loss": 10.830300331115723,
    "ent_coef": 0.03612631559371948,
    "learning_rate": 0.001
  },
  {
    "episode": 12687,
    "reward": 91.178777,
    "length": 61,
    "time": 184079.367666,
    "actor_loss": -73.16285705566406,
    "critic_loss": 4.041032791137695,
    "ent_coef": 0.03616988658905029,
    "learning_rate": 0.001
  },
  {
    "episode": 12688,
    "reward": 89.378214,
    "length": 70,
    "time": 184091.624726,
    "actor_loss": -73.89485168457031,
    "critic_loss": 4.551932334899902,
    "ent_coef": 0.03643380478024483,
    "learning_rate": 0.001
  },
  {
    "episode": 12689,
    "reward": 90.618788,
    "length": 61,
    "time": 184103.597338,
    "actor_loss": -75.53846740722656,
    "critic_loss": 10.910619735717773,
    "ent_coef": 0.03792214393615723,
    "learning_rate": 0.001
  },
  {
    "episode": 12690,
    "reward": 91.464298,
    "length": 61,
    "time": 184118.135427,
    "actor_loss": -74.37059020996094,
    "critic_loss": 5.421080589294434,
    "ent_coef": 0.039046477526426315,
    "learning_rate": 0.001
  },
  {
    "episode": 12691,
    "reward": 89.751523,
    "length": 64,
    "time": 184130.12546,
    "actor_loss": -76.21648406982422,
    "critic_loss": 5.995328903198242,
    "ent_coef": 0.03832146152853966,
    "learning_rate": 0.001
  },
  {
    "episode": 12692,
    "reward": 86.049145,
    "length": 72,
    "time": 184143.699703,
    "actor_loss": -73.86890411376953,
    "critic_loss": 6.1791839599609375,
    "ent_coef": 0.04084132984280586,
    "learning_rate": 0.001
  },
  {
    "episode": 12693,
    "reward": 90.827307,
    "length": 63,
    "time": 184154.980453,
    "actor_loss": -65.36048889160156,
    "critic_loss": 4.381991386413574,
    "ent_coef": 0.04189867526292801,
    "learning_rate": 0.001
  },
  {
    "episode": 12694,
    "reward": 86.505855,
    "length": 69,
    "time": 184168.651249,
    "actor_loss": -72.87944793701172,
    "critic_loss": 8.367531776428223,
    "ent_coef": 0.040914490818977356,
    "learning_rate": 0.001
  },
  {
    "episode": 12695,
    "reward": 86.980957,
    "length": 68,
    "time": 184181.482249,
    "actor_loss": -75.80058288574219,
    "critic_loss": 4.572500228881836,
    "ent_coef": 0.04132506251335144,
    "learning_rate": 0.001
  },
  {
    "episode": 12696,
    "reward": 87.356504,
    "length": 70,
    "time": 184194.572874,
    "actor_loss": -69.41380310058594,
    "critic_loss": 18.004718780517578,
    "ent_coef": 0.04052438959479332,
    "learning_rate": 0.001
  },
  {
    "episode": 12697,
    "reward": 88.508419,
    "length": 67,
    "time": 184209.009321,
    "actor_loss": -78.28097534179688,
    "critic_loss": 5.394801616668701,
    "ent_coef": 0.039631206542253494,
    "learning_rate": 0.001
  },
  {
    "episode": 12698,
    "reward": 90.93049,
    "length": 62,
    "time": 184220.317806,
    "actor_loss": -70.85543823242188,
    "critic_loss": 3.2786202430725098,
    "ent_coef": 0.04156043380498886,
    "learning_rate": 0.001
  },
  {
    "episode": 12699,
    "reward": 92.173823,
    "length": 60,
    "time": 184233.903002,
    "actor_loss": -75.31796264648438,
    "critic_loss": 8.641183853149414,
    "ent_coef": 0.04472329840064049,
    "learning_rate": 0.001
  },
  {
    "episode": 12700,
    "reward": 90.140449,
    "length": 63,
    "time": 184246.102118,
    "actor_loss": -72.97535705566406,
    "critic_loss": 4.203855991363525,
    "ent_coef": 0.04867568984627724,
    "learning_rate": 0.001
  },
  {
    "episode": 12701,
    "reward": 89.711869,
    "length": 70,
    "time": 184258.941954,
    "actor_loss": -76.13597106933594,
    "critic_loss": 5.612565994262695,
    "ent_coef": 0.05008259415626526,
    "learning_rate": 0.001
  },
  {
    "episode": 12702,
    "reward": 90.709103,
    "length": 61,
    "time": 184270.297001,
    "actor_loss": -76.44049835205078,
    "critic_loss": 17.86142349243164,
    "ent_coef": 0.0535777248442173,
    "learning_rate": 0.001
  },
  {
    "episode": 12703,
    "reward": 90.226329,
    "length": 63,
    "time": 184283.605198,
    "actor_loss": -69.54029846191406,
    "critic_loss": 3.467474937438965,
    "ent_coef": 0.05558115988969803,
    "learning_rate": 0.001
  },
  {
    "episode": 12704,
    "reward": 87.509909,
    "length": 73,
    "time": 184298.157092,
    "actor_loss": -67.42069244384766,
    "critic_loss": 13.050155639648438,
    "ent_coef": 0.05360319837927818,
    "learning_rate": 0.001
  },
  {
    "episode": 12705,
    "reward": 89.588396,
    "length": 64,
    "time": 184310.307455,
    "actor_loss": -72.12965393066406,
    "critic_loss": 3.7298128604888916,
    "ent_coef": 0.05234755575656891,
    "learning_rate": 0.001
  },
  {
    "episode": 12706,
    "reward": 89.624626,
    "length": 63,
    "time": 184323.923411,
    "actor_loss": -77.98485565185547,
    "critic_loss": 24.485191345214844,
    "ent_coef": 0.049996793270111084,
    "learning_rate": 0.001
  },
  {
    "episode": 12707,
    "reward": 89.782744,
    "length": 64,
    "time": 184337.907998,
    "actor_loss": -77.30520629882812,
    "critic_loss": 4.7521162033081055,
    "ent_coef": 0.04939400404691696,
    "learning_rate": 0.001
  },
  {
    "episode": 12708,
    "reward": 91.502697,
    "length": 60,
    "time": 184351.580768,
    "actor_loss": -72.91526794433594,
    "critic_loss": 20.461410522460938,
    "ent_coef": 0.05131954327225685,
    "learning_rate": 0.001
  },
  {
    "episode": 12709,
    "reward": 89.82477,
    "length": 64,
    "time": 184366.923141,
    "actor_loss": -69.34439086914062,
    "critic_loss": 4.398646831512451,
    "ent_coef": 0.05195099115371704,
    "learning_rate": 0.001
  },
  {
    "episode": 12710,
    "reward": 89.328204,
    "length": 64,
    "time": 184380.891504,
    "actor_loss": -67.94572448730469,
    "critic_loss": 11.023588180541992,
    "ent_coef": 0.05281788855791092,
    "learning_rate": 0.001
  },
  {
    "episode": 12711,
    "reward": 90.898768,
    "length": 61,
    "time": 184393.000605,
    "actor_loss": -75.0884017944336,
    "critic_loss": 60.90010070800781,
    "ent_coef": 0.053435686975717545,
    "learning_rate": 0.001
  },
  {
    "episode": 12712,
    "reward": 91.539821,
    "length": 61,
    "time": 184404.287761,
    "actor_loss": -75.36254119873047,
    "critic_loss": 7.353978633880615,
    "ent_coef": 0.0549854077398777,
    "learning_rate": 0.001
  },
  {
    "episode": 12713,
    "reward": 92.0375,
    "length": 60,
    "time": 184416.352206,
    "actor_loss": -73.74305725097656,
    "critic_loss": 5.0931806564331055,
    "ent_coef": 0.055792663246393204,
    "learning_rate": 0.001
  },
  {
    "episode": 12714,
    "reward": 90.546787,
    "length": 62,
    "time": 184427.453445,
    "actor_loss": -69.45563507080078,
    "critic_loss": 5.662850379943848,
    "ent_coef": 0.05662798136472702,
    "learning_rate": 0.001
  },
  {
    "episode": 12715,
    "reward": 87.747935,
    "length": 68,
    "time": 184441.509251,
    "actor_loss": -72.26825714111328,
    "critic_loss": 4.397043228149414,
    "ent_coef": 0.05667212978005409,
    "learning_rate": 0.001
  },
  {
    "episode": 12716,
    "reward": 88.780118,
    "length": 66,
    "time": 184453.133321,
    "actor_loss": -71.80461883544922,
    "critic_loss": 12.478204727172852,
    "ent_coef": 0.056918542832136154,
    "learning_rate": 0.001
  },
  {
    "episode": 12717,
    "reward": 89.912793,
    "length": 64,
    "time": 184465.00845,
    "actor_loss": -70.99488830566406,
    "critic_loss": 5.954256057739258,
    "ent_coef": 0.056879132986068726,
    "learning_rate": 0.001
  },
  {
    "episode": 12718,
    "reward": 89.593581,
    "length": 64,
    "time": 184478.550787,
    "actor_loss": -72.0572509765625,
    "critic_loss": 5.02134895324707,
    "ent_coef": 0.05784878134727478,
    "learning_rate": 0.001
  },
  {
    "episode": 12719,
    "reward": 88.737596,
    "length": 66,
    "time": 184491.884043,
    "actor_loss": -74.8996810913086,
    "critic_loss": 3.942274332046509,
    "ent_coef": 0.05505571886897087,
    "learning_rate": 0.001
  },
  {
    "episode": 12720,
    "reward": 87.775573,
    "length": 73,
    "time": 184504.491045,
    "actor_loss": -69.77857971191406,
    "critic_loss": 2.448789119720459,
    "ent_coef": 0.052319031208753586,
    "learning_rate": 0.001
  },
  {
    "episode": 12721,
    "reward": 89.055856,
    "length": 67,
    "time": 184518.580603,
    "actor_loss": -70.83210754394531,
    "critic_loss": 4.97144889831543,
    "ent_coef": 0.05239523947238922,
    "learning_rate": 0.001
  },
  {
    "episode": 12722,
    "reward": 90.789091,
    "length": 62,
    "time": 184529.914552,
    "actor_loss": -75.24758911132812,
    "critic_loss": 3.661367177963257,
    "ent_coef": 0.052995465695858,
    "learning_rate": 0.001
  },
  {
    "episode": 12723,
    "reward": 90.973407,
    "length": 63,
    "time": 184541.575359,
    "actor_loss": -76.10104370117188,
    "critic_loss": 6.037512302398682,
    "ent_coef": 0.0541149266064167,
    "learning_rate": 0.001
  },
  {
    "episode": 12724,
    "reward": 90.744302,
    "length": 62,
    "time": 184554.695601,
    "actor_loss": -73.96373748779297,
    "critic_loss": 5.601102828979492,
    "ent_coef": 0.05360207334160805,
    "learning_rate": 0.001
  },
  {
    "episode": 12725,
    "reward": 88.408202,
    "length": 70,
    "time": 184566.900871,
    "actor_loss": -77.56672668457031,
    "critic_loss": 6.167943477630615,
    "ent_coef": 0.057438064366579056,
    "learning_rate": 0.001
  },
  {
    "episode": 12726,
    "reward": 89.190496,
    "length": 65,
    "time": 184578.703445,
    "actor_loss": -72.58467102050781,
    "critic_loss": 31.317367553710938,
    "ent_coef": 0.05828132852911949,
    "learning_rate": 0.001
  },
  {
    "episode": 12727,
    "reward": 91.312324,
    "length": 62,
    "time": 184590.237764,
    "actor_loss": -68.6339340209961,
    "critic_loss": 48.120025634765625,
    "ent_coef": 0.0611429363489151,
    "learning_rate": 0.001
  },
  {
    "episode": 12728,
    "reward": 89.761397,
    "length": 63,
    "time": 184602.923403,
    "actor_loss": -72.21908569335938,
    "critic_loss": 93.32221984863281,
    "ent_coef": 0.06230951100587845,
    "learning_rate": 0.001
  },
  {
    "episode": 12729,
    "reward": 87.204248,
    "length": 68,
    "time": 184615.774814,
    "actor_loss": -73.5610580444336,
    "critic_loss": 3.2165117263793945,
    "ent_coef": 0.06023223325610161,
    "learning_rate": 0.001
  },
  {
    "episode": 12730,
    "reward": 88.226633,
    "length": 69,
    "time": 184628.206198,
    "actor_loss": -70.16728210449219,
    "critic_loss": 5.076722145080566,
    "ent_coef": 0.05601312592625618,
    "learning_rate": 0.001
  },
  {
    "episode": 12731,
    "reward": 87.760916,
    "length": 67,
    "time": 184641.129942,
    "actor_loss": -73.3264389038086,
    "critic_loss": 4.405540466308594,
    "ent_coef": 0.053360890597105026,
    "learning_rate": 0.001
  },
  {
    "episode": 12732,
    "reward": 90.666968,
    "length": 63,
    "time": 184652.236977,
    "actor_loss": -72.34701538085938,
    "critic_loss": 6.9614176750183105,
    "ent_coef": 0.050282616168260574,
    "learning_rate": 0.001
  },
  {
    "episode": 12733,
    "reward": 84.202854,
    "length": 75,
    "time": 184665.51704,
    "actor_loss": -72.3300552368164,
    "critic_loss": 3.6499619483947754,
    "ent_coef": 0.04566345363855362,
    "learning_rate": 0.001
  },
  {
    "episode": 12734,
    "reward": 80.640827,
    "length": 78,
    "time": 184679.032404,
    "actor_loss": -73.955078125,
    "critic_loss": 3.733757495880127,
    "ent_coef": 0.04309205710887909,
    "learning_rate": 0.001
  },
  {
    "episode": 12735,
    "reward": 91.696794,
    "length": 61,
    "time": 184691.199751,
    "actor_loss": -74.44261169433594,
    "critic_loss": 4.4254350662231445,
    "ent_coef": 0.04400862380862236,
    "learning_rate": 0.001
  },
  {
    "episode": 12736,
    "reward": 90.909798,
    "length": 61,
    "time": 184702.214318,
    "actor_loss": -76.40104675292969,
    "critic_loss": 13.159679412841797,
    "ent_coef": 0.04464789107441902,
    "learning_rate": 0.001
  },
  {
    "episode": 12737,
    "reward": 91.039688,
    "length": 61,
    "time": 184714.173707,
    "actor_loss": -79.06285095214844,
    "critic_loss": 2.7732419967651367,
    "ent_coef": 0.04450996592640877,
    "learning_rate": 0.001
  },
  {
    "episode": 12738,
    "reward": 91.208919,
    "length": 62,
    "time": 184725.599565,
    "actor_loss": -72.83726501464844,
    "critic_loss": 32.76054763793945,
    "ent_coef": 0.04571454972028732,
    "learning_rate": 0.001
  },
  {
    "episode": 12739,
    "reward": 90.152272,
    "length": 64,
    "time": 184738.122109,
    "actor_loss": -77.24835205078125,
    "critic_loss": 12.042875289916992,
    "ent_coef": 0.046341586858034134,
    "learning_rate": 0.001
  },
  {
    "episode": 12740,
    "reward": 85.672477,
    "length": 75,
    "time": 184753.278964,
    "actor_loss": -73.45257568359375,
    "critic_loss": 4.290605545043945,
    "ent_coef": 0.04441683739423752,
    "learning_rate": 0.001
  },
  {
    "episode": 12741,
    "reward": 91.824657,
    "length": 60,
    "time": 184766.04858,
    "actor_loss": -75.06802368164062,
    "critic_loss": 541.33642578125,
    "ent_coef": 0.04438318312168121,
    "learning_rate": 0.001
  },
  {
    "episode": 12742,
    "reward": 88.991694,
    "length": 64,
    "time": 184777.545782,
    "actor_loss": -67.44122314453125,
    "critic_loss": 9.616508483886719,
    "ent_coef": 0.044527988880872726,
    "learning_rate": 0.001
  },
  {
    "episode": 12743,
    "reward": 90.958142,
    "length": 61,
    "time": 184795.241404,
    "actor_loss": -69.05239868164062,
    "critic_loss": 7.41278600692749,
    "ent_coef": 0.04765373840928078,
    "learning_rate": 0.001
  },
  {
    "episode": 12744,
    "reward": 89.029701,
    "length": 67,
    "time": 184809.242098,
    "actor_loss": -68.99623107910156,
    "critic_loss": 10.166122436523438,
    "ent_coef": 0.04781480133533478,
    "learning_rate": 0.001
  },
  {
    "episode": 12745,
    "reward": 85.86302,
    "length": 72,
    "time": 184824.730367,
    "actor_loss": -74.07100677490234,
    "critic_loss": 13.75946044921875,
    "ent_coef": 0.045033346861600876,
    "learning_rate": 0.001
  },
  {
    "episode": 12746,
    "reward": 88.429812,
    "length": 67,
    "time": 184836.779874,
    "actor_loss": -70.50892639160156,
    "critic_loss": 4.423543930053711,
    "ent_coef": 0.04333946108818054,
    "learning_rate": 0.001
  },
  {
    "episode": 12747,
    "reward": 89.428272,
    "length": 66,
    "time": 184848.995675,
    "actor_loss": -75.55517578125,
    "critic_loss": 7.482335567474365,
    "ent_coef": 0.043470948934555054,
    "learning_rate": 0.001
  },
  {
    "episode": 12748,
    "reward": 82.944773,
    "length": 76,
    "time": 184863.303428,
    "actor_loss": -71.7958984375,
    "critic_loss": 4.391351699829102,
    "ent_coef": 0.040794488042593,
    "learning_rate": 0.001
  },
  {
    "episode": 12749,
    "reward": 86.001507,
    "length": 72,
    "time": 184875.987112,
    "actor_loss": -67.29021453857422,
    "critic_loss": 15.249795913696289,
    "ent_coef": 0.039973076432943344,
    "learning_rate": 0.001
  },
  {
    "episode": 12750,
    "reward": 88.147708,
    "length": 67,
    "time": 184888.24512,
    "actor_loss": -73.7509765625,
    "critic_loss": 16.865610122680664,
    "ent_coef": 0.04079001769423485,
    "learning_rate": 0.001
  },
  {
    "episode": 12751,
    "reward": 90.377354,
    "length": 61,
    "time": 184901.224629,
    "actor_loss": -69.08638000488281,
    "critic_loss": 3.9693830013275146,
    "ent_coef": 0.042329005897045135,
    "learning_rate": 0.001
  },
  {
    "episode": 12752,
    "reward": 90.291461,
    "length": 63,
    "time": 184915.156061,
    "actor_loss": -72.10191345214844,
    "critic_loss": 4.760064601898193,
    "ent_coef": 0.043391551822423935,
    "learning_rate": 0.001
  },
  {
    "episode": 12753,
    "reward": 86.505187,
    "length": 70,
    "time": 184929.515885,
    "actor_loss": -72.0601806640625,
    "critic_loss": 5.808402061462402,
    "ent_coef": 0.04151657223701477,
    "learning_rate": 0.001
  },
  {
    "episode": 12754,
    "reward": 90.326568,
    "length": 62,
    "time": 184941.07436,
    "actor_loss": -75.64411926269531,
    "critic_loss": 6.257973670959473,
    "ent_coef": 0.04154015704989433,
    "learning_rate": 0.001
  },
  {
    "episode": 12755,
    "reward": 91.910214,
    "length": 60,
    "time": 184955.319116,
    "actor_loss": -74.77872467041016,
    "critic_loss": 7.346027851104736,
    "ent_coef": 0.04310464486479759,
    "learning_rate": 0.001
  },
  {
    "episode": 12756,
    "reward": 90.851091,
    "length": 61,
    "time": 184970.634449,
    "actor_loss": -79.2578125,
    "critic_loss": 11.977092742919922,
    "ent_coef": 0.043538983911275864,
    "learning_rate": 0.001
  },
  {
    "episode": 12757,
    "reward": 89.581233,
    "length": 64,
    "time": 184985.326493,
    "actor_loss": -73.54092407226562,
    "critic_loss": 38.14904022216797,
    "ent_coef": 0.04458191990852356,
    "learning_rate": 0.001
  },
  {
    "episode": 12758,
    "reward": 85.642473,
    "length": 76,
    "time": 184998.673427,
    "actor_loss": -77.17078399658203,
    "critic_loss": 4.137029647827148,
    "ent_coef": 0.04313034936785698,
    "learning_rate": 0.001
  },
  {
    "episode": 12759,
    "reward": 89.875523,
    "length": 64,
    "time": 185011.119276,
    "actor_loss": -71.32377624511719,
    "critic_loss": 2.4262874126434326,
    "ent_coef": 0.0419594869017601,
    "learning_rate": 0.001
  },
  {
    "episode": 12760,
    "reward": 89.849407,
    "length": 64,
    "time": 185022.674706,
    "actor_loss": -75.410400390625,
    "critic_loss": 3.487131118774414,
    "ent_coef": 0.04118946194648743,
    "learning_rate": 0.001
  },
  {
    "episode": 12761,
    "reward": 91.512982,
    "length": 61,
    "time": 185035.49094,
    "actor_loss": -74.74737548828125,
    "critic_loss": 9.070211410522461,
    "ent_coef": 0.04127178341150284,
    "learning_rate": 0.001
  },
  {
    "episode": 12762,
    "reward": 89.48563,
    "length": 69,
    "time": 185047.724489,
    "actor_loss": -75.96528625488281,
    "critic_loss": 27.72489356994629,
    "ent_coef": 0.041311997920274734,
    "learning_rate": 0.001
  },
  {
    "episode": 12763,
    "reward": 90.304596,
    "length": 63,
    "time": 185060.684689,
    "actor_loss": -71.69338989257812,
    "critic_loss": 11.426506042480469,
    "ent_coef": 0.04242727532982826,
    "learning_rate": 0.001
  },
  {
    "episode": 12764,
    "reward": 90.687777,
    "length": 63,
    "time": 185073.136116,
    "actor_loss": -75.90262603759766,
    "critic_loss": 5.680935859680176,
    "ent_coef": 0.041227906942367554,
    "learning_rate": 0.001
  },
  {
    "episode": 12765,
    "reward": 91.407286,
    "length": 62,
    "time": 185084.640412,
    "actor_loss": -76.939208984375,
    "critic_loss": 4.461755752563477,
    "ent_coef": 0.041025251150131226,
    "learning_rate": 0.001
  },
  {
    "episode": 12766,
    "reward": 92.205529,
    "length": 59,
    "time": 185095.792142,
    "actor_loss": -75.96670532226562,
    "critic_loss": 2.8557920455932617,
    "ent_coef": 0.04435470700263977,
    "learning_rate": 0.001
  },
  {
    "episode": 12767,
    "reward": 88.652234,
    "length": 66,
    "time": 185108.217534,
    "actor_loss": -73.03777313232422,
    "critic_loss": 7.425501823425293,
    "ent_coef": 0.04327058792114258,
    "learning_rate": 0.001
  },
  {
    "episode": 12768,
    "reward": 91.983096,
    "length": 60,
    "time": 185119.368972,
    "actor_loss": -77.39608764648438,
    "critic_loss": 7.189997673034668,
    "ent_coef": 0.04473913460969925,
    "learning_rate": 0.001
  },
  {
    "episode": 12769,
    "reward": 87.685936,
    "length": 73,
    "time": 185134.041919,
    "actor_loss": -67.79936218261719,
    "critic_loss": 5.737545490264893,
    "ent_coef": 0.042649056762456894,
    "learning_rate": 0.001
  },
  {
    "episode": 12770,
    "reward": 92.094817,
    "length": 59,
    "time": 185145.331545,
    "actor_loss": -76.76069641113281,
    "critic_loss": 23.82709503173828,
    "ent_coef": 0.042226243764162064,
    "learning_rate": 0.001
  },
  {
    "episode": 12771,
    "reward": 89.514018,
    "length": 65,
    "time": 185159.9476,
    "actor_loss": -70.93717956542969,
    "critic_loss": 9.653460502624512,
    "ent_coef": 0.04163845255970955,
    "learning_rate": 0.001
  },
  {
    "episode": 12772,
    "reward": 90.041173,
    "length": 64,
    "time": 185171.629948,
    "actor_loss": -71.60159301757812,
    "critic_loss": 3.2135169506073,
    "ent_coef": 0.04207437485456467,
    "learning_rate": 0.001
  },
  {
    "episode": 12773,
    "reward": 91.329447,
    "length": 61,
    "time": 185183.265494,
    "actor_loss": -76.53521728515625,
    "critic_loss": 3.061577558517456,
    "ent_coef": 0.042159710079431534,
    "learning_rate": 0.001
  },
  {
    "episode": 12774,
    "reward": 85.117837,
    "length": 74,
    "time": 185197.543272,
    "actor_loss": -69.13646697998047,
    "critic_loss": 16.81439971923828,
    "ent_coef": 0.03956332802772522,
    "learning_rate": 0.001
  },
  {
    "episode": 12775,
    "reward": 88.858225,
    "length": 65,
    "time": 185210.374066,
    "actor_loss": -74.17169952392578,
    "critic_loss": 4.032423973083496,
    "ent_coef": 0.038503628224134445,
    "learning_rate": 0.001
  },
  {
    "episode": 12776,
    "reward": 91.856861,
    "length": 60,
    "time": 185222.647473,
    "actor_loss": -70.1126937866211,
    "critic_loss": 8.929262161254883,
    "ent_coef": 0.03874460980296135,
    "learning_rate": 0.001
  },
  {
    "episode": 12777,
    "reward": 89.954156,
    "length": 63,
    "time": 185234.576503,
    "actor_loss": -71.7804183959961,
    "critic_loss": 34.97357940673828,
    "ent_coef": 0.040904056280851364,
    "learning_rate": 0.001
  },
  {
    "episode": 12778,
    "reward": 91.589057,
    "length": 60,
    "time": 185246.743142,
    "actor_loss": -73.79712677001953,
    "critic_loss": 20.439617156982422,
    "ent_coef": 0.0418541245162487,
    "learning_rate": 0.001
  },
  {
    "episode": 12779,
    "reward": 89.491279,
    "length": 69,
    "time": 185258.826555,
    "actor_loss": -72.64422607421875,
    "critic_loss": 4.945767402648926,
    "ent_coef": 0.041121482849121094,
    "learning_rate": 0.001
  },
  {
    "episode": 12780,
    "reward": 91.861227,
    "length": 59,
    "time": 185270.175427,
    "actor_loss": -66.08319854736328,
    "critic_loss": 7.093837261199951,
    "ent_coef": 0.04295961558818817,
    "learning_rate": 0.001
  },
  {
    "episode": 12781,
    "reward": 91.023737,
    "length": 62,
    "time": 185281.778654,
    "actor_loss": -72.5046615600586,
    "critic_loss": 4.7205586433410645,
    "ent_coef": 0.04567619413137436,
    "learning_rate": 0.001
  },
  {
    "episode": 12782,
    "reward": 87.64753,
    "length": 67,
    "time": 185296.459764,
    "actor_loss": -73.25664520263672,
    "critic_loss": 124.07308959960938,
    "ent_coef": 0.04686012864112854,
    "learning_rate": 0.001
  },
  {
    "episode": 12783,
    "reward": 85.901721,
    "length": 71,
    "time": 185309.506002,
    "actor_loss": -70.4192123413086,
    "critic_loss": 6.777379035949707,
    "ent_coef": 0.046589259058237076,
    "learning_rate": 0.001
  },
  {
    "episode": 12784,
    "reward": 89.383292,
    "length": 65,
    "time": 185322.292764,
    "actor_loss": -67.59959411621094,
    "critic_loss": 18.525043487548828,
    "ent_coef": 0.04636729136109352,
    "learning_rate": 0.001
  },
  {
    "episode": 12785,
    "reward": 90.981403,
    "length": 62,
    "time": 185334.151566,
    "actor_loss": -74.1960220336914,
    "critic_loss": 4.724954605102539,
    "ent_coef": 0.047495286911726,
    "learning_rate": 0.001
  },
  {
    "episode": 12786,
    "reward": 89.348208,
    "length": 65,
    "time": 185349.181626,
    "actor_loss": -77.50492858886719,
    "critic_loss": 3.5063929557800293,
    "ent_coef": 0.046886298805475235,
    "learning_rate": 0.001
  },
  {
    "episode": 12787,
    "reward": 90.307488,
    "length": 62,
    "time": 185363.843117,
    "actor_loss": -73.16561126708984,
    "critic_loss": 26.283435821533203,
    "ent_coef": 0.046893879771232605,
    "learning_rate": 0.001
  },
  {
    "episode": 12788,
    "reward": 90.867827,
    "length": 61,
    "time": 185375.578773,
    "actor_loss": -69.28453826904297,
    "critic_loss": 5.905614376068115,
    "ent_coef": 0.04824554920196533,
    "learning_rate": 0.001
  },
  {
    "episode": 12789,
    "reward": 89.996575,
    "length": 62,
    "time": 185387.832853,
    "actor_loss": -72.24847412109375,
    "critic_loss": 62.53799819946289,
    "ent_coef": 0.050261497497558594,
    "learning_rate": 0.001
  },
  {
    "episode": 12790,
    "reward": 90.521942,
    "length": 62,
    "time": 185400.24578,
    "actor_loss": -69.45604705810547,
    "critic_loss": 3.1977930068969727,
    "ent_coef": 0.05388066545128822,
    "learning_rate": 0.001
  },
  {
    "episode": 12791,
    "reward": 90.053358,
    "length": 63,
    "time": 185414.482937,
    "actor_loss": -79.74411010742188,
    "critic_loss": 63.232635498046875,
    "ent_coef": 0.055133480578660965,
    "learning_rate": 0.001
  },
  {
    "episode": 12792,
    "reward": 89.713693,
    "length": 64,
    "time": 185426.862561,
    "actor_loss": -74.34359741210938,
    "critic_loss": 3.413585901260376,
    "ent_coef": 0.05447187274694443,
    "learning_rate": 0.001
  },
  {
    "episode": 12793,
    "reward": 91.146736,
    "length": 61,
    "time": 185439.201187,
    "actor_loss": -70.91688537597656,
    "critic_loss": 4.760402679443359,
    "ent_coef": 0.05417700856924057,
    "learning_rate": 0.001
  },
  {
    "episode": 12794,
    "reward": 91.428077,
    "length": 60,
    "time": 185450.338884,
    "actor_loss": -73.89352416992188,
    "critic_loss": 7.638675689697266,
    "ent_coef": 0.05269595608115196,
    "learning_rate": 0.001
  },
  {
    "episode": 12795,
    "reward": 90.339462,
    "length": 62,
    "time": 185462.865042,
    "actor_loss": -80.64067077636719,
    "critic_loss": 29.68524742126465,
    "ent_coef": 0.051554758101701736,
    "learning_rate": 0.001
  },
  {
    "episode": 12796,
    "reward": 91.857256,
    "length": 60,
    "time": 185474.067105,
    "actor_loss": -72.64404296875,
    "critic_loss": 2.5408973693847656,
    "ent_coef": 0.05302755907177925,
    "learning_rate": 0.001
  },
  {
    "episode": 12797,
    "reward": 86.210824,
    "length": 73,
    "time": 185487.075476,
    "actor_loss": -74.53858184814453,
    "critic_loss": 3.2282090187072754,
    "ent_coef": 0.051712602376937866,
    "learning_rate": 0.001
  },
  {
    "episode": 12798,
    "reward": 91.295011,
    "length": 61,
    "time": 185498.434256,
    "actor_loss": -69.19393920898438,
    "critic_loss": 18.9130859375,
    "ent_coef": 0.052163317799568176,
    "learning_rate": 0.001
  },
  {
    "episode": 12799,
    "reward": 89.875215,
    "length": 64,
    "time": 185510.8429,
    "actor_loss": -70.79847717285156,
    "critic_loss": 2.0862417221069336,
    "ent_coef": 0.05119019374251366,
    "learning_rate": 0.001
  },
  {
    "episode": 12800,
    "reward": 91.502932,
    "length": 61,
    "time": 185522.217552,
    "actor_loss": -75.97303009033203,
    "critic_loss": 2.554335832595825,
    "ent_coef": 0.049466460943222046,
    "learning_rate": 0.001
  },
  {
    "episode": 12801,
    "reward": 91.462521,
    "length": 61,
    "time": 185534.183189,
    "actor_loss": -71.68122863769531,
    "critic_loss": 3.14772629737854,
    "ent_coef": 0.04817216098308563,
    "learning_rate": 0.001
  },
  {
    "episode": 12802,
    "reward": 89.850679,
    "length": 63,
    "time": 185546.650221,
    "actor_loss": -69.90470123291016,
    "critic_loss": 6.959413051605225,
    "ent_coef": 0.04652089625597,
    "learning_rate": 0.001
  },
  {
    "episode": 12803,
    "reward": 88.492701,
    "length": 66,
    "time": 185559.127976,
    "actor_loss": -69.9146499633789,
    "critic_loss": 21.909896850585938,
    "ent_coef": 0.04419413208961487,
    "learning_rate": 0.001
  },
  {
    "episode": 12804,
    "reward": 90.201803,
    "length": 63,
    "time": 185573.851193,
    "actor_loss": -75.12794494628906,
    "critic_loss": 42.423397064208984,
    "ent_coef": 0.04363657534122467,
    "learning_rate": 0.001
  },
  {
    "episode": 12805,
    "reward": 86.932461,
    "length": 68,
    "time": 185586.325958,
    "actor_loss": -76.91462707519531,
    "critic_loss": 18.124656677246094,
    "ent_coef": 0.041916098445653915,
    "learning_rate": 0.001
  },
  {
    "episode": 12806,
    "reward": 88.786525,
    "length": 70,
    "time": 185599.525128,
    "actor_loss": -72.56187438964844,
    "critic_loss": 4.651344299316406,
    "ent_coef": 0.042021576315164566,
    "learning_rate": 0.001
  },
  {
    "episode": 12807,
    "reward": 92.432629,
    "length": 58,
    "time": 185610.706279,
    "actor_loss": -77.31758117675781,
    "critic_loss": 7.7328619956970215,
    "ent_coef": 0.044881921261548996,
    "learning_rate": 0.001
  },
  {
    "episode": 12808,
    "reward": 92.163998,
    "length": 59,
    "time": 185624.369629,
    "actor_loss": -75.68486022949219,
    "critic_loss": 2.304032325744629,
    "ent_coef": 0.04487515240907669,
    "learning_rate": 0.001
  },
  {
    "episode": 12809,
    "reward": 86.46255,
    "length": 70,
    "time": 185638.95007,
    "actor_loss": -72.11060333251953,
    "critic_loss": 7.7911176681518555,
    "ent_coef": 0.042650267481803894,
    "learning_rate": 0.001
  },
  {
    "episode": 12810,
    "reward": 85.010603,
    "length": 72,
    "time": 185651.890172,
    "actor_loss": -75.00254821777344,
    "critic_loss": 6.968949317932129,
    "ent_coef": 0.040572650730609894,
    "learning_rate": 0.001
  },
  {
    "episode": 12811,
    "reward": 86.585641,
    "length": 69,
    "time": 185664.949501,
    "actor_loss": -68.22723388671875,
    "critic_loss": 43.39247512817383,
    "ent_coef": 0.039756324142217636,
    "learning_rate": 0.001
  },
  {
    "episode": 12812,
    "reward": 90.108762,
    "length": 63,
    "time": 185677.471367,
    "actor_loss": -78.5059814453125,
    "critic_loss": 1.9714767932891846,
    "ent_coef": 0.04012828320264816,
    "learning_rate": 0.001
  },
  {
    "episode": 12813,
    "reward": 89.785438,
    "length": 63,
    "time": 185689.753363,
    "actor_loss": -73.61264038085938,
    "critic_loss": 10.53251838684082,
    "ent_coef": 0.04105522483587265,
    "learning_rate": 0.001
  },
  {
    "episode": 12814,
    "reward": 86.455672,
    "length": 70,
    "time": 185702.255179,
    "actor_loss": -74.96003723144531,
    "critic_loss": 4.334059715270996,
    "ent_coef": 0.04040908440947533,
    "learning_rate": 0.001
  },
  {
    "episode": 12815,
    "reward": 87.286736,
    "length": 68,
    "time": 185715.859988,
    "actor_loss": -75.31735229492188,
    "critic_loss": 31.504150390625,
    "ent_coef": 0.04000282287597656,
    "learning_rate": 0.001
  },
  {
    "episode": 12816,
    "reward": 77.589536,
    "length": 85,
    "time": 185731.282027,
    "actor_loss": -69.88676452636719,
    "critic_loss": 4.011228084564209,
    "ent_coef": 0.037713319063186646,
    "learning_rate": 0.001
  },
  {
    "episode": 12817,
    "reward": 81.718717,
    "length": 78,
    "time": 185746.75734,
    "actor_loss": -75.27999877929688,
    "critic_loss": 68.73298645019531,
    "ent_coef": 0.0369732566177845,
    "learning_rate": 0.001
  },
  {
    "episode": 12818,
    "reward": 86.670217,
    "length": 70,
    "time": 185759.538697,
    "actor_loss": -68.99736785888672,
    "critic_loss": 4.628777503967285,
    "ent_coef": 0.03629586473107338,
    "learning_rate": 0.001
  },
  {
    "episode": 12819,
    "reward": 83.580906,
    "length": 80,
    "time": 185773.865872,
    "actor_loss": -73.18916320800781,
    "critic_loss": 22.327678680419922,
    "ent_coef": 0.03446410596370697,
    "learning_rate": 0.001
  },
  {
    "episode": 12820,
    "reward": 89.409831,
    "length": 68,
    "time": 185788.725456,
    "actor_loss": -74.805419921875,
    "critic_loss": 4.92512321472168,
    "ent_coef": 0.034894656389951706,
    "learning_rate": 0.001
  }
]