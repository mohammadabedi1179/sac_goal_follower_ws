[
  {
    "episode": 1,
    "reward": -209.337528,
    "length": 273,
    "time": 40.605588,
    "actor_loss": -2.3438735008239746,
    "critic_loss": 0.4711819291114807,
    "ent_coef": 0.8400141000747681,
    "learning_rate": 0.001
  },
  {
    "episode": 2,
    "reward": -41.366789,
    "length": 567,
    "time": 120.609693,
    "actor_loss": -1.0146574974060059,
    "critic_loss": 1.7578494548797607,
    "ent_coef": 0.47588157653808594,
    "learning_rate": 0.001
  },
  {
    "episode": 3,
    "reward": -97.016537,
    "length": 570,
    "time": 200.737696,
    "actor_loss": -0.923427402973175,
    "critic_loss": 0.7911739349365234,
    "ent_coef": 0.27084049582481384,
    "learning_rate": 0.001
  },
  {
    "episode": 4,
    "reward": -103.46424,
    "length": 548,
    "time": 280.850584,
    "actor_loss": -0.7047423124313354,
    "critic_loss": 0.4844833314418793,
    "ent_coef": 0.16120994091033936,
    "learning_rate": 0.001
  },
  {
    "episode": 5,
    "reward": -156.770258,
    "length": 194,
    "time": 311.452999,
    "actor_loss": -0.9181069135665894,
    "critic_loss": 1.1891124248504639,
    "ent_coef": 0.13286934792995453,
    "learning_rate": 0.001
  },
  {
    "episode": 6,
    "reward": -43.856559,
    "length": 558,
    "time": 391.46456,
    "actor_loss": -0.641426682472229,
    "critic_loss": 1.7258647680282593,
    "ent_coef": 0.08217041194438934,
    "learning_rate": 0.001
  },
  {
    "episode": 7,
    "reward": -136.349073,
    "length": 232,
    "time": 427.374027,
    "actor_loss": -0.4029606878757477,
    "critic_loss": 0.3301428556442261,
    "ent_coef": 0.06864795833826065,
    "learning_rate": 0.001
  },
  {
    "episode": 8,
    "reward": -151.003724,
    "length": 317,
    "time": 474.451774,
    "actor_loss": 0.7586097717285156,
    "critic_loss": 10.1392822265625,
    "ent_coef": 0.052252188324928284,
    "learning_rate": 0.001
  },
  {
    "episode": 9,
    "reward": -178.311846,
    "length": 548,
    "time": 553.659093,
    "actor_loss": 2.1926610469818115,
    "critic_loss": 205.3482208251953,
    "ent_coef": 0.03487645834684372,
    "learning_rate": 0.001
  },
  {
    "episode": 10,
    "reward": -117.528996,
    "length": 120,
    "time": 577.079528,
    "actor_loss": 2.555471658706665,
    "critic_loss": 1.005826711654663,
    "ent_coef": 0.03225889801979065,
    "learning_rate": 0.001
  },
  {
    "episode": 11,
    "reward": -101.147147,
    "length": 569,
    "time": 657.206119,
    "actor_loss": 3.6619763374328613,
    "critic_loss": 3.3376641273498535,
    "ent_coef": 0.02382543869316578,
    "learning_rate": 0.001
  },
  {
    "episode": 12,
    "reward": -178.101292,
    "length": 295,
    "time": 700.907406,
    "actor_loss": 3.563462257385254,
    "critic_loss": 1.8274149894714355,
    "ent_coef": 0.021567944437265396,
    "learning_rate": 0.001
  },
  {
    "episode": 13,
    "reward": -120.345627,
    "length": 372,
    "time": 755.602671,
    "actor_loss": 2.183919906616211,
    "critic_loss": 1.5529614686965942,
    "ent_coef": 0.01850830391049385,
    "learning_rate": 0.001
  },
  {
    "episode": 14,
    "reward": -114.453618,
    "length": 112,
    "time": 775.115369,
    "actor_loss": 3.727634906768799,
    "critic_loss": 0.588603138923645,
    "ent_coef": 0.018526151776313782,
    "learning_rate": 0.001
  },
  {
    "episode": 15,
    "reward": -163.360987,
    "length": 425,
    "time": 837.395766,
    "actor_loss": 4.108246803283691,
    "critic_loss": 9.339136123657227,
    "ent_coef": 0.02150150202214718,
    "learning_rate": 0.001
  },
  {
    "episode": 16,
    "reward": -112.962349,
    "length": 205,
    "time": 868.960006,
    "actor_loss": 4.218351364135742,
    "critic_loss": 9.417619705200195,
    "ent_coef": 0.021286720409989357,
    "learning_rate": 0.001
  },
  {
    "episode": 17,
    "reward": -123.662341,
    "length": 235,
    "time": 904.390097,
    "actor_loss": 4.848958969116211,
    "critic_loss": 0.4306570291519165,
    "ent_coef": 0.021312782540917397,
    "learning_rate": 0.001
  },
  {
    "episode": 18,
    "reward": -120.022336,
    "length": 1,
    "time": 914.182525,
    "actor_loss": 4.37644100189209,
    "critic_loss": 1.4117515087127686,
    "ent_coef": 0.021309256553649902,
    "learning_rate": 0.001
  },
  {
    "episode": 19,
    "reward": -119.820143,
    "length": 99,
    "time": 931.602899,
    "actor_loss": 3.916672468185425,
    "critic_loss": 1.2190730571746826,
    "ent_coef": 0.01973126456141472,
    "learning_rate": 0.001
  },
  {
    "episode": 20,
    "reward": 112.522753,
    "length": 165,
    "time": 958.100402,
    "actor_loss": 4.36784553527832,
    "critic_loss": 165.68048095703125,
    "ent_coef": 0.019355375319719315,
    "learning_rate": 0.001
  },
  {
    "episode": 21,
    "reward": -105.818487,
    "length": 559,
    "time": 1038.183285,
    "actor_loss": 5.069652080535889,
    "critic_loss": 0.35416117310523987,
    "ent_coef": 0.018353283405303955,
    "learning_rate": 0.001
  },
  {
    "episode": 22,
    "reward": -123.454491,
    "length": 188,
    "time": 1068.165627,
    "actor_loss": 5.564444541931152,
    "critic_loss": 2.876528739929199,
    "ent_coef": 0.0187582615762949,
    "learning_rate": 0.001
  },
  {
    "episode": 23,
    "reward": -136.277356,
    "length": 359,
    "time": 1122.657807,
    "actor_loss": 6.142289161682129,
    "critic_loss": 1.6137497425079346,
    "ent_coef": 0.018684592097997665,
    "learning_rate": 0.001
  },
  {
    "episode": 24,
    "reward": 108.298607,
    "length": 138,
    "time": 1146.484512,
    "actor_loss": 7.041450500488281,
    "critic_loss": 10.269233703613281,
    "ent_coef": 0.018211673945188522,
    "learning_rate": 0.001
  },
  {
    "episode": 25,
    "reward": -133.826798,
    "length": 84,
    "time": 1162.690109,
    "actor_loss": 7.245344638824463,
    "critic_loss": 2.083059787750244,
    "ent_coef": 0.017429359257221222,
    "learning_rate": 0.001
  },
  {
    "episode": 26,
    "reward": -96.996075,
    "length": 563,
    "time": 1242.721252,
    "actor_loss": 6.105589866638184,
    "critic_loss": 20.79784393310547,
    "ent_coef": 0.019855378195643425,
    "learning_rate": 0.001
  },
  {
    "episode": 27,
    "reward": -137.378547,
    "length": 364,
    "time": 1296.316331,
    "actor_loss": 7.906004905700684,
    "critic_loss": 2.709758758544922,
    "ent_coef": 0.017804116010665894,
    "learning_rate": 0.001
  },
  {
    "episode": 28,
    "reward": 140.042484,
    "length": 35,
    "time": 1304.752119,
    "actor_loss": 7.387729644775391,
    "critic_loss": 3.205915689468384,
    "ent_coef": 0.0180898979306221,
    "learning_rate": 0.001
  },
  {
    "episode": 29,
    "reward": -165.613915,
    "length": 347,
    "time": 1357.665,
    "actor_loss": 8.048966407775879,
    "critic_loss": 7.42417573928833,
    "ent_coef": 0.020540976896882057,
    "learning_rate": 0.001
  },
  {
    "episode": 30,
    "reward": 101.479366,
    "length": 283,
    "time": 1399.469983,
    "actor_loss": 5.993828773498535,
    "critic_loss": 0.7941659688949585,
    "ent_coef": 0.017443185672163963,
    "learning_rate": 0.001
  },
  {
    "episode": 31,
    "reward": -146.297981,
    "length": 554,
    "time": 1479.522994,
    "actor_loss": 5.950736999511719,
    "critic_loss": 166.8717803955078,
    "ent_coef": 0.022855613380670547,
    "learning_rate": 0.001
  },
  {
    "episode": 32,
    "reward": -164.445537,
    "length": 303,
    "time": 1524.770189,
    "actor_loss": 8.113812446594238,
    "critic_loss": 2.128540515899658,
    "ent_coef": 0.024415157735347748,
    "learning_rate": 0.001
  },
  {
    "episode": 33,
    "reward": -95.442673,
    "length": 564,
    "time": 1604.856778,
    "actor_loss": 8.988265991210938,
    "critic_loss": 14.982004165649414,
    "ent_coef": 0.0229586623609066,
    "learning_rate": 0.001
  },
  {
    "episode": 34,
    "reward": -107.207693,
    "length": 136,
    "time": 1628.291436,
    "actor_loss": 6.537193298339844,
    "critic_loss": 121.63066101074219,
    "ent_coef": 0.022688232362270355,
    "learning_rate": 0.001
  },
  {
    "episode": 35,
    "reward": -181.822601,
    "length": 270,
    "time": 1669.055008,
    "actor_loss": 8.81456184387207,
    "critic_loss": 1.5407743453979492,
    "ent_coef": 0.020543228834867477,
    "learning_rate": 0.001
  },
  {
    "episode": 36,
    "reward": -111.489175,
    "length": 178,
    "time": 1700.916321,
    "actor_loss": 10.239789009094238,
    "critic_loss": 25.446720123291016,
    "ent_coef": 0.019477009773254395,
    "learning_rate": 0.001
  },
  {
    "episode": 37,
    "reward": -143.721924,
    "length": 208,
    "time": 1735.162071,
    "actor_loss": 9.275749206542969,
    "critic_loss": 154.46412658691406,
    "ent_coef": 0.018741561099886894,
    "learning_rate": 0.001
  },
  {
    "episode": 38,
    "reward": -122.857619,
    "length": 241,
    "time": 1772.642036,
    "actor_loss": 8.32215690612793,
    "critic_loss": 0.742209792137146,
    "ent_coef": 0.020489182323217392,
    "learning_rate": 0.001
  },
  {
    "episode": 39,
    "reward": -112.234885,
    "length": 89,
    "time": 1790.327037,
    "actor_loss": 8.854277610778809,
    "critic_loss": 3.8453991413116455,
    "ent_coef": 0.021575849503278732,
    "learning_rate": 0.001
  },
  {
    "episode": 40,
    "reward": -88.16184,
    "length": 543,
    "time": 1870.401518,
    "actor_loss": 7.8370466232299805,
    "critic_loss": 159.21958923339844,
    "ent_coef": 0.01972775347530842,
    "learning_rate": 0.001
  },
  {
    "episode": 41,
    "reward": -126.116061,
    "length": 101,
    "time": 1888.660116,
    "actor_loss": 9.951513290405273,
    "critic_loss": 64.60688781738281,
    "ent_coef": 0.019856298342347145,
    "learning_rate": 0.001
  },
  {
    "episode": 42,
    "reward": -167.827087,
    "length": 318,
    "time": 1935.542594,
    "actor_loss": 11.388819694519043,
    "critic_loss": 16.566938400268555,
    "ent_coef": 0.01868284121155739,
    "learning_rate": 0.001
  },
  {
    "episode": 43,
    "reward": -108.537643,
    "length": 159,
    "time": 1962.394392,
    "actor_loss": 12.426004409790039,
    "critic_loss": 156.9973907470703,
    "ent_coef": 0.01863299310207367,
    "learning_rate": 0.001
  },
  {
    "episode": 44,
    "reward": -204.089564,
    "length": 525,
    "time": 2037.894979,
    "actor_loss": 11.716716766357422,
    "critic_loss": 2.3991549015045166,
    "ent_coef": 0.02046765200793743,
    "learning_rate": 0.001
  },
  {
    "episode": 45,
    "reward": -120.77265,
    "length": 26,
    "time": 2045.987613,
    "actor_loss": 11.91541862487793,
    "critic_loss": 5.557387828826904,
    "ent_coef": 0.019542358815670013,
    "learning_rate": 0.001
  },
  {
    "episode": 46,
    "reward": -132.404768,
    "length": 169,
    "time": 2072.394941,
    "actor_loss": 10.320133209228516,
    "critic_loss": 3.3664889335632324,
    "ent_coef": 0.019572747871279716,
    "learning_rate": 0.001
  },
  {
    "episode": 47,
    "reward": -76.881115,
    "length": 544,
    "time": 2152.494139,
    "actor_loss": 10.482759475708008,
    "critic_loss": 116.9158935546875,
    "ent_coef": 0.016422362998127937,
    "learning_rate": 0.001
  },
  {
    "episode": 48,
    "reward": -92.060556,
    "length": 543,
    "time": 2232.615861,
    "actor_loss": 9.517635345458984,
    "critic_loss": 224.0465087890625,
    "ent_coef": 0.01772705465555191,
    "learning_rate": 0.001
  },
  {
    "episode": 49,
    "reward": -157.393926,
    "length": 360,
    "time": 2286.530226,
    "actor_loss": 9.830835342407227,
    "critic_loss": 6.462319374084473,
    "ent_coef": 0.01735708862543106,
    "learning_rate": 0.001
  },
  {
    "episode": 50,
    "reward": -119.541731,
    "length": 81,
    "time": 2301.538032,
    "actor_loss": 6.557060241699219,
    "critic_loss": 7.469805717468262,
    "ent_coef": 0.017189523205161095,
    "learning_rate": 0.001
  },
  {
    "episode": 51,
    "reward": -116.854875,
    "length": 113,
    "time": 2321.36855,
    "actor_loss": 8.860076904296875,
    "critic_loss": 12.509092330932617,
    "ent_coef": 0.01693384349346161,
    "learning_rate": 0.001
  },
  {
    "episode": 52,
    "reward": -75.013054,
    "length": 540,
    "time": 2401.480954,
    "actor_loss": 8.694089889526367,
    "critic_loss": 10.198986053466797,
    "ent_coef": 0.01646379940211773,
    "learning_rate": 0.001
  },
  {
    "episode": 53,
    "reward": -187.33083,
    "length": 500,
    "time": 2476.013011,
    "actor_loss": 10.569568634033203,
    "critic_loss": 127.68748474121094,
    "ent_coef": 0.019318880513310432,
    "learning_rate": 0.001
  },
  {
    "episode": 54,
    "reward": -133.166809,
    "length": 145,
    "time": 2500.35251,
    "actor_loss": 10.292448997497559,
    "critic_loss": 10.40739631652832,
    "ent_coef": 0.019060174003243446,
    "learning_rate": 0.001
  },
  {
    "episode": 55,
    "reward": -195.877095,
    "length": 441,
    "time": 2564.878936,
    "actor_loss": 10.295788764953613,
    "critic_loss": 1.9821728467941284,
    "ent_coef": 0.019238006323575974,
    "learning_rate": 0.001
  },
  {
    "episode": 56,
    "reward": -120.023027,
    "length": 1,
    "time": 2577.52053,
    "actor_loss": 8.87307357788086,
    "critic_loss": 2.0840961933135986,
    "ent_coef": 0.019220296293497086,
    "learning_rate": 0.001
  },
  {
    "episode": 57,
    "reward": -110.06885,
    "length": 160,
    "time": 2602.907248,
    "actor_loss": 11.556312561035156,
    "critic_loss": 13.936521530151367,
    "ent_coef": 0.018527474254369736,
    "learning_rate": 0.001
  },
  {
    "episode": 58,
    "reward": -60.020501,
    "length": 558,
    "time": 2682.9538,
    "actor_loss": 12.346782684326172,
    "critic_loss": 7.146791458129883,
    "ent_coef": 0.018287738785147667,
    "learning_rate": 0.001
  },
  {
    "episode": 59,
    "reward": -99.792116,
    "length": 561,
    "time": 2762.989738,
    "actor_loss": 10.7940034866333,
    "critic_loss": 3.0644075870513916,
    "ent_coef": 0.016464082524180412,
    "learning_rate": 0.001
  },
  {
    "episode": 60,
    "reward": -162.969447,
    "length": 147,
    "time": 2787.365511,
    "actor_loss": 11.518936157226562,
    "critic_loss": 60.012054443359375,
    "ent_coef": 0.016710957512259483,
    "learning_rate": 0.001
  },
  {
    "episode": 61,
    "reward": -112.217459,
    "length": 122,
    "time": 2809.485171,
    "actor_loss": 12.769274711608887,
    "critic_loss": 2.8373141288757324,
    "ent_coef": 0.016228776425123215,
    "learning_rate": 0.001
  },
  {
    "episode": 62,
    "reward": -126.951979,
    "length": 131,
    "time": 2831.090058,
    "actor_loss": 10.528367042541504,
    "critic_loss": 1.9810103178024292,
    "ent_coef": 0.016029147431254387,
    "learning_rate": 0.001
  },
  {
    "episode": 63,
    "reward": -175.903573,
    "length": 364,
    "time": 2884.348817,
    "actor_loss": 13.65867805480957,
    "critic_loss": 1.3268778324127197,
    "ent_coef": 0.015758026391267776,
    "learning_rate": 0.001
  },
  {
    "episode": 64,
    "reward": -106.765278,
    "length": 104,
    "time": 2902.20104,
    "actor_loss": 11.925329208374023,
    "critic_loss": 5.8627519607543945,
    "ent_coef": 0.014672605320811272,
    "learning_rate": 0.001
  },
  {
    "episode": 65,
    "reward": -99.780366,
    "length": 555,
    "time": 2982.28937,
    "actor_loss": 12.950864791870117,
    "critic_loss": 2.4237558841705322,
    "ent_coef": 0.017714733257889748,
    "learning_rate": 0.001
  },
  {
    "episode": 66,
    "reward": -121.008813,
    "length": 70,
    "time": 2996.423844,
    "actor_loss": 11.11685562133789,
    "critic_loss": 4.010380744934082,
    "ent_coef": 0.017702480778098106,
    "learning_rate": 0.001
  },
  {
    "episode": 67,
    "reward": -114.324968,
    "length": 169,
    "time": 3024.242892,
    "actor_loss": 12.985509872436523,
    "critic_loss": 5.022616386413574,
    "ent_coef": 0.0169708002358675,
    "learning_rate": 0.001
  },
  {
    "episode": 68,
    "reward": -167.359204,
    "length": 471,
    "time": 3093.127575,
    "actor_loss": 12.955995559692383,
    "critic_loss": 2.7204232215881348,
    "ent_coef": 0.012772604823112488,
    "learning_rate": 0.001
  },
  {
    "episode": 69,
    "reward": -139.869061,
    "length": 404,
    "time": 3151.590329,
    "actor_loss": 12.831136703491211,
    "critic_loss": 5.30355167388916,
    "ent_coef": 0.016894452273845673,
    "learning_rate": 0.001
  },
  {
    "episode": 70,
    "reward": -162.754235,
    "length": 420,
    "time": 3212.97652,
    "actor_loss": 11.398752212524414,
    "critic_loss": 1.4346728324890137,
    "ent_coef": 0.015170223079621792,
    "learning_rate": 0.001
  },
  {
    "episode": 71,
    "reward": -165.409613,
    "length": 310,
    "time": 3261.016675,
    "actor_loss": 12.458269119262695,
    "critic_loss": 4.276921272277832,
    "ent_coef": 0.017233211547136307,
    "learning_rate": 0.001
  },
  {
    "episode": 72,
    "reward": -147.024951,
    "length": 294,
    "time": 3304.998693,
    "actor_loss": 13.612129211425781,
    "critic_loss": 6.34094762802124,
    "ent_coef": 0.016986394301056862,
    "learning_rate": 0.001
  },
  {
    "episode": 73,
    "reward": -120.440186,
    "length": 17,
    "time": 3313.059609,
    "actor_loss": 10.368003845214844,
    "critic_loss": 2.257840156555176,
    "ent_coef": 0.016729630529880524,
    "learning_rate": 0.001
  },
  {
    "episode": 74,
    "reward": -112.109363,
    "length": 92,
    "time": 3329.3098,
    "actor_loss": 12.224967956542969,
    "critic_loss": 2.393639326095581,
    "ent_coef": 0.015967272222042084,
    "learning_rate": 0.001
  },
  {
    "episode": 75,
    "reward": -158.90494,
    "length": 322,
    "time": 3377.757084,
    "actor_loss": 13.120420455932617,
    "critic_loss": 2.037890911102295,
    "ent_coef": 0.016553375869989395,
    "learning_rate": 0.001
  },
  {
    "episode": 76,
    "reward": -108.207248,
    "length": 87,
    "time": 3395.742127,
    "actor_loss": 12.330251693725586,
    "critic_loss": 3.066915512084961,
    "ent_coef": 0.01584930717945099,
    "learning_rate": 0.001
  },
  {
    "episode": 77,
    "reward": -120.343905,
    "length": 13,
    "time": 3403.81256,
    "actor_loss": 10.804116249084473,
    "critic_loss": 4.084011554718018,
    "ent_coef": 0.015910672023892403,
    "learning_rate": 0.001
  },
  {
    "episode": 78,
    "reward": -109.175131,
    "length": 161,
    "time": 3429.542568,
    "actor_loss": 12.564300537109375,
    "critic_loss": 5.455012321472168,
    "ent_coef": 0.016155781224370003,
    "learning_rate": 0.001
  },
  {
    "episode": 79,
    "reward": -116.509039,
    "length": 89,
    "time": 3447.190676,
    "actor_loss": 14.78792953491211,
    "critic_loss": 4.7644944190979,
    "ent_coef": 0.017089921981096268,
    "learning_rate": 0.001
  },
  {
    "episode": 80,
    "reward": -153.314703,
    "length": 246,
    "time": 3484.561878,
    "actor_loss": 15.482104301452637,
    "critic_loss": 3.6810576915740967,
    "ent_coef": 0.017120247706770897,
    "learning_rate": 0.001
  },
  {
    "episode": 81,
    "reward": -139.824546,
    "length": 562,
    "time": 3564.675957,
    "actor_loss": 13.344939231872559,
    "critic_loss": 3.0831055641174316,
    "ent_coef": 0.020258063450455666,
    "learning_rate": 0.001
  },
  {
    "episode": 82,
    "reward": -134.655843,
    "length": 246,
    "time": 3602.180267,
    "actor_loss": 14.78205680847168,
    "critic_loss": 6.744784355163574,
    "ent_coef": 0.021447962149977684,
    "learning_rate": 0.001
  },
  {
    "episode": 83,
    "reward": -127.562423,
    "length": 561,
    "time": 3682.270505,
    "actor_loss": 12.588149070739746,
    "critic_loss": 1.9413634538650513,
    "ent_coef": 0.02041713520884514,
    "learning_rate": 0.001
  },
  {
    "episode": 84,
    "reward": -124.401981,
    "length": 67,
    "time": 3696.315118,
    "actor_loss": 14.43478775024414,
    "critic_loss": 7.9036149978637695,
    "ent_coef": 0.019939208403229713,
    "learning_rate": 0.001
  },
  {
    "episode": 85,
    "reward": -87.706575,
    "length": 545,
    "time": 3776.403518,
    "actor_loss": 15.63598346710205,
    "critic_loss": 10.357961654663086,
    "ent_coef": 0.017870433628559113,
    "learning_rate": 0.001
  },
  {
    "episode": 86,
    "reward": -97.400019,
    "length": 559,
    "time": 3856.424344,
    "actor_loss": 14.877483367919922,
    "critic_loss": 1.9234538078308105,
    "ent_coef": 0.016313647851347923,
    "learning_rate": 0.001
  },
  {
    "episode": 87,
    "reward": -104.996501,
    "length": 98,
    "time": 3873.270985,
    "actor_loss": 15.233050346374512,
    "critic_loss": 8.376998901367188,
    "ent_coef": 0.01753491908311844,
    "learning_rate": 0.001
  },
  {
    "episode": 88,
    "reward": -165.39453,
    "length": 257,
    "time": 3912.741563,
    "actor_loss": 14.334157943725586,
    "critic_loss": 151.1027069091797,
    "ent_coef": 0.016594327986240387,
    "learning_rate": 0.001
  },
  {
    "episode": 89,
    "reward": -104.205751,
    "length": 135,
    "time": 3935.064874,
    "actor_loss": 14.776975631713867,
    "critic_loss": 150.26165771484375,
    "ent_coef": 0.015098734758794308,
    "learning_rate": 0.001
  },
  {
    "episode": 90,
    "reward": -114.101595,
    "length": 112,
    "time": 3954.114278,
    "actor_loss": 16.782928466796875,
    "critic_loss": 352.0569152832031,
    "ent_coef": 0.0139461075887084,
    "learning_rate": 0.001
  },
  {
    "episode": 91,
    "reward": -145.565012,
    "length": 394,
    "time": 4013.67083,
    "actor_loss": 16.103912353515625,
    "critic_loss": 1.0738646984100342,
    "ent_coef": 0.013205697759985924,
    "learning_rate": 0.001
  },
  {
    "episode": 92,
    "reward": -198.263611,
    "length": 340,
    "time": 4063.668973,
    "actor_loss": 15.880056381225586,
    "critic_loss": 3.346773624420166,
    "ent_coef": 0.015889707952737808,
    "learning_rate": 0.001
  },
  {
    "episode": 93,
    "reward": -111.940586,
    "length": 76,
    "time": 4078.309459,
    "actor_loss": 15.230707168579102,
    "critic_loss": 94.52946472167969,
    "ent_coef": 0.01596633531153202,
    "learning_rate": 0.001
  },
  {
    "episode": 94,
    "reward": -117.947386,
    "length": 68,
    "time": 4092.48695,
    "actor_loss": 16.040307998657227,
    "critic_loss": 1.414139747619629,
    "ent_coef": 0.016316721215844154,
    "learning_rate": 0.001
  },
  {
    "episode": 95,
    "reward": -91.120771,
    "length": 561,
    "time": 4172.587402,
    "actor_loss": 14.805028915405273,
    "critic_loss": 0.6076227426528931,
    "ent_coef": 0.013800439424812794,
    "learning_rate": 0.001
  },
  {
    "episode": 96,
    "reward": -215.049831,
    "length": 380,
    "time": 4228.143557,
    "actor_loss": 16.987037658691406,
    "critic_loss": 2.7909557819366455,
    "ent_coef": 0.013028099201619625,
    "learning_rate": 0.001
  },
  {
    "episode": 97,
    "reward": -137.139197,
    "length": 272,
    "time": 4271.888349,
    "actor_loss": 18.743011474609375,
    "critic_loss": 5.1347222328186035,
    "ent_coef": 0.01367037370800972,
    "learning_rate": 0.001
  },
  {
    "episode": 98,
    "reward": -120.492518,
    "length": 367,
    "time": 4328.096985,
    "actor_loss": 15.807657241821289,
    "critic_loss": 128.63809204101562,
    "ent_coef": 0.012513727881014347,
    "learning_rate": 0.001
  },
  {
    "episode": 99,
    "reward": 70.068508,
    "length": 499,
    "time": 4400.724489,
    "actor_loss": 18.640439987182617,
    "critic_loss": 5.839754581451416,
    "ent_coef": 0.014034779742360115,
    "learning_rate": 0.001
  },
  {
    "episode": 100,
    "reward": -142.696389,
    "length": 156,
    "time": 4428.288379,
    "actor_loss": 14.758136749267578,
    "critic_loss": 17.75051498413086,
    "ent_coef": 0.014245242811739445,
    "learning_rate": 0.001
  },
  {
    "episode": 101,
    "reward": -120.606465,
    "length": 19,
    "time": 4436.311177,
    "actor_loss": 15.975796699523926,
    "critic_loss": 1.6393613815307617,
    "ent_coef": 0.014305218122899532,
    "learning_rate": 0.001
  },
  {
    "episode": 102,
    "reward": -153.884186,
    "length": 248,
    "time": 4474.89923,
    "actor_loss": 18.93010711669922,
    "critic_loss": 25.4591121673584,
    "ent_coef": 0.013669050298631191,
    "learning_rate": 0.001
  },
  {
    "episode": 103,
    "reward": -70.009737,
    "length": 551,
    "time": 4554.935714,
    "actor_loss": 16.47435760498047,
    "critic_loss": 14.63930892944336,
    "ent_coef": 0.01224201824516058,
    "learning_rate": 0.001
  },
  {
    "episode": 104,
    "reward": -130.585298,
    "length": 147,
    "time": 4580.420393,
    "actor_loss": 14.879924774169922,
    "critic_loss": 3.7240238189697266,
    "ent_coef": 0.01229603961110115,
    "learning_rate": 0.001
  },
  {
    "episode": 105,
    "reward": -192.49365,
    "length": 449,
    "time": 4645.695544,
    "actor_loss": 18.65938949584961,
    "critic_loss": 22.309181213378906,
    "ent_coef": 0.011208700947463512,
    "learning_rate": 0.001
  },
  {
    "episode": 106,
    "reward": -144.926553,
    "length": 325,
    "time": 4697.093734,
    "actor_loss": 17.150596618652344,
    "critic_loss": 3.4275126457214355,
    "ent_coef": 0.011936083436012268,
    "learning_rate": 0.001
  },
  {
    "episode": 107,
    "reward": -208.38887,
    "length": 535,
    "time": 4774.966797,
    "actor_loss": 16.408611297607422,
    "critic_loss": 114.92515563964844,
    "ent_coef": 0.015915680676698685,
    "learning_rate": 0.001
  },
  {
    "episode": 108,
    "reward": -44.194319,
    "length": 534,
    "time": 4854.972912,
    "actor_loss": 18.276168823242188,
    "critic_loss": 4.364248275756836,
    "ent_coef": 0.016596537083387375,
    "learning_rate": 0.001
  },
  {
    "episode": 109,
    "reward": -128.587076,
    "length": 92,
    "time": 4872.316683,
    "actor_loss": 19.639944076538086,
    "critic_loss": 2.6271233558654785,
    "ent_coef": 0.01563645526766777,
    "learning_rate": 0.001
  },
  {
    "episode": 110,
    "reward": -103.901837,
    "length": 545,
    "time": 4952.423615,
    "actor_loss": 20.642913818359375,
    "critic_loss": 96.85723876953125,
    "ent_coef": 0.013793827965855598,
    "learning_rate": 0.001
  },
  {
    "episode": 111,
    "reward": -185.106773,
    "length": 401,
    "time": 5013.144776,
    "actor_loss": 18.1231689453125,
    "critic_loss": 17.19045639038086,
    "ent_coef": 0.011271919123828411,
    "learning_rate": 0.001
  },
  {
    "episode": 112,
    "reward": -143.944281,
    "length": 465,
    "time": 5082.018847,
    "actor_loss": 16.00615119934082,
    "critic_loss": 109.17228698730469,
    "ent_coef": 0.010839725844562054,
    "learning_rate": 0.001
  },
  {
    "episode": 113,
    "reward": -134.913672,
    "length": 553,
    "time": 5162.073139,
    "actor_loss": 19.450214385986328,
    "critic_loss": 2.239798069000244,
    "ent_coef": 0.011008127592504025,
    "learning_rate": 0.001
  },
  {
    "episode": 114,
    "reward": -133.574224,
    "length": 383,
    "time": 5217.963443,
    "actor_loss": 18.67768096923828,
    "critic_loss": 121.41244506835938,
    "ent_coef": 0.01132605504244566,
    "learning_rate": 0.001
  },
  {
    "episode": 115,
    "reward": -160.206961,
    "length": 534,
    "time": 5295.874857,
    "actor_loss": 18.49283218383789,
    "critic_loss": 18.63806915283203,
    "ent_coef": 0.012334898114204407,
    "learning_rate": 0.001
  },
  {
    "episode": 116,
    "reward": -139.014837,
    "length": 387,
    "time": 5353.765042,
    "actor_loss": 17.673377990722656,
    "critic_loss": 11.763980865478516,
    "ent_coef": 0.012878583744168282,
    "learning_rate": 0.001
  },
  {
    "episode": 117,
    "reward": -180.885433,
    "length": 378,
    "time": 5409.51634,
    "actor_loss": 16.57611083984375,
    "critic_loss": 99.65287780761719,
    "ent_coef": 0.013669116422533989,
    "learning_rate": 0.001
  },
  {
    "episode": 118,
    "reward": -138.257755,
    "length": 286,
    "time": 5453.199289,
    "actor_loss": 17.237154006958008,
    "critic_loss": 2.4444525241851807,
    "ent_coef": 0.012632500380277634,
    "learning_rate": 0.001
  },
  {
    "episode": 119,
    "reward": -163.754942,
    "length": 389,
    "time": 5510.984457,
    "actor_loss": 18.10283088684082,
    "critic_loss": 5.706913948059082,
    "ent_coef": 0.012322764843702316,
    "learning_rate": 0.001
  },
  {
    "episode": 120,
    "reward": -38.65929,
    "length": 541,
    "time": 5591.124541,
    "actor_loss": 19.884815216064453,
    "critic_loss": 3.082361936569214,
    "ent_coef": 0.014374395832419395,
    "learning_rate": 0.001
  },
  {
    "episode": 121,
    "reward": -118.715526,
    "length": 141,
    "time": 5615.719056,
    "actor_loss": 15.46395492553711,
    "critic_loss": 4.1635260581970215,
    "ent_coef": 0.013213721103966236,
    "learning_rate": 0.001
  },
  {
    "episode": 122,
    "reward": -148.24743,
    "length": 347,
    "time": 5668.025408,
    "actor_loss": 19.369184494018555,
    "critic_loss": 2.603395938873291,
    "ent_coef": 0.011179300025105476,
    "learning_rate": 0.001
  },
  {
    "episode": 123,
    "reward": -119.497305,
    "length": 77,
    "time": 5682.968162,
    "actor_loss": 16.757156372070312,
    "critic_loss": 164.3066864013672,
    "ent_coef": 0.010874422267079353,
    "learning_rate": 0.001
  },
  {
    "episode": 124,
    "reward": -113.202809,
    "length": 120,
    "time": 5703.782402,
    "actor_loss": 20.893342971801758,
    "critic_loss": 9.305587768554688,
    "ent_coef": 0.010762768797576427,
    "learning_rate": 0.001
  },
  {
    "episode": 125,
    "reward": -135.489033,
    "length": 532,
    "time": 5783.849271,
    "actor_loss": 18.770004272460938,
    "critic_loss": 17.406932830810547,
    "ent_coef": 0.01026579737663269,
    "learning_rate": 0.001
  },
  {
    "episode": 126,
    "reward": -55.498663,
    "length": 567,
    "time": 5863.952578,
    "actor_loss": 19.33464813232422,
    "critic_loss": 29.520748138427734,
    "ent_coef": 0.007401308976113796,
    "learning_rate": 0.001
  },
  {
    "episode": 127,
    "reward": -139.809529,
    "length": 256,
    "time": 5901.904606,
    "actor_loss": 19.071212768554688,
    "critic_loss": 108.48100280761719,
    "ent_coef": 0.006079827435314655,
    "learning_rate": 0.001
  },
  {
    "episode": 128,
    "reward": -164.239581,
    "length": 570,
    "time": 5979.249079,
    "actor_loss": 19.333498001098633,
    "critic_loss": 13.869173049926758,
    "ent_coef": 0.008140582591295242,
    "learning_rate": 0.001
  },
  {
    "episode": 129,
    "reward": -104.194172,
    "length": 209,
    "time": 6010.83566,
    "actor_loss": 17.805721282958984,
    "critic_loss": 91.34330749511719,
    "ent_coef": 0.009013772942125797,
    "learning_rate": 0.001
  },
  {
    "episode": 130,
    "reward": -104.201632,
    "length": 199,
    "time": 6040.523514,
    "actor_loss": 18.981990814208984,
    "critic_loss": 93.47242736816406,
    "ent_coef": 0.010154662653803825,
    "learning_rate": 0.001
  },
  {
    "episode": 131,
    "reward": -128.188697,
    "length": 110,
    "time": 6059.064675,
    "actor_loss": 18.91527557373047,
    "critic_loss": 1.9777857065200806,
    "ent_coef": 0.011197786778211594,
    "learning_rate": 0.001
  },
  {
    "episode": 132,
    "reward": -120.021534,
    "length": 1,
    "time": 6070.305307,
    "actor_loss": 19.745012283325195,
    "critic_loss": 5.467052936553955,
    "ent_coef": 0.01119703333824873,
    "learning_rate": 0.001
  },
  {
    "episode": 133,
    "reward": -37.103969,
    "length": 558,
    "time": 6150.338438,
    "actor_loss": 20.561080932617188,
    "critic_loss": 35.65110778808594,
    "ent_coef": 0.010273534804582596,
    "learning_rate": 0.001
  },
  {
    "episode": 134,
    "reward": -129.471606,
    "length": 170,
    "time": 6180.531965,
    "actor_loss": 19.07001495361328,
    "critic_loss": 3.804720878601074,
    "ent_coef": 0.010066907852888107,
    "learning_rate": 0.001
  },
  {
    "episode": 135,
    "reward": -110.409291,
    "length": 74,
    "time": 6197.421978,
    "actor_loss": 19.704280853271484,
    "critic_loss": 1.7396187782287598,
    "ent_coef": 0.010233731009066105,
    "learning_rate": 0.001
  },
  {
    "episode": 136,
    "reward": -145.448994,
    "length": 455,
    "time": 6270.85091,
    "actor_loss": 20.565494537353516,
    "critic_loss": 4.399753570556641,
    "ent_coef": 0.010080344043672085,
    "learning_rate": 0.001
  },
  {
    "episode": 137,
    "reward": -120.077129,
    "length": 3,
    "time": 6278.945317,
    "actor_loss": 18.723926544189453,
    "critic_loss": 1.2184127569198608,
    "ent_coef": 0.010134306736290455,
    "learning_rate": 0.001
  },
  {
    "episode": 138,
    "reward": -61.86786,
    "length": 534,
    "time": 6358.995652,
    "actor_loss": 19.45213508605957,
    "critic_loss": 10.857034683227539,
    "ent_coef": 0.01112046092748642,
    "learning_rate": 0.001
  },
  {
    "episode": 139,
    "reward": -117.805721,
    "length": 182,
    "time": 6390.218118,
    "actor_loss": 21.627025604248047,
    "critic_loss": 5.144437789916992,
    "ent_coef": 0.010323487222194672,
    "learning_rate": 0.001
  },
  {
    "episode": 140,
    "reward": -120.02244,
    "length": 1,
    "time": 6399.75398,
    "actor_loss": 20.349102020263672,
    "critic_loss": 3.0700340270996094,
    "ent_coef": 0.010319903492927551,
    "learning_rate": 0.001
  },
  {
    "episode": 141,
    "reward": -120.509952,
    "length": 18,
    "time": 6407.809418,
    "actor_loss": 17.052600860595703,
    "critic_loss": 0.7584990859031677,
    "ent_coef": 0.010298652574419975,
    "learning_rate": 0.001
  },
  {
    "episode": 142,
    "reward": -125.290091,
    "length": 276,
    "time": 6450.645911,
    "actor_loss": 20.892845153808594,
    "critic_loss": 207.34201049804688,
    "ent_coef": 0.010069063864648342,
    "learning_rate": 0.001
  },
  {
    "episode": 143,
    "reward": -66.915185,
    "length": 560,
    "time": 6530.753152,
    "actor_loss": 19.44487762451172,
    "critic_loss": 2.101973295211792,
    "ent_coef": 0.010234375484287739,
    "learning_rate": 0.001
  },
  {
    "episode": 144,
    "reward": -117.02009,
    "length": 77,
    "time": 6545.369676,
    "actor_loss": 18.934354782104492,
    "critic_loss": 128.3055419921875,
    "ent_coef": 0.010452097281813622,
    "learning_rate": 0.001
  },
  {
    "episode": 145,
    "reward": -103.718967,
    "length": 602,
    "time": 6625.469492,
    "actor_loss": 16.161849975585938,
    "critic_loss": 17.555133819580078,
    "ent_coef": 0.009459072723984718,
    "learning_rate": 0.001
  },
  {
    "episode": 146,
    "reward": -161.123402,
    "length": 401,
    "time": 6680.671811,
    "actor_loss": 19.746944427490234,
    "critic_loss": 100.28628540039062,
    "ent_coef": 0.010203121230006218,
    "learning_rate": 0.001
  },
  {
    "episode": 147,
    "reward": -134.917784,
    "length": 232,
    "time": 6713.560947,
    "actor_loss": 21.8934326171875,
    "critic_loss": 176.319091796875,
    "ent_coef": 0.009169017896056175,
    "learning_rate": 0.001
  },
  {
    "episode": 148,
    "reward": 75.067699,
    "length": 460,
    "time": 6776.662196,
    "actor_loss": 20.251853942871094,
    "critic_loss": 218.15318298339844,
    "ent_coef": 0.00992493238300085,
    "learning_rate": 0.001
  },
  {
    "episode": 149,
    "reward": -164.07866,
    "length": 274,
    "time": 6816.030853,
    "actor_loss": 22.55600929260254,
    "critic_loss": 6.179112434387207,
    "ent_coef": 0.0091042909771204,
    "learning_rate": 0.001
  },
  {
    "episode": 150,
    "reward": -105.187939,
    "length": 135,
    "time": 6837.582291,
    "actor_loss": 20.511762619018555,
    "critic_loss": 1.1149656772613525,
    "ent_coef": 0.00813166331499815,
    "learning_rate": 0.001
  },
  {
    "episode": 151,
    "reward": -107.695448,
    "length": 153,
    "time": 6862.071615,
    "actor_loss": 16.947959899902344,
    "critic_loss": 1.2962901592254639,
    "ent_coef": 0.007416768930852413,
    "learning_rate": 0.001
  },
  {
    "episode": 152,
    "reward": -159.306697,
    "length": 407,
    "time": 6919.30428,
    "actor_loss": 19.852367401123047,
    "critic_loss": 1.7350200414657593,
    "ent_coef": 0.008296729065477848,
    "learning_rate": 0.001
  },
  {
    "episode": 153,
    "reward": -192.911312,
    "length": 439,
    "time": 6977.594938,
    "actor_loss": 21.107234954833984,
    "critic_loss": 4.36657190322876,
    "ent_coef": 0.007143386173993349,
    "learning_rate": 0.001
  },
  {
    "episode": 154,
    "reward": -179.312807,
    "length": 434,
    "time": 7036.482182,
    "actor_loss": 20.06252670288086,
    "critic_loss": 138.09832763671875,
    "ent_coef": 0.007718945387750864,
    "learning_rate": 0.001
  },
  {
    "episode": 155,
    "reward": -120.022532,
    "length": 1,
    "time": 7045.359797,
    "actor_loss": 24.121612548828125,
    "critic_loss": 5.3790507316589355,
    "ent_coef": 0.0077253226190805435,
    "learning_rate": 0.001
  },
  {
    "episode": 156,
    "reward": -59.566168,
    "length": 608,
    "time": 7125.444512,
    "actor_loss": 21.853195190429688,
    "critic_loss": 8.636260986328125,
    "ent_coef": 0.008086422458291054,
    "learning_rate": 0.001
  },
  {
    "episode": 157,
    "reward": -64.5198,
    "length": 594,
    "time": 7205.552603,
    "actor_loss": 19.42355728149414,
    "critic_loss": 75.70167541503906,
    "ent_coef": 0.008860298432409763,
    "learning_rate": 0.001
  },
  {
    "episode": 158,
    "reward": -156.527279,
    "length": 533,
    "time": 7278.686313,
    "actor_loss": 18.806385040283203,
    "critic_loss": 3.626436233520508,
    "ent_coef": 0.008155097253620625,
    "learning_rate": 0.001
  },
  {
    "episode": 159,
    "reward": -116.348674,
    "length": 182,
    "time": 7308.081178,
    "actor_loss": 18.485124588012695,
    "critic_loss": 7.369685649871826,
    "ent_coef": 0.006863742135465145,
    "learning_rate": 0.001
  },
  {
    "episode": 160,
    "reward": -148.237851,
    "length": 252,
    "time": 7345.918388,
    "actor_loss": 20.067001342773438,
    "critic_loss": 2.4249894618988037,
    "ent_coef": 0.006603585090488195,
    "learning_rate": 0.001
  },
  {
    "episode": 161,
    "reward": -110.168738,
    "length": 177,
    "time": 7372.044886,
    "actor_loss": 18.91901397705078,
    "critic_loss": 20.643077850341797,
    "ent_coef": 0.006175765302032232,
    "learning_rate": 0.001
  },
  {
    "episode": 162,
    "reward": 113.242164,
    "length": 204,
    "time": 7401.391163,
    "actor_loss": 17.36761474609375,
    "critic_loss": 1.9117717742919922,
    "ent_coef": 0.006843378767371178,
    "learning_rate": 0.001
  },
  {
    "episode": 163,
    "reward": -141.11953,
    "length": 219,
    "time": 7432.508529,
    "actor_loss": 21.481426239013672,
    "critic_loss": 2.8216233253479004,
    "ent_coef": 0.008018942549824715,
    "learning_rate": 0.001
  },
  {
    "episode": 164,
    "reward": -120.587409,
    "length": 25,
    "time": 7440.527742,
    "actor_loss": 21.02637481689453,
    "critic_loss": 16.422767639160156,
    "ent_coef": 0.007955855689942837,
    "learning_rate": 0.001
  },
  {
    "episode": 165,
    "reward": -116.759125,
    "length": 242,
    "time": 7473.828614,
    "actor_loss": 20.245315551757812,
    "critic_loss": 6.497139930725098,
    "ent_coef": 0.006844296120107174,
    "learning_rate": 0.001
  },
  {
    "episode": 166,
    "reward": -113.108304,
    "length": 614,
    "time": 7553.852164,
    "actor_loss": 18.404560089111328,
    "critic_loss": 1.5413587093353271,
    "ent_coef": 0.00860997661948204,
    "learning_rate": 0.001
  },
  {
    "episode": 167,
    "reward": 134.531439,
    "length": 45,
    "time": 7563.017187,
    "actor_loss": 21.55452537536621,
    "critic_loss": 59.35185241699219,
    "ent_coef": 0.008849147707223892,
    "learning_rate": 0.001
  },
  {
    "episode": 168,
    "reward": -112.390597,
    "length": 612,
    "time": 7643.074825,
    "actor_loss": 23.156415939331055,
    "critic_loss": 10.855659484863281,
    "ent_coef": 0.009896526113152504,
    "learning_rate": 0.001
  },
  {
    "episode": 169,
    "reward": -41.927229,
    "length": 615,
    "time": 7723.179834,
    "actor_loss": 19.62995147705078,
    "critic_loss": 115.40383911132812,
    "ent_coef": 0.012576629407703876,
    "learning_rate": 0.001
  },
  {
    "episode": 170,
    "reward": -107.666641,
    "length": 168,
    "time": 7747.65932,
    "actor_loss": 19.415775299072266,
    "critic_loss": 23.35072898864746,
    "ent_coef": 0.011352462694048882,
    "learning_rate": 0.001
  },
  {
    "episode": 171,
    "reward": -120.492472,
    "length": 207,
    "time": 7781.57664,
    "actor_loss": 20.300065994262695,
    "critic_loss": 3.004631519317627,
    "ent_coef": 0.011462968774139881,
    "learning_rate": 0.001
  },
  {
    "episode": 172,
    "reward": -107.773442,
    "length": 165,
    "time": 7806.073512,
    "actor_loss": 19.54767608642578,
    "critic_loss": 2.5485663414001465,
    "ent_coef": 0.01178216002881527,
    "learning_rate": 0.001
  },
  {
    "episode": 173,
    "reward": -138.62945,
    "length": 280,
    "time": 7843.811476,
    "actor_loss": 20.097999572753906,
    "critic_loss": 96.68426513671875,
    "ent_coef": 0.011848414316773415,
    "learning_rate": 0.001
  },
  {
    "episode": 174,
    "reward": -172.174356,
    "length": 398,
    "time": 7896.647851,
    "actor_loss": 17.54730987548828,
    "critic_loss": 7.041811466217041,
    "ent_coef": 0.012587596662342548,
    "learning_rate": 0.001
  },
  {
    "episode": 175,
    "reward": -145.748011,
    "length": 403,
    "time": 7949.888499,
    "actor_loss": 19.6590518951416,
    "critic_loss": 59.53461456298828,
    "ent_coef": 0.01189375575631857,
    "learning_rate": 0.001
  },
  {
    "episode": 176,
    "reward": -198.361415,
    "length": 445,
    "time": 8008.400943,
    "actor_loss": 22.232343673706055,
    "critic_loss": 1.0523602962493896,
    "ent_coef": 0.011677389033138752,
    "learning_rate": 0.001
  },
  {
    "episode": 177,
    "reward": -113.319436,
    "length": 212,
    "time": 8039.282959,
    "actor_loss": 19.614412307739258,
    "critic_loss": 19.743541717529297,
    "ent_coef": 0.011499615386128426,
    "learning_rate": 0.001
  },
  {
    "episode": 178,
    "reward": -120.590078,
    "length": 22,
    "time": 8047.302792,
    "actor_loss": 20.535842895507812,
    "critic_loss": 1.4763609170913696,
    "ent_coef": 0.011296665295958519,
    "learning_rate": 0.001
  },
  {
    "episode": 179,
    "reward": -109.41329,
    "length": 610,
    "time": 8127.42971,
    "actor_loss": 20.070167541503906,
    "critic_loss": 1.1710448265075684,
    "ent_coef": 0.008394007571041584,
    "learning_rate": 0.001
  },
  {
    "episode": 180,
    "reward": -182.434696,
    "length": 493,
    "time": 8192.581681,
    "actor_loss": 17.918752670288086,
    "critic_loss": 3.9542834758758545,
    "ent_coef": 0.00905144214630127,
    "learning_rate": 0.001
  },
  {
    "episode": 181,
    "reward": -40.099594,
    "length": 593,
    "time": 8272.586263,
    "actor_loss": 22.534358978271484,
    "critic_loss": 129.08358764648438,
    "ent_coef": 0.007928172126412392,
    "learning_rate": 0.001
  },
  {
    "episode": 182,
    "reward": 77.253559,
    "length": 462,
    "time": 8335.217824,
    "actor_loss": 20.652976989746094,
    "critic_loss": 4.178557395935059,
    "ent_coef": 0.007717870641499758,
    "learning_rate": 0.001
  },
  {
    "episode": 183,
    "reward": -136.017702,
    "length": 153,
    "time": 8359.575929,
    "actor_loss": 19.187299728393555,
    "critic_loss": 12.86724853515625,
    "ent_coef": 0.008507010526955128,
    "learning_rate": 0.001
  },
  {
    "episode": 184,
    "reward": -120.212129,
    "length": 292,
    "time": 8400.021704,
    "actor_loss": 21.680255889892578,
    "critic_loss": 2.8507936000823975,
    "ent_coef": 0.010713914409279823,
    "learning_rate": 0.001
  },
  {
    "episode": 185,
    "reward": -106.226069,
    "length": 143,
    "time": 8421.625074,
    "actor_loss": 22.081890106201172,
    "critic_loss": 2.620422124862671,
    "ent_coef": 0.009580486454069614,
    "learning_rate": 0.001
  },
  {
    "episode": 186,
    "reward": -163.089023,
    "length": 334,
    "time": 8466.287617,
    "actor_loss": 22.29112434387207,
    "critic_loss": 4.914841651916504,
    "ent_coef": 0.007854877971112728,
    "learning_rate": 0.001
  },
  {
    "episode": 187,
    "reward": -121.974431,
    "length": 294,
    "time": 8506.186178,
    "actor_loss": 22.938575744628906,
    "critic_loss": 1.9628679752349854,
    "ent_coef": 0.009166635572910309,
    "learning_rate": 0.001
  },
  {
    "episode": 188,
    "reward": -168.819245,
    "length": 387,
    "time": 8558.891873,
    "actor_loss": 22.074310302734375,
    "critic_loss": 2.1142640113830566,
    "ent_coef": 0.011213009245693684,
    "learning_rate": 0.001
  },
  {
    "episode": 189,
    "reward": -102.125273,
    "length": 109,
    "time": 8575.261177,
    "actor_loss": 20.041362762451172,
    "critic_loss": 222.42530822753906,
    "ent_coef": 0.009959869086742401,
    "learning_rate": 0.001
  },
  {
    "episode": 190,
    "reward": -119.015497,
    "length": 221,
    "time": 8605.365243,
    "actor_loss": 23.41384506225586,
    "critic_loss": 1.4288612604141235,
    "ent_coef": 0.009063302539288998,
    "learning_rate": 0.001
  },
  {
    "episode": 191,
    "reward": -114.249526,
    "length": 175,
    "time": 8632.443535,
    "actor_loss": 22.01898956298828,
    "critic_loss": 1.2064744234085083,
    "ent_coef": 0.008299431763589382,
    "learning_rate": 0.001
  },
  {
    "episode": 192,
    "reward": -241.536891,
    "length": 578,
    "time": 8708.335029,
    "actor_loss": 22.13619613647461,
    "critic_loss": 7.1155171394348145,
    "ent_coef": 0.008711779490113258,
    "learning_rate": 0.001
  },
  {
    "episode": 193,
    "reward": -129.502655,
    "length": 244,
    "time": 8743.520497,
    "actor_loss": 20.37000274658203,
    "critic_loss": 3.510462760925293,
    "ent_coef": 0.0088173383846879,
    "learning_rate": 0.001
  },
  {
    "episode": 194,
    "reward": -146.933265,
    "length": 329,
    "time": 8791.895151,
    "actor_loss": 20.051576614379883,
    "critic_loss": 125.95990753173828,
    "ent_coef": 0.009409538470208645,
    "learning_rate": 0.001
  },
  {
    "episode": 195,
    "reward": -109.970916,
    "length": 144,
    "time": 8812.65322,
    "actor_loss": 21.677112579345703,
    "critic_loss": 22.93993377685547,
    "ent_coef": 0.010078069753944874,
    "learning_rate": 0.001
  },
  {
    "episode": 196,
    "reward": -106.574562,
    "length": 117,
    "time": 8830.225157,
    "actor_loss": 20.254608154296875,
    "critic_loss": 3.261381149291992,
    "ent_coef": 0.0088040791451931,
    "learning_rate": 0.001
  },
  {
    "episode": 197,
    "reward": -108.51827,
    "length": 195,
    "time": 8860.085792,
    "actor_loss": 22.00399398803711,
    "critic_loss": 4.927408218383789,
    "ent_coef": 0.007929407991468906,
    "learning_rate": 0.001
  },
  {
    "episode": 198,
    "reward": -110.552381,
    "length": 604,
    "time": 8940.1403,
    "actor_loss": 24.16529083251953,
    "critic_loss": 10.088088035583496,
    "ent_coef": 0.008670181035995483,
    "learning_rate": 0.001
  },
  {
    "episode": 199,
    "reward": 118.766897,
    "length": 99,
    "time": 8959.138323,
    "actor_loss": 23.49272918701172,
    "critic_loss": 0.8599468469619751,
    "ent_coef": 0.00891146156936884,
    "learning_rate": 0.001
  },
  {
    "episode": 200,
    "reward": -121.110003,
    "length": 36,
    "time": 8967.248811,
    "actor_loss": 21.468921661376953,
    "critic_loss": 5.923830986022949,
    "ent_coef": 0.008990331552922726,
    "learning_rate": 0.001
  },
  {
    "episode": 201,
    "reward": -102.086131,
    "length": 610,
    "time": 9047.251986,
    "actor_loss": 21.539613723754883,
    "critic_loss": 1.5955427885055542,
    "ent_coef": 0.010918035171926022,
    "learning_rate": 0.001
  },
  {
    "episode": 202,
    "reward": -105.221738,
    "length": 101,
    "time": 9062.566959,
    "actor_loss": 21.446182250976562,
    "critic_loss": 3.2494306564331055,
    "ent_coef": 0.010397065430879593,
    "learning_rate": 0.001
  },
  {
    "episode": 203,
    "reward": -123.68101,
    "length": 170,
    "time": 9087.29566,
    "actor_loss": 21.63503646850586,
    "critic_loss": 11.587194442749023,
    "ent_coef": 0.009954697452485561,
    "learning_rate": 0.001
  },
  {
    "episode": 204,
    "reward": -93.610595,
    "length": 612,
    "time": 9167.352862,
    "actor_loss": 22.057109832763672,
    "critic_loss": 16.061132431030273,
    "ent_coef": 0.008269491605460644,
    "learning_rate": 0.001
  },
  {
    "episode": 205,
    "reward": -106.943917,
    "length": 605,
    "time": 9247.354176,
    "actor_loss": 19.889169692993164,
    "critic_loss": 87.55352020263672,
    "ent_coef": 0.008259757421910763,
    "learning_rate": 0.001
  },
  {
    "episode": 206,
    "reward": -184.413793,
    "length": 473,
    "time": 9310.475839,
    "actor_loss": 19.348188400268555,
    "critic_loss": 0.6349534392356873,
    "ent_coef": 0.010496167466044426,
    "learning_rate": 0.001
  },
  {
    "episode": 207,
    "reward": -181.916898,
    "length": 515,
    "time": 9379.73649,
    "actor_loss": 21.309751510620117,
    "critic_loss": 1.7883963584899902,
    "ent_coef": 0.011311741545796394,
    "learning_rate": 0.001
  },
  {
    "episode": 208,
    "reward": -120.590641,
    "length": 283,
    "time": 9419.272392,
    "actor_loss": 23.060914993286133,
    "critic_loss": 84.51593017578125,
    "ent_coef": 0.010393441654741764,
    "learning_rate": 0.001
  },
  {
    "episode": 209,
    "reward": -102.038825,
    "length": 170,
    "time": 9445.682302,
    "actor_loss": 19.41497802734375,
    "critic_loss": 4.2183732986450195,
    "ent_coef": 0.010209142230451107,
    "learning_rate": 0.001
  },
  {
    "episode": 210,
    "reward": -169.479986,
    "length": 388,
    "time": 9499.023862,
    "actor_loss": 21.630556106567383,
    "critic_loss": 14.526853561401367,
    "ent_coef": 0.01173422858119011,
    "learning_rate": 0.001
  },
  {
    "episode": 211,
    "reward": -88.028597,
    "length": 591,
    "time": 9579.059809,
    "actor_loss": 21.041109085083008,
    "critic_loss": 2.7118775844573975,
    "ent_coef": 0.01273239217698574,
    "learning_rate": 0.001
  },
  {
    "episode": 212,
    "reward": -126.734676,
    "length": 161,
    "time": 9605.991438,
    "actor_loss": 20.413063049316406,
    "critic_loss": 4.658038139343262,
    "ent_coef": 0.011315038427710533,
    "learning_rate": 0.001
  },
  {
    "episode": 213,
    "reward": -109.470898,
    "length": 194,
    "time": 9633.556658,
    "actor_loss": 21.687965393066406,
    "critic_loss": 25.69024658203125,
    "ent_coef": 0.010033376514911652,
    "learning_rate": 0.001
  },
  {
    "episode": 214,
    "reward": -152.751713,
    "length": 315,
    "time": 9677.225174,
    "actor_loss": 21.098474502563477,
    "critic_loss": 21.17837142944336,
    "ent_coef": 0.009753180667757988,
    "learning_rate": 0.001
  },
  {
    "episode": 215,
    "reward": -117.374442,
    "length": 170,
    "time": 9703.116077,
    "actor_loss": 20.507827758789062,
    "critic_loss": 3.0977160930633545,
    "ent_coef": 0.010746117681264877,
    "learning_rate": 0.001
  },
  {
    "episode": 216,
    "reward": -160.235684,
    "length": 280,
    "time": 9742.16007,
    "actor_loss": 20.022998809814453,
    "critic_loss": 0.9265242218971252,
    "ent_coef": 0.009419746696949005,
    "learning_rate": 0.001
  },
  {
    "episode": 217,
    "reward": -98.239474,
    "length": 180,
    "time": 9768.472234,
    "actor_loss": 21.377147674560547,
    "critic_loss": 0.9530888795852661,
    "ent_coef": 0.010223970748484135,
    "learning_rate": 0.001
  },
  {
    "episode": 218,
    "reward": -160.95369,
    "length": 248,
    "time": 9804.657765,
    "actor_loss": 20.513835906982422,
    "critic_loss": 11.095251083374023,
    "ent_coef": 0.012215533293783665,
    "learning_rate": 0.001
  },
  {
    "episode": 219,
    "reward": -208.331178,
    "length": 446,
    "time": 9864.851701,
    "actor_loss": 18.49445343017578,
    "critic_loss": 2.1124911308288574,
    "ent_coef": 0.012746120803058147,
    "learning_rate": 0.001
  },
  {
    "episode": 220,
    "reward": -103.113886,
    "length": 186,
    "time": 9891.65372,
    "actor_loss": 20.327312469482422,
    "critic_loss": 0.9836058020591736,
    "ent_coef": 0.01284494437277317,
    "learning_rate": 0.001
  },
  {
    "episode": 221,
    "reward": -133.206372,
    "length": 334,
    "time": 9937.095741,
    "actor_loss": 20.217403411865234,
    "critic_loss": 0.4971086084842682,
    "ent_coef": 0.011987166479229927,
    "learning_rate": 0.001
  },
  {
    "episode": 222,
    "reward": -113.91984,
    "length": 147,
    "time": 9958.770589,
    "actor_loss": 21.131912231445312,
    "critic_loss": 3.4314537048339844,
    "ent_coef": 0.01162315346300602,
    "learning_rate": 0.001
  },
  {
    "episode": 223,
    "reward": -99.671204,
    "length": 212,
    "time": 9991.901576,
    "actor_loss": 21.34787368774414,
    "critic_loss": 4.35094690322876,
    "ent_coef": 0.01092217955738306,
    "learning_rate": 0.001
  },
  {
    "episode": 224,
    "reward": -135.205301,
    "length": 404,
    "time": 10047.163772,
    "actor_loss": 21.610973358154297,
    "critic_loss": 3.392653465270996,
    "ent_coef": 0.009192164056003094,
    "learning_rate": 0.001
  },
  {
    "episode": 225,
    "reward": -157.046656,
    "length": 575,
    "time": 10125.055605,
    "actor_loss": 20.539087295532227,
    "critic_loss": 83.34780883789062,
    "ent_coef": 0.007955458015203476,
    "learning_rate": 0.001
  },
  {
    "episode": 226,
    "reward": 131.722929,
    "length": 119,
    "time": 10146.260519,
    "actor_loss": 23.47370719909668,
    "critic_loss": 220.3516845703125,
    "ent_coef": 0.008089261129498482,
    "learning_rate": 0.001
  },
  {
    "episode": 227,
    "reward": -86.322522,
    "length": 585,
    "time": 10226.317332,
    "actor_loss": 24.191055297851562,
    "critic_loss": 3.8105762004852295,
    "ent_coef": 0.009522571228444576,
    "learning_rate": 0.001
  },
  {
    "episode": 228,
    "reward": -110.890767,
    "length": 108,
    "time": 10243.581022,
    "actor_loss": 21.24677276611328,
    "critic_loss": 1.615601658821106,
    "ent_coef": 0.008634591475129128,
    "learning_rate": 0.001
  },
  {
    "episode": 229,
    "reward": -117.678987,
    "length": 162,
    "time": 10269.831969,
    "actor_loss": 23.105533599853516,
    "critic_loss": 5.1334943771362305,
    "ent_coef": 0.00782773271203041,
    "learning_rate": 0.001
  },
  {
    "episode": 230,
    "reward": -96.734359,
    "length": 610,
    "time": 10349.89914,
    "actor_loss": 23.011268615722656,
    "critic_loss": 1.9937653541564941,
    "ent_coef": 0.009161924943327904,
    "learning_rate": 0.001
  },
  {
    "episode": 231,
    "reward": -60.976129,
    "length": 617,
    "time": 10429.979527,
    "actor_loss": 22.79348373413086,
    "critic_loss": 6.026181221008301,
    "ent_coef": 0.008091799914836884,
    "learning_rate": 0.001
  },
  {
    "episode": 232,
    "reward": -151.952544,
    "length": 246,
    "time": 10465.306398,
    "actor_loss": 19.226703643798828,
    "critic_loss": 16.891033172607422,
    "ent_coef": 0.007548906374722719,
    "learning_rate": 0.001
  },
  {
    "episode": 233,
    "reward": -114.317815,
    "length": 116,
    "time": 10482.677306,
    "actor_loss": 20.917083740234375,
    "critic_loss": 1.68332839012146,
    "ent_coef": 0.008118853904306889,
    "learning_rate": 0.001
  },
  {
    "episode": 234,
    "reward": -111.566773,
    "length": 179,
    "time": 10508.971878,
    "actor_loss": 19.849102020263672,
    "critic_loss": 0.7272562384605408,
    "ent_coef": 0.008443469181656837,
    "learning_rate": 0.001
  },
  {
    "episode": 235,
    "reward": -110.592831,
    "length": 177,
    "time": 10533.914747,
    "actor_loss": 23.252185821533203,
    "critic_loss": 114.99496459960938,
    "ent_coef": 0.009327884763479233,
    "learning_rate": 0.001
  },
  {
    "episode": 236,
    "reward": -110.571766,
    "length": 168,
    "time": 10558.849697,
    "actor_loss": 21.239124298095703,
    "critic_loss": 164.93252563476562,
    "ent_coef": 0.009421251714229584,
    "learning_rate": 0.001
  },
  {
    "episode": 237,
    "reward": -100.909909,
    "length": 107,
    "time": 10576.549217,
    "actor_loss": 19.8321533203125,
    "critic_loss": 3.939037322998047,
    "ent_coef": 0.009374051354825497,
    "learning_rate": 0.001
  },
  {
    "episode": 238,
    "reward": -109.808406,
    "length": 136,
    "time": 10596.542753,
    "actor_loss": 23.949052810668945,
    "critic_loss": 31.757158279418945,
    "ent_coef": 0.009912238456308842,
    "learning_rate": 0.001
  },
  {
    "episode": 239,
    "reward": -108.192934,
    "length": 230,
    "time": 10629.589284,
    "actor_loss": 20.506135940551758,
    "critic_loss": 6.560798168182373,
    "ent_coef": 0.010178684256970882,
    "learning_rate": 0.001
  },
  {
    "episode": 240,
    "reward": -80.94581,
    "length": 595,
    "time": 10709.667303,
    "actor_loss": 23.274799346923828,
    "critic_loss": 11.56972885131836,
    "ent_coef": 0.00941243302077055,
    "learning_rate": 0.001
  },
  {
    "episode": 241,
    "reward": -136.589765,
    "length": 258,
    "time": 10748.582911,
    "actor_loss": 22.844329833984375,
    "critic_loss": 160.69570922851562,
    "ent_coef": 0.008826883509755135,
    "learning_rate": 0.001
  },
  {
    "episode": 242,
    "reward": -120.757976,
    "length": 213,
    "time": 10781.039011,
    "actor_loss": 20.747373580932617,
    "critic_loss": 1.4405219554901123,
    "ent_coef": 0.008222708478569984,
    "learning_rate": 0.001
  },
  {
    "episode": 243,
    "reward": -113.037281,
    "length": 180,
    "time": 10806.578368,
    "actor_loss": 22.733299255371094,
    "critic_loss": 74.22039794921875,
    "ent_coef": 0.007649441249668598,
    "learning_rate": 0.001
  },
  {
    "episode": 244,
    "reward": -101.285613,
    "length": 147,
    "time": 10830.94256,
    "actor_loss": 19.50580406188965,
    "critic_loss": 4.785395622253418,
    "ent_coef": 0.007918254472315311,
    "learning_rate": 0.001
  },
  {
    "episode": 245,
    "reward": -128.824477,
    "length": 197,
    "time": 10859.554107,
    "actor_loss": 20.839427947998047,
    "critic_loss": 149.6173095703125,
    "ent_coef": 0.006943351123481989,
    "learning_rate": 0.001
  },
  {
    "episode": 246,
    "reward": -130.170547,
    "length": 594,
    "time": 10939.658605,
    "actor_loss": 22.774917602539062,
    "critic_loss": 3.357673168182373,
    "ent_coef": 0.007602923549711704,
    "learning_rate": 0.001
  },
  {
    "episode": 247,
    "reward": -122.525107,
    "length": 175,
    "time": 10964.349392,
    "actor_loss": 21.80270767211914,
    "critic_loss": 3.4726059436798096,
    "ent_coef": 0.009022911079227924,
    "learning_rate": 0.001
  },
  {
    "episode": 248,
    "reward": -107.752008,
    "length": 70,
    "time": 10976.634041,
    "actor_loss": 19.486783981323242,
    "critic_loss": 2.8019156455993652,
    "ent_coef": 0.009311637841165066,
    "learning_rate": 0.001
  },
  {
    "episode": 249,
    "reward": -128.345478,
    "length": 119,
    "time": 10994.41,
    "actor_loss": 22.53205108642578,
    "critic_loss": 1.7939002513885498,
    "ent_coef": 0.00963546708226204,
    "learning_rate": 0.001
  },
  {
    "episode": 250,
    "reward": -133.186186,
    "length": 282,
    "time": 11033.829278,
    "actor_loss": 21.14506721496582,
    "critic_loss": 1.8080416917800903,
    "ent_coef": 0.010713934898376465,
    "learning_rate": 0.001
  },
  {
    "episode": 251,
    "reward": -210.204916,
    "length": 349,
    "time": 11080.206023,
    "actor_loss": 20.409496307373047,
    "critic_loss": 0.6442152261734009,
    "ent_coef": 0.010196556337177753,
    "learning_rate": 0.001
  },
  {
    "episode": 252,
    "reward": -147.384979,
    "length": 274,
    "time": 11118.510407,
    "actor_loss": 22.76556396484375,
    "critic_loss": 6.154506683349609,
    "ent_coef": 0.0076219551265239716,
    "learning_rate": 0.001
  },
  {
    "episode": 253,
    "reward": -120.021644,
    "length": 1,
    "time": 11127.834955,
    "actor_loss": 24.636432647705078,
    "critic_loss": 17.1029052734375,
    "ent_coef": 0.007613419089466333,
    "learning_rate": 0.001
  },
  {
    "episode": 254,
    "reward": -220.764389,
    "length": 536,
    "time": 11199.983849,
    "actor_loss": 19.700023651123047,
    "critic_loss": 3.666250228881836,
    "ent_coef": 0.007919077761471272,
    "learning_rate": 0.001
  },
  {
    "episode": 255,
    "reward": -183.464418,
    "length": 402,
    "time": 11255.909367,
    "actor_loss": 22.20807647705078,
    "critic_loss": 71.52452087402344,
    "ent_coef": 0.007224533706903458,
    "learning_rate": 0.001
  },
  {
    "episode": 256,
    "reward": -31.905658,
    "length": 602,
    "time": 11335.97066,
    "actor_loss": 21.719057083129883,
    "critic_loss": 2.3549115657806396,
    "ent_coef": 0.004846886731684208,
    "learning_rate": 0.001
  },
  {
    "episode": 257,
    "reward": -113.677783,
    "length": 170,
    "time": 11361.32239,
    "actor_loss": 22.205196380615234,
    "critic_loss": 25.70364761352539,
    "ent_coef": 0.006506599020212889,
    "learning_rate": 0.001
  },
  {
    "episode": 258,
    "reward": -158.442227,
    "length": 384,
    "time": 11413.875566,
    "actor_loss": 21.613304138183594,
    "critic_loss": 8.190849304199219,
    "ent_coef": 0.008161528035998344,
    "learning_rate": 0.001
  },
  {
    "episode": 259,
    "reward": -179.985134,
    "length": 532,
    "time": 11484.404328,
    "actor_loss": 22.215282440185547,
    "critic_loss": 30.492992401123047,
    "ent_coef": 0.008062152191996574,
    "learning_rate": 0.001
  },
  {
    "episode": 260,
    "reward": -104.79608,
    "length": 108,
    "time": 11500.475064,
    "actor_loss": 26.647884368896484,
    "critic_loss": 3.7604832649230957,
    "ent_coef": 0.009967997670173645,
    "learning_rate": 0.001
  },
  {
    "episode": 261,
    "reward": -107.558853,
    "length": 144,
    "time": 11523.651438,
    "actor_loss": 24.683637619018555,
    "critic_loss": 3.3391199111938477,
    "ent_coef": 0.010465167462825775,
    "learning_rate": 0.001
  },
  {
    "episode": 262,
    "reward": -113.083156,
    "length": 144,
    "time": 11545.879183,
    "actor_loss": 22.95352554321289,
    "critic_loss": 2.9862165451049805,
    "ent_coef": 0.009358277544379234,
    "learning_rate": 0.001
  },
  {
    "episode": 263,
    "reward": -103.620057,
    "length": 170,
    "time": 11573.574284,
    "actor_loss": 21.175743103027344,
    "critic_loss": 61.70204162597656,
    "ent_coef": 0.008235292509198189,
    "learning_rate": 0.001
  },
  {
    "episode": 264,
    "reward": -90.520859,
    "length": 614,
    "time": 11653.687791,
    "actor_loss": 20.104774475097656,
    "critic_loss": 1.6901397705078125,
    "ent_coef": 0.011889089830219746,
    "learning_rate": 0.001
  },
  {
    "episode": 265,
    "reward": -116.632128,
    "length": 115,
    "time": 11670.877869,
    "actor_loss": 21.86734962463379,
    "critic_loss": 3.9865119457244873,
    "ent_coef": 0.01148455124348402,
    "learning_rate": 0.001
  },
  {
    "episode": 266,
    "reward": -120.856419,
    "length": 34,
    "time": 11678.905436,
    "actor_loss": 22.930023193359375,
    "critic_loss": 94.33879089355469,
    "ent_coef": 0.011270425282418728,
    "learning_rate": 0.001
  },
  {
    "episode": 267,
    "reward": -228.43611,
    "length": 603,
    "time": 11758.351696,
    "actor_loss": 22.279577255249023,
    "critic_loss": 6.057066917419434,
    "ent_coef": 0.011018498800694942,
    "learning_rate": 0.001
  },
  {
    "episode": 268,
    "reward": -120.45135,
    "length": 128,
    "time": 11777.182194,
    "actor_loss": 21.40302276611328,
    "critic_loss": 112.4687728881836,
    "ent_coef": 0.011024579405784607,
    "learning_rate": 0.001
  },
  {
    "episode": 269,
    "reward": -117.066962,
    "length": 285,
    "time": 11816.767659,
    "actor_loss": 22.497434616088867,
    "critic_loss": 1.2535734176635742,
    "ent_coef": 0.01083228550851345,
    "learning_rate": 0.001
  },
  {
    "episode": 270,
    "reward": -85.143582,
    "length": 601,
    "time": 11896.780524,
    "actor_loss": 22.3328857421875,
    "critic_loss": 132.107177734375,
    "ent_coef": 0.008628676645457745,
    "learning_rate": 0.001
  },
  {
    "episode": 271,
    "reward": -129.677348,
    "length": 150,
    "time": 11918.771351,
    "actor_loss": 22.104209899902344,
    "critic_loss": 2.6346349716186523,
    "ent_coef": 0.008148995228111744,
    "learning_rate": 0.001
  },
  {
    "episode": 272,
    "reward": -120.223258,
    "length": 9,
    "time": 11926.791271,
    "actor_loss": 21.71381378173828,
    "critic_loss": 52.24331283569336,
    "ent_coef": 0.008161497302353382,
    "learning_rate": 0.001
  },
  {
    "episode": 273,
    "reward": -161.211594,
    "length": 470,
    "time": 11990.973196,
    "actor_loss": 22.681793212890625,
    "critic_loss": 3.0295560359954834,
    "ent_coef": 0.009586097672581673,
    "learning_rate": 0.001
  },
  {
    "episode": 274,
    "reward": -144.072976,
    "length": 307,
    "time": 12031.949076,
    "actor_loss": 23.864490509033203,
    "critic_loss": 144.56002807617188,
    "ent_coef": 0.009173084981739521,
    "learning_rate": 0.001
  },
  {
    "episode": 275,
    "reward": -138.883653,
    "length": 293,
    "time": 12071.376962,
    "actor_loss": 22.702640533447266,
    "critic_loss": 181.20355224609375,
    "ent_coef": 0.008423831313848495,
    "learning_rate": 0.001
  },
  {
    "episode": 276,
    "reward": -147.162069,
    "length": 319,
    "time": 12115.045881,
    "actor_loss": 23.32840919494629,
    "critic_loss": 4.080414295196533,
    "ent_coef": 0.008576723746955395,
    "learning_rate": 0.001
  },
  {
    "episode": 277,
    "reward": -109.354242,
    "length": 98,
    "time": 12130.034873,
    "actor_loss": 23.912914276123047,
    "critic_loss": 5.626650810241699,
    "ent_coef": 0.008875804953277111,
    "learning_rate": 0.001
  },
  {
    "episode": 278,
    "reward": -78.343086,
    "length": 594,
    "time": 12210.146067,
    "actor_loss": 23.145835876464844,
    "critic_loss": 161.02268981933594,
    "ent_coef": 0.008133125491440296,
    "learning_rate": 0.001
  },
  {
    "episode": 279,
    "reward": -117.807813,
    "length": 72,
    "time": 12224.383619,
    "actor_loss": 23.113548278808594,
    "critic_loss": 111.50712585449219,
    "ent_coef": 0.008214247412979603,
    "learning_rate": 0.001
  },
  {
    "episode": 280,
    "reward": 60.771872,
    "length": 499,
    "time": 12293.073176,
    "actor_loss": 23.535720825195312,
    "critic_loss": 1.1239389181137085,
    "ent_coef": 0.006461295764893293,
    "learning_rate": 0.001
  },
  {
    "episode": 281,
    "reward": -200.27286,
    "length": 496,
    "time": 12358.243545,
    "actor_loss": 19.685916900634766,
    "critic_loss": 1.3020660877227783,
    "ent_coef": 0.005375949665904045,
    "learning_rate": 0.001
  },
  {
    "episode": 282,
    "reward": -91.222754,
    "length": 158,
    "time": 12383.026178,
    "actor_loss": 23.87641716003418,
    "critic_loss": 5.383698463439941,
    "ent_coef": 0.007570791523903608,
    "learning_rate": 0.001
  },
  {
    "episode": 283,
    "reward": -143.804419,
    "length": 303,
    "time": 12426.13192,
    "actor_loss": 22.298582077026367,
    "critic_loss": 3.0431041717529297,
    "ent_coef": 0.008722861297428608,
    "learning_rate": 0.001
  },
  {
    "episode": 284,
    "reward": -118.651967,
    "length": 615,
    "time": 12506.245017,
    "actor_loss": 24.852237701416016,
    "critic_loss": 291.7225646972656,
    "ent_coef": 0.00809789914637804,
    "learning_rate": 0.001
  },
  {
    "episode": 285,
    "reward": -159.797782,
    "length": 305,
    "time": 12548.844409,
    "actor_loss": 21.133983612060547,
    "critic_loss": 4.973708629608154,
    "ent_coef": 0.009282263927161694,
    "learning_rate": 0.001
  },
  {
    "episode": 286,
    "reward": -130.217418,
    "length": 379,
    "time": 12602.318615,
    "actor_loss": 23.098045349121094,
    "critic_loss": 0.6470035314559937,
    "ent_coef": 0.0091713797301054,
    "learning_rate": 0.001
  },
  {
    "episode": 287,
    "reward": -139.443656,
    "length": 166,
    "time": 12628.342343,
    "actor_loss": 19.855026245117188,
    "critic_loss": 2.582490921020508,
    "ent_coef": 0.009522860869765282,
    "learning_rate": 0.001
  },
  {
    "episode": 288,
    "reward": -141.118808,
    "length": 300,
    "time": 12669.10868,
    "actor_loss": 24.93987274169922,
    "critic_loss": 63.65296936035156,
    "ent_coef": 0.00894918106496334,
    "learning_rate": 0.001
  },
  {
    "episode": 289,
    "reward": -92.588479,
    "length": 581,
    "time": 12749.162755,
    "actor_loss": 22.723243713378906,
    "critic_loss": 104.52509307861328,
    "ent_coef": 0.009258212521672249,
    "learning_rate": 0.001
  },
  {
    "episode": 290,
    "reward": -122.860275,
    "length": 594,
    "time": 12829.193779,
    "actor_loss": 24.233646392822266,
    "critic_loss": 1.8183465003967285,
    "ent_coef": 0.0079469233751297,
    "learning_rate": 0.001
  },
  {
    "episode": 291,
    "reward": -174.891789,
    "length": 449,
    "time": 12889.298051,
    "actor_loss": 23.622570037841797,
    "critic_loss": 0.7414050102233887,
    "ent_coef": 0.008297259919345379,
    "learning_rate": 0.001
  },
  {
    "episode": 292,
    "reward": -39.767323,
    "length": 593,
    "time": 12969.424958,
    "actor_loss": 22.145776748657227,
    "critic_loss": 5.014387130737305,
    "ent_coef": 0.007569693494588137,
    "learning_rate": 0.001
  },
  {
    "episode": 293,
    "reward": -106.974408,
    "length": 598,
    "time": 13049.460015,
    "actor_loss": 20.43976402282715,
    "critic_loss": 3.340372085571289,
    "ent_coef": 0.009329059161245823,
    "learning_rate": 0.001
  },
  {
    "episode": 294,
    "reward": -142.06422,
    "length": 609,
    "time": 13129.535092,
    "actor_loss": 22.209205627441406,
    "critic_loss": 1.861495018005371,
    "ent_coef": 0.007889130152761936,
    "learning_rate": 0.001
  },
  {
    "episode": 295,
    "reward": -160.813858,
    "length": 447,
    "time": 13189.717505,
    "actor_loss": 24.215957641601562,
    "critic_loss": 113.88936614990234,
    "ent_coef": 0.008439415134489536,
    "learning_rate": 0.001
  },
  {
    "episode": 296,
    "reward": -126.16589,
    "length": 222,
    "time": 13221.541743,
    "actor_loss": 23.20012664794922,
    "critic_loss": 3.884572982788086,
    "ent_coef": 0.008414702489972115,
    "learning_rate": 0.001
  },
  {
    "episode": 297,
    "reward": -147.002135,
    "length": 304,
    "time": 13262.586717,
    "actor_loss": 24.949443817138672,
    "critic_loss": 14.398712158203125,
    "ent_coef": 0.007181531749665737,
    "learning_rate": 0.001
  },
  {
    "episode": 298,
    "reward": -165.681643,
    "length": 499,
    "time": 13330.539304,
    "actor_loss": 20.68124771118164,
    "critic_loss": 7.917415618896484,
    "ent_coef": 0.008943525142967701,
    "learning_rate": 0.001
  },
  {
    "episode": 299,
    "reward": -110.112072,
    "length": 112,
    "time": 13348.362598,
    "actor_loss": 23.501523971557617,
    "critic_loss": 0.3888505697250366,
    "ent_coef": 0.009027339518070221,
    "learning_rate": 0.001
  },
  {
    "episode": 300,
    "reward": -123.870034,
    "length": 251,
    "time": 13383.679467,
    "actor_loss": 24.506574630737305,
    "critic_loss": 42.644264221191406,
    "ent_coef": 0.008131318725645542,
    "learning_rate": 0.001
  },
  {
    "episode": 301,
    "reward": -141.007925,
    "length": 605,
    "time": 13463.722226,
    "actor_loss": 21.289936065673828,
    "critic_loss": 2.2382192611694336,
    "ent_coef": 0.006833918858319521,
    "learning_rate": 0.001
  },
  {
    "episode": 302,
    "reward": -100.04553,
    "length": 578,
    "time": 13543.810024,
    "actor_loss": 24.650409698486328,
    "critic_loss": 3.303781747817993,
    "ent_coef": 0.008119477890431881,
    "learning_rate": 0.001
  },
  {
    "episode": 303,
    "reward": -138.200699,
    "length": 169,
    "time": 13568.610157,
    "actor_loss": 21.061933517456055,
    "critic_loss": 22.372316360473633,
    "ent_coef": 0.007016901392489672,
    "learning_rate": 0.001
  },
  {
    "episode": 304,
    "reward": -69.721273,
    "length": 605,
    "time": 13648.714493,
    "actor_loss": 20.714641571044922,
    "critic_loss": 0.7693695425987244,
    "ent_coef": 0.00700636301189661,
    "learning_rate": 0.001
  },
  {
    "episode": 305,
    "reward": -114.662922,
    "length": 151,
    "time": 13670.387978,
    "actor_loss": 20.63223648071289,
    "critic_loss": 2.1042637825012207,
    "ent_coef": 0.0073378803208470345,
    "learning_rate": 0.001
  },
  {
    "episode": 306,
    "reward": -111.73634,
    "length": 596,
    "time": 13750.459882,
    "actor_loss": 22.240947723388672,
    "critic_loss": 6.489499092102051,
    "ent_coef": 0.006767728831619024,
    "learning_rate": 0.001
  },
  {
    "episode": 307,
    "reward": -198.752445,
    "length": 557,
    "time": 13826.032784,
    "actor_loss": 24.325923919677734,
    "critic_loss": 30.15033531188965,
    "ent_coef": 0.00678554642945528,
    "learning_rate": 0.001
  },
  {
    "episode": 308,
    "reward": -120.560405,
    "length": 19,
    "time": 13834.149293,
    "actor_loss": 21.582805633544922,
    "critic_loss": 2.3573458194732666,
    "ent_coef": 0.0067147379741072655,
    "learning_rate": 0.001
  },
  {
    "episode": 309,
    "reward": -112.09023,
    "length": 158,
    "time": 13858.034299,
    "actor_loss": 22.4263916015625,
    "critic_loss": 0.9244872331619263,
    "ent_coef": 0.006851364858448505,
    "learning_rate": 0.001
  },
  {
    "episode": 310,
    "reward": -107.57647,
    "length": 91,
    "time": 13873.551616,
    "actor_loss": 20.852630615234375,
    "critic_loss": 2.34773588180542,
    "ent_coef": 0.007503844797611237,
    "learning_rate": 0.001
  },
  {
    "episode": 311,
    "reward": -93.09976,
    "length": 599,
    "time": 13953.602775,
    "actor_loss": 22.430339813232422,
    "critic_loss": 4.971938133239746,
    "ent_coef": 0.007777760736644268,
    "learning_rate": 0.001
  },
  {
    "episode": 312,
    "reward": -157.146774,
    "length": 447,
    "time": 14015.775363,
    "actor_loss": 22.821521759033203,
    "critic_loss": 45.037391662597656,
    "ent_coef": 0.006853381171822548,
    "learning_rate": 0.001
  },
  {
    "episode": 313,
    "reward": -112.348394,
    "length": 79,
    "time": 14029.395045,
    "actor_loss": 23.44123077392578,
    "critic_loss": 1.5088005065917969,
    "ent_coef": 0.006781784351915121,
    "learning_rate": 0.001
  },
  {
    "episode": 314,
    "reward": -197.279238,
    "length": 571,
    "time": 14105.735627,
    "actor_loss": 21.621110916137695,
    "critic_loss": 1.6371389627456665,
    "ent_coef": 0.00829917099326849,
    "learning_rate": 0.001
  },
  {
    "episode": 315,
    "reward": -112.735086,
    "length": 609,
    "time": 14185.790979,
    "actor_loss": 22.5576229095459,
    "critic_loss": 8.100791931152344,
    "ent_coef": 0.007404697593301535,
    "learning_rate": 0.001
  },
  {
    "episode": 316,
    "reward": -109.971282,
    "length": 609,
    "time": 14265.825648,
    "actor_loss": 21.71154022216797,
    "critic_loss": 7.245984077453613,
    "ent_coef": 0.006457737646996975,
    "learning_rate": 0.001
  },
  {
    "episode": 317,
    "reward": -127.938666,
    "length": 202,
    "time": 14294.547927,
    "actor_loss": 23.143089294433594,
    "critic_loss": 155.09010314941406,
    "ent_coef": 0.006448992528021336,
    "learning_rate": 0.001
  },
  {
    "episode": 318,
    "reward": -112.469049,
    "length": 144,
    "time": 14317.00579,
    "actor_loss": 23.34372901916504,
    "critic_loss": 136.28611755371094,
    "ent_coef": 0.006642486900091171,
    "learning_rate": 0.001
  },
  {
    "episode": 319,
    "reward": -91.050245,
    "length": 582,
    "time": 14397.079819,
    "actor_loss": 24.803020477294922,
    "critic_loss": 2.1532135009765625,
    "ent_coef": 0.007064072415232658,
    "learning_rate": 0.001
  },
  {
    "episode": 320,
    "reward": -179.091158,
    "length": 492,
    "time": 14463.787702,
    "actor_loss": 21.56027603149414,
    "critic_loss": 1.258811354637146,
    "ent_coef": 0.007643906399607658,
    "learning_rate": 0.001
  },
  {
    "episode": 321,
    "reward": -124.588313,
    "length": 304,
    "time": 14506.143181,
    "actor_loss": 21.746618270874023,
    "critic_loss": 0.9838364124298096,
    "ent_coef": 0.005967125296592712,
    "learning_rate": 0.001
  },
  {
    "episode": 322,
    "reward": -114.616011,
    "length": 198,
    "time": 14537.491458,
    "actor_loss": 22.827035903930664,
    "critic_loss": 8.053108215332031,
    "ent_coef": 0.005307916551828384,
    "learning_rate": 0.001
  },
  {
    "episode": 323,
    "reward": -119.690557,
    "length": 323,
    "time": 14581.024577,
    "actor_loss": 24.751827239990234,
    "critic_loss": 2.391170024871826,
    "ent_coef": 0.005529541056603193,
    "learning_rate": 0.001
  },
  {
    "episode": 324,
    "reward": -120.479353,
    "length": 20,
    "time": 14589.081915,
    "actor_loss": 23.983320236206055,
    "critic_loss": 66.92826080322266,
    "ent_coef": 0.005459717940539122,
    "learning_rate": 0.001
  },
  {
    "episode": 325,
    "reward": -122.223471,
    "length": 341,
    "time": 14637.081643,
    "actor_loss": 23.314199447631836,
    "critic_loss": 1.5026638507843018,
    "ent_coef": 0.006022830493748188,
    "learning_rate": 0.001
  },
  {
    "episode": 326,
    "reward": -123.03424,
    "length": 358,
    "time": 14688.763731,
    "actor_loss": 21.612585067749023,
    "critic_loss": 68.04730224609375,
    "ent_coef": 0.007696129381656647,
    "learning_rate": 0.001
  },
  {
    "episode": 327,
    "reward": -53.503995,
    "length": 608,
    "time": 14768.78001,
    "actor_loss": 24.691240310668945,
    "critic_loss": 13.134000778198242,
    "ent_coef": 0.007522625382989645,
    "learning_rate": 0.001
  },
  {
    "episode": 328,
    "reward": -139.281605,
    "length": 175,
    "time": 14793.72663,
    "actor_loss": 23.01198959350586,
    "critic_loss": 0.810326099395752,
    "ent_coef": 0.007110645528882742,
    "learning_rate": 0.001
  },
  {
    "episode": 329,
    "reward": -163.746666,
    "length": 307,
    "time": 14836.504286,
    "actor_loss": 22.883167266845703,
    "critic_loss": 0.8134885430335999,
    "ent_coef": 0.008619321510195732,
    "learning_rate": 0.001
  },
  {
    "episode": 330,
    "reward": -52.78732,
    "length": 598,
    "time": 14916.57347,
    "actor_loss": 19.55258560180664,
    "critic_loss": 18.166770935058594,
    "ent_coef": 0.00853398721665144,
    "learning_rate": 0.001
  },
  {
    "episode": 331,
    "reward": -160.612351,
    "length": 448,
    "time": 14978.548037,
    "actor_loss": 25.401029586791992,
    "critic_loss": 0.5945469737052917,
    "ent_coef": 0.007333811838179827,
    "learning_rate": 0.001
  },
  {
    "episode": 332,
    "reward": -49.276657,
    "length": 578,
    "time": 15058.631084,
    "actor_loss": 22.402828216552734,
    "critic_loss": 3.4529032707214355,
    "ent_coef": 0.0075740087777376175,
    "learning_rate": 0.001
  },
  {
    "episode": 333,
    "reward": -115.685768,
    "length": 581,
    "time": 15138.685473,
    "actor_loss": 21.807144165039062,
    "critic_loss": 2.7666664123535156,
    "ent_coef": 0.008166386745870113,
    "learning_rate": 0.001
  },
  {
    "episode": 334,
    "reward": -123.05545,
    "length": 108,
    "time": 15157.285834,
    "actor_loss": 19.244522094726562,
    "critic_loss": 6.572394371032715,
    "ent_coef": 0.009263851679861546,
    "learning_rate": 0.001
  },
  {
    "episode": 335,
    "reward": -71.452679,
    "length": 575,
    "time": 15237.409939,
    "actor_loss": 23.044273376464844,
    "critic_loss": 4.7307515144348145,
    "ent_coef": 0.008666993118822575,
    "learning_rate": 0.001
  },
  {
    "episode": 336,
    "reward": -132.354533,
    "length": 242,
    "time": 15273.107885,
    "actor_loss": 21.604707717895508,
    "critic_loss": 3.788226842880249,
    "ent_coef": 0.008966442197561264,
    "learning_rate": 0.001
  },
  {
    "episode": 337,
    "reward": -160.72734,
    "length": 371,
    "time": 15325.890184,
    "actor_loss": 20.52923011779785,
    "critic_loss": 23.037683486938477,
    "ent_coef": 0.008905429393053055,
    "learning_rate": 0.001
  },
  {
    "episode": 338,
    "reward": -106.93388,
    "length": 155,
    "time": 15352.05909,
    "actor_loss": 23.879566192626953,
    "critic_loss": 9.081253051757812,
    "ent_coef": 0.0076538193970918655,
    "learning_rate": 0.001
  },
  {
    "episode": 339,
    "reward": -123.994013,
    "length": 195,
    "time": 15382.156124,
    "actor_loss": 22.082706451416016,
    "critic_loss": 6.826085090637207,
    "ent_coef": 0.007545340806245804,
    "learning_rate": 0.001
  },
  {
    "episode": 340,
    "reward": -99.138634,
    "length": 111,
    "time": 15399.541723,
    "actor_loss": 23.465599060058594,
    "critic_loss": 9.584617614746094,
    "ent_coef": 0.007262575905770063,
    "learning_rate": 0.001
  },
  {
    "episode": 341,
    "reward": -213.242574,
    "length": 478,
    "time": 15465.731984,
    "actor_loss": 23.596561431884766,
    "critic_loss": 1.3388404846191406,
    "ent_coef": 0.006636313162744045,
    "learning_rate": 0.001
  },
  {
    "episode": 342,
    "reward": -85.461136,
    "length": 593,
    "time": 15545.831908,
    "actor_loss": 22.884613037109375,
    "critic_loss": 0.6480594873428345,
    "ent_coef": 0.007408257573843002,
    "learning_rate": 0.001
  },
  {
    "episode": 343,
    "reward": 110.978401,
    "length": 93,
    "time": 15561.392397,
    "actor_loss": 23.37124252319336,
    "critic_loss": 121.58712768554688,
    "ent_coef": 0.007223145570605993,
    "learning_rate": 0.001
  },
  {
    "episode": 344,
    "reward": -126.751925,
    "length": 614,
    "time": 15641.522267,
    "actor_loss": 22.20553970336914,
    "critic_loss": 9.541060447692871,
    "ent_coef": 0.0066906241700053215,
    "learning_rate": 0.001
  },
  {
    "episode": 345,
    "reward": -120.022025,
    "length": 1,
    "time": 15650.427522,
    "actor_loss": 27.188236236572266,
    "critic_loss": 2.3650379180908203,
    "ent_coef": 0.006683797109872103,
    "learning_rate": 0.001
  },
  {
    "episode": 346,
    "reward": -79.572153,
    "length": 606,
    "time": 15730.461226,
    "actor_loss": 21.974559783935547,
    "critic_loss": 2.806530237197876,
    "ent_coef": 0.005755120888352394,
    "learning_rate": 0.001
  },
  {
    "episode": 347,
    "reward": -121.707804,
    "length": 197,
    "time": 15758.179026,
    "actor_loss": 22.67591667175293,
    "critic_loss": 3.898158550262451,
    "ent_coef": 0.0055740210227668285,
    "learning_rate": 0.001
  },
  {
    "episode": 348,
    "reward": -120.638535,
    "length": 21,
    "time": 15766.190915,
    "actor_loss": 22.39409637451172,
    "critic_loss": 3.1176724433898926,
    "ent_coef": 0.00566856050863862,
    "learning_rate": 0.001
  },
  {
    "episode": 349,
    "reward": -104.871785,
    "length": 117,
    "time": 15784.243491,
    "actor_loss": 24.583297729492188,
    "critic_loss": 11.439485549926758,
    "ent_coef": 0.006259717047214508,
    "learning_rate": 0.001
  },
  {
    "episode": 350,
    "reward": -131.085622,
    "length": 616,
    "time": 15864.30121,
    "actor_loss": 21.9468994140625,
    "critic_loss": 4.371395111083984,
    "ent_coef": 0.005828443914651871,
    "learning_rate": 0.001
  },
  {
    "episode": 351,
    "reward": -131.276902,
    "length": 352,
    "time": 15913.223004,
    "actor_loss": 22.89689826965332,
    "critic_loss": 0.3399204909801483,
    "ent_coef": 0.006369790993630886,
    "learning_rate": 0.001
  },
  {
    "episode": 352,
    "reward": -50.122684,
    "length": 605,
    "time": 15993.239339,
    "actor_loss": 23.25609016418457,
    "critic_loss": 14.596233367919922,
    "ent_coef": 0.00656985305249691,
    "learning_rate": 0.001
  },
  {
    "episode": 353,
    "reward": -146.803513,
    "length": 368,
    "time": 16043.153696,
    "actor_loss": 21.702465057373047,
    "critic_loss": 19.12103271484375,
    "ent_coef": 0.006237543188035488,
    "learning_rate": 0.001
  },
  {
    "episode": 354,
    "reward": -144.999163,
    "length": 419,
    "time": 16098.896974,
    "actor_loss": 22.998882293701172,
    "critic_loss": 4.259570121765137,
    "ent_coef": 0.007523496635258198,
    "learning_rate": 0.001
  },
  {
    "episode": 355,
    "reward": -129.629432,
    "length": 323,
    "time": 16143.266726,
    "actor_loss": 25.397085189819336,
    "critic_loss": 1.0951528549194336,
    "ent_coef": 0.007795203942805529,
    "learning_rate": 0.001
  },
  {
    "episode": 356,
    "reward": -125.299457,
    "length": 165,
    "time": 16166.675027,
    "actor_loss": 21.922536849975586,
    "critic_loss": 4.055237293243408,
    "ent_coef": 0.007425891701132059,
    "learning_rate": 0.001
  },
  {
    "episode": 357,
    "reward": -215.812476,
    "length": 499,
    "time": 16234.032384,
    "actor_loss": 23.071189880371094,
    "critic_loss": 1.2906121015548706,
    "ent_coef": 0.006230486091226339,
    "learning_rate": 0.001
  },
  {
    "episode": 358,
    "reward": -110.603904,
    "length": 82,
    "time": 16247.1904,
    "actor_loss": 22.83832550048828,
    "critic_loss": 4.668796062469482,
    "ent_coef": 0.006661797408014536,
    "learning_rate": 0.001
  },
  {
    "episode": 359,
    "reward": -109.32596,
    "length": 189,
    "time": 16275.786059,
    "actor_loss": 22.616615295410156,
    "critic_loss": 170.8914031982422,
    "ent_coef": 0.007783099543303251,
    "learning_rate": 0.001
  },
  {
    "episode": 360,
    "reward": -140.236293,
    "length": 387,
    "time": 16328.670734,
    "actor_loss": 21.40121078491211,
    "critic_loss": 4.374695777893066,
    "ent_coef": 0.006513816770166159,
    "learning_rate": 0.001
  },
  {
    "episode": 361,
    "reward": -138.207693,
    "length": 357,
    "time": 16376.146596,
    "actor_loss": 19.321895599365234,
    "critic_loss": 8.755626678466797,
    "ent_coef": 0.006515922956168652,
    "learning_rate": 0.001
  },
  {
    "episode": 362,
    "reward": -134.86076,
    "length": 571,
    "time": 16456.153788,
    "actor_loss": 22.352710723876953,
    "critic_loss": 2.7951982021331787,
    "ent_coef": 0.004636564292013645,
    "learning_rate": 0.001
  },
  {
    "episode": 363,
    "reward": -55.729161,
    "length": 610,
    "time": 16536.259489,
    "actor_loss": 24.926944732666016,
    "critic_loss": 206.3372802734375,
    "ent_coef": 0.005032604560256004,
    "learning_rate": 0.001
  },
  {
    "episode": 364,
    "reward": 62.125521,
    "length": 355,
    "time": 16583.842124,
    "actor_loss": 23.177608489990234,
    "critic_loss": 117.25186157226562,
    "ent_coef": 0.007501072250306606,
    "learning_rate": 0.001
  },
  {
    "episode": 365,
    "reward": -127.998855,
    "length": 134,
    "time": 16603.28367,
    "actor_loss": 20.123924255371094,
    "critic_loss": 41.484642028808594,
    "ent_coef": 0.00862037856131792,
    "learning_rate": 0.001
  },
  {
    "episode": 366,
    "reward": 125.234934,
    "length": 72,
    "time": 16615.499396,
    "actor_loss": 22.248367309570312,
    "critic_loss": 3.0637717247009277,
    "ent_coef": 0.008334084413945675,
    "learning_rate": 0.001
  },
  {
    "episode": 367,
    "reward": -136.383012,
    "length": 143,
    "time": 16639.41265,
    "actor_loss": 22.336524963378906,
    "critic_loss": 2.4604339599609375,
    "ent_coef": 0.008156035095453262,
    "learning_rate": 0.001
  },
  {
    "episode": 368,
    "reward": -134.1075,
    "length": 276,
    "time": 16677.683288,
    "actor_loss": 22.64844512939453,
    "critic_loss": 1.6346521377563477,
    "ent_coef": 0.00725912768393755,
    "learning_rate": 0.001
  },
  {
    "episode": 369,
    "reward": 110.888664,
    "length": 264,
    "time": 16714.475676,
    "actor_loss": 23.26267433166504,
    "critic_loss": 113.69538116455078,
    "ent_coef": 0.006966665852814913,
    "learning_rate": 0.001
  },
  {
    "episode": 370,
    "reward": -85.702856,
    "length": 603,
    "time": 16794.516277,
    "actor_loss": 22.981246948242188,
    "critic_loss": 67.17062377929688,
    "ent_coef": 0.006783653981983662,
    "learning_rate": 0.001
  },
  {
    "episode": 371,
    "reward": -119.946326,
    "length": 154,
    "time": 16816.968035,
    "actor_loss": 22.993209838867188,
    "critic_loss": 2.7558040618896484,
    "ent_coef": 0.007352075539529324,
    "learning_rate": 0.001
  },
  {
    "episode": 372,
    "reward": -122.323973,
    "length": 214,
    "time": 16849.077299,
    "actor_loss": 22.43596076965332,
    "critic_loss": 5.654047012329102,
    "ent_coef": 0.007273329421877861,
    "learning_rate": 0.001
  },
  {
    "episode": 373,
    "reward": -39.644345,
    "length": 594,
    "time": 16929.225,
    "actor_loss": 23.402587890625,
    "critic_loss": 2.097451686859131,
    "ent_coef": 0.008228552527725697,
    "learning_rate": 0.001
  },
  {
    "episode": 374,
    "reward": -123.891233,
    "length": 200,
    "time": 16961.734209,
    "actor_loss": 25.000499725341797,
    "critic_loss": 2.921135425567627,
    "ent_coef": 0.00791996531188488,
    "learning_rate": 0.001
  },
  {
    "episode": 375,
    "reward": -201.320098,
    "length": 380,
    "time": 17021.932496,
    "actor_loss": 21.986106872558594,
    "critic_loss": 0.5153385400772095,
    "ent_coef": 0.008134867064654827,
    "learning_rate": 0.001
  },
  {
    "episode": 376,
    "reward": -121.360203,
    "length": 134,
    "time": 17044.715676,
    "actor_loss": 20.899763107299805,
    "critic_loss": 23.223949432373047,
    "ent_coef": 0.008211016654968262,
    "learning_rate": 0.001
  },
  {
    "episode": 377,
    "reward": -93.498628,
    "length": 584,
    "time": 17124.783627,
    "actor_loss": 21.722536087036133,
    "critic_loss": 1.7782783508300781,
    "ent_coef": 0.007076408714056015,
    "learning_rate": 0.001
  },
  {
    "episode": 378,
    "reward": -108.504405,
    "length": 576,
    "time": 17204.835686,
    "actor_loss": 22.935562133789062,
    "critic_loss": 75.64723205566406,
    "ent_coef": 0.007401125505566597,
    "learning_rate": 0.001
  },
  {
    "episode": 379,
    "reward": -175.187928,
    "length": 351,
    "time": 17254.487537,
    "actor_loss": 24.36160659790039,
    "critic_loss": 1.7110010385513306,
    "ent_coef": 0.007782116066664457,
    "learning_rate": 0.001
  },
  {
    "episode": 380,
    "reward": -134.514742,
    "length": 437,
    "time": 17313.473266,
    "actor_loss": 22.76031494140625,
    "critic_loss": 75.42041778564453,
    "ent_coef": 0.006336945109069347,
    "learning_rate": 0.001
  },
  {
    "episode": 381,
    "reward": -120.521811,
    "length": 23,
    "time": 17321.508429,
    "actor_loss": 22.183860778808594,
    "critic_loss": 2.4481358528137207,
    "ent_coef": 0.0062239947728812695,
    "learning_rate": 0.001
  },
  {
    "episode": 382,
    "reward": -195.690535,
    "length": 517,
    "time": 17390.124798,
    "actor_loss": 22.983699798583984,
    "critic_loss": 2.8838515281677246,
    "ent_coef": 0.006518455687910318,
    "learning_rate": 0.001
  },
  {
    "episode": 383,
    "reward": -133.128091,
    "length": 158,
    "time": 17415.45329,
    "actor_loss": 22.387706756591797,
    "critic_loss": 4.922524452209473,
    "ent_coef": 0.006794482469558716,
    "learning_rate": 0.001
  },
  {
    "episode": 384,
    "reward": -91.389439,
    "length": 600,
    "time": 17495.497949,
    "actor_loss": 21.80940818786621,
    "critic_loss": 0.9775301814079285,
    "ent_coef": 0.006844628602266312,
    "learning_rate": 0.001
  },
  {
    "episode": 385,
    "reward": -122.331428,
    "length": 604,
    "time": 17575.501403,
    "actor_loss": 23.361173629760742,
    "critic_loss": 1.675431489944458,
    "ent_coef": 0.005512066651135683,
    "learning_rate": 0.001
  },
  {
    "episode": 386,
    "reward": -146.893588,
    "length": 287,
    "time": 17615.517243,
    "actor_loss": 23.376991271972656,
    "critic_loss": 65.51646423339844,
    "ent_coef": 0.005047967191785574,
    "learning_rate": 0.001
  },
  {
    "episode": 387,
    "reward": -41.360389,
    "length": 603,
    "time": 17695.612224,
    "actor_loss": 22.258861541748047,
    "critic_loss": 20.942760467529297,
    "ent_coef": 0.006877931300550699,
    "learning_rate": 0.001
  },
  {
    "episode": 388,
    "reward": -121.211463,
    "length": 40,
    "time": 17703.710219,
    "actor_loss": 21.148677825927734,
    "critic_loss": 7.527459144592285,
    "ent_coef": 0.007276326883584261,
    "learning_rate": 0.001
  },
  {
    "episode": 389,
    "reward": -215.491504,
    "length": 515,
    "time": 17772.585512,
    "actor_loss": 20.366539001464844,
    "critic_loss": 3.7921104431152344,
    "ent_coef": 0.009187741205096245,
    "learning_rate": 0.001
  },
  {
    "episode": 390,
    "reward": -188.60086,
    "length": 367,
    "time": 17822.289038,
    "actor_loss": 22.6546630859375,
    "critic_loss": 4.402507305145264,
    "ent_coef": 0.007497400511056185,
    "learning_rate": 0.001
  },
  {
    "episode": 391,
    "reward": -116.394904,
    "length": 169,
    "time": 17848.024462,
    "actor_loss": 23.236801147460938,
    "critic_loss": 68.54464721679688,
    "ent_coef": 0.007259916979819536,
    "learning_rate": 0.001
  },
  {
    "episode": 392,
    "reward": -69.221366,
    "length": 603,
    "time": 17928.124315,
    "actor_loss": 24.20895004272461,
    "critic_loss": 2.634291410446167,
    "ent_coef": 0.008612132631242275,
    "learning_rate": 0.001
  },
  {
    "episode": 393,
    "reward": 98.777171,
    "length": 91,
    "time": 17943.305276,
    "actor_loss": 20.886943817138672,
    "critic_loss": 267.57513427734375,
    "ent_coef": 0.008302554488182068,
    "learning_rate": 0.001
  },
  {
    "episode": 394,
    "reward": -175.450836,
    "length": 285,
    "time": 17982.395265,
    "actor_loss": 18.7913818359375,
    "critic_loss": 1.2689423561096191,
    "ent_coef": 0.00859982892870903,
    "learning_rate": 0.001
  },
  {
    "episode": 395,
    "reward": 74.153175,
    "length": 345,
    "time": 18030.503141,
    "actor_loss": 23.08892059326172,
    "critic_loss": 46.503299713134766,
    "ent_coef": 0.009911817498505116,
    "learning_rate": 0.001
  },
  {
    "episode": 396,
    "reward": -85.442091,
    "length": 602,
    "time": 18110.514071,
    "actor_loss": 20.86391830444336,
    "critic_loss": 2.0143117904663086,
    "ent_coef": 0.00876394473016262,
    "learning_rate": 0.001
  },
  {
    "episode": 397,
    "reward": -121.689078,
    "length": 115,
    "time": 18130.555093,
    "actor_loss": 19.004928588867188,
    "critic_loss": 100.17719268798828,
    "ent_coef": 0.008410491049289703,
    "learning_rate": 0.001
  },
  {
    "episode": 398,
    "reward": -115.968429,
    "length": 111,
    "time": 18147.439979,
    "actor_loss": 21.432722091674805,
    "critic_loss": 56.61406707763672,
    "ent_coef": 0.008688452653586864,
    "learning_rate": 0.001
  },
  {
    "episode": 399,
    "reward": -56.970731,
    "length": 611,
    "time": 18227.529438,
    "actor_loss": 20.21732521057129,
    "critic_loss": 3.9314017295837402,
    "ent_coef": 0.007193208206444979,
    "learning_rate": 0.001
  },
  {
    "episode": 400,
    "reward": -97.01868,
    "length": 606,
    "time": 18307.616722,
    "actor_loss": 24.06490135192871,
    "critic_loss": 95.9561767578125,
    "ent_coef": 0.009657252579927444,
    "learning_rate": 0.001
  },
  {
    "episode": 401,
    "reward": -121.656399,
    "length": 237,
    "time": 18343.03267,
    "actor_loss": 23.323097229003906,
    "critic_loss": 80.11868286132812,
    "ent_coef": 0.008491476066410542,
    "learning_rate": 0.001
  },
  {
    "episode": 402,
    "reward": -104.979415,
    "length": 580,
    "time": 18423.072586,
    "actor_loss": 23.097171783447266,
    "critic_loss": 80.25773620605469,
    "ent_coef": 0.008745638653635979,
    "learning_rate": 0.001
  },
  {
    "episode": 403,
    "reward": -109.965521,
    "length": 600,
    "time": 18503.146344,
    "actor_loss": 21.889141082763672,
    "critic_loss": 2.3549742698669434,
    "ent_coef": 0.010689043439924717,
    "learning_rate": 0.001
  },
  {
    "episode": 404,
    "reward": -113.925906,
    "length": 85,
    "time": 18517.390212,
    "actor_loss": 22.96431541442871,
    "critic_loss": 4.347804069519043,
    "ent_coef": 0.010166852734982967,
    "learning_rate": 0.001
  },
  {
    "episode": 405,
    "reward": -107.06693,
    "length": 611,
    "time": 18597.413443,
    "actor_loss": 21.23328399658203,
    "critic_loss": 131.99172973632812,
    "ent_coef": 0.010571965016424656,
    "learning_rate": 0.001
  },
  {
    "episode": 406,
    "reward": -77.590948,
    "length": 581,
    "time": 18677.430713,
    "actor_loss": 22.873401641845703,
    "critic_loss": 5.727860450744629,
    "ent_coef": 0.011069524101912975,
    "learning_rate": 0.001
  },
  {
    "episode": 407,
    "reward": -202.556235,
    "length": 509,
    "time": 18745.906416,
    "actor_loss": 20.228120803833008,
    "critic_loss": 12.171786308288574,
    "ent_coef": 0.008172677829861641,
    "learning_rate": 0.001
  },
  {
    "episode": 408,
    "reward": -105.763122,
    "length": 115,
    "time": 18763.355394,
    "actor_loss": 19.992033004760742,
    "critic_loss": 3.6913399696350098,
    "ent_coef": 0.008456866256892681,
    "learning_rate": 0.001
  },
  {
    "episode": 409,
    "reward": -219.053938,
    "length": 488,
    "time": 18828.305091,
    "actor_loss": 24.271411895751953,
    "critic_loss": 3.675590991973877,
    "ent_coef": 0.009964680299162865,
    "learning_rate": 0.001
  },
  {
    "episode": 410,
    "reward": -36.662477,
    "length": 579,
    "time": 18908.319578,
    "actor_loss": 23.153789520263672,
    "critic_loss": 29.949932098388672,
    "ent_coef": 0.00836056936532259,
    "learning_rate": 0.001
  },
  {
    "episode": 411,
    "reward": -181.903653,
    "length": 384,
    "time": 18960.097623,
    "actor_loss": 22.308727264404297,
    "critic_loss": 1.7466468811035156,
    "ent_coef": 0.012758318334817886,
    "learning_rate": 0.001
  },
  {
    "episode": 412,
    "reward": -119.941796,
    "length": 194,
    "time": 18988.311641,
    "actor_loss": 21.05986976623535,
    "critic_loss": 6.560730934143066,
    "ent_coef": 0.01264205202460289,
    "learning_rate": 0.001
  },
  {
    "episode": 413,
    "reward": -151.22205,
    "length": 274,
    "time": 19026.064842,
    "actor_loss": 22.86207389831543,
    "critic_loss": 1.7960491180419922,
    "ent_coef": 0.012018885463476181,
    "learning_rate": 0.001
  },
  {
    "episode": 414,
    "reward": -220.397706,
    "length": 589,
    "time": 19103.394621,
    "actor_loss": 21.281068801879883,
    "critic_loss": 4.42449951171875,
    "ent_coef": 0.010095890611410141,
    "learning_rate": 0.001
  },
  {
    "episode": 415,
    "reward": -249.110741,
    "length": 539,
    "time": 19176.810083,
    "actor_loss": 22.18086051940918,
    "critic_loss": 5.989032745361328,
    "ent_coef": 0.01043248362839222,
    "learning_rate": 0.001
  },
  {
    "episode": 416,
    "reward": -140.579285,
    "length": 252,
    "time": 19216.33584,
    "actor_loss": 22.152544021606445,
    "critic_loss": 1.1112382411956787,
    "ent_coef": 0.010267505422234535,
    "learning_rate": 0.001
  },
  {
    "episode": 417,
    "reward": -165.237915,
    "length": 261,
    "time": 19253.40602,
    "actor_loss": 24.514358520507812,
    "critic_loss": 91.18046569824219,
    "ent_coef": 0.00847659632563591,
    "learning_rate": 0.001
  },
  {
    "episode": 418,
    "reward": -270.887702,
    "length": 491,
    "time": 19325.483328,
    "actor_loss": 21.057750701904297,
    "critic_loss": 22.11181640625,
    "ent_coef": 0.0089267548173666,
    "learning_rate": 0.001
  },
  {
    "episode": 419,
    "reward": -134.790901,
    "length": 231,
    "time": 19360.358405,
    "actor_loss": 20.586013793945312,
    "critic_loss": 118.6043701171875,
    "ent_coef": 0.008016965351998806,
    "learning_rate": 0.001
  },
  {
    "episode": 420,
    "reward": -113.351741,
    "length": 147,
    "time": 19384.580335,
    "actor_loss": 22.183231353759766,
    "critic_loss": 6.1527180671691895,
    "ent_coef": 0.007099356967955828,
    "learning_rate": 0.001
  },
  {
    "episode": 421,
    "reward": -118.953524,
    "length": 168,
    "time": 19411.074624,
    "actor_loss": 20.709972381591797,
    "critic_loss": 3.5521721839904785,
    "ent_coef": 0.007242297288030386,
    "learning_rate": 0.001
  },
  {
    "episode": 422,
    "reward": -131.960578,
    "length": 138,
    "time": 19434.409186,
    "actor_loss": 20.171926498413086,
    "critic_loss": 2.10256290435791,
    "ent_coef": 0.007383427117019892,
    "learning_rate": 0.001
  },
  {
    "episode": 423,
    "reward": -134.264787,
    "length": 291,
    "time": 19477.087337,
    "actor_loss": 21.003459930419922,
    "critic_loss": 1.5778199434280396,
    "ent_coef": 0.008671346120536327,
    "learning_rate": 0.001
  },
  {
    "episode": 424,
    "reward": -77.342301,
    "length": 594,
    "time": 19557.13485,
    "actor_loss": 21.34361457824707,
    "critic_loss": 2.442582845687866,
    "ent_coef": 0.007968991994857788,
    "learning_rate": 0.001
  },
  {
    "episode": 425,
    "reward": -86.825469,
    "length": 586,
    "time": 19637.153287,
    "actor_loss": 22.821699142456055,
    "critic_loss": 2.1438984870910645,
    "ent_coef": 0.00809120200574398,
    "learning_rate": 0.001
  },
  {
    "episode": 426,
    "reward": -120.430895,
    "length": 16,
    "time": 19645.178369,
    "actor_loss": 24.462963104248047,
    "critic_loss": 1.7876780033111572,
    "ent_coef": 0.007906596176326275,
    "learning_rate": 0.001
  },
  {
    "episode": 427,
    "reward": -132.819571,
    "length": 219,
    "time": 19677.350909,
    "actor_loss": 19.734771728515625,
    "critic_loss": 11.321449279785156,
    "ent_coef": 0.007726394571363926,
    "learning_rate": 0.001
  },
  {
    "episode": 428,
    "reward": -107.526722,
    "length": 131,
    "time": 19697.840432,
    "actor_loss": 23.95012855529785,
    "critic_loss": 107.967529296875,
    "ent_coef": 0.008130907081067562,
    "learning_rate": 0.001
  },
  {
    "episode": 429,
    "reward": -126.62872,
    "length": 198,
    "time": 19727.585001,
    "actor_loss": 22.605487823486328,
    "critic_loss": 49.260318756103516,
    "ent_coef": 0.009686837904155254,
    "learning_rate": 0.001
  },
  {
    "episode": 430,
    "reward": -155.818026,
    "length": 596,
    "time": 19807.618623,
    "actor_loss": 21.64580535888672,
    "critic_loss": 80.51100158691406,
    "ent_coef": 0.00849385280162096,
    "learning_rate": 0.001
  },
  {
    "episode": 431,
    "reward": -192.707757,
    "length": 332,
    "time": 19853.337228,
    "actor_loss": 19.667306900024414,
    "critic_loss": 12.067849159240723,
    "ent_coef": 0.010545823723077774,
    "learning_rate": 0.001
  },
  {
    "episode": 432,
    "reward": -128.957704,
    "length": 181,
    "time": 19882.466104,
    "actor_loss": 22.517602920532227,
    "critic_loss": 2.6600003242492676,
    "ent_coef": 0.009266693145036697,
    "learning_rate": 0.001
  },
  {
    "episode": 433,
    "reward": -119.765132,
    "length": 608,
    "time": 19962.575195,
    "actor_loss": 22.582660675048828,
    "critic_loss": 10.599822998046875,
    "ent_coef": 0.011280984617769718,
    "learning_rate": 0.001
  },
  {
    "episode": 434,
    "reward": -168.577791,
    "length": 375,
    "time": 20012.380516,
    "actor_loss": 21.637414932250977,
    "critic_loss": 2.016603469848633,
    "ent_coef": 0.010235258378088474,
    "learning_rate": 0.001
  },
  {
    "episode": 435,
    "reward": -162.089367,
    "length": 390,
    "time": 20064.858352,
    "actor_loss": 18.747941970825195,
    "critic_loss": 12.24417781829834,
    "ent_coef": 0.009885904379189014,
    "learning_rate": 0.001
  },
  {
    "episode": 436,
    "reward": -139.65691,
    "length": 523,
    "time": 20134.729814,
    "actor_loss": 22.637550354003906,
    "critic_loss": 2.004476547241211,
    "ent_coef": 0.006629361771047115,
    "learning_rate": 0.001
  },
  {
    "episode": 437,
    "reward": -65.746761,
    "length": 591,
    "time": 20214.801091,
    "actor_loss": 20.253204345703125,
    "critic_loss": 3.585819721221924,
    "ent_coef": 0.00930760707706213,
    "learning_rate": 0.001
  },
  {
    "episode": 438,
    "reward": -114.878696,
    "length": 260,
    "time": 20253.642347,
    "actor_loss": 21.965238571166992,
    "critic_loss": 208.99301147460938,
    "ent_coef": 0.00923597626388073,
    "learning_rate": 0.001
  },
  {
    "episode": 439,
    "reward": -102.091636,
    "length": 595,
    "time": 20333.72177,
    "actor_loss": 21.634624481201172,
    "critic_loss": 113.45350646972656,
    "ent_coef": 0.008699065074324608,
    "learning_rate": 0.001
  },
  {
    "episode": 440,
    "reward": -214.574966,
    "length": 495,
    "time": 20402.593474,
    "actor_loss": 19.580245971679688,
    "critic_loss": 60.383426666259766,
    "ent_coef": 0.009940187446773052,
    "learning_rate": 0.001
  },
  {
    "episode": 441,
    "reward": 118.618465,
    "length": 186,
    "time": 20431.000198,
    "actor_loss": 22.141315460205078,
    "critic_loss": 1.3171054124832153,
    "ent_coef": 0.009135357104241848,
    "learning_rate": 0.001
  },
  {
    "episode": 442,
    "reward": -170.204778,
    "length": 357,
    "time": 20480.781937,
    "actor_loss": 23.102691650390625,
    "critic_loss": 150.58819580078125,
    "ent_coef": 0.007570610847324133,
    "learning_rate": 0.001
  },
  {
    "episode": 443,
    "reward": -120.243406,
    "length": 9,
    "time": 20488.877199,
    "actor_loss": 21.915645599365234,
    "critic_loss": 3.2749180793762207,
    "ent_coef": 0.007597650401294231,
    "learning_rate": 0.001
  },
  {
    "episode": 444,
    "reward": -164.028084,
    "length": 392,
    "time": 20542.861885,
    "actor_loss": 21.74512481689453,
    "critic_loss": 2.5412585735321045,
    "ent_coef": 0.007845422253012657,
    "learning_rate": 0.001
  },
  {
    "episode": 445,
    "reward": -151.675579,
    "length": 305,
    "time": 20585.592341,
    "actor_loss": 18.7539119720459,
    "critic_loss": 0.7254742383956909,
    "ent_coef": 0.007694231811910868,
    "learning_rate": 0.001
  },
  {
    "episode": 446,
    "reward": -137.422696,
    "length": 606,
    "time": 20665.642273,
    "actor_loss": 19.823322296142578,
    "critic_loss": 2.562690019607544,
    "ent_coef": 0.007137264125049114,
    "learning_rate": 0.001
  },
  {
    "episode": 447,
    "reward": -82.934834,
    "length": 602,
    "time": 20745.752385,
    "actor_loss": 21.820947647094727,
    "critic_loss": 0.3535994589328766,
    "ent_coef": 0.007848992012441158,
    "learning_rate": 0.001
  },
  {
    "episode": 448,
    "reward": -126.667844,
    "length": 280,
    "time": 20788.694201,
    "actor_loss": 21.514514923095703,
    "critic_loss": 5.084104537963867,
    "ent_coef": 0.00926271639764309,
    "learning_rate": 0.001
  },
  {
    "episode": 449,
    "reward": -70.391849,
    "length": 591,
    "time": 20868.77208,
    "actor_loss": 21.199199676513672,
    "critic_loss": 2.305788278579712,
    "ent_coef": 0.008273657411336899,
    "learning_rate": 0.001
  },
  {
    "episode": 450,
    "reward": -94.318012,
    "length": 603,
    "time": 20948.814439,
    "actor_loss": 20.87289810180664,
    "critic_loss": 29.538616180419922,
    "ent_coef": 0.008539771661162376,
    "learning_rate": 0.001
  },
  {
    "episode": 451,
    "reward": -119.8236,
    "length": 167,
    "time": 20973.713281,
    "actor_loss": 19.06052017211914,
    "critic_loss": 5.770158767700195,
    "ent_coef": 0.00934121198952198,
    "learning_rate": 0.001
  },
  {
    "episode": 452,
    "reward": -105.930848,
    "length": 226,
    "time": 21006.240974,
    "actor_loss": 19.61419677734375,
    "critic_loss": 1.6184601783752441,
    "ent_coef": 0.008104674518108368,
    "learning_rate": 0.001
  },
  {
    "episode": 453,
    "reward": -157.053875,
    "length": 525,
    "time": 21076.736526,
    "actor_loss": 20.926467895507812,
    "critic_loss": 3.8515143394470215,
    "ent_coef": 0.006830237340182066,
    "learning_rate": 0.001
  },
  {
    "episode": 454,
    "reward": -110.982289,
    "length": 77,
    "time": 21091.844368,
    "actor_loss": 21.803653717041016,
    "critic_loss": 1.5169312953948975,
    "ent_coef": 0.007353849709033966,
    "learning_rate": 0.001
  },
  {
    "episode": 455,
    "reward": -73.905476,
    "length": 580,
    "time": 21171.943355,
    "actor_loss": 21.52024269104004,
    "critic_loss": 5.4672393798828125,
    "ent_coef": 0.010203816927969456,
    "learning_rate": 0.001
  },
  {
    "episode": 456,
    "reward": -115.627976,
    "length": 142,
    "time": 21192.980079,
    "actor_loss": 21.79764747619629,
    "critic_loss": 3.7495224475860596,
    "ent_coef": 0.010603716596961021,
    "learning_rate": 0.001
  },
  {
    "episode": 457,
    "reward": -112.43346,
    "length": 134,
    "time": 21214.538576,
    "actor_loss": 20.7326717376709,
    "critic_loss": 6.685111045837402,
    "ent_coef": 0.01026794221252203,
    "learning_rate": 0.001
  },
  {
    "episode": 458,
    "reward": -97.889754,
    "length": 134,
    "time": 21235.327902,
    "actor_loss": 21.023727416992188,
    "critic_loss": 127.28977966308594,
    "ent_coef": 0.010724669322371483,
    "learning_rate": 0.001
  },
  {
    "episode": 459,
    "reward": 124.196922,
    "length": 72,
    "time": 21249.778928,
    "actor_loss": 20.776752471923828,
    "critic_loss": 4.464592933654785,
    "ent_coef": 0.01022760383784771,
    "learning_rate": 0.001
  },
  {
    "episode": 460,
    "reward": -167.554877,
    "length": 532,
    "time": 21321.608078,
    "actor_loss": 18.97871971130371,
    "critic_loss": 1.4008562564849854,
    "ent_coef": 0.00984028447419405,
    "learning_rate": 0.001
  },
  {
    "episode": 461,
    "reward": -138.142982,
    "length": 293,
    "time": 21362.669058,
    "actor_loss": 23.20929718017578,
    "critic_loss": 72.81275939941406,
    "ent_coef": 0.009281976148486137,
    "learning_rate": 0.001
  },
  {
    "episode": 462,
    "reward": -99.84229,
    "length": 103,
    "time": 21379.798276,
    "actor_loss": 22.734848022460938,
    "critic_loss": 56.476722717285156,
    "ent_coef": 0.009745919145643711,
    "learning_rate": 0.001
  },
  {
    "episode": 463,
    "reward": -121.425021,
    "length": 198,
    "time": 21408.363428,
    "actor_loss": 24.599910736083984,
    "critic_loss": 82.480712890625,
    "ent_coef": 0.010722403414547443,
    "learning_rate": 0.001
  },
  {
    "episode": 464,
    "reward": -124.563264,
    "length": 272,
    "time": 21449.141071,
    "actor_loss": 24.335567474365234,
    "critic_loss": 2.662076711654663,
    "ent_coef": 0.009814300574362278,
    "learning_rate": 0.001
  },
  {
    "episode": 465,
    "reward": -109.02757,
    "length": 145,
    "time": 21474.577352,
    "actor_loss": 20.589305877685547,
    "critic_loss": 4.81729793548584,
    "ent_coef": 0.010689298622310162,
    "learning_rate": 0.001
  },
  {
    "episode": 466,
    "reward": -105.82565,
    "length": 109,
    "time": 21492.394821,
    "actor_loss": 22.15437126159668,
    "critic_loss": 0.4352771043777466,
    "ent_coef": 0.010834211483597755,
    "learning_rate": 0.001
  },
  {
    "episode": 467,
    "reward": -113.430632,
    "length": 237,
    "time": 21527.437365,
    "actor_loss": 20.451072692871094,
    "critic_loss": 105.47935485839844,
    "ent_coef": 0.01004101987928152,
    "learning_rate": 0.001
  },
  {
    "episode": 468,
    "reward": -106.60609,
    "length": 103,
    "time": 21543.447067,
    "actor_loss": 22.19870376586914,
    "critic_loss": 2.6987483501434326,
    "ent_coef": 0.009508442133665085,
    "learning_rate": 0.001
  },
  {
    "episode": 469,
    "reward": 114.097867,
    "length": 365,
    "time": 21593.421603,
    "actor_loss": 24.05353546142578,
    "critic_loss": 80.6500244140625,
    "ent_coef": 0.009729542769491673,
    "learning_rate": 0.001
  },
  {
    "episode": 470,
    "reward": -155.168308,
    "length": 305,
    "time": 21639.278002,
    "actor_loss": 21.096250534057617,
    "critic_loss": 204.06375122070312,
    "ent_coef": 0.009455334395170212,
    "learning_rate": 0.001
  },
  {
    "episode": 471,
    "reward": -134.541618,
    "length": 199,
    "time": 21670.450449,
    "actor_loss": 21.928010940551758,
    "critic_loss": 1.2286410331726074,
    "ent_coef": 0.008809341117739677,
    "learning_rate": 0.001
  },
  {
    "episode": 472,
    "reward": -150.72176,
    "length": 498,
    "time": 21738.13685,
    "actor_loss": 21.107810974121094,
    "critic_loss": 2.9351439476013184,
    "ent_coef": 0.009218781255185604,
    "learning_rate": 0.001
  },
  {
    "episode": 473,
    "reward": -112.947885,
    "length": 141,
    "time": 21759.936552,
    "actor_loss": 19.82276153564453,
    "critic_loss": 3.7262372970581055,
    "ent_coef": 0.010876128450036049,
    "learning_rate": 0.001
  },
  {
    "episode": 474,
    "reward": -111.260736,
    "length": 173,
    "time": 21785.568503,
    "actor_loss": 22.281518936157227,
    "critic_loss": 7.487729072570801,
    "ent_coef": 0.010601582005620003,
    "learning_rate": 0.001
  },
  {
    "episode": 475,
    "reward": -116.270591,
    "length": 180,
    "time": 21812.725748,
    "actor_loss": 20.41378402709961,
    "critic_loss": 138.12939453125,
    "ent_coef": 0.010018365457654,
    "learning_rate": 0.001
  },
  {
    "episode": 476,
    "reward": -122.523892,
    "length": 224,
    "time": 21846.293988,
    "actor_loss": 21.839866638183594,
    "critic_loss": 1.6675872802734375,
    "ent_coef": 0.009415755048394203,
    "learning_rate": 0.001
  },
  {
    "episode": 477,
    "reward": -98.832084,
    "length": 83,
    "time": 21860.358525,
    "actor_loss": 19.034347534179688,
    "critic_loss": 1.1050240993499756,
    "ent_coef": 0.009019039571285248,
    "learning_rate": 0.001
  },
  {
    "episode": 478,
    "reward": -145.594486,
    "length": 214,
    "time": 21892.13394,
    "actor_loss": 21.869075775146484,
    "critic_loss": 10.165406227111816,
    "ent_coef": 0.008271380327641964,
    "learning_rate": 0.001
  },
  {
    "episode": 479,
    "reward": -99.520454,
    "length": 183,
    "time": 21918.051596,
    "actor_loss": 20.941314697265625,
    "critic_loss": 6.57380485534668,
    "ent_coef": 0.008260888047516346,
    "learning_rate": 0.001
  },
  {
    "episode": 480,
    "reward": -124.81611,
    "length": 292,
    "time": 21957.623091,
    "actor_loss": 22.39041519165039,
    "critic_loss": 0.8265800476074219,
    "ent_coef": 0.009443028829991817,
    "learning_rate": 0.001
  },
  {
    "episode": 481,
    "reward": -93.991152,
    "length": 103,
    "time": 21974.124333,
    "actor_loss": 22.225486755371094,
    "critic_loss": 187.43881225585938,
    "ent_coef": 0.010095770470798016,
    "learning_rate": 0.001
  },
  {
    "episode": 482,
    "reward": -118.022323,
    "length": 116,
    "time": 21993.645207,
    "actor_loss": 21.585065841674805,
    "critic_loss": 116.37742614746094,
    "ent_coef": 0.00893461611121893,
    "learning_rate": 0.001
  },
  {
    "episode": 483,
    "reward": -124.378877,
    "length": 188,
    "time": 22020.625914,
    "actor_loss": 20.31989288330078,
    "critic_loss": 0.6668152809143066,
    "ent_coef": 0.007462791632860899,
    "learning_rate": 0.001
  },
  {
    "episode": 484,
    "reward": -139.567135,
    "length": 209,
    "time": 22050.221747,
    "actor_loss": 22.631629943847656,
    "critic_loss": 32.06541442871094,
    "ent_coef": 0.007409462705254555,
    "learning_rate": 0.001
  },
  {
    "episode": 485,
    "reward": -126.766503,
    "length": 218,
    "time": 22081.776872,
    "actor_loss": 21.600303649902344,
    "critic_loss": 6.343963623046875,
    "ent_coef": 0.006622069515287876,
    "learning_rate": 0.001
  },
  {
    "episode": 486,
    "reward": -122.681366,
    "length": 141,
    "time": 22102.050245,
    "actor_loss": 21.069921493530273,
    "critic_loss": 3.7340247631073,
    "ent_coef": 0.007360069081187248,
    "learning_rate": 0.001
  },
  {
    "episode": 487,
    "reward": -154.516738,
    "length": 295,
    "time": 22144.839606,
    "actor_loss": 18.471412658691406,
    "critic_loss": 4.785201072692871,
    "ent_coef": 0.008661800064146519,
    "learning_rate": 0.001
  },
  {
    "episode": 488,
    "reward": -134.26902,
    "length": 272,
    "time": 22184.089405,
    "actor_loss": 19.331676483154297,
    "critic_loss": 0.6131325364112854,
    "ent_coef": 0.00802973285317421,
    "learning_rate": 0.001
  },
  {
    "episode": 489,
    "reward": -132.150149,
    "length": 160,
    "time": 22206.952215,
    "actor_loss": 21.352996826171875,
    "critic_loss": 2.5622012615203857,
    "ent_coef": 0.00887866597622633,
    "learning_rate": 0.001
  },
  {
    "episode": 490,
    "reward": -114.550313,
    "length": 91,
    "time": 22220.990696,
    "actor_loss": 20.37417984008789,
    "critic_loss": 1.9721519947052002,
    "ent_coef": 0.008764847181737423,
    "learning_rate": 0.001
  },
  {
    "episode": 491,
    "reward": -110.205143,
    "length": 187,
    "time": 22249.359629,
    "actor_loss": 21.545591354370117,
    "critic_loss": 2.4272546768188477,
    "ent_coef": 0.008210140280425549,
    "learning_rate": 0.001
  },
  {
    "episode": 492,
    "reward": -42.316868,
    "length": 600,
    "time": 22329.415105,
    "actor_loss": 21.915027618408203,
    "critic_loss": 3.3215246200561523,
    "ent_coef": 0.012778392061591148,
    "learning_rate": 0.001
  },
  {
    "episode": 493,
    "reward": -173.443584,
    "length": 489,
    "time": 22394.610807,
    "actor_loss": 21.541959762573242,
    "critic_loss": 15.060272216796875,
    "ent_coef": 0.009178374893963337,
    "learning_rate": 0.001
  },
  {
    "episode": 494,
    "reward": -103.180348,
    "length": 173,
    "time": 22419.298271,
    "actor_loss": 20.467668533325195,
    "critic_loss": 0.6019219756126404,
    "ent_coef": 0.00958174280822277,
    "learning_rate": 0.001
  },
  {
    "episode": 495,
    "reward": -141.197073,
    "length": 113,
    "time": 22436.455316,
    "actor_loss": 21.85822868347168,
    "critic_loss": 0.6044456958770752,
    "ent_coef": 0.009591890498995781,
    "learning_rate": 0.001
  },
  {
    "episode": 496,
    "reward": -122.693274,
    "length": 177,
    "time": 22463.02676,
    "actor_loss": 20.7415714263916,
    "critic_loss": 5.509516716003418,
    "ent_coef": 0.009827843867242336,
    "learning_rate": 0.001
  },
  {
    "episode": 497,
    "reward": -120.177549,
    "length": 135,
    "time": 22484.218689,
    "actor_loss": 21.782346725463867,
    "critic_loss": 3.076627731323242,
    "ent_coef": 0.009938462637364864,
    "learning_rate": 0.001
  },
  {
    "episode": 498,
    "reward": -67.01287,
    "length": 611,
    "time": 22564.269579,
    "actor_loss": 21.59432601928711,
    "critic_loss": 15.430492401123047,
    "ent_coef": 0.010708106681704521,
    "learning_rate": 0.001
  },
  {
    "episode": 499,
    "reward": -156.424512,
    "length": 274,
    "time": 22604.372144,
    "actor_loss": 20.25292205810547,
    "critic_loss": 6.897261619567871,
    "ent_coef": 0.009453450329601765,
    "learning_rate": 0.001
  },
  {
    "episode": 500,
    "reward": -135.254057,
    "length": 355,
    "time": 22656.328412,
    "actor_loss": 18.996171951293945,
    "critic_loss": 25.21635627746582,
    "ent_coef": 0.008723144419491291,
    "learning_rate": 0.001
  },
  {
    "episode": 501,
    "reward": -147.446958,
    "length": 524,
    "time": 22728.332378,
    "actor_loss": 20.434303283691406,
    "critic_loss": 3.7760210037231445,
    "ent_coef": 0.011164112947881222,
    "learning_rate": 0.001
  },
  {
    "episode": 502,
    "reward": -167.94716,
    "length": 449,
    "time": 22787.691742,
    "actor_loss": 21.644956588745117,
    "critic_loss": 1.7209628820419312,
    "ent_coef": 0.009479694068431854,
    "learning_rate": 0.001
  },
  {
    "episode": 503,
    "reward": -76.7961,
    "length": 615,
    "time": 22867.727785,
    "actor_loss": 23.076736450195312,
    "critic_loss": 47.125431060791016,
    "ent_coef": 0.010691259987652302,
    "learning_rate": 0.001
  },
  {
    "episode": 504,
    "reward": -126.147391,
    "length": 600,
    "time": 22947.781739,
    "actor_loss": 20.210899353027344,
    "critic_loss": 2.359689712524414,
    "ent_coef": 0.009822582826018333,
    "learning_rate": 0.001
  },
  {
    "episode": 505,
    "reward": -195.205922,
    "length": 401,
    "time": 23001.887983,
    "actor_loss": 22.669010162353516,
    "critic_loss": 11.842447280883789,
    "ent_coef": 0.010673915967345238,
    "learning_rate": 0.001
  },
  {
    "episode": 506,
    "reward": -90.852199,
    "length": 606,
    "time": 23081.98204,
    "actor_loss": 21.927860260009766,
    "critic_loss": 1.4285593032836914,
    "ent_coef": 0.008864430710673332,
    "learning_rate": 0.001
  },
  {
    "episode": 507,
    "reward": -158.087761,
    "length": 332,
    "time": 23127.930763,
    "actor_loss": 23.578163146972656,
    "critic_loss": 177.359375,
    "ent_coef": 0.010666711255908012,
    "learning_rate": 0.001
  },
  {
    "episode": 508,
    "reward": -146.076479,
    "length": 327,
    "time": 23173.602505,
    "actor_loss": 20.88391876220703,
    "critic_loss": 0.6593899130821228,
    "ent_coef": 0.010057964362204075,
    "learning_rate": 0.001
  },
  {
    "episode": 509,
    "reward": -120.101579,
    "length": 228,
    "time": 23205.386193,
    "actor_loss": 22.6876277923584,
    "critic_loss": 2.0581631660461426,
    "ent_coef": 0.009799196384847164,
    "learning_rate": 0.001
  },
  {
    "episode": 510,
    "reward": -161.82996,
    "length": 341,
    "time": 23252.547013,
    "actor_loss": 20.52271270751953,
    "critic_loss": 2.323085308074951,
    "ent_coef": 0.007093255873769522,
    "learning_rate": 0.001
  },
  {
    "episode": 511,
    "reward": -271.485248,
    "length": 546,
    "time": 23326.197731,
    "actor_loss": 21.282546997070312,
    "critic_loss": 0.5064033269882202,
    "ent_coef": 0.008225551806390285,
    "learning_rate": 0.001
  },
  {
    "episode": 512,
    "reward": 122.581193,
    "length": 32,
    "time": 23333.825116,
    "actor_loss": 22.129127502441406,
    "critic_loss": 101.35591125488281,
    "ent_coef": 0.008202802389860153,
    "learning_rate": 0.001
  },
  {
    "episode": 513,
    "reward": -202.143505,
    "length": 519,
    "time": 23403.722718,
    "actor_loss": 21.605812072753906,
    "critic_loss": 3.2168984413146973,
    "ent_coef": 0.008077324368059635,
    "learning_rate": 0.001
  },
  {
    "episode": 514,
    "reward": -106.866067,
    "length": 80,
    "time": 23419.266092,
    "actor_loss": 24.526655197143555,
    "critic_loss": 33.2662239074707,
    "ent_coef": 0.007554203271865845,
    "learning_rate": 0.001
  },
  {
    "episode": 515,
    "reward": 125.528948,
    "length": 53,
    "time": 23431.069259,
    "actor_loss": 23.72317886352539,
    "critic_loss": 95.25780487060547,
    "ent_coef": 0.0073219421319663525,
    "learning_rate": 0.001
  },
  {
    "episode": 516,
    "reward": -132.097479,
    "length": 82,
    "time": 23445.952177,
    "actor_loss": 25.998138427734375,
    "critic_loss": 65.56048583984375,
    "ent_coef": 0.007137584500014782,
    "learning_rate": 0.001
  },
  {
    "episode": 517,
    "reward": -132.444027,
    "length": 232,
    "time": 23481.75783,
    "actor_loss": 21.775941848754883,
    "critic_loss": 2.5884320735931396,
    "ent_coef": 0.006867602001875639,
    "learning_rate": 0.001
  },
  {
    "episode": 518,
    "reward": -116.035716,
    "length": 575,
    "time": 23561.867381,
    "actor_loss": 23.215736389160156,
    "critic_loss": 0.9329885840415955,
    "ent_coef": 0.008498386479914188,
    "learning_rate": 0.001
  },
  {
    "episode": 519,
    "reward": -109.600524,
    "length": 136,
    "time": 23585.334963,
    "actor_loss": 22.063152313232422,
    "critic_loss": 1.41819429397583,
    "ent_coef": 0.008976456709206104,
    "learning_rate": 0.001
  },
  {
    "episode": 520,
    "reward": -178.039392,
    "length": 373,
    "time": 23636.662174,
    "actor_loss": 21.612157821655273,
    "critic_loss": 47.10203552246094,
    "ent_coef": 0.008883836679160595,
    "learning_rate": 0.001
  },
  {
    "episode": 521,
    "reward": -123.789904,
    "length": 179,
    "time": 23662.591134,
    "actor_loss": 22.51485252380371,
    "critic_loss": 75.79707336425781,
    "ent_coef": 0.00934554636478424,
    "learning_rate": 0.001
  },
  {
    "episode": 522,
    "reward": -91.795471,
    "length": 593,
    "time": 23742.62264,
    "actor_loss": 21.13815689086914,
    "critic_loss": 8.102294921875,
    "ent_coef": 0.009452588856220245,
    "learning_rate": 0.001
  },
  {
    "episode": 523,
    "reward": -112.199515,
    "length": 232,
    "time": 23776.200258,
    "actor_loss": 22.674827575683594,
    "critic_loss": 95.55628967285156,
    "ent_coef": 0.009095252491533756,
    "learning_rate": 0.001
  },
  {
    "episode": 524,
    "reward": -200.008168,
    "length": 541,
    "time": 23850.603532,
    "actor_loss": 22.593835830688477,
    "critic_loss": 0.5771791338920593,
    "ent_coef": 0.010615660808980465,
    "learning_rate": 0.001
  },
  {
    "episode": 525,
    "reward": -59.867862,
    "length": 555,
    "time": 23930.718011,
    "actor_loss": 22.97085952758789,
    "critic_loss": 129.1375732421875,
    "ent_coef": 0.011313198134303093,
    "learning_rate": 0.001
  },
  {
    "episode": 526,
    "reward": -134.84751,
    "length": 148,
    "time": 23953.785527,
    "actor_loss": 23.66353988647461,
    "critic_loss": 4.762009620666504,
    "ent_coef": 0.010295991785824299,
    "learning_rate": 0.001
  },
  {
    "episode": 527,
    "reward": -190.12998,
    "length": 551,
    "time": 24028.481534,
    "actor_loss": 19.066669464111328,
    "critic_loss": 89.3518295288086,
    "ent_coef": 0.011236683465540409,
    "learning_rate": 0.001
  },
  {
    "episode": 528,
    "reward": -186.157019,
    "length": 478,
    "time": 24095.029675,
    "actor_loss": 21.332138061523438,
    "critic_loss": 82.50457000732422,
    "ent_coef": 0.00877640675753355,
    "learning_rate": 0.001
  },
  {
    "episode": 529,
    "reward": 95.495887,
    "length": 344,
    "time": 24142.690443,
    "actor_loss": 22.859453201293945,
    "critic_loss": 1.636946439743042,
    "ent_coef": 0.006906114984303713,
    "learning_rate": 0.001
  },
  {
    "episode": 530,
    "reward": -154.876404,
    "length": 187,
    "time": 24171.675545,
    "actor_loss": 22.65287971496582,
    "critic_loss": 32.7311897277832,
    "ent_coef": 0.006806558929383755,
    "learning_rate": 0.001
  },
  {
    "episode": 531,
    "reward": -120.394816,
    "length": 13,
    "time": 24179.741119,
    "actor_loss": 21.85489273071289,
    "critic_loss": 102.72390747070312,
    "ent_coef": 0.006879334803670645,
    "learning_rate": 0.001
  },
  {
    "episode": 532,
    "reward": -159.221863,
    "length": 439,
    "time": 24240.207816,
    "actor_loss": 20.618019104003906,
    "critic_loss": 35.56061553955078,
    "ent_coef": 0.007886158302426338,
    "learning_rate": 0.001
  },
  {
    "episode": 533,
    "reward": 120.872535,
    "length": 65,
    "time": 24253.591465,
    "actor_loss": 22.8808650970459,
    "critic_loss": 4.861449718475342,
    "ent_coef": 0.007882632315158844,
    "learning_rate": 0.001
  },
  {
    "episode": 534,
    "reward": -164.378961,
    "length": 198,
    "time": 24282.774368,
    "actor_loss": 23.032737731933594,
    "critic_loss": 3.485138416290283,
    "ent_coef": 0.007758835796266794,
    "learning_rate": 0.001
  },
  {
    "episode": 535,
    "reward": -178.006145,
    "length": 378,
    "time": 24334.491681,
    "actor_loss": 18.695892333984375,
    "critic_loss": 0.4671410322189331,
    "ent_coef": 0.008633645251393318,
    "learning_rate": 0.001
  },
  {
    "episode": 536,
    "reward": -153.808534,
    "length": 433,
    "time": 24392.908649,
    "actor_loss": 22.15027618408203,
    "critic_loss": 3.6871817111968994,
    "ent_coef": 0.011106242425739765,
    "learning_rate": 0.001
  },
  {
    "episode": 537,
    "reward": -110.067457,
    "length": 165,
    "time": 24417.643151,
    "actor_loss": 23.970333099365234,
    "critic_loss": 4.932868957519531,
    "ent_coef": 0.011180958710610867,
    "learning_rate": 0.001
  },
  {
    "episode": 538,
    "reward": -103.653178,
    "length": 113,
    "time": 24435.272203,
    "actor_loss": 23.547103881835938,
    "critic_loss": 50.957550048828125,
    "ent_coef": 0.01077478937804699,
    "learning_rate": 0.001
  },
  {
    "episode": 539,
    "reward": -172.454159,
    "length": 432,
    "time": 24493.714927,
    "actor_loss": 22.80072593688965,
    "critic_loss": 2.836395025253296,
    "ent_coef": 0.010382261127233505,
    "learning_rate": 0.001
  },
  {
    "episode": 540,
    "reward": -139.981916,
    "length": 236,
    "time": 24529.850726,
    "actor_loss": 23.609207153320312,
    "critic_loss": 0.8311461806297302,
    "ent_coef": 0.009364647790789604,
    "learning_rate": 0.001
  },
  {
    "episode": 541,
    "reward": -111.529291,
    "length": 89,
    "time": 24545.838444,
    "actor_loss": 22.810827255249023,
    "critic_loss": 7.474721431732178,
    "ent_coef": 0.009433663450181484,
    "learning_rate": 0.001
  },
  {
    "episode": 542,
    "reward": -153.402723,
    "length": 253,
    "time": 24584.021015,
    "actor_loss": 24.813812255859375,
    "critic_loss": 39.4821891784668,
    "ent_coef": 0.010536651127040386,
    "learning_rate": 0.001
  },
  {
    "episode": 543,
    "reward": -118.065395,
    "length": 174,
    "time": 24610.190661,
    "actor_loss": 21.288564682006836,
    "critic_loss": 209.6564178466797,
    "ent_coef": 0.014151102863252163,
    "learning_rate": 0.001
  },
  {
    "episode": 544,
    "reward": -145.925818,
    "length": 166,
    "time": 24637.536832,
    "actor_loss": 22.21271324157715,
    "critic_loss": 9.215377807617188,
    "ent_coef": 0.015459577552974224,
    "learning_rate": 0.001
  },
  {
    "episode": 545,
    "reward": -140.128864,
    "length": 326,
    "time": 24684.943806,
    "actor_loss": 24.077543258666992,
    "critic_loss": 11.371391296386719,
    "ent_coef": 0.014604680240154266,
    "learning_rate": 0.001
  },
  {
    "episode": 546,
    "reward": -113.880065,
    "length": 143,
    "time": 24707.326152,
    "actor_loss": 21.782459259033203,
    "critic_loss": 28.72675895690918,
    "ent_coef": 0.013628640212118626,
    "learning_rate": 0.001
  },
  {
    "episode": 547,
    "reward": -110.251491,
    "length": 564,
    "time": 24787.350775,
    "actor_loss": 22.96457290649414,
    "critic_loss": 9.462011337280273,
    "ent_coef": 0.011832482181489468,
    "learning_rate": 0.001
  },
  {
    "episode": 548,
    "reward": -129.413619,
    "length": 262,
    "time": 24827.147732,
    "actor_loss": 20.66342544555664,
    "critic_loss": 6.532054901123047,
    "ent_coef": 0.01293825265020132,
    "learning_rate": 0.001
  },
  {
    "episode": 549,
    "reward": -120.021905,
    "length": 1,
    "time": 24841.009169,
    "actor_loss": 24.44249725341797,
    "critic_loss": 3.578922748565674,
    "ent_coef": 0.012938542291522026,
    "learning_rate": 0.001
  },
  {
    "episode": 550,
    "reward": -142.04779,
    "length": 283,
    "time": 24884.005121,
    "actor_loss": 24.451818466186523,
    "critic_loss": 3.099747657775879,
    "ent_coef": 0.012907004915177822,
    "learning_rate": 0.001
  },
  {
    "episode": 551,
    "reward": -134.294594,
    "length": 275,
    "time": 24922.732173,
    "actor_loss": 20.045757293701172,
    "critic_loss": 99.7469482421875,
    "ent_coef": 0.012322935275733471,
    "learning_rate": 0.001
  },
  {
    "episode": 552,
    "reward": -148.773472,
    "length": 458,
    "time": 24985.632025,
    "actor_loss": 21.80438804626465,
    "critic_loss": 1.0798996686935425,
    "ent_coef": 0.009214768186211586,
    "learning_rate": 0.001
  },
  {
    "episode": 553,
    "reward": -99.348784,
    "length": 77,
    "time": 24998.546822,
    "actor_loss": 22.14745330810547,
    "critic_loss": 3.60250186920166,
    "ent_coef": 0.009899849072098732,
    "learning_rate": 0.001
  },
  {
    "episode": 554,
    "reward": -94.045976,
    "length": 572,
    "time": 25078.57228,
    "actor_loss": 21.96299934387207,
    "critic_loss": 3.154873847961426,
    "ent_coef": 0.008698596619069576,
    "learning_rate": 0.001
  },
  {
    "episode": 555,
    "reward": -135.524948,
    "length": 589,
    "time": 25158.59514,
    "actor_loss": 19.657777786254883,
    "critic_loss": 1.4007896184921265,
    "ent_coef": 0.009324678219854832,
    "learning_rate": 0.001
  },
  {
    "episode": 556,
    "reward": -158.869495,
    "length": 291,
    "time": 25198.526407,
    "actor_loss": 21.679737091064453,
    "critic_loss": 8.060074806213379,
    "ent_coef": 0.009921478107571602,
    "learning_rate": 0.001
  },
  {
    "episode": 557,
    "reward": -115.170753,
    "length": 134,
    "time": 25218.777005,
    "actor_loss": 22.048986434936523,
    "critic_loss": 55.210731506347656,
    "ent_coef": 0.010563354007899761,
    "learning_rate": 0.001
  },
  {
    "episode": 558,
    "reward": -177.044506,
    "length": 331,
    "time": 25263.857581,
    "actor_loss": 21.455848693847656,
    "critic_loss": 4.03321647644043,
    "ent_coef": 0.008793921209871769,
    "learning_rate": 0.001
  },
  {
    "episode": 559,
    "reward": -122.885632,
    "length": 395,
    "time": 25320.184921,
    "actor_loss": 22.542556762695312,
    "critic_loss": 3.6042189598083496,
    "ent_coef": 0.007979225367307663,
    "learning_rate": 0.001
  },
  {
    "episode": 560,
    "reward": -129.145469,
    "length": 310,
    "time": 25364.875921,
    "actor_loss": 21.649791717529297,
    "critic_loss": 0.3923521339893341,
    "ent_coef": 0.007630002684891224,
    "learning_rate": 0.001
  },
  {
    "episode": 561,
    "reward": -190.347793,
    "length": 566,
    "time": 25442.7791,
    "actor_loss": 21.827373504638672,
    "critic_loss": 1.90854811668396,
    "ent_coef": 0.011384163983166218,
    "learning_rate": 0.001
  },
  {
    "episode": 562,
    "reward": -77.907851,
    "length": 598,
    "time": 25522.783342,
    "actor_loss": 21.298404693603516,
    "critic_loss": 0.9165806770324707,
    "ent_coef": 0.01433356199413538,
    "learning_rate": 0.001
  },
  {
    "episode": 563,
    "reward": -130.179554,
    "length": 225,
    "time": 25554.26958,
    "actor_loss": 19.784528732299805,
    "critic_loss": 90.24278259277344,
    "ent_coef": 0.014216247014701366,
    "learning_rate": 0.001
  },
  {
    "episode": 564,
    "reward": -109.113629,
    "length": 108,
    "time": 25571.600945,
    "actor_loss": 19.595630645751953,
    "critic_loss": 4.755034446716309,
    "ent_coef": 0.014425722882151604,
    "learning_rate": 0.001
  },
  {
    "episode": 565,
    "reward": -118.131408,
    "length": 173,
    "time": 25598.020701,
    "actor_loss": 20.29016876220703,
    "critic_loss": 3.8227572441101074,
    "ent_coef": 0.01359608955681324,
    "learning_rate": 0.001
  },
  {
    "episode": 566,
    "reward": -133.389899,
    "length": 373,
    "time": 25649.796108,
    "actor_loss": 21.80902671813965,
    "critic_loss": 1.5143901109695435,
    "ent_coef": 0.011966834776103497,
    "learning_rate": 0.001
  },
  {
    "episode": 567,
    "reward": -108.269646,
    "length": 166,
    "time": 25673.19126,
    "actor_loss": 19.63071060180664,
    "critic_loss": 4.773737907409668,
    "ent_coef": 0.012093545868992805,
    "learning_rate": 0.001
  },
  {
    "episode": 568,
    "reward": -111.454602,
    "length": 141,
    "time": 25695.677898,
    "actor_loss": 21.548206329345703,
    "critic_loss": 86.42593383789062,
    "ent_coef": 0.012658840045332909,
    "learning_rate": 0.001
  },
  {
    "episode": 569,
    "reward": -140.61669,
    "length": 237,
    "time": 25729.41149,
    "actor_loss": 22.48084259033203,
    "critic_loss": 1.7984873056411743,
    "ent_coef": 0.011928919702768326,
    "learning_rate": 0.001
  },
  {
    "episode": 570,
    "reward": -104.453176,
    "length": 147,
    "time": 25753.676819,
    "actor_loss": 22.792980194091797,
    "critic_loss": 5.061437129974365,
    "ent_coef": 0.011935058981180191,
    "learning_rate": 0.001
  },
  {
    "episode": 571,
    "reward": -100.465532,
    "length": 115,
    "time": 25771.744431,
    "actor_loss": 20.92120361328125,
    "critic_loss": 3.184985876083374,
    "ent_coef": 0.014593305997550488,
    "learning_rate": 0.001
  },
  {
    "episode": 572,
    "reward": -141.06124,
    "length": 284,
    "time": 25810.133975,
    "actor_loss": 23.531259536743164,
    "critic_loss": 106.53874206542969,
    "ent_coef": 0.013250431045889854,
    "learning_rate": 0.001
  },
  {
    "episode": 573,
    "reward": -106.825487,
    "length": 154,
    "time": 25832.392473,
    "actor_loss": 22.207923889160156,
    "critic_loss": 5.761061191558838,
    "ent_coef": 0.01222531683743,
    "learning_rate": 0.001
  },
  {
    "episode": 574,
    "reward": -111.235009,
    "length": 124,
    "time": 25851.787536,
    "actor_loss": 22.394546508789062,
    "critic_loss": 8.82726001739502,
    "ent_coef": 0.011493361555039883,
    "learning_rate": 0.001
  },
  {
    "episode": 575,
    "reward": -113.861482,
    "length": 69,
    "time": 25865.329504,
    "actor_loss": 20.664215087890625,
    "critic_loss": 6.957484722137451,
    "ent_coef": 0.011093254201114178,
    "learning_rate": 0.001
  },
  {
    "episode": 576,
    "reward": -141.19842,
    "length": 240,
    "time": 25901.852784,
    "actor_loss": 21.08492088317871,
    "critic_loss": 1.764249563217163,
    "ent_coef": 0.009910759516060352,
    "learning_rate": 0.001
  },
  {
    "episode": 577,
    "reward": -142.185993,
    "length": 352,
    "time": 25951.325721,
    "actor_loss": 20.228763580322266,
    "critic_loss": 13.14281177520752,
    "ent_coef": 0.010134200565516949,
    "learning_rate": 0.001
  },
  {
    "episode": 578,
    "reward": -178.700493,
    "length": 350,
    "time": 26002.058026,
    "actor_loss": 18.831886291503906,
    "critic_loss": 18.342830657958984,
    "ent_coef": 0.009625888429582119,
    "learning_rate": 0.001
  },
  {
    "episode": 579,
    "reward": -127.418614,
    "length": 238,
    "time": 26036.667065,
    "actor_loss": 20.164413452148438,
    "critic_loss": 0.7440025806427002,
    "ent_coef": 0.009117702022194862,
    "learning_rate": 0.001
  },
  {
    "episode": 580,
    "reward": -140.453525,
    "length": 339,
    "time": 26086.145988,
    "actor_loss": 22.99591827392578,
    "critic_loss": 71.98103332519531,
    "ent_coef": 0.009910679422318935,
    "learning_rate": 0.001
  },
  {
    "episode": 581,
    "reward": -177.696202,
    "length": 540,
    "time": 26164.253345,
    "actor_loss": 18.87656593322754,
    "critic_loss": 26.316917419433594,
    "ent_coef": 0.010329208336770535,
    "learning_rate": 0.001
  },
  {
    "episode": 582,
    "reward": -120.491191,
    "length": 17,
    "time": 26172.380696,
    "actor_loss": 23.696409225463867,
    "critic_loss": 2.227168560028076,
    "ent_coef": 0.010450726374983788,
    "learning_rate": 0.001
  },
  {
    "episode": 583,
    "reward": -69.285806,
    "length": 558,
    "time": 26252.449814,
    "actor_loss": 21.817249298095703,
    "critic_loss": 78.55592346191406,
    "ent_coef": 0.0109964394941926,
    "learning_rate": 0.001
  },
  {
    "episode": 584,
    "reward": -121.436349,
    "length": 219,
    "time": 26285.481108,
    "actor_loss": 24.751659393310547,
    "critic_loss": 7.277976036071777,
    "ent_coef": 0.009676072746515274,
    "learning_rate": 0.001
  },
  {
    "episode": 585,
    "reward": -101.94738,
    "length": 99,
    "time": 26301.862402,
    "actor_loss": 21.022354125976562,
    "critic_loss": 4.333925724029541,
    "ent_coef": 0.00960433017462492,
    "learning_rate": 0.001
  },
  {
    "episode": 586,
    "reward": -210.447662,
    "length": 570,
    "time": 26381.203674,
    "actor_loss": 21.033092498779297,
    "critic_loss": 126.08319091796875,
    "ent_coef": 0.012202090583741665,
    "learning_rate": 0.001
  },
  {
    "episode": 587,
    "reward": -131.696178,
    "length": 209,
    "time": 26411.295258,
    "actor_loss": 21.189287185668945,
    "critic_loss": 1.912163496017456,
    "ent_coef": 0.011764980852603912,
    "learning_rate": 0.001
  },
  {
    "episode": 588,
    "reward": -138.586665,
    "length": 590,
    "time": 26491.392645,
    "actor_loss": 22.48370361328125,
    "critic_loss": 65.88927459716797,
    "ent_coef": 0.007724004331976175,
    "learning_rate": 0.001
  },
  {
    "episode": 589,
    "reward": -115.237066,
    "length": 79,
    "time": 26507.287394,
    "actor_loss": 20.4549503326416,
    "critic_loss": 3.3109970092773438,
    "ent_coef": 0.007685354445129633,
    "learning_rate": 0.001
  },
  {
    "episode": 590,
    "reward": 61.17887,
    "length": 301,
    "time": 26551.882151,
    "actor_loss": 23.54340934753418,
    "critic_loss": 0.5741478204727173,
    "ent_coef": 0.006578847300261259,
    "learning_rate": 0.001
  },
  {
    "episode": 591,
    "reward": -169.053784,
    "length": 242,
    "time": 26586.743173,
    "actor_loss": 22.13409996032715,
    "critic_loss": 1.512622356414795,
    "ent_coef": 0.007340014912188053,
    "learning_rate": 0.001
  },
  {
    "episode": 592,
    "reward": -119.112057,
    "length": 196,
    "time": 26617.666293,
    "actor_loss": 21.58196258544922,
    "critic_loss": 1.3771915435791016,
    "ent_coef": 0.008435339666903019,
    "learning_rate": 0.001
  },
  {
    "episode": 593,
    "reward": -112.3045,
    "length": 76,
    "time": 26631.286364,
    "actor_loss": 25.001815795898438,
    "critic_loss": 3.7271761894226074,
    "ent_coef": 0.007746503222733736,
    "learning_rate": 0.001
  },
  {
    "episode": 594,
    "reward": -141.029649,
    "length": 566,
    "time": 26711.313876,
    "actor_loss": 21.469982147216797,
    "critic_loss": 1.1763064861297607,
    "ent_coef": 0.0076635149307549,
    "learning_rate": 0.001
  },
  {
    "episode": 595,
    "reward": -125.517316,
    "length": 103,
    "time": 26727.967184,
    "actor_loss": 20.470338821411133,
    "critic_loss": 8.575207710266113,
    "ent_coef": 0.007741669192910194,
    "learning_rate": 0.001
  },
  {
    "episode": 596,
    "reward": -115.673583,
    "length": 123,
    "time": 26746.626115,
    "actor_loss": 22.401077270507812,
    "critic_loss": 0.6034385561943054,
    "ent_coef": 0.00760169792920351,
    "learning_rate": 0.001
  },
  {
    "episode": 597,
    "reward": -142.172086,
    "length": 426,
    "time": 26804.813084,
    "actor_loss": 21.998092651367188,
    "critic_loss": 0.9336073398590088,
    "ent_coef": 0.0074926577508449554,
    "learning_rate": 0.001
  },
  {
    "episode": 598,
    "reward": -114.276704,
    "length": 76,
    "time": 26819.876985,
    "actor_loss": 21.078060150146484,
    "critic_loss": 1.1849299669265747,
    "ent_coef": 0.007338317576795816,
    "learning_rate": 0.001
  },
  {
    "episode": 599,
    "reward": -107.377374,
    "length": 80,
    "time": 26835.531624,
    "actor_loss": 21.67678451538086,
    "critic_loss": 7.065871238708496,
    "ent_coef": 0.007252557203173637,
    "learning_rate": 0.001
  },
  {
    "episode": 600,
    "reward": -140.596776,
    "length": 339,
    "time": 26882.067569,
    "actor_loss": 21.75746726989746,
    "critic_loss": 42.88905334472656,
    "ent_coef": 0.007478433661162853,
    "learning_rate": 0.001
  },
  {
    "episode": 601,
    "reward": -124.593708,
    "length": 270,
    "time": 26919.353279,
    "actor_loss": 23.987031936645508,
    "critic_loss": 4.537083625793457,
    "ent_coef": 0.007960841991007328,
    "learning_rate": 0.001
  },
  {
    "episode": 602,
    "reward": -140.003069,
    "length": 315,
    "time": 26962.75778,
    "actor_loss": 24.054489135742188,
    "critic_loss": 9.810306549072266,
    "ent_coef": 0.007316490635275841,
    "learning_rate": 0.001
  },
  {
    "episode": 603,
    "reward": -155.192012,
    "length": 471,
    "time": 27025.342493,
    "actor_loss": 22.568805694580078,
    "critic_loss": 21.47641372680664,
    "ent_coef": 0.008770240470767021,
    "learning_rate": 0.001
  },
  {
    "episode": 604,
    "reward": -128.90126,
    "length": 289,
    "time": 27064.632639,
    "actor_loss": 19.579540252685547,
    "critic_loss": 3.537316083908081,
    "ent_coef": 0.00933654885739088,
    "learning_rate": 0.001
  },
  {
    "episode": 605,
    "reward": -133.066471,
    "length": 179,
    "time": 27092.598305,
    "actor_loss": 23.161579132080078,
    "critic_loss": 26.940505981445312,
    "ent_coef": 0.009855602867901325,
    "learning_rate": 0.001
  },
  {
    "episode": 606,
    "reward": -116.958926,
    "length": 606,
    "time": 27172.681872,
    "actor_loss": 22.414886474609375,
    "critic_loss": 207.0480194091797,
    "ent_coef": 0.008030815981328487,
    "learning_rate": 0.001
  },
  {
    "episode": 607,
    "reward": -143.491733,
    "length": 267,
    "time": 27210.997796,
    "actor_loss": 23.159616470336914,
    "critic_loss": 49.825347900390625,
    "ent_coef": 0.008474782109260559,
    "learning_rate": 0.001
  },
  {
    "episode": 608,
    "reward": -102.215896,
    "length": 170,
    "time": 27236.126091,
    "actor_loss": 22.959367752075195,
    "critic_loss": 2.5697999000549316,
    "ent_coef": 0.00851072184741497,
    "learning_rate": 0.001
  },
  {
    "episode": 609,
    "reward": -123.579751,
    "length": 261,
    "time": 27272.115193,
    "actor_loss": 20.40439224243164,
    "critic_loss": 3.5856308937072754,
    "ent_coef": 0.008851046673953533,
    "learning_rate": 0.001
  },
  {
    "episode": 610,
    "reward": -181.984709,
    "length": 440,
    "time": 27330.403446,
    "actor_loss": 22.572704315185547,
    "critic_loss": 1.357259750366211,
    "ent_coef": 0.009602471254765987,
    "learning_rate": 0.001
  },
  {
    "episode": 611,
    "reward": -123.939628,
    "length": 218,
    "time": 27360.462401,
    "actor_loss": 25.492008209228516,
    "critic_loss": 7.787616729736328,
    "ent_coef": 0.008053598925471306,
    "learning_rate": 0.001
  },
  {
    "episode": 612,
    "reward": -102.126122,
    "length": 172,
    "time": 27386.08993,
    "actor_loss": 19.66350746154785,
    "critic_loss": 3.2578277587890625,
    "ent_coef": 0.010144871659576893,
    "learning_rate": 0.001
  },
  {
    "episode": 613,
    "reward": -101.26676,
    "length": 155,
    "time": 27410.213511,
    "actor_loss": 20.799644470214844,
    "critic_loss": 1.0039503574371338,
    "ent_coef": 0.010760325938463211,
    "learning_rate": 0.001
  },
  {
    "episode": 614,
    "reward": -117.965454,
    "length": 206,
    "time": 27439.172098,
    "actor_loss": 23.845455169677734,
    "critic_loss": 6.7528486251831055,
    "ent_coef": 0.010675051249563694,
    "learning_rate": 0.001
  },
  {
    "episode": 615,
    "reward": -106.37099,
    "length": 115,
    "time": 27457.271541,
    "actor_loss": 22.962295532226562,
    "critic_loss": 73.43873596191406,
    "ent_coef": 0.010316036641597748,
    "learning_rate": 0.001
  },
  {
    "episode": 616,
    "reward": -121.300302,
    "length": 44,
    "time": 27465.364323,
    "actor_loss": 24.568195343017578,
    "critic_loss": 17.307525634765625,
    "ent_coef": 0.0100410683080554,
    "learning_rate": 0.001
  },
  {
    "episode": 617,
    "reward": -112.146907,
    "length": 88,
    "time": 27481.062198,
    "actor_loss": 21.385910034179688,
    "critic_loss": 2.040418863296509,
    "ent_coef": 0.009484052658081055,
    "learning_rate": 0.001
  },
  {
    "episode": 618,
    "reward": -208.624388,
    "length": 531,
    "time": 27552.175828,
    "actor_loss": 23.216251373291016,
    "critic_loss": 81.0784912109375,
    "ent_coef": 0.008645525202155113,
    "learning_rate": 0.001
  },
  {
    "episode": 619,
    "reward": -125.864732,
    "length": 272,
    "time": 27589.922881,
    "actor_loss": 27.041818618774414,
    "critic_loss": 40.94392776489258,
    "ent_coef": 0.007613622583448887,
    "learning_rate": 0.001
  },
  {
    "episode": 620,
    "reward": -108.550249,
    "length": 211,
    "time": 27619.929548,
    "actor_loss": 23.67100715637207,
    "critic_loss": 53.48154067993164,
    "ent_coef": 0.0067109838128089905,
    "learning_rate": 0.001
  },
  {
    "episode": 621,
    "reward": -122.869616,
    "length": 264,
    "time": 27657.704957,
    "actor_loss": 20.957111358642578,
    "critic_loss": 151.44692993164062,
    "ent_coef": 0.006135809700936079,
    "learning_rate": 0.001
  },
  {
    "episode": 622,
    "reward": -124.265353,
    "length": 114,
    "time": 27675.57008,
    "actor_loss": 23.555126190185547,
    "critic_loss": 2.611905574798584,
    "ent_coef": 0.006149969529360533,
    "learning_rate": 0.001
  },
  {
    "episode": 623,
    "reward": -132.126171,
    "length": 153,
    "time": 27697.411044,
    "actor_loss": 23.46938705444336,
    "critic_loss": 1.806199550628662,
    "ent_coef": 0.006756292190402746,
    "learning_rate": 0.001
  },
  {
    "episode": 624,
    "reward": -124.779274,
    "length": 168,
    "time": 27722.907922,
    "actor_loss": 21.21944808959961,
    "critic_loss": 155.15188598632812,
    "ent_coef": 0.0068936715833842754,
    "learning_rate": 0.001
  },
  {
    "episode": 625,
    "reward": -200.486241,
    "length": 446,
    "time": 27782.503074,
    "actor_loss": 23.920066833496094,
    "critic_loss": 0.9256336688995361,
    "ent_coef": 0.007603202480822802,
    "learning_rate": 0.001
  },
  {
    "episode": 626,
    "reward": -91.460066,
    "length": 111,
    "time": 27801.012784,
    "actor_loss": 20.702709197998047,
    "critic_loss": 2.5971341133117676,
    "ent_coef": 0.00728211272507906,
    "learning_rate": 0.001
  },
  {
    "episode": 627,
    "reward": -127.588772,
    "length": 226,
    "time": 27835.28167,
    "actor_loss": 22.067737579345703,
    "critic_loss": 4.782745361328125,
    "ent_coef": 0.007070323918014765,
    "learning_rate": 0.001
  },
  {
    "episode": 628,
    "reward": -103.276141,
    "length": 110,
    "time": 27851.90624,
    "actor_loss": 23.9053897857666,
    "critic_loss": 16.090709686279297,
    "ent_coef": 0.0073351445607841015,
    "learning_rate": 0.001
  },
  {
    "episode": 629,
    "reward": -120.156736,
    "length": 6,
    "time": 27859.943168,
    "actor_loss": 24.529109954833984,
    "critic_loss": 1.5703623294830322,
    "ent_coef": 0.007346103899180889,
    "learning_rate": 0.001
  },
  {
    "episode": 630,
    "reward": -177.524928,
    "length": 458,
    "time": 27921.915815,
    "actor_loss": 26.09195899963379,
    "critic_loss": 24.466846466064453,
    "ent_coef": 0.010433638468384743,
    "learning_rate": 0.001
  },
  {
    "episode": 631,
    "reward": -99.043497,
    "length": 99,
    "time": 27938.149409,
    "actor_loss": 20.6079044342041,
    "critic_loss": 99.94320678710938,
    "ent_coef": 0.011289088055491447,
    "learning_rate": 0.001
  },
  {
    "episode": 632,
    "reward": -127.28287,
    "length": 303,
    "time": 27980.665288,
    "actor_loss": 24.878429412841797,
    "critic_loss": 104.425537109375,
    "ent_coef": 0.009569177404046059,
    "learning_rate": 0.001
  },
  {
    "episode": 633,
    "reward": -189.550713,
    "length": 493,
    "time": 28046.607106,
    "actor_loss": 23.01590347290039,
    "critic_loss": 70.23321533203125,
    "ent_coef": 0.00852308887988329,
    "learning_rate": 0.001
  },
  {
    "episode": 634,
    "reward": -117.33357,
    "length": 202,
    "time": 28075.369457,
    "actor_loss": 22.485103607177734,
    "critic_loss": 8.39300537109375,
    "ent_coef": 0.008823095820844173,
    "learning_rate": 0.001
  },
  {
    "episode": 635,
    "reward": -133.590403,
    "length": 247,
    "time": 28109.397103,
    "actor_loss": 23.52307891845703,
    "critic_loss": 67.38507080078125,
    "ent_coef": 0.01065679732710123,
    "learning_rate": 0.001
  },
  {
    "episode": 636,
    "reward": -123.654114,
    "length": 179,
    "time": 28137.297872,
    "actor_loss": 22.9576416015625,
    "critic_loss": 3.6954331398010254,
    "ent_coef": 0.009402335621416569,
    "learning_rate": 0.001
  },
  {
    "episode": 637,
    "reward": -122.80406,
    "length": 217,
    "time": 28168.014603,
    "actor_loss": 26.90202522277832,
    "critic_loss": 14.536699295043945,
    "ent_coef": 0.010372820310294628,
    "learning_rate": 0.001
  },
  {
    "episode": 638,
    "reward": -58.93504,
    "length": 580,
    "time": 28248.079186,
    "actor_loss": 23.9748477935791,
    "critic_loss": 8.893047332763672,
    "ent_coef": 0.00865546241402626,
    "learning_rate": 0.001
  },
  {
    "episode": 639,
    "reward": -147.417994,
    "length": 277,
    "time": 28286.09226,
    "actor_loss": 23.72311019897461,
    "critic_loss": 6.629273414611816,
    "ent_coef": 0.008411778137087822,
    "learning_rate": 0.001
  },
  {
    "episode": 640,
    "reward": -171.089557,
    "length": 358,
    "time": 28336.418677,
    "actor_loss": 22.561031341552734,
    "critic_loss": 80.65579986572266,
    "ent_coef": 0.009027236141264439,
    "learning_rate": 0.001
  },
  {
    "episode": 641,
    "reward": -119.891228,
    "length": 262,
    "time": 28372.541228,
    "actor_loss": 21.010128021240234,
    "critic_loss": 7.244556427001953,
    "ent_coef": 0.010284533724188805,
    "learning_rate": 0.001
  },
  {
    "episode": 642,
    "reward": -99.462156,
    "length": 601,
    "time": 28452.634722,
    "actor_loss": 23.083084106445312,
    "critic_loss": 2.429553508758545,
    "ent_coef": 0.007162943948060274,
    "learning_rate": 0.001
  },
  {
    "episode": 643,
    "reward": -116.822177,
    "length": 101,
    "time": 28468.862425,
    "actor_loss": 20.395347595214844,
    "critic_loss": 9.36268138885498,
    "ent_coef": 0.00845520943403244,
    "learning_rate": 0.001
  },
  {
    "episode": 644,
    "reward": -128.833528,
    "length": 166,
    "time": 28493.818852,
    "actor_loss": 26.462642669677734,
    "critic_loss": 183.49266052246094,
    "ent_coef": 0.009451255202293396,
    "learning_rate": 0.001
  },
  {
    "episode": 645,
    "reward": -187.243561,
    "length": 342,
    "time": 28541.719393,
    "actor_loss": 23.999759674072266,
    "critic_loss": 7.349994659423828,
    "ent_coef": 0.007297491189092398,
    "learning_rate": 0.001
  },
  {
    "episode": 646,
    "reward": -135.36441,
    "length": 157,
    "time": 28568.237502,
    "actor_loss": 22.404014587402344,
    "critic_loss": 98.59069061279297,
    "ent_coef": 0.0071237962692976,
    "learning_rate": 0.001
  },
  {
    "episode": 647,
    "reward": -79.306858,
    "length": 571,
    "time": 28648.298116,
    "actor_loss": 22.09733772277832,
    "critic_loss": 96.80154418945312,
    "ent_coef": 0.010614315047860146,
    "learning_rate": 0.001
  },
  {
    "episode": 648,
    "reward": -177.349406,
    "length": 422,
    "time": 28705.634347,
    "actor_loss": 25.3427734375,
    "critic_loss": 51.05541229248047,
    "ent_coef": 0.010616268031299114,
    "learning_rate": 0.001
  },
  {
    "episode": 649,
    "reward": -129.044716,
    "length": 270,
    "time": 28743.303044,
    "actor_loss": 21.556720733642578,
    "critic_loss": 73.96875762939453,
    "ent_coef": 0.009464144706726074,
    "learning_rate": 0.001
  },
  {
    "episode": 650,
    "reward": -221.167369,
    "length": 410,
    "time": 28798.709365,
    "actor_loss": 21.883098602294922,
    "critic_loss": 5.711886405944824,
    "ent_coef": 0.007650148589164019,
    "learning_rate": 0.001
  },
  {
    "episode": 651,
    "reward": -131.8358,
    "length": 174,
    "time": 28824.696251,
    "actor_loss": 20.808185577392578,
    "critic_loss": 2.3912014961242676,
    "ent_coef": 0.008841770701110363,
    "learning_rate": 0.001
  },
  {
    "episode": 652,
    "reward": -192.491705,
    "length": 456,
    "time": 28885.894697,
    "actor_loss": 20.554933547973633,
    "critic_loss": 8.110218048095703,
    "ent_coef": 0.010381569154560566,
    "learning_rate": 0.001
  },
  {
    "episode": 653,
    "reward": -117.796561,
    "length": 232,
    "time": 28917.829002,
    "actor_loss": 23.517444610595703,
    "critic_loss": 101.76338195800781,
    "ent_coef": 0.009424760937690735,
    "learning_rate": 0.001
  },
  {
    "episode": 654,
    "reward": -122.784124,
    "length": 75,
    "time": 28932.631921,
    "actor_loss": 19.431411743164062,
    "critic_loss": 3.376819372177124,
    "ent_coef": 0.00952394213527441,
    "learning_rate": 0.001
  },
  {
    "episode": 655,
    "reward": -116.640575,
    "length": 612,
    "time": 29012.743437,
    "actor_loss": 22.95629119873047,
    "critic_loss": 6.321075916290283,
    "ent_coef": 0.008433405309915543,
    "learning_rate": 0.001
  },
  {
    "episode": 656,
    "reward": -141.462967,
    "length": 193,
    "time": 29041.232254,
    "actor_loss": 23.76645278930664,
    "critic_loss": 40.21421813964844,
    "ent_coef": 0.008081088773906231,
    "learning_rate": 0.001
  },
  {
    "episode": 657,
    "reward": -150.097017,
    "length": 376,
    "time": 29091.472753,
    "actor_loss": 20.1748104095459,
    "critic_loss": 2.1232151985168457,
    "ent_coef": 0.008670032024383545,
    "learning_rate": 0.001
  },
  {
    "episode": 658,
    "reward": -136.64046,
    "length": 354,
    "time": 29139.27102,
    "actor_loss": 23.443561553955078,
    "critic_loss": 11.084537506103516,
    "ent_coef": 0.008030418306589127,
    "learning_rate": 0.001
  },
  {
    "episode": 659,
    "reward": -207.045504,
    "length": 472,
    "time": 29202.003058,
    "actor_loss": 23.314964294433594,
    "critic_loss": 51.289024353027344,
    "ent_coef": 0.00920789036899805,
    "learning_rate": 0.001
  },
  {
    "episode": 660,
    "reward": -111.767713,
    "length": 143,
    "time": 29222.853973,
    "actor_loss": 25.981369018554688,
    "critic_loss": 5.790163040161133,
    "ent_coef": 0.010184340178966522,
    "learning_rate": 0.001
  },
  {
    "episode": 661,
    "reward": -150.30006,
    "length": 224,
    "time": 29256.03167,
    "actor_loss": 27.97247886657715,
    "critic_loss": 89.18844604492188,
    "ent_coef": 0.009849739260971546,
    "learning_rate": 0.001
  },
  {
    "episode": 662,
    "reward": -155.859067,
    "length": 378,
    "time": 29307.627914,
    "actor_loss": 19.860309600830078,
    "critic_loss": 6.280500411987305,
    "ent_coef": 0.009475094266235828,
    "learning_rate": 0.001
  },
  {
    "episode": 663,
    "reward": -163.024966,
    "length": 286,
    "time": 29347.960798,
    "actor_loss": 24.211660385131836,
    "critic_loss": 0.805296003818512,
    "ent_coef": 0.008345862850546837,
    "learning_rate": 0.001
  },
  {
    "episode": 664,
    "reward": -156.362664,
    "length": 290,
    "time": 29389.74541,
    "actor_loss": 24.307106018066406,
    "critic_loss": 0.47200143337249756,
    "ent_coef": 0.010000500828027725,
    "learning_rate": 0.001
  },
  {
    "episode": 665,
    "reward": -110.621059,
    "length": 177,
    "time": 29417.729005,
    "actor_loss": 24.108623504638672,
    "critic_loss": 67.30679321289062,
    "ent_coef": 0.008857636712491512,
    "learning_rate": 0.001
  },
  {
    "episode": 666,
    "reward": -202.774031,
    "length": 556,
    "time": 29491.93018,
    "actor_loss": 21.778764724731445,
    "critic_loss": 6.50834846496582,
    "ent_coef": 0.012337544932961464,
    "learning_rate": 0.001
  },
  {
    "episode": 667,
    "reward": -121.541217,
    "length": 235,
    "time": 29524.248701,
    "actor_loss": 22.5587215423584,
    "critic_loss": 130.73257446289062,
    "ent_coef": 0.011987869627773762,
    "learning_rate": 0.001
  },
  {
    "episode": 668,
    "reward": -63.164224,
    "length": 588,
    "time": 29604.340699,
    "actor_loss": 25.38339614868164,
    "critic_loss": 14.79448413848877,
    "ent_coef": 0.009540928527712822,
    "learning_rate": 0.001
  },
  {
    "episode": 669,
    "reward": -156.587701,
    "length": 349,
    "time": 29651.697063,
    "actor_loss": 21.74576759338379,
    "critic_loss": 8.177450180053711,
    "ent_coef": 0.010331962257623672,
    "learning_rate": 0.001
  },
  {
    "episode": 670,
    "reward": -153.97681,
    "length": 233,
    "time": 29684.240375,
    "actor_loss": 22.29749870300293,
    "critic_loss": 27.85512924194336,
    "ent_coef": 0.008416516706347466,
    "learning_rate": 0.001
  },
  {
    "episode": 671,
    "reward": -113.382984,
    "length": 179,
    "time": 29709.925747,
    "actor_loss": 24.43677520751953,
    "critic_loss": 9.1992769241333,
    "ent_coef": 0.00873279944062233,
    "learning_rate": 0.001
  },
  {
    "episode": 672,
    "reward": -111.459148,
    "length": 107,
    "time": 29727.343571,
    "actor_loss": 20.920265197753906,
    "critic_loss": 98.76617431640625,
    "ent_coef": 0.009665526449680328,
    "learning_rate": 0.001
  },
  {
    "episode": 673,
    "reward": -121.176204,
    "length": 263,
    "time": 29765.841265,
    "actor_loss": 23.343935012817383,
    "critic_loss": 4.498325347900391,
    "ent_coef": 0.009871109388768673,
    "learning_rate": 0.001
  },
  {
    "episode": 674,
    "reward": -108.044779,
    "length": 218,
    "time": 29795.716179,
    "actor_loss": 23.28757095336914,
    "critic_loss": 8.334250450134277,
    "ent_coef": 0.009720574133098125,
    "learning_rate": 0.001
  },
  {
    "episode": 675,
    "reward": -120.670352,
    "length": 237,
    "time": 29829.888023,
    "actor_loss": 21.87409019470215,
    "critic_loss": 3.0183658599853516,
    "ent_coef": 0.010755795985460281,
    "learning_rate": 0.001
  },
  {
    "episode": 676,
    "reward": -117.647002,
    "length": 190,
    "time": 29857.498812,
    "actor_loss": 23.085403442382812,
    "critic_loss": 6.498915672302246,
    "ent_coef": 0.010558710433542728,
    "learning_rate": 0.001
  },
  {
    "episode": 677,
    "reward": -120.021703,
    "length": 1,
    "time": 29866.24321,
    "actor_loss": 25.025278091430664,
    "critic_loss": 6.508160591125488,
    "ent_coef": 0.010540942661464214,
    "learning_rate": 0.001
  },
  {
    "episode": 678,
    "reward": 123.330362,
    "length": 48,
    "time": 29875.100976,
    "actor_loss": 22.457313537597656,
    "critic_loss": 6.302768230438232,
    "ent_coef": 0.009866125881671906,
    "learning_rate": 0.001
  },
  {
    "episode": 679,
    "reward": -139.095214,
    "length": 173,
    "time": 29899.374059,
    "actor_loss": 24.55914306640625,
    "critic_loss": 0.833160400390625,
    "ent_coef": 0.009808050468564034,
    "learning_rate": 0.001
  },
  {
    "episode": 680,
    "reward": -165.718528,
    "length": 404,
    "time": 29954.888009,
    "actor_loss": 23.706695556640625,
    "critic_loss": 7.805493354797363,
    "ent_coef": 0.007889999076724052,
    "learning_rate": 0.001
  },
  {
    "episode": 681,
    "reward": -116.10063,
    "length": 196,
    "time": 29982.340423,
    "actor_loss": 23.28142547607422,
    "critic_loss": 8.986047744750977,
    "ent_coef": 0.00738917151466012,
    "learning_rate": 0.001
  },
  {
    "episode": 682,
    "reward": -180.86721,
    "length": 334,
    "time": 30030.420609,
    "actor_loss": 22.540443420410156,
    "critic_loss": 9.222366333007812,
    "ent_coef": 0.006922933738678694,
    "learning_rate": 0.001
  },
  {
    "episode": 683,
    "reward": -120.619986,
    "length": 26,
    "time": 30038.497716,
    "actor_loss": 25.64523696899414,
    "critic_loss": 1.009649634361267,
    "ent_coef": 0.00691687548533082,
    "learning_rate": 0.001
  },
  {
    "episode": 684,
    "reward": -115.611716,
    "length": 117,
    "time": 30057.983549,
    "actor_loss": 24.07839012145996,
    "critic_loss": 1.0476007461547852,
    "ent_coef": 0.006947000976651907,
    "learning_rate": 0.001
  },
  {
    "episode": 685,
    "reward": -178.290916,
    "length": 374,
    "time": 30108.558946,
    "actor_loss": 25.72906494140625,
    "critic_loss": 88.12239074707031,
    "ent_coef": 0.009668582119047642,
    "learning_rate": 0.001
  },
  {
    "episode": 686,
    "reward": -140.010246,
    "length": 220,
    "time": 30139.636651,
    "actor_loss": 26.109397888183594,
    "critic_loss": 5.3709516525268555,
    "ent_coef": 0.009563570842146873,
    "learning_rate": 0.001
  },
  {
    "episode": 687,
    "reward": -103.388233,
    "length": 104,
    "time": 30156.448258,
    "actor_loss": 24.296146392822266,
    "critic_loss": 4.0464067459106445,
    "ent_coef": 0.009727983735501766,
    "learning_rate": 0.001
  },
  {
    "episode": 688,
    "reward": -128.120339,
    "length": 199,
    "time": 30185.06882,
    "actor_loss": 21.652299880981445,
    "critic_loss": 1.593210220336914,
    "ent_coef": 0.009792820550501347,
    "learning_rate": 0.001
  },
  {
    "episode": 689,
    "reward": -140.962748,
    "length": 224,
    "time": 30216.925656,
    "actor_loss": 23.428272247314453,
    "critic_loss": 1.2222731113433838,
    "ent_coef": 0.008759758435189724,
    "learning_rate": 0.001
  },
  {
    "episode": 690,
    "reward": -128.156241,
    "length": 134,
    "time": 30237.693064,
    "actor_loss": 22.989164352416992,
    "critic_loss": 3.1760334968566895,
    "ent_coef": 0.008395993150770664,
    "learning_rate": 0.001
  },
  {
    "episode": 691,
    "reward": -169.63351,
    "length": 282,
    "time": 30276.031218,
    "actor_loss": 25.897045135498047,
    "critic_loss": 86.84225463867188,
    "ent_coef": 0.007248072884976864,
    "learning_rate": 0.001
  },
  {
    "episode": 692,
    "reward": -117.525415,
    "length": 180,
    "time": 30302.823054,
    "actor_loss": 24.859264373779297,
    "critic_loss": 4.7312469482421875,
    "ent_coef": 0.006906510330736637,
    "learning_rate": 0.001
  },
  {
    "episode": 693,
    "reward": -121.904209,
    "length": 182,
    "time": 30331.217297,
    "actor_loss": 23.14177131652832,
    "critic_loss": 1.2248034477233887,
    "ent_coef": 0.007345767226070166,
    "learning_rate": 0.001
  },
  {
    "episode": 694,
    "reward": -146.480752,
    "length": 349,
    "time": 30379.323353,
    "actor_loss": 23.54543685913086,
    "critic_loss": 6.968500137329102,
    "ent_coef": 0.00899810716509819,
    "learning_rate": 0.001
  },
  {
    "episode": 695,
    "reward": -134.211063,
    "length": 277,
    "time": 30417.738523,
    "actor_loss": 23.397594451904297,
    "critic_loss": 2.676957368850708,
    "ent_coef": 0.009191233664751053,
    "learning_rate": 0.001
  },
  {
    "episode": 696,
    "reward": -120.713166,
    "length": 27,
    "time": 30425.806597,
    "actor_loss": 23.74164390563965,
    "critic_loss": 7.849662780761719,
    "ent_coef": 0.00923102255910635,
    "learning_rate": 0.001
  },
  {
    "episode": 697,
    "reward": -134.72047,
    "length": 167,
    "time": 30451.027817,
    "actor_loss": 27.17254066467285,
    "critic_loss": 5.08879280090332,
    "ent_coef": 0.008074404671788216,
    "learning_rate": 0.001
  },
  {
    "episode": 698,
    "reward": -137.263836,
    "length": 203,
    "time": 30480.453312,
    "actor_loss": 24.384777069091797,
    "critic_loss": 1.68667471408844,
    "ent_coef": 0.008602585643529892,
    "learning_rate": 0.001
  },
  {
    "episode": 699,
    "reward": -193.092497,
    "length": 477,
    "time": 30543.824571,
    "actor_loss": 21.646167755126953,
    "critic_loss": 2.491893768310547,
    "ent_coef": 0.010466684587299824,
    "learning_rate": 0.001
  },
  {
    "episode": 700,
    "reward": -156.717238,
    "length": 337,
    "time": 30590.228165,
    "actor_loss": 24.745376586914062,
    "critic_loss": 18.855777740478516,
    "ent_coef": 0.011088229715824127,
    "learning_rate": 0.001
  },
  {
    "episode": 701,
    "reward": -179.711608,
    "length": 300,
    "time": 30633.261531,
    "actor_loss": 21.696590423583984,
    "critic_loss": 30.753746032714844,
    "ent_coef": 0.008913705125451088,
    "learning_rate": 0.001
  },
  {
    "episode": 702,
    "reward": -139.782304,
    "length": 203,
    "time": 30664.446878,
    "actor_loss": 25.767881393432617,
    "critic_loss": 33.0439453125,
    "ent_coef": 0.008314598351716995,
    "learning_rate": 0.001
  },
  {
    "episode": 703,
    "reward": -122.663478,
    "length": 158,
    "time": 30688.367686,
    "actor_loss": 22.620458602905273,
    "critic_loss": 1.3573187589645386,
    "ent_coef": 0.009727070108056068,
    "learning_rate": 0.001
  },
  {
    "episode": 704,
    "reward": -101.584917,
    "length": 125,
    "time": 30707.094503,
    "actor_loss": 21.36882781982422,
    "critic_loss": 3.4622273445129395,
    "ent_coef": 0.010412425734102726,
    "learning_rate": 0.001
  },
  {
    "episode": 705,
    "reward": -124.916017,
    "length": 210,
    "time": 30738.690137,
    "actor_loss": 24.90505599975586,
    "critic_loss": 5.44064998626709,
    "ent_coef": 0.009769290685653687,
    "learning_rate": 0.001
  },
  {
    "episode": 706,
    "reward": -93.34159,
    "length": 613,
    "time": 30818.779308,
    "actor_loss": 21.3338565826416,
    "critic_loss": 2.0051496028900146,
    "ent_coef": 0.007500832434743643,
    "learning_rate": 0.001
  },
  {
    "episode": 707,
    "reward": -117.441316,
    "length": 138,
    "time": 30839.852427,
    "actor_loss": 25.182575225830078,
    "critic_loss": 229.99334716796875,
    "ent_coef": 0.007604207377880812,
    "learning_rate": 0.001
  },
  {
    "episode": 708,
    "reward": -186.22871,
    "length": 303,
    "time": 30882.94142,
    "actor_loss": 27.37668228149414,
    "critic_loss": 225.7091827392578,
    "ent_coef": 0.009660757146775723,
    "learning_rate": 0.001
  },
  {
    "episode": 709,
    "reward": -133.214771,
    "length": 212,
    "time": 30914.759531,
    "actor_loss": 21.847700119018555,
    "critic_loss": 3.3408150672912598,
    "ent_coef": 0.010379652492702007,
    "learning_rate": 0.001
  },
  {
    "episode": 710,
    "reward": -134.217412,
    "length": 170,
    "time": 30941.503324,
    "actor_loss": 26.317432403564453,
    "critic_loss": 2.8257617950439453,
    "ent_coef": 0.010761783458292484,
    "learning_rate": 0.001
  },
  {
    "episode": 711,
    "reward": -155.701744,
    "length": 271,
    "time": 30978.706264,
    "actor_loss": 23.500579833984375,
    "critic_loss": 11.448654174804688,
    "ent_coef": 0.011229831725358963,
    "learning_rate": 0.001
  },
  {
    "episode": 712,
    "reward": -116.713694,
    "length": 171,
    "time": 31004.782172,
    "actor_loss": 24.296401977539062,
    "critic_loss": 3.2751641273498535,
    "ent_coef": 0.010900260880589485,
    "learning_rate": 0.001
  },
  {
    "episode": 713,
    "reward": -120.331265,
    "length": 12,
    "time": 31012.819534,
    "actor_loss": 23.641407012939453,
    "critic_loss": 1.5756943225860596,
    "ent_coef": 0.010855537839233875,
    "learning_rate": 0.001
  },
  {
    "episode": 714,
    "reward": -146.144926,
    "length": 447,
    "time": 31073.878404,
    "actor_loss": 23.284942626953125,
    "critic_loss": 115.57428741455078,
    "ent_coef": 0.01247363444417715,
    "learning_rate": 0.001
  },
  {
    "episode": 715,
    "reward": -186.877264,
    "length": 411,
    "time": 31133.147927,
    "actor_loss": 24.414634704589844,
    "critic_loss": 2.6336617469787598,
    "ent_coef": 0.013249862939119339,
    "learning_rate": 0.001
  },
  {
    "episode": 716,
    "reward": -124.285307,
    "length": 221,
    "time": 31165.199825,
    "actor_loss": 25.801326751708984,
    "critic_loss": 1.7703001499176025,
    "ent_coef": 0.01085888221859932,
    "learning_rate": 0.001
  },
  {
    "episode": 717,
    "reward": -114.801181,
    "length": 81,
    "time": 31181.356503,
    "actor_loss": 23.253616333007812,
    "critic_loss": 1.877450942993164,
    "ent_coef": 0.010053855367004871,
    "learning_rate": 0.001
  },
  {
    "episode": 718,
    "reward": -181.567093,
    "length": 389,
    "time": 31233.670172,
    "actor_loss": 24.108783721923828,
    "critic_loss": 1.6852818727493286,
    "ent_coef": 0.011455782689154148,
    "learning_rate": 0.001
  },
  {
    "episode": 719,
    "reward": -105.18199,
    "length": 105,
    "time": 31249.610453,
    "actor_loss": 25.481962203979492,
    "critic_loss": 10.481889724731445,
    "ent_coef": 0.010598888620734215,
    "learning_rate": 0.001
  },
  {
    "episode": 720,
    "reward": -123.685651,
    "length": 135,
    "time": 31270.046549,
    "actor_loss": 25.498802185058594,
    "critic_loss": 3.533923625946045,
    "ent_coef": 0.00993883702903986,
    "learning_rate": 0.001
  },
  {
    "episode": 721,
    "reward": -99.980938,
    "length": 105,
    "time": 31287.941182,
    "actor_loss": 23.705860137939453,
    "critic_loss": 9.609991073608398,
    "ent_coef": 0.009460529312491417,
    "learning_rate": 0.001
  },
  {
    "episode": 722,
    "reward": -117.83395,
    "length": 144,
    "time": 31311.059225,
    "actor_loss": 26.73415756225586,
    "critic_loss": 196.34213256835938,
    "ent_coef": 0.009831879287958145,
    "learning_rate": 0.001
  },
  {
    "episode": 723,
    "reward": -119.640033,
    "length": 168,
    "time": 31335.938964,
    "actor_loss": 24.884464263916016,
    "critic_loss": 5.509897232055664,
    "ent_coef": 0.008650503121316433,
    "learning_rate": 0.001
  },
  {
    "episode": 724,
    "reward": -111.910907,
    "length": 154,
    "time": 31361.219885,
    "actor_loss": 21.99420928955078,
    "critic_loss": 2.3616371154785156,
    "ent_coef": 0.008054259233176708,
    "learning_rate": 0.001
  },
  {
    "episode": 725,
    "reward": -147.836791,
    "length": 206,
    "time": 31391.906677,
    "actor_loss": 24.383333206176758,
    "critic_loss": 4.9428815841674805,
    "ent_coef": 0.009052444249391556,
    "learning_rate": 0.001
  },
  {
    "episode": 726,
    "reward": -73.530788,
    "length": 585,
    "time": 31471.985453,
    "actor_loss": 24.41413116455078,
    "critic_loss": 30.12788963317871,
    "ent_coef": 0.012213878333568573,
    "learning_rate": 0.001
  },
  {
    "episode": 727,
    "reward": -135.021648,
    "length": 148,
    "time": 31494.117901,
    "actor_loss": 23.430858612060547,
    "critic_loss": 3.692178249359131,
    "ent_coef": 0.011542036198079586,
    "learning_rate": 0.001
  },
  {
    "episode": 728,
    "reward": -104.626183,
    "length": 165,
    "time": 31519.262871,
    "actor_loss": 27.587114334106445,
    "critic_loss": 4.295866966247559,
    "ent_coef": 0.010087056085467339,
    "learning_rate": 0.001
  },
  {
    "episode": 729,
    "reward": -118.218412,
    "length": 610,
    "time": 31599.270976,
    "actor_loss": 26.871089935302734,
    "critic_loss": 1.7134528160095215,
    "ent_coef": 0.013270728290081024,
    "learning_rate": 0.001
  },
  {
    "episode": 730,
    "reward": -145.541093,
    "length": 228,
    "time": 31631.031466,
    "actor_loss": 24.98436737060547,
    "critic_loss": 136.74569702148438,
    "ent_coef": 0.013079782947897911,
    "learning_rate": 0.001
  },
  {
    "episode": 731,
    "reward": -145.195413,
    "length": 595,
    "time": 31711.135714,
    "actor_loss": 27.491744995117188,
    "critic_loss": 58.9052734375,
    "ent_coef": 0.014021823182702065,
    "learning_rate": 0.001
  },
  {
    "episode": 732,
    "reward": -169.131774,
    "length": 306,
    "time": 31754.595854,
    "actor_loss": 27.937267303466797,
    "critic_loss": 12.412626266479492,
    "ent_coef": 0.012571706436574459,
    "learning_rate": 0.001
  },
  {
    "episode": 733,
    "reward": -120.393025,
    "length": 15,
    "time": 31762.713183,
    "actor_loss": 23.22005844116211,
    "critic_loss": 4.5853424072265625,
    "ent_coef": 0.012500393204391003,
    "learning_rate": 0.001
  },
  {
    "episode": 734,
    "reward": -173.561844,
    "length": 275,
    "time": 31801.066369,
    "actor_loss": 25.61265754699707,
    "critic_loss": 2.0231573581695557,
    "ent_coef": 0.010501003824174404,
    "learning_rate": 0.001
  },
  {
    "episode": 735,
    "reward": -118.019577,
    "length": 157,
    "time": 31823.677471,
    "actor_loss": 23.81028938293457,
    "critic_loss": 0.35750898718833923,
    "ent_coef": 0.00979926623404026,
    "learning_rate": 0.001
  },
  {
    "episode": 736,
    "reward": -121.984396,
    "length": 128,
    "time": 31843.777377,
    "actor_loss": 26.414531707763672,
    "critic_loss": 1.4270777702331543,
    "ent_coef": 0.010187992826104164,
    "learning_rate": 0.001
  },
  {
    "episode": 737,
    "reward": -199.579126,
    "length": 412,
    "time": 31900.58913,
    "actor_loss": 25.40515899658203,
    "critic_loss": 2.795656442642212,
    "ent_coef": 0.0114542031660676,
    "learning_rate": 0.001
  },
  {
    "episode": 738,
    "reward": -132.080559,
    "length": 217,
    "time": 31935.299966,
    "actor_loss": 24.814105987548828,
    "critic_loss": 14.436498641967773,
    "ent_coef": 0.011367414146661758,
    "learning_rate": 0.001
  },
  {
    "episode": 739,
    "reward": -111.576262,
    "length": 198,
    "time": 31966.681413,
    "actor_loss": 24.443557739257812,
    "critic_loss": 93.06837463378906,
    "ent_coef": 0.010620045475661755,
    "learning_rate": 0.001
  },
  {
    "episode": 740,
    "reward": -112.991301,
    "length": 592,
    "time": 32046.695421,
    "actor_loss": 22.94923973083496,
    "critic_loss": 4.361300468444824,
    "ent_coef": 0.009772836230695248,
    "learning_rate": 0.001
  },
  {
    "episode": 741,
    "reward": -146.631834,
    "length": 222,
    "time": 32078.351411,
    "actor_loss": 22.567548751831055,
    "critic_loss": 15.144308090209961,
    "ent_coef": 0.010901923291385174,
    "learning_rate": 0.001
  },
  {
    "episode": 742,
    "reward": -131.708435,
    "length": 130,
    "time": 32099.224956,
    "actor_loss": 24.746286392211914,
    "critic_loss": 7.605462074279785,
    "ent_coef": 0.009174209088087082,
    "learning_rate": 0.001
  },
  {
    "episode": 743,
    "reward": -138.68863,
    "length": 233,
    "time": 32134.373312,
    "actor_loss": 26.740842819213867,
    "critic_loss": 116.46049499511719,
    "ent_coef": 0.007571726106107235,
    "learning_rate": 0.001
  },
  {
    "episode": 744,
    "reward": -107.413261,
    "length": 135,
    "time": 32156.041635,
    "actor_loss": 24.003501892089844,
    "critic_loss": 3.8347017765045166,
    "ent_coef": 0.007744963280856609,
    "learning_rate": 0.001
  },
  {
    "episode": 745,
    "reward": -133.961602,
    "length": 209,
    "time": 32186.976946,
    "actor_loss": 26.117233276367188,
    "critic_loss": 3.063335418701172,
    "ent_coef": 0.008756004273891449,
    "learning_rate": 0.001
  },
  {
    "episode": 746,
    "reward": -186.041903,
    "length": 262,
    "time": 32225.156824,
    "actor_loss": 24.576583862304688,
    "critic_loss": 1.3855736255645752,
    "ent_coef": 0.008098914287984371,
    "learning_rate": 0.001
  },
  {
    "episode": 747,
    "reward": -129.254828,
    "length": 220,
    "time": 32256.946091,
    "actor_loss": 25.194541931152344,
    "critic_loss": 31.635751724243164,
    "ent_coef": 0.008048757910728455,
    "learning_rate": 0.001
  },
  {
    "episode": 748,
    "reward": -136.313229,
    "length": 273,
    "time": 32295.917932,
    "actor_loss": 25.371105194091797,
    "critic_loss": 2.6363534927368164,
    "ent_coef": 0.00979117676615715,
    "learning_rate": 0.001
  },
  {
    "episode": 749,
    "reward": -224.740749,
    "length": 489,
    "time": 32362.062619,
    "actor_loss": 25.357009887695312,
    "critic_loss": 134.5640106201172,
    "ent_coef": 0.010353908874094486,
    "learning_rate": 0.001
  },
  {
    "episode": 750,
    "reward": -202.364394,
    "length": 601,
    "time": 32441.242504,
    "actor_loss": 24.11276626586914,
    "critic_loss": 0.8855047821998596,
    "ent_coef": 0.008357587270438671,
    "learning_rate": 0.001
  },
  {
    "episode": 751,
    "reward": -258.000539,
    "length": 534,
    "time": 32512.008685,
    "actor_loss": 27.109928131103516,
    "critic_loss": 23.659608840942383,
    "ent_coef": 0.009928453713655472,
    "learning_rate": 0.001
  },
  {
    "episode": 752,
    "reward": -196.625602,
    "length": 376,
    "time": 32565.872332,
    "actor_loss": 26.563079833984375,
    "critic_loss": 8.15243148803711,
    "ent_coef": 0.010643340647220612,
    "learning_rate": 0.001
  },
  {
    "episode": 753,
    "reward": -238.298643,
    "length": 576,
    "time": 32645.203986,
    "actor_loss": 25.808643341064453,
    "critic_loss": 1.8765619993209839,
    "ent_coef": 0.010302646085619926,
    "learning_rate": 0.001
  },
  {
    "episode": 754,
    "reward": -129.720163,
    "length": 455,
    "time": 32705.270324,
    "actor_loss": 26.591699600219727,
    "critic_loss": 0.3847256302833557,
    "ent_coef": 0.010015962645411491,
    "learning_rate": 0.001
  },
  {
    "episode": 755,
    "reward": -110.18307,
    "length": 97,
    "time": 32720.266656,
    "actor_loss": 25.36791229248047,
    "critic_loss": 2.484560012817383,
    "ent_coef": 0.00994924921542406,
    "learning_rate": 0.001
  },
  {
    "episode": 756,
    "reward": -153.646133,
    "length": 419,
    "time": 32777.164489,
    "actor_loss": 27.620830535888672,
    "critic_loss": 16.896656036376953,
    "ent_coef": 0.00960729829967022,
    "learning_rate": 0.001
  },
  {
    "episode": 757,
    "reward": -130.413002,
    "length": 228,
    "time": 32808.662795,
    "actor_loss": 26.192907333374023,
    "critic_loss": 195.4710693359375,
    "ent_coef": 0.010782308876514435,
    "learning_rate": 0.001
  },
  {
    "episode": 758,
    "reward": -125.024765,
    "length": 189,
    "time": 32835.35815,
    "actor_loss": 23.604846954345703,
    "critic_loss": 6.301150321960449,
    "ent_coef": 0.014053476974368095,
    "learning_rate": 0.001
  },
  {
    "episode": 759,
    "reward": -138.684455,
    "length": 308,
    "time": 32876.693172,
    "actor_loss": 20.747547149658203,
    "critic_loss": 2.0183205604553223,
    "ent_coef": 0.012603703886270523,
    "learning_rate": 0.001
  },
  {
    "episode": 760,
    "reward": 102.484634,
    "length": 317,
    "time": 32921.192696,
    "actor_loss": 24.720325469970703,
    "critic_loss": 1.560405969619751,
    "ent_coef": 0.009652058593928814,
    "learning_rate": 0.001
  },
  {
    "episode": 761,
    "reward": -122.697386,
    "length": 105,
    "time": 32939.204129,
    "actor_loss": 24.902095794677734,
    "critic_loss": 3.6901907920837402,
    "ent_coef": 0.009325270541012287,
    "learning_rate": 0.001
  },
  {
    "episode": 762,
    "reward": 115.423161,
    "length": 103,
    "time": 32957.301676,
    "actor_loss": 24.15021514892578,
    "critic_loss": 1.2517991065979004,
    "ent_coef": 0.008776537142693996,
    "learning_rate": 0.001
  },
  {
    "episode": 763,
    "reward": -166.64328,
    "length": 421,
    "time": 33014.010381,
    "actor_loss": 28.00084686279297,
    "critic_loss": 2.192744255065918,
    "ent_coef": 0.007514117751270533,
    "learning_rate": 0.001
  },
  {
    "episode": 764,
    "reward": -117.558777,
    "length": 164,
    "time": 33039.193177,
    "actor_loss": 29.14937973022461,
    "critic_loss": 106.699462890625,
    "ent_coef": 0.006940633989870548,
    "learning_rate": 0.001
  },
  {
    "episode": 765,
    "reward": -143.254197,
    "length": 310,
    "time": 33082.34821,
    "actor_loss": 23.932140350341797,
    "critic_loss": 8.370805740356445,
    "ent_coef": 0.008049441501498222,
    "learning_rate": 0.001
  },
  {
    "episode": 766,
    "reward": -219.922602,
    "length": 556,
    "time": 33160.275438,
    "actor_loss": 26.170406341552734,
    "critic_loss": 2.242642402648926,
    "ent_coef": 0.007458643522113562,
    "learning_rate": 0.001
  },
  {
    "episode": 767,
    "reward": -154.343286,
    "length": 308,
    "time": 33205.977367,
    "actor_loss": 27.648605346679688,
    "critic_loss": 1.9929392337799072,
    "ent_coef": 0.007497800514101982,
    "learning_rate": 0.001
  },
  {
    "episode": 768,
    "reward": -120.521516,
    "length": 20,
    "time": 33214.020303,
    "actor_loss": 24.692428588867188,
    "critic_loss": 5.99923849105835,
    "ent_coef": 0.007458736188709736,
    "learning_rate": 0.001
  },
  {
    "episode": 769,
    "reward": -123.128102,
    "length": 248,
    "time": 33248.512452,
    "actor_loss": 26.599536895751953,
    "critic_loss": 3.509929656982422,
    "ent_coef": 0.009542957879602909,
    "learning_rate": 0.001
  },
  {
    "episode": 770,
    "reward": 143.361023,
    "length": 44,
    "time": 33257.015164,
    "actor_loss": 24.685325622558594,
    "critic_loss": 1.5939052104949951,
    "ent_coef": 0.009752939455211163,
    "learning_rate": 0.001
  },
  {
    "episode": 771,
    "reward": -120.021922,
    "length": 1,
    "time": 33265.378904,
    "actor_loss": 25.868831634521484,
    "critic_loss": 6.231021881103516,
    "ent_coef": 0.009755260311067104,
    "learning_rate": 0.001
  },
  {
    "episode": 772,
    "reward": -135.142616,
    "length": 146,
    "time": 33286.922202,
    "actor_loss": 25.291770935058594,
    "critic_loss": 2.409381866455078,
    "ent_coef": 0.01006276160478592,
    "learning_rate": 0.001
  },
  {
    "episode": 773,
    "reward": -149.307674,
    "length": 173,
    "time": 33313.994144,
    "actor_loss": 26.634126663208008,
    "critic_loss": 22.866287231445312,
    "ent_coef": 0.01092065405100584,
    "learning_rate": 0.001
  },
  {
    "episode": 774,
    "reward": -163.329739,
    "length": 598,
    "time": 33392.607773,
    "actor_loss": 27.371261596679688,
    "critic_loss": 0.6273406147956848,
    "ent_coef": 0.009364147670567036,
    "learning_rate": 0.001
  },
  {
    "episode": 775,
    "reward": -95.9554,
    "length": 156,
    "time": 33415.343421,
    "actor_loss": 26.01854133605957,
    "critic_loss": 3.137108564376831,
    "ent_coef": 0.009560059756040573,
    "learning_rate": 0.001
  },
  {
    "episode": 776,
    "reward": -114.055992,
    "length": 89,
    "time": 33429.790893,
    "actor_loss": 27.288896560668945,
    "critic_loss": 69.17760467529297,
    "ent_coef": 0.009972271509468555,
    "learning_rate": 0.001
  },
  {
    "episode": 777,
    "reward": -100.197563,
    "length": 151,
    "time": 33454.483532,
    "actor_loss": 26.491594314575195,
    "critic_loss": 49.45759582519531,
    "ent_coef": 0.009970270097255707,
    "learning_rate": 0.001
  },
  {
    "episode": 778,
    "reward": -122.030994,
    "length": 244,
    "time": 33489.284313,
    "actor_loss": 27.362266540527344,
    "critic_loss": 2.5113773345947266,
    "ent_coef": 0.008377041667699814,
    "learning_rate": 0.001
  },
  {
    "episode": 779,
    "reward": -132.359029,
    "length": 204,
    "time": 33518.232261,
    "actor_loss": 26.46721076965332,
    "critic_loss": 1.5987968444824219,
    "ent_coef": 0.007346990052610636,
    "learning_rate": 0.001
  },
  {
    "episode": 780,
    "reward": -100.022708,
    "length": 99,
    "time": 33533.399405,
    "actor_loss": 29.181320190429688,
    "critic_loss": 11.819374084472656,
    "ent_coef": 0.00751767260953784,
    "learning_rate": 0.001
  },
  {
    "episode": 781,
    "reward": -134.768322,
    "length": 213,
    "time": 33564.220396,
    "actor_loss": 28.07320213317871,
    "critic_loss": 1.4859669208526611,
    "ent_coef": 0.0077331215143203735,
    "learning_rate": 0.001
  },
  {
    "episode": 782,
    "reward": -229.244535,
    "length": 587,
    "time": 33642.723706,
    "actor_loss": 25.363967895507812,
    "critic_loss": 2.7375621795654297,
    "ent_coef": 0.009638399817049503,
    "learning_rate": 0.001
  },
  {
    "episode": 783,
    "reward": -211.943515,
    "length": 523,
    "time": 33712.891176,
    "actor_loss": 25.572154998779297,
    "critic_loss": 1.375213861465454,
    "ent_coef": 0.008298533968627453,
    "learning_rate": 0.001
  },
  {
    "episode": 784,
    "reward": -145.343292,
    "length": 264,
    "time": 33750.169673,
    "actor_loss": 25.19427490234375,
    "critic_loss": 6.249567031860352,
    "ent_coef": 0.007351160515099764,
    "learning_rate": 0.001
  },
  {
    "episode": 785,
    "reward": -159.533541,
    "length": 354,
    "time": 33799.692877,
    "actor_loss": 28.05733871459961,
    "critic_loss": 70.56399536132812,
    "ent_coef": 0.007174607366323471,
    "learning_rate": 0.001
  },
  {
    "episode": 786,
    "reward": -130.872413,
    "length": 259,
    "time": 33838.253075,
    "actor_loss": 24.016632080078125,
    "critic_loss": 5.864542007446289,
    "ent_coef": 0.00848095491528511,
    "learning_rate": 0.001
  },
  {
    "episode": 787,
    "reward": -118.255275,
    "length": 182,
    "time": 33868.112744,
    "actor_loss": 27.40631866455078,
    "critic_loss": 2.6034293174743652,
    "ent_coef": 0.009401878342032433,
    "learning_rate": 0.001
  },
  {
    "episode": 788,
    "reward": -173.562708,
    "length": 324,
    "time": 33915.764906,
    "actor_loss": 26.065086364746094,
    "critic_loss": 3.090771198272705,
    "ent_coef": 0.009351153858006,
    "learning_rate": 0.001
  },
  {
    "episode": 789,
    "reward": -140.023316,
    "length": 219,
    "time": 33948.202414,
    "actor_loss": 24.467409133911133,
    "critic_loss": 4.238528728485107,
    "ent_coef": 0.011072221212089062,
    "learning_rate": 0.001
  },
  {
    "episode": 790,
    "reward": -170.669675,
    "length": 361,
    "time": 33998.874297,
    "actor_loss": 25.535484313964844,
    "critic_loss": 0.5775501132011414,
    "ent_coef": 0.01195015013217926,
    "learning_rate": 0.001
  },
  {
    "episode": 791,
    "reward": -118.567667,
    "length": 184,
    "time": 34025.021778,
    "actor_loss": 27.026073455810547,
    "critic_loss": 105.69473266601562,
    "ent_coef": 0.01007496565580368,
    "learning_rate": 0.001
  },
  {
    "episode": 792,
    "reward": -125.294379,
    "length": 286,
    "time": 34065.035412,
    "actor_loss": 25.116024017333984,
    "critic_loss": 4.915580749511719,
    "ent_coef": 0.009957745671272278,
    "learning_rate": 0.001
  },
  {
    "episode": 793,
    "reward": -102.957453,
    "length": 83,
    "time": 34078.26282,
    "actor_loss": 28.661453247070312,
    "critic_loss": 83.28153228759766,
    "ent_coef": 0.011160791851580143,
    "learning_rate": 0.001
  },
  {
    "episode": 794,
    "reward": -81.599361,
    "length": 604,
    "time": 34158.340707,
    "actor_loss": 27.476295471191406,
    "critic_loss": 3.551043748855591,
    "ent_coef": 0.011231519281864166,
    "learning_rate": 0.001
  },
  {
    "episode": 795,
    "reward": -122.746999,
    "length": 263,
    "time": 34193.938822,
    "actor_loss": 26.427043914794922,
    "critic_loss": 59.272220611572266,
    "ent_coef": 0.009812180884182453,
    "learning_rate": 0.001
  },
  {
    "episode": 796,
    "reward": -136.292089,
    "length": 531,
    "time": 34266.607795,
    "actor_loss": 25.64052963256836,
    "critic_loss": 0.7160428762435913,
    "ent_coef": 0.010036462917923927,
    "learning_rate": 0.001
  },
  {
    "episode": 797,
    "reward": -110.814856,
    "length": 214,
    "time": 34298.390213,
    "actor_loss": 24.614652633666992,
    "critic_loss": 1.5232274532318115,
    "ent_coef": 0.009610290639102459,
    "learning_rate": 0.001
  },
  {
    "episode": 798,
    "reward": -162.753823,
    "length": 380,
    "time": 34351.386784,
    "actor_loss": 28.400514602661133,
    "critic_loss": 1.5422031879425049,
    "ent_coef": 0.011559711769223213,
    "learning_rate": 0.001
  },
  {
    "episode": 799,
    "reward": -116.38762,
    "length": 158,
    "time": 34374.347735,
    "actor_loss": 28.014739990234375,
    "critic_loss": 3.9717483520507812,
    "ent_coef": 0.010628287680447102,
    "learning_rate": 0.001
  },
  {
    "episode": 800,
    "reward": -57.317987,
    "length": 606,
    "time": 34454.389852,
    "actor_loss": 25.419662475585938,
    "critic_loss": 2.74149227142334,
    "ent_coef": 0.008216445334255695,
    "learning_rate": 0.001
  },
  {
    "episode": 801,
    "reward": -146.363112,
    "length": 270,
    "time": 34491.128886,
    "actor_loss": 27.117143630981445,
    "critic_loss": 104.37261962890625,
    "ent_coef": 0.008097651414573193,
    "learning_rate": 0.001
  },
  {
    "episode": 802,
    "reward": -135.260059,
    "length": 286,
    "time": 34530.287214,
    "actor_loss": 25.665096282958984,
    "critic_loss": 19.66085433959961,
    "ent_coef": 0.009369801729917526,
    "learning_rate": 0.001
  },
  {
    "episode": 803,
    "reward": -120.021582,
    "length": 1,
    "time": 34538.727228,
    "actor_loss": 25.893404006958008,
    "critic_loss": 3.5919342041015625,
    "ent_coef": 0.009364951401948929,
    "learning_rate": 0.001
  },
  {
    "episode": 804,
    "reward": -111.612046,
    "length": 138,
    "time": 34558.708218,
    "actor_loss": 25.040376663208008,
    "critic_loss": 9.669116973876953,
    "ent_coef": 0.009271620772778988,
    "learning_rate": 0.001
  },
  {
    "episode": 805,
    "reward": -132.891229,
    "length": 211,
    "time": 34588.194778,
    "actor_loss": 25.52252960205078,
    "critic_loss": 2.090006113052368,
    "ent_coef": 0.008986170403659344,
    "learning_rate": 0.001
  },
  {
    "episode": 806,
    "reward": -150.110491,
    "length": 334,
    "time": 34634.652475,
    "actor_loss": 28.04538345336914,
    "critic_loss": 1.4296785593032837,
    "ent_coef": 0.011017648503184319,
    "learning_rate": 0.001
  },
  {
    "episode": 807,
    "reward": -276.384164,
    "length": 550,
    "time": 34709.6831,
    "actor_loss": 28.779216766357422,
    "critic_loss": 1.0229520797729492,
    "ent_coef": 0.009971605613827705,
    "learning_rate": 0.001
  },
  {
    "episode": 808,
    "reward": -110.749758,
    "length": 117,
    "time": 34728.956203,
    "actor_loss": 26.964927673339844,
    "critic_loss": 103.04121398925781,
    "ent_coef": 0.009605723433196545,
    "learning_rate": 0.001
  },
  {
    "episode": 809,
    "reward": -106.492654,
    "length": 113,
    "time": 34745.73835,
    "actor_loss": 26.78534507751465,
    "critic_loss": 2.1221625804901123,
    "ent_coef": 0.009345060214400291,
    "learning_rate": 0.001
  },
  {
    "episode": 810,
    "reward": -161.666852,
    "length": 341,
    "time": 34791.232393,
    "actor_loss": 25.240825653076172,
    "critic_loss": 1.0711455345153809,
    "ent_coef": 0.00900990143418312,
    "learning_rate": 0.001
  },
  {
    "episode": 811,
    "reward": -97.604242,
    "length": 136,
    "time": 34814.805994,
    "actor_loss": 22.4104061126709,
    "critic_loss": 1.8346624374389648,
    "ent_coef": 0.009837714023888111,
    "learning_rate": 0.001
  },
  {
    "episode": 812,
    "reward": -113.420826,
    "length": 253,
    "time": 34850.178715,
    "actor_loss": 27.698467254638672,
    "critic_loss": 2.417180061340332,
    "ent_coef": 0.009357158094644547,
    "learning_rate": 0.001
  },
  {
    "episode": 813,
    "reward": -130.352616,
    "length": 221,
    "time": 34880.85763,
    "actor_loss": 29.23162841796875,
    "critic_loss": 1.174912929534912,
    "ent_coef": 0.010071051307022572,
    "learning_rate": 0.001
  },
  {
    "episode": 814,
    "reward": -143.026898,
    "length": 446,
    "time": 34940.029567,
    "actor_loss": 27.796335220336914,
    "critic_loss": 5.368740081787109,
    "ent_coef": 0.011082066223025322,
    "learning_rate": 0.001
  },
  {
    "episode": 815,
    "reward": -153.084661,
    "length": 312,
    "time": 34983.069996,
    "actor_loss": 26.57994842529297,
    "critic_loss": 9.682466506958008,
    "ent_coef": 0.009659209288656712,
    "learning_rate": 0.001
  },
  {
    "episode": 816,
    "reward": -125.573808,
    "length": 436,
    "time": 35041.473793,
    "actor_loss": 27.086606979370117,
    "critic_loss": 0.5907102823257446,
    "ent_coef": 0.012264647521078587,
    "learning_rate": 0.001
  },
  {
    "episode": 817,
    "reward": 85.601097,
    "length": 504,
    "time": 35108.335156,
    "actor_loss": 23.949779510498047,
    "critic_loss": 0.5700066685676575,
    "ent_coef": 0.012695308774709702,
    "learning_rate": 0.001
  },
  {
    "episode": 818,
    "reward": -215.974566,
    "length": 517,
    "time": 35177.489891,
    "actor_loss": 27.14247703552246,
    "critic_loss": 1.2954779863357544,
    "ent_coef": 0.012067502364516258,
    "learning_rate": 0.001
  },
  {
    "episode": 819,
    "reward": -144.67914,
    "length": 374,
    "time": 35226.801792,
    "actor_loss": 27.13754653930664,
    "critic_loss": 23.824369430541992,
    "ent_coef": 0.012085048481822014,
    "learning_rate": 0.001
  },
  {
    "episode": 820,
    "reward": -118.333481,
    "length": 134,
    "time": 35247.265215,
    "actor_loss": 24.666500091552734,
    "critic_loss": 4.611533164978027,
    "ent_coef": 0.01228133775293827,
    "learning_rate": 0.001
  },
  {
    "episode": 821,
    "reward": -168.034739,
    "length": 521,
    "time": 35316.707587,
    "actor_loss": 27.6672306060791,
    "critic_loss": 13.250494003295898,
    "ent_coef": 0.011897080577909946,
    "learning_rate": 0.001
  },
  {
    "episode": 822,
    "reward": -105.719455,
    "length": 159,
    "time": 35340.671627,
    "actor_loss": 27.38874626159668,
    "critic_loss": 1.4465217590332031,
    "ent_coef": 0.011327470652759075,
    "learning_rate": 0.001
  },
  {
    "episode": 823,
    "reward": -135.486214,
    "length": 216,
    "time": 35370.878775,
    "actor_loss": 25.700143814086914,
    "critic_loss": 84.08757019042969,
    "ent_coef": 0.01128832995891571,
    "learning_rate": 0.001
  },
  {
    "episode": 824,
    "reward": -172.55079,
    "length": 517,
    "time": 35439.709095,
    "actor_loss": 29.647199630737305,
    "critic_loss": 87.33383178710938,
    "ent_coef": 0.012392845004796982,
    "learning_rate": 0.001
  },
  {
    "episode": 825,
    "reward": -108.47452,
    "length": 105,
    "time": 35456.304912,
    "actor_loss": 25.34621810913086,
    "critic_loss": 54.4780158996582,
    "ent_coef": 0.011816464364528656,
    "learning_rate": 0.001
  },
  {
    "episode": 826,
    "reward": -115.858149,
    "length": 119,
    "time": 35475.318343,
    "actor_loss": 25.158065795898438,
    "critic_loss": 4.087319850921631,
    "ent_coef": 0.011321378871798515,
    "learning_rate": 0.001
  },
  {
    "episode": 827,
    "reward": -120.021646,
    "length": 1,
    "time": 35483.525494,
    "actor_loss": 23.106761932373047,
    "critic_loss": 1.6560128927230835,
    "ent_coef": 0.011312183924019337,
    "learning_rate": 0.001
  },
  {
    "episode": 828,
    "reward": -157.030812,
    "length": 373,
    "time": 35536.084213,
    "actor_loss": 26.419267654418945,
    "critic_loss": 21.691444396972656,
    "ent_coef": 0.01233871653676033,
    "learning_rate": 0.001
  },
  {
    "episode": 829,
    "reward": -120.021597,
    "length": 1,
    "time": 35547.693535,
    "actor_loss": 27.78228187561035,
    "critic_loss": 88.8542709350586,
    "ent_coef": 0.012365792877972126,
    "learning_rate": 0.001
  },
  {
    "episode": 830,
    "reward": -136.196783,
    "length": 288,
    "time": 35590.091147,
    "actor_loss": 26.02450942993164,
    "critic_loss": 4.813149929046631,
    "ent_coef": 0.014896758832037449,
    "learning_rate": 0.001
  },
  {
    "episode": 831,
    "reward": -107.174616,
    "length": 124,
    "time": 35609.199754,
    "actor_loss": 25.675678253173828,
    "critic_loss": 3.943443775177002,
    "ent_coef": 0.016543999314308167,
    "learning_rate": 0.001
  },
  {
    "episode": 832,
    "reward": -183.761327,
    "length": 453,
    "time": 35669.954261,
    "actor_loss": 27.564680099487305,
    "critic_loss": 122.25224304199219,
    "ent_coef": 0.012460806407034397,
    "learning_rate": 0.001
  },
  {
    "episode": 833,
    "reward": -115.117651,
    "length": 91,
    "time": 35686.146916,
    "actor_loss": 27.542320251464844,
    "critic_loss": 2.216036796569824,
    "ent_coef": 0.012378966435790062,
    "learning_rate": 0.001
  },
  {
    "episode": 834,
    "reward": -121.311318,
    "length": 40,
    "time": 35694.17879,
    "actor_loss": 27.309001922607422,
    "critic_loss": 3.2360634803771973,
    "ent_coef": 0.012684895657002926,
    "learning_rate": 0.001
  },
  {
    "episode": 835,
    "reward": -120.355641,
    "length": 12,
    "time": 35702.222921,
    "actor_loss": 25.227819442749023,
    "critic_loss": 3.951045036315918,
    "ent_coef": 0.012662631459534168,
    "learning_rate": 0.001
  },
  {
    "episode": 836,
    "reward": -129.210106,
    "length": 150,
    "time": 35724.527341,
    "actor_loss": 26.747472763061523,
    "critic_loss": 1.3189492225646973,
    "ent_coef": 0.011768588796257973,
    "learning_rate": 0.001
  },
  {
    "episode": 837,
    "reward": -148.235454,
    "length": 260,
    "time": 35760.459023,
    "actor_loss": 28.25689697265625,
    "critic_loss": 113.97203063964844,
    "ent_coef": 0.010770550929009914,
    "learning_rate": 0.001
  },
  {
    "episode": 838,
    "reward": -36.949584,
    "length": 606,
    "time": 35840.547251,
    "actor_loss": 25.97691535949707,
    "critic_loss": 112.29801177978516,
    "ent_coef": 0.010535099543631077,
    "learning_rate": 0.001
  },
  {
    "episode": 839,
    "reward": -122.480722,
    "length": 105,
    "time": 35858.801405,
    "actor_loss": 26.305198669433594,
    "critic_loss": 117.02767181396484,
    "ent_coef": 0.010707427747547626,
    "learning_rate": 0.001
  },
  {
    "episode": 840,
    "reward": -117.611262,
    "length": 134,
    "time": 35882.955034,
    "actor_loss": 27.471839904785156,
    "critic_loss": 14.021954536437988,
    "ent_coef": 0.01055697351694107,
    "learning_rate": 0.001
  },
  {
    "episode": 841,
    "reward": -154.052157,
    "length": 254,
    "time": 35918.211808,
    "actor_loss": 26.193758010864258,
    "critic_loss": 1.3834514617919922,
    "ent_coef": 0.011170816607773304,
    "learning_rate": 0.001
  },
  {
    "episode": 842,
    "reward": -144.381985,
    "length": 595,
    "time": 35998.288216,
    "actor_loss": 29.41185760498047,
    "critic_loss": 3.2325339317321777,
    "ent_coef": 0.013233906589448452,
    "learning_rate": 0.001
  },
  {
    "episode": 843,
    "reward": -128.573844,
    "length": 242,
    "time": 36031.971048,
    "actor_loss": 26.329437255859375,
    "critic_loss": 2.373638153076172,
    "ent_coef": 0.012681150808930397,
    "learning_rate": 0.001
  },
  {
    "episode": 844,
    "reward": -104.839244,
    "length": 145,
    "time": 36054.329574,
    "actor_loss": 26.04056167602539,
    "critic_loss": 33.003170013427734,
    "ent_coef": 0.012484691105782986,
    "learning_rate": 0.001
  },
  {
    "episode": 845,
    "reward": -120.637514,
    "length": 21,
    "time": 36062.433517,
    "actor_loss": 28.314929962158203,
    "critic_loss": 3.5442423820495605,
    "ent_coef": 0.012418827041983604,
    "learning_rate": 0.001
  },
  {
    "episode": 846,
    "reward": -119.444579,
    "length": 222,
    "time": 36093.603797,
    "actor_loss": 27.953350067138672,
    "critic_loss": 4.634487628936768,
    "ent_coef": 0.01206456869840622,
    "learning_rate": 0.001
  },
  {
    "episode": 847,
    "reward": -125.124262,
    "length": 239,
    "time": 36128.266182,
    "actor_loss": 31.62049674987793,
    "critic_loss": 39.37384033203125,
    "ent_coef": 0.011181209236383438,
    "learning_rate": 0.001
  },
  {
    "episode": 848,
    "reward": -111.630373,
    "length": 77,
    "time": 36142.974614,
    "actor_loss": 27.15843963623047,
    "critic_loss": 5.807247638702393,
    "ent_coef": 0.011428594589233398,
    "learning_rate": 0.001
  },
  {
    "episode": 849,
    "reward": -113.926678,
    "length": 222,
    "time": 36174.979172,
    "actor_loss": 23.920812606811523,
    "critic_loss": 28.75105857849121,
    "ent_coef": 0.009772361256182194,
    "learning_rate": 0.001
  },
  {
    "episode": 850,
    "reward": -170.098114,
    "length": 293,
    "time": 36216.405044,
    "actor_loss": 28.13864517211914,
    "critic_loss": 86.38154602050781,
    "ent_coef": 0.009796921163797379,
    "learning_rate": 0.001
  },
  {
    "episode": 851,
    "reward": -143.513053,
    "length": 191,
    "time": 36243.963448,
    "actor_loss": 27.976261138916016,
    "critic_loss": 2.0256950855255127,
    "ent_coef": 0.012667964212596416,
    "learning_rate": 0.001
  },
  {
    "episode": 852,
    "reward": 131.00746,
    "length": 56,
    "time": 36255.024993,
    "actor_loss": 25.41797637939453,
    "critic_loss": 2.565621852874756,
    "ent_coef": 0.01307841669768095,
    "learning_rate": 0.001
  },
  {
    "episode": 853,
    "reward": -189.611667,
    "length": 429,
    "time": 36315.867049,
    "actor_loss": 23.84941864013672,
    "critic_loss": 1.6926435232162476,
    "ent_coef": 0.014890189282596111,
    "learning_rate": 0.001
  },
  {
    "episode": 854,
    "reward": -120.021324,
    "length": 1,
    "time": 36346.598546,
    "actor_loss": 26.539897918701172,
    "critic_loss": 177.60763549804688,
    "ent_coef": 0.014886689372360706,
    "learning_rate": 0.001
  },
  {
    "episode": 855,
    "reward": -120.021383,
    "length": 1,
    "time": 36377.33046,
    "actor_loss": 24.34160614013672,
    "critic_loss": 2.168421506881714,
    "ent_coef": 0.014881203882396221,
    "learning_rate": 0.001
  },
  {
    "episode": 856,
    "reward": -120.02097,
    "length": 1,
    "time": 36408.111291,
    "actor_loss": 27.241586685180664,
    "critic_loss": 16.94171905517578,
    "ent_coef": 0.014877386391162872,
    "learning_rate": 0.001
  },
  {
    "episode": 857,
    "reward": -120.020583,
    "length": 1,
    "time": 36438.883435,
    "actor_loss": 22.160335540771484,
    "critic_loss": 31.754058837890625,
    "ent_coef": 0.014872507192194462,
    "learning_rate": 0.001
  },
  {
    "episode": 858,
    "reward": -120.021385,
    "length": 1,
    "time": 36469.623821,
    "actor_loss": 30.043317794799805,
    "critic_loss": 3.067519426345825,
    "ent_coef": 0.014868797734379768,
    "learning_rate": 0.001
  },
  {
    "episode": 859,
    "reward": -120.021069,
    "length": 1,
    "time": 36500.369264,
    "actor_loss": 25.674869537353516,
    "critic_loss": 2.3085408210754395,
    "ent_coef": 0.014862531796097755,
    "learning_rate": 0.001
  },
  {
    "episode": 860,
    "reward": -120.021274,
    "length": 1,
    "time": 36531.1242,
    "actor_loss": 26.93449592590332,
    "critic_loss": 2.2398548126220703,
    "ent_coef": 0.014856664463877678,
    "learning_rate": 0.001
  }
]